{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(Y='full', batch_size=4, bert_parallel_count=None, bert_parallel_final_layer='sum', bidirectional=None, cell_type='gru', code_emb=None, criterion='prec_at_8', cuda_device_no=1, data_path='./mimicdata/mimic3/train_full.csv', dropout=0.2, embed_file='./mimicdata/mimic3/processed_full.embed', embed_size=100, filter_size='10', from_scratch=False, gpu=True, last_module='caml_attn', lmbda=0, lr=5e-05, max_sequence_length=2500, model='bert-tiny', n_epochs=15, num_filter_maps=50, patience=10, pool=None, pos=False, pretrain=True, pretrain_batch_size=1, pretrain_datafile='./mimicdata/mimic3/pretrain_bert_tiny_2500', pretrain_epochs=3, pretrain_lr=0.0001, public_model=None, quiet=None, redefined_tokenizer=True, rnn_dim=128, rnn_layers=1, samples=None, seed=1367, stack_filters=None, test_model=None, tokenizer_path='./tokenizers/bert-tiny-mimic3-full-100-limit-100000-vocab.txt', version='mimic3', vocab='./mimicdata/mimic3/vocab.csv', warmup_steps=0, weight_decay=0)\n",
      "[pretrain] create config, model\n",
      "[pretrain] prepare optimizer, scheduler\n",
      "[pretrain] create dataloader\n",
      "[pretrain] start epoch\n",
      "0it [00:00, ?it/s]Train epoch: 0 [batch #0, batch_size 1, seq length 2500]\tLoss: 11.983726\n",
      "25it [00:02,  8.77it/s]Train epoch: 0 [batch #25, batch_size 1, seq length 2500]\tLoss: 11.154247\n",
      "50it [00:05,  8.79it/s]Train epoch: 0 [batch #50, batch_size 1, seq length 2500]\tLoss: 10.106557\n",
      "75it [00:08,  8.77it/s]Train epoch: 0 [batch #75, batch_size 1, seq length 2500]\tLoss: 9.142443\n",
      "100it [00:11,  8.78it/s]Train epoch: 0 [batch #100, batch_size 1, seq length 2500]\tLoss: 8.335648\n",
      "125it [00:14,  8.80it/s]Train epoch: 0 [batch #125, batch_size 1, seq length 2500]\tLoss: 8.005662\n",
      "150it [00:17,  8.79it/s]Train epoch: 0 [batch #150, batch_size 1, seq length 2500]\tLoss: 7.490252\n",
      "175it [00:20,  8.72it/s]Train epoch: 0 [batch #175, batch_size 1, seq length 2500]\tLoss: 7.447006\n",
      "200it [00:22,  8.76it/s]Train epoch: 0 [batch #200, batch_size 1, seq length 2500]\tLoss: 7.134561\n",
      "225it [00:25,  8.73it/s]Train epoch: 0 [batch #225, batch_size 1, seq length 2500]\tLoss: 7.138224\n",
      "250it [00:28,  8.79it/s]Train epoch: 0 [batch #250, batch_size 1, seq length 2500]\tLoss: 7.092832\n",
      "275it [00:31,  8.80it/s]Train epoch: 0 [batch #275, batch_size 1, seq length 2500]\tLoss: 7.017278\n",
      "300it [00:34,  8.79it/s]Train epoch: 0 [batch #300, batch_size 1, seq length 2500]\tLoss: 7.227330\n",
      "325it [00:37,  8.80it/s]Train epoch: 0 [batch #325, batch_size 1, seq length 2500]\tLoss: 6.890234\n",
      "350it [00:40,  8.77it/s]Train epoch: 0 [batch #350, batch_size 1, seq length 2500]\tLoss: 7.159616\n",
      "375it [00:42,  8.78it/s]Train epoch: 0 [batch #375, batch_size 1, seq length 2500]\tLoss: 7.049206\n",
      "400it [00:45,  8.76it/s]Train epoch: 0 [batch #400, batch_size 1, seq length 2500]\tLoss: 7.248583\n",
      "425it [00:48,  8.72it/s]Train epoch: 0 [batch #425, batch_size 1, seq length 2500]\tLoss: 6.833982\n",
      "450it [00:51,  8.78it/s]Train epoch: 0 [batch #450, batch_size 1, seq length 2500]\tLoss: 7.139547\n",
      "475it [00:54,  8.77it/s]Train epoch: 0 [batch #475, batch_size 1, seq length 2500]\tLoss: 6.935740\n",
      "500it [00:57,  8.70it/s]Train epoch: 0 [batch #500, batch_size 1, seq length 2500]\tLoss: 6.887252\n",
      "525it [00:59,  8.76it/s]Train epoch: 0 [batch #525, batch_size 1, seq length 2500]\tLoss: 6.752984\n",
      "550it [01:02,  8.72it/s]Train epoch: 0 [batch #550, batch_size 1, seq length 2500]\tLoss: 6.696375\n",
      "575it [01:05,  8.45it/s]Train epoch: 0 [batch #575, batch_size 1, seq length 2500]\tLoss: 6.828143\n",
      "600it [01:08,  8.76it/s]Train epoch: 0 [batch #600, batch_size 1, seq length 2500]\tLoss: 6.911068\n",
      "625it [01:11,  8.62it/s]Train epoch: 0 [batch #625, batch_size 1, seq length 2500]\tLoss: 6.995156\n",
      "650it [01:14,  8.77it/s]Train epoch: 0 [batch #650, batch_size 1, seq length 2500]\tLoss: 6.692192\n",
      "675it [01:17,  8.77it/s]Train epoch: 0 [batch #675, batch_size 1, seq length 2500]\tLoss: 6.899894\n",
      "700it [01:19,  8.78it/s]Train epoch: 0 [batch #700, batch_size 1, seq length 2500]\tLoss: 6.670982\n",
      "725it [01:22,  8.76it/s]Train epoch: 0 [batch #725, batch_size 1, seq length 2500]\tLoss: 6.884053\n",
      "750it [01:25,  8.76it/s]Train epoch: 0 [batch #750, batch_size 1, seq length 2500]\tLoss: 6.853910\n",
      "775it [01:28,  8.77it/s]Train epoch: 0 [batch #775, batch_size 1, seq length 2500]\tLoss: 6.684672\n",
      "800it [01:31,  8.76it/s]Train epoch: 0 [batch #800, batch_size 1, seq length 2500]\tLoss: 6.701495\n",
      "825it [01:34,  8.77it/s]Train epoch: 0 [batch #825, batch_size 1, seq length 2500]\tLoss: 6.725097\n",
      "850it [01:37,  8.76it/s]Train epoch: 0 [batch #850, batch_size 1, seq length 2500]\tLoss: 7.031571\n",
      "875it [01:39,  8.73it/s]Train epoch: 0 [batch #875, batch_size 1, seq length 2500]\tLoss: 6.853845\n",
      "900it [01:42,  8.78it/s]Train epoch: 0 [batch #900, batch_size 1, seq length 2500]\tLoss: 6.718472\n",
      "925it [01:45,  8.77it/s]Train epoch: 0 [batch #925, batch_size 1, seq length 2500]\tLoss: 6.778285\n",
      "950it [01:48,  8.72it/s]Train epoch: 0 [batch #950, batch_size 1, seq length 2500]\tLoss: 6.790867\n",
      "975it [01:51,  8.77it/s]Train epoch: 0 [batch #975, batch_size 1, seq length 2500]\tLoss: 6.784745\n",
      "1000it [01:54,  8.76it/s]Train epoch: 0 [batch #1000, batch_size 1, seq length 2500]\tLoss: 6.672996\n",
      "1025it [01:57,  8.77it/s]Train epoch: 0 [batch #1025, batch_size 1, seq length 2500]\tLoss: 6.734373\n",
      "1050it [01:59,  8.77it/s]Train epoch: 0 [batch #1050, batch_size 1, seq length 2500]\tLoss: 6.730127\n",
      "1075it [02:02,  8.79it/s]Train epoch: 0 [batch #1075, batch_size 1, seq length 2500]\tLoss: 6.599666\n",
      "1100it [02:05,  8.77it/s]Train epoch: 0 [batch #1100, batch_size 1, seq length 2500]\tLoss: 6.829382\n",
      "1125it [02:08,  8.65it/s]Train epoch: 0 [batch #1125, batch_size 1, seq length 2500]\tLoss: 6.739903\n",
      "1150it [02:11,  8.74it/s]Train epoch: 0 [batch #1150, batch_size 1, seq length 2500]\tLoss: 6.727035\n",
      "1175it [02:14,  8.75it/s]Train epoch: 0 [batch #1175, batch_size 1, seq length 2500]\tLoss: 6.742459\n",
      "1200it [02:17,  8.76it/s]Train epoch: 0 [batch #1200, batch_size 1, seq length 2500]\tLoss: 6.699519\n",
      "1225it [02:19,  8.75it/s]Train epoch: 0 [batch #1225, batch_size 1, seq length 2500]\tLoss: 6.743037\n",
      "1250it [02:22,  8.71it/s]Train epoch: 0 [batch #1250, batch_size 1, seq length 2500]\tLoss: 6.598393\n",
      "1275it [02:25,  8.75it/s]Train epoch: 0 [batch #1275, batch_size 1, seq length 2500]\tLoss: 6.449710\n",
      "1300it [02:28,  8.78it/s]Train epoch: 0 [batch #1300, batch_size 1, seq length 2500]\tLoss: 6.598675\n",
      "1325it [02:31,  8.70it/s]Train epoch: 0 [batch #1325, batch_size 1, seq length 2500]\tLoss: 6.774793\n",
      "1350it [02:34,  8.74it/s]Train epoch: 0 [batch #1350, batch_size 1, seq length 2500]\tLoss: 6.620295\n",
      "1375it [02:37,  8.76it/s]Train epoch: 0 [batch #1375, batch_size 1, seq length 2500]\tLoss: 6.719329\n",
      "1400it [02:39,  8.76it/s]Train epoch: 0 [batch #1400, batch_size 1, seq length 2500]\tLoss: 6.842342\n",
      "1425it [02:42,  8.76it/s]Train epoch: 0 [batch #1425, batch_size 1, seq length 2500]\tLoss: 6.657162\n",
      "1450it [02:45,  8.75it/s]Train epoch: 0 [batch #1450, batch_size 1, seq length 2500]\tLoss: 6.447145\n",
      "1475it [02:48,  8.75it/s]Train epoch: 0 [batch #1475, batch_size 1, seq length 2500]\tLoss: 6.618217\n",
      "1500it [02:51,  8.71it/s]Train epoch: 0 [batch #1500, batch_size 1, seq length 2500]\tLoss: 6.437603\n",
      "1525it [02:54,  8.76it/s]Train epoch: 0 [batch #1525, batch_size 1, seq length 2500]\tLoss: 6.574681\n",
      "1550it [02:57,  8.75it/s]Train epoch: 0 [batch #1550, batch_size 1, seq length 2500]\tLoss: 6.400005\n",
      "1575it [02:59,  8.64it/s]Train epoch: 0 [batch #1575, batch_size 1, seq length 2500]\tLoss: 6.606200\n",
      "1600it [03:02,  8.72it/s]Train epoch: 0 [batch #1600, batch_size 1, seq length 2500]\tLoss: 6.585184\n",
      "1625it [03:05,  8.74it/s]Train epoch: 0 [batch #1625, batch_size 1, seq length 2500]\tLoss: 6.793582\n",
      "1650it [03:08,  8.75it/s]Train epoch: 0 [batch #1650, batch_size 1, seq length 2500]\tLoss: 6.616474\n",
      "1675it [03:11,  8.76it/s]Train epoch: 0 [batch #1675, batch_size 1, seq length 2500]\tLoss: 6.756668\n",
      "1700it [03:14,  8.76it/s]Train epoch: 0 [batch #1700, batch_size 1, seq length 2500]\tLoss: 6.543148\n",
      "1725it [03:17,  8.74it/s]Train epoch: 0 [batch #1725, batch_size 1, seq length 2500]\tLoss: 6.635657\n",
      "1750it [03:20,  8.68it/s]Train epoch: 0 [batch #1750, batch_size 1, seq length 2500]\tLoss: 6.600801\n",
      "1775it [03:22,  8.73it/s]Train epoch: 0 [batch #1775, batch_size 1, seq length 2500]\tLoss: 6.571186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800it [03:25,  8.77it/s]Train epoch: 0 [batch #1800, batch_size 1, seq length 2500]\tLoss: 6.478663\n",
      "1825it [03:28,  8.75it/s]Train epoch: 0 [batch #1825, batch_size 1, seq length 2500]\tLoss: 6.686508\n",
      "1850it [03:31,  8.77it/s]Train epoch: 0 [batch #1850, batch_size 1, seq length 2500]\tLoss: 6.894117\n",
      "1875it [03:34,  8.75it/s]Train epoch: 0 [batch #1875, batch_size 1, seq length 2500]\tLoss: 6.661513\n",
      "1900it [03:37,  8.77it/s]Train epoch: 0 [batch #1900, batch_size 1, seq length 2500]\tLoss: 6.535904\n",
      "1925it [03:40,  8.77it/s]Train epoch: 0 [batch #1925, batch_size 1, seq length 2500]\tLoss: 6.564649\n",
      "1950it [03:42,  8.75it/s]Train epoch: 0 [batch #1950, batch_size 1, seq length 2500]\tLoss: 6.644576\n",
      "1975it [03:45,  8.78it/s]Train epoch: 0 [batch #1975, batch_size 1, seq length 2500]\tLoss: 6.731329\n",
      "2000it [03:48,  8.77it/s]Train epoch: 0 [batch #2000, batch_size 1, seq length 2500]\tLoss: 6.401672\n",
      "2025it [03:51,  8.78it/s]Train epoch: 0 [batch #2025, batch_size 1, seq length 2500]\tLoss: 6.281580\n",
      "2050it [03:54,  8.77it/s]Train epoch: 0 [batch #2050, batch_size 1, seq length 2500]\tLoss: 6.642151\n",
      "2075it [03:57,  8.75it/s]Train epoch: 0 [batch #2075, batch_size 1, seq length 2500]\tLoss: 6.491656\n",
      "2100it [04:00,  8.76it/s]Train epoch: 0 [batch #2100, batch_size 1, seq length 2500]\tLoss: 6.543137\n",
      "2125it [04:02,  8.75it/s]Train epoch: 0 [batch #2125, batch_size 1, seq length 2500]\tLoss: 6.393946\n",
      "2150it [04:05,  8.71it/s]Train epoch: 0 [batch #2150, batch_size 1, seq length 2500]\tLoss: 6.702598\n",
      "2175it [04:08,  8.72it/s]Train epoch: 0 [batch #2175, batch_size 1, seq length 2500]\tLoss: 6.674650\n",
      "2200it [04:11,  8.76it/s]Train epoch: 0 [batch #2200, batch_size 1, seq length 2500]\tLoss: 6.369860\n",
      "2225it [04:14,  8.74it/s]Train epoch: 0 [batch #2225, batch_size 1, seq length 2500]\tLoss: 6.555137\n",
      "2250it [04:17,  8.77it/s]Train epoch: 0 [batch #2250, batch_size 1, seq length 2500]\tLoss: 6.593107\n",
      "2275it [04:20,  8.76it/s]Train epoch: 0 [batch #2275, batch_size 1, seq length 2500]\tLoss: 6.395713\n",
      "2300it [04:22,  8.76it/s]Train epoch: 0 [batch #2300, batch_size 1, seq length 2500]\tLoss: 6.648230\n",
      "2325it [04:25,  8.77it/s]Train epoch: 0 [batch #2325, batch_size 1, seq length 2500]\tLoss: 6.689661\n",
      "2350it [04:28,  8.68it/s]Train epoch: 0 [batch #2350, batch_size 1, seq length 2500]\tLoss: 6.450029\n",
      "2375it [04:31,  8.76it/s]Train epoch: 0 [batch #2375, batch_size 1, seq length 2500]\tLoss: 5.965474\n",
      "2400it [04:34,  8.75it/s]Train epoch: 0 [batch #2400, batch_size 1, seq length 2500]\tLoss: 6.494550\n",
      "2425it [04:37,  8.77it/s]Train epoch: 0 [batch #2425, batch_size 1, seq length 2500]\tLoss: 6.316563\n",
      "2450it [04:40,  8.68it/s]Train epoch: 0 [batch #2450, batch_size 1, seq length 2500]\tLoss: 6.436193\n",
      "2475it [04:42,  8.70it/s]Train epoch: 0 [batch #2475, batch_size 1, seq length 2500]\tLoss: 6.262447\n",
      "2500it [04:45,  8.77it/s]Train epoch: 0 [batch #2500, batch_size 1, seq length 2500]\tLoss: 6.530380\n",
      "2525it [04:48,  8.76it/s]Train epoch: 0 [batch #2525, batch_size 1, seq length 2500]\tLoss: 6.399220\n",
      "2550it [04:51,  8.74it/s]Train epoch: 0 [batch #2550, batch_size 1, seq length 2500]\tLoss: 6.623963\n",
      "2575it [04:54,  8.67it/s]Train epoch: 0 [batch #2575, batch_size 1, seq length 2500]\tLoss: 6.558960\n",
      "2600it [04:57,  8.76it/s]Train epoch: 0 [batch #2600, batch_size 1, seq length 2500]\tLoss: 6.856792\n",
      "2625it [05:00,  8.76it/s]Train epoch: 0 [batch #2625, batch_size 1, seq length 2500]\tLoss: 6.425261\n",
      "2650it [05:02,  8.77it/s]Train epoch: 0 [batch #2650, batch_size 1, seq length 2500]\tLoss: 6.709855\n",
      "2675it [05:05,  8.76it/s]Train epoch: 0 [batch #2675, batch_size 1, seq length 2500]\tLoss: 6.620738\n",
      "2700it [05:08,  8.77it/s]Train epoch: 0 [batch #2700, batch_size 1, seq length 2500]\tLoss: 6.474225\n",
      "2725it [05:11,  8.76it/s]Train epoch: 0 [batch #2725, batch_size 1, seq length 2500]\tLoss: 6.552542\n",
      "2750it [05:14,  8.77it/s]Train epoch: 0 [batch #2750, batch_size 1, seq length 2500]\tLoss: 6.675482\n",
      "2775it [05:17,  8.67it/s]Train epoch: 0 [batch #2775, batch_size 1, seq length 2500]\tLoss: 6.304515\n",
      "2800it [05:20,  8.77it/s]Train epoch: 0 [batch #2800, batch_size 1, seq length 2500]\tLoss: 6.536841\n",
      "2825it [05:22,  8.76it/s]Train epoch: 0 [batch #2825, batch_size 1, seq length 2500]\tLoss: 6.563050\n",
      "2850it [05:25,  8.70it/s]Train epoch: 0 [batch #2850, batch_size 1, seq length 2500]\tLoss: 6.494273\n",
      "2875it [05:28,  8.76it/s]Train epoch: 0 [batch #2875, batch_size 1, seq length 2500]\tLoss: 6.625449\n",
      "2900it [05:31,  8.69it/s]Train epoch: 0 [batch #2900, batch_size 1, seq length 2500]\tLoss: 6.525874\n",
      "2925it [05:34,  8.77it/s]Train epoch: 0 [batch #2925, batch_size 1, seq length 2500]\tLoss: 6.531090\n",
      "2950it [05:37,  8.75it/s]Train epoch: 0 [batch #2950, batch_size 1, seq length 2500]\tLoss: 6.516537\n",
      "2975it [05:40,  8.68it/s]Train epoch: 0 [batch #2975, batch_size 1, seq length 2500]\tLoss: 6.583792\n",
      "3000it [05:43,  8.67it/s]Train epoch: 0 [batch #3000, batch_size 1, seq length 2500]\tLoss: 6.548339\n",
      "3025it [05:45,  8.75it/s]Train epoch: 0 [batch #3025, batch_size 1, seq length 2500]\tLoss: 6.579365\n",
      "3050it [05:48,  8.76it/s]Train epoch: 0 [batch #3050, batch_size 1, seq length 2500]\tLoss: 6.377240\n",
      "3075it [05:51,  8.75it/s]Train epoch: 0 [batch #3075, batch_size 1, seq length 2500]\tLoss: 6.429379\n",
      "3100it [05:54,  8.76it/s]Train epoch: 0 [batch #3100, batch_size 1, seq length 2500]\tLoss: 6.412377\n",
      "3125it [05:57,  8.74it/s]Train epoch: 0 [batch #3125, batch_size 1, seq length 2500]\tLoss: 6.556768\n",
      "3150it [06:00,  8.75it/s]Train epoch: 0 [batch #3150, batch_size 1, seq length 2500]\tLoss: 6.572057\n",
      "3175it [06:03,  8.70it/s]Train epoch: 0 [batch #3175, batch_size 1, seq length 2500]\tLoss: 6.732944\n",
      "3200it [06:05,  8.77it/s]Train epoch: 0 [batch #3200, batch_size 1, seq length 2500]\tLoss: 6.513007\n",
      "3225it [06:08,  8.75it/s]Train epoch: 0 [batch #3225, batch_size 1, seq length 2500]\tLoss: 5.959106\n",
      "3250it [06:11,  8.75it/s]Train epoch: 0 [batch #3250, batch_size 1, seq length 2500]\tLoss: 6.572577\n",
      "3275it [06:14,  8.77it/s]Train epoch: 0 [batch #3275, batch_size 1, seq length 2500]\tLoss: 6.604464\n",
      "3300it [06:17,  8.66it/s]Train epoch: 0 [batch #3300, batch_size 1, seq length 2500]\tLoss: 6.260586\n",
      "3325it [06:20,  8.76it/s]Train epoch: 0 [batch #3325, batch_size 1, seq length 2500]\tLoss: 6.166571\n",
      "3350it [06:23,  8.76it/s]Train epoch: 0 [batch #3350, batch_size 1, seq length 2500]\tLoss: 6.555471\n",
      "3375it [06:25,  8.74it/s]Train epoch: 0 [batch #3375, batch_size 1, seq length 2500]\tLoss: 6.483727\n",
      "3400it [06:28,  8.65it/s]Train epoch: 0 [batch #3400, batch_size 1, seq length 2500]\tLoss: 6.334267\n",
      "3425it [06:31,  8.72it/s]Train epoch: 0 [batch #3425, batch_size 1, seq length 2500]\tLoss: 6.397544\n",
      "3450it [06:34,  8.65it/s]Train epoch: 0 [batch #3450, batch_size 1, seq length 2500]\tLoss: 6.588798\n",
      "3475it [06:37,  8.76it/s]Train epoch: 0 [batch #3475, batch_size 1, seq length 2500]\tLoss: 6.440489\n",
      "3500it [06:40,  8.77it/s]Train epoch: 0 [batch #3500, batch_size 1, seq length 2500]\tLoss: 6.551897\n",
      "3525it [06:43,  8.73it/s]Train epoch: 0 [batch #3525, batch_size 1, seq length 2500]\tLoss: 6.301340\n",
      "3550it [06:46,  8.77it/s]Train epoch: 0 [batch #3550, batch_size 1, seq length 2500]\tLoss: 6.729815\n",
      "3575it [06:48,  8.76it/s]Train epoch: 0 [batch #3575, batch_size 1, seq length 2500]\tLoss: 6.487702\n",
      "3600it [06:51,  8.75it/s]Train epoch: 0 [batch #3600, batch_size 1, seq length 2500]\tLoss: 6.435017\n",
      "3625it [06:54,  8.72it/s]Train epoch: 0 [batch #3625, batch_size 1, seq length 2500]\tLoss: 6.452634\n",
      "3650it [06:57,  8.77it/s]Train epoch: 0 [batch #3650, batch_size 1, seq length 2500]\tLoss: 6.309203\n",
      "3675it [07:00,  8.77it/s]Train epoch: 0 [batch #3675, batch_size 1, seq length 2500]\tLoss: 6.370670\n",
      "3700it [07:03,  8.74it/s]Train epoch: 0 [batch #3700, batch_size 1, seq length 2500]\tLoss: 6.486786\n",
      "3725it [07:06,  8.77it/s]Train epoch: 0 [batch #3725, batch_size 1, seq length 2500]\tLoss: 6.208112\n",
      "3750it [07:08,  8.77it/s]Train epoch: 0 [batch #3750, batch_size 1, seq length 2500]\tLoss: 6.172232\n",
      "3775it [07:11,  8.76it/s]Train epoch: 0 [batch #3775, batch_size 1, seq length 2500]\tLoss: 6.482620\n",
      "3800it [07:14,  8.74it/s]Train epoch: 0 [batch #3800, batch_size 1, seq length 2500]\tLoss: 6.486137\n",
      "3825it [07:17,  8.76it/s]Train epoch: 0 [batch #3825, batch_size 1, seq length 2500]\tLoss: 6.627146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3850it [07:20,  8.78it/s]Train epoch: 0 [batch #3850, batch_size 1, seq length 2500]\tLoss: 6.543909\n",
      "3875it [07:23,  8.76it/s]Train epoch: 0 [batch #3875, batch_size 1, seq length 2500]\tLoss: 6.221578\n",
      "3900it [07:26,  8.76it/s]Train epoch: 0 [batch #3900, batch_size 1, seq length 2500]\tLoss: 6.509789\n",
      "3925it [07:28,  8.77it/s]Train epoch: 0 [batch #3925, batch_size 1, seq length 2500]\tLoss: 6.378506\n",
      "3950it [07:31,  8.75it/s]Train epoch: 0 [batch #3950, batch_size 1, seq length 2500]\tLoss: 6.425415\n",
      "3975it [07:34,  8.72it/s]Train epoch: 0 [batch #3975, batch_size 1, seq length 2500]\tLoss: 6.198830\n",
      "4000it [07:37,  8.77it/s]Train epoch: 0 [batch #4000, batch_size 1, seq length 2500]\tLoss: 6.684294\n",
      "4025it [07:40,  8.76it/s]Train epoch: 0 [batch #4025, batch_size 1, seq length 2500]\tLoss: 6.155429\n",
      "4050it [07:43,  8.76it/s]Train epoch: 0 [batch #4050, batch_size 1, seq length 2500]\tLoss: 6.304522\n",
      "4075it [07:46,  8.77it/s]Train epoch: 0 [batch #4075, batch_size 1, seq length 2500]\tLoss: 6.392400\n",
      "4100it [07:48,  8.77it/s]Train epoch: 0 [batch #4100, batch_size 1, seq length 2500]\tLoss: 6.257484\n",
      "4125it [07:51,  8.65it/s]Train epoch: 0 [batch #4125, batch_size 1, seq length 2500]\tLoss: 6.483174\n",
      "4150it [07:54,  8.78it/s]Train epoch: 0 [batch #4150, batch_size 1, seq length 2500]\tLoss: 6.419741\n",
      "4175it [07:57,  8.74it/s]Train epoch: 0 [batch #4175, batch_size 1, seq length 2500]\tLoss: 6.469993\n",
      "4200it [08:00,  8.75it/s]Train epoch: 0 [batch #4200, batch_size 1, seq length 2500]\tLoss: 6.212714\n",
      "4225it [08:03,  8.76it/s]Train epoch: 0 [batch #4225, batch_size 1, seq length 2500]\tLoss: 6.483623\n",
      "4250it [08:06,  8.75it/s]Train epoch: 0 [batch #4250, batch_size 1, seq length 2500]\tLoss: 6.485005\n",
      "4275it [08:08,  8.77it/s]Train epoch: 0 [batch #4275, batch_size 1, seq length 2500]\tLoss: 6.435979\n",
      "4300it [08:11,  8.76it/s]Train epoch: 0 [batch #4300, batch_size 1, seq length 2500]\tLoss: 6.561310\n",
      "4325it [08:14,  8.76it/s]Train epoch: 0 [batch #4325, batch_size 1, seq length 2500]\tLoss: 6.466822\n",
      "4350it [08:17,  8.76it/s]Train epoch: 0 [batch #4350, batch_size 1, seq length 2500]\tLoss: 6.571156\n",
      "4375it [08:20,  8.77it/s]Train epoch: 0 [batch #4375, batch_size 1, seq length 2500]\tLoss: 6.574250\n",
      "4400it [08:23,  8.76it/s]Train epoch: 0 [batch #4400, batch_size 1, seq length 2500]\tLoss: 6.524132\n",
      "4425it [08:26,  8.76it/s]Train epoch: 0 [batch #4425, batch_size 1, seq length 2500]\tLoss: 6.276875\n",
      "4450it [08:28,  8.77it/s]Train epoch: 0 [batch #4450, batch_size 1, seq length 2500]\tLoss: 6.385367\n",
      "4475it [08:31,  8.75it/s]Train epoch: 0 [batch #4475, batch_size 1, seq length 2500]\tLoss: 6.499360\n",
      "4500it [08:34,  8.76it/s]Train epoch: 0 [batch #4500, batch_size 1, seq length 2500]\tLoss: 6.363763\n",
      "4525it [08:37,  8.76it/s]Train epoch: 0 [batch #4525, batch_size 1, seq length 2500]\tLoss: 6.367712\n",
      "4550it [08:40,  8.77it/s]Train epoch: 0 [batch #4550, batch_size 1, seq length 2500]\tLoss: 6.459575\n",
      "4575it [08:43,  8.76it/s]Train epoch: 0 [batch #4575, batch_size 1, seq length 2500]\tLoss: 6.585556\n",
      "4600it [08:46,  8.74it/s]Train epoch: 0 [batch #4600, batch_size 1, seq length 2500]\tLoss: 6.285158\n",
      "4625it [08:48,  8.77it/s]Train epoch: 0 [batch #4625, batch_size 1, seq length 2500]\tLoss: 6.355988\n",
      "4650it [08:51,  8.74it/s]Train epoch: 0 [batch #4650, batch_size 1, seq length 2500]\tLoss: 6.329431\n",
      "4675it [08:54,  8.75it/s]Train epoch: 0 [batch #4675, batch_size 1, seq length 2500]\tLoss: 6.373638\n",
      "4700it [08:57,  8.76it/s]Train epoch: 0 [batch #4700, batch_size 1, seq length 2500]\tLoss: 6.236387\n",
      "4725it [09:00,  8.74it/s]Train epoch: 0 [batch #4725, batch_size 1, seq length 2500]\tLoss: 6.249256\n",
      "4750it [09:03,  8.76it/s]Train epoch: 0 [batch #4750, batch_size 1, seq length 2500]\tLoss: 6.303476\n",
      "4775it [09:06,  8.73it/s]Train epoch: 0 [batch #4775, batch_size 1, seq length 2500]\tLoss: 6.187590\n",
      "4800it [09:08,  8.73it/s]Train epoch: 0 [batch #4800, batch_size 1, seq length 2500]\tLoss: 6.129285\n",
      "4825it [09:11,  8.73it/s]Train epoch: 0 [batch #4825, batch_size 1, seq length 2500]\tLoss: 6.132542\n",
      "4850it [09:14,  8.76it/s]Train epoch: 0 [batch #4850, batch_size 1, seq length 2500]\tLoss: 6.397725\n",
      "4875it [09:17,  8.78it/s]Train epoch: 0 [batch #4875, batch_size 1, seq length 2500]\tLoss: 6.578594\n",
      "4900it [09:20,  8.77it/s]Train epoch: 0 [batch #4900, batch_size 1, seq length 2500]\tLoss: 6.364441\n",
      "4925it [09:23,  8.77it/s]Train epoch: 0 [batch #4925, batch_size 1, seq length 2500]\tLoss: 6.249272\n",
      "4950it [09:26,  8.77it/s]Train epoch: 0 [batch #4950, batch_size 1, seq length 2500]\tLoss: 6.435061\n",
      "4975it [09:28,  8.67it/s]Train epoch: 0 [batch #4975, batch_size 1, seq length 2500]\tLoss: 6.508408\n",
      "5000it [09:31,  8.78it/s]Train epoch: 0 [batch #5000, batch_size 1, seq length 2500]\tLoss: 6.516901\n",
      "5025it [09:34,  8.77it/s]Train epoch: 0 [batch #5025, batch_size 1, seq length 2500]\tLoss: 6.229220\n",
      "5050it [09:37,  8.77it/s]Train epoch: 0 [batch #5050, batch_size 1, seq length 2500]\tLoss: 6.410992\n",
      "5075it [09:40,  8.77it/s]Train epoch: 0 [batch #5075, batch_size 1, seq length 2500]\tLoss: 6.225146\n",
      "5100it [09:43,  8.77it/s]Train epoch: 0 [batch #5100, batch_size 1, seq length 2500]\tLoss: 6.199167\n",
      "5125it [09:46,  8.74it/s]Train epoch: 0 [batch #5125, batch_size 1, seq length 2500]\tLoss: 6.360983\n",
      "5150it [09:48,  8.77it/s]Train epoch: 0 [batch #5150, batch_size 1, seq length 2500]\tLoss: 6.484123\n",
      "5175it [09:51,  8.74it/s]Train epoch: 0 [batch #5175, batch_size 1, seq length 2500]\tLoss: 6.418043\n",
      "5200it [09:54,  8.78it/s]Train epoch: 0 [batch #5200, batch_size 1, seq length 2500]\tLoss: 6.241838\n",
      "5225it [09:57,  8.74it/s]Train epoch: 0 [batch #5225, batch_size 1, seq length 2500]\tLoss: 6.278842\n",
      "5250it [10:00,  8.75it/s]Train epoch: 0 [batch #5250, batch_size 1, seq length 2500]\tLoss: 6.373624\n",
      "5275it [10:03,  8.77it/s]Train epoch: 0 [batch #5275, batch_size 1, seq length 2500]\tLoss: 6.550738\n",
      "5300it [10:06,  8.77it/s]Train epoch: 0 [batch #5300, batch_size 1, seq length 2500]\tLoss: 6.463201\n",
      "5325it [10:08,  8.75it/s]Train epoch: 0 [batch #5325, batch_size 1, seq length 2500]\tLoss: 6.437661\n",
      "5350it [10:11,  8.74it/s]Train epoch: 0 [batch #5350, batch_size 1, seq length 2500]\tLoss: 6.281549\n",
      "5375it [10:14,  8.76it/s]Train epoch: 0 [batch #5375, batch_size 1, seq length 2500]\tLoss: 6.221737\n",
      "5400it [10:17,  8.73it/s]Train epoch: 0 [batch #5400, batch_size 1, seq length 2500]\tLoss: 6.147661\n",
      "5425it [10:20,  8.75it/s]Train epoch: 0 [batch #5425, batch_size 1, seq length 2500]\tLoss: 6.544749\n",
      "5450it [10:23,  8.76it/s]Train epoch: 0 [batch #5450, batch_size 1, seq length 2500]\tLoss: 6.494807\n",
      "5475it [10:26,  8.76it/s]Train epoch: 0 [batch #5475, batch_size 1, seq length 2500]\tLoss: 6.385719\n",
      "5500it [10:28,  8.77it/s]Train epoch: 0 [batch #5500, batch_size 1, seq length 2500]\tLoss: 6.317142\n",
      "5525it [10:31,  8.77it/s]Train epoch: 0 [batch #5525, batch_size 1, seq length 2500]\tLoss: 6.382387\n",
      "5550it [10:34,  8.75it/s]Train epoch: 0 [batch #5550, batch_size 1, seq length 2500]\tLoss: 6.248541\n",
      "5575it [10:37,  8.74it/s]Train epoch: 0 [batch #5575, batch_size 1, seq length 2500]\tLoss: 6.523525\n",
      "5600it [10:40,  8.66it/s]Train epoch: 0 [batch #5600, batch_size 1, seq length 2500]\tLoss: 6.285621\n",
      "5625it [10:43,  8.73it/s]Train epoch: 0 [batch #5625, batch_size 1, seq length 2500]\tLoss: 6.288386\n",
      "5650it [10:46,  8.77it/s]Train epoch: 0 [batch #5650, batch_size 1, seq length 2500]\tLoss: 6.448515\n",
      "5675it [10:48,  8.78it/s]Train epoch: 0 [batch #5675, batch_size 1, seq length 2500]\tLoss: 6.717171\n",
      "5700it [10:51,  8.77it/s]Train epoch: 0 [batch #5700, batch_size 1, seq length 2500]\tLoss: 6.131393\n",
      "5725it [10:54,  8.77it/s]Train epoch: 0 [batch #5725, batch_size 1, seq length 2500]\tLoss: 6.351990\n",
      "5750it [10:57,  8.76it/s]Train epoch: 0 [batch #5750, batch_size 1, seq length 2500]\tLoss: 6.457458\n",
      "5775it [11:00,  8.77it/s]Train epoch: 0 [batch #5775, batch_size 1, seq length 2500]\tLoss: 6.545814\n",
      "5800it [11:03,  8.77it/s]Train epoch: 0 [batch #5800, batch_size 1, seq length 2500]\tLoss: 6.589683\n",
      "5825it [11:06,  8.76it/s]Train epoch: 0 [batch #5825, batch_size 1, seq length 2500]\tLoss: 6.175964\n",
      "5850it [11:08,  8.76it/s]Train epoch: 0 [batch #5850, batch_size 1, seq length 2500]\tLoss: 6.482732\n",
      "5875it [11:11,  8.76it/s]Train epoch: 0 [batch #5875, batch_size 1, seq length 2500]\tLoss: 6.142209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5900it [11:14,  8.77it/s]Train epoch: 0 [batch #5900, batch_size 1, seq length 2500]\tLoss: 6.543758\n",
      "5925it [11:17,  8.74it/s]Train epoch: 0 [batch #5925, batch_size 1, seq length 2500]\tLoss: 6.373137\n",
      "5950it [11:20,  8.76it/s]Train epoch: 0 [batch #5950, batch_size 1, seq length 2500]\tLoss: 6.263706\n",
      "5975it [11:23,  8.78it/s]Train epoch: 0 [batch #5975, batch_size 1, seq length 2500]\tLoss: 6.052218\n",
      "6000it [11:25,  8.78it/s]Train epoch: 0 [batch #6000, batch_size 1, seq length 2500]\tLoss: 6.390425\n",
      "6025it [11:28,  8.76it/s]Train epoch: 0 [batch #6025, batch_size 1, seq length 2500]\tLoss: 6.384313\n",
      "6050it [11:31,  8.75it/s]Train epoch: 0 [batch #6050, batch_size 1, seq length 2500]\tLoss: 6.319529\n",
      "6075it [11:34,  8.76it/s]Train epoch: 0 [batch #6075, batch_size 1, seq length 2500]\tLoss: 6.425057\n",
      "6100it [11:37,  8.77it/s]Train epoch: 0 [batch #6100, batch_size 1, seq length 2500]\tLoss: 6.407975\n",
      "6125it [11:40,  8.77it/s]Train epoch: 0 [batch #6125, batch_size 1, seq length 2500]\tLoss: 5.777795\n",
      "6150it [11:43,  8.74it/s]Train epoch: 0 [batch #6150, batch_size 1, seq length 2500]\tLoss: 6.309197\n",
      "6175it [11:45,  8.75it/s]Train epoch: 0 [batch #6175, batch_size 1, seq length 2500]\tLoss: 6.417945\n",
      "6200it [11:48,  8.77it/s]Train epoch: 0 [batch #6200, batch_size 1, seq length 2500]\tLoss: 6.119496\n",
      "6225it [11:51,  8.77it/s]Train epoch: 0 [batch #6225, batch_size 1, seq length 2500]\tLoss: 6.583373\n",
      "6250it [11:54,  8.74it/s]Train epoch: 0 [batch #6250, batch_size 1, seq length 2500]\tLoss: 6.268573\n",
      "6275it [11:57,  8.76it/s]Train epoch: 0 [batch #6275, batch_size 1, seq length 2500]\tLoss: 5.614403\n",
      "6300it [12:00,  8.75it/s]Train epoch: 0 [batch #6300, batch_size 1, seq length 2500]\tLoss: 6.438490\n",
      "6325it [12:03,  8.75it/s]Train epoch: 0 [batch #6325, batch_size 1, seq length 2500]\tLoss: 6.210926\n",
      "6350it [12:05,  8.76it/s]Train epoch: 0 [batch #6350, batch_size 1, seq length 2500]\tLoss: 6.625287\n",
      "6375it [12:08,  8.77it/s]Train epoch: 0 [batch #6375, batch_size 1, seq length 2500]\tLoss: 6.244160\n",
      "6400it [12:11,  8.75it/s]Train epoch: 0 [batch #6400, batch_size 1, seq length 2500]\tLoss: 6.416834\n",
      "6425it [12:14,  8.78it/s]Train epoch: 0 [batch #6425, batch_size 1, seq length 2500]\tLoss: 6.080829\n",
      "6450it [12:17,  8.77it/s]Train epoch: 0 [batch #6450, batch_size 1, seq length 2500]\tLoss: 6.345691\n",
      "6475it [12:20,  8.72it/s]Train epoch: 0 [batch #6475, batch_size 1, seq length 2500]\tLoss: 6.348558\n",
      "6500it [12:23,  8.77it/s]Train epoch: 0 [batch #6500, batch_size 1, seq length 2500]\tLoss: 6.194899\n",
      "6525it [12:25,  8.76it/s]Train epoch: 0 [batch #6525, batch_size 1, seq length 2500]\tLoss: 6.389973\n",
      "6550it [12:28,  8.77it/s]Train epoch: 0 [batch #6550, batch_size 1, seq length 2500]\tLoss: 6.143617\n",
      "6575it [12:31,  8.76it/s]Train epoch: 0 [batch #6575, batch_size 1, seq length 2500]\tLoss: 6.403800\n",
      "6600it [12:34,  8.72it/s]Train epoch: 0 [batch #6600, batch_size 1, seq length 2500]\tLoss: 6.614901\n",
      "6625it [12:37,  8.75it/s]Train epoch: 0 [batch #6625, batch_size 1, seq length 2500]\tLoss: 6.274543\n",
      "6650it [12:40,  8.78it/s]Train epoch: 0 [batch #6650, batch_size 1, seq length 2500]\tLoss: 6.121324\n",
      "6675it [12:43,  8.74it/s]Train epoch: 0 [batch #6675, batch_size 1, seq length 2500]\tLoss: 6.641619\n",
      "6700it [12:45,  8.73it/s]Train epoch: 0 [batch #6700, batch_size 1, seq length 2500]\tLoss: 6.356169\n",
      "6725it [12:48,  8.77it/s]Train epoch: 0 [batch #6725, batch_size 1, seq length 2500]\tLoss: 6.491561\n",
      "6750it [12:51,  8.72it/s]Train epoch: 0 [batch #6750, batch_size 1, seq length 2500]\tLoss: 6.046794\n",
      "6775it [12:54,  8.78it/s]Train epoch: 0 [batch #6775, batch_size 1, seq length 2500]\tLoss: 6.170469\n",
      "6800it [12:57,  8.76it/s]Train epoch: 0 [batch #6800, batch_size 1, seq length 2500]\tLoss: 6.394907\n",
      "6825it [13:00,  8.77it/s]Train epoch: 0 [batch #6825, batch_size 1, seq length 2500]\tLoss: 6.460456\n",
      "6850it [13:03,  8.77it/s]Train epoch: 0 [batch #6850, batch_size 1, seq length 2500]\tLoss: 6.145015\n",
      "6875it [13:05,  8.74it/s]Train epoch: 0 [batch #6875, batch_size 1, seq length 2500]\tLoss: 6.263978\n",
      "6900it [13:08,  8.73it/s]Train epoch: 0 [batch #6900, batch_size 1, seq length 2500]\tLoss: 6.359344\n",
      "6925it [13:11,  8.78it/s]Train epoch: 0 [batch #6925, batch_size 1, seq length 2500]\tLoss: 6.046540\n",
      "6950it [13:14,  8.78it/s]Train epoch: 0 [batch #6950, batch_size 1, seq length 2500]\tLoss: 6.207439\n",
      "6975it [13:17,  8.78it/s]Train epoch: 0 [batch #6975, batch_size 1, seq length 2500]\tLoss: 6.472683\n",
      "7000it [13:20,  8.76it/s]Train epoch: 0 [batch #7000, batch_size 1, seq length 2500]\tLoss: 6.262107\n",
      "7025it [13:23,  8.70it/s]Train epoch: 0 [batch #7025, batch_size 1, seq length 2500]\tLoss: 6.458320\n",
      "7050it [13:25,  8.76it/s]Train epoch: 0 [batch #7050, batch_size 1, seq length 2500]\tLoss: 6.368469\n",
      "7075it [13:28,  8.77it/s]Train epoch: 0 [batch #7075, batch_size 1, seq length 2500]\tLoss: 6.192133\n",
      "7100it [13:31,  8.62it/s]Train epoch: 0 [batch #7100, batch_size 1, seq length 2500]\tLoss: 6.338009\n",
      "7125it [13:34,  8.77it/s]Train epoch: 0 [batch #7125, batch_size 1, seq length 2500]\tLoss: 6.065354\n",
      "7150it [13:37,  8.74it/s]Train epoch: 0 [batch #7150, batch_size 1, seq length 2500]\tLoss: 6.227166\n",
      "7175it [13:40,  8.75it/s]Train epoch: 0 [batch #7175, batch_size 1, seq length 2500]\tLoss: 6.280488\n",
      "7200it [13:43,  8.76it/s]Train epoch: 0 [batch #7200, batch_size 1, seq length 2500]\tLoss: 6.205601\n",
      "7225it [13:45,  8.76it/s]Train epoch: 0 [batch #7225, batch_size 1, seq length 2500]\tLoss: 6.360398\n",
      "7250it [13:48,  8.69it/s]Train epoch: 0 [batch #7250, batch_size 1, seq length 2500]\tLoss: 6.279428\n",
      "7275it [13:51,  8.77it/s]Train epoch: 0 [batch #7275, batch_size 1, seq length 2500]\tLoss: 6.296538\n",
      "7300it [13:54,  8.74it/s]Train epoch: 0 [batch #7300, batch_size 1, seq length 2500]\tLoss: 6.401433\n",
      "7325it [13:57,  8.77it/s]Train epoch: 0 [batch #7325, batch_size 1, seq length 2500]\tLoss: 6.249874\n",
      "7350it [14:00,  8.71it/s]Train epoch: 0 [batch #7350, batch_size 1, seq length 2500]\tLoss: 6.402832\n",
      "7375it [14:03,  8.69it/s]Train epoch: 0 [batch #7375, batch_size 1, seq length 2500]\tLoss: 6.481106\n",
      "7400it [14:05,  8.75it/s]Train epoch: 0 [batch #7400, batch_size 1, seq length 2500]\tLoss: 6.287248\n",
      "7425it [14:08,  8.73it/s]Train epoch: 0 [batch #7425, batch_size 1, seq length 2500]\tLoss: 6.510532\n",
      "7450it [14:11,  8.73it/s]Train epoch: 0 [batch #7450, batch_size 1, seq length 2500]\tLoss: 6.122426\n",
      "7475it [14:14,  8.78it/s]Train epoch: 0 [batch #7475, batch_size 1, seq length 2500]\tLoss: 6.180703\n",
      "7500it [14:17,  8.74it/s]Train epoch: 0 [batch #7500, batch_size 1, seq length 2500]\tLoss: 6.342898\n",
      "7525it [14:20,  8.74it/s]Train epoch: 0 [batch #7525, batch_size 1, seq length 2500]\tLoss: 6.220855\n",
      "7550it [14:23,  8.75it/s]Train epoch: 0 [batch #7550, batch_size 1, seq length 2500]\tLoss: 6.130977\n",
      "7575it [14:25,  8.72it/s]Train epoch: 0 [batch #7575, batch_size 1, seq length 2500]\tLoss: 6.180966\n",
      "7600it [14:28,  8.78it/s]Train epoch: 0 [batch #7600, batch_size 1, seq length 2500]\tLoss: 6.310881\n",
      "7625it [14:31,  8.74it/s]Train epoch: 0 [batch #7625, batch_size 1, seq length 2500]\tLoss: 6.202174\n",
      "7650it [14:34,  8.77it/s]Train epoch: 0 [batch #7650, batch_size 1, seq length 2500]\tLoss: 6.217034\n",
      "7675it [14:37,  8.76it/s]Train epoch: 0 [batch #7675, batch_size 1, seq length 2500]\tLoss: 6.512971\n",
      "7700it [14:40,  8.76it/s]Train epoch: 0 [batch #7700, batch_size 1, seq length 2500]\tLoss: 6.199028\n",
      "7725it [14:43,  8.77it/s]Train epoch: 0 [batch #7725, batch_size 1, seq length 2500]\tLoss: 6.319001\n",
      "7750it [14:45,  8.78it/s]Train epoch: 0 [batch #7750, batch_size 1, seq length 2500]\tLoss: 6.440835\n",
      "7775it [14:48,  8.76it/s]Train epoch: 0 [batch #7775, batch_size 1, seq length 2500]\tLoss: 6.235122\n",
      "7800it [14:51,  8.73it/s]Train epoch: 0 [batch #7800, batch_size 1, seq length 2500]\tLoss: 6.257836\n",
      "7825it [14:54,  8.75it/s]Train epoch: 0 [batch #7825, batch_size 1, seq length 2500]\tLoss: 6.196762\n",
      "7850it [14:57,  8.76it/s]Train epoch: 0 [batch #7850, batch_size 1, seq length 2500]\tLoss: 6.242259\n",
      "7875it [15:00,  8.76it/s]Train epoch: 0 [batch #7875, batch_size 1, seq length 2500]\tLoss: 6.493468\n",
      "7900it [15:03,  8.56it/s]Train epoch: 0 [batch #7900, batch_size 1, seq length 2500]\tLoss: 6.102760\n",
      "7925it [15:06,  8.76it/s]Train epoch: 0 [batch #7925, batch_size 1, seq length 2500]\tLoss: 6.224292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7950it [15:08,  8.68it/s]Train epoch: 0 [batch #7950, batch_size 1, seq length 2500]\tLoss: 6.343680\n",
      "7975it [15:11,  8.78it/s]Train epoch: 0 [batch #7975, batch_size 1, seq length 2500]\tLoss: 6.266463\n",
      "8000it [15:14,  8.74it/s]Train epoch: 0 [batch #8000, batch_size 1, seq length 2500]\tLoss: 6.140420\n",
      "8025it [15:17,  8.77it/s]Train epoch: 0 [batch #8025, batch_size 1, seq length 2500]\tLoss: 6.384792\n",
      "8050it [15:20,  8.77it/s]Train epoch: 0 [batch #8050, batch_size 1, seq length 2500]\tLoss: 6.086614\n",
      "8075it [15:23,  8.77it/s]Train epoch: 0 [batch #8075, batch_size 1, seq length 2500]\tLoss: 6.417187\n",
      "8100it [15:26,  8.75it/s]Train epoch: 0 [batch #8100, batch_size 1, seq length 2500]\tLoss: 6.218485\n",
      "8125it [15:28,  8.75it/s]Train epoch: 0 [batch #8125, batch_size 1, seq length 2500]\tLoss: 6.325582\n",
      "8150it [15:31,  8.75it/s]Train epoch: 0 [batch #8150, batch_size 1, seq length 2500]\tLoss: 6.101068\n",
      "8175it [15:34,  8.75it/s]Train epoch: 0 [batch #8175, batch_size 1, seq length 2500]\tLoss: 6.013507\n",
      "8200it [15:37,  8.78it/s]Train epoch: 0 [batch #8200, batch_size 1, seq length 2500]\tLoss: 6.262545\n",
      "8225it [15:40,  8.76it/s]Train epoch: 0 [batch #8225, batch_size 1, seq length 2500]\tLoss: 6.053021\n",
      "8250it [15:43,  8.77it/s]Train epoch: 0 [batch #8250, batch_size 1, seq length 2500]\tLoss: 6.136448\n",
      "8275it [15:46,  8.77it/s]Train epoch: 0 [batch #8275, batch_size 1, seq length 2500]\tLoss: 6.223964\n",
      "8300it [15:48,  8.61it/s]Train epoch: 0 [batch #8300, batch_size 1, seq length 2500]\tLoss: 6.315019\n",
      "8325it [15:51,  8.77it/s]Train epoch: 0 [batch #8325, batch_size 1, seq length 2500]\tLoss: 6.227396\n",
      "8350it [15:54,  8.45it/s]Train epoch: 0 [batch #8350, batch_size 1, seq length 2500]\tLoss: 6.094670\n",
      "8375it [15:57,  8.75it/s]Train epoch: 0 [batch #8375, batch_size 1, seq length 2500]\tLoss: 6.192961\n",
      "8400it [16:00,  8.78it/s]Train epoch: 0 [batch #8400, batch_size 1, seq length 2500]\tLoss: 6.132404\n",
      "8425it [16:03,  8.77it/s]Train epoch: 0 [batch #8425, batch_size 1, seq length 2500]\tLoss: 6.440901\n",
      "8450it [16:06,  8.66it/s]Train epoch: 0 [batch #8450, batch_size 1, seq length 2500]\tLoss: 6.143882\n",
      "8475it [16:08,  8.77it/s]Train epoch: 0 [batch #8475, batch_size 1, seq length 2500]\tLoss: 6.412041\n",
      "8500it [16:11,  8.73it/s]Train epoch: 0 [batch #8500, batch_size 1, seq length 2500]\tLoss: 6.203155\n",
      "8525it [16:14,  8.78it/s]Train epoch: 0 [batch #8525, batch_size 1, seq length 2500]\tLoss: 6.139730\n",
      "8550it [16:17,  8.64it/s]Train epoch: 0 [batch #8550, batch_size 1, seq length 2500]\tLoss: 6.295624\n",
      "8575it [16:20,  8.75it/s]Train epoch: 0 [batch #8575, batch_size 1, seq length 2500]\tLoss: 6.376354\n",
      "8600it [16:23,  8.63it/s]Train epoch: 0 [batch #8600, batch_size 1, seq length 2500]\tLoss: 6.319361\n",
      "8625it [16:26,  8.77it/s]Train epoch: 0 [batch #8625, batch_size 1, seq length 2500]\tLoss: 6.034542\n",
      "8650it [16:28,  8.77it/s]Train epoch: 0 [batch #8650, batch_size 1, seq length 2500]\tLoss: 6.362569\n",
      "8675it [16:31,  8.78it/s]Train epoch: 0 [batch #8675, batch_size 1, seq length 2500]\tLoss: 6.158848\n",
      "8700it [16:34,  8.75it/s]Train epoch: 0 [batch #8700, batch_size 1, seq length 2500]\tLoss: 6.157147\n",
      "8725it [16:37,  8.76it/s]Train epoch: 0 [batch #8725, batch_size 1, seq length 2500]\tLoss: 6.161920\n",
      "8750it [16:40,  8.76it/s]Train epoch: 0 [batch #8750, batch_size 1, seq length 2500]\tLoss: 6.088716\n",
      "8775it [16:43,  8.76it/s]Train epoch: 0 [batch #8775, batch_size 1, seq length 2500]\tLoss: 6.312925\n",
      "8800it [16:46,  8.76it/s]Train epoch: 0 [batch #8800, batch_size 1, seq length 2500]\tLoss: 6.451575\n",
      "8825it [16:48,  8.65it/s]Train epoch: 0 [batch #8825, batch_size 1, seq length 2500]\tLoss: 6.329354\n",
      "8850it [16:51,  8.76it/s]Train epoch: 0 [batch #8850, batch_size 1, seq length 2500]\tLoss: 6.135325\n",
      "8875it [16:54,  8.76it/s]Train epoch: 0 [batch #8875, batch_size 1, seq length 2500]\tLoss: 6.169148\n",
      "8900it [16:57,  8.77it/s]Train epoch: 0 [batch #8900, batch_size 1, seq length 2500]\tLoss: 6.229525\n",
      "8925it [17:00,  8.76it/s]Train epoch: 0 [batch #8925, batch_size 1, seq length 2500]\tLoss: 6.092276\n",
      "8950it [17:03,  8.75it/s]Train epoch: 0 [batch #8950, batch_size 1, seq length 2500]\tLoss: 6.391928\n",
      "8975it [17:06,  8.74it/s]Train epoch: 0 [batch #8975, batch_size 1, seq length 2500]\tLoss: 6.516312\n",
      "9000it [17:08,  8.73it/s]Train epoch: 0 [batch #9000, batch_size 1, seq length 2500]\tLoss: 6.326843\n",
      "9025it [17:11,  8.75it/s]Train epoch: 0 [batch #9025, batch_size 1, seq length 2500]\tLoss: 6.047804\n",
      "9050it [17:14,  8.78it/s]Train epoch: 0 [batch #9050, batch_size 1, seq length 2500]\tLoss: 6.161595\n",
      "9075it [17:17,  8.77it/s]Train epoch: 0 [batch #9075, batch_size 1, seq length 2500]\tLoss: 5.934403\n",
      "9100it [17:20,  8.77it/s]Train epoch: 0 [batch #9100, batch_size 1, seq length 2500]\tLoss: 6.042435\n",
      "9125it [17:23,  8.75it/s]Train epoch: 0 [batch #9125, batch_size 1, seq length 2500]\tLoss: 6.220257\n",
      "9150it [17:26,  8.67it/s]Train epoch: 0 [batch #9150, batch_size 1, seq length 2500]\tLoss: 6.207398\n",
      "9175it [17:28,  8.77it/s]Train epoch: 0 [batch #9175, batch_size 1, seq length 2500]\tLoss: 6.036925\n",
      "9200it [17:31,  8.68it/s]Train epoch: 0 [batch #9200, batch_size 1, seq length 2500]\tLoss: 6.107673\n",
      "9225it [17:34,  8.77it/s]Train epoch: 0 [batch #9225, batch_size 1, seq length 2500]\tLoss: 6.194865\n",
      "9250it [17:37,  8.70it/s]Train epoch: 0 [batch #9250, batch_size 1, seq length 2500]\tLoss: 6.408479\n",
      "9275it [17:40,  8.71it/s]Train epoch: 0 [batch #9275, batch_size 1, seq length 2500]\tLoss: 6.082972\n",
      "9300it [17:43,  8.75it/s]Train epoch: 0 [batch #9300, batch_size 1, seq length 2500]\tLoss: 6.065560\n",
      "9325it [17:46,  8.77it/s]Train epoch: 0 [batch #9325, batch_size 1, seq length 2500]\tLoss: 6.097758\n",
      "9350it [17:48,  8.77it/s]Train epoch: 0 [batch #9350, batch_size 1, seq length 2500]\tLoss: 6.040398\n",
      "9375it [17:51,  8.73it/s]Train epoch: 0 [batch #9375, batch_size 1, seq length 2500]\tLoss: 6.113755\n",
      "9400it [17:54,  8.77it/s]Train epoch: 0 [batch #9400, batch_size 1, seq length 2500]\tLoss: 6.132588\n",
      "9425it [17:57,  8.72it/s]Train epoch: 0 [batch #9425, batch_size 1, seq length 2500]\tLoss: 6.211439\n",
      "9450it [18:00,  8.59it/s]Train epoch: 0 [batch #9450, batch_size 1, seq length 2500]\tLoss: 6.154846\n",
      "9475it [18:03,  8.77it/s]Train epoch: 0 [batch #9475, batch_size 1, seq length 2500]\tLoss: 6.239700\n",
      "9500it [18:06,  8.76it/s]Train epoch: 0 [batch #9500, batch_size 1, seq length 2500]\tLoss: 5.793632\n",
      "9525it [18:08,  8.71it/s]Train epoch: 0 [batch #9525, batch_size 1, seq length 2500]\tLoss: 6.300696\n",
      "9550it [18:11,  8.77it/s]Train epoch: 0 [batch #9550, batch_size 1, seq length 2500]\tLoss: 6.202955\n",
      "9575it [18:14,  8.77it/s]Train epoch: 0 [batch #9575, batch_size 1, seq length 2500]\tLoss: 6.061803\n",
      "9600it [18:17,  8.56it/s]Train epoch: 0 [batch #9600, batch_size 1, seq length 2500]\tLoss: 5.596076\n",
      "9625it [18:20,  8.70it/s]Train epoch: 0 [batch #9625, batch_size 1, seq length 2500]\tLoss: 6.180034\n",
      "9650it [18:23,  8.75it/s]Train epoch: 0 [batch #9650, batch_size 1, seq length 2500]\tLoss: 6.053976\n",
      "9675it [18:26,  8.73it/s]Train epoch: 0 [batch #9675, batch_size 1, seq length 2500]\tLoss: 6.174776\n",
      "9700it [18:29,  8.61it/s]Train epoch: 0 [batch #9700, batch_size 1, seq length 2500]\tLoss: 6.231304\n",
      "9725it [18:31,  8.76it/s]Train epoch: 0 [batch #9725, batch_size 1, seq length 2500]\tLoss: 6.152287\n",
      "9750it [18:34,  8.77it/s]Train epoch: 0 [batch #9750, batch_size 1, seq length 2500]\tLoss: 6.076281\n",
      "9775it [18:37,  8.72it/s]Train epoch: 0 [batch #9775, batch_size 1, seq length 2500]\tLoss: 6.144616\n",
      "9800it [18:40,  8.77it/s]Train epoch: 0 [batch #9800, batch_size 1, seq length 2500]\tLoss: 6.068926\n",
      "9825it [18:43,  8.77it/s]Train epoch: 0 [batch #9825, batch_size 1, seq length 2500]\tLoss: 6.039523\n",
      "9850it [18:46,  8.73it/s]Train epoch: 0 [batch #9850, batch_size 1, seq length 2500]\tLoss: 6.250388\n",
      "9875it [18:49,  8.75it/s]Train epoch: 0 [batch #9875, batch_size 1, seq length 2500]\tLoss: 6.020279\n",
      "9900it [18:51,  8.70it/s]Train epoch: 0 [batch #9900, batch_size 1, seq length 2500]\tLoss: 6.244949\n",
      "9925it [18:54,  8.74it/s]Train epoch: 0 [batch #9925, batch_size 1, seq length 2500]\tLoss: 6.118221\n",
      "9950it [18:57,  8.68it/s]Train epoch: 0 [batch #9950, batch_size 1, seq length 2500]\tLoss: 6.286385\n",
      "9975it [19:00,  8.74it/s]Train epoch: 0 [batch #9975, batch_size 1, seq length 2500]\tLoss: 6.175900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000it [19:03,  8.77it/s]Train epoch: 0 [batch #10000, batch_size 1, seq length 2500]\tLoss: 6.342573\n",
      "10025it [19:06,  8.76it/s]Train epoch: 0 [batch #10025, batch_size 1, seq length 2500]\tLoss: 6.412858\n",
      "10050it [19:09,  8.77it/s]Train epoch: 0 [batch #10050, batch_size 1, seq length 2500]\tLoss: 6.288843\n",
      "10075it [19:11,  8.75it/s]Train epoch: 0 [batch #10075, batch_size 1, seq length 2500]\tLoss: 6.364231\n",
      "10100it [19:14,  8.72it/s]Train epoch: 0 [batch #10100, batch_size 1, seq length 2500]\tLoss: 6.240973\n",
      "10125it [19:17,  8.75it/s]Train epoch: 0 [batch #10125, batch_size 1, seq length 2500]\tLoss: 6.206641\n",
      "10150it [19:20,  8.78it/s]Train epoch: 0 [batch #10150, batch_size 1, seq length 2500]\tLoss: 6.156912\n",
      "10175it [19:23,  8.68it/s]Train epoch: 0 [batch #10175, batch_size 1, seq length 2500]\tLoss: 6.243673\n",
      "10200it [19:26,  8.76it/s]Train epoch: 0 [batch #10200, batch_size 1, seq length 2500]\tLoss: 6.441432\n",
      "10225it [19:29,  8.78it/s]Train epoch: 0 [batch #10225, batch_size 1, seq length 2500]\tLoss: 6.131798\n",
      "10250it [19:32,  8.76it/s]Train epoch: 0 [batch #10250, batch_size 1, seq length 2500]\tLoss: 6.079492\n",
      "10275it [19:34,  8.75it/s]Train epoch: 0 [batch #10275, batch_size 1, seq length 2500]\tLoss: 6.212801\n",
      "10300it [19:37,  8.74it/s]Train epoch: 0 [batch #10300, batch_size 1, seq length 2500]\tLoss: 6.247308\n",
      "10325it [19:40,  8.78it/s]Train epoch: 0 [batch #10325, batch_size 1, seq length 2500]\tLoss: 6.231907\n",
      "10350it [19:43,  8.75it/s]Train epoch: 0 [batch #10350, batch_size 1, seq length 2500]\tLoss: 6.055730\n",
      "10375it [19:46,  8.77it/s]Train epoch: 0 [batch #10375, batch_size 1, seq length 2500]\tLoss: 6.102750\n",
      "10400it [19:49,  8.75it/s]Train epoch: 0 [batch #10400, batch_size 1, seq length 2500]\tLoss: 5.952771\n",
      "10425it [19:52,  8.76it/s]Train epoch: 0 [batch #10425, batch_size 1, seq length 2500]\tLoss: 6.199326\n",
      "10450it [19:54,  8.77it/s]Train epoch: 0 [batch #10450, batch_size 1, seq length 2500]\tLoss: 6.077173\n",
      "10475it [19:57,  8.77it/s]Train epoch: 0 [batch #10475, batch_size 1, seq length 2500]\tLoss: 6.191580\n",
      "10500it [20:00,  8.78it/s]Train epoch: 0 [batch #10500, batch_size 1, seq length 2500]\tLoss: 6.202253\n",
      "10525it [20:03,  8.77it/s]Train epoch: 0 [batch #10525, batch_size 1, seq length 2500]\tLoss: 6.151534\n",
      "10550it [20:06,  8.78it/s]Train epoch: 0 [batch #10550, batch_size 1, seq length 2500]\tLoss: 6.154097\n",
      "10575it [20:09,  8.76it/s]Train epoch: 0 [batch #10575, batch_size 1, seq length 2500]\tLoss: 6.217212\n",
      "10600it [20:12,  8.73it/s]Train epoch: 0 [batch #10600, batch_size 1, seq length 2500]\tLoss: 5.884491\n",
      "10625it [20:14,  8.77it/s]Train epoch: 0 [batch #10625, batch_size 1, seq length 2500]\tLoss: 6.045185\n",
      "10650it [20:17,  8.76it/s]Train epoch: 0 [batch #10650, batch_size 1, seq length 2500]\tLoss: 6.278597\n",
      "10675it [20:20,  8.77it/s]Train epoch: 0 [batch #10675, batch_size 1, seq length 2500]\tLoss: 6.080543\n",
      "10700it [20:23,  8.77it/s]Train epoch: 0 [batch #10700, batch_size 1, seq length 2500]\tLoss: 6.123308\n",
      "10725it [20:26,  8.71it/s]Train epoch: 0 [batch #10725, batch_size 1, seq length 2500]\tLoss: 6.223837\n",
      "10750it [20:29,  8.76it/s]Train epoch: 0 [batch #10750, batch_size 1, seq length 2500]\tLoss: 6.009977\n",
      "10775it [20:31,  8.75it/s]Train epoch: 0 [batch #10775, batch_size 1, seq length 2500]\tLoss: 6.218033\n",
      "10800it [20:34,  8.76it/s]Train epoch: 0 [batch #10800, batch_size 1, seq length 2500]\tLoss: 6.034471\n",
      "10825it [20:37,  8.73it/s]Train epoch: 0 [batch #10825, batch_size 1, seq length 2500]\tLoss: 6.173969\n",
      "10850it [20:40,  8.77it/s]Train epoch: 0 [batch #10850, batch_size 1, seq length 2500]\tLoss: 6.374469\n",
      "10875it [20:43,  8.77it/s]Train epoch: 0 [batch #10875, batch_size 1, seq length 2500]\tLoss: 6.195048\n",
      "10900it [20:46,  8.78it/s]Train epoch: 0 [batch #10900, batch_size 1, seq length 2500]\tLoss: 6.016348\n",
      "10925it [20:49,  8.77it/s]Train epoch: 0 [batch #10925, batch_size 1, seq length 2500]\tLoss: 6.133398\n",
      "10950it [20:52,  8.74it/s]Train epoch: 0 [batch #10950, batch_size 1, seq length 2500]\tLoss: 6.070294\n",
      "10975it [20:54,  8.74it/s]Train epoch: 0 [batch #10975, batch_size 1, seq length 2500]\tLoss: 6.086851\n",
      "11000it [20:57,  8.76it/s]Train epoch: 0 [batch #11000, batch_size 1, seq length 2500]\tLoss: 6.148318\n",
      "11025it [21:00,  8.77it/s]Train epoch: 0 [batch #11025, batch_size 1, seq length 2500]\tLoss: 6.323008\n",
      "11050it [21:03,  8.68it/s]Train epoch: 0 [batch #11050, batch_size 1, seq length 2500]\tLoss: 6.051018\n",
      "11075it [21:06,  8.77it/s]Train epoch: 0 [batch #11075, batch_size 1, seq length 2500]\tLoss: 6.154406\n",
      "11100it [21:09,  8.75it/s]Train epoch: 0 [batch #11100, batch_size 1, seq length 2500]\tLoss: 6.128754\n",
      "11125it [21:12,  8.74it/s]Train epoch: 0 [batch #11125, batch_size 1, seq length 2500]\tLoss: 6.094341\n",
      "11150it [21:14,  8.75it/s]Train epoch: 0 [batch #11150, batch_size 1, seq length 2500]\tLoss: 5.883831\n",
      "11175it [21:17,  8.76it/s]Train epoch: 0 [batch #11175, batch_size 1, seq length 2500]\tLoss: 6.394104\n",
      "11200it [21:20,  8.76it/s]Train epoch: 0 [batch #11200, batch_size 1, seq length 2500]\tLoss: 6.004770\n",
      "11225it [21:23,  8.77it/s]Train epoch: 0 [batch #11225, batch_size 1, seq length 2500]\tLoss: 6.011311\n",
      "11250it [21:26,  8.76it/s]Train epoch: 0 [batch #11250, batch_size 1, seq length 2500]\tLoss: 5.991718\n",
      "11275it [21:29,  8.75it/s]Train epoch: 0 [batch #11275, batch_size 1, seq length 2500]\tLoss: 6.024274\n",
      "11300it [21:32,  8.75it/s]Train epoch: 0 [batch #11300, batch_size 1, seq length 2500]\tLoss: 6.257213\n",
      "11325it [21:34,  8.77it/s]Train epoch: 0 [batch #11325, batch_size 1, seq length 2500]\tLoss: 5.971699\n",
      "11350it [21:37,  8.74it/s]Train epoch: 0 [batch #11350, batch_size 1, seq length 2500]\tLoss: 5.876165\n",
      "11375it [21:40,  8.75it/s]Train epoch: 0 [batch #11375, batch_size 1, seq length 2500]\tLoss: 6.142932\n",
      "11400it [21:43,  8.76it/s]Train epoch: 0 [batch #11400, batch_size 1, seq length 2500]\tLoss: 6.224750\n",
      "11425it [21:46,  8.77it/s]Train epoch: 0 [batch #11425, batch_size 1, seq length 2500]\tLoss: 6.006945\n",
      "11450it [21:49,  8.75it/s]Train epoch: 0 [batch #11450, batch_size 1, seq length 2500]\tLoss: 5.930076\n",
      "11475it [21:52,  8.61it/s]Train epoch: 0 [batch #11475, batch_size 1, seq length 2500]\tLoss: 6.172965\n",
      "11500it [21:54,  8.77it/s]Train epoch: 0 [batch #11500, batch_size 1, seq length 2500]\tLoss: 6.123473\n",
      "11525it [21:57,  8.76it/s]Train epoch: 0 [batch #11525, batch_size 1, seq length 2500]\tLoss: 6.052695\n",
      "11550it [22:00,  8.78it/s]Train epoch: 0 [batch #11550, batch_size 1, seq length 2500]\tLoss: 5.933207\n",
      "11575it [22:03,  8.75it/s]Train epoch: 0 [batch #11575, batch_size 1, seq length 2500]\tLoss: 5.896352\n",
      "11600it [22:06,  8.51it/s]Train epoch: 0 [batch #11600, batch_size 1, seq length 2500]\tLoss: 6.191872\n",
      "11625it [22:09,  8.73it/s]Train epoch: 0 [batch #11625, batch_size 1, seq length 2500]\tLoss: 6.074375\n",
      "11650it [22:12,  8.77it/s]Train epoch: 0 [batch #11650, batch_size 1, seq length 2500]\tLoss: 6.054821\n",
      "11675it [22:14,  8.77it/s]Train epoch: 0 [batch #11675, batch_size 1, seq length 2500]\tLoss: 6.095120\n",
      "11700it [22:17,  8.77it/s]Train epoch: 0 [batch #11700, batch_size 1, seq length 2500]\tLoss: 6.181717\n",
      "11725it [22:20,  8.75it/s]Train epoch: 0 [batch #11725, batch_size 1, seq length 2500]\tLoss: 5.890966\n",
      "11750it [22:23,  8.77it/s]Train epoch: 0 [batch #11750, batch_size 1, seq length 2500]\tLoss: 6.121153\n",
      "11775it [22:26,  8.74it/s]Train epoch: 0 [batch #11775, batch_size 1, seq length 2500]\tLoss: 5.974068\n",
      "11800it [22:29,  8.77it/s]Train epoch: 0 [batch #11800, batch_size 1, seq length 2500]\tLoss: 5.964204\n",
      "11825it [22:32,  8.77it/s]Train epoch: 0 [batch #11825, batch_size 1, seq length 2500]\tLoss: 6.477346\n",
      "11850it [22:34,  8.75it/s]Train epoch: 0 [batch #11850, batch_size 1, seq length 2500]\tLoss: 6.252964\n",
      "11875it [22:37,  8.74it/s]Train epoch: 0 [batch #11875, batch_size 1, seq length 2500]\tLoss: 6.136504\n",
      "11900it [22:40,  8.73it/s]Train epoch: 0 [batch #11900, batch_size 1, seq length 2500]\tLoss: 6.320223\n",
      "11925it [22:43,  8.76it/s]Train epoch: 0 [batch #11925, batch_size 1, seq length 2500]\tLoss: 6.101629\n",
      "11950it [22:46,  8.76it/s]Train epoch: 0 [batch #11950, batch_size 1, seq length 2500]\tLoss: 6.219634\n",
      "11975it [22:49,  8.72it/s]Train epoch: 0 [batch #11975, batch_size 1, seq length 2500]\tLoss: 5.755040\n",
      "12000it [22:52,  8.78it/s]Train epoch: 0 [batch #12000, batch_size 1, seq length 2500]\tLoss: 6.256793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12025it [22:54,  8.77it/s]Train epoch: 0 [batch #12025, batch_size 1, seq length 2500]\tLoss: 6.171950\n",
      "12050it [22:57,  8.76it/s]Train epoch: 0 [batch #12050, batch_size 1, seq length 2500]\tLoss: 6.231042\n",
      "12075it [23:00,  8.76it/s]Train epoch: 0 [batch #12075, batch_size 1, seq length 2500]\tLoss: 6.157690\n",
      "12100it [23:03,  8.72it/s]Train epoch: 0 [batch #12100, batch_size 1, seq length 2500]\tLoss: 6.077376\n",
      "12125it [23:06,  8.77it/s]Train epoch: 0 [batch #12125, batch_size 1, seq length 2500]\tLoss: 5.939850\n",
      "12150it [23:09,  8.74it/s]Train epoch: 0 [batch #12150, batch_size 1, seq length 2500]\tLoss: 6.165136\n",
      "12175it [23:12,  8.77it/s]Train epoch: 0 [batch #12175, batch_size 1, seq length 2500]\tLoss: 6.113050\n",
      "12200it [23:14,  8.77it/s]Train epoch: 0 [batch #12200, batch_size 1, seq length 2500]\tLoss: 5.867997\n",
      "12225it [23:17,  8.77it/s]Train epoch: 0 [batch #12225, batch_size 1, seq length 2500]\tLoss: 6.076768\n",
      "12250it [23:20,  8.66it/s]Train epoch: 0 [batch #12250, batch_size 1, seq length 2500]\tLoss: 6.240548\n",
      "12275it [23:23,  8.72it/s]Train epoch: 0 [batch #12275, batch_size 1, seq length 2500]\tLoss: 6.180161\n",
      "12300it [23:26,  8.76it/s]Train epoch: 0 [batch #12300, batch_size 1, seq length 2500]\tLoss: 5.952634\n",
      "12325it [23:29,  8.76it/s]Train epoch: 0 [batch #12325, batch_size 1, seq length 2500]\tLoss: 6.240397\n",
      "12350it [23:32,  8.65it/s]Train epoch: 0 [batch #12350, batch_size 1, seq length 2500]\tLoss: 6.280617\n",
      "12375it [23:34,  8.76it/s]Train epoch: 0 [batch #12375, batch_size 1, seq length 2500]\tLoss: 6.012805\n",
      "12400it [23:37,  8.76it/s]Train epoch: 0 [batch #12400, batch_size 1, seq length 2500]\tLoss: 6.050434\n",
      "12425it [23:40,  8.76it/s]Train epoch: 0 [batch #12425, batch_size 1, seq length 2500]\tLoss: 5.859224\n",
      "12450it [23:43,  8.75it/s]Train epoch: 0 [batch #12450, batch_size 1, seq length 2500]\tLoss: 6.088907\n",
      "12475it [23:46,  8.76it/s]Train epoch: 0 [batch #12475, batch_size 1, seq length 2500]\tLoss: 6.157438\n",
      "12500it [23:49,  8.71it/s]Train epoch: 0 [batch #12500, batch_size 1, seq length 2500]\tLoss: 6.068802\n",
      "12525it [23:52,  8.76it/s]Train epoch: 0 [batch #12525, batch_size 1, seq length 2500]\tLoss: 6.166607\n",
      "12550it [23:54,  8.76it/s]Train epoch: 0 [batch #12550, batch_size 1, seq length 2500]\tLoss: 5.854857\n",
      "12575it [23:57,  8.75it/s]Train epoch: 0 [batch #12575, batch_size 1, seq length 2500]\tLoss: 6.267584\n",
      "12600it [24:00,  8.78it/s]Train epoch: 0 [batch #12600, batch_size 1, seq length 2500]\tLoss: 6.333764\n",
      "12625it [24:03,  8.77it/s]Train epoch: 0 [batch #12625, batch_size 1, seq length 2500]\tLoss: 6.160311\n",
      "12650it [24:06,  8.76it/s]Train epoch: 0 [batch #12650, batch_size 1, seq length 2500]\tLoss: 6.293298\n",
      "12675it [24:09,  8.74it/s]Train epoch: 0 [batch #12675, batch_size 1, seq length 2500]\tLoss: 6.173667\n",
      "12700it [24:12,  8.77it/s]Train epoch: 0 [batch #12700, batch_size 1, seq length 2500]\tLoss: 6.154020\n",
      "12725it [24:14,  8.76it/s]Train epoch: 0 [batch #12725, batch_size 1, seq length 2500]\tLoss: 6.192313\n",
      "12750it [24:17,  8.77it/s]Train epoch: 0 [batch #12750, batch_size 1, seq length 2500]\tLoss: 6.109770\n",
      "12775it [24:20,  8.76it/s]Train epoch: 0 [batch #12775, batch_size 1, seq length 2500]\tLoss: 5.963019\n",
      "12800it [24:23,  8.76it/s]Train epoch: 0 [batch #12800, batch_size 1, seq length 2500]\tLoss: 5.877135\n",
      "12825it [24:26,  8.78it/s]Train epoch: 0 [batch #12825, batch_size 1, seq length 2500]\tLoss: 5.957762\n",
      "12850it [24:29,  8.74it/s]Train epoch: 0 [batch #12850, batch_size 1, seq length 2500]\tLoss: 6.146687\n",
      "12875it [24:32,  8.76it/s]Train epoch: 0 [batch #12875, batch_size 1, seq length 2500]\tLoss: 5.916204\n",
      "12900it [24:34,  8.74it/s]Train epoch: 0 [batch #12900, batch_size 1, seq length 2500]\tLoss: 6.166272\n",
      "12925it [24:37,  8.76it/s]Train epoch: 0 [batch #12925, batch_size 1, seq length 2500]\tLoss: 6.058091\n",
      "12950it [24:40,  8.74it/s]Train epoch: 0 [batch #12950, batch_size 1, seq length 2500]\tLoss: 6.036695\n",
      "12975it [24:43,  8.76it/s]Train epoch: 0 [batch #12975, batch_size 1, seq length 2500]\tLoss: 6.067845\n",
      "13000it [24:46,  8.76it/s]Train epoch: 0 [batch #13000, batch_size 1, seq length 2500]\tLoss: 6.089510\n",
      "13025it [24:49,  8.77it/s]Train epoch: 0 [batch #13025, batch_size 1, seq length 2500]\tLoss: 6.192849\n",
      "13050it [24:52,  8.76it/s]Train epoch: 0 [batch #13050, batch_size 1, seq length 2500]\tLoss: 6.172048\n",
      "13075it [24:54,  8.76it/s]Train epoch: 0 [batch #13075, batch_size 1, seq length 2500]\tLoss: 5.952477\n",
      "13100it [24:57,  8.75it/s]Train epoch: 0 [batch #13100, batch_size 1, seq length 2500]\tLoss: 6.068625\n",
      "13125it [25:00,  8.75it/s]Train epoch: 0 [batch #13125, batch_size 1, seq length 2500]\tLoss: 5.998403\n",
      "13150it [25:03,  8.78it/s]Train epoch: 0 [batch #13150, batch_size 1, seq length 2500]\tLoss: 6.067958\n",
      "13175it [25:06,  8.77it/s]Train epoch: 0 [batch #13175, batch_size 1, seq length 2500]\tLoss: 5.432817\n",
      "13200it [25:09,  8.77it/s]Train epoch: 0 [batch #13200, batch_size 1, seq length 2500]\tLoss: 6.198853\n",
      "13225it [25:12,  8.78it/s]Train epoch: 0 [batch #13225, batch_size 1, seq length 2500]\tLoss: 6.021113\n",
      "13250it [25:14,  8.76it/s]Train epoch: 0 [batch #13250, batch_size 1, seq length 2500]\tLoss: 6.008311\n",
      "13275it [25:17,  8.72it/s]Train epoch: 0 [batch #13275, batch_size 1, seq length 2500]\tLoss: 5.999791\n",
      "13300it [25:20,  8.78it/s]Train epoch: 0 [batch #13300, batch_size 1, seq length 2500]\tLoss: 5.758749\n",
      "13325it [25:23,  8.78it/s]Train epoch: 0 [batch #13325, batch_size 1, seq length 2500]\tLoss: 6.079879\n",
      "13350it [25:26,  8.75it/s]Train epoch: 0 [batch #13350, batch_size 1, seq length 2500]\tLoss: 6.003894\n",
      "13375it [25:29,  8.72it/s]Train epoch: 0 [batch #13375, batch_size 1, seq length 2500]\tLoss: 6.225899\n",
      "13400it [25:32,  8.76it/s]Train epoch: 0 [batch #13400, batch_size 1, seq length 2500]\tLoss: 6.080562\n",
      "13425it [25:34,  8.76it/s]Train epoch: 0 [batch #13425, batch_size 1, seq length 2500]\tLoss: 6.216398\n",
      "13450it [25:37,  8.75it/s]Train epoch: 0 [batch #13450, batch_size 1, seq length 2500]\tLoss: 5.886822\n",
      "13475it [25:40,  8.77it/s]Train epoch: 0 [batch #13475, batch_size 1, seq length 2500]\tLoss: 6.109274\n",
      "13500it [25:43,  8.76it/s]Train epoch: 0 [batch #13500, batch_size 1, seq length 2500]\tLoss: 6.076694\n",
      "13525it [25:46,  8.77it/s]Train epoch: 0 [batch #13525, batch_size 1, seq length 2500]\tLoss: 6.039424\n",
      "13550it [25:49,  8.78it/s]Train epoch: 0 [batch #13550, batch_size 1, seq length 2500]\tLoss: 5.974826\n",
      "13575it [25:51,  8.77it/s]Train epoch: 0 [batch #13575, batch_size 1, seq length 2500]\tLoss: 6.026603\n",
      "13600it [25:54,  8.78it/s]Train epoch: 0 [batch #13600, batch_size 1, seq length 2500]\tLoss: 6.014730\n",
      "13625it [25:57,  8.77it/s]Train epoch: 0 [batch #13625, batch_size 1, seq length 2500]\tLoss: 6.213209\n",
      "13650it [26:00,  8.72it/s]Train epoch: 0 [batch #13650, batch_size 1, seq length 2500]\tLoss: 6.036266\n",
      "13675it [26:03,  8.76it/s]Train epoch: 0 [batch #13675, batch_size 1, seq length 2500]\tLoss: 5.889190\n",
      "13700it [26:06,  8.77it/s]Train epoch: 0 [batch #13700, batch_size 1, seq length 2500]\tLoss: 6.079730\n",
      "13725it [26:09,  8.77it/s]Train epoch: 0 [batch #13725, batch_size 1, seq length 2500]\tLoss: 6.027437\n",
      "13750it [26:11,  8.78it/s]Train epoch: 0 [batch #13750, batch_size 1, seq length 2500]\tLoss: 6.046670\n",
      "13775it [26:14,  8.73it/s]Train epoch: 0 [batch #13775, batch_size 1, seq length 2500]\tLoss: 5.904841\n",
      "13800it [26:17,  8.76it/s]Train epoch: 0 [batch #13800, batch_size 1, seq length 2500]\tLoss: 6.001628\n",
      "13825it [26:20,  8.77it/s]Train epoch: 0 [batch #13825, batch_size 1, seq length 2500]\tLoss: 5.887208\n",
      "13850it [26:23,  8.77it/s]Train epoch: 0 [batch #13850, batch_size 1, seq length 2500]\tLoss: 5.758593\n",
      "13875it [26:26,  8.76it/s]Train epoch: 0 [batch #13875, batch_size 1, seq length 2500]\tLoss: 5.879384\n",
      "13900it [26:29,  8.75it/s]Train epoch: 0 [batch #13900, batch_size 1, seq length 2500]\tLoss: 5.822237\n",
      "13925it [26:31,  8.77it/s]Train epoch: 0 [batch #13925, batch_size 1, seq length 2500]\tLoss: 6.065923\n",
      "13950it [26:34,  8.74it/s]Train epoch: 0 [batch #13950, batch_size 1, seq length 2500]\tLoss: 5.879347\n",
      "13975it [26:37,  8.75it/s]Train epoch: 0 [batch #13975, batch_size 1, seq length 2500]\tLoss: 5.811783\n",
      "14000it [26:40,  8.77it/s]Train epoch: 0 [batch #14000, batch_size 1, seq length 2500]\tLoss: 5.767737\n",
      "14025it [26:43,  8.76it/s]Train epoch: 0 [batch #14025, batch_size 1, seq length 2500]\tLoss: 6.008247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14050it [26:46,  8.78it/s]Train epoch: 0 [batch #14050, batch_size 1, seq length 2500]\tLoss: 5.986345\n",
      "14075it [26:49,  8.77it/s]Train epoch: 0 [batch #14075, batch_size 1, seq length 2500]\tLoss: 5.976213\n",
      "14100it [26:51,  8.77it/s]Train epoch: 0 [batch #14100, batch_size 1, seq length 2500]\tLoss: 5.982092\n",
      "14125it [26:54,  8.75it/s]Train epoch: 0 [batch #14125, batch_size 1, seq length 2500]\tLoss: 6.142155\n",
      "14150it [26:57,  8.73it/s]Train epoch: 0 [batch #14150, batch_size 1, seq length 2500]\tLoss: 5.808205\n",
      "14175it [27:00,  8.73it/s]Train epoch: 0 [batch #14175, batch_size 1, seq length 2500]\tLoss: 6.020637\n",
      "14200it [27:03,  8.76it/s]Train epoch: 0 [batch #14200, batch_size 1, seq length 2500]\tLoss: 6.014069\n",
      "14225it [27:06,  8.77it/s]Train epoch: 0 [batch #14225, batch_size 1, seq length 2500]\tLoss: 5.931472\n",
      "14250it [27:09,  8.76it/s]Train epoch: 0 [batch #14250, batch_size 1, seq length 2500]\tLoss: 5.768554\n",
      "14275it [27:11,  8.77it/s]Train epoch: 0 [batch #14275, batch_size 1, seq length 2500]\tLoss: 5.987721\n",
      "14300it [27:14,  8.76it/s]Train epoch: 0 [batch #14300, batch_size 1, seq length 2500]\tLoss: 5.896751\n",
      "14325it [27:17,  8.77it/s]Train epoch: 0 [batch #14325, batch_size 1, seq length 2500]\tLoss: 6.072259\n",
      "14350it [27:20,  8.74it/s]Train epoch: 0 [batch #14350, batch_size 1, seq length 2500]\tLoss: 6.051417\n",
      "14375it [27:23,  8.75it/s]Train epoch: 0 [batch #14375, batch_size 1, seq length 2500]\tLoss: 5.896797\n",
      "14400it [27:26,  8.75it/s]Train epoch: 0 [batch #14400, batch_size 1, seq length 2500]\tLoss: 5.910617\n",
      "14425it [27:29,  8.73it/s]Train epoch: 0 [batch #14425, batch_size 1, seq length 2500]\tLoss: 6.048259\n",
      "14450it [27:31,  8.74it/s]Train epoch: 0 [batch #14450, batch_size 1, seq length 2500]\tLoss: 5.895154\n",
      "14475it [27:34,  8.76it/s]Train epoch: 0 [batch #14475, batch_size 1, seq length 2500]\tLoss: 6.032144\n",
      "14500it [27:37,  8.77it/s]Train epoch: 0 [batch #14500, batch_size 1, seq length 2500]\tLoss: 6.074754\n",
      "14525it [27:40,  8.76it/s]Train epoch: 0 [batch #14525, batch_size 1, seq length 2500]\tLoss: 5.908408\n",
      "14550it [27:43,  8.75it/s]Train epoch: 0 [batch #14550, batch_size 1, seq length 2500]\tLoss: 5.845775\n",
      "14575it [27:46,  8.77it/s]Train epoch: 0 [batch #14575, batch_size 1, seq length 2500]\tLoss: 5.709297\n",
      "14600it [27:49,  8.75it/s]Train epoch: 0 [batch #14600, batch_size 1, seq length 2500]\tLoss: 6.186481\n",
      "14625it [27:51,  8.76it/s]Train epoch: 0 [batch #14625, batch_size 1, seq length 2500]\tLoss: 5.951324\n",
      "14650it [27:54,  8.71it/s]Train epoch: 0 [batch #14650, batch_size 1, seq length 2500]\tLoss: 6.223312\n",
      "14675it [27:57,  8.75it/s]Train epoch: 0 [batch #14675, batch_size 1, seq length 2500]\tLoss: 5.761804\n",
      "14700it [28:00,  8.74it/s]Train epoch: 0 [batch #14700, batch_size 1, seq length 2500]\tLoss: 6.037833\n",
      "14725it [28:03,  8.77it/s]Train epoch: 0 [batch #14725, batch_size 1, seq length 2500]\tLoss: 5.991284\n",
      "14750it [28:06,  8.75it/s]Train epoch: 0 [batch #14750, batch_size 1, seq length 2500]\tLoss: 5.996412\n",
      "14775it [28:09,  8.76it/s]Train epoch: 0 [batch #14775, batch_size 1, seq length 2500]\tLoss: 5.903075\n",
      "14800it [28:11,  8.78it/s]Train epoch: 0 [batch #14800, batch_size 1, seq length 2500]\tLoss: 5.921730\n",
      "14825it [28:14,  8.77it/s]Train epoch: 0 [batch #14825, batch_size 1, seq length 2500]\tLoss: 6.045228\n",
      "14850it [28:17,  8.76it/s]Train epoch: 0 [batch #14850, batch_size 1, seq length 2500]\tLoss: 5.734826\n",
      "14875it [28:20,  8.77it/s]Train epoch: 0 [batch #14875, batch_size 1, seq length 2500]\tLoss: 5.930823\n",
      "14900it [28:23,  8.76it/s]Train epoch: 0 [batch #14900, batch_size 1, seq length 2500]\tLoss: 5.947553\n",
      "14925it [28:26,  8.76it/s]Train epoch: 0 [batch #14925, batch_size 1, seq length 2500]\tLoss: 5.836423\n",
      "14950it [28:29,  8.76it/s]Train epoch: 0 [batch #14950, batch_size 1, seq length 2500]\tLoss: 5.885665\n",
      "14975it [28:31,  8.76it/s]Train epoch: 0 [batch #14975, batch_size 1, seq length 2500]\tLoss: 6.198576\n",
      "15000it [28:34,  8.77it/s]Train epoch: 0 [batch #15000, batch_size 1, seq length 2500]\tLoss: 5.927519\n",
      "15025it [28:37,  8.64it/s]Train epoch: 0 [batch #15025, batch_size 1, seq length 2500]\tLoss: 5.665050\n",
      "15050it [28:40,  8.76it/s]Train epoch: 0 [batch #15050, batch_size 1, seq length 2500]\tLoss: 6.062337\n",
      "15075it [28:43,  8.77it/s]Train epoch: 0 [batch #15075, batch_size 1, seq length 2500]\tLoss: 5.873203\n",
      "15100it [28:46,  8.74it/s]Train epoch: 0 [batch #15100, batch_size 1, seq length 2500]\tLoss: 5.812754\n",
      "15125it [28:49,  8.66it/s]Train epoch: 0 [batch #15125, batch_size 1, seq length 2500]\tLoss: 5.962289\n",
      "15150it [28:51,  8.78it/s]Train epoch: 0 [batch #15150, batch_size 1, seq length 2500]\tLoss: 5.846158\n",
      "15175it [28:54,  8.76it/s]Train epoch: 0 [batch #15175, batch_size 1, seq length 2500]\tLoss: 5.838792\n",
      "15200it [28:57,  8.77it/s]Train epoch: 0 [batch #15200, batch_size 1, seq length 2500]\tLoss: 5.927081\n",
      "15225it [29:00,  8.76it/s]Train epoch: 0 [batch #15225, batch_size 1, seq length 2500]\tLoss: 5.994751\n",
      "15250it [29:03,  8.72it/s]Train epoch: 0 [batch #15250, batch_size 1, seq length 2500]\tLoss: 5.961174\n",
      "15275it [29:06,  8.77it/s]Train epoch: 0 [batch #15275, batch_size 1, seq length 2500]\tLoss: 5.682169\n",
      "15300it [29:09,  8.78it/s]Train epoch: 0 [batch #15300, batch_size 1, seq length 2500]\tLoss: 5.968410\n",
      "15325it [29:11,  8.77it/s]Train epoch: 0 [batch #15325, batch_size 1, seq length 2500]\tLoss: 5.983328\n",
      "15350it [29:14,  8.77it/s]Train epoch: 0 [batch #15350, batch_size 1, seq length 2500]\tLoss: 6.144883\n",
      "15375it [29:17,  8.77it/s]Train epoch: 0 [batch #15375, batch_size 1, seq length 2500]\tLoss: 5.919649\n",
      "15400it [29:20,  8.64it/s]Train epoch: 0 [batch #15400, batch_size 1, seq length 2500]\tLoss: 5.950195\n",
      "15425it [29:23,  8.73it/s]Train epoch: 0 [batch #15425, batch_size 1, seq length 2500]\tLoss: 5.768612\n",
      "15450it [29:26,  8.77it/s]Train epoch: 0 [batch #15450, batch_size 1, seq length 2500]\tLoss: 5.787409\n",
      "15475it [29:28,  8.75it/s]Train epoch: 0 [batch #15475, batch_size 1, seq length 2500]\tLoss: 5.945089\n",
      "15500it [29:31,  8.74it/s]Train epoch: 0 [batch #15500, batch_size 1, seq length 2500]\tLoss: 6.024423\n",
      "15525it [29:34,  8.76it/s]Train epoch: 0 [batch #15525, batch_size 1, seq length 2500]\tLoss: 5.978737\n",
      "15550it [29:37,  8.72it/s]Train epoch: 0 [batch #15550, batch_size 1, seq length 2500]\tLoss: 6.017124\n",
      "15575it [29:40,  8.75it/s]Train epoch: 0 [batch #15575, batch_size 1, seq length 2500]\tLoss: 5.953827\n",
      "15600it [29:43,  8.76it/s]Train epoch: 0 [batch #15600, batch_size 1, seq length 2500]\tLoss: 6.000615\n",
      "15625it [29:46,  8.74it/s]Train epoch: 0 [batch #15625, batch_size 1, seq length 2500]\tLoss: 5.877666\n",
      "15650it [29:49,  8.72it/s]Train epoch: 0 [batch #15650, batch_size 1, seq length 2500]\tLoss: 6.275385\n",
      "15675it [29:51,  8.72it/s]Train epoch: 0 [batch #15675, batch_size 1, seq length 2500]\tLoss: 5.795857\n",
      "15700it [29:54,  8.73it/s]Train epoch: 0 [batch #15700, batch_size 1, seq length 2500]\tLoss: 5.912273\n",
      "15725it [29:57,  8.78it/s]Train epoch: 0 [batch #15725, batch_size 1, seq length 2500]\tLoss: 5.952890\n",
      "15750it [30:00,  8.75it/s]Train epoch: 0 [batch #15750, batch_size 1, seq length 2500]\tLoss: 6.036860\n",
      "15775it [30:03,  8.77it/s]Train epoch: 0 [batch #15775, batch_size 1, seq length 2500]\tLoss: 6.167167\n",
      "15800it [30:06,  8.75it/s]Train epoch: 0 [batch #15800, batch_size 1, seq length 2500]\tLoss: 5.707038\n",
      "15825it [30:09,  8.77it/s]Train epoch: 0 [batch #15825, batch_size 1, seq length 2500]\tLoss: 5.723393\n",
      "15850it [30:11,  8.77it/s]Train epoch: 0 [batch #15850, batch_size 1, seq length 2500]\tLoss: 5.884734\n",
      "15875it [30:14,  8.75it/s]Train epoch: 0 [batch #15875, batch_size 1, seq length 2500]\tLoss: 5.875623\n",
      "15900it [30:17,  8.74it/s]Train epoch: 0 [batch #15900, batch_size 1, seq length 2500]\tLoss: 5.924505\n",
      "15925it [30:20,  8.77it/s]Train epoch: 0 [batch #15925, batch_size 1, seq length 2500]\tLoss: 5.961729\n",
      "15950it [30:23,  8.75it/s]Train epoch: 0 [batch #15950, batch_size 1, seq length 2500]\tLoss: 5.994965\n",
      "15975it [30:26,  8.57it/s]Train epoch: 0 [batch #15975, batch_size 1, seq length 2500]\tLoss: 5.777470\n",
      "16000it [30:29,  8.75it/s]Train epoch: 0 [batch #16000, batch_size 1, seq length 2500]\tLoss: 6.113360\n",
      "16025it [30:31,  8.73it/s]Train epoch: 0 [batch #16025, batch_size 1, seq length 2500]\tLoss: 5.800666\n",
      "16050it [30:34,  8.77it/s]Train epoch: 0 [batch #16050, batch_size 1, seq length 2500]\tLoss: 6.125640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16075it [30:37,  8.75it/s]Train epoch: 0 [batch #16075, batch_size 1, seq length 2500]\tLoss: 5.576343\n",
      "16100it [30:40,  8.75it/s]Train epoch: 0 [batch #16100, batch_size 1, seq length 2500]\tLoss: 6.010576\n",
      "16125it [30:43,  8.76it/s]Train epoch: 0 [batch #16125, batch_size 1, seq length 2500]\tLoss: 5.802914\n",
      "16150it [30:46,  8.76it/s]Train epoch: 0 [batch #16150, batch_size 1, seq length 2500]\tLoss: 5.759998\n",
      "16175it [30:49,  8.76it/s]Train epoch: 0 [batch #16175, batch_size 1, seq length 2500]\tLoss: 5.932520\n",
      "16200it [30:51,  8.54it/s]Train epoch: 0 [batch #16200, batch_size 1, seq length 2500]\tLoss: 6.078829\n",
      "16225it [30:54,  8.76it/s]Train epoch: 0 [batch #16225, batch_size 1, seq length 2500]\tLoss: 5.748368\n",
      "16250it [30:57,  8.73it/s]Train epoch: 0 [batch #16250, batch_size 1, seq length 2500]\tLoss: 5.723348\n",
      "16275it [31:00,  8.76it/s]Train epoch: 0 [batch #16275, batch_size 1, seq length 2500]\tLoss: 5.755432\n",
      "16300it [31:03,  8.76it/s]Train epoch: 0 [batch #16300, batch_size 1, seq length 2500]\tLoss: 5.865024\n",
      "16325it [31:06,  8.77it/s]Train epoch: 0 [batch #16325, batch_size 1, seq length 2500]\tLoss: 5.990847\n",
      "16350it [31:09,  8.75it/s]Train epoch: 0 [batch #16350, batch_size 1, seq length 2500]\tLoss: 5.874071\n",
      "16375it [31:11,  8.74it/s]Train epoch: 0 [batch #16375, batch_size 1, seq length 2500]\tLoss: 6.008729\n",
      "16400it [31:14,  8.75it/s]Train epoch: 0 [batch #16400, batch_size 1, seq length 2500]\tLoss: 5.946776\n",
      "16425it [31:17,  8.74it/s]Train epoch: 0 [batch #16425, batch_size 1, seq length 2500]\tLoss: 5.867187\n",
      "16450it [31:20,  8.76it/s]Train epoch: 0 [batch #16450, batch_size 1, seq length 2500]\tLoss: 5.762337\n",
      "16475it [31:23,  8.77it/s]Train epoch: 0 [batch #16475, batch_size 1, seq length 2500]\tLoss: 5.942184\n",
      "16500it [31:26,  8.74it/s]Train epoch: 0 [batch #16500, batch_size 1, seq length 2500]\tLoss: 5.791507\n",
      "16525it [31:29,  8.78it/s]Train epoch: 0 [batch #16525, batch_size 1, seq length 2500]\tLoss: 6.065060\n",
      "16550it [31:31,  8.76it/s]Train epoch: 0 [batch #16550, batch_size 1, seq length 2500]\tLoss: 5.748892\n",
      "16575it [31:34,  8.75it/s]Train epoch: 0 [batch #16575, batch_size 1, seq length 2500]\tLoss: 6.236985\n",
      "16600it [31:37,  8.76it/s]Train epoch: 0 [batch #16600, batch_size 1, seq length 2500]\tLoss: 5.814787\n",
      "16625it [31:40,  8.76it/s]Train epoch: 0 [batch #16625, batch_size 1, seq length 2500]\tLoss: 5.756887\n",
      "16650it [31:43,  8.75it/s]Train epoch: 0 [batch #16650, batch_size 1, seq length 2500]\tLoss: 5.910840\n",
      "16675it [31:46,  8.63it/s]Train epoch: 0 [batch #16675, batch_size 1, seq length 2500]\tLoss: 5.739358\n",
      "16700it [31:49,  8.76it/s]Train epoch: 0 [batch #16700, batch_size 1, seq length 2500]\tLoss: 5.908605\n",
      "16725it [31:51,  8.75it/s]Train epoch: 0 [batch #16725, batch_size 1, seq length 2500]\tLoss: 5.750601\n",
      "16750it [31:54,  8.76it/s]Train epoch: 0 [batch #16750, batch_size 1, seq length 2500]\tLoss: 5.600126\n",
      "16775it [31:57,  8.76it/s]Train epoch: 0 [batch #16775, batch_size 1, seq length 2500]\tLoss: 5.628643\n",
      "16800it [32:00,  8.76it/s]Train epoch: 0 [batch #16800, batch_size 1, seq length 2500]\tLoss: 5.974155\n",
      "16825it [32:03,  8.76it/s]Train epoch: 0 [batch #16825, batch_size 1, seq length 2500]\tLoss: 5.536522\n",
      "16850it [32:06,  8.78it/s]Train epoch: 0 [batch #16850, batch_size 1, seq length 2500]\tLoss: 5.721019\n",
      "16875it [32:09,  8.76it/s]Train epoch: 0 [batch #16875, batch_size 1, seq length 2500]\tLoss: 5.832735\n",
      "16900it [32:11,  8.74it/s]Train epoch: 0 [batch #16900, batch_size 1, seq length 2500]\tLoss: 5.705126\n",
      "16925it [32:14,  8.75it/s]Train epoch: 0 [batch #16925, batch_size 1, seq length 2500]\tLoss: 5.988860\n",
      "16950it [32:17,  8.77it/s]Train epoch: 0 [batch #16950, batch_size 1, seq length 2500]\tLoss: 5.799961\n",
      "16975it [32:20,  8.73it/s]Train epoch: 0 [batch #16975, batch_size 1, seq length 2500]\tLoss: 5.928667\n",
      "17000it [32:23,  8.77it/s]Train epoch: 0 [batch #17000, batch_size 1, seq length 2500]\tLoss: 5.837202\n",
      "17025it [32:26,  8.76it/s]Train epoch: 0 [batch #17025, batch_size 1, seq length 2500]\tLoss: 5.771653\n",
      "17050it [32:29,  8.77it/s]Train epoch: 0 [batch #17050, batch_size 1, seq length 2500]\tLoss: 5.946654\n",
      "17075it [32:31,  8.76it/s]Train epoch: 0 [batch #17075, batch_size 1, seq length 2500]\tLoss: 5.644370\n",
      "17100it [32:34,  8.77it/s]Train epoch: 0 [batch #17100, batch_size 1, seq length 2500]\tLoss: 5.658774\n",
      "17125it [32:37,  8.71it/s]Train epoch: 0 [batch #17125, batch_size 1, seq length 2500]\tLoss: 5.724570\n",
      "17150it [32:40,  8.73it/s]Train epoch: 0 [batch #17150, batch_size 1, seq length 2500]\tLoss: 5.540570\n",
      "17175it [32:43,  8.73it/s]Train epoch: 0 [batch #17175, batch_size 1, seq length 2500]\tLoss: 5.822356\n",
      "17200it [32:46,  8.77it/s]Train epoch: 0 [batch #17200, batch_size 1, seq length 2500]\tLoss: 5.969303\n",
      "17225it [32:49,  8.71it/s]Train epoch: 0 [batch #17225, batch_size 1, seq length 2500]\tLoss: 6.028260\n",
      "17250it [32:51,  8.75it/s]Train epoch: 0 [batch #17250, batch_size 1, seq length 2500]\tLoss: 5.877049\n",
      "17275it [32:54,  8.76it/s]Train epoch: 0 [batch #17275, batch_size 1, seq length 2500]\tLoss: 5.775718\n",
      "17300it [32:57,  8.72it/s]Train epoch: 0 [batch #17300, batch_size 1, seq length 2500]\tLoss: 5.859212\n",
      "17325it [33:00,  8.75it/s]Train epoch: 0 [batch #17325, batch_size 1, seq length 2500]\tLoss: 5.554418\n",
      "17350it [33:03,  8.78it/s]Train epoch: 0 [batch #17350, batch_size 1, seq length 2500]\tLoss: 5.618553\n",
      "17375it [33:06,  8.69it/s]Train epoch: 0 [batch #17375, batch_size 1, seq length 2500]\tLoss: 5.734156\n",
      "17400it [33:09,  8.77it/s]Train epoch: 0 [batch #17400, batch_size 1, seq length 2500]\tLoss: 5.774199\n",
      "17425it [33:11,  8.76it/s]Train epoch: 0 [batch #17425, batch_size 1, seq length 2500]\tLoss: 5.874698\n",
      "17450it [33:14,  8.73it/s]Train epoch: 0 [batch #17450, batch_size 1, seq length 2500]\tLoss: 5.597529\n",
      "17475it [33:17,  8.77it/s]Train epoch: 0 [batch #17475, batch_size 1, seq length 2500]\tLoss: 5.742460\n",
      "17500it [33:20,  8.75it/s]Train epoch: 0 [batch #17500, batch_size 1, seq length 2500]\tLoss: 5.915308\n",
      "17525it [33:23,  8.72it/s]Train epoch: 0 [batch #17525, batch_size 1, seq length 2500]\tLoss: 5.785347\n",
      "17550it [33:26,  8.77it/s]Train epoch: 0 [batch #17550, batch_size 1, seq length 2500]\tLoss: 5.957414\n",
      "17575it [33:29,  8.75it/s]Train epoch: 0 [batch #17575, batch_size 1, seq length 2500]\tLoss: 5.783412\n",
      "17600it [33:32,  8.76it/s]Train epoch: 0 [batch #17600, batch_size 1, seq length 2500]\tLoss: 5.915016\n",
      "17625it [33:34,  8.75it/s]Train epoch: 0 [batch #17625, batch_size 1, seq length 2500]\tLoss: 5.986354\n",
      "17650it [33:37,  8.76it/s]Train epoch: 0 [batch #17650, batch_size 1, seq length 2500]\tLoss: 5.639845\n",
      "17675it [33:40,  8.75it/s]Train epoch: 0 [batch #17675, batch_size 1, seq length 2500]\tLoss: 5.804541\n",
      "17700it [33:43,  8.68it/s]Train epoch: 0 [batch #17700, batch_size 1, seq length 2500]\tLoss: 5.836557\n",
      "17725it [33:46,  8.74it/s]Train epoch: 0 [batch #17725, batch_size 1, seq length 2500]\tLoss: 5.842313\n",
      "17750it [33:49,  8.75it/s]Train epoch: 0 [batch #17750, batch_size 1, seq length 2500]\tLoss: 6.008486\n",
      "17775it [33:52,  8.77it/s]Train epoch: 0 [batch #17775, batch_size 1, seq length 2500]\tLoss: 5.895636\n",
      "17800it [33:54,  8.72it/s]Train epoch: 0 [batch #17800, batch_size 1, seq length 2500]\tLoss: 5.915909\n",
      "17825it [33:57,  8.78it/s]Train epoch: 0 [batch #17825, batch_size 1, seq length 2500]\tLoss: 5.957783\n",
      "17850it [34:00,  8.76it/s]Train epoch: 0 [batch #17850, batch_size 1, seq length 2500]\tLoss: 5.690449\n",
      "17875it [34:03,  8.74it/s]Train epoch: 0 [batch #17875, batch_size 1, seq length 2500]\tLoss: 5.808800\n",
      "17900it [34:06,  8.74it/s]Train epoch: 0 [batch #17900, batch_size 1, seq length 2500]\tLoss: 5.993750\n",
      "17925it [34:09,  8.76it/s]Train epoch: 0 [batch #17925, batch_size 1, seq length 2500]\tLoss: 5.717242\n",
      "17950it [34:12,  8.77it/s]Train epoch: 0 [batch #17950, batch_size 1, seq length 2500]\tLoss: 5.659852\n",
      "17975it [34:14,  8.76it/s]Train epoch: 0 [batch #17975, batch_size 1, seq length 2500]\tLoss: 5.862274\n",
      "18000it [34:17,  8.57it/s]Train epoch: 0 [batch #18000, batch_size 1, seq length 2500]\tLoss: 5.779345\n",
      "18025it [34:20,  8.77it/s]Train epoch: 0 [batch #18025, batch_size 1, seq length 2500]\tLoss: 5.861539\n",
      "18050it [34:23,  8.77it/s]Train epoch: 0 [batch #18050, batch_size 1, seq length 2500]\tLoss: 5.896866\n",
      "18075it [34:26,  8.77it/s]Train epoch: 0 [batch #18075, batch_size 1, seq length 2500]\tLoss: 5.635686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18100it [34:29,  8.75it/s]Train epoch: 0 [batch #18100, batch_size 1, seq length 2500]\tLoss: 5.796333\n",
      "18125it [34:32,  8.76it/s]Train epoch: 0 [batch #18125, batch_size 1, seq length 2500]\tLoss: 5.659412\n",
      "18150it [34:34,  8.68it/s]Train epoch: 0 [batch #18150, batch_size 1, seq length 2500]\tLoss: 5.768170\n",
      "18175it [34:37,  8.77it/s]Train epoch: 0 [batch #18175, batch_size 1, seq length 2500]\tLoss: 5.942307\n",
      "18200it [34:40,  8.60it/s]Train epoch: 0 [batch #18200, batch_size 1, seq length 2500]\tLoss: 6.032034\n",
      "18225it [34:43,  8.79it/s]Train epoch: 0 [batch #18225, batch_size 1, seq length 2500]\tLoss: 5.902918\n",
      "18250it [34:46,  8.62it/s]Train epoch: 0 [batch #18250, batch_size 1, seq length 2500]\tLoss: 6.013006\n",
      "18275it [34:49,  8.77it/s]Train epoch: 0 [batch #18275, batch_size 1, seq length 2500]\tLoss: 5.762630\n",
      "18300it [34:52,  8.75it/s]Train epoch: 0 [batch #18300, batch_size 1, seq length 2500]\tLoss: 5.746568\n",
      "18325it [34:54,  8.76it/s]Train epoch: 0 [batch #18325, batch_size 1, seq length 2500]\tLoss: 5.525726\n",
      "18350it [34:57,  8.75it/s]Train epoch: 0 [batch #18350, batch_size 1, seq length 2500]\tLoss: 5.665935\n",
      "18375it [35:00,  8.74it/s]Train epoch: 0 [batch #18375, batch_size 1, seq length 2500]\tLoss: 5.926328\n",
      "18400it [35:03,  8.73it/s]Train epoch: 0 [batch #18400, batch_size 1, seq length 2500]\tLoss: 5.635548\n",
      "18425it [35:06,  8.73it/s]Train epoch: 0 [batch #18425, batch_size 1, seq length 2500]\tLoss: 5.763013\n",
      "18450it [35:09,  8.75it/s]Train epoch: 0 [batch #18450, batch_size 1, seq length 2500]\tLoss: 5.502182\n",
      "18475it [35:12,  8.76it/s]Train epoch: 0 [batch #18475, batch_size 1, seq length 2500]\tLoss: 5.705856\n",
      "18500it [35:14,  8.77it/s]Train epoch: 0 [batch #18500, batch_size 1, seq length 2500]\tLoss: 5.541956\n",
      "18525it [35:17,  8.76it/s]Train epoch: 0 [batch #18525, batch_size 1, seq length 2500]\tLoss: 5.792559\n",
      "18550it [35:20,  8.74it/s]Train epoch: 0 [batch #18550, batch_size 1, seq length 2500]\tLoss: 5.599879\n",
      "18575it [35:23,  8.77it/s]Train epoch: 0 [batch #18575, batch_size 1, seq length 2500]\tLoss: 5.920293\n",
      "18600it [35:26,  8.76it/s]Train epoch: 0 [batch #18600, batch_size 1, seq length 2500]\tLoss: 5.843735\n",
      "18625it [35:29,  8.77it/s]Train epoch: 0 [batch #18625, batch_size 1, seq length 2500]\tLoss: 5.735076\n",
      "18650it [35:32,  8.77it/s]Train epoch: 0 [batch #18650, batch_size 1, seq length 2500]\tLoss: 5.668291\n",
      "18675it [35:34,  8.73it/s]Train epoch: 0 [batch #18675, batch_size 1, seq length 2500]\tLoss: 5.489006\n",
      "18700it [35:37,  8.74it/s]Train epoch: 0 [batch #18700, batch_size 1, seq length 2500]\tLoss: 5.485971\n",
      "18725it [35:40,  8.76it/s]Train epoch: 0 [batch #18725, batch_size 1, seq length 2500]\tLoss: 5.720587\n",
      "18750it [35:43,  8.77it/s]Train epoch: 0 [batch #18750, batch_size 1, seq length 2500]\tLoss: 5.354500\n",
      "18775it [35:46,  8.75it/s]Train epoch: 0 [batch #18775, batch_size 1, seq length 2500]\tLoss: 5.677625\n",
      "18800it [35:49,  8.77it/s]Train epoch: 0 [batch #18800, batch_size 1, seq length 2500]\tLoss: 5.822339\n",
      "18825it [35:52,  8.76it/s]Train epoch: 0 [batch #18825, batch_size 1, seq length 2500]\tLoss: 5.732552\n",
      "18850it [35:54,  8.75it/s]Train epoch: 0 [batch #18850, batch_size 1, seq length 2500]\tLoss: 5.827292\n",
      "18875it [35:57,  8.76it/s]Train epoch: 0 [batch #18875, batch_size 1, seq length 2500]\tLoss: 5.784137\n",
      "18900it [36:00,  8.76it/s]Train epoch: 0 [batch #18900, batch_size 1, seq length 2500]\tLoss: 5.781301\n",
      "18925it [36:03,  8.75it/s]Train epoch: 0 [batch #18925, batch_size 1, seq length 2500]\tLoss: 5.788931\n",
      "18950it [36:06,  8.76it/s]Train epoch: 0 [batch #18950, batch_size 1, seq length 2500]\tLoss: 5.774993\n",
      "18975it [36:09,  8.57it/s]Train epoch: 0 [batch #18975, batch_size 1, seq length 2500]\tLoss: 5.709610\n",
      "19000it [36:12,  8.67it/s]Train epoch: 0 [batch #19000, batch_size 1, seq length 2500]\tLoss: 5.681745\n",
      "19025it [36:14,  8.74it/s]Train epoch: 0 [batch #19025, batch_size 1, seq length 2500]\tLoss: 5.688005\n",
      "19050it [36:17,  8.72it/s]Train epoch: 0 [batch #19050, batch_size 1, seq length 2500]\tLoss: 5.699042\n",
      "19075it [36:20,  8.76it/s]Train epoch: 0 [batch #19075, batch_size 1, seq length 2500]\tLoss: 5.849373\n",
      "19100it [36:23,  8.73it/s]Train epoch: 0 [batch #19100, batch_size 1, seq length 2500]\tLoss: 5.754204\n",
      "19125it [36:26,  8.73it/s]Train epoch: 0 [batch #19125, batch_size 1, seq length 2500]\tLoss: 5.944354\n",
      "19150it [36:29,  8.77it/s]Train epoch: 0 [batch #19150, batch_size 1, seq length 2500]\tLoss: 5.844013\n",
      "19175it [36:32,  8.76it/s]Train epoch: 0 [batch #19175, batch_size 1, seq length 2500]\tLoss: 5.869808\n",
      "19200it [36:35,  8.74it/s]Train epoch: 0 [batch #19200, batch_size 1, seq length 2500]\tLoss: 5.849529\n",
      "19225it [36:37,  8.76it/s]Train epoch: 0 [batch #19225, batch_size 1, seq length 2500]\tLoss: 5.773941\n",
      "19250it [36:40,  8.62it/s]Train epoch: 0 [batch #19250, batch_size 1, seq length 2500]\tLoss: 5.795442\n",
      "19275it [36:43,  8.77it/s]Train epoch: 0 [batch #19275, batch_size 1, seq length 2500]\tLoss: 5.652173\n",
      "19300it [36:46,  8.69it/s]Train epoch: 0 [batch #19300, batch_size 1, seq length 2500]\tLoss: 5.816920\n",
      "19325it [36:49,  8.77it/s]Train epoch: 0 [batch #19325, batch_size 1, seq length 2500]\tLoss: 5.830767\n",
      "19350it [36:52,  8.77it/s]Train epoch: 0 [batch #19350, batch_size 1, seq length 2500]\tLoss: 5.603305\n",
      "19375it [36:55,  8.76it/s]Train epoch: 0 [batch #19375, batch_size 1, seq length 2500]\tLoss: 5.579236\n",
      "19400it [36:57,  8.76it/s]Train epoch: 0 [batch #19400, batch_size 1, seq length 2500]\tLoss: 5.858273\n",
      "19425it [37:00,  8.77it/s]Train epoch: 0 [batch #19425, batch_size 1, seq length 2500]\tLoss: 5.755242\n",
      "19450it [37:03,  8.77it/s]Train epoch: 0 [batch #19450, batch_size 1, seq length 2500]\tLoss: 5.596497\n",
      "19475it [37:06,  8.76it/s]Train epoch: 0 [batch #19475, batch_size 1, seq length 2500]\tLoss: 5.722987\n",
      "19500it [37:09,  8.77it/s]Train epoch: 0 [batch #19500, batch_size 1, seq length 2500]\tLoss: 5.592046\n",
      "19525it [37:12,  8.78it/s]Train epoch: 0 [batch #19525, batch_size 1, seq length 2500]\tLoss: 5.952672\n",
      "19550it [37:15,  8.75it/s]Train epoch: 0 [batch #19550, batch_size 1, seq length 2500]\tLoss: 5.772596\n",
      "19575it [37:17,  8.74it/s]Train epoch: 0 [batch #19575, batch_size 1, seq length 2500]\tLoss: 5.832231\n",
      "19600it [37:20,  8.64it/s]Train epoch: 0 [batch #19600, batch_size 1, seq length 2500]\tLoss: 5.645825\n",
      "19625it [37:23,  8.75it/s]Train epoch: 0 [batch #19625, batch_size 1, seq length 2500]\tLoss: 5.774351\n",
      "19650it [37:26,  8.77it/s]Train epoch: 0 [batch #19650, batch_size 1, seq length 2500]\tLoss: 5.782050\n",
      "19675it [37:29,  8.77it/s]Train epoch: 0 [batch #19675, batch_size 1, seq length 2500]\tLoss: 5.703812\n",
      "19700it [37:32,  8.78it/s]Train epoch: 0 [batch #19700, batch_size 1, seq length 2500]\tLoss: 6.023495\n",
      "19725it [37:35,  8.50it/s]Train epoch: 0 [batch #19725, batch_size 1, seq length 2500]\tLoss: 5.852436\n",
      "19750it [37:37,  8.78it/s]Train epoch: 0 [batch #19750, batch_size 1, seq length 2500]\tLoss: 5.756951\n",
      "19775it [37:40,  8.72it/s]Train epoch: 0 [batch #19775, batch_size 1, seq length 2500]\tLoss: 5.777144\n",
      "19800it [37:43,  8.75it/s]Train epoch: 0 [batch #19800, batch_size 1, seq length 2500]\tLoss: 5.728333\n",
      "19825it [37:46,  8.67it/s]Train epoch: 0 [batch #19825, batch_size 1, seq length 2500]\tLoss: 5.845973\n",
      "19850it [37:49,  8.74it/s]Train epoch: 0 [batch #19850, batch_size 1, seq length 2500]\tLoss: 5.767336\n",
      "19875it [37:52,  8.77it/s]Train epoch: 0 [batch #19875, batch_size 1, seq length 2500]\tLoss: 5.820879\n",
      "19900it [37:55,  8.78it/s]Train epoch: 0 [batch #19900, batch_size 1, seq length 2500]\tLoss: 5.644286\n",
      "19925it [37:57,  8.73it/s]Train epoch: 0 [batch #19925, batch_size 1, seq length 2500]\tLoss: 5.657752\n",
      "19950it [38:00,  8.68it/s]Train epoch: 0 [batch #19950, batch_size 1, seq length 2500]\tLoss: 5.659697\n",
      "19975it [38:03,  8.78it/s]Train epoch: 0 [batch #19975, batch_size 1, seq length 2500]\tLoss: 5.846840\n",
      "20000it [38:06,  8.74it/s]Train epoch: 0 [batch #20000, batch_size 1, seq length 2500]\tLoss: 5.507782\n",
      "20025it [38:09,  8.78it/s]Train epoch: 0 [batch #20025, batch_size 1, seq length 2500]\tLoss: 5.713506\n",
      "20050it [38:12,  8.66it/s]Train epoch: 0 [batch #20050, batch_size 1, seq length 2500]\tLoss: 5.740765\n",
      "20075it [38:15,  8.78it/s]Train epoch: 0 [batch #20075, batch_size 1, seq length 2500]\tLoss: 5.831067\n",
      "20100it [38:17,  8.74it/s]Train epoch: 0 [batch #20100, batch_size 1, seq length 2500]\tLoss: 6.008890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20125it [38:20,  8.77it/s]Train epoch: 0 [batch #20125, batch_size 1, seq length 2500]\tLoss: 5.481490\n",
      "20150it [38:23,  8.77it/s]Train epoch: 0 [batch #20150, batch_size 1, seq length 2500]\tLoss: 5.839852\n",
      "20175it [38:26,  8.75it/s]Train epoch: 0 [batch #20175, batch_size 1, seq length 2500]\tLoss: 5.832273\n",
      "20200it [38:29,  8.72it/s]Train epoch: 0 [batch #20200, batch_size 1, seq length 2500]\tLoss: 5.940968\n",
      "20225it [38:32,  8.76it/s]Train epoch: 0 [batch #20225, batch_size 1, seq length 2500]\tLoss: 5.432546\n",
      "20250it [38:35,  8.77it/s]Train epoch: 0 [batch #20250, batch_size 1, seq length 2500]\tLoss: 5.835339\n",
      "20275it [38:37,  8.69it/s]Train epoch: 0 [batch #20275, batch_size 1, seq length 2500]\tLoss: 5.487961\n",
      "20300it [38:40,  8.77it/s]Train epoch: 0 [batch #20300, batch_size 1, seq length 2500]\tLoss: 5.677973\n",
      "20325it [38:43,  8.78it/s]Train epoch: 0 [batch #20325, batch_size 1, seq length 2500]\tLoss: 5.608487\n",
      "20350it [38:46,  8.77it/s]Train epoch: 0 [batch #20350, batch_size 1, seq length 2500]\tLoss: 5.798627\n",
      "20375it [38:49,  8.75it/s]Train epoch: 0 [batch #20375, batch_size 1, seq length 2500]\tLoss: 5.596178\n",
      "20400it [38:52,  8.72it/s]Train epoch: 0 [batch #20400, batch_size 1, seq length 2500]\tLoss: 5.512253\n",
      "20425it [38:55,  8.75it/s]Train epoch: 0 [batch #20425, batch_size 1, seq length 2500]\tLoss: 5.734486\n",
      "20450it [38:57,  8.77it/s]Train epoch: 0 [batch #20450, batch_size 1, seq length 2500]\tLoss: 5.736453\n",
      "20475it [39:00,  8.75it/s]Train epoch: 0 [batch #20475, batch_size 1, seq length 2500]\tLoss: 5.761859\n",
      "20500it [39:03,  8.77it/s]Train epoch: 0 [batch #20500, batch_size 1, seq length 2500]\tLoss: 5.921013\n",
      "20525it [39:06,  8.76it/s]Train epoch: 0 [batch #20525, batch_size 1, seq length 2500]\tLoss: 5.730011\n",
      "20550it [39:09,  8.77it/s]Train epoch: 0 [batch #20550, batch_size 1, seq length 2500]\tLoss: 5.654697\n",
      "20575it [39:12,  8.78it/s]Train epoch: 0 [batch #20575, batch_size 1, seq length 2500]\tLoss: 5.658901\n",
      "20600it [39:15,  8.69it/s]Train epoch: 0 [batch #20600, batch_size 1, seq length 2500]\tLoss: 5.676003\n",
      "20625it [39:17,  8.76it/s]Train epoch: 0 [batch #20625, batch_size 1, seq length 2500]\tLoss: 5.684848\n",
      "20650it [39:20,  8.75it/s]Train epoch: 0 [batch #20650, batch_size 1, seq length 2500]\tLoss: 5.996693\n",
      "20675it [39:23,  8.78it/s]Train epoch: 0 [batch #20675, batch_size 1, seq length 2500]\tLoss: 6.034253\n",
      "20700it [39:26,  8.74it/s]Train epoch: 0 [batch #20700, batch_size 1, seq length 2500]\tLoss: 5.871434\n",
      "20725it [39:29,  8.74it/s]Train epoch: 0 [batch #20725, batch_size 1, seq length 2500]\tLoss: 5.730227\n",
      "20750it [39:32,  8.65it/s]Train epoch: 0 [batch #20750, batch_size 1, seq length 2500]\tLoss: 5.733037\n",
      "20775it [39:35,  8.77it/s]Train epoch: 0 [batch #20775, batch_size 1, seq length 2500]\tLoss: 5.692018\n",
      "20800it [39:37,  8.78it/s]Train epoch: 0 [batch #20800, batch_size 1, seq length 2500]\tLoss: 5.740298\n",
      "20825it [39:40,  8.74it/s]Train epoch: 0 [batch #20825, batch_size 1, seq length 2500]\tLoss: 5.725911\n",
      "20850it [39:43,  8.77it/s]Train epoch: 0 [batch #20850, batch_size 1, seq length 2500]\tLoss: 5.775726\n",
      "20875it [39:46,  8.76it/s]Train epoch: 0 [batch #20875, batch_size 1, seq length 2500]\tLoss: 5.581167\n",
      "20900it [39:49,  8.77it/s]Train epoch: 0 [batch #20900, batch_size 1, seq length 2500]\tLoss: 5.765360\n",
      "20925it [39:52,  8.77it/s]Train epoch: 0 [batch #20925, batch_size 1, seq length 2500]\tLoss: 5.808743\n",
      "20950it [39:55,  8.77it/s]Train epoch: 0 [batch #20950, batch_size 1, seq length 2500]\tLoss: 5.602527\n",
      "20975it [39:57,  8.77it/s]Train epoch: 0 [batch #20975, batch_size 1, seq length 2500]\tLoss: 5.567842\n",
      "21000it [40:00,  8.79it/s]Train epoch: 0 [batch #21000, batch_size 1, seq length 2500]\tLoss: 5.563861\n",
      "21025it [40:03,  8.77it/s]Train epoch: 0 [batch #21025, batch_size 1, seq length 2500]\tLoss: 5.652692\n",
      "21050it [40:06,  8.74it/s]Train epoch: 0 [batch #21050, batch_size 1, seq length 2500]\tLoss: 5.705517\n",
      "21075it [40:09,  8.78it/s]Train epoch: 0 [batch #21075, batch_size 1, seq length 2500]\tLoss: 5.493448\n",
      "21100it [40:12,  8.78it/s]Train epoch: 0 [batch #21100, batch_size 1, seq length 2500]\tLoss: 5.507897\n",
      "21125it [40:15,  8.78it/s]Train epoch: 0 [batch #21125, batch_size 1, seq length 2500]\tLoss: 5.514523\n",
      "21150it [40:17,  8.72it/s]Train epoch: 0 [batch #21150, batch_size 1, seq length 2500]\tLoss: 5.760505\n",
      "21175it [40:20,  8.78it/s]Train epoch: 0 [batch #21175, batch_size 1, seq length 2500]\tLoss: 5.610242\n",
      "21200it [40:23,  8.75it/s]Train epoch: 0 [batch #21200, batch_size 1, seq length 2500]\tLoss: 5.969502\n",
      "21225it [40:26,  8.77it/s]Train epoch: 0 [batch #21225, batch_size 1, seq length 2500]\tLoss: 5.596076\n",
      "21250it [40:29,  8.76it/s]Train epoch: 0 [batch #21250, batch_size 1, seq length 2500]\tLoss: 5.750353\n",
      "21275it [40:32,  8.74it/s]Train epoch: 0 [batch #21275, batch_size 1, seq length 2500]\tLoss: 5.712401\n",
      "21300it [40:35,  8.77it/s]Train epoch: 0 [batch #21300, batch_size 1, seq length 2500]\tLoss: 5.754044\n",
      "21325it [40:37,  8.76it/s]Train epoch: 0 [batch #21325, batch_size 1, seq length 2500]\tLoss: 5.811933\n",
      "21350it [40:40,  8.72it/s]Train epoch: 0 [batch #21350, batch_size 1, seq length 2500]\tLoss: 5.728432\n",
      "21375it [40:43,  8.69it/s]Train epoch: 0 [batch #21375, batch_size 1, seq length 2500]\tLoss: 5.723177\n",
      "21400it [40:46,  8.76it/s]Train epoch: 0 [batch #21400, batch_size 1, seq length 2500]\tLoss: 5.832519\n",
      "21425it [40:49,  8.77it/s]Train epoch: 0 [batch #21425, batch_size 1, seq length 2500]\tLoss: 5.722445\n",
      "21450it [40:52,  8.77it/s]Train epoch: 0 [batch #21450, batch_size 1, seq length 2500]\tLoss: 5.752949\n",
      "21475it [40:55,  8.78it/s]Train epoch: 0 [batch #21475, batch_size 1, seq length 2500]\tLoss: 5.737743\n",
      "21500it [40:57,  8.76it/s]Train epoch: 0 [batch #21500, batch_size 1, seq length 2500]\tLoss: 5.583368\n",
      "21525it [41:00,  8.71it/s]Train epoch: 0 [batch #21525, batch_size 1, seq length 2500]\tLoss: 5.781429\n",
      "21550it [41:03,  8.75it/s]Train epoch: 0 [batch #21550, batch_size 1, seq length 2500]\tLoss: 5.657248\n",
      "21575it [41:06,  8.73it/s]Train epoch: 0 [batch #21575, batch_size 1, seq length 2500]\tLoss: 5.561398\n",
      "21600it [41:09,  8.74it/s]Train epoch: 0 [batch #21600, batch_size 1, seq length 2500]\tLoss: 5.710414\n",
      "21625it [41:12,  8.67it/s]Train epoch: 0 [batch #21625, batch_size 1, seq length 2500]\tLoss: 5.690244\n",
      "21650it [41:15,  8.77it/s]Train epoch: 0 [batch #21650, batch_size 1, seq length 2500]\tLoss: 5.755400\n",
      "21675it [41:17,  8.77it/s]Train epoch: 0 [batch #21675, batch_size 1, seq length 2500]\tLoss: 5.793378\n",
      "21700it [41:20,  8.77it/s]Train epoch: 0 [batch #21700, batch_size 1, seq length 2500]\tLoss: 5.781140\n",
      "21725it [41:23,  8.78it/s]Train epoch: 0 [batch #21725, batch_size 1, seq length 2500]\tLoss: 5.528344\n",
      "21750it [41:26,  8.74it/s]Train epoch: 0 [batch #21750, batch_size 1, seq length 2500]\tLoss: 5.775474\n",
      "21775it [41:29,  8.75it/s]Train epoch: 0 [batch #21775, batch_size 1, seq length 2500]\tLoss: 5.588075\n",
      "21800it [41:32,  8.77it/s]Train epoch: 0 [batch #21800, batch_size 1, seq length 2500]\tLoss: 5.543111\n",
      "21825it [41:34,  8.71it/s]Train epoch: 0 [batch #21825, batch_size 1, seq length 2500]\tLoss: 5.779019\n",
      "21850it [41:37,  8.77it/s]Train epoch: 0 [batch #21850, batch_size 1, seq length 2500]\tLoss: 5.474489\n",
      "21875it [41:40,  8.78it/s]Train epoch: 0 [batch #21875, batch_size 1, seq length 2500]\tLoss: 5.523818\n",
      "21900it [41:43,  8.59it/s]Train epoch: 0 [batch #21900, batch_size 1, seq length 2500]\tLoss: 5.741480\n",
      "21925it [41:46,  8.76it/s]Train epoch: 0 [batch #21925, batch_size 1, seq length 2500]\tLoss: 5.475850\n",
      "21950it [41:49,  8.78it/s]Train epoch: 0 [batch #21950, batch_size 1, seq length 2500]\tLoss: 5.639772\n",
      "21975it [41:52,  8.77it/s]Train epoch: 0 [batch #21975, batch_size 1, seq length 2500]\tLoss: 5.805788\n",
      "22000it [41:54,  8.77it/s]Train epoch: 0 [batch #22000, batch_size 1, seq length 2500]\tLoss: 5.682368\n",
      "22025it [41:57,  8.76it/s]Train epoch: 0 [batch #22025, batch_size 1, seq length 2500]\tLoss: 5.607367\n",
      "22050it [42:00,  8.75it/s]Train epoch: 0 [batch #22050, batch_size 1, seq length 2500]\tLoss: 5.515730\n",
      "22075it [42:03,  8.75it/s]Train epoch: 0 [batch #22075, batch_size 1, seq length 2500]\tLoss: 5.486689\n",
      "22100it [42:06,  8.76it/s]Train epoch: 0 [batch #22100, batch_size 1, seq length 2500]\tLoss: 5.589032\n",
      "22125it [42:09,  8.66it/s]Train epoch: 0 [batch #22125, batch_size 1, seq length 2500]\tLoss: 5.683260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22150it [42:12,  8.76it/s]Train epoch: 0 [batch #22150, batch_size 1, seq length 2500]\tLoss: 5.709766\n",
      "22175it [42:14,  8.72it/s]Train epoch: 0 [batch #22175, batch_size 1, seq length 2500]\tLoss: 5.658451\n",
      "22200it [42:17,  8.77it/s]Train epoch: 0 [batch #22200, batch_size 1, seq length 2500]\tLoss: 5.703195\n",
      "22225it [42:20,  8.77it/s]Train epoch: 0 [batch #22225, batch_size 1, seq length 2500]\tLoss: 5.618521\n",
      "22250it [42:23,  8.73it/s]Train epoch: 0 [batch #22250, batch_size 1, seq length 2500]\tLoss: 5.636790\n",
      "22275it [42:26,  8.78it/s]Train epoch: 0 [batch #22275, batch_size 1, seq length 2500]\tLoss: 5.552438\n",
      "22300it [42:29,  8.77it/s]Train epoch: 0 [batch #22300, batch_size 1, seq length 2500]\tLoss: 5.630172\n",
      "22325it [42:32,  8.78it/s]Train epoch: 0 [batch #22325, batch_size 1, seq length 2500]\tLoss: 5.541324\n",
      "22350it [42:34,  8.77it/s]Train epoch: 0 [batch #22350, batch_size 1, seq length 2500]\tLoss: 5.587335\n",
      "22375it [42:37,  8.78it/s]Train epoch: 0 [batch #22375, batch_size 1, seq length 2500]\tLoss: 5.748216\n",
      "22400it [42:40,  8.78it/s]Train epoch: 0 [batch #22400, batch_size 1, seq length 2500]\tLoss: 5.752198\n",
      "22425it [42:43,  8.78it/s]Train epoch: 0 [batch #22425, batch_size 1, seq length 2500]\tLoss: 5.517276\n",
      "22450it [42:46,  8.73it/s]Train epoch: 0 [batch #22450, batch_size 1, seq length 2500]\tLoss: 5.468771\n",
      "22475it [42:49,  8.73it/s]Train epoch: 0 [batch #22475, batch_size 1, seq length 2500]\tLoss: 5.635511\n",
      "22500it [42:52,  8.77it/s]Train epoch: 0 [batch #22500, batch_size 1, seq length 2500]\tLoss: 5.542821\n",
      "22525it [42:54,  8.78it/s]Train epoch: 0 [batch #22525, batch_size 1, seq length 2500]\tLoss: 5.724439\n",
      "22550it [42:57,  8.77it/s]Train epoch: 0 [batch #22550, batch_size 1, seq length 2500]\tLoss: 5.519556\n",
      "22575it [43:00,  8.77it/s]Train epoch: 0 [batch #22575, batch_size 1, seq length 2500]\tLoss: 5.603776\n",
      "22600it [43:03,  8.78it/s]Train epoch: 0 [batch #22600, batch_size 1, seq length 2500]\tLoss: 5.529195\n",
      "22625it [43:06,  8.73it/s]Train epoch: 0 [batch #22625, batch_size 1, seq length 2500]\tLoss: 5.731255\n",
      "22650it [43:09,  8.78it/s]Train epoch: 0 [batch #22650, batch_size 1, seq length 2500]\tLoss: 5.731069\n",
      "22675it [43:12,  8.74it/s]Train epoch: 0 [batch #22675, batch_size 1, seq length 2500]\tLoss: 5.843773\n",
      "22700it [43:14,  8.76it/s]Train epoch: 0 [batch #22700, batch_size 1, seq length 2500]\tLoss: 5.564753\n",
      "22725it [43:17,  8.77it/s]Train epoch: 0 [batch #22725, batch_size 1, seq length 2500]\tLoss: 5.662214\n",
      "22750it [43:20,  8.79it/s]Train epoch: 0 [batch #22750, batch_size 1, seq length 2500]\tLoss: 5.697048\n",
      "22775it [43:23,  8.77it/s]Train epoch: 0 [batch #22775, batch_size 1, seq length 2500]\tLoss: 5.548276\n",
      "22800it [43:26,  8.75it/s]Train epoch: 0 [batch #22800, batch_size 1, seq length 2500]\tLoss: 5.605811\n",
      "22825it [43:29,  8.69it/s]Train epoch: 0 [batch #22825, batch_size 1, seq length 2500]\tLoss: 5.743610\n",
      "22850it [43:32,  8.77it/s]Train epoch: 0 [batch #22850, batch_size 1, seq length 2500]\tLoss: 5.407516\n",
      "22875it [43:34,  8.74it/s]Train epoch: 0 [batch #22875, batch_size 1, seq length 2500]\tLoss: 5.730077\n",
      "22900it [43:37,  8.72it/s]Train epoch: 0 [batch #22900, batch_size 1, seq length 2500]\tLoss: 5.620429\n",
      "22925it [43:40,  8.78it/s]Train epoch: 0 [batch #22925, batch_size 1, seq length 2500]\tLoss: 5.704455\n",
      "22950it [43:43,  8.76it/s]Train epoch: 0 [batch #22950, batch_size 1, seq length 2500]\tLoss: 5.895732\n",
      "22975it [43:46,  8.74it/s]Train epoch: 0 [batch #22975, batch_size 1, seq length 2500]\tLoss: 5.634425\n",
      "23000it [43:49,  8.75it/s]Train epoch: 0 [batch #23000, batch_size 1, seq length 2500]\tLoss: 5.663729\n",
      "23025it [43:52,  8.74it/s]Train epoch: 0 [batch #23025, batch_size 1, seq length 2500]\tLoss: 5.766576\n",
      "23050it [43:54,  8.78it/s]Train epoch: 0 [batch #23050, batch_size 1, seq length 2500]\tLoss: 5.563370\n",
      "23075it [43:57,  8.78it/s]Train epoch: 0 [batch #23075, batch_size 1, seq length 2500]\tLoss: 5.575653\n",
      "23100it [44:00,  8.77it/s]Train epoch: 0 [batch #23100, batch_size 1, seq length 2500]\tLoss: 5.611295\n",
      "23125it [44:03,  8.77it/s]Train epoch: 0 [batch #23125, batch_size 1, seq length 2500]\tLoss: 5.690514\n",
      "23150it [44:06,  8.75it/s]Train epoch: 0 [batch #23150, batch_size 1, seq length 2500]\tLoss: 5.646620\n",
      "23175it [44:09,  8.74it/s]Train epoch: 0 [batch #23175, batch_size 1, seq length 2500]\tLoss: 5.564144\n",
      "23200it [44:12,  8.74it/s]Train epoch: 0 [batch #23200, batch_size 1, seq length 2500]\tLoss: 5.448857\n",
      "23225it [44:14,  8.74it/s]Train epoch: 0 [batch #23225, batch_size 1, seq length 2500]\tLoss: 5.853595\n",
      "23250it [44:17,  8.78it/s]Train epoch: 0 [batch #23250, batch_size 1, seq length 2500]\tLoss: 5.871723\n",
      "23275it [44:20,  8.69it/s]Train epoch: 0 [batch #23275, batch_size 1, seq length 2500]\tLoss: 5.624609\n",
      "23300it [44:23,  8.75it/s]Train epoch: 0 [batch #23300, batch_size 1, seq length 2500]\tLoss: 5.538310\n",
      "23325it [44:26,  8.68it/s]Train epoch: 0 [batch #23325, batch_size 1, seq length 2500]\tLoss: 5.633471\n",
      "23350it [44:29,  8.78it/s]Train epoch: 0 [batch #23350, batch_size 1, seq length 2500]\tLoss: 5.806747\n",
      "23375it [44:32,  8.77it/s]Train epoch: 0 [batch #23375, batch_size 1, seq length 2500]\tLoss: 5.702154\n",
      "23400it [44:34,  8.78it/s]Train epoch: 0 [batch #23400, batch_size 1, seq length 2500]\tLoss: 5.736331\n",
      "23425it [44:37,  8.77it/s]Train epoch: 0 [batch #23425, batch_size 1, seq length 2500]\tLoss: 5.586034\n",
      "23450it [44:40,  8.77it/s]Train epoch: 0 [batch #23450, batch_size 1, seq length 2500]\tLoss: 5.487776\n",
      "23475it [44:43,  8.77it/s]Train epoch: 0 [batch #23475, batch_size 1, seq length 2500]\tLoss: 5.752281\n",
      "23500it [44:46,  8.77it/s]Train epoch: 0 [batch #23500, batch_size 1, seq length 2500]\tLoss: 5.814382\n",
      "23525it [44:49,  8.77it/s]Train epoch: 0 [batch #23525, batch_size 1, seq length 2500]\tLoss: 5.682688\n",
      "23550it [44:51,  8.78it/s]Train epoch: 0 [batch #23550, batch_size 1, seq length 2500]\tLoss: 5.584184\n",
      "23575it [44:54,  8.76it/s]Train epoch: 0 [batch #23575, batch_size 1, seq length 2500]\tLoss: 5.368906\n",
      "23600it [44:57,  8.73it/s]Train epoch: 0 [batch #23600, batch_size 1, seq length 2500]\tLoss: 5.512285\n",
      "23625it [45:00,  8.73it/s]Train epoch: 0 [batch #23625, batch_size 1, seq length 2500]\tLoss: 5.469251\n",
      "23650it [45:03,  8.73it/s]Train epoch: 0 [batch #23650, batch_size 1, seq length 2500]\tLoss: 5.703089\n",
      "23675it [45:06,  8.77it/s]Train epoch: 0 [batch #23675, batch_size 1, seq length 2500]\tLoss: 5.711565\n",
      "23700it [45:09,  8.75it/s]Train epoch: 0 [batch #23700, batch_size 1, seq length 2500]\tLoss: 5.754584\n",
      "23725it [45:11,  8.76it/s]Train epoch: 0 [batch #23725, batch_size 1, seq length 2500]\tLoss: 5.640704\n",
      "23750it [45:14,  8.77it/s]Train epoch: 0 [batch #23750, batch_size 1, seq length 2500]\tLoss: 5.509569\n",
      "23775it [45:17,  8.76it/s]Train epoch: 0 [batch #23775, batch_size 1, seq length 2500]\tLoss: 5.747306\n",
      "23800it [45:20,  8.76it/s]Train epoch: 0 [batch #23800, batch_size 1, seq length 2500]\tLoss: 5.543654\n",
      "23825it [45:23,  8.74it/s]Train epoch: 0 [batch #23825, batch_size 1, seq length 2500]\tLoss: 5.673820\n",
      "23850it [45:26,  8.76it/s]Train epoch: 0 [batch #23850, batch_size 1, seq length 2500]\tLoss: 5.394102\n",
      "23875it [45:29,  8.76it/s]Train epoch: 0 [batch #23875, batch_size 1, seq length 2500]\tLoss: 5.494546\n",
      "23900it [45:31,  8.77it/s]Train epoch: 0 [batch #23900, batch_size 1, seq length 2500]\tLoss: 5.577232\n",
      "23925it [45:34,  8.74it/s]Train epoch: 0 [batch #23925, batch_size 1, seq length 2500]\tLoss: 5.733591\n",
      "23950it [45:37,  8.73it/s]Train epoch: 0 [batch #23950, batch_size 1, seq length 2500]\tLoss: 5.374077\n",
      "23975it [45:40,  8.75it/s]Train epoch: 0 [batch #23975, batch_size 1, seq length 2500]\tLoss: 5.533447\n",
      "24000it [45:43,  8.77it/s]Train epoch: 0 [batch #24000, batch_size 1, seq length 2500]\tLoss: 5.653177\n",
      "24025it [45:46,  8.78it/s]Train epoch: 0 [batch #24025, batch_size 1, seq length 2500]\tLoss: 5.663892\n",
      "24050it [45:49,  8.77it/s]Train epoch: 0 [batch #24050, batch_size 1, seq length 2500]\tLoss: 5.608514\n",
      "24075it [45:51,  8.78it/s]Train epoch: 0 [batch #24075, batch_size 1, seq length 2500]\tLoss: 5.491935\n",
      "24100it [45:54,  8.75it/s]Train epoch: 0 [batch #24100, batch_size 1, seq length 2500]\tLoss: 5.577329\n",
      "24125it [45:57,  8.76it/s]Train epoch: 0 [batch #24125, batch_size 1, seq length 2500]\tLoss: 5.527641\n",
      "24150it [46:00,  8.76it/s]Train epoch: 0 [batch #24150, batch_size 1, seq length 2500]\tLoss: 5.592437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24175it [46:03,  8.76it/s]Train epoch: 0 [batch #24175, batch_size 1, seq length 2500]\tLoss: 5.394934\n",
      "24200it [46:06,  8.76it/s]Train epoch: 0 [batch #24200, batch_size 1, seq length 2500]\tLoss: 5.655654\n",
      "24225it [46:09,  8.74it/s]Train epoch: 0 [batch #24225, batch_size 1, seq length 2500]\tLoss: 5.575264\n",
      "24250it [46:11,  8.76it/s]Train epoch: 0 [batch #24250, batch_size 1, seq length 2500]\tLoss: 5.487233\n",
      "24275it [46:14,  8.77it/s]Train epoch: 0 [batch #24275, batch_size 1, seq length 2500]\tLoss: 5.506519\n",
      "24300it [46:17,  8.73it/s]Train epoch: 0 [batch #24300, batch_size 1, seq length 2500]\tLoss: 5.667355\n",
      "24325it [46:20,  8.74it/s]Train epoch: 0 [batch #24325, batch_size 1, seq length 2500]\tLoss: 5.613362\n",
      "24350it [46:23,  8.76it/s]Train epoch: 0 [batch #24350, batch_size 1, seq length 2500]\tLoss: 5.589925\n",
      "24375it [46:26,  8.78it/s]Train epoch: 0 [batch #24375, batch_size 1, seq length 2500]\tLoss: 5.506123\n",
      "24400it [46:29,  8.76it/s]Train epoch: 0 [batch #24400, batch_size 1, seq length 2500]\tLoss: 5.468802\n",
      "24425it [46:31,  8.67it/s]Train epoch: 0 [batch #24425, batch_size 1, seq length 2500]\tLoss: 5.935404\n",
      "24450it [46:34,  8.74it/s]Train epoch: 0 [batch #24450, batch_size 1, seq length 2500]\tLoss: 5.525134\n",
      "24475it [46:37,  8.76it/s]Train epoch: 0 [batch #24475, batch_size 1, seq length 2500]\tLoss: 5.719068\n",
      "24500it [46:40,  8.76it/s]Train epoch: 0 [batch #24500, batch_size 1, seq length 2500]\tLoss: 5.637152\n",
      "24525it [46:43,  8.78it/s]Train epoch: 0 [batch #24525, batch_size 1, seq length 2500]\tLoss: 5.638920\n",
      "24550it [46:46,  8.77it/s]Train epoch: 0 [batch #24550, batch_size 1, seq length 2500]\tLoss: 5.546820\n",
      "24575it [46:49,  8.76it/s]Train epoch: 0 [batch #24575, batch_size 1, seq length 2500]\tLoss: 5.663184\n",
      "24600it [46:51,  8.78it/s]Train epoch: 0 [batch #24600, batch_size 1, seq length 2500]\tLoss: 5.373120\n",
      "24625it [46:54,  8.77it/s]Train epoch: 0 [batch #24625, batch_size 1, seq length 2500]\tLoss: 5.360586\n",
      "24650it [46:57,  8.77it/s]Train epoch: 0 [batch #24650, batch_size 1, seq length 2500]\tLoss: 5.584915\n",
      "24675it [47:00,  8.75it/s]Train epoch: 0 [batch #24675, batch_size 1, seq length 2500]\tLoss: 5.325979\n",
      "24700it [47:03,  8.74it/s]Train epoch: 0 [batch #24700, batch_size 1, seq length 2500]\tLoss: 5.500794\n",
      "24725it [47:06,  8.71it/s]Train epoch: 0 [batch #24725, batch_size 1, seq length 2500]\tLoss: 5.511539\n",
      "24750it [47:09,  8.75it/s]Train epoch: 0 [batch #24750, batch_size 1, seq length 2500]\tLoss: 5.605884\n",
      "24775it [47:11,  8.76it/s]Train epoch: 0 [batch #24775, batch_size 1, seq length 2500]\tLoss: 5.594215\n",
      "24800it [47:14,  8.77it/s]Train epoch: 0 [batch #24800, batch_size 1, seq length 2500]\tLoss: 5.501690\n",
      "24825it [47:17,  8.76it/s]Train epoch: 0 [batch #24825, batch_size 1, seq length 2500]\tLoss: 5.647597\n",
      "24850it [47:20,  8.78it/s]Train epoch: 0 [batch #24850, batch_size 1, seq length 2500]\tLoss: 5.594037\n",
      "24875it [47:23,  8.74it/s]Train epoch: 0 [batch #24875, batch_size 1, seq length 2500]\tLoss: 5.695639\n",
      "24900it [47:26,  8.75it/s]Train epoch: 0 [batch #24900, batch_size 1, seq length 2500]\tLoss: 5.526600\n",
      "24925it [47:29,  8.75it/s]Train epoch: 0 [batch #24925, batch_size 1, seq length 2500]\tLoss: 5.514225\n",
      "24950it [47:31,  8.77it/s]Train epoch: 0 [batch #24950, batch_size 1, seq length 2500]\tLoss: 5.344500\n",
      "24975it [47:34,  8.77it/s]Train epoch: 0 [batch #24975, batch_size 1, seq length 2500]\tLoss: 5.721371\n",
      "25000it [47:37,  8.76it/s]Train epoch: 0 [batch #25000, batch_size 1, seq length 2500]\tLoss: 5.495595\n",
      "25025it [47:40,  8.77it/s]Train epoch: 0 [batch #25025, batch_size 1, seq length 2500]\tLoss: 5.351444\n",
      "25050it [47:43,  8.77it/s]Train epoch: 0 [batch #25050, batch_size 1, seq length 2500]\tLoss: 5.622231\n",
      "25075it [47:46,  8.77it/s]Train epoch: 0 [batch #25075, batch_size 1, seq length 2500]\tLoss: 5.418773\n",
      "25100it [47:49,  8.76it/s]Train epoch: 0 [batch #25100, batch_size 1, seq length 2500]\tLoss: 5.554767\n",
      "25125it [47:51,  8.76it/s]Train epoch: 0 [batch #25125, batch_size 1, seq length 2500]\tLoss: 5.170916\n",
      "25150it [47:54,  8.76it/s]Train epoch: 0 [batch #25150, batch_size 1, seq length 2500]\tLoss: 5.473628\n",
      "25175it [47:57,  8.76it/s]Train epoch: 0 [batch #25175, batch_size 1, seq length 2500]\tLoss: 5.538824\n",
      "25200it [48:00,  8.76it/s]Train epoch: 0 [batch #25200, batch_size 1, seq length 2500]\tLoss: 5.502784\n",
      "25225it [48:03,  8.71it/s]Train epoch: 0 [batch #25225, batch_size 1, seq length 2500]\tLoss: 5.504079\n",
      "25250it [48:06,  8.74it/s]Train epoch: 0 [batch #25250, batch_size 1, seq length 2500]\tLoss: 5.415362\n",
      "25275it [48:09,  8.75it/s]Train epoch: 0 [batch #25275, batch_size 1, seq length 2500]\tLoss: 5.598421\n",
      "25300it [48:11,  8.75it/s]Train epoch: 0 [batch #25300, batch_size 1, seq length 2500]\tLoss: 5.691032\n",
      "25325it [48:14,  8.73it/s]Train epoch: 0 [batch #25325, batch_size 1, seq length 2500]\tLoss: 5.344106\n",
      "25350it [48:17,  8.76it/s]Train epoch: 0 [batch #25350, batch_size 1, seq length 2500]\tLoss: 5.408318\n",
      "25375it [48:20,  8.78it/s]Train epoch: 0 [batch #25375, batch_size 1, seq length 2500]\tLoss: 5.574979\n",
      "25400it [48:23,  8.76it/s]Train epoch: 0 [batch #25400, batch_size 1, seq length 2500]\tLoss: 5.751373\n",
      "25425it [48:26,  8.77it/s]Train epoch: 0 [batch #25425, batch_size 1, seq length 2500]\tLoss: 5.785449\n",
      "25450it [48:29,  8.74it/s]Train epoch: 0 [batch #25450, batch_size 1, seq length 2500]\tLoss: 5.799455\n",
      "25475it [48:31,  8.76it/s]Train epoch: 0 [batch #25475, batch_size 1, seq length 2500]\tLoss: 5.647621\n",
      "25500it [48:34,  8.76it/s]Train epoch: 0 [batch #25500, batch_size 1, seq length 2500]\tLoss: 5.766209\n",
      "25525it [48:37,  8.76it/s]Train epoch: 0 [batch #25525, batch_size 1, seq length 2500]\tLoss: 5.455136\n",
      "25550it [48:40,  8.74it/s]Train epoch: 0 [batch #25550, batch_size 1, seq length 2500]\tLoss: 5.818651\n",
      "25575it [48:43,  8.77it/s]Train epoch: 0 [batch #25575, batch_size 1, seq length 2500]\tLoss: 5.373274\n",
      "25600it [48:46,  8.74it/s]Train epoch: 0 [batch #25600, batch_size 1, seq length 2500]\tLoss: 5.358624\n",
      "25625it [48:49,  8.74it/s]Train epoch: 0 [batch #25625, batch_size 1, seq length 2500]\tLoss: 5.400174\n",
      "25650it [48:51,  8.75it/s]Train epoch: 0 [batch #25650, batch_size 1, seq length 2500]\tLoss: 5.505360\n",
      "25675it [48:54,  8.76it/s]Train epoch: 0 [batch #25675, batch_size 1, seq length 2500]\tLoss: 5.455475\n",
      "25700it [48:57,  8.75it/s]Train epoch: 0 [batch #25700, batch_size 1, seq length 2500]\tLoss: 5.231218\n",
      "25725it [49:00,  8.78it/s]Train epoch: 0 [batch #25725, batch_size 1, seq length 2500]\tLoss: 5.809225\n",
      "25750it [49:03,  8.75it/s]Train epoch: 0 [batch #25750, batch_size 1, seq length 2500]\tLoss: 5.339748\n",
      "25775it [49:06,  8.72it/s]Train epoch: 0 [batch #25775, batch_size 1, seq length 2500]\tLoss: 5.721294\n",
      "25800it [49:09,  8.76it/s]Train epoch: 0 [batch #25800, batch_size 1, seq length 2500]\tLoss: 5.482020\n",
      "25825it [49:11,  8.77it/s]Train epoch: 0 [batch #25825, batch_size 1, seq length 2500]\tLoss: 5.374769\n",
      "25850it [49:14,  8.75it/s]Train epoch: 0 [batch #25850, batch_size 1, seq length 2500]\tLoss: 5.658259\n",
      "25875it [49:17,  8.72it/s]Train epoch: 0 [batch #25875, batch_size 1, seq length 2500]\tLoss: 5.543993\n",
      "25900it [49:20,  8.73it/s]Train epoch: 0 [batch #25900, batch_size 1, seq length 2500]\tLoss: 5.375764\n",
      "25925it [49:23,  8.78it/s]Train epoch: 0 [batch #25925, batch_size 1, seq length 2500]\tLoss: 5.692426\n",
      "25950it [49:26,  8.77it/s]Train epoch: 0 [batch #25950, batch_size 1, seq length 2500]\tLoss: 5.557268\n",
      "25975it [49:29,  8.78it/s]Train epoch: 0 [batch #25975, batch_size 1, seq length 2500]\tLoss: 5.599822\n",
      "26000it [49:32,  8.74it/s]Train epoch: 0 [batch #26000, batch_size 1, seq length 2500]\tLoss: 5.589332\n",
      "26025it [49:34,  8.77it/s]Train epoch: 0 [batch #26025, batch_size 1, seq length 2500]\tLoss: 5.435841\n",
      "26050it [49:37,  8.76it/s]Train epoch: 0 [batch #26050, batch_size 1, seq length 2500]\tLoss: 5.088375\n",
      "26075it [49:40,  8.74it/s]Train epoch: 0 [batch #26075, batch_size 1, seq length 2500]\tLoss: 5.645488\n",
      "26100it [49:43,  8.74it/s]Train epoch: 0 [batch #26100, batch_size 1, seq length 2500]\tLoss: 5.478874\n",
      "26125it [49:46,  8.76it/s]Train epoch: 0 [batch #26125, batch_size 1, seq length 2500]\tLoss: 5.494890\n",
      "26150it [49:49,  8.76it/s]Train epoch: 0 [batch #26150, batch_size 1, seq length 2500]\tLoss: 5.531544\n",
      "26175it [49:52,  8.77it/s]Train epoch: 0 [batch #26175, batch_size 1, seq length 2500]\tLoss: 5.547834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26200it [49:54,  8.76it/s]Train epoch: 0 [batch #26200, batch_size 1, seq length 2500]\tLoss: 5.323098\n",
      "26225it [49:57,  8.76it/s]Train epoch: 0 [batch #26225, batch_size 1, seq length 2500]\tLoss: 5.468013\n",
      "26250it [50:00,  8.75it/s]Train epoch: 0 [batch #26250, batch_size 1, seq length 2500]\tLoss: 5.523501\n",
      "26275it [50:03,  8.76it/s]Train epoch: 0 [batch #26275, batch_size 1, seq length 2500]\tLoss: 5.390597\n",
      "26300it [50:06,  8.77it/s]Train epoch: 0 [batch #26300, batch_size 1, seq length 2500]\tLoss: 5.665246\n",
      "26325it [50:09,  8.76it/s]Train epoch: 0 [batch #26325, batch_size 1, seq length 2500]\tLoss: 5.467694\n",
      "26350it [50:11,  8.77it/s]Train epoch: 0 [batch #26350, batch_size 1, seq length 2500]\tLoss: 5.530383\n",
      "26375it [50:14,  8.76it/s]Train epoch: 0 [batch #26375, batch_size 1, seq length 2500]\tLoss: 5.697480\n",
      "26400it [50:17,  8.75it/s]Train epoch: 0 [batch #26400, batch_size 1, seq length 2500]\tLoss: 5.451486\n",
      "26425it [50:20,  8.55it/s]Train epoch: 0 [batch #26425, batch_size 1, seq length 2500]\tLoss: 5.640164\n",
      "26450it [50:23,  8.77it/s]Train epoch: 0 [batch #26450, batch_size 1, seq length 2500]\tLoss: 5.559852\n",
      "26475it [50:26,  8.72it/s]Train epoch: 0 [batch #26475, batch_size 1, seq length 2500]\tLoss: 5.365981\n",
      "26500it [50:29,  8.74it/s]Train epoch: 0 [batch #26500, batch_size 1, seq length 2500]\tLoss: 5.458007\n",
      "26525it [50:31,  8.77it/s]Train epoch: 0 [batch #26525, batch_size 1, seq length 2500]\tLoss: 5.738652\n",
      "26550it [50:34,  8.70it/s]Train epoch: 0 [batch #26550, batch_size 1, seq length 2500]\tLoss: 5.601796\n",
      "26575it [50:37,  8.72it/s]Train epoch: 0 [batch #26575, batch_size 1, seq length 2500]\tLoss: 5.359657\n",
      "26600it [50:40,  8.58it/s]Train epoch: 0 [batch #26600, batch_size 1, seq length 2500]\tLoss: 5.356581\n",
      "26625it [50:43,  8.76it/s]Train epoch: 0 [batch #26625, batch_size 1, seq length 2500]\tLoss: 5.458971\n",
      "26650it [50:46,  8.67it/s]Train epoch: 0 [batch #26650, batch_size 1, seq length 2500]\tLoss: 5.626572\n",
      "26675it [50:49,  8.73it/s]Train epoch: 0 [batch #26675, batch_size 1, seq length 2500]\tLoss: 5.260764\n",
      "26700it [50:52,  8.72it/s]Train epoch: 0 [batch #26700, batch_size 1, seq length 2500]\tLoss: 5.497848\n",
      "26725it [50:54,  8.71it/s]Train epoch: 0 [batch #26725, batch_size 1, seq length 2500]\tLoss: 5.489746\n",
      "26750it [50:57,  8.76it/s]Train epoch: 0 [batch #26750, batch_size 1, seq length 2500]\tLoss: 5.509758\n",
      "26775it [51:00,  8.75it/s]Train epoch: 0 [batch #26775, batch_size 1, seq length 2500]\tLoss: 5.604820\n",
      "26800it [51:03,  8.72it/s]Train epoch: 0 [batch #26800, batch_size 1, seq length 2500]\tLoss: 5.349112\n",
      "26825it [51:06,  8.74it/s]Train epoch: 0 [batch #26825, batch_size 1, seq length 2500]\tLoss: 5.451541\n",
      "26850it [51:09,  8.77it/s]Train epoch: 0 [batch #26850, batch_size 1, seq length 2500]\tLoss: 5.446914\n",
      "26875it [51:12,  8.77it/s]Train epoch: 0 [batch #26875, batch_size 1, seq length 2500]\tLoss: 5.596853\n",
      "26900it [51:14,  8.76it/s]Train epoch: 0 [batch #26900, batch_size 1, seq length 2500]\tLoss: 5.690035\n",
      "26925it [51:17,  8.75it/s]Train epoch: 0 [batch #26925, batch_size 1, seq length 2500]\tLoss: 5.547495\n",
      "26950it [51:20,  8.78it/s]Train epoch: 0 [batch #26950, batch_size 1, seq length 2500]\tLoss: 5.533235\n",
      "26975it [51:23,  8.76it/s]Train epoch: 0 [batch #26975, batch_size 1, seq length 2500]\tLoss: 5.402696\n",
      "27000it [51:26,  8.77it/s]Train epoch: 0 [batch #27000, batch_size 1, seq length 2500]\tLoss: 5.388778\n",
      "27025it [51:29,  8.71it/s]Train epoch: 0 [batch #27025, batch_size 1, seq length 2500]\tLoss: 5.421834\n",
      "27050it [51:32,  8.72it/s]Train epoch: 0 [batch #27050, batch_size 1, seq length 2500]\tLoss: 5.722685\n",
      "27075it [51:34,  8.64it/s]Train epoch: 0 [batch #27075, batch_size 1, seq length 2500]\tLoss: 5.517133\n",
      "27100it [51:37,  8.61it/s]Train epoch: 0 [batch #27100, batch_size 1, seq length 2500]\tLoss: 5.474375\n",
      "27125it [51:40,  8.77it/s]Train epoch: 0 [batch #27125, batch_size 1, seq length 2500]\tLoss: 5.607836\n",
      "27150it [51:43,  8.75it/s]Train epoch: 0 [batch #27150, batch_size 1, seq length 2500]\tLoss: 5.418237\n",
      "27175it [51:46,  8.77it/s]Train epoch: 0 [batch #27175, batch_size 1, seq length 2500]\tLoss: 5.393221\n",
      "27200it [51:49,  8.77it/s]Train epoch: 0 [batch #27200, batch_size 1, seq length 2500]\tLoss: 5.645422\n",
      "27225it [51:52,  8.76it/s]Train epoch: 0 [batch #27225, batch_size 1, seq length 2500]\tLoss: 5.368144\n",
      "27250it [51:54,  8.75it/s]Train epoch: 0 [batch #27250, batch_size 1, seq length 2500]\tLoss: 5.701103\n",
      "27275it [51:57,  8.76it/s]Train epoch: 0 [batch #27275, batch_size 1, seq length 2500]\tLoss: 5.467452\n",
      "27300it [52:00,  8.75it/s]Train epoch: 0 [batch #27300, batch_size 1, seq length 2500]\tLoss: 5.610466\n",
      "27325it [52:03,  8.77it/s]Train epoch: 0 [batch #27325, batch_size 1, seq length 2500]\tLoss: 5.242455\n",
      "27350it [52:06,  8.73it/s]Train epoch: 0 [batch #27350, batch_size 1, seq length 2500]\tLoss: 5.569912\n",
      "27375it [52:09,  8.74it/s]Train epoch: 0 [batch #27375, batch_size 1, seq length 2500]\tLoss: 5.541934\n",
      "27400it [52:12,  8.78it/s]Train epoch: 0 [batch #27400, batch_size 1, seq length 2500]\tLoss: 5.446652\n",
      "27425it [52:14,  8.76it/s]Train epoch: 0 [batch #27425, batch_size 1, seq length 2500]\tLoss: 5.460305\n",
      "27450it [52:17,  8.66it/s]Train epoch: 0 [batch #27450, batch_size 1, seq length 2500]\tLoss: 5.191591\n",
      "27475it [52:20,  8.77it/s]Train epoch: 0 [batch #27475, batch_size 1, seq length 2500]\tLoss: 5.386457\n",
      "27500it [52:23,  8.77it/s]Train epoch: 0 [batch #27500, batch_size 1, seq length 2500]\tLoss: 5.645391\n",
      "27525it [52:26,  8.75it/s]Train epoch: 0 [batch #27525, batch_size 1, seq length 2500]\tLoss: 5.461884\n",
      "27550it [52:29,  8.75it/s]Train epoch: 0 [batch #27550, batch_size 1, seq length 2500]\tLoss: 5.502044\n",
      "27575it [52:32,  8.78it/s]Train epoch: 0 [batch #27575, batch_size 1, seq length 2500]\tLoss: 5.641477\n",
      "27600it [52:34,  8.78it/s]Train epoch: 0 [batch #27600, batch_size 1, seq length 2500]\tLoss: 5.315887\n",
      "27625it [52:37,  8.77it/s]Train epoch: 0 [batch #27625, batch_size 1, seq length 2500]\tLoss: 5.457512\n",
      "27650it [52:40,  8.76it/s]Train epoch: 0 [batch #27650, batch_size 1, seq length 2500]\tLoss: 5.406221\n",
      "27675it [52:43,  8.77it/s]Train epoch: 0 [batch #27675, batch_size 1, seq length 2500]\tLoss: 5.384506\n",
      "27700it [52:46,  8.60it/s]Train epoch: 0 [batch #27700, batch_size 1, seq length 2500]\tLoss: 5.387381\n",
      "27725it [52:49,  8.77it/s]Train epoch: 0 [batch #27725, batch_size 1, seq length 2500]\tLoss: 5.648535\n",
      "27750it [52:52,  8.73it/s]Train epoch: 0 [batch #27750, batch_size 1, seq length 2500]\tLoss: 5.249024\n",
      "27775it [52:55,  8.77it/s]Train epoch: 0 [batch #27775, batch_size 1, seq length 2500]\tLoss: 5.529482\n",
      "27800it [52:57,  8.76it/s]Train epoch: 0 [batch #27800, batch_size 1, seq length 2500]\tLoss: 5.298731\n",
      "27825it [53:00,  8.69it/s]Train epoch: 0 [batch #27825, batch_size 1, seq length 2500]\tLoss: 5.580402\n",
      "27850it [53:03,  8.69it/s]Train epoch: 0 [batch #27850, batch_size 1, seq length 2500]\tLoss: 5.472041\n",
      "27875it [53:06,  8.74it/s]Train epoch: 0 [batch #27875, batch_size 1, seq length 2500]\tLoss: 5.663753\n",
      "27900it [53:09,  8.75it/s]Train epoch: 0 [batch #27900, batch_size 1, seq length 2500]\tLoss: 5.432100\n",
      "27925it [53:12,  8.76it/s]Train epoch: 0 [batch #27925, batch_size 1, seq length 2500]\tLoss: 5.742264\n",
      "27950it [53:15,  8.69it/s]Train epoch: 0 [batch #27950, batch_size 1, seq length 2500]\tLoss: 5.653049\n",
      "27975it [53:17,  8.76it/s]Train epoch: 0 [batch #27975, batch_size 1, seq length 2500]\tLoss: 5.496487\n",
      "28000it [53:20,  8.77it/s]Train epoch: 0 [batch #28000, batch_size 1, seq length 2500]\tLoss: 5.250536\n",
      "28025it [53:23,  8.77it/s]Train epoch: 0 [batch #28025, batch_size 1, seq length 2500]\tLoss: 5.340193\n",
      "28050it [53:26,  8.78it/s]Train epoch: 0 [batch #28050, batch_size 1, seq length 2500]\tLoss: 5.627398\n",
      "28075it [53:29,  8.76it/s]Train epoch: 0 [batch #28075, batch_size 1, seq length 2500]\tLoss: 5.420450\n",
      "28100it [53:32,  8.78it/s]Train epoch: 0 [batch #28100, batch_size 1, seq length 2500]\tLoss: 5.365438\n",
      "28125it [53:35,  8.76it/s]Train epoch: 0 [batch #28125, batch_size 1, seq length 2500]\tLoss: 5.279827\n",
      "28150it [53:37,  8.77it/s]Train epoch: 0 [batch #28150, batch_size 1, seq length 2500]\tLoss: 5.435321\n",
      "28175it [53:40,  8.76it/s]Train epoch: 0 [batch #28175, batch_size 1, seq length 2500]\tLoss: 5.342787\n",
      "28200it [53:43,  8.78it/s]Train epoch: 0 [batch #28200, batch_size 1, seq length 2500]\tLoss: 5.151057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28225it [53:46,  8.74it/s]Train epoch: 0 [batch #28225, batch_size 1, seq length 2500]\tLoss: 5.437657\n",
      "28250it [53:49,  8.77it/s]Train epoch: 0 [batch #28250, batch_size 1, seq length 2500]\tLoss: 5.338261\n",
      "28275it [53:52,  8.78it/s]Train epoch: 0 [batch #28275, batch_size 1, seq length 2500]\tLoss: 5.438719\n",
      "28300it [53:55,  8.76it/s]Train epoch: 0 [batch #28300, batch_size 1, seq length 2500]\tLoss: 5.516650\n",
      "28325it [53:57,  8.74it/s]Train epoch: 0 [batch #28325, batch_size 1, seq length 2500]\tLoss: 5.329623\n",
      "28350it [54:00,  8.77it/s]Train epoch: 0 [batch #28350, batch_size 1, seq length 2500]\tLoss: 5.328217\n",
      "28375it [54:03,  8.78it/s]Train epoch: 0 [batch #28375, batch_size 1, seq length 2500]\tLoss: 5.598046\n",
      "28400it [54:06,  8.75it/s]Train epoch: 0 [batch #28400, batch_size 1, seq length 2500]\tLoss: 5.566352\n",
      "28425it [54:09,  8.75it/s]Train epoch: 0 [batch #28425, batch_size 1, seq length 2500]\tLoss: 5.678467\n",
      "28450it [54:12,  8.75it/s]Train epoch: 0 [batch #28450, batch_size 1, seq length 2500]\tLoss: 5.443249\n",
      "28475it [54:15,  8.75it/s]Train epoch: 0 [batch #28475, batch_size 1, seq length 2500]\tLoss: 5.371657\n",
      "28500it [54:17,  8.76it/s]Train epoch: 0 [batch #28500, batch_size 1, seq length 2500]\tLoss: 5.316630\n",
      "28525it [54:20,  8.78it/s]Train epoch: 0 [batch #28525, batch_size 1, seq length 2500]\tLoss: 5.093583\n",
      "28550it [54:23,  8.75it/s]Train epoch: 0 [batch #28550, batch_size 1, seq length 2500]\tLoss: 5.650210\n",
      "28575it [54:26,  8.76it/s]Train epoch: 0 [batch #28575, batch_size 1, seq length 2500]\tLoss: 5.519968\n",
      "28600it [54:29,  8.76it/s]Train epoch: 0 [batch #28600, batch_size 1, seq length 2500]\tLoss: 4.934332\n",
      "28625it [54:32,  8.77it/s]Train epoch: 0 [batch #28625, batch_size 1, seq length 2500]\tLoss: 5.570677\n",
      "28650it [54:35,  8.76it/s]Train epoch: 0 [batch #28650, batch_size 1, seq length 2500]\tLoss: 5.411647\n",
      "28675it [54:37,  8.76it/s]Train epoch: 0 [batch #28675, batch_size 1, seq length 2500]\tLoss: 5.283376\n",
      "28700it [54:40,  8.78it/s]Train epoch: 0 [batch #28700, batch_size 1, seq length 2500]\tLoss: 5.492112\n",
      "28725it [54:43,  8.67it/s]Train epoch: 0 [batch #28725, batch_size 1, seq length 2500]\tLoss: 5.568235\n",
      "28750it [54:46,  8.77it/s]Train epoch: 0 [batch #28750, batch_size 1, seq length 2500]\tLoss: 5.604636\n",
      "28775it [54:49,  8.74it/s]Train epoch: 0 [batch #28775, batch_size 1, seq length 2500]\tLoss: 5.576436\n",
      "28800it [54:52,  8.77it/s]Train epoch: 0 [batch #28800, batch_size 1, seq length 2500]\tLoss: 5.106628\n",
      "28825it [54:55,  8.75it/s]Train epoch: 0 [batch #28825, batch_size 1, seq length 2500]\tLoss: 5.338434\n",
      "28850it [54:57,  8.78it/s]Train epoch: 0 [batch #28850, batch_size 1, seq length 2500]\tLoss: 5.169456\n",
      "28875it [55:00,  8.75it/s]Train epoch: 0 [batch #28875, batch_size 1, seq length 2500]\tLoss: 5.608718\n",
      "28900it [55:03,  8.76it/s]Train epoch: 0 [batch #28900, batch_size 1, seq length 2500]\tLoss: 5.389285\n",
      "28925it [55:06,  8.68it/s]Train epoch: 0 [batch #28925, batch_size 1, seq length 2500]\tLoss: 5.320816\n",
      "28950it [55:09,  8.75it/s]Train epoch: 0 [batch #28950, batch_size 1, seq length 2500]\tLoss: 5.585710\n",
      "28975it [55:12,  8.77it/s]Train epoch: 0 [batch #28975, batch_size 1, seq length 2500]\tLoss: 5.505103\n",
      "29000it [55:15,  8.71it/s]Train epoch: 0 [batch #29000, batch_size 1, seq length 2500]\tLoss: 5.272992\n",
      "29025it [55:17,  8.76it/s]Train epoch: 0 [batch #29025, batch_size 1, seq length 2500]\tLoss: 5.243545\n",
      "29050it [55:20,  8.77it/s]Train epoch: 0 [batch #29050, batch_size 1, seq length 2500]\tLoss: 5.382508\n",
      "29075it [55:23,  8.78it/s]Train epoch: 0 [batch #29075, batch_size 1, seq length 2500]\tLoss: 5.474737\n",
      "29100it [55:26,  8.77it/s]Train epoch: 0 [batch #29100, batch_size 1, seq length 2500]\tLoss: 5.456368\n",
      "29125it [55:29,  8.76it/s]Train epoch: 0 [batch #29125, batch_size 1, seq length 2500]\tLoss: 5.682280\n",
      "29150it [55:32,  8.79it/s]Train epoch: 0 [batch #29150, batch_size 1, seq length 2500]\tLoss: 4.826034\n",
      "29175it [55:35,  8.69it/s]Train epoch: 0 [batch #29175, batch_size 1, seq length 2500]\tLoss: 5.345029\n",
      "29200it [55:37,  8.75it/s]Train epoch: 0 [batch #29200, batch_size 1, seq length 2500]\tLoss: 5.439950\n",
      "29225it [55:40,  8.75it/s]Train epoch: 0 [batch #29225, batch_size 1, seq length 2500]\tLoss: 5.502180\n",
      "29250it [55:43,  8.78it/s]Train epoch: 0 [batch #29250, batch_size 1, seq length 2500]\tLoss: 5.317203\n",
      "29275it [55:46,  8.75it/s]Train epoch: 0 [batch #29275, batch_size 1, seq length 2500]\tLoss: 5.157850\n",
      "29300it [55:49,  8.73it/s]Train epoch: 0 [batch #29300, batch_size 1, seq length 2500]\tLoss: 5.568666\n",
      "29325it [55:52,  8.72it/s]Train epoch: 0 [batch #29325, batch_size 1, seq length 2500]\tLoss: 5.257534\n",
      "29350it [55:55,  8.78it/s]Train epoch: 0 [batch #29350, batch_size 1, seq length 2500]\tLoss: 5.393235\n",
      "29375it [55:57,  8.78it/s]Train epoch: 0 [batch #29375, batch_size 1, seq length 2500]\tLoss: 5.362363\n",
      "29400it [56:00,  8.75it/s]Train epoch: 0 [batch #29400, batch_size 1, seq length 2500]\tLoss: 5.454744\n",
      "29425it [56:03,  8.73it/s]Train epoch: 0 [batch #29425, batch_size 1, seq length 2500]\tLoss: 5.457668\n",
      "29450it [56:06,  8.77it/s]Train epoch: 0 [batch #29450, batch_size 1, seq length 2500]\tLoss: 5.452097\n",
      "29475it [56:09,  8.75it/s]Train epoch: 0 [batch #29475, batch_size 1, seq length 2500]\tLoss: 5.521733\n",
      "29500it [56:12,  8.77it/s]Train epoch: 0 [batch #29500, batch_size 1, seq length 2500]\tLoss: 5.396488\n",
      "29525it [56:14,  8.77it/s]Train epoch: 0 [batch #29525, batch_size 1, seq length 2500]\tLoss: 5.547297\n",
      "29550it [56:17,  8.74it/s]Train epoch: 0 [batch #29550, batch_size 1, seq length 2500]\tLoss: 5.494503\n",
      "29575it [56:20,  8.75it/s]Train epoch: 0 [batch #29575, batch_size 1, seq length 2500]\tLoss: 5.497408\n",
      "29600it [56:23,  8.74it/s]Train epoch: 0 [batch #29600, batch_size 1, seq length 2500]\tLoss: 5.295348\n",
      "29625it [56:26,  8.77it/s]Train epoch: 0 [batch #29625, batch_size 1, seq length 2500]\tLoss: 5.612676\n",
      "29650it [56:29,  8.78it/s]Train epoch: 0 [batch #29650, batch_size 1, seq length 2500]\tLoss: 5.382508\n",
      "29675it [56:32,  8.75it/s]Train epoch: 0 [batch #29675, batch_size 1, seq length 2500]\tLoss: 5.305180\n",
      "29700it [56:34,  8.77it/s]Train epoch: 0 [batch #29700, batch_size 1, seq length 2500]\tLoss: 5.604621\n",
      "29725it [56:37,  8.68it/s]Train epoch: 0 [batch #29725, batch_size 1, seq length 2500]\tLoss: 5.131101\n",
      "29750it [56:40,  8.75it/s]Train epoch: 0 [batch #29750, batch_size 1, seq length 2500]\tLoss: 5.540778\n",
      "29775it [56:43,  8.71it/s]Train epoch: 0 [batch #29775, batch_size 1, seq length 2500]\tLoss: 5.102774\n",
      "29800it [56:46,  8.77it/s]Train epoch: 0 [batch #29800, batch_size 1, seq length 2500]\tLoss: 5.335583\n",
      "29825it [56:49,  8.74it/s]Train epoch: 0 [batch #29825, batch_size 1, seq length 2500]\tLoss: 5.500858\n",
      "29850it [56:52,  8.78it/s]Train epoch: 0 [batch #29850, batch_size 1, seq length 2500]\tLoss: 5.391548\n",
      "29875it [56:54,  8.78it/s]Train epoch: 0 [batch #29875, batch_size 1, seq length 2500]\tLoss: 5.571092\n",
      "29900it [56:57,  8.76it/s]Train epoch: 0 [batch #29900, batch_size 1, seq length 2500]\tLoss: 5.002990\n",
      "29925it [57:00,  8.75it/s]Train epoch: 0 [batch #29925, batch_size 1, seq length 2500]\tLoss: 5.502497\n",
      "29950it [57:03,  8.76it/s]Train epoch: 0 [batch #29950, batch_size 1, seq length 2500]\tLoss: 5.363538\n",
      "29975it [57:06,  8.78it/s]Train epoch: 0 [batch #29975, batch_size 1, seq length 2500]\tLoss: 5.565590\n",
      "30000it [57:09,  8.74it/s]Train epoch: 0 [batch #30000, batch_size 1, seq length 2500]\tLoss: 5.525879\n",
      "30025it [57:12,  8.78it/s]Train epoch: 0 [batch #30025, batch_size 1, seq length 2500]\tLoss: 5.531905\n",
      "30050it [57:14,  8.73it/s]Train epoch: 0 [batch #30050, batch_size 1, seq length 2500]\tLoss: 5.405396\n",
      "30075it [57:17,  8.78it/s]Train epoch: 0 [batch #30075, batch_size 1, seq length 2500]\tLoss: 4.944963\n",
      "30100it [57:20,  8.75it/s]Train epoch: 0 [batch #30100, batch_size 1, seq length 2500]\tLoss: 5.392967\n",
      "30125it [57:23,  8.67it/s]Train epoch: 0 [batch #30125, batch_size 1, seq length 2500]\tLoss: 5.200687\n",
      "30150it [57:26,  8.76it/s]Train epoch: 0 [batch #30150, batch_size 1, seq length 2500]\tLoss: 5.088089\n",
      "30175it [57:29,  8.77it/s]Train epoch: 0 [batch #30175, batch_size 1, seq length 2500]\tLoss: 5.516893\n",
      "30200it [57:32,  8.78it/s]Train epoch: 0 [batch #30200, batch_size 1, seq length 2500]\tLoss: 5.174053\n",
      "30225it [57:34,  8.61it/s]Train epoch: 0 [batch #30225, batch_size 1, seq length 2500]\tLoss: 5.391981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30250it [57:37,  8.74it/s]Train epoch: 0 [batch #30250, batch_size 1, seq length 2500]\tLoss: 5.496471\n",
      "30275it [57:40,  8.73it/s]Train epoch: 0 [batch #30275, batch_size 1, seq length 2500]\tLoss: 5.621560\n",
      "30300it [57:43,  8.76it/s]Train epoch: 0 [batch #30300, batch_size 1, seq length 2500]\tLoss: 5.484625\n",
      "30325it [57:46,  8.76it/s]Train epoch: 0 [batch #30325, batch_size 1, seq length 2500]\tLoss: 5.136746\n",
      "30350it [57:49,  8.75it/s]Train epoch: 0 [batch #30350, batch_size 1, seq length 2500]\tLoss: 5.200742\n",
      "30375it [57:52,  8.75it/s]Train epoch: 0 [batch #30375, batch_size 1, seq length 2500]\tLoss: 5.407220\n",
      "30400it [57:54,  8.77it/s]Train epoch: 0 [batch #30400, batch_size 1, seq length 2500]\tLoss: 5.291265\n",
      "30425it [57:57,  8.76it/s]Train epoch: 0 [batch #30425, batch_size 1, seq length 2500]\tLoss: 5.251706\n",
      "30450it [58:00,  8.76it/s]Train epoch: 0 [batch #30450, batch_size 1, seq length 2500]\tLoss: 5.095509\n",
      "30475it [58:03,  8.78it/s]Train epoch: 0 [batch #30475, batch_size 1, seq length 2500]\tLoss: 5.568581\n",
      "30500it [58:06,  8.77it/s]Train epoch: 0 [batch #30500, batch_size 1, seq length 2500]\tLoss: 5.180718\n",
      "30525it [58:09,  8.78it/s]Train epoch: 0 [batch #30525, batch_size 1, seq length 2500]\tLoss: 5.246666\n",
      "30550it [58:12,  8.75it/s]Train epoch: 0 [batch #30550, batch_size 1, seq length 2500]\tLoss: 5.310272\n",
      "30575it [58:14,  8.77it/s]Train epoch: 0 [batch #30575, batch_size 1, seq length 2500]\tLoss: 5.513585\n",
      "30600it [58:17,  8.78it/s]Train epoch: 0 [batch #30600, batch_size 1, seq length 2500]\tLoss: 5.421061\n",
      "30625it [58:20,  8.74it/s]Train epoch: 0 [batch #30625, batch_size 1, seq length 2500]\tLoss: 5.430153\n",
      "30650it [58:23,  8.76it/s]Train epoch: 0 [batch #30650, batch_size 1, seq length 2500]\tLoss: 5.186685\n",
      "30675it [58:26,  8.75it/s]Train epoch: 0 [batch #30675, batch_size 1, seq length 2500]\tLoss: 5.454102\n",
      "30700it [58:29,  8.58it/s]Train epoch: 0 [batch #30700, batch_size 1, seq length 2500]\tLoss: 5.607738\n",
      "30725it [58:32,  8.76it/s]Train epoch: 0 [batch #30725, batch_size 1, seq length 2500]\tLoss: 5.382487\n",
      "30750it [58:34,  8.76it/s]Train epoch: 0 [batch #30750, batch_size 1, seq length 2500]\tLoss: 5.047700\n",
      "30775it [58:37,  8.73it/s]Train epoch: 0 [batch #30775, batch_size 1, seq length 2500]\tLoss: 5.197732\n",
      "30800it [58:40,  8.58it/s]Train epoch: 0 [batch #30800, batch_size 1, seq length 2500]\tLoss: 5.311769\n",
      "30825it [58:43,  8.74it/s]Train epoch: 0 [batch #30825, batch_size 1, seq length 2500]\tLoss: 5.333194\n",
      "30850it [58:46,  8.68it/s]Train epoch: 0 [batch #30850, batch_size 1, seq length 2500]\tLoss: 5.305536\n",
      "30875it [58:49,  8.78it/s]Train epoch: 0 [batch #30875, batch_size 1, seq length 2500]\tLoss: 5.468754\n",
      "30900it [58:52,  8.77it/s]Train epoch: 0 [batch #30900, batch_size 1, seq length 2500]\tLoss: 5.349640\n",
      "30925it [58:54,  8.76it/s]Train epoch: 0 [batch #30925, batch_size 1, seq length 2500]\tLoss: 5.432224\n",
      "30950it [58:57,  8.77it/s]Train epoch: 0 [batch #30950, batch_size 1, seq length 2500]\tLoss: 5.678397\n",
      "30975it [59:00,  8.77it/s]Train epoch: 0 [batch #30975, batch_size 1, seq length 2500]\tLoss: 5.367288\n",
      "31000it [59:03,  8.76it/s]Train epoch: 0 [batch #31000, batch_size 1, seq length 2500]\tLoss: 5.350556\n",
      "31025it [59:06,  8.78it/s]Train epoch: 0 [batch #31025, batch_size 1, seq length 2500]\tLoss: 5.294786\n",
      "31050it [59:09,  8.75it/s]Train epoch: 0 [batch #31050, batch_size 1, seq length 2500]\tLoss: 5.395570\n",
      "31075it [59:12,  8.74it/s]Train epoch: 0 [batch #31075, batch_size 1, seq length 2500]\tLoss: 5.352531\n",
      "31100it [59:14,  8.74it/s]Train epoch: 0 [batch #31100, batch_size 1, seq length 2500]\tLoss: 5.000794\n",
      "31125it [59:17,  8.77it/s]Train epoch: 0 [batch #31125, batch_size 1, seq length 2500]\tLoss: 5.432445\n",
      "31150it [59:20,  8.76it/s]Train epoch: 0 [batch #31150, batch_size 1, seq length 2500]\tLoss: 5.356997\n",
      "31175it [59:23,  8.75it/s]Train epoch: 0 [batch #31175, batch_size 1, seq length 2500]\tLoss: 5.064739\n",
      "31200it [59:26,  8.74it/s]Train epoch: 0 [batch #31200, batch_size 1, seq length 2500]\tLoss: 5.320277\n",
      "31225it [59:29,  8.73it/s]Train epoch: 0 [batch #31225, batch_size 1, seq length 2500]\tLoss: 5.276620\n",
      "31250it [59:32,  8.77it/s]Train epoch: 0 [batch #31250, batch_size 1, seq length 2500]\tLoss: 5.187668\n",
      "31275it [59:34,  8.77it/s]Train epoch: 0 [batch #31275, batch_size 1, seq length 2500]\tLoss: 5.267192\n",
      "31300it [59:37,  8.72it/s]Train epoch: 0 [batch #31300, batch_size 1, seq length 2500]\tLoss: 5.173761\n",
      "31325it [59:40,  8.76it/s]Train epoch: 0 [batch #31325, batch_size 1, seq length 2500]\tLoss: 5.262409\n",
      "31350it [59:43,  8.76it/s]Train epoch: 0 [batch #31350, batch_size 1, seq length 2500]\tLoss: 5.229649\n",
      "31375it [59:46,  8.76it/s]Train epoch: 0 [batch #31375, batch_size 1, seq length 2500]\tLoss: 5.190508\n",
      "31400it [59:49,  8.75it/s]Train epoch: 0 [batch #31400, batch_size 1, seq length 2500]\tLoss: 5.705794\n",
      "31425it [59:52,  8.77it/s]Train epoch: 0 [batch #31425, batch_size 1, seq length 2500]\tLoss: 5.304115\n",
      "31450it [59:54,  8.71it/s]Train epoch: 0 [batch #31450, batch_size 1, seq length 2500]\tLoss: 5.140491\n",
      "31475it [59:57,  8.77it/s]Train epoch: 0 [batch #31475, batch_size 1, seq length 2500]\tLoss: 5.417460\n",
      "31500it [1:00:00,  8.76it/s]Train epoch: 0 [batch #31500, batch_size 1, seq length 2500]\tLoss: 5.497420\n",
      "31525it [1:00:03,  8.70it/s]Train epoch: 0 [batch #31525, batch_size 1, seq length 2500]\tLoss: 5.499433\n",
      "31550it [1:00:06,  8.74it/s]Train epoch: 0 [batch #31550, batch_size 1, seq length 2500]\tLoss: 5.323336\n",
      "31575it [1:00:09,  8.77it/s]Train epoch: 0 [batch #31575, batch_size 1, seq length 2500]\tLoss: 5.348073\n",
      "31600it [1:00:12,  8.76it/s]Train epoch: 0 [batch #31600, batch_size 1, seq length 2500]\tLoss: 5.589982\n",
      "31625it [1:00:14,  8.76it/s]Train epoch: 0 [batch #31625, batch_size 1, seq length 2500]\tLoss: 5.574791\n",
      "31650it [1:00:17,  8.62it/s]Train epoch: 0 [batch #31650, batch_size 1, seq length 2500]\tLoss: 5.278979\n",
      "31675it [1:00:20,  8.77it/s]Train epoch: 0 [batch #31675, batch_size 1, seq length 2500]\tLoss: 5.179885\n",
      "31700it [1:00:23,  8.76it/s]Train epoch: 0 [batch #31700, batch_size 1, seq length 2500]\tLoss: 5.212232\n",
      "31725it [1:00:26,  8.77it/s]Train epoch: 0 [batch #31725, batch_size 1, seq length 2500]\tLoss: 5.441955\n",
      "31750it [1:00:29,  8.46it/s]Train epoch: 0 [batch #31750, batch_size 1, seq length 2500]\tLoss: 5.413212\n",
      "31775it [1:00:32,  8.75it/s]Train epoch: 0 [batch #31775, batch_size 1, seq length 2500]\tLoss: 5.552411\n",
      "31800it [1:00:35,  8.74it/s]Train epoch: 0 [batch #31800, batch_size 1, seq length 2500]\tLoss: 5.418877\n",
      "31825it [1:00:37,  8.75it/s]Train epoch: 0 [batch #31825, batch_size 1, seq length 2500]\tLoss: 5.485649\n",
      "31850it [1:00:40,  8.76it/s]Train epoch: 0 [batch #31850, batch_size 1, seq length 2500]\tLoss: 5.131397\n",
      "31875it [1:00:43,  8.74it/s]Train epoch: 0 [batch #31875, batch_size 1, seq length 2500]\tLoss: 5.582088\n",
      "31900it [1:00:46,  8.74it/s]Train epoch: 0 [batch #31900, batch_size 1, seq length 2500]\tLoss: 5.192941\n",
      "31925it [1:00:49,  8.76it/s]Train epoch: 0 [batch #31925, batch_size 1, seq length 2500]\tLoss: 5.366230\n",
      "31950it [1:00:52,  8.76it/s]Train epoch: 0 [batch #31950, batch_size 1, seq length 2500]\tLoss: 5.308894\n",
      "31975it [1:00:54,  8.77it/s]Train epoch: 0 [batch #31975, batch_size 1, seq length 2500]\tLoss: 5.303937\n",
      "32000it [1:00:57,  8.75it/s]Train epoch: 0 [batch #32000, batch_size 1, seq length 2500]\tLoss: 5.258906\n",
      "32025it [1:01:00,  8.76it/s]Train epoch: 0 [batch #32025, batch_size 1, seq length 2500]\tLoss: 5.149722\n",
      "32050it [1:01:03,  8.69it/s]Train epoch: 0 [batch #32050, batch_size 1, seq length 2500]\tLoss: 5.249704\n",
      "32075it [1:01:06,  8.77it/s]Train epoch: 0 [batch #32075, batch_size 1, seq length 2500]\tLoss: 5.278782\n",
      "32100it [1:01:09,  8.76it/s]Train epoch: 0 [batch #32100, batch_size 1, seq length 2500]\tLoss: 5.515211\n",
      "32125it [1:01:12,  8.76it/s]Train epoch: 0 [batch #32125, batch_size 1, seq length 2500]\tLoss: 5.409250\n",
      "32150it [1:01:14,  8.76it/s]Train epoch: 0 [batch #32150, batch_size 1, seq length 2500]\tLoss: 5.324289\n",
      "32175it [1:01:17,  8.77it/s]Train epoch: 0 [batch #32175, batch_size 1, seq length 2500]\tLoss: 5.336435\n",
      "32200it [1:01:20,  8.75it/s]Train epoch: 0 [batch #32200, batch_size 1, seq length 2500]\tLoss: 5.074356\n",
      "32225it [1:01:23,  8.78it/s]Train epoch: 0 [batch #32225, batch_size 1, seq length 2500]\tLoss: 5.420643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32250it [1:01:26,  8.77it/s]Train epoch: 0 [batch #32250, batch_size 1, seq length 2500]\tLoss: 5.215317\n",
      "32275it [1:01:29,  8.63it/s]Train epoch: 0 [batch #32275, batch_size 1, seq length 2500]\tLoss: 5.082062\n",
      "32300it [1:01:32,  8.78it/s]Train epoch: 0 [batch #32300, batch_size 1, seq length 2500]\tLoss: 5.509199\n",
      "32325it [1:01:34,  8.76it/s]Train epoch: 0 [batch #32325, batch_size 1, seq length 2500]\tLoss: 5.316428\n",
      "32350it [1:01:37,  8.73it/s]Train epoch: 0 [batch #32350, batch_size 1, seq length 2500]\tLoss: 5.465279\n",
      "32375it [1:01:40,  8.74it/s]Train epoch: 0 [batch #32375, batch_size 1, seq length 2500]\tLoss: 4.981320\n",
      "32400it [1:01:43,  8.74it/s]Train epoch: 0 [batch #32400, batch_size 1, seq length 2500]\tLoss: 5.355024\n",
      "32425it [1:01:46,  8.75it/s]Train epoch: 0 [batch #32425, batch_size 1, seq length 2500]\tLoss: 4.937742\n",
      "32450it [1:01:49,  8.75it/s]Train epoch: 0 [batch #32450, batch_size 1, seq length 2500]\tLoss: 5.464174\n",
      "32475it [1:01:52,  8.78it/s]Train epoch: 0 [batch #32475, batch_size 1, seq length 2500]\tLoss: 5.174715\n",
      "32500it [1:01:54,  8.75it/s]Train epoch: 0 [batch #32500, batch_size 1, seq length 2500]\tLoss: 5.032581\n",
      "32525it [1:01:57,  8.77it/s]Train epoch: 0 [batch #32525, batch_size 1, seq length 2500]\tLoss: 5.197589\n",
      "32550it [1:02:00,  8.73it/s]Train epoch: 0 [batch #32550, batch_size 1, seq length 2500]\tLoss: 5.610735\n",
      "32575it [1:02:03,  8.77it/s]Train epoch: 0 [batch #32575, batch_size 1, seq length 2500]\tLoss: 5.355078\n",
      "32600it [1:02:06,  8.77it/s]Train epoch: 0 [batch #32600, batch_size 1, seq length 2500]\tLoss: 5.363383\n",
      "32625it [1:02:09,  8.76it/s]Train epoch: 0 [batch #32625, batch_size 1, seq length 2500]\tLoss: 5.340883\n",
      "32650it [1:02:12,  8.77it/s]Train epoch: 0 [batch #32650, batch_size 1, seq length 2500]\tLoss: 5.414683\n",
      "32675it [1:02:14,  8.76it/s]Train epoch: 0 [batch #32675, batch_size 1, seq length 2500]\tLoss: 5.300778\n",
      "32700it [1:02:17,  8.77it/s]Train epoch: 0 [batch #32700, batch_size 1, seq length 2500]\tLoss: 5.418237\n",
      "32725it [1:02:20,  8.76it/s]Train epoch: 0 [batch #32725, batch_size 1, seq length 2500]\tLoss: 5.232488\n",
      "32750it [1:02:23,  8.78it/s]Train epoch: 0 [batch #32750, batch_size 1, seq length 2500]\tLoss: 5.202471\n",
      "32775it [1:02:26,  8.77it/s]Train epoch: 0 [batch #32775, batch_size 1, seq length 2500]\tLoss: 5.316893\n",
      "32800it [1:02:29,  8.73it/s]Train epoch: 0 [batch #32800, batch_size 1, seq length 2500]\tLoss: 5.350122\n",
      "32825it [1:02:32,  8.78it/s]Train epoch: 0 [batch #32825, batch_size 1, seq length 2500]\tLoss: 5.284425\n",
      "32850it [1:02:34,  8.77it/s]Train epoch: 0 [batch #32850, batch_size 1, seq length 2500]\tLoss: 5.239046\n",
      "32875it [1:02:37,  8.77it/s]Train epoch: 0 [batch #32875, batch_size 1, seq length 2500]\tLoss: 5.313867\n",
      "32900it [1:02:40,  8.76it/s]Train epoch: 0 [batch #32900, batch_size 1, seq length 2500]\tLoss: 5.488215\n",
      "32925it [1:02:43,  8.78it/s]Train epoch: 0 [batch #32925, batch_size 1, seq length 2500]\tLoss: 5.280268\n",
      "32950it [1:02:46,  8.62it/s]Train epoch: 0 [batch #32950, batch_size 1, seq length 2500]\tLoss: 5.386206\n",
      "32975it [1:02:49,  8.77it/s]Train epoch: 0 [batch #32975, batch_size 1, seq length 2500]\tLoss: 5.511303\n",
      "33000it [1:02:52,  8.74it/s]Train epoch: 0 [batch #33000, batch_size 1, seq length 2500]\tLoss: 5.251839\n",
      "33025it [1:02:54,  8.75it/s]Train epoch: 0 [batch #33025, batch_size 1, seq length 2500]\tLoss: 5.250312\n",
      "33050it [1:02:57,  8.72it/s]Train epoch: 0 [batch #33050, batch_size 1, seq length 2500]\tLoss: 5.338122\n",
      "33075it [1:03:00,  8.77it/s]Train epoch: 0 [batch #33075, batch_size 1, seq length 2500]\tLoss: 5.057001\n",
      "33100it [1:03:03,  8.74it/s]Train epoch: 0 [batch #33100, batch_size 1, seq length 2500]\tLoss: 5.259093\n",
      "33125it [1:03:06,  8.74it/s]Train epoch: 0 [batch #33125, batch_size 1, seq length 2500]\tLoss: 5.368549\n",
      "33150it [1:03:09,  8.78it/s]Train epoch: 0 [batch #33150, batch_size 1, seq length 2500]\tLoss: 5.437259\n",
      "33175it [1:03:12,  8.78it/s]Train epoch: 0 [batch #33175, batch_size 1, seq length 2500]\tLoss: 5.108199\n",
      "33200it [1:03:14,  8.77it/s]Train epoch: 0 [batch #33200, batch_size 1, seq length 2500]\tLoss: 5.095710\n",
      "33225it [1:03:17,  8.72it/s]Train epoch: 0 [batch #33225, batch_size 1, seq length 2500]\tLoss: 5.126120\n",
      "33250it [1:03:20,  8.76it/s]Train epoch: 0 [batch #33250, batch_size 1, seq length 2500]\tLoss: 4.905126\n",
      "33275it [1:03:23,  8.72it/s]Train epoch: 0 [batch #33275, batch_size 1, seq length 2500]\tLoss: 5.240490\n",
      "33300it [1:03:26,  8.76it/s]Train epoch: 0 [batch #33300, batch_size 1, seq length 2500]\tLoss: 5.039833\n",
      "33325it [1:03:29,  8.77it/s]Train epoch: 0 [batch #33325, batch_size 1, seq length 2500]\tLoss: 5.383881\n",
      "33350it [1:03:32,  8.78it/s]Train epoch: 0 [batch #33350, batch_size 1, seq length 2500]\tLoss: 5.307459\n",
      "33375it [1:03:34,  8.73it/s]Train epoch: 0 [batch #33375, batch_size 1, seq length 2500]\tLoss: 5.434049\n",
      "33400it [1:03:37,  8.77it/s]Train epoch: 0 [batch #33400, batch_size 1, seq length 2500]\tLoss: 5.013129\n",
      "33425it [1:03:40,  8.78it/s]Train epoch: 0 [batch #33425, batch_size 1, seq length 2500]\tLoss: 5.178526\n",
      "33450it [1:03:43,  8.74it/s]Train epoch: 0 [batch #33450, batch_size 1, seq length 2500]\tLoss: 5.538787\n",
      "33475it [1:03:46,  8.77it/s]Train epoch: 0 [batch #33475, batch_size 1, seq length 2500]\tLoss: 5.219905\n",
      "33500it [1:03:49,  8.78it/s]Train epoch: 0 [batch #33500, batch_size 1, seq length 2500]\tLoss: 5.254622\n",
      "33525it [1:03:52,  8.77it/s]Train epoch: 0 [batch #33525, batch_size 1, seq length 2500]\tLoss: 5.360162\n",
      "33550it [1:03:54,  8.80it/s]Train epoch: 0 [batch #33550, batch_size 1, seq length 2500]\tLoss: 5.061860\n",
      "33575it [1:03:57,  8.76it/s]Train epoch: 0 [batch #33575, batch_size 1, seq length 2500]\tLoss: 5.337968\n",
      "33600it [1:04:00,  8.76it/s]Train epoch: 0 [batch #33600, batch_size 1, seq length 2500]\tLoss: 5.176671\n",
      "33625it [1:04:03,  8.77it/s]Train epoch: 0 [batch #33625, batch_size 1, seq length 2500]\tLoss: 5.273326\n",
      "33650it [1:04:06,  8.76it/s]Train epoch: 0 [batch #33650, batch_size 1, seq length 2500]\tLoss: 5.325298\n",
      "33675it [1:04:09,  8.77it/s]Train epoch: 0 [batch #33675, batch_size 1, seq length 2500]\tLoss: 5.155060\n",
      "33700it [1:04:12,  8.73it/s]Train epoch: 0 [batch #33700, batch_size 1, seq length 2500]\tLoss: 5.257721\n",
      "33725it [1:04:14,  8.76it/s]Train epoch: 0 [batch #33725, batch_size 1, seq length 2500]\tLoss: 4.968968\n",
      "33750it [1:04:17,  8.75it/s]Train epoch: 0 [batch #33750, batch_size 1, seq length 2500]\tLoss: 5.266478\n",
      "33775it [1:04:20,  8.75it/s]Train epoch: 0 [batch #33775, batch_size 1, seq length 2500]\tLoss: 5.424830\n",
      "33800it [1:04:23,  8.70it/s]Train epoch: 0 [batch #33800, batch_size 1, seq length 2500]\tLoss: 5.237032\n",
      "33825it [1:04:26,  8.75it/s]Train epoch: 0 [batch #33825, batch_size 1, seq length 2500]\tLoss: 5.485773\n",
      "33850it [1:04:29,  8.76it/s]Train epoch: 0 [batch #33850, batch_size 1, seq length 2500]\tLoss: 5.334044\n",
      "33875it [1:04:32,  8.74it/s]Train epoch: 0 [batch #33875, batch_size 1, seq length 2500]\tLoss: 5.105670\n",
      "33900it [1:04:34,  8.76it/s]Train epoch: 0 [batch #33900, batch_size 1, seq length 2500]\tLoss: 5.271417\n",
      "33925it [1:04:37,  8.74it/s]Train epoch: 0 [batch #33925, batch_size 1, seq length 2500]\tLoss: 5.365093\n",
      "33950it [1:04:40,  8.56it/s]Train epoch: 0 [batch #33950, batch_size 1, seq length 2500]\tLoss: 5.174670\n",
      "33975it [1:04:43,  8.70it/s]Train epoch: 0 [batch #33975, batch_size 1, seq length 2500]\tLoss: 5.113933\n",
      "34000it [1:04:46,  8.77it/s]Train epoch: 0 [batch #34000, batch_size 1, seq length 2500]\tLoss: 5.244243\n",
      "34025it [1:04:49,  8.75it/s]Train epoch: 0 [batch #34025, batch_size 1, seq length 2500]\tLoss: 5.466163\n",
      "34050it [1:04:52,  8.76it/s]Train epoch: 0 [batch #34050, batch_size 1, seq length 2500]\tLoss: 5.255487\n",
      "34075it [1:04:54,  8.75it/s]Train epoch: 0 [batch #34075, batch_size 1, seq length 2500]\tLoss: 5.348756\n",
      "34100it [1:04:57,  8.78it/s]Train epoch: 0 [batch #34100, batch_size 1, seq length 2500]\tLoss: 5.377523\n",
      "34125it [1:05:00,  8.76it/s]Train epoch: 0 [batch #34125, batch_size 1, seq length 2500]\tLoss: 5.263918\n",
      "34150it [1:05:03,  8.77it/s]Train epoch: 0 [batch #34150, batch_size 1, seq length 2500]\tLoss: 5.303141\n",
      "34175it [1:05:06,  8.62it/s]Train epoch: 0 [batch #34175, batch_size 1, seq length 2500]\tLoss: 4.938822\n",
      "34200it [1:05:09,  8.77it/s]Train epoch: 0 [batch #34200, batch_size 1, seq length 2500]\tLoss: 5.270690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34225it [1:05:12,  8.78it/s]Train epoch: 0 [batch #34225, batch_size 1, seq length 2500]\tLoss: 5.080325\n",
      "34250it [1:05:14,  8.76it/s]Train epoch: 0 [batch #34250, batch_size 1, seq length 2500]\tLoss: 5.041338\n",
      "34275it [1:05:17,  8.76it/s]Train epoch: 0 [batch #34275, batch_size 1, seq length 2500]\tLoss: 5.161095\n",
      "34300it [1:05:20,  8.77it/s]Train epoch: 0 [batch #34300, batch_size 1, seq length 2500]\tLoss: 5.302970\n",
      "34325it [1:05:23,  8.77it/s]Train epoch: 0 [batch #34325, batch_size 1, seq length 2500]\tLoss: 5.197766\n",
      "34350it [1:05:26,  8.77it/s]Train epoch: 0 [batch #34350, batch_size 1, seq length 2500]\tLoss: 5.332032\n",
      "34375it [1:05:29,  8.59it/s]Train epoch: 0 [batch #34375, batch_size 1, seq length 2500]\tLoss: 5.477349\n",
      "34400it [1:05:32,  8.77it/s]Train epoch: 0 [batch #34400, batch_size 1, seq length 2500]\tLoss: 5.236472\n",
      "34425it [1:05:34,  8.77it/s]Train epoch: 0 [batch #34425, batch_size 1, seq length 2500]\tLoss: 5.125843\n",
      "34450it [1:05:37,  8.78it/s]Train epoch: 0 [batch #34450, batch_size 1, seq length 2500]\tLoss: 5.076692\n",
      "34475it [1:05:40,  8.75it/s]Train epoch: 0 [batch #34475, batch_size 1, seq length 2500]\tLoss: 5.220516\n",
      "34500it [1:05:43,  8.76it/s]Train epoch: 0 [batch #34500, batch_size 1, seq length 2500]\tLoss: 5.031982\n",
      "34525it [1:05:46,  8.74it/s]Train epoch: 0 [batch #34525, batch_size 1, seq length 2500]\tLoss: 5.130519\n",
      "34550it [1:05:49,  8.78it/s]Train epoch: 0 [batch #34550, batch_size 1, seq length 2500]\tLoss: 5.363760\n",
      "34575it [1:05:52,  8.75it/s]Train epoch: 0 [batch #34575, batch_size 1, seq length 2500]\tLoss: 5.195627\n",
      "34600it [1:05:54,  8.66it/s]Train epoch: 0 [batch #34600, batch_size 1, seq length 2500]\tLoss: 5.564157\n",
      "34625it [1:05:57,  8.74it/s]Train epoch: 0 [batch #34625, batch_size 1, seq length 2500]\tLoss: 5.180394\n",
      "34650it [1:06:00,  8.75it/s]Train epoch: 0 [batch #34650, batch_size 1, seq length 2500]\tLoss: 5.324980\n",
      "34675it [1:06:03,  8.64it/s]Train epoch: 0 [batch #34675, batch_size 1, seq length 2500]\tLoss: 5.224945\n",
      "34700it [1:06:06,  8.77it/s]Train epoch: 0 [batch #34700, batch_size 1, seq length 2500]\tLoss: 5.553217\n",
      "34725it [1:06:09,  8.74it/s]Train epoch: 0 [batch #34725, batch_size 1, seq length 2500]\tLoss: 5.184090\n",
      "34750it [1:06:12,  8.78it/s]Train epoch: 0 [batch #34750, batch_size 1, seq length 2500]\tLoss: 5.494172\n",
      "34775it [1:06:15,  8.77it/s]Train epoch: 0 [batch #34775, batch_size 1, seq length 2500]\tLoss: 5.154065\n",
      "34800it [1:06:17,  8.78it/s]Train epoch: 0 [batch #34800, batch_size 1, seq length 2500]\tLoss: 5.406637\n",
      "34825it [1:06:20,  8.76it/s]Train epoch: 0 [batch #34825, batch_size 1, seq length 2500]\tLoss: 5.302741\n",
      "34850it [1:06:23,  8.74it/s]Train epoch: 0 [batch #34850, batch_size 1, seq length 2500]\tLoss: 5.050172\n",
      "34875it [1:06:26,  8.76it/s]Train epoch: 0 [batch #34875, batch_size 1, seq length 2500]\tLoss: 5.136071\n",
      "34900it [1:06:29,  8.77it/s]Train epoch: 0 [batch #34900, batch_size 1, seq length 2500]\tLoss: 5.223255\n",
      "34925it [1:06:32,  8.77it/s]Train epoch: 0 [batch #34925, batch_size 1, seq length 2500]\tLoss: 5.171362\n",
      "34950it [1:06:34,  8.75it/s]Train epoch: 0 [batch #34950, batch_size 1, seq length 2500]\tLoss: 5.249583\n",
      "34975it [1:06:37,  8.77it/s]Train epoch: 0 [batch #34975, batch_size 1, seq length 2500]\tLoss: 5.248673\n",
      "35000it [1:06:40,  8.69it/s]Train epoch: 0 [batch #35000, batch_size 1, seq length 2500]\tLoss: 5.060766\n",
      "35025it [1:06:43,  8.72it/s]Train epoch: 0 [batch #35025, batch_size 1, seq length 2500]\tLoss: 5.171062\n",
      "35050it [1:06:46,  8.78it/s]Train epoch: 0 [batch #35050, batch_size 1, seq length 2500]\tLoss: 5.457424\n",
      "35075it [1:06:49,  8.72it/s]Train epoch: 0 [batch #35075, batch_size 1, seq length 2500]\tLoss: 5.149490\n",
      "35100it [1:06:52,  8.76it/s]Train epoch: 0 [batch #35100, batch_size 1, seq length 2500]\tLoss: 5.394405\n",
      "35125it [1:06:54,  8.77it/s]Train epoch: 0 [batch #35125, batch_size 1, seq length 2500]\tLoss: 5.101311\n",
      "35150it [1:06:57,  8.72it/s]Train epoch: 0 [batch #35150, batch_size 1, seq length 2500]\tLoss: 5.288935\n",
      "35175it [1:07:00,  8.69it/s]Train epoch: 0 [batch #35175, batch_size 1, seq length 2500]\tLoss: 5.043648\n",
      "35200it [1:07:03,  8.77it/s]Train epoch: 0 [batch #35200, batch_size 1, seq length 2500]\tLoss: 5.073468\n",
      "35225it [1:07:06,  8.78it/s]Train epoch: 0 [batch #35225, batch_size 1, seq length 2500]\tLoss: 5.214678\n",
      "35250it [1:07:09,  8.75it/s]Train epoch: 0 [batch #35250, batch_size 1, seq length 2500]\tLoss: 5.099947\n",
      "35275it [1:07:12,  8.79it/s]Train epoch: 0 [batch #35275, batch_size 1, seq length 2500]\tLoss: 5.364624\n",
      "35300it [1:07:14,  8.74it/s]Train epoch: 0 [batch #35300, batch_size 1, seq length 2500]\tLoss: 5.196645\n",
      "35325it [1:07:17,  8.77it/s]Train epoch: 0 [batch #35325, batch_size 1, seq length 2500]\tLoss: 5.201983\n",
      "35350it [1:07:20,  8.77it/s]Train epoch: 0 [batch #35350, batch_size 1, seq length 2500]\tLoss: 5.247627\n",
      "35375it [1:07:23,  8.77it/s]Train epoch: 0 [batch #35375, batch_size 1, seq length 2500]\tLoss: 5.306502\n",
      "35400it [1:07:26,  8.78it/s]Train epoch: 0 [batch #35400, batch_size 1, seq length 2500]\tLoss: 5.246745\n",
      "35425it [1:07:29,  8.75it/s]Train epoch: 0 [batch #35425, batch_size 1, seq length 2500]\tLoss: 5.319430\n",
      "35450it [1:07:32,  8.75it/s]Train epoch: 0 [batch #35450, batch_size 1, seq length 2500]\tLoss: 4.609538\n",
      "35475it [1:07:34,  8.77it/s]Train epoch: 0 [batch #35475, batch_size 1, seq length 2500]\tLoss: 5.214969\n",
      "35500it [1:07:37,  8.74it/s]Train epoch: 0 [batch #35500, batch_size 1, seq length 2500]\tLoss: 5.131561\n",
      "35525it [1:07:40,  8.78it/s]Train epoch: 0 [batch #35525, batch_size 1, seq length 2500]\tLoss: 5.556958\n",
      "35550it [1:07:43,  8.75it/s]Train epoch: 0 [batch #35550, batch_size 1, seq length 2500]\tLoss: 5.076916\n",
      "35575it [1:07:46,  8.72it/s]Train epoch: 0 [batch #35575, batch_size 1, seq length 2500]\tLoss: 5.160100\n",
      "35600it [1:07:49,  8.75it/s]Train epoch: 0 [batch #35600, batch_size 1, seq length 2500]\tLoss: 5.203536\n",
      "35625it [1:07:52,  8.77it/s]Train epoch: 0 [batch #35625, batch_size 1, seq length 2500]\tLoss: 5.350711\n",
      "35650it [1:07:54,  8.74it/s]Train epoch: 0 [batch #35650, batch_size 1, seq length 2500]\tLoss: 5.069775\n",
      "35675it [1:07:57,  8.77it/s]Train epoch: 0 [batch #35675, batch_size 1, seq length 2500]\tLoss: 5.244573\n",
      "35700it [1:08:00,  8.71it/s]Train epoch: 0 [batch #35700, batch_size 1, seq length 2500]\tLoss: 5.283333\n",
      "35725it [1:08:03,  8.78it/s]Train epoch: 0 [batch #35725, batch_size 1, seq length 2500]\tLoss: 5.250392\n",
      "35750it [1:08:06,  8.76it/s]Train epoch: 0 [batch #35750, batch_size 1, seq length 2500]\tLoss: 5.093097\n",
      "35775it [1:08:09,  8.76it/s]Train epoch: 0 [batch #35775, batch_size 1, seq length 2500]\tLoss: 5.156794\n",
      "35800it [1:08:12,  8.77it/s]Train epoch: 0 [batch #35800, batch_size 1, seq length 2500]\tLoss: 5.001849\n",
      "35825it [1:08:14,  8.78it/s]Train epoch: 0 [batch #35825, batch_size 1, seq length 2500]\tLoss: 5.017311\n",
      "35850it [1:08:17,  8.75it/s]Train epoch: 0 [batch #35850, batch_size 1, seq length 2500]\tLoss: 5.195469\n",
      "35875it [1:08:20,  8.77it/s]Train epoch: 0 [batch #35875, batch_size 1, seq length 2500]\tLoss: 5.482056\n",
      "35900it [1:08:23,  8.75it/s]Train epoch: 0 [batch #35900, batch_size 1, seq length 2500]\tLoss: 5.300133\n",
      "35925it [1:08:26,  8.78it/s]Train epoch: 0 [batch #35925, batch_size 1, seq length 2500]\tLoss: 5.044334\n",
      "35950it [1:08:29,  8.77it/s]Train epoch: 0 [batch #35950, batch_size 1, seq length 2500]\tLoss: 4.934626\n",
      "35975it [1:08:32,  8.73it/s]Train epoch: 0 [batch #35975, batch_size 1, seq length 2500]\tLoss: 5.091459\n",
      "36000it [1:08:34,  8.76it/s]Train epoch: 0 [batch #36000, batch_size 1, seq length 2500]\tLoss: 5.294814\n",
      "36025it [1:08:37,  8.78it/s]Train epoch: 0 [batch #36025, batch_size 1, seq length 2500]\tLoss: 4.998684\n",
      "36050it [1:08:40,  8.77it/s]Train epoch: 0 [batch #36050, batch_size 1, seq length 2500]\tLoss: 5.249500\n",
      "36075it [1:08:43,  8.77it/s]Train epoch: 0 [batch #36075, batch_size 1, seq length 2500]\tLoss: 5.479041\n",
      "36100it [1:08:46,  8.71it/s]Train epoch: 0 [batch #36100, batch_size 1, seq length 2500]\tLoss: 5.217062\n",
      "36125it [1:08:49,  8.78it/s]Train epoch: 0 [batch #36125, batch_size 1, seq length 2500]\tLoss: 5.165980\n",
      "36150it [1:08:52,  8.77it/s]Train epoch: 0 [batch #36150, batch_size 1, seq length 2500]\tLoss: 5.059503\n",
      "36175it [1:08:54,  8.63it/s]Train epoch: 0 [batch #36175, batch_size 1, seq length 2500]\tLoss: 4.970066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36200it [1:08:57,  8.74it/s]Train epoch: 0 [batch #36200, batch_size 1, seq length 2500]\tLoss: 5.052518\n",
      "36225it [1:09:00,  8.78it/s]Train epoch: 0 [batch #36225, batch_size 1, seq length 2500]\tLoss: 5.227919\n",
      "36250it [1:09:03,  8.77it/s]Train epoch: 0 [batch #36250, batch_size 1, seq length 2500]\tLoss: 5.151323\n",
      "36275it [1:09:06,  8.63it/s]Train epoch: 0 [batch #36275, batch_size 1, seq length 2500]\tLoss: 5.109637\n",
      "36300it [1:09:09,  8.78it/s]Train epoch: 0 [batch #36300, batch_size 1, seq length 2500]\tLoss: 5.215601\n",
      "36325it [1:09:12,  8.69it/s]Train epoch: 0 [batch #36325, batch_size 1, seq length 2500]\tLoss: 4.970236\n",
      "36350it [1:09:14,  8.64it/s]Train epoch: 0 [batch #36350, batch_size 1, seq length 2500]\tLoss: 5.293339\n",
      "36375it [1:09:17,  8.74it/s]Train epoch: 0 [batch #36375, batch_size 1, seq length 2500]\tLoss: 5.071507\n",
      "36400it [1:09:20,  8.75it/s]Train epoch: 0 [batch #36400, batch_size 1, seq length 2500]\tLoss: 5.104449\n",
      "36425it [1:09:23,  8.70it/s]Train epoch: 0 [batch #36425, batch_size 1, seq length 2500]\tLoss: 5.228864\n",
      "36450it [1:09:26,  8.76it/s]Train epoch: 0 [batch #36450, batch_size 1, seq length 2500]\tLoss: 5.142082\n",
      "36475it [1:09:29,  8.77it/s]Train epoch: 0 [batch #36475, batch_size 1, seq length 2500]\tLoss: 5.216106\n",
      "36500it [1:09:32,  8.78it/s]Train epoch: 0 [batch #36500, batch_size 1, seq length 2500]\tLoss: 5.453057\n",
      "36525it [1:09:34,  8.61it/s]Train epoch: 0 [batch #36525, batch_size 1, seq length 2500]\tLoss: 5.220453\n",
      "36550it [1:09:37,  8.78it/s]Train epoch: 0 [batch #36550, batch_size 1, seq length 2500]\tLoss: 5.232565\n",
      "36575it [1:09:40,  8.78it/s]Train epoch: 0 [batch #36575, batch_size 1, seq length 2500]\tLoss: 5.475231\n",
      "36600it [1:09:43,  8.72it/s]Train epoch: 0 [batch #36600, batch_size 1, seq length 2500]\tLoss: 4.961649\n",
      "36625it [1:09:46,  8.78it/s]Train epoch: 0 [batch #36625, batch_size 1, seq length 2500]\tLoss: 5.185256\n",
      "36650it [1:09:49,  8.75it/s]Train epoch: 0 [batch #36650, batch_size 1, seq length 2500]\tLoss: 5.103595\n",
      "36675it [1:09:52,  8.74it/s]Train epoch: 0 [batch #36675, batch_size 1, seq length 2500]\tLoss: 5.044110\n",
      "36700it [1:09:54,  8.71it/s]Train epoch: 0 [batch #36700, batch_size 1, seq length 2500]\tLoss: 5.102113\n",
      "36725it [1:09:57,  8.77it/s]Train epoch: 0 [batch #36725, batch_size 1, seq length 2500]\tLoss: 5.089241\n",
      "36750it [1:10:00,  8.66it/s]Train epoch: 0 [batch #36750, batch_size 1, seq length 2500]\tLoss: 5.101241\n",
      "36775it [1:10:03,  8.76it/s]Train epoch: 0 [batch #36775, batch_size 1, seq length 2500]\tLoss: 5.237139\n",
      "36800it [1:10:06,  8.76it/s]Train epoch: 0 [batch #36800, batch_size 1, seq length 2500]\tLoss: 5.095668\n",
      "36825it [1:10:09,  8.76it/s]Train epoch: 0 [batch #36825, batch_size 1, seq length 2500]\tLoss: 5.365847\n",
      "36850it [1:10:12,  8.76it/s]Train epoch: 0 [batch #36850, batch_size 1, seq length 2500]\tLoss: 5.163660\n",
      "36875it [1:10:14,  8.75it/s]Train epoch: 0 [batch #36875, batch_size 1, seq length 2500]\tLoss: 5.275561\n",
      "36900it [1:10:17,  8.73it/s]Train epoch: 0 [batch #36900, batch_size 1, seq length 2500]\tLoss: 5.047504\n",
      "36925it [1:10:20,  8.77it/s]Train epoch: 0 [batch #36925, batch_size 1, seq length 2500]\tLoss: 5.042937\n",
      "36950it [1:10:23,  8.76it/s]Train epoch: 0 [batch #36950, batch_size 1, seq length 2500]\tLoss: 5.308896\n",
      "36975it [1:10:26,  8.78it/s]Train epoch: 0 [batch #36975, batch_size 1, seq length 2500]\tLoss: 5.047104\n",
      "37000it [1:10:29,  8.77it/s]Train epoch: 0 [batch #37000, batch_size 1, seq length 2500]\tLoss: 5.090559\n",
      "37025it [1:10:32,  8.75it/s]Train epoch: 0 [batch #37025, batch_size 1, seq length 2500]\tLoss: 5.008431\n",
      "37050it [1:10:35,  8.75it/s]Train epoch: 0 [batch #37050, batch_size 1, seq length 2500]\tLoss: 4.899959\n",
      "37075it [1:10:37,  8.77it/s]Train epoch: 0 [batch #37075, batch_size 1, seq length 2500]\tLoss: 5.109842\n",
      "37100it [1:10:40,  8.76it/s]Train epoch: 0 [batch #37100, batch_size 1, seq length 2500]\tLoss: 5.233255\n",
      "37125it [1:10:43,  8.75it/s]Train epoch: 0 [batch #37125, batch_size 1, seq length 2500]\tLoss: 5.246226\n",
      "37150it [1:10:46,  8.76it/s]Train epoch: 0 [batch #37150, batch_size 1, seq length 2500]\tLoss: 4.954214\n",
      "37175it [1:10:49,  8.73it/s]Train epoch: 0 [batch #37175, batch_size 1, seq length 2500]\tLoss: 5.187823\n",
      "37200it [1:10:52,  8.76it/s]Train epoch: 0 [batch #37200, batch_size 1, seq length 2500]\tLoss: 5.236436\n",
      "37225it [1:10:55,  8.77it/s]Train epoch: 0 [batch #37225, batch_size 1, seq length 2500]\tLoss: 5.142039\n",
      "37250it [1:10:57,  8.77it/s]Train epoch: 0 [batch #37250, batch_size 1, seq length 2500]\tLoss: 5.093756\n",
      "37275it [1:11:00,  8.75it/s]Train epoch: 0 [batch #37275, batch_size 1, seq length 2500]\tLoss: 5.147227\n",
      "37300it [1:11:03,  8.77it/s]Train epoch: 0 [batch #37300, batch_size 1, seq length 2500]\tLoss: 5.085947\n",
      "37325it [1:11:06,  8.77it/s]Train epoch: 0 [batch #37325, batch_size 1, seq length 2500]\tLoss: 5.184694\n",
      "37350it [1:11:09,  8.77it/s]Train epoch: 0 [batch #37350, batch_size 1, seq length 2500]\tLoss: 5.433432\n",
      "37375it [1:11:12,  8.77it/s]Train epoch: 0 [batch #37375, batch_size 1, seq length 2500]\tLoss: 5.241193\n",
      "37400it [1:11:14,  8.76it/s]Train epoch: 0 [batch #37400, batch_size 1, seq length 2500]\tLoss: 5.171926\n",
      "37425it [1:11:17,  8.78it/s]Train epoch: 0 [batch #37425, batch_size 1, seq length 2500]\tLoss: 5.224524\n",
      "37450it [1:11:20,  8.76it/s]Train epoch: 0 [batch #37450, batch_size 1, seq length 2500]\tLoss: 5.059129\n",
      "37475it [1:11:23,  8.76it/s]Train epoch: 0 [batch #37475, batch_size 1, seq length 2500]\tLoss: 5.128755\n",
      "37500it [1:11:26,  8.72it/s]Train epoch: 0 [batch #37500, batch_size 1, seq length 2500]\tLoss: 5.012979\n",
      "37525it [1:11:29,  8.74it/s]Train epoch: 0 [batch #37525, batch_size 1, seq length 2500]\tLoss: 5.229869\n",
      "37550it [1:11:32,  8.76it/s]Train epoch: 0 [batch #37550, batch_size 1, seq length 2500]\tLoss: 4.968593\n",
      "37575it [1:11:34,  8.77it/s]Train epoch: 0 [batch #37575, batch_size 1, seq length 2500]\tLoss: 5.422706\n",
      "37600it [1:11:37,  8.76it/s]Train epoch: 0 [batch #37600, batch_size 1, seq length 2500]\tLoss: 5.306345\n",
      "37625it [1:11:40,  8.73it/s]Train epoch: 0 [batch #37625, batch_size 1, seq length 2500]\tLoss: 5.439661\n",
      "37650it [1:11:43,  8.75it/s]Train epoch: 0 [batch #37650, batch_size 1, seq length 2500]\tLoss: 4.888870\n",
      "37675it [1:11:46,  8.75it/s]Train epoch: 0 [batch #37675, batch_size 1, seq length 2500]\tLoss: 5.400381\n",
      "37700it [1:11:49,  8.74it/s]Train epoch: 0 [batch #37700, batch_size 1, seq length 2500]\tLoss: 5.188383\n",
      "37725it [1:11:52,  8.76it/s]Train epoch: 0 [batch #37725, batch_size 1, seq length 2500]\tLoss: 5.281940\n",
      "37750it [1:11:54,  8.74it/s]Train epoch: 0 [batch #37750, batch_size 1, seq length 2500]\tLoss: 4.876762\n",
      "37775it [1:11:57,  8.76it/s]Train epoch: 0 [batch #37775, batch_size 1, seq length 2500]\tLoss: 5.064911\n",
      "37800it [1:12:00,  8.77it/s]Train epoch: 0 [batch #37800, batch_size 1, seq length 2500]\tLoss: 5.344609\n",
      "37825it [1:12:03,  8.73it/s]Train epoch: 0 [batch #37825, batch_size 1, seq length 2500]\tLoss: 4.975049\n",
      "37850it [1:12:06,  8.77it/s]Train epoch: 0 [batch #37850, batch_size 1, seq length 2500]\tLoss: 5.066853\n",
      "37875it [1:12:09,  8.76it/s]Train epoch: 0 [batch #37875, batch_size 1, seq length 2500]\tLoss: 5.470950\n",
      "37900it [1:12:12,  8.77it/s]Train epoch: 0 [batch #37900, batch_size 1, seq length 2500]\tLoss: 5.064625\n",
      "37925it [1:12:14,  8.74it/s]Train epoch: 0 [batch #37925, batch_size 1, seq length 2500]\tLoss: 5.026301\n",
      "37950it [1:12:17,  8.76it/s]Train epoch: 0 [batch #37950, batch_size 1, seq length 2500]\tLoss: 5.082925\n",
      "37975it [1:12:20,  8.76it/s]Train epoch: 0 [batch #37975, batch_size 1, seq length 2500]\tLoss: 5.240972\n",
      "38000it [1:12:23,  8.73it/s]Train epoch: 0 [batch #38000, batch_size 1, seq length 2500]\tLoss: 5.086745\n",
      "38025it [1:12:26,  8.72it/s]Train epoch: 0 [batch #38025, batch_size 1, seq length 2500]\tLoss: 5.085849\n",
      "38050it [1:12:29,  8.74it/s]Train epoch: 0 [batch #38050, batch_size 1, seq length 2500]\tLoss: 5.331571\n",
      "38075it [1:12:32,  8.77it/s]Train epoch: 0 [batch #38075, batch_size 1, seq length 2500]\tLoss: 5.030549\n",
      "38100it [1:12:34,  8.76it/s]Train epoch: 0 [batch #38100, batch_size 1, seq length 2500]\tLoss: 5.100642\n",
      "38125it [1:12:37,  8.71it/s]Train epoch: 0 [batch #38125, batch_size 1, seq length 2500]\tLoss: 5.102315\n",
      "38150it [1:12:40,  8.73it/s]Train epoch: 0 [batch #38150, batch_size 1, seq length 2500]\tLoss: 5.127047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38175it [1:12:43,  8.76it/s]Train epoch: 0 [batch #38175, batch_size 1, seq length 2500]\tLoss: 5.086089\n",
      "38200it [1:12:46,  8.74it/s]Train epoch: 0 [batch #38200, batch_size 1, seq length 2500]\tLoss: 5.111672\n",
      "38225it [1:12:49,  8.77it/s]Train epoch: 0 [batch #38225, batch_size 1, seq length 2500]\tLoss: 4.951957\n",
      "38250it [1:12:52,  8.78it/s]Train epoch: 0 [batch #38250, batch_size 1, seq length 2500]\tLoss: 4.787132\n",
      "38275it [1:12:54,  8.75it/s]Train epoch: 0 [batch #38275, batch_size 1, seq length 2500]\tLoss: 5.135259\n",
      "38300it [1:12:57,  8.74it/s]Train epoch: 0 [batch #38300, batch_size 1, seq length 2500]\tLoss: 5.246671\n",
      "38325it [1:13:00,  8.76it/s]Train epoch: 0 [batch #38325, batch_size 1, seq length 2500]\tLoss: 5.104048\n",
      "38350it [1:13:03,  8.76it/s]Train epoch: 0 [batch #38350, batch_size 1, seq length 2500]\tLoss: 5.107870\n",
      "38375it [1:13:06,  8.76it/s]Train epoch: 0 [batch #38375, batch_size 1, seq length 2500]\tLoss: 5.240309\n",
      "38400it [1:13:09,  8.77it/s]Train epoch: 0 [batch #38400, batch_size 1, seq length 2500]\tLoss: 5.314732\n",
      "38425it [1:13:12,  8.76it/s]Train epoch: 0 [batch #38425, batch_size 1, seq length 2500]\tLoss: 4.814222\n",
      "38450it [1:13:14,  8.71it/s]Train epoch: 0 [batch #38450, batch_size 1, seq length 2500]\tLoss: 5.319016\n",
      "38475it [1:13:17,  8.73it/s]Train epoch: 0 [batch #38475, batch_size 1, seq length 2500]\tLoss: 4.992380\n",
      "38500it [1:13:20,  8.76it/s]Train epoch: 0 [batch #38500, batch_size 1, seq length 2500]\tLoss: 4.993187\n",
      "38525it [1:13:23,  8.75it/s]Train epoch: 0 [batch #38525, batch_size 1, seq length 2500]\tLoss: 4.949421\n",
      "38550it [1:13:26,  8.77it/s]Train epoch: 0 [batch #38550, batch_size 1, seq length 2500]\tLoss: 5.155457\n",
      "38575it [1:13:29,  8.77it/s]Train epoch: 0 [batch #38575, batch_size 1, seq length 2500]\tLoss: 4.953968\n",
      "38600it [1:13:32,  8.77it/s]Train epoch: 0 [batch #38600, batch_size 1, seq length 2500]\tLoss: 4.965102\n",
      "38625it [1:13:34,  8.77it/s]Train epoch: 0 [batch #38625, batch_size 1, seq length 2500]\tLoss: 4.944117\n",
      "38650it [1:13:37,  8.74it/s]Train epoch: 0 [batch #38650, batch_size 1, seq length 2500]\tLoss: 5.091734\n",
      "38675it [1:13:40,  8.75it/s]Train epoch: 0 [batch #38675, batch_size 1, seq length 2500]\tLoss: 5.331672\n",
      "38700it [1:13:43,  8.75it/s]Train epoch: 0 [batch #38700, batch_size 1, seq length 2500]\tLoss: 5.204848\n",
      "38725it [1:13:46,  8.77it/s]Train epoch: 0 [batch #38725, batch_size 1, seq length 2500]\tLoss: 4.548779\n",
      "38750it [1:13:49,  8.75it/s]Train epoch: 0 [batch #38750, batch_size 1, seq length 2500]\tLoss: 5.005475\n",
      "38775it [1:13:51,  8.77it/s]Train epoch: 0 [batch #38775, batch_size 1, seq length 2500]\tLoss: 4.987604\n",
      "38800it [1:13:54,  8.78it/s]Train epoch: 0 [batch #38800, batch_size 1, seq length 2500]\tLoss: 5.267583\n",
      "38825it [1:13:57,  8.76it/s]Train epoch: 0 [batch #38825, batch_size 1, seq length 2500]\tLoss: 5.178948\n",
      "38850it [1:14:00,  8.77it/s]Train epoch: 0 [batch #38850, batch_size 1, seq length 2500]\tLoss: 4.928858\n",
      "38875it [1:14:03,  8.77it/s]Train epoch: 0 [batch #38875, batch_size 1, seq length 2500]\tLoss: 4.992881\n",
      "38900it [1:14:06,  8.78it/s]Train epoch: 0 [batch #38900, batch_size 1, seq length 2500]\tLoss: 5.106842\n",
      "38925it [1:14:09,  8.76it/s]Train epoch: 0 [batch #38925, batch_size 1, seq length 2500]\tLoss: 5.168703\n",
      "38950it [1:14:11,  8.74it/s]Train epoch: 0 [batch #38950, batch_size 1, seq length 2500]\tLoss: 5.118783\n",
      "38975it [1:14:14,  8.78it/s]Train epoch: 0 [batch #38975, batch_size 1, seq length 2500]\tLoss: 5.120974\n",
      "39000it [1:14:17,  8.76it/s]Train epoch: 0 [batch #39000, batch_size 1, seq length 2500]\tLoss: 4.901306\n",
      "39025it [1:14:20,  8.77it/s]Train epoch: 0 [batch #39025, batch_size 1, seq length 2500]\tLoss: 4.996069\n",
      "39050it [1:14:23,  8.77it/s]Train epoch: 0 [batch #39050, batch_size 1, seq length 2500]\tLoss: 5.233289\n",
      "39075it [1:14:26,  8.77it/s]Train epoch: 0 [batch #39075, batch_size 1, seq length 2500]\tLoss: 5.154154\n",
      "39100it [1:14:29,  8.75it/s]Train epoch: 0 [batch #39100, batch_size 1, seq length 2500]\tLoss: 4.927666\n",
      "39125it [1:14:31,  8.74it/s]Train epoch: 0 [batch #39125, batch_size 1, seq length 2500]\tLoss: 4.929286\n",
      "39150it [1:14:34,  8.77it/s]Train epoch: 0 [batch #39150, batch_size 1, seq length 2500]\tLoss: 5.147596\n",
      "39175it [1:14:37,  8.76it/s]Train epoch: 0 [batch #39175, batch_size 1, seq length 2500]\tLoss: 5.069124\n",
      "39200it [1:14:40,  8.74it/s]Train epoch: 0 [batch #39200, batch_size 1, seq length 2500]\tLoss: 5.235356\n",
      "39225it [1:14:43,  8.71it/s]Train epoch: 0 [batch #39225, batch_size 1, seq length 2500]\tLoss: 5.122759\n",
      "39250it [1:14:46,  8.67it/s]Train epoch: 0 [batch #39250, batch_size 1, seq length 2500]\tLoss: 5.029376\n",
      "39275it [1:14:49,  8.77it/s]Train epoch: 0 [batch #39275, batch_size 1, seq length 2500]\tLoss: 4.906285\n",
      "39300it [1:14:51,  8.75it/s]Train epoch: 0 [batch #39300, batch_size 1, seq length 2500]\tLoss: 4.900991\n",
      "39325it [1:14:54,  8.76it/s]Train epoch: 0 [batch #39325, batch_size 1, seq length 2500]\tLoss: 5.336375\n",
      "39350it [1:14:57,  8.78it/s]Train epoch: 0 [batch #39350, batch_size 1, seq length 2500]\tLoss: 5.403138\n",
      "39375it [1:15:00,  8.78it/s]Train epoch: 0 [batch #39375, batch_size 1, seq length 2500]\tLoss: 4.434362\n",
      "39400it [1:15:03,  8.79it/s]Train epoch: 0 [batch #39400, batch_size 1, seq length 2500]\tLoss: 5.150357\n",
      "39425it [1:15:06,  8.78it/s]Train epoch: 0 [batch #39425, batch_size 1, seq length 2500]\tLoss: 5.107354\n",
      "39450it [1:15:09,  8.78it/s]Train epoch: 0 [batch #39450, batch_size 1, seq length 2500]\tLoss: 5.311599\n",
      "39475it [1:15:11,  8.78it/s]Train epoch: 0 [batch #39475, batch_size 1, seq length 2500]\tLoss: 5.152614\n",
      "39500it [1:15:14,  8.77it/s]Train epoch: 0 [batch #39500, batch_size 1, seq length 2500]\tLoss: 5.049200\n",
      "39525it [1:15:17,  8.78it/s]Train epoch: 0 [batch #39525, batch_size 1, seq length 2500]\tLoss: 5.174100\n",
      "39550it [1:15:20,  8.78it/s]Train epoch: 0 [batch #39550, batch_size 1, seq length 2500]\tLoss: 4.906809\n",
      "39575it [1:15:23,  8.77it/s]Train epoch: 0 [batch #39575, batch_size 1, seq length 2500]\tLoss: 4.947673\n",
      "39600it [1:15:26,  8.77it/s]Train epoch: 0 [batch #39600, batch_size 1, seq length 2500]\tLoss: 4.933678\n",
      "39625it [1:15:29,  8.75it/s]Train epoch: 0 [batch #39625, batch_size 1, seq length 2500]\tLoss: 5.073228\n",
      "39650it [1:15:31,  8.76it/s]Train epoch: 0 [batch #39650, batch_size 1, seq length 2500]\tLoss: 4.644538\n",
      "39675it [1:15:34,  8.76it/s]Train epoch: 0 [batch #39675, batch_size 1, seq length 2500]\tLoss: 4.833814\n",
      "39700it [1:15:37,  8.71it/s]Train epoch: 0 [batch #39700, batch_size 1, seq length 2500]\tLoss: 5.059563\n",
      "39725it [1:15:40,  8.76it/s]Train epoch: 0 [batch #39725, batch_size 1, seq length 2500]\tLoss: 5.301104\n",
      "39750it [1:15:43,  8.77it/s]Train epoch: 0 [batch #39750, batch_size 1, seq length 2500]\tLoss: 4.914754\n",
      "39775it [1:15:46,  8.77it/s]Train epoch: 0 [batch #39775, batch_size 1, seq length 2500]\tLoss: 5.160511\n",
      "39800it [1:15:49,  8.77it/s]Train epoch: 0 [batch #39800, batch_size 1, seq length 2500]\tLoss: 4.982445\n",
      "39825it [1:15:51,  8.75it/s]Train epoch: 0 [batch #39825, batch_size 1, seq length 2500]\tLoss: 5.260525\n",
      "39850it [1:15:54,  8.76it/s]Train epoch: 0 [batch #39850, batch_size 1, seq length 2500]\tLoss: 5.049177\n",
      "39875it [1:15:57,  8.78it/s]Train epoch: 0 [batch #39875, batch_size 1, seq length 2500]\tLoss: 5.017632\n",
      "39900it [1:16:00,  8.75it/s]Train epoch: 0 [batch #39900, batch_size 1, seq length 2500]\tLoss: 4.928777\n",
      "39925it [1:16:03,  8.76it/s]Train epoch: 0 [batch #39925, batch_size 1, seq length 2500]\tLoss: 4.979166\n",
      "39950it [1:16:06,  8.78it/s]Train epoch: 0 [batch #39950, batch_size 1, seq length 2500]\tLoss: 5.275009\n",
      "39975it [1:16:09,  8.75it/s]Train epoch: 0 [batch #39975, batch_size 1, seq length 2500]\tLoss: 5.131399\n",
      "40000it [1:16:11,  8.78it/s]Train epoch: 0 [batch #40000, batch_size 1, seq length 2500]\tLoss: 5.257772\n",
      "40025it [1:16:14,  8.76it/s]Train epoch: 0 [batch #40025, batch_size 1, seq length 2500]\tLoss: 4.924774\n",
      "40050it [1:16:17,  8.76it/s]Train epoch: 0 [batch #40050, batch_size 1, seq length 2500]\tLoss: 5.215890\n",
      "40075it [1:16:20,  8.76it/s]Train epoch: 0 [batch #40075, batch_size 1, seq length 2500]\tLoss: 5.036004\n",
      "40100it [1:16:23,  8.76it/s]Train epoch: 0 [batch #40100, batch_size 1, seq length 2500]\tLoss: 5.071065\n",
      "40125it [1:16:26,  8.76it/s]Train epoch: 0 [batch #40125, batch_size 1, seq length 2500]\tLoss: 4.661872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40150it [1:16:29,  8.78it/s]Train epoch: 0 [batch #40150, batch_size 1, seq length 2500]\tLoss: 5.434927\n",
      "40175it [1:16:31,  8.77it/s]Train epoch: 0 [batch #40175, batch_size 1, seq length 2500]\tLoss: 4.885627\n",
      "40200it [1:16:34,  8.73it/s]Train epoch: 0 [batch #40200, batch_size 1, seq length 2500]\tLoss: 4.950820\n",
      "40225it [1:16:37,  8.78it/s]Train epoch: 0 [batch #40225, batch_size 1, seq length 2500]\tLoss: 5.080584\n",
      "40250it [1:16:40,  8.75it/s]Train epoch: 0 [batch #40250, batch_size 1, seq length 2500]\tLoss: 5.043050\n",
      "40275it [1:16:43,  8.70it/s]Train epoch: 0 [batch #40275, batch_size 1, seq length 2500]\tLoss: 4.917031\n",
      "40300it [1:16:46,  8.76it/s]Train epoch: 0 [batch #40300, batch_size 1, seq length 2500]\tLoss: 4.970056\n",
      "40325it [1:16:49,  8.72it/s]Train epoch: 0 [batch #40325, batch_size 1, seq length 2500]\tLoss: 5.061126\n",
      "40350it [1:16:51,  8.71it/s]Train epoch: 0 [batch #40350, batch_size 1, seq length 2500]\tLoss: 4.951272\n",
      "40375it [1:16:54,  8.76it/s]Train epoch: 0 [batch #40375, batch_size 1, seq length 2500]\tLoss: 4.874912\n",
      "40400it [1:16:57,  8.75it/s]Train epoch: 0 [batch #40400, batch_size 1, seq length 2500]\tLoss: 4.966950\n",
      "40425it [1:17:00,  8.78it/s]Train epoch: 0 [batch #40425, batch_size 1, seq length 2500]\tLoss: 5.295362\n",
      "40450it [1:17:03,  8.75it/s]Train epoch: 0 [batch #40450, batch_size 1, seq length 2500]\tLoss: 5.009234\n",
      "40475it [1:17:06,  8.73it/s]Train epoch: 0 [batch #40475, batch_size 1, seq length 2500]\tLoss: 5.058596\n",
      "40500it [1:17:09,  8.78it/s]Train epoch: 0 [batch #40500, batch_size 1, seq length 2500]\tLoss: 5.124034\n",
      "40525it [1:17:11,  8.74it/s]Train epoch: 0 [batch #40525, batch_size 1, seq length 2500]\tLoss: 5.076580\n",
      "40550it [1:17:14,  8.76it/s]Train epoch: 0 [batch #40550, batch_size 1, seq length 2500]\tLoss: 4.912622\n",
      "40575it [1:17:17,  8.74it/s]Train epoch: 0 [batch #40575, batch_size 1, seq length 2500]\tLoss: 5.194721\n",
      "40600it [1:17:20,  8.77it/s]Train epoch: 0 [batch #40600, batch_size 1, seq length 2500]\tLoss: 5.292393\n",
      "40625it [1:17:23,  8.78it/s]Train epoch: 0 [batch #40625, batch_size 1, seq length 2500]\tLoss: 4.832369\n",
      "40650it [1:17:26,  8.66it/s]Train epoch: 0 [batch #40650, batch_size 1, seq length 2500]\tLoss: 5.268683\n",
      "40675it [1:17:29,  8.77it/s]Train epoch: 0 [batch #40675, batch_size 1, seq length 2500]\tLoss: 5.354852\n",
      "40700it [1:17:31,  8.75it/s]Train epoch: 0 [batch #40700, batch_size 1, seq length 2500]\tLoss: 5.086276\n",
      "40725it [1:17:34,  8.76it/s]Train epoch: 0 [batch #40725, batch_size 1, seq length 2500]\tLoss: 5.066415\n",
      "40750it [1:17:37,  8.72it/s]Train epoch: 0 [batch #40750, batch_size 1, seq length 2500]\tLoss: 5.112266\n",
      "40775it [1:17:40,  8.72it/s]Train epoch: 0 [batch #40775, batch_size 1, seq length 2500]\tLoss: 4.984526\n",
      "40800it [1:17:43,  8.76it/s]Train epoch: 0 [batch #40800, batch_size 1, seq length 2500]\tLoss: 5.143603\n",
      "40825it [1:17:46,  8.76it/s]Train epoch: 0 [batch #40825, batch_size 1, seq length 2500]\tLoss: 5.071283\n",
      "40850it [1:17:49,  8.76it/s]Train epoch: 0 [batch #40850, batch_size 1, seq length 2500]\tLoss: 5.105619\n",
      "40875it [1:17:51,  8.76it/s]Train epoch: 0 [batch #40875, batch_size 1, seq length 2500]\tLoss: 5.001753\n",
      "40900it [1:17:54,  8.76it/s]Train epoch: 0 [batch #40900, batch_size 1, seq length 2500]\tLoss: 4.827247\n",
      "40925it [1:17:57,  8.77it/s]Train epoch: 0 [batch #40925, batch_size 1, seq length 2500]\tLoss: 5.103278\n",
      "40950it [1:18:00,  8.77it/s]Train epoch: 0 [batch #40950, batch_size 1, seq length 2500]\tLoss: 4.955475\n",
      "40975it [1:18:03,  8.53it/s]Train epoch: 0 [batch #40975, batch_size 1, seq length 2500]\tLoss: 5.023514\n",
      "41000it [1:18:06,  8.74it/s]Train epoch: 0 [batch #41000, batch_size 1, seq length 2500]\tLoss: 5.026744\n",
      "41025it [1:18:09,  8.70it/s]Train epoch: 0 [batch #41025, batch_size 1, seq length 2500]\tLoss: 5.119260\n",
      "41050it [1:18:11,  8.77it/s]Train epoch: 0 [batch #41050, batch_size 1, seq length 2500]\tLoss: 4.688487\n",
      "41075it [1:18:14,  8.70it/s]Train epoch: 0 [batch #41075, batch_size 1, seq length 2500]\tLoss: 5.001975\n",
      "41100it [1:18:17,  8.77it/s]Train epoch: 0 [batch #41100, batch_size 1, seq length 2500]\tLoss: 5.338177\n",
      "41125it [1:18:20,  8.77it/s]Train epoch: 0 [batch #41125, batch_size 1, seq length 2500]\tLoss: 4.763691\n",
      "41150it [1:18:23,  8.77it/s]Train epoch: 0 [batch #41150, batch_size 1, seq length 2500]\tLoss: 5.142572\n",
      "41175it [1:18:26,  8.76it/s]Train epoch: 0 [batch #41175, batch_size 1, seq length 2500]\tLoss: 4.852932\n",
      "41200it [1:18:29,  8.76it/s]Train epoch: 0 [batch #41200, batch_size 1, seq length 2500]\tLoss: 4.839494\n",
      "41225it [1:18:31,  8.77it/s]Train epoch: 0 [batch #41225, batch_size 1, seq length 2500]\tLoss: 4.975122\n",
      "41250it [1:18:34,  8.74it/s]Train epoch: 0 [batch #41250, batch_size 1, seq length 2500]\tLoss: 4.782943\n",
      "41275it [1:18:37,  8.74it/s]Train epoch: 0 [batch #41275, batch_size 1, seq length 2500]\tLoss: 5.031811\n",
      "41300it [1:18:40,  8.74it/s]Train epoch: 0 [batch #41300, batch_size 1, seq length 2500]\tLoss: 5.014529\n",
      "41325it [1:18:43,  8.76it/s]Train epoch: 0 [batch #41325, batch_size 1, seq length 2500]\tLoss: 4.915469\n",
      "41350it [1:18:46,  8.76it/s]Train epoch: 0 [batch #41350, batch_size 1, seq length 2500]\tLoss: 4.987168\n",
      "41375it [1:18:49,  8.78it/s]Train epoch: 0 [batch #41375, batch_size 1, seq length 2500]\tLoss: 4.948255\n",
      "41400it [1:18:51,  8.71it/s]Train epoch: 0 [batch #41400, batch_size 1, seq length 2500]\tLoss: 4.914898\n",
      "41425it [1:18:54,  8.76it/s]Train epoch: 0 [batch #41425, batch_size 1, seq length 2500]\tLoss: 5.216426\n",
      "41450it [1:18:57,  8.71it/s]Train epoch: 0 [batch #41450, batch_size 1, seq length 2500]\tLoss: 5.052157\n",
      "41475it [1:19:00,  8.73it/s]Train epoch: 0 [batch #41475, batch_size 1, seq length 2500]\tLoss: 5.215374\n",
      "41500it [1:19:03,  8.78it/s]Train epoch: 0 [batch #41500, batch_size 1, seq length 2500]\tLoss: 4.998196\n",
      "41525it [1:19:06,  8.76it/s]Train epoch: 0 [batch #41525, batch_size 1, seq length 2500]\tLoss: 4.832577\n",
      "41550it [1:19:09,  8.76it/s]Train epoch: 0 [batch #41550, batch_size 1, seq length 2500]\tLoss: 4.874441\n",
      "41575it [1:19:11,  8.78it/s]Train epoch: 0 [batch #41575, batch_size 1, seq length 2500]\tLoss: 4.950118\n",
      "41600it [1:19:14,  8.76it/s]Train epoch: 0 [batch #41600, batch_size 1, seq length 2500]\tLoss: 5.137801\n",
      "41625it [1:19:17,  8.77it/s]Train epoch: 0 [batch #41625, batch_size 1, seq length 2500]\tLoss: 4.940237\n",
      "41650it [1:19:20,  8.78it/s]Train epoch: 0 [batch #41650, batch_size 1, seq length 2500]\tLoss: 5.061040\n",
      "41675it [1:19:23,  8.75it/s]Train epoch: 0 [batch #41675, batch_size 1, seq length 2500]\tLoss: 5.073150\n",
      "41700it [1:19:26,  8.78it/s]Train epoch: 0 [batch #41700, batch_size 1, seq length 2500]\tLoss: 5.035752\n",
      "41725it [1:19:29,  8.68it/s]Train epoch: 0 [batch #41725, batch_size 1, seq length 2500]\tLoss: 4.926551\n",
      "41750it [1:19:31,  8.77it/s]Train epoch: 0 [batch #41750, batch_size 1, seq length 2500]\tLoss: 4.984262\n",
      "41775it [1:19:34,  8.77it/s]Train epoch: 0 [batch #41775, batch_size 1, seq length 2500]\tLoss: 4.778520\n",
      "41800it [1:19:37,  8.77it/s]Train epoch: 0 [batch #41800, batch_size 1, seq length 2500]\tLoss: 4.639284\n",
      "41825it [1:19:40,  8.78it/s]Train epoch: 0 [batch #41825, batch_size 1, seq length 2500]\tLoss: 4.708954\n",
      "41850it [1:19:43,  8.75it/s]Train epoch: 0 [batch #41850, batch_size 1, seq length 2500]\tLoss: 5.025037\n",
      "41875it [1:19:46,  8.74it/s]Train epoch: 0 [batch #41875, batch_size 1, seq length 2500]\tLoss: 4.964889\n",
      "41900it [1:19:49,  8.77it/s]Train epoch: 0 [batch #41900, batch_size 1, seq length 2500]\tLoss: 5.236759\n",
      "41925it [1:19:51,  8.78it/s]Train epoch: 0 [batch #41925, batch_size 1, seq length 2500]\tLoss: 4.979239\n",
      "41950it [1:19:54,  8.70it/s]Train epoch: 0 [batch #41950, batch_size 1, seq length 2500]\tLoss: 4.706810\n",
      "41975it [1:19:57,  8.77it/s]Train epoch: 0 [batch #41975, batch_size 1, seq length 2500]\tLoss: 4.651307\n",
      "42000it [1:20:00,  8.72it/s]Train epoch: 0 [batch #42000, batch_size 1, seq length 2500]\tLoss: 5.245137\n",
      "42025it [1:20:03,  8.71it/s]Train epoch: 0 [batch #42025, batch_size 1, seq length 2500]\tLoss: 5.246457\n",
      "42050it [1:20:06,  8.75it/s]Train epoch: 0 [batch #42050, batch_size 1, seq length 2500]\tLoss: 5.062607\n",
      "42075it [1:20:09,  8.75it/s]Train epoch: 0 [batch #42075, batch_size 1, seq length 2500]\tLoss: 4.896565\n",
      "42100it [1:20:11,  8.77it/s]Train epoch: 0 [batch #42100, batch_size 1, seq length 2500]\tLoss: 4.781989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42125it [1:20:14,  8.65it/s]Train epoch: 0 [batch #42125, batch_size 1, seq length 2500]\tLoss: 5.012333\n",
      "42150it [1:20:17,  8.74it/s]Train epoch: 0 [batch #42150, batch_size 1, seq length 2500]\tLoss: 4.755371\n",
      "42175it [1:20:20,  8.78it/s]Train epoch: 0 [batch #42175, batch_size 1, seq length 2500]\tLoss: 4.862541\n",
      "42200it [1:20:23,  8.78it/s]Train epoch: 0 [batch #42200, batch_size 1, seq length 2500]\tLoss: 5.071296\n",
      "42225it [1:20:26,  8.74it/s]Train epoch: 0 [batch #42225, batch_size 1, seq length 2500]\tLoss: 5.115718\n",
      "42250it [1:20:29,  8.78it/s]Train epoch: 0 [batch #42250, batch_size 1, seq length 2500]\tLoss: 4.951979\n",
      "42275it [1:20:31,  8.73it/s]Train epoch: 0 [batch #42275, batch_size 1, seq length 2500]\tLoss: 5.130140\n",
      "42300it [1:20:34,  8.74it/s]Train epoch: 0 [batch #42300, batch_size 1, seq length 2500]\tLoss: 5.010593\n",
      "42325it [1:20:37,  8.75it/s]Train epoch: 0 [batch #42325, batch_size 1, seq length 2500]\tLoss: 5.003683\n",
      "42350it [1:20:40,  8.64it/s]Train epoch: 0 [batch #42350, batch_size 1, seq length 2500]\tLoss: 5.154084\n",
      "42375it [1:20:43,  8.73it/s]Train epoch: 0 [batch #42375, batch_size 1, seq length 2500]\tLoss: 5.065719\n",
      "42400it [1:20:46,  8.74it/s]Train epoch: 0 [batch #42400, batch_size 1, seq length 2500]\tLoss: 5.033237\n",
      "42425it [1:20:49,  8.77it/s]Train epoch: 0 [batch #42425, batch_size 1, seq length 2500]\tLoss: 4.779757\n",
      "42450it [1:20:51,  8.78it/s]Train epoch: 0 [batch #42450, batch_size 1, seq length 2500]\tLoss: 4.702134\n",
      "42475it [1:20:54,  8.78it/s]Train epoch: 0 [batch #42475, batch_size 1, seq length 2500]\tLoss: 4.796406\n",
      "42500it [1:20:57,  8.77it/s]Train epoch: 0 [batch #42500, batch_size 1, seq length 2500]\tLoss: 4.500443\n",
      "42525it [1:21:00,  8.76it/s]Train epoch: 0 [batch #42525, batch_size 1, seq length 2500]\tLoss: 4.991130\n",
      "42550it [1:21:03,  8.78it/s]Train epoch: 0 [batch #42550, batch_size 1, seq length 2500]\tLoss: 5.187397\n",
      "42575it [1:21:06,  8.76it/s]Train epoch: 0 [batch #42575, batch_size 1, seq length 2500]\tLoss: 4.820676\n",
      "42600it [1:21:09,  8.64it/s]Train epoch: 0 [batch #42600, batch_size 1, seq length 2500]\tLoss: 4.883903\n",
      "42625it [1:21:11,  8.76it/s]Train epoch: 0 [batch #42625, batch_size 1, seq length 2500]\tLoss: 4.968826\n",
      "42650it [1:21:14,  8.76it/s]Train epoch: 0 [batch #42650, batch_size 1, seq length 2500]\tLoss: 4.823425\n",
      "42675it [1:21:17,  8.76it/s]Train epoch: 0 [batch #42675, batch_size 1, seq length 2500]\tLoss: 4.948431\n",
      "42700it [1:21:20,  8.75it/s]Train epoch: 0 [batch #42700, batch_size 1, seq length 2500]\tLoss: 5.006617\n",
      "42725it [1:21:23,  8.76it/s]Train epoch: 0 [batch #42725, batch_size 1, seq length 2500]\tLoss: 4.890105\n",
      "42750it [1:21:26,  8.76it/s]Train epoch: 0 [batch #42750, batch_size 1, seq length 2500]\tLoss: 4.718608\n",
      "42775it [1:21:29,  8.77it/s]Train epoch: 0 [batch #42775, batch_size 1, seq length 2500]\tLoss: 4.823100\n",
      "42800it [1:21:31,  8.62it/s]Train epoch: 0 [batch #42800, batch_size 1, seq length 2500]\tLoss: 4.800124\n",
      "42825it [1:21:34,  8.74it/s]Train epoch: 0 [batch #42825, batch_size 1, seq length 2500]\tLoss: 4.837363\n",
      "42850it [1:21:37,  8.74it/s]Train epoch: 0 [batch #42850, batch_size 1, seq length 2500]\tLoss: 4.939787\n",
      "42875it [1:21:40,  8.77it/s]Train epoch: 0 [batch #42875, batch_size 1, seq length 2500]\tLoss: 5.159127\n",
      "42900it [1:21:43,  8.77it/s]Train epoch: 0 [batch #42900, batch_size 1, seq length 2500]\tLoss: 4.864301\n",
      "42925it [1:21:46,  8.77it/s]Train epoch: 0 [batch #42925, batch_size 1, seq length 2500]\tLoss: 4.935839\n",
      "42950it [1:21:49,  8.76it/s]Train epoch: 0 [batch #42950, batch_size 1, seq length 2500]\tLoss: 5.168680\n",
      "42975it [1:21:51,  8.73it/s]Train epoch: 0 [batch #42975, batch_size 1, seq length 2500]\tLoss: 4.986693\n",
      "43000it [1:21:54,  8.73it/s]Train epoch: 0 [batch #43000, batch_size 1, seq length 2500]\tLoss: 5.061263\n",
      "43025it [1:21:57,  8.76it/s]Train epoch: 0 [batch #43025, batch_size 1, seq length 2500]\tLoss: 4.811502\n",
      "43050it [1:22:00,  8.72it/s]Train epoch: 0 [batch #43050, batch_size 1, seq length 2500]\tLoss: 4.800463\n",
      "43075it [1:22:03,  8.75it/s]Train epoch: 0 [batch #43075, batch_size 1, seq length 2500]\tLoss: 4.951653\n",
      "43100it [1:22:06,  8.78it/s]Train epoch: 0 [batch #43100, batch_size 1, seq length 2500]\tLoss: 4.808918\n",
      "43125it [1:22:09,  8.76it/s]Train epoch: 0 [batch #43125, batch_size 1, seq length 2500]\tLoss: 4.986205\n",
      "43150it [1:22:11,  8.77it/s]Train epoch: 0 [batch #43150, batch_size 1, seq length 2500]\tLoss: 4.848790\n",
      "43175it [1:22:14,  8.75it/s]Train epoch: 0 [batch #43175, batch_size 1, seq length 2500]\tLoss: 4.864479\n",
      "43200it [1:22:17,  8.77it/s]Train epoch: 0 [batch #43200, batch_size 1, seq length 2500]\tLoss: 4.834716\n",
      "43225it [1:22:20,  8.74it/s]Train epoch: 0 [batch #43225, batch_size 1, seq length 2500]\tLoss: 4.984854\n",
      "43250it [1:22:23,  8.76it/s]Train epoch: 0 [batch #43250, batch_size 1, seq length 2500]\tLoss: 4.955363\n",
      "43275it [1:22:26,  8.78it/s]Train epoch: 0 [batch #43275, batch_size 1, seq length 2500]\tLoss: 4.733193\n",
      "43300it [1:22:29,  8.76it/s]Train epoch: 0 [batch #43300, batch_size 1, seq length 2500]\tLoss: 5.011534\n",
      "43325it [1:22:31,  8.77it/s]Train epoch: 0 [batch #43325, batch_size 1, seq length 2500]\tLoss: 4.894196\n",
      "43350it [1:22:34,  8.73it/s]Train epoch: 0 [batch #43350, batch_size 1, seq length 2500]\tLoss: 4.980860\n",
      "43375it [1:22:37,  8.68it/s]Train epoch: 0 [batch #43375, batch_size 1, seq length 2500]\tLoss: 5.048932\n",
      "43400it [1:22:40,  8.74it/s]Train epoch: 0 [batch #43400, batch_size 1, seq length 2500]\tLoss: 5.249098\n",
      "43425it [1:22:43,  8.76it/s]Train epoch: 0 [batch #43425, batch_size 1, seq length 2500]\tLoss: 4.808586\n",
      "43450it [1:22:46,  8.77it/s]Train epoch: 0 [batch #43450, batch_size 1, seq length 2500]\tLoss: 4.610571\n",
      "43475it [1:22:49,  8.71it/s]Train epoch: 0 [batch #43475, batch_size 1, seq length 2500]\tLoss: 4.852702\n",
      "43500it [1:22:52,  8.77it/s]Train epoch: 0 [batch #43500, batch_size 1, seq length 2500]\tLoss: 5.152305\n",
      "43525it [1:22:54,  8.75it/s]Train epoch: 0 [batch #43525, batch_size 1, seq length 2500]\tLoss: 4.890932\n",
      "43550it [1:22:57,  8.74it/s]Train epoch: 0 [batch #43550, batch_size 1, seq length 2500]\tLoss: 4.808731\n",
      "43575it [1:23:00,  8.76it/s]Train epoch: 0 [batch #43575, batch_size 1, seq length 2500]\tLoss: 4.603512\n",
      "43600it [1:23:03,  8.61it/s]Train epoch: 0 [batch #43600, batch_size 1, seq length 2500]\tLoss: 4.650387\n",
      "43625it [1:23:06,  8.75it/s]Train epoch: 0 [batch #43625, batch_size 1, seq length 2500]\tLoss: 5.007188\n",
      "43650it [1:23:09,  8.77it/s]Train epoch: 0 [batch #43650, batch_size 1, seq length 2500]\tLoss: 4.895949\n",
      "43675it [1:23:12,  8.75it/s]Train epoch: 0 [batch #43675, batch_size 1, seq length 2500]\tLoss: 5.182091\n",
      "43700it [1:23:14,  8.74it/s]Train epoch: 0 [batch #43700, batch_size 1, seq length 2500]\tLoss: 4.998995\n",
      "43725it [1:23:17,  8.75it/s]Train epoch: 0 [batch #43725, batch_size 1, seq length 2500]\tLoss: 5.131657\n",
      "43750it [1:23:20,  8.77it/s]Train epoch: 0 [batch #43750, batch_size 1, seq length 2500]\tLoss: 4.934953\n",
      "43775it [1:23:23,  8.75it/s]Train epoch: 0 [batch #43775, batch_size 1, seq length 2500]\tLoss: 4.741626\n",
      "43800it [1:23:26,  8.77it/s]Train epoch: 0 [batch #43800, batch_size 1, seq length 2500]\tLoss: 4.858747\n",
      "43825it [1:23:29,  8.72it/s]Train epoch: 0 [batch #43825, batch_size 1, seq length 2500]\tLoss: 4.923243\n",
      "43850it [1:23:32,  8.76it/s]Train epoch: 0 [batch #43850, batch_size 1, seq length 2500]\tLoss: 5.044398\n",
      "43875it [1:23:34,  8.77it/s]Train epoch: 0 [batch #43875, batch_size 1, seq length 2500]\tLoss: 4.882294\n",
      "43900it [1:23:37,  8.67it/s]Train epoch: 0 [batch #43900, batch_size 1, seq length 2500]\tLoss: 5.061633\n",
      "43925it [1:23:40,  8.73it/s]Train epoch: 0 [batch #43925, batch_size 1, seq length 2500]\tLoss: 4.887166\n",
      "43950it [1:23:43,  8.77it/s]Train epoch: 0 [batch #43950, batch_size 1, seq length 2500]\tLoss: 4.754484\n",
      "43975it [1:23:46,  8.77it/s]Train epoch: 0 [batch #43975, batch_size 1, seq length 2500]\tLoss: 4.969468\n",
      "44000it [1:23:49,  8.77it/s]Train epoch: 0 [batch #44000, batch_size 1, seq length 2500]\tLoss: 4.854146\n",
      "44025it [1:23:52,  8.75it/s]Train epoch: 0 [batch #44025, batch_size 1, seq length 2500]\tLoss: 4.623632\n",
      "44050it [1:23:54,  8.75it/s]Train epoch: 0 [batch #44050, batch_size 1, seq length 2500]\tLoss: 4.958502\n",
      "44075it [1:23:57,  8.77it/s]Train epoch: 0 [batch #44075, batch_size 1, seq length 2500]\tLoss: 4.969814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100it [1:24:00,  8.76it/s]Train epoch: 0 [batch #44100, batch_size 1, seq length 2500]\tLoss: 4.972388\n",
      "44125it [1:24:03,  8.75it/s]Train epoch: 0 [batch #44125, batch_size 1, seq length 2500]\tLoss: 4.738900\n",
      "44150it [1:24:06,  8.73it/s]Train epoch: 0 [batch #44150, batch_size 1, seq length 2500]\tLoss: 5.138890\n",
      "44175it [1:24:09,  8.53it/s]Train epoch: 0 [batch #44175, batch_size 1, seq length 2500]\tLoss: 4.743610\n",
      "44200it [1:24:12,  8.74it/s]Train epoch: 0 [batch #44200, batch_size 1, seq length 2500]\tLoss: 4.930711\n",
      "44225it [1:24:14,  8.76it/s]Train epoch: 0 [batch #44225, batch_size 1, seq length 2500]\tLoss: 4.925861\n",
      "44250it [1:24:17,  8.73it/s]Train epoch: 0 [batch #44250, batch_size 1, seq length 2500]\tLoss: 4.839396\n",
      "44275it [1:24:20,  8.76it/s]Train epoch: 0 [batch #44275, batch_size 1, seq length 2500]\tLoss: 4.766380\n",
      "44300it [1:24:23,  8.75it/s]Train epoch: 0 [batch #44300, batch_size 1, seq length 2500]\tLoss: 4.779402\n",
      "44325it [1:24:26,  8.75it/s]Train epoch: 0 [batch #44325, batch_size 1, seq length 2500]\tLoss: 5.278970\n",
      "44350it [1:24:29,  8.75it/s]Train epoch: 0 [batch #44350, batch_size 1, seq length 2500]\tLoss: 4.804052\n",
      "44375it [1:24:31,  8.78it/s]Train epoch: 0 [batch #44375, batch_size 1, seq length 2500]\tLoss: 4.804025\n",
      "44400it [1:24:34,  8.73it/s]Train epoch: 0 [batch #44400, batch_size 1, seq length 2500]\tLoss: 5.003005\n",
      "44425it [1:24:37,  8.77it/s]Train epoch: 0 [batch #44425, batch_size 1, seq length 2500]\tLoss: 5.023150\n",
      "44450it [1:24:40,  8.72it/s]Train epoch: 0 [batch #44450, batch_size 1, seq length 2500]\tLoss: 4.989965\n",
      "44475it [1:24:43,  8.77it/s]Train epoch: 0 [batch #44475, batch_size 1, seq length 2500]\tLoss: 4.815861\n",
      "44500it [1:24:46,  8.75it/s]Train epoch: 0 [batch #44500, batch_size 1, seq length 2500]\tLoss: 4.800470\n",
      "44525it [1:24:49,  8.69it/s]Train epoch: 0 [batch #44525, batch_size 1, seq length 2500]\tLoss: 4.787343\n",
      "44550it [1:24:52,  8.75it/s]Train epoch: 0 [batch #44550, batch_size 1, seq length 2500]\tLoss: 4.910378\n",
      "44575it [1:24:54,  8.72it/s]Train epoch: 0 [batch #44575, batch_size 1, seq length 2500]\tLoss: 4.907584\n",
      "44600it [1:24:57,  8.77it/s]Train epoch: 0 [batch #44600, batch_size 1, seq length 2500]\tLoss: 4.857965\n",
      "44625it [1:25:00,  8.78it/s]Train epoch: 0 [batch #44625, batch_size 1, seq length 2500]\tLoss: 4.970938\n",
      "44650it [1:25:03,  8.78it/s]Train epoch: 0 [batch #44650, batch_size 1, seq length 2500]\tLoss: 4.565968\n",
      "44675it [1:25:06,  8.78it/s]Train epoch: 0 [batch #44675, batch_size 1, seq length 2500]\tLoss: 4.660104\n",
      "44700it [1:25:09,  8.77it/s]Train epoch: 0 [batch #44700, batch_size 1, seq length 2500]\tLoss: 4.837406\n",
      "44725it [1:25:11,  8.66it/s]Train epoch: 0 [batch #44725, batch_size 1, seq length 2500]\tLoss: 5.010608\n",
      "44750it [1:25:14,  8.72it/s]Train epoch: 0 [batch #44750, batch_size 1, seq length 2500]\tLoss: 4.622869\n",
      "44775it [1:25:17,  8.78it/s]Train epoch: 0 [batch #44775, batch_size 1, seq length 2500]\tLoss: 4.722545\n",
      "44800it [1:25:20,  8.78it/s]Train epoch: 0 [batch #44800, batch_size 1, seq length 2500]\tLoss: 4.698498\n",
      "44825it [1:25:23,  8.76it/s]Train epoch: 0 [batch #44825, batch_size 1, seq length 2500]\tLoss: 4.824492\n",
      "44850it [1:25:26,  8.78it/s]Train epoch: 0 [batch #44850, batch_size 1, seq length 2500]\tLoss: 4.720264\n",
      "44875it [1:25:29,  8.75it/s]Train epoch: 0 [batch #44875, batch_size 1, seq length 2500]\tLoss: 4.914941\n",
      "44900it [1:25:31,  8.78it/s]Train epoch: 0 [batch #44900, batch_size 1, seq length 2500]\tLoss: 4.469560\n",
      "44925it [1:25:34,  8.63it/s]Train epoch: 0 [batch #44925, batch_size 1, seq length 2500]\tLoss: 4.888318\n",
      "44950it [1:25:37,  8.74it/s]Train epoch: 0 [batch #44950, batch_size 1, seq length 2500]\tLoss: 5.010089\n",
      "44975it [1:25:40,  8.76it/s]Train epoch: 0 [batch #44975, batch_size 1, seq length 2500]\tLoss: 5.031729\n",
      "45000it [1:25:43,  8.75it/s]Train epoch: 0 [batch #45000, batch_size 1, seq length 2500]\tLoss: 4.958279\n",
      "45025it [1:25:46,  8.76it/s]Train epoch: 0 [batch #45025, batch_size 1, seq length 2500]\tLoss: 4.893856\n",
      "45050it [1:25:49,  8.77it/s]Train epoch: 0 [batch #45050, batch_size 1, seq length 2500]\tLoss: 4.660245\n",
      "45075it [1:25:51,  8.77it/s]Train epoch: 0 [batch #45075, batch_size 1, seq length 2500]\tLoss: 4.923170\n",
      "45100it [1:25:54,  8.75it/s]Train epoch: 0 [batch #45100, batch_size 1, seq length 2500]\tLoss: 4.933544\n",
      "45125it [1:25:57,  8.77it/s]Train epoch: 0 [batch #45125, batch_size 1, seq length 2500]\tLoss: 4.722026\n",
      "45150it [1:26:00,  8.71it/s]Train epoch: 0 [batch #45150, batch_size 1, seq length 2500]\tLoss: 5.041873\n",
      "45175it [1:26:03,  8.75it/s]Train epoch: 0 [batch #45175, batch_size 1, seq length 2500]\tLoss: 4.982967\n",
      "45200it [1:26:06,  8.75it/s]Train epoch: 0 [batch #45200, batch_size 1, seq length 2500]\tLoss: 4.872096\n",
      "45225it [1:26:09,  8.76it/s]Train epoch: 0 [batch #45225, batch_size 1, seq length 2500]\tLoss: 5.092676\n",
      "45250it [1:26:11,  8.77it/s]Train epoch: 0 [batch #45250, batch_size 1, seq length 2500]\tLoss: 4.780120\n",
      "45275it [1:26:14,  8.78it/s]Train epoch: 0 [batch #45275, batch_size 1, seq length 2500]\tLoss: 4.750857\n",
      "45300it [1:26:17,  8.78it/s]Train epoch: 0 [batch #45300, batch_size 1, seq length 2500]\tLoss: 4.614559\n",
      "45325it [1:26:20,  8.73it/s]Train epoch: 0 [batch #45325, batch_size 1, seq length 2500]\tLoss: 5.083469\n",
      "45350it [1:26:23,  8.77it/s]Train epoch: 0 [batch #45350, batch_size 1, seq length 2500]\tLoss: 4.688627\n",
      "45375it [1:26:26,  8.76it/s]Train epoch: 0 [batch #45375, batch_size 1, seq length 2500]\tLoss: 4.877939\n",
      "45400it [1:26:29,  8.79it/s]Train epoch: 0 [batch #45400, batch_size 1, seq length 2500]\tLoss: 4.968091\n",
      "45425it [1:26:31,  8.77it/s]Train epoch: 0 [batch #45425, batch_size 1, seq length 2500]\tLoss: 4.726929\n",
      "45450it [1:26:34,  8.70it/s]Train epoch: 0 [batch #45450, batch_size 1, seq length 2500]\tLoss: 4.860669\n",
      "45475it [1:26:37,  8.74it/s]Train epoch: 0 [batch #45475, batch_size 1, seq length 2500]\tLoss: 4.968193\n",
      "45500it [1:26:40,  8.77it/s]Train epoch: 0 [batch #45500, batch_size 1, seq length 2500]\tLoss: 4.874570\n",
      "45525it [1:26:43,  8.71it/s]Train epoch: 0 [batch #45525, batch_size 1, seq length 2500]\tLoss: 4.794781\n",
      "45550it [1:26:46,  8.75it/s]Train epoch: 0 [batch #45550, batch_size 1, seq length 2500]\tLoss: 4.844610\n",
      "45575it [1:26:49,  8.76it/s]Train epoch: 0 [batch #45575, batch_size 1, seq length 2500]\tLoss: 4.822977\n",
      "45600it [1:26:51,  8.75it/s]Train epoch: 0 [batch #45600, batch_size 1, seq length 2500]\tLoss: 4.926499\n",
      "45625it [1:26:54,  8.76it/s]Train epoch: 0 [batch #45625, batch_size 1, seq length 2500]\tLoss: 4.914261\n",
      "45650it [1:26:57,  8.76it/s]Train epoch: 0 [batch #45650, batch_size 1, seq length 2500]\tLoss: 4.992840\n",
      "45675it [1:27:00,  8.78it/s]Train epoch: 0 [batch #45675, batch_size 1, seq length 2500]\tLoss: 4.825002\n",
      "45700it [1:27:03,  8.76it/s]Train epoch: 0 [batch #45700, batch_size 1, seq length 2500]\tLoss: 4.541920\n",
      "45725it [1:27:06,  8.78it/s]Train epoch: 0 [batch #45725, batch_size 1, seq length 2500]\tLoss: 4.942659\n",
      "45750it [1:27:09,  8.77it/s]Train epoch: 0 [batch #45750, batch_size 1, seq length 2500]\tLoss: 4.217247\n",
      "45775it [1:27:11,  8.77it/s]Train epoch: 0 [batch #45775, batch_size 1, seq length 2500]\tLoss: 4.700442\n",
      "45800it [1:27:14,  8.77it/s]Train epoch: 0 [batch #45800, batch_size 1, seq length 2500]\tLoss: 4.804871\n",
      "45825it [1:27:17,  8.75it/s]Train epoch: 0 [batch #45825, batch_size 1, seq length 2500]\tLoss: 4.729003\n",
      "45850it [1:27:20,  8.76it/s]Train epoch: 0 [batch #45850, batch_size 1, seq length 2500]\tLoss: 4.905222\n",
      "45875it [1:27:23,  8.72it/s]Train epoch: 0 [batch #45875, batch_size 1, seq length 2500]\tLoss: 4.658932\n",
      "45900it [1:27:26,  8.59it/s]Train epoch: 0 [batch #45900, batch_size 1, seq length 2500]\tLoss: 4.766393\n",
      "45925it [1:27:29,  8.76it/s]Train epoch: 0 [batch #45925, batch_size 1, seq length 2500]\tLoss: 4.956316\n",
      "45950it [1:27:31,  8.75it/s]Train epoch: 0 [batch #45950, batch_size 1, seq length 2500]\tLoss: 5.000424\n",
      "45975it [1:27:34,  8.78it/s]Train epoch: 0 [batch #45975, batch_size 1, seq length 2500]\tLoss: 4.613622\n",
      "46000it [1:27:37,  8.76it/s]Train epoch: 0 [batch #46000, batch_size 1, seq length 2500]\tLoss: 4.727896\n",
      "46025it [1:27:40,  8.71it/s]Train epoch: 0 [batch #46025, batch_size 1, seq length 2500]\tLoss: 4.725852\n",
      "46050it [1:27:43,  8.77it/s]Train epoch: 0 [batch #46050, batch_size 1, seq length 2500]\tLoss: 5.023933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46075it [1:27:46,  8.76it/s]Train epoch: 0 [batch #46075, batch_size 1, seq length 2500]\tLoss: 4.922335\n",
      "46100it [1:27:49,  8.78it/s]Train epoch: 0 [batch #46100, batch_size 1, seq length 2500]\tLoss: 4.695475\n",
      "46125it [1:27:51,  8.75it/s]Train epoch: 0 [batch #46125, batch_size 1, seq length 2500]\tLoss: 4.651205\n",
      "46150it [1:27:54,  8.74it/s]Train epoch: 0 [batch #46150, batch_size 1, seq length 2500]\tLoss: 4.759410\n",
      "46175it [1:27:57,  8.75it/s]Train epoch: 0 [batch #46175, batch_size 1, seq length 2500]\tLoss: 4.656399\n",
      "46200it [1:28:00,  8.74it/s]Train epoch: 0 [batch #46200, batch_size 1, seq length 2500]\tLoss: 4.918859\n",
      "46225it [1:28:03,  8.78it/s]Train epoch: 0 [batch #46225, batch_size 1, seq length 2500]\tLoss: 4.656851\n",
      "46250it [1:28:06,  8.50it/s]Train epoch: 0 [batch #46250, batch_size 1, seq length 2500]\tLoss: 4.721055\n",
      "46275it [1:28:09,  8.77it/s]Train epoch: 0 [batch #46275, batch_size 1, seq length 2500]\tLoss: 4.746237\n",
      "46300it [1:28:11,  8.76it/s]Train epoch: 0 [batch #46300, batch_size 1, seq length 2500]\tLoss: 4.680789\n",
      "46325it [1:28:14,  8.74it/s]Train epoch: 0 [batch #46325, batch_size 1, seq length 2500]\tLoss: 4.596260\n",
      "46350it [1:28:17,  8.75it/s]Train epoch: 0 [batch #46350, batch_size 1, seq length 2500]\tLoss: 4.634009\n",
      "46375it [1:28:20,  8.78it/s]Train epoch: 0 [batch #46375, batch_size 1, seq length 2500]\tLoss: 4.785143\n",
      "46400it [1:28:23,  8.77it/s]Train epoch: 0 [batch #46400, batch_size 1, seq length 2500]\tLoss: 4.618963\n",
      "46425it [1:28:26,  8.78it/s]Train epoch: 0 [batch #46425, batch_size 1, seq length 2500]\tLoss: 4.779981\n",
      "46450it [1:28:29,  8.77it/s]Train epoch: 0 [batch #46450, batch_size 1, seq length 2500]\tLoss: 4.992554\n",
      "46475it [1:28:31,  8.77it/s]Train epoch: 0 [batch #46475, batch_size 1, seq length 2500]\tLoss: 4.665373\n",
      "46500it [1:28:34,  8.75it/s]Train epoch: 0 [batch #46500, batch_size 1, seq length 2500]\tLoss: 4.922638\n",
      "46525it [1:28:37,  8.78it/s]Train epoch: 0 [batch #46525, batch_size 1, seq length 2500]\tLoss: 4.944541\n",
      "46550it [1:28:40,  8.78it/s]Train epoch: 0 [batch #46550, batch_size 1, seq length 2500]\tLoss: 4.554179\n",
      "46575it [1:28:43,  8.78it/s]Train epoch: 0 [batch #46575, batch_size 1, seq length 2500]\tLoss: 4.823256\n",
      "46600it [1:28:46,  8.77it/s]Train epoch: 0 [batch #46600, batch_size 1, seq length 2500]\tLoss: 4.709774\n",
      "46625it [1:28:49,  8.66it/s]Train epoch: 0 [batch #46625, batch_size 1, seq length 2500]\tLoss: 4.754717\n",
      "46650it [1:28:51,  8.78it/s]Train epoch: 0 [batch #46650, batch_size 1, seq length 2500]\tLoss: 4.464975\n",
      "46675it [1:28:54,  8.78it/s]Train epoch: 0 [batch #46675, batch_size 1, seq length 2500]\tLoss: 4.809418\n",
      "46700it [1:28:57,  8.76it/s]Train epoch: 0 [batch #46700, batch_size 1, seq length 2500]\tLoss: 4.933152\n",
      "46725it [1:29:00,  8.77it/s]Train epoch: 0 [batch #46725, batch_size 1, seq length 2500]\tLoss: 4.724253\n",
      "46750it [1:29:03,  8.77it/s]Train epoch: 0 [batch #46750, batch_size 1, seq length 2500]\tLoss: 4.799684\n",
      "46775it [1:29:06,  8.77it/s]Train epoch: 0 [batch #46775, batch_size 1, seq length 2500]\tLoss: 4.617638\n",
      "46800it [1:29:08,  8.77it/s]Train epoch: 0 [batch #46800, batch_size 1, seq length 2500]\tLoss: 4.630010\n",
      "46825it [1:29:11,  8.78it/s]Train epoch: 0 [batch #46825, batch_size 1, seq length 2500]\tLoss: 4.856131\n",
      "46850it [1:29:14,  8.74it/s]Train epoch: 0 [batch #46850, batch_size 1, seq length 2500]\tLoss: 4.891218\n",
      "46875it [1:29:17,  8.76it/s]Train epoch: 0 [batch #46875, batch_size 1, seq length 2500]\tLoss: 4.573197\n",
      "46900it [1:29:20,  8.75it/s]Train epoch: 0 [batch #46900, batch_size 1, seq length 2500]\tLoss: 4.606780\n",
      "46925it [1:29:23,  8.76it/s]Train epoch: 0 [batch #46925, batch_size 1, seq length 2500]\tLoss: 4.745914\n",
      "46950it [1:29:26,  8.77it/s]Train epoch: 0 [batch #46950, batch_size 1, seq length 2500]\tLoss: 4.751581\n",
      "46975it [1:29:28,  8.75it/s]Train epoch: 0 [batch #46975, batch_size 1, seq length 2500]\tLoss: 4.941294\n",
      "47000it [1:29:31,  8.78it/s]Train epoch: 0 [batch #47000, batch_size 1, seq length 2500]\tLoss: 4.855250\n",
      "47025it [1:29:34,  8.76it/s]Train epoch: 0 [batch #47025, batch_size 1, seq length 2500]\tLoss: 4.926419\n",
      "47050it [1:29:37,  8.76it/s]Train epoch: 0 [batch #47050, batch_size 1, seq length 2500]\tLoss: 4.781979\n",
      "47075it [1:29:40,  8.77it/s]Train epoch: 0 [batch #47075, batch_size 1, seq length 2500]\tLoss: 4.856868\n",
      "47100it [1:29:43,  8.74it/s]Train epoch: 0 [batch #47100, batch_size 1, seq length 2500]\tLoss: 4.862725\n",
      "47125it [1:29:46,  8.68it/s]Train epoch: 0 [batch #47125, batch_size 1, seq length 2500]\tLoss: 4.566100\n",
      "47150it [1:29:48,  8.77it/s]Train epoch: 0 [batch #47150, batch_size 1, seq length 2500]\tLoss: 4.595475\n",
      "47175it [1:29:51,  8.77it/s]Train epoch: 0 [batch #47175, batch_size 1, seq length 2500]\tLoss: 4.915807\n",
      "47200it [1:29:54,  8.77it/s]Train epoch: 0 [batch #47200, batch_size 1, seq length 2500]\tLoss: 4.684761\n",
      "47225it [1:29:57,  8.76it/s]Train epoch: 0 [batch #47225, batch_size 1, seq length 2500]\tLoss: 4.663544\n",
      "47250it [1:30:00,  8.73it/s]Train epoch: 0 [batch #47250, batch_size 1, seq length 2500]\tLoss: 5.043523\n",
      "47275it [1:30:03,  8.74it/s]Train epoch: 0 [batch #47275, batch_size 1, seq length 2500]\tLoss: 4.464224\n",
      "47300it [1:30:06,  8.74it/s]Train epoch: 0 [batch #47300, batch_size 1, seq length 2500]\tLoss: 4.800360\n",
      "47325it [1:30:09,  8.74it/s]Train epoch: 0 [batch #47325, batch_size 1, seq length 2500]\tLoss: 4.531428\n",
      "47350it [1:30:11,  8.78it/s]Train epoch: 0 [batch #47350, batch_size 1, seq length 2500]\tLoss: 4.427558\n",
      "47375it [1:30:14,  8.78it/s]Train epoch: 0 [batch #47375, batch_size 1, seq length 2500]\tLoss: 4.693500\n",
      "47400it [1:30:17,  8.76it/s]Train epoch: 0 [batch #47400, batch_size 1, seq length 2500]\tLoss: 4.546891\n",
      "47425it [1:30:20,  8.73it/s]Train epoch: 0 [batch #47425, batch_size 1, seq length 2500]\tLoss: 4.857357\n",
      "47450it [1:30:23,  8.74it/s]Train epoch: 0 [batch #47450, batch_size 1, seq length 2500]\tLoss: 4.968957\n",
      "47475it [1:30:26,  8.69it/s]Train epoch: 0 [batch #47475, batch_size 1, seq length 2500]\tLoss: 4.852595\n",
      "47500it [1:30:29,  8.76it/s]Train epoch: 0 [batch #47500, batch_size 1, seq length 2500]\tLoss: 4.664809\n",
      "47525it [1:30:31,  8.75it/s]Train epoch: 0 [batch #47525, batch_size 1, seq length 2500]\tLoss: 4.665984\n",
      "47550it [1:30:34,  8.75it/s]Train epoch: 0 [batch #47550, batch_size 1, seq length 2500]\tLoss: 4.716030\n",
      "47575it [1:30:37,  8.69it/s]Train epoch: 0 [batch #47575, batch_size 1, seq length 2500]\tLoss: 4.780030\n",
      "47600it [1:30:40,  8.70it/s]Train epoch: 0 [batch #47600, batch_size 1, seq length 2500]\tLoss: 5.037825\n",
      "47625it [1:30:43,  8.78it/s]Train epoch: 0 [batch #47625, batch_size 1, seq length 2500]\tLoss: 4.468138\n",
      "47650it [1:30:46,  8.77it/s]Train epoch: 0 [batch #47650, batch_size 1, seq length 2500]\tLoss: 4.877988\n",
      "47675it [1:30:49,  8.76it/s]Train epoch: 0 [batch #47675, batch_size 1, seq length 2500]\tLoss: 4.610410\n",
      "47700it [1:30:51,  8.76it/s]Train epoch: 0 [batch #47700, batch_size 1, seq length 2500]\tLoss: 5.035636\n",
      "47725it [1:30:54,  8.73it/s]Train epoch: 0 [batch #47725, batch_size 1, seq length 2500]\tLoss: 4.774744\n",
      "47750it [1:30:57,  8.75it/s]Train epoch: 0 [batch #47750, batch_size 1, seq length 2500]\tLoss: 4.602141\n",
      "47775it [1:31:00,  8.77it/s]Train epoch: 0 [batch #47775, batch_size 1, seq length 2500]\tLoss: 4.453149\n",
      "47800it [1:31:03,  8.74it/s]Train epoch: 0 [batch #47800, batch_size 1, seq length 2500]\tLoss: 4.682909\n",
      "47825it [1:31:06,  8.77it/s]Train epoch: 0 [batch #47825, batch_size 1, seq length 2500]\tLoss: 5.192466\n",
      "47850it [1:31:09,  8.75it/s]Train epoch: 0 [batch #47850, batch_size 1, seq length 2500]\tLoss: 4.683105\n",
      "47875it [1:31:11,  8.76it/s]Train epoch: 0 [batch #47875, batch_size 1, seq length 2500]\tLoss: 4.876824\n",
      "47900it [1:31:14,  8.75it/s]Train epoch: 0 [batch #47900, batch_size 1, seq length 2500]\tLoss: 4.775123\n",
      "47925it [1:31:17,  8.77it/s]Train epoch: 0 [batch #47925, batch_size 1, seq length 2500]\tLoss: 4.709653\n",
      "47950it [1:31:20,  8.72it/s]Train epoch: 0 [batch #47950, batch_size 1, seq length 2500]\tLoss: 4.590033\n",
      "47975it [1:31:23,  8.76it/s]Train epoch: 0 [batch #47975, batch_size 1, seq length 2500]\tLoss: 4.693459\n",
      "48000it [1:31:26,  8.76it/s]Train epoch: 0 [batch #48000, batch_size 1, seq length 2500]\tLoss: 4.900803\n",
      "48025it [1:31:29,  8.78it/s]Train epoch: 0 [batch #48025, batch_size 1, seq length 2500]\tLoss: 4.786577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48050it [1:31:31,  8.62it/s]Train epoch: 0 [batch #48050, batch_size 1, seq length 2500]\tLoss: 4.512440\n",
      "48075it [1:31:34,  8.71it/s]Train epoch: 0 [batch #48075, batch_size 1, seq length 2500]\tLoss: 4.509799\n",
      "48100it [1:31:37,  8.74it/s]Train epoch: 0 [batch #48100, batch_size 1, seq length 2500]\tLoss: 4.978672\n",
      "48125it [1:31:40,  8.77it/s]Train epoch: 0 [batch #48125, batch_size 1, seq length 2500]\tLoss: 4.748319\n",
      "48150it [1:31:43,  8.62it/s]Train epoch: 0 [batch #48150, batch_size 1, seq length 2500]\tLoss: 4.997809\n",
      "48175it [1:31:46,  8.73it/s]Train epoch: 0 [batch #48175, batch_size 1, seq length 2500]\tLoss: 4.926142\n",
      "48200it [1:31:49,  8.70it/s]Train epoch: 0 [batch #48200, batch_size 1, seq length 2500]\tLoss: 4.537711\n",
      "48225it [1:31:52,  8.73it/s]Train epoch: 0 [batch #48225, batch_size 1, seq length 2500]\tLoss: 4.557923\n",
      "48250it [1:31:54,  8.75it/s]Train epoch: 0 [batch #48250, batch_size 1, seq length 2500]\tLoss: 4.667467\n",
      "48275it [1:31:57,  8.57it/s]Train epoch: 0 [batch #48275, batch_size 1, seq length 2500]\tLoss: 4.839755\n",
      "48300it [1:32:00,  8.74it/s]Train epoch: 0 [batch #48300, batch_size 1, seq length 2500]\tLoss: 4.770492\n",
      "48325it [1:32:03,  8.71it/s]Train epoch: 0 [batch #48325, batch_size 1, seq length 2500]\tLoss: 4.638022\n",
      "48350it [1:32:06,  8.71it/s]Train epoch: 0 [batch #48350, batch_size 1, seq length 2500]\tLoss: 4.884667\n",
      "48375it [1:32:09,  8.76it/s]Train epoch: 0 [batch #48375, batch_size 1, seq length 2500]\tLoss: 4.531794\n",
      "48400it [1:32:12,  8.69it/s]Train epoch: 0 [batch #48400, batch_size 1, seq length 2500]\tLoss: 4.637275\n",
      "48425it [1:32:14,  8.74it/s]Train epoch: 0 [batch #48425, batch_size 1, seq length 2500]\tLoss: 4.875588\n",
      "48450it [1:32:17,  8.75it/s]Train epoch: 0 [batch #48450, batch_size 1, seq length 2500]\tLoss: 4.845939\n",
      "48475it [1:32:20,  8.73it/s]Train epoch: 0 [batch #48475, batch_size 1, seq length 2500]\tLoss: 4.886379\n",
      "48500it [1:32:23,  8.74it/s]Train epoch: 0 [batch #48500, batch_size 1, seq length 2500]\tLoss: 4.646769\n",
      "48525it [1:32:26,  8.74it/s]Train epoch: 0 [batch #48525, batch_size 1, seq length 2500]\tLoss: 4.446100\n",
      "48550it [1:32:29,  8.74it/s]Train epoch: 0 [batch #48550, batch_size 1, seq length 2500]\tLoss: 4.408174\n",
      "48575it [1:32:32,  8.76it/s]Train epoch: 0 [batch #48575, batch_size 1, seq length 2500]\tLoss: 4.618503\n",
      "48600it [1:32:34,  8.73it/s]Train epoch: 0 [batch #48600, batch_size 1, seq length 2500]\tLoss: 4.694566\n",
      "48625it [1:32:37,  8.75it/s]Train epoch: 0 [batch #48625, batch_size 1, seq length 2500]\tLoss: 4.756599\n",
      "48650it [1:32:40,  8.77it/s]Train epoch: 0 [batch #48650, batch_size 1, seq length 2500]\tLoss: 4.656262\n",
      "48675it [1:32:43,  8.73it/s]Train epoch: 0 [batch #48675, batch_size 1, seq length 2500]\tLoss: 4.694810\n",
      "48700it [1:32:46,  8.69it/s]Train epoch: 0 [batch #48700, batch_size 1, seq length 2500]\tLoss: 4.704767\n",
      "48725it [1:32:49,  8.76it/s]Train epoch: 0 [batch #48725, batch_size 1, seq length 2500]\tLoss: 4.605953\n",
      "48750it [1:32:52,  8.76it/s]Train epoch: 0 [batch #48750, batch_size 1, seq length 2500]\tLoss: 4.366938\n",
      "48775it [1:32:54,  8.70it/s]Train epoch: 0 [batch #48775, batch_size 1, seq length 2500]\tLoss: 4.870572\n",
      "48800it [1:32:57,  8.76it/s]Train epoch: 0 [batch #48800, batch_size 1, seq length 2500]\tLoss: 4.795154\n",
      "48825it [1:33:00,  8.69it/s]Train epoch: 0 [batch #48825, batch_size 1, seq length 2500]\tLoss: 4.756665\n",
      "48850it [1:33:03,  8.77it/s]Train epoch: 0 [batch #48850, batch_size 1, seq length 2500]\tLoss: 4.721752\n",
      "48875it [1:33:06,  8.76it/s]Train epoch: 0 [batch #48875, batch_size 1, seq length 2500]\tLoss: 4.617812\n",
      "48900it [1:33:09,  8.74it/s]Train epoch: 0 [batch #48900, batch_size 1, seq length 2500]\tLoss: 4.581627\n",
      "48925it [1:33:12,  8.77it/s]Train epoch: 0 [batch #48925, batch_size 1, seq length 2500]\tLoss: 4.615858\n",
      "48950it [1:33:14,  8.76it/s]Train epoch: 0 [batch #48950, batch_size 1, seq length 2500]\tLoss: 5.072787\n",
      "48975it [1:33:17,  8.77it/s]Train epoch: 0 [batch #48975, batch_size 1, seq length 2500]\tLoss: 4.948031\n",
      "49000it [1:33:20,  8.75it/s]Train epoch: 0 [batch #49000, batch_size 1, seq length 2500]\tLoss: 4.661567\n",
      "49025it [1:33:23,  8.72it/s]Train epoch: 0 [batch #49025, batch_size 1, seq length 2500]\tLoss: 4.834985\n",
      "49050it [1:33:26,  8.74it/s]Train epoch: 0 [batch #49050, batch_size 1, seq length 2500]\tLoss: 4.587500\n",
      "49075it [1:33:29,  8.72it/s]Train epoch: 0 [batch #49075, batch_size 1, seq length 2500]\tLoss: 4.826361\n",
      "49100it [1:33:32,  8.75it/s]Train epoch: 0 [batch #49100, batch_size 1, seq length 2500]\tLoss: 4.816925\n",
      "49125it [1:33:35,  8.77it/s]Train epoch: 0 [batch #49125, batch_size 1, seq length 2500]\tLoss: 4.586180\n",
      "49150it [1:33:37,  8.76it/s]Train epoch: 0 [batch #49150, batch_size 1, seq length 2500]\tLoss: 4.477291\n",
      "49175it [1:33:40,  8.76it/s]Train epoch: 0 [batch #49175, batch_size 1, seq length 2500]\tLoss: 4.722896\n",
      "49200it [1:33:43,  8.76it/s]Train epoch: 0 [batch #49200, batch_size 1, seq length 2500]\tLoss: 4.708537\n",
      "49225it [1:33:46,  8.75it/s]Train epoch: 0 [batch #49225, batch_size 1, seq length 2500]\tLoss: 4.852812\n",
      "49250it [1:33:49,  8.76it/s]Train epoch: 0 [batch #49250, batch_size 1, seq length 2500]\tLoss: 4.570885\n",
      "49275it [1:33:52,  8.76it/s]Train epoch: 0 [batch #49275, batch_size 1, seq length 2500]\tLoss: 4.640462\n",
      "49300it [1:33:55,  8.78it/s]Train epoch: 0 [batch #49300, batch_size 1, seq length 2500]\tLoss: 4.726146\n",
      "49325it [1:33:57,  8.75it/s]Train epoch: 0 [batch #49325, batch_size 1, seq length 2500]\tLoss: 4.843359\n",
      "49350it [1:34:00,  8.76it/s]Train epoch: 0 [batch #49350, batch_size 1, seq length 2500]\tLoss: 4.475390\n",
      "49375it [1:34:03,  8.76it/s]Train epoch: 0 [batch #49375, batch_size 1, seq length 2500]\tLoss: 4.624880\n",
      "49400it [1:34:06,  8.75it/s]Train epoch: 0 [batch #49400, batch_size 1, seq length 2500]\tLoss: 4.554366\n",
      "49425it [1:34:09,  8.77it/s]Train epoch: 0 [batch #49425, batch_size 1, seq length 2500]\tLoss: 4.816532\n",
      "49450it [1:34:12,  8.62it/s]Train epoch: 0 [batch #49450, batch_size 1, seq length 2500]\tLoss: 4.848866\n",
      "49475it [1:34:15,  8.76it/s]Train epoch: 0 [batch #49475, batch_size 1, seq length 2500]\tLoss: 4.695782\n",
      "49500it [1:34:17,  8.74it/s]Train epoch: 0 [batch #49500, batch_size 1, seq length 2500]\tLoss: 4.750521\n",
      "49525it [1:34:20,  8.76it/s]Train epoch: 0 [batch #49525, batch_size 1, seq length 2500]\tLoss: 4.644012\n",
      "49550it [1:34:23,  8.73it/s]Train epoch: 0 [batch #49550, batch_size 1, seq length 2500]\tLoss: 4.914327\n",
      "49575it [1:34:26,  8.76it/s]Train epoch: 0 [batch #49575, batch_size 1, seq length 2500]\tLoss: 4.523809\n",
      "49600it [1:34:29,  8.75it/s]Train epoch: 0 [batch #49600, batch_size 1, seq length 2500]\tLoss: 4.690548\n",
      "49625it [1:34:32,  8.49it/s]Train epoch: 0 [batch #49625, batch_size 1, seq length 2500]\tLoss: 4.882705\n",
      "49650it [1:34:35,  8.73it/s]Train epoch: 0 [batch #49650, batch_size 1, seq length 2500]\tLoss: 4.579733\n",
      "49675it [1:34:37,  8.64it/s]Train epoch: 0 [batch #49675, batch_size 1, seq length 2500]\tLoss: 4.855803\n",
      "49700it [1:34:40,  8.78it/s]Train epoch: 0 [batch #49700, batch_size 1, seq length 2500]\tLoss: 4.733744\n",
      "49725it [1:34:43,  8.76it/s]Train epoch: 0 [batch #49725, batch_size 1, seq length 2500]\tLoss: 4.813838\n",
      "49750it [1:34:46,  8.75it/s]Train epoch: 0 [batch #49750, batch_size 1, seq length 2500]\tLoss: 4.680316\n",
      "49775it [1:34:49,  8.74it/s]Train epoch: 0 [batch #49775, batch_size 1, seq length 2500]\tLoss: 4.650581\n",
      "49800it [1:34:52,  8.68it/s]Train epoch: 0 [batch #49800, batch_size 1, seq length 2500]\tLoss: 4.337817\n",
      "49825it [1:34:55,  8.67it/s]Train epoch: 0 [batch #49825, batch_size 1, seq length 2500]\tLoss: 4.749369\n",
      "49850it [1:34:58,  8.76it/s]Train epoch: 0 [batch #49850, batch_size 1, seq length 2500]\tLoss: 4.707493\n",
      "49875it [1:35:00,  8.72it/s]Train epoch: 0 [batch #49875, batch_size 1, seq length 2500]\tLoss: 4.658212\n",
      "49900it [1:35:03,  8.69it/s]Train epoch: 0 [batch #49900, batch_size 1, seq length 2500]\tLoss: 4.637373\n",
      "49925it [1:35:06,  8.76it/s]Train epoch: 0 [batch #49925, batch_size 1, seq length 2500]\tLoss: 4.714063\n",
      "49950it [1:35:09,  8.58it/s]Train epoch: 0 [batch #49950, batch_size 1, seq length 2500]\tLoss: 4.528014\n",
      "49975it [1:35:12,  8.68it/s]Train epoch: 0 [batch #49975, batch_size 1, seq length 2500]\tLoss: 4.802299\n",
      "50000it [1:35:15,  8.76it/s]Train epoch: 0 [batch #50000, batch_size 1, seq length 2500]\tLoss: 4.467915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50025it [1:35:18,  8.74it/s]Train epoch: 0 [batch #50025, batch_size 1, seq length 2500]\tLoss: 4.584060\n",
      "50050it [1:35:20,  8.77it/s]Train epoch: 0 [batch #50050, batch_size 1, seq length 2500]\tLoss: 4.881400\n",
      "50075it [1:35:23,  8.77it/s]Train epoch: 0 [batch #50075, batch_size 1, seq length 2500]\tLoss: 4.361469\n",
      "50100it [1:35:26,  8.77it/s]Train epoch: 0 [batch #50100, batch_size 1, seq length 2500]\tLoss: 4.741238\n",
      "50125it [1:35:29,  8.78it/s]Train epoch: 0 [batch #50125, batch_size 1, seq length 2500]\tLoss: 4.698146\n",
      "50150it [1:35:32,  8.77it/s]Train epoch: 0 [batch #50150, batch_size 1, seq length 2500]\tLoss: 4.808418\n",
      "50175it [1:35:35,  8.75it/s]Train epoch: 0 [batch #50175, batch_size 1, seq length 2500]\tLoss: 4.701468\n",
      "50200it [1:35:38,  8.74it/s]Train epoch: 0 [batch #50200, batch_size 1, seq length 2500]\tLoss: 4.718924\n",
      "50225it [1:35:40,  8.74it/s]Train epoch: 0 [batch #50225, batch_size 1, seq length 2500]\tLoss: 4.678936\n",
      "50250it [1:35:43,  8.75it/s]Train epoch: 0 [batch #50250, batch_size 1, seq length 2500]\tLoss: 4.686189\n",
      "50275it [1:35:46,  8.76it/s]Train epoch: 0 [batch #50275, batch_size 1, seq length 2500]\tLoss: 4.659795\n",
      "50300it [1:35:49,  8.73it/s]Train epoch: 0 [batch #50300, batch_size 1, seq length 2500]\tLoss: 4.675687\n",
      "50325it [1:35:52,  8.76it/s]Train epoch: 0 [batch #50325, batch_size 1, seq length 2500]\tLoss: 4.625101\n",
      "50350it [1:35:55,  8.76it/s]Train epoch: 0 [batch #50350, batch_size 1, seq length 2500]\tLoss: 4.413217\n",
      "50375it [1:35:58,  8.76it/s]Train epoch: 0 [batch #50375, batch_size 1, seq length 2500]\tLoss: 4.636525\n",
      "50400it [1:36:01,  8.71it/s]Train epoch: 0 [batch #50400, batch_size 1, seq length 2500]\tLoss: 4.723251\n",
      "50425it [1:36:03,  8.77it/s]Train epoch: 0 [batch #50425, batch_size 1, seq length 2500]\tLoss: 4.590069\n",
      "50450it [1:36:06,  8.75it/s]Train epoch: 0 [batch #50450, batch_size 1, seq length 2500]\tLoss: 4.416306\n",
      "50475it [1:36:09,  8.75it/s]Train epoch: 0 [batch #50475, batch_size 1, seq length 2500]\tLoss: 4.529592\n",
      "50500it [1:36:12,  8.75it/s]Train epoch: 0 [batch #50500, batch_size 1, seq length 2500]\tLoss: 4.474885\n",
      "50525it [1:36:15,  8.71it/s]Train epoch: 0 [batch #50525, batch_size 1, seq length 2500]\tLoss: 4.560998\n",
      "50550it [1:36:18,  8.76it/s]Train epoch: 0 [batch #50550, batch_size 1, seq length 2500]\tLoss: 4.419939\n",
      "50575it [1:36:21,  8.75it/s]Train epoch: 0 [batch #50575, batch_size 1, seq length 2500]\tLoss: 4.461137\n",
      "50600it [1:36:23,  8.74it/s]Train epoch: 0 [batch #50600, batch_size 1, seq length 2500]\tLoss: 4.661586\n",
      "50625it [1:36:26,  8.75it/s]Train epoch: 0 [batch #50625, batch_size 1, seq length 2500]\tLoss: 4.754084\n",
      "50650it [1:36:29,  8.78it/s]Train epoch: 0 [batch #50650, batch_size 1, seq length 2500]\tLoss: 4.763746\n",
      "50675it [1:36:32,  8.75it/s]Train epoch: 0 [batch #50675, batch_size 1, seq length 2500]\tLoss: 4.812285\n",
      "50700it [1:36:35,  8.73it/s]Train epoch: 0 [batch #50700, batch_size 1, seq length 2500]\tLoss: 4.644821\n",
      "50725it [1:36:38,  8.72it/s]Train epoch: 0 [batch #50725, batch_size 1, seq length 2500]\tLoss: 4.504778\n",
      "50750it [1:36:41,  8.77it/s]Train epoch: 0 [batch #50750, batch_size 1, seq length 2500]\tLoss: 4.516233\n",
      "50775it [1:36:43,  8.75it/s]Train epoch: 0 [batch #50775, batch_size 1, seq length 2500]\tLoss: 4.877988\n",
      "50800it [1:36:46,  8.64it/s]Train epoch: 0 [batch #50800, batch_size 1, seq length 2500]\tLoss: 4.659559\n",
      "50825it [1:36:49,  8.76it/s]Train epoch: 0 [batch #50825, batch_size 1, seq length 2500]\tLoss: 4.667105\n",
      "50850it [1:36:52,  8.75it/s]Train epoch: 0 [batch #50850, batch_size 1, seq length 2500]\tLoss: 4.828191\n",
      "50875it [1:36:55,  8.73it/s]Train epoch: 0 [batch #50875, batch_size 1, seq length 2500]\tLoss: 4.643808\n",
      "50900it [1:36:58,  8.59it/s]Train epoch: 0 [batch #50900, batch_size 1, seq length 2500]\tLoss: 4.592155\n",
      "50925it [1:37:01,  8.47it/s]Train epoch: 0 [batch #50925, batch_size 1, seq length 2500]\tLoss: 4.529024\n",
      "50950it [1:37:03,  8.73it/s]Train epoch: 0 [batch #50950, batch_size 1, seq length 2500]\tLoss: 4.728426\n",
      "50975it [1:37:06,  8.65it/s]Train epoch: 0 [batch #50975, batch_size 1, seq length 2500]\tLoss: 4.550554\n",
      "51000it [1:37:09,  8.74it/s]Train epoch: 0 [batch #51000, batch_size 1, seq length 2500]\tLoss: 4.420367\n",
      "51025it [1:37:12,  8.76it/s]Train epoch: 0 [batch #51025, batch_size 1, seq length 2500]\tLoss: 4.551579\n",
      "51050it [1:37:15,  8.71it/s]Train epoch: 0 [batch #51050, batch_size 1, seq length 2500]\tLoss: 5.017615\n",
      "51075it [1:37:18,  8.70it/s]Train epoch: 0 [batch #51075, batch_size 1, seq length 2500]\tLoss: 4.694890\n",
      "51100it [1:37:21,  8.76it/s]Train epoch: 0 [batch #51100, batch_size 1, seq length 2500]\tLoss: 4.405887\n",
      "51125it [1:37:24,  8.71it/s]Train epoch: 0 [batch #51125, batch_size 1, seq length 2500]\tLoss: 4.514688\n",
      "51150it [1:37:26,  8.74it/s]Train epoch: 0 [batch #51150, batch_size 1, seq length 2500]\tLoss: 4.442407\n",
      "51175it [1:37:29,  8.77it/s]Train epoch: 0 [batch #51175, batch_size 1, seq length 2500]\tLoss: 4.700616\n",
      "51200it [1:37:32,  8.73it/s]Train epoch: 0 [batch #51200, batch_size 1, seq length 2500]\tLoss: 4.448609\n",
      "51225it [1:37:35,  8.70it/s]Train epoch: 0 [batch #51225, batch_size 1, seq length 2500]\tLoss: 4.451167\n",
      "51250it [1:37:38,  8.74it/s]Train epoch: 0 [batch #51250, batch_size 1, seq length 2500]\tLoss: 4.794670\n",
      "51275it [1:37:41,  8.72it/s]Train epoch: 0 [batch #51275, batch_size 1, seq length 2500]\tLoss: 4.539090\n",
      "51300it [1:37:44,  8.75it/s]Train epoch: 0 [batch #51300, batch_size 1, seq length 2500]\tLoss: 4.763617\n",
      "51325it [1:37:46,  8.74it/s]Train epoch: 0 [batch #51325, batch_size 1, seq length 2500]\tLoss: 4.381985\n",
      "51350it [1:37:49,  8.76it/s]Train epoch: 0 [batch #51350, batch_size 1, seq length 2500]\tLoss: 4.599754\n",
      "51375it [1:37:52,  8.74it/s]Train epoch: 0 [batch #51375, batch_size 1, seq length 2500]\tLoss: 4.573596\n",
      "51400it [1:37:55,  8.75it/s]Train epoch: 0 [batch #51400, batch_size 1, seq length 2500]\tLoss: 4.455453\n",
      "51425it [1:37:58,  8.77it/s]Train epoch: 0 [batch #51425, batch_size 1, seq length 2500]\tLoss: 4.581621\n",
      "51450it [1:38:01,  8.73it/s]Train epoch: 0 [batch #51450, batch_size 1, seq length 2500]\tLoss: 4.520807\n",
      "51475it [1:38:04,  8.74it/s]Train epoch: 0 [batch #51475, batch_size 1, seq length 2500]\tLoss: 4.477551\n",
      "51500it [1:38:07,  8.75it/s]Train epoch: 0 [batch #51500, batch_size 1, seq length 2500]\tLoss: 4.492052\n",
      "51525it [1:38:09,  8.70it/s]Train epoch: 0 [batch #51525, batch_size 1, seq length 2500]\tLoss: 4.347720\n",
      "51550it [1:38:12,  8.71it/s]Train epoch: 0 [batch #51550, batch_size 1, seq length 2500]\tLoss: 4.822863\n",
      "51575it [1:38:15,  8.76it/s]Train epoch: 0 [batch #51575, batch_size 1, seq length 2500]\tLoss: 4.385384\n",
      "51600it [1:38:18,  8.74it/s]Train epoch: 0 [batch #51600, batch_size 1, seq length 2500]\tLoss: 4.357277\n",
      "51625it [1:38:21,  8.73it/s]Train epoch: 0 [batch #51625, batch_size 1, seq length 2500]\tLoss: 4.736073\n",
      "51650it [1:38:24,  8.73it/s]Train epoch: 0 [batch #51650, batch_size 1, seq length 2500]\tLoss: 4.275406\n",
      "51675it [1:38:27,  8.75it/s]Train epoch: 0 [batch #51675, batch_size 1, seq length 2500]\tLoss: 4.632329\n",
      "51700it [1:38:29,  8.76it/s]Train epoch: 0 [batch #51700, batch_size 1, seq length 2500]\tLoss: 4.673305\n",
      "51725it [1:38:32,  8.72it/s]Train epoch: 0 [batch #51725, batch_size 1, seq length 2500]\tLoss: 4.442437\n",
      "51750it [1:38:35,  8.74it/s]Train epoch: 0 [batch #51750, batch_size 1, seq length 2500]\tLoss: 4.495276\n",
      "51775it [1:38:38,  8.75it/s]Train epoch: 0 [batch #51775, batch_size 1, seq length 2500]\tLoss: 4.660096\n",
      "51800it [1:38:41,  8.69it/s]Train epoch: 0 [batch #51800, batch_size 1, seq length 2500]\tLoss: 4.662197\n",
      "51825it [1:38:44,  8.76it/s]Train epoch: 0 [batch #51825, batch_size 1, seq length 2500]\tLoss: 4.718524\n",
      "51850it [1:38:47,  8.77it/s]Train epoch: 0 [batch #51850, batch_size 1, seq length 2500]\tLoss: 4.491426\n",
      "51875it [1:38:49,  8.62it/s]Train epoch: 0 [batch #51875, batch_size 1, seq length 2500]\tLoss: 4.563411\n",
      "51900it [1:38:52,  8.72it/s]Train epoch: 0 [batch #51900, batch_size 1, seq length 2500]\tLoss: 4.571714\n",
      "51925it [1:38:55,  8.67it/s]Train epoch: 0 [batch #51925, batch_size 1, seq length 2500]\tLoss: 4.606305\n",
      "51950it [1:38:58,  8.76it/s]Train epoch: 0 [batch #51950, batch_size 1, seq length 2500]\tLoss: 4.706100\n",
      "51975it [1:39:01,  8.69it/s]Train epoch: 0 [batch #51975, batch_size 1, seq length 2500]\tLoss: 4.609444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52000it [1:39:04,  8.74it/s]Train epoch: 0 [batch #52000, batch_size 1, seq length 2500]\tLoss: 4.660941\n",
      "52025it [1:39:07,  8.72it/s]Train epoch: 0 [batch #52025, batch_size 1, seq length 2500]\tLoss: 4.397704\n",
      "52050it [1:39:10,  8.73it/s]Train epoch: 0 [batch #52050, batch_size 1, seq length 2500]\tLoss: 4.839502\n",
      "52075it [1:39:12,  8.74it/s]Train epoch: 0 [batch #52075, batch_size 1, seq length 2500]\tLoss: 4.603949\n",
      "52100it [1:39:15,  8.76it/s]Train epoch: 0 [batch #52100, batch_size 1, seq length 2500]\tLoss: 4.769854\n",
      "52125it [1:39:18,  8.71it/s]Train epoch: 0 [batch #52125, batch_size 1, seq length 2500]\tLoss: 4.665849\n",
      "52150it [1:39:21,  8.75it/s]Train epoch: 0 [batch #52150, batch_size 1, seq length 2500]\tLoss: 4.423246\n",
      "52175it [1:39:24,  8.74it/s]Train epoch: 0 [batch #52175, batch_size 1, seq length 2500]\tLoss: 4.738095\n",
      "52200it [1:39:27,  8.73it/s]Train epoch: 0 [batch #52200, batch_size 1, seq length 2500]\tLoss: 4.652096\n",
      "52225it [1:39:30,  8.78it/s]Train epoch: 0 [batch #52225, batch_size 1, seq length 2500]\tLoss: 4.727078\n",
      "52250it [1:39:32,  8.77it/s]Train epoch: 0 [batch #52250, batch_size 1, seq length 2500]\tLoss: 4.649214\n",
      "52275it [1:39:35,  8.70it/s]Train epoch: 0 [batch #52275, batch_size 1, seq length 2500]\tLoss: 4.322536\n",
      "52300it [1:39:38,  8.69it/s]Train epoch: 0 [batch #52300, batch_size 1, seq length 2500]\tLoss: 4.469072\n",
      "52325it [1:39:41,  8.73it/s]Train epoch: 0 [batch #52325, batch_size 1, seq length 2500]\tLoss: 4.334110\n",
      "52350it [1:39:44,  8.72it/s]Train epoch: 0 [batch #52350, batch_size 1, seq length 2500]\tLoss: 4.731287\n",
      "52375it [1:39:47,  8.71it/s]Train epoch: 0 [batch #52375, batch_size 1, seq length 2500]\tLoss: 4.714504\n",
      "52400it [1:39:50,  8.72it/s]Train epoch: 0 [batch #52400, batch_size 1, seq length 2500]\tLoss: 4.523697\n",
      "52425it [1:39:52,  8.74it/s]Train epoch: 0 [batch #52425, batch_size 1, seq length 2500]\tLoss: 4.086473\n",
      "52450it [1:39:55,  8.76it/s]Train epoch: 0 [batch #52450, batch_size 1, seq length 2500]\tLoss: 4.370660\n",
      "52465it [1:39:57,  8.75it/s]\n",
      "Epoch 0: 5.5556\n",
      "0it [00:00, ?it/s]Train epoch: 1 [batch #0, batch_size 1, seq length 2500]\tLoss: 4.348500\n",
      "25it [00:02,  8.76it/s]Train epoch: 1 [batch #25, batch_size 1, seq length 2500]\tLoss: 4.332283\n",
      "50it [00:05,  8.70it/s]Train epoch: 1 [batch #50, batch_size 1, seq length 2500]\tLoss: 4.480997\n",
      "75it [00:08,  8.74it/s]Train epoch: 1 [batch #75, batch_size 1, seq length 2500]\tLoss: 4.555734\n",
      "100it [00:11,  8.74it/s]Train epoch: 1 [batch #100, batch_size 1, seq length 2500]\tLoss: 4.411078\n",
      "125it [00:14,  8.76it/s]Train epoch: 1 [batch #125, batch_size 1, seq length 2500]\tLoss: 4.831005\n",
      "150it [00:17,  8.75it/s]Train epoch: 1 [batch #150, batch_size 1, seq length 2500]\tLoss: 4.576241\n",
      "175it [00:20,  8.72it/s]Train epoch: 1 [batch #175, batch_size 1, seq length 2500]\tLoss: 4.486077\n",
      "200it [00:22,  8.75it/s]Train epoch: 1 [batch #200, batch_size 1, seq length 2500]\tLoss: 4.546762\n",
      "225it [00:25,  8.76it/s]Train epoch: 1 [batch #225, batch_size 1, seq length 2500]\tLoss: 4.783795\n",
      "250it [00:28,  8.73it/s]Train epoch: 1 [batch #250, batch_size 1, seq length 2500]\tLoss: 4.631901\n",
      "275it [00:31,  8.70it/s]Train epoch: 1 [batch #275, batch_size 1, seq length 2500]\tLoss: 4.769424\n",
      "300it [00:34,  8.75it/s]Train epoch: 1 [batch #300, batch_size 1, seq length 2500]\tLoss: 4.318521\n",
      "325it [00:37,  8.70it/s]Train epoch: 1 [batch #325, batch_size 1, seq length 2500]\tLoss: 4.309431\n",
      "350it [00:40,  8.71it/s]Train epoch: 1 [batch #350, batch_size 1, seq length 2500]\tLoss: 4.612154\n",
      "375it [00:42,  8.77it/s]Train epoch: 1 [batch #375, batch_size 1, seq length 2500]\tLoss: 4.597962\n",
      "400it [00:45,  8.77it/s]Train epoch: 1 [batch #400, batch_size 1, seq length 2500]\tLoss: 4.672013\n",
      "425it [00:48,  8.73it/s]Train epoch: 1 [batch #425, batch_size 1, seq length 2500]\tLoss: 4.520436\n",
      "450it [00:51,  8.66it/s]Train epoch: 1 [batch #450, batch_size 1, seq length 2500]\tLoss: 4.611543\n",
      "475it [00:54,  8.76it/s]Train epoch: 1 [batch #475, batch_size 1, seq length 2500]\tLoss: 4.808216\n",
      "500it [00:57,  8.55it/s]Train epoch: 1 [batch #500, batch_size 1, seq length 2500]\tLoss: 4.516499\n",
      "525it [01:00,  8.75it/s]Train epoch: 1 [batch #525, batch_size 1, seq length 2500]\tLoss: 4.795343\n",
      "550it [01:03,  8.70it/s]Train epoch: 1 [batch #550, batch_size 1, seq length 2500]\tLoss: 4.172396\n",
      "575it [01:05,  8.77it/s]Train epoch: 1 [batch #575, batch_size 1, seq length 2500]\tLoss: 4.593883\n",
      "600it [01:08,  8.68it/s]Train epoch: 1 [batch #600, batch_size 1, seq length 2500]\tLoss: 4.780876\n",
      "625it [01:11,  8.73it/s]Train epoch: 1 [batch #625, batch_size 1, seq length 2500]\tLoss: 4.399850\n",
      "650it [01:14,  8.77it/s]Train epoch: 1 [batch #650, batch_size 1, seq length 2500]\tLoss: 4.633460\n",
      "675it [01:17,  8.70it/s]Train epoch: 1 [batch #675, batch_size 1, seq length 2500]\tLoss: 4.535605\n",
      "700it [01:20,  8.76it/s]Train epoch: 1 [batch #700, batch_size 1, seq length 2500]\tLoss: 4.652557\n",
      "725it [01:23,  8.75it/s]Train epoch: 1 [batch #725, batch_size 1, seq length 2500]\tLoss: 4.622658\n",
      "750it [01:25,  8.76it/s]Train epoch: 1 [batch #750, batch_size 1, seq length 2500]\tLoss: 4.680841\n",
      "775it [01:28,  8.72it/s]Train epoch: 1 [batch #775, batch_size 1, seq length 2500]\tLoss: 4.789654\n",
      "800it [01:31,  8.71it/s]Train epoch: 1 [batch #800, batch_size 1, seq length 2500]\tLoss: 4.575578\n",
      "825it [01:34,  8.72it/s]Train epoch: 1 [batch #825, batch_size 1, seq length 2500]\tLoss: 4.417479\n",
      "850it [01:37,  8.77it/s]Train epoch: 1 [batch #850, batch_size 1, seq length 2500]\tLoss: 4.639655\n",
      "875it [01:40,  8.73it/s]Train epoch: 1 [batch #875, batch_size 1, seq length 2500]\tLoss: 4.701419\n",
      "900it [01:43,  8.76it/s]Train epoch: 1 [batch #900, batch_size 1, seq length 2500]\tLoss: 4.549874\n",
      "925it [01:45,  8.72it/s]Train epoch: 1 [batch #925, batch_size 1, seq length 2500]\tLoss: 4.370722\n",
      "950it [01:48,  8.72it/s]Train epoch: 1 [batch #950, batch_size 1, seq length 2500]\tLoss: 4.682648\n",
      "975it [01:51,  8.73it/s]Train epoch: 1 [batch #975, batch_size 1, seq length 2500]\tLoss: 4.539371\n",
      "1000it [01:54,  8.73it/s]Train epoch: 1 [batch #1000, batch_size 1, seq length 2500]\tLoss: 4.604873\n",
      "1025it [01:57,  8.66it/s]Train epoch: 1 [batch #1025, batch_size 1, seq length 2500]\tLoss: 4.677350\n",
      "1050it [02:00,  8.72it/s]Train epoch: 1 [batch #1050, batch_size 1, seq length 2500]\tLoss: 4.613572\n",
      "1075it [02:03,  8.75it/s]Train epoch: 1 [batch #1075, batch_size 1, seq length 2500]\tLoss: 4.447221\n",
      "1100it [02:06,  8.71it/s]Train epoch: 1 [batch #1100, batch_size 1, seq length 2500]\tLoss: 4.357232\n",
      "1125it [02:08,  8.73it/s]Train epoch: 1 [batch #1125, batch_size 1, seq length 2500]\tLoss: 4.579330\n",
      "1150it [02:11,  8.71it/s]Train epoch: 1 [batch #1150, batch_size 1, seq length 2500]\tLoss: 4.693457\n",
      "1175it [02:14,  8.76it/s]Train epoch: 1 [batch #1175, batch_size 1, seq length 2500]\tLoss: 4.644285\n",
      "1200it [02:17,  8.78it/s]Train epoch: 1 [batch #1200, batch_size 1, seq length 2500]\tLoss: 4.643817\n",
      "1225it [02:20,  8.70it/s]Train epoch: 1 [batch #1225, batch_size 1, seq length 2500]\tLoss: 4.544925\n",
      "1250it [02:23,  8.73it/s]Train epoch: 1 [batch #1250, batch_size 1, seq length 2500]\tLoss: 4.724739\n",
      "1275it [02:26,  8.76it/s]Train epoch: 1 [batch #1275, batch_size 1, seq length 2500]\tLoss: 4.570273\n",
      "1300it [02:28,  8.75it/s]Train epoch: 1 [batch #1300, batch_size 1, seq length 2500]\tLoss: 4.688508\n",
      "1325it [02:31,  8.77it/s]Train epoch: 1 [batch #1325, batch_size 1, seq length 2500]\tLoss: 4.276807\n",
      "1350it [02:34,  8.73it/s]Train epoch: 1 [batch #1350, batch_size 1, seq length 2500]\tLoss: 3.970728\n",
      "1375it [02:37,  8.72it/s]Train epoch: 1 [batch #1375, batch_size 1, seq length 2500]\tLoss: 4.294163\n",
      "1400it [02:40,  8.75it/s]Train epoch: 1 [batch #1400, batch_size 1, seq length 2500]\tLoss: 4.027757\n",
      "1425it [02:43,  8.74it/s]Train epoch: 1 [batch #1425, batch_size 1, seq length 2500]\tLoss: 4.377055\n",
      "1450it [02:46,  8.75it/s]Train epoch: 1 [batch #1450, batch_size 1, seq length 2500]\tLoss: 4.366272\n",
      "1475it [02:48,  8.75it/s]Train epoch: 1 [batch #1475, batch_size 1, seq length 2500]\tLoss: 4.449711\n",
      "1500it [02:51,  8.76it/s]Train epoch: 1 [batch #1500, batch_size 1, seq length 2500]\tLoss: 4.623079\n",
      "1525it [02:54,  8.67it/s]Train epoch: 1 [batch #1525, batch_size 1, seq length 2500]\tLoss: 4.728008\n",
      "1550it [02:57,  8.78it/s]Train epoch: 1 [batch #1550, batch_size 1, seq length 2500]\tLoss: 4.544647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575it [03:00,  8.70it/s]Train epoch: 1 [batch #1575, batch_size 1, seq length 2500]\tLoss: 4.573134\n",
      "1600it [03:03,  8.75it/s]Train epoch: 1 [batch #1600, batch_size 1, seq length 2500]\tLoss: 4.560743\n",
      "1625it [03:06,  8.70it/s]Train epoch: 1 [batch #1625, batch_size 1, seq length 2500]\tLoss: 4.704294\n",
      "1650it [03:08,  8.76it/s]Train epoch: 1 [batch #1650, batch_size 1, seq length 2500]\tLoss: 4.372649\n",
      "1675it [03:11,  8.72it/s]Train epoch: 1 [batch #1675, batch_size 1, seq length 2500]\tLoss: 4.191141\n",
      "1700it [03:14,  8.71it/s]Train epoch: 1 [batch #1700, batch_size 1, seq length 2500]\tLoss: 4.701409\n",
      "1725it [03:17,  8.74it/s]Train epoch: 1 [batch #1725, batch_size 1, seq length 2500]\tLoss: 4.396045\n",
      "1750it [03:20,  8.70it/s]Train epoch: 1 [batch #1750, batch_size 1, seq length 2500]\tLoss: 4.381159\n",
      "1775it [03:23,  8.76it/s]Train epoch: 1 [batch #1775, batch_size 1, seq length 2500]\tLoss: 4.954130\n",
      "1800it [03:26,  8.76it/s]Train epoch: 1 [batch #1800, batch_size 1, seq length 2500]\tLoss: 4.518310\n",
      "1825it [03:28,  8.68it/s]Train epoch: 1 [batch #1825, batch_size 1, seq length 2500]\tLoss: 4.228701\n",
      "1850it [03:31,  8.76it/s]Train epoch: 1 [batch #1850, batch_size 1, seq length 2500]\tLoss: 4.463986\n",
      "1875it [03:34,  8.77it/s]Train epoch: 1 [batch #1875, batch_size 1, seq length 2500]\tLoss: 4.287794\n",
      "1900it [03:37,  8.78it/s]Train epoch: 1 [batch #1900, batch_size 1, seq length 2500]\tLoss: 4.304465\n",
      "1925it [03:40,  8.75it/s]Train epoch: 1 [batch #1925, batch_size 1, seq length 2500]\tLoss: 4.315174\n",
      "1950it [03:43,  8.72it/s]Train epoch: 1 [batch #1950, batch_size 1, seq length 2500]\tLoss: 4.395527\n",
      "1975it [03:46,  8.77it/s]Train epoch: 1 [batch #1975, batch_size 1, seq length 2500]\tLoss: 4.304470\n",
      "2000it [03:48,  8.76it/s]Train epoch: 1 [batch #2000, batch_size 1, seq length 2500]\tLoss: 4.099087\n",
      "2025it [03:51,  8.74it/s]Train epoch: 1 [batch #2025, batch_size 1, seq length 2500]\tLoss: 4.488611\n",
      "2050it [03:54,  8.74it/s]Train epoch: 1 [batch #2050, batch_size 1, seq length 2500]\tLoss: 4.387399\n",
      "2075it [03:57,  8.75it/s]Train epoch: 1 [batch #2075, batch_size 1, seq length 2500]\tLoss: 4.554570\n",
      "2100it [04:00,  8.75it/s]Train epoch: 1 [batch #2100, batch_size 1, seq length 2500]\tLoss: 4.464309\n",
      "2125it [04:03,  8.73it/s]Train epoch: 1 [batch #2125, batch_size 1, seq length 2500]\tLoss: 4.488364\n",
      "2150it [04:06,  8.64it/s]Train epoch: 1 [batch #2150, batch_size 1, seq length 2500]\tLoss: 4.617446\n",
      "2175it [04:09,  8.77it/s]Train epoch: 1 [batch #2175, batch_size 1, seq length 2500]\tLoss: 4.572027\n",
      "2200it [04:11,  8.77it/s]Train epoch: 1 [batch #2200, batch_size 1, seq length 2500]\tLoss: 4.746171\n",
      "2225it [04:14,  8.70it/s]Train epoch: 1 [batch #2225, batch_size 1, seq length 2500]\tLoss: 4.458618\n",
      "2250it [04:17,  8.75it/s]Train epoch: 1 [batch #2250, batch_size 1, seq length 2500]\tLoss: 4.309459\n",
      "2275it [04:20,  8.77it/s]Train epoch: 1 [batch #2275, batch_size 1, seq length 2500]\tLoss: 4.359171\n",
      "2300it [04:23,  8.77it/s]Train epoch: 1 [batch #2300, batch_size 1, seq length 2500]\tLoss: 4.246890\n",
      "2325it [04:26,  8.77it/s]Train epoch: 1 [batch #2325, batch_size 1, seq length 2500]\tLoss: 4.329970\n",
      "2350it [04:29,  8.74it/s]Train epoch: 1 [batch #2350, batch_size 1, seq length 2500]\tLoss: 4.514678\n",
      "2375it [04:31,  8.66it/s]Train epoch: 1 [batch #2375, batch_size 1, seq length 2500]\tLoss: 4.668686\n",
      "2400it [04:34,  8.73it/s]Train epoch: 1 [batch #2400, batch_size 1, seq length 2500]\tLoss: 4.578279\n",
      "2425it [04:37,  8.76it/s]Train epoch: 1 [batch #2425, batch_size 1, seq length 2500]\tLoss: 4.423569\n",
      "2450it [04:40,  8.75it/s]Train epoch: 1 [batch #2450, batch_size 1, seq length 2500]\tLoss: 4.505904\n",
      "2475it [04:43,  8.77it/s]Train epoch: 1 [batch #2475, batch_size 1, seq length 2500]\tLoss: 4.656033\n",
      "2500it [04:46,  8.70it/s]Train epoch: 1 [batch #2500, batch_size 1, seq length 2500]\tLoss: 4.541993\n",
      "2525it [04:49,  8.74it/s]Train epoch: 1 [batch #2525, batch_size 1, seq length 2500]\tLoss: 4.525330\n",
      "2550it [04:51,  8.76it/s]Train epoch: 1 [batch #2550, batch_size 1, seq length 2500]\tLoss: 4.376352\n",
      "2575it [04:54,  8.75it/s]Train epoch: 1 [batch #2575, batch_size 1, seq length 2500]\tLoss: 4.471165\n",
      "2600it [04:57,  8.75it/s]Train epoch: 1 [batch #2600, batch_size 1, seq length 2500]\tLoss: 4.709205\n",
      "2625it [05:00,  8.69it/s]Train epoch: 1 [batch #2625, batch_size 1, seq length 2500]\tLoss: 4.450610\n",
      "2650it [05:03,  8.74it/s]Train epoch: 1 [batch #2650, batch_size 1, seq length 2500]\tLoss: 4.312471\n",
      "2675it [05:06,  8.76it/s]Train epoch: 1 [batch #2675, batch_size 1, seq length 2500]\tLoss: 4.466723\n",
      "2700it [05:09,  8.76it/s]Train epoch: 1 [batch #2700, batch_size 1, seq length 2500]\tLoss: 4.492028\n",
      "2725it [05:11,  8.76it/s]Train epoch: 1 [batch #2725, batch_size 1, seq length 2500]\tLoss: 4.557914\n",
      "2750it [05:14,  8.69it/s]Train epoch: 1 [batch #2750, batch_size 1, seq length 2500]\tLoss: 4.499021\n",
      "2775it [05:17,  8.76it/s]Train epoch: 1 [batch #2775, batch_size 1, seq length 2500]\tLoss: 4.393284\n",
      "2800it [05:20,  8.76it/s]Train epoch: 1 [batch #2800, batch_size 1, seq length 2500]\tLoss: 4.242764\n",
      "2825it [05:23,  8.73it/s]Train epoch: 1 [batch #2825, batch_size 1, seq length 2500]\tLoss: 4.490160\n",
      "2850it [05:26,  8.71it/s]Train epoch: 1 [batch #2850, batch_size 1, seq length 2500]\tLoss: 4.125544\n",
      "2875it [05:29,  8.77it/s]Train epoch: 1 [batch #2875, batch_size 1, seq length 2500]\tLoss: 4.203575\n",
      "2900it [05:31,  8.67it/s]Train epoch: 1 [batch #2900, batch_size 1, seq length 2500]\tLoss: 4.223063\n",
      "2925it [05:34,  8.74it/s]Train epoch: 1 [batch #2925, batch_size 1, seq length 2500]\tLoss: 4.649490\n",
      "2950it [05:37,  8.73it/s]Train epoch: 1 [batch #2950, batch_size 1, seq length 2500]\tLoss: 4.576199\n",
      "2975it [05:40,  8.61it/s]Train epoch: 1 [batch #2975, batch_size 1, seq length 2500]\tLoss: 4.426216\n",
      "3000it [05:43,  8.72it/s]Train epoch: 1 [batch #3000, batch_size 1, seq length 2500]\tLoss: 4.324438\n",
      "3025it [05:46,  8.74it/s]Train epoch: 1 [batch #3025, batch_size 1, seq length 2500]\tLoss: 4.147319\n",
      "3050it [05:49,  8.72it/s]Train epoch: 1 [batch #3050, batch_size 1, seq length 2500]\tLoss: 4.658603\n",
      "3075it [05:52,  8.75it/s]Train epoch: 1 [batch #3075, batch_size 1, seq length 2500]\tLoss: 4.307786\n",
      "3100it [05:54,  8.73it/s]Train epoch: 1 [batch #3100, batch_size 1, seq length 2500]\tLoss: 4.316992\n",
      "3125it [05:57,  8.75it/s]Train epoch: 1 [batch #3125, batch_size 1, seq length 2500]\tLoss: 4.607415\n",
      "3150it [06:00,  8.72it/s]Train epoch: 1 [batch #3150, batch_size 1, seq length 2500]\tLoss: 4.631016\n",
      "3175it [06:03,  8.74it/s]Train epoch: 1 [batch #3175, batch_size 1, seq length 2500]\tLoss: 4.641172\n",
      "3200it [06:06,  8.73it/s]Train epoch: 1 [batch #3200, batch_size 1, seq length 2500]\tLoss: 4.456014\n",
      "3225it [06:09,  8.73it/s]Train epoch: 1 [batch #3225, batch_size 1, seq length 2500]\tLoss: 4.483313\n",
      "3250it [06:12,  8.72it/s]Train epoch: 1 [batch #3250, batch_size 1, seq length 2500]\tLoss: 4.604919\n",
      "3275it [06:14,  8.71it/s]Train epoch: 1 [batch #3275, batch_size 1, seq length 2500]\tLoss: 4.544572\n",
      "3300it [06:17,  8.73it/s]Train epoch: 1 [batch #3300, batch_size 1, seq length 2500]\tLoss: 4.478158\n",
      "3325it [06:20,  8.73it/s]Train epoch: 1 [batch #3325, batch_size 1, seq length 2500]\tLoss: 4.412065\n",
      "3350it [06:23,  8.71it/s]Train epoch: 1 [batch #3350, batch_size 1, seq length 2500]\tLoss: 4.475243\n",
      "3375it [06:26,  8.76it/s]Train epoch: 1 [batch #3375, batch_size 1, seq length 2500]\tLoss: 4.570127\n",
      "3400it [06:29,  8.76it/s]Train epoch: 1 [batch #3400, batch_size 1, seq length 2500]\tLoss: 4.575674\n",
      "3425it [06:32,  8.50it/s]Train epoch: 1 [batch #3425, batch_size 1, seq length 2500]\tLoss: 4.388138\n",
      "3450it [06:34,  8.69it/s]Train epoch: 1 [batch #3450, batch_size 1, seq length 2500]\tLoss: 4.583277\n",
      "3475it [06:37,  8.74it/s]Train epoch: 1 [batch #3475, batch_size 1, seq length 2500]\tLoss: 4.739002\n",
      "3500it [06:40,  8.73it/s]Train epoch: 1 [batch #3500, batch_size 1, seq length 2500]\tLoss: 4.082081\n",
      "3525it [06:43,  8.60it/s]Train epoch: 1 [batch #3525, batch_size 1, seq length 2500]\tLoss: 4.242790\n",
      "3550it [06:46,  8.76it/s]Train epoch: 1 [batch #3550, batch_size 1, seq length 2500]\tLoss: 4.134673\n",
      "3575it [06:49,  8.75it/s]Train epoch: 1 [batch #3575, batch_size 1, seq length 2500]\tLoss: 4.780897\n",
      "3600it [06:52,  8.75it/s]Train epoch: 1 [batch #3600, batch_size 1, seq length 2500]\tLoss: 4.531149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3625it [06:55,  8.78it/s]Train epoch: 1 [batch #3625, batch_size 1, seq length 2500]\tLoss: 4.367382\n",
      "3650it [06:57,  8.73it/s]Train epoch: 1 [batch #3650, batch_size 1, seq length 2500]\tLoss: 4.445841\n",
      "3675it [07:00,  8.78it/s]Train epoch: 1 [batch #3675, batch_size 1, seq length 2500]\tLoss: 4.325506\n",
      "3700it [07:03,  8.74it/s]Train epoch: 1 [batch #3700, batch_size 1, seq length 2500]\tLoss: 3.895369\n",
      "3725it [07:06,  8.75it/s]Train epoch: 1 [batch #3725, batch_size 1, seq length 2500]\tLoss: 4.484255\n",
      "3750it [07:09,  8.75it/s]Train epoch: 1 [batch #3750, batch_size 1, seq length 2500]\tLoss: 4.250221\n",
      "3775it [07:12,  8.72it/s]Train epoch: 1 [batch #3775, batch_size 1, seq length 2500]\tLoss: 4.459758\n",
      "3800it [07:15,  8.73it/s]Train epoch: 1 [batch #3800, batch_size 1, seq length 2500]\tLoss: 4.606428\n",
      "3825it [07:17,  8.75it/s]Train epoch: 1 [batch #3825, batch_size 1, seq length 2500]\tLoss: 4.381401\n",
      "3850it [07:20,  8.71it/s]Train epoch: 1 [batch #3850, batch_size 1, seq length 2500]\tLoss: 4.280781\n",
      "3875it [07:23,  8.75it/s]Train epoch: 1 [batch #3875, batch_size 1, seq length 2500]\tLoss: 4.502036\n",
      "3900it [07:26,  8.75it/s]Train epoch: 1 [batch #3900, batch_size 1, seq length 2500]\tLoss: 4.538403\n",
      "3925it [07:29,  8.74it/s]Train epoch: 1 [batch #3925, batch_size 1, seq length 2500]\tLoss: 4.616676\n",
      "3950it [07:32,  8.68it/s]Train epoch: 1 [batch #3950, batch_size 1, seq length 2500]\tLoss: 4.378946\n",
      "3975it [07:35,  8.74it/s]Train epoch: 1 [batch #3975, batch_size 1, seq length 2500]\tLoss: 4.416840\n",
      "4000it [07:37,  8.74it/s]Train epoch: 1 [batch #4000, batch_size 1, seq length 2500]\tLoss: 4.340354\n",
      "4025it [07:40,  8.73it/s]Train epoch: 1 [batch #4025, batch_size 1, seq length 2500]\tLoss: 4.315269\n",
      "4050it [07:43,  8.75it/s]Train epoch: 1 [batch #4050, batch_size 1, seq length 2500]\tLoss: 4.362028\n",
      "4075it [07:46,  8.77it/s]Train epoch: 1 [batch #4075, batch_size 1, seq length 2500]\tLoss: 4.601481\n",
      "4100it [07:49,  8.75it/s]Train epoch: 1 [batch #4100, batch_size 1, seq length 2500]\tLoss: 4.564248\n",
      "4125it [07:52,  8.76it/s]Train epoch: 1 [batch #4125, batch_size 1, seq length 2500]\tLoss: 4.857756\n",
      "4150it [07:55,  8.75it/s]Train epoch: 1 [batch #4150, batch_size 1, seq length 2500]\tLoss: 4.731574\n",
      "4175it [07:57,  8.76it/s]Train epoch: 1 [batch #4175, batch_size 1, seq length 2500]\tLoss: 4.561268\n",
      "4200it [08:00,  8.62it/s]Train epoch: 1 [batch #4200, batch_size 1, seq length 2500]\tLoss: 4.231585\n",
      "4225it [08:03,  8.75it/s]Train epoch: 1 [batch #4225, batch_size 1, seq length 2500]\tLoss: 4.346024\n",
      "4250it [08:06,  8.73it/s]Train epoch: 1 [batch #4250, batch_size 1, seq length 2500]\tLoss: 4.618225\n",
      "4275it [08:09,  8.76it/s]Train epoch: 1 [batch #4275, batch_size 1, seq length 2500]\tLoss: 4.653517\n",
      "4300it [08:12,  8.76it/s]Train epoch: 1 [batch #4300, batch_size 1, seq length 2500]\tLoss: 4.294676\n",
      "4325it [08:15,  8.74it/s]Train epoch: 1 [batch #4325, batch_size 1, seq length 2500]\tLoss: 4.505238\n",
      "4350it [08:18,  8.67it/s]Train epoch: 1 [batch #4350, batch_size 1, seq length 2500]\tLoss: 4.278543\n",
      "4375it [08:20,  8.72it/s]Train epoch: 1 [batch #4375, batch_size 1, seq length 2500]\tLoss: 4.752022\n",
      "4400it [08:23,  8.72it/s]Train epoch: 1 [batch #4400, batch_size 1, seq length 2500]\tLoss: 4.612462\n",
      "4425it [08:26,  8.77it/s]Train epoch: 1 [batch #4425, batch_size 1, seq length 2500]\tLoss: 4.440961\n",
      "4450it [08:29,  8.71it/s]Train epoch: 1 [batch #4450, batch_size 1, seq length 2500]\tLoss: 4.415682\n",
      "4475it [08:32,  8.72it/s]Train epoch: 1 [batch #4475, batch_size 1, seq length 2500]\tLoss: 4.397397\n",
      "4500it [08:35,  8.75it/s]Train epoch: 1 [batch #4500, batch_size 1, seq length 2500]\tLoss: 4.047508\n",
      "4525it [08:38,  8.71it/s]Train epoch: 1 [batch #4525, batch_size 1, seq length 2500]\tLoss: 4.666404\n",
      "4550it [08:40,  8.77it/s]Train epoch: 1 [batch #4550, batch_size 1, seq length 2500]\tLoss: 4.402434\n",
      "4575it [08:43,  8.73it/s]Train epoch: 1 [batch #4575, batch_size 1, seq length 2500]\tLoss: 4.343612\n",
      "4600it [08:46,  8.74it/s]Train epoch: 1 [batch #4600, batch_size 1, seq length 2500]\tLoss: 4.399555\n",
      "4625it [08:49,  8.76it/s]Train epoch: 1 [batch #4625, batch_size 1, seq length 2500]\tLoss: 4.435084\n",
      "4650it [08:52,  8.78it/s]Train epoch: 1 [batch #4650, batch_size 1, seq length 2500]\tLoss: 4.485709\n",
      "4675it [08:55,  8.67it/s]Train epoch: 1 [batch #4675, batch_size 1, seq length 2500]\tLoss: 4.408713\n",
      "4700it [08:58,  8.72it/s]Train epoch: 1 [batch #4700, batch_size 1, seq length 2500]\tLoss: 4.592621\n",
      "4725it [09:00,  8.69it/s]Train epoch: 1 [batch #4725, batch_size 1, seq length 2500]\tLoss: 4.213867\n",
      "4750it [09:03,  8.73it/s]Train epoch: 1 [batch #4750, batch_size 1, seq length 2500]\tLoss: 4.303909\n",
      "4775it [09:06,  8.75it/s]Train epoch: 1 [batch #4775, batch_size 1, seq length 2500]\tLoss: 4.458135\n",
      "4800it [09:09,  8.73it/s]Train epoch: 1 [batch #4800, batch_size 1, seq length 2500]\tLoss: 4.530908\n",
      "4825it [09:12,  8.74it/s]Train epoch: 1 [batch #4825, batch_size 1, seq length 2500]\tLoss: 4.256749\n",
      "4850it [09:15,  8.77it/s]Train epoch: 1 [batch #4850, batch_size 1, seq length 2500]\tLoss: 4.475377\n",
      "4875it [09:18,  8.75it/s]Train epoch: 1 [batch #4875, batch_size 1, seq length 2500]\tLoss: 4.558279\n",
      "4900it [09:21,  8.75it/s]Train epoch: 1 [batch #4900, batch_size 1, seq length 2500]\tLoss: 4.606354\n",
      "4925it [09:23,  8.74it/s]Train epoch: 1 [batch #4925, batch_size 1, seq length 2500]\tLoss: 4.508727\n",
      "4950it [09:26,  8.76it/s]Train epoch: 1 [batch #4950, batch_size 1, seq length 2500]\tLoss: 4.589491\n",
      "4975it [09:29,  8.77it/s]Train epoch: 1 [batch #4975, batch_size 1, seq length 2500]\tLoss: 4.717509\n",
      "5000it [09:32,  8.74it/s]Train epoch: 1 [batch #5000, batch_size 1, seq length 2500]\tLoss: 4.403671\n",
      "5025it [09:35,  8.70it/s]Train epoch: 1 [batch #5025, batch_size 1, seq length 2500]\tLoss: 4.490589\n",
      "5050it [09:38,  8.77it/s]Train epoch: 1 [batch #5050, batch_size 1, seq length 2500]\tLoss: 4.521598\n",
      "5075it [09:41,  8.75it/s]Train epoch: 1 [batch #5075, batch_size 1, seq length 2500]\tLoss: 4.475322\n",
      "5100it [09:43,  8.71it/s]Train epoch: 1 [batch #5100, batch_size 1, seq length 2500]\tLoss: 4.530575\n",
      "5125it [09:46,  8.76it/s]Train epoch: 1 [batch #5125, batch_size 1, seq length 2500]\tLoss: 4.440603\n",
      "5150it [09:49,  8.74it/s]Train epoch: 1 [batch #5150, batch_size 1, seq length 2500]\tLoss: 4.167199\n",
      "5175it [09:52,  8.76it/s]Train epoch: 1 [batch #5175, batch_size 1, seq length 2500]\tLoss: 3.993274\n",
      "5200it [09:55,  8.77it/s]Train epoch: 1 [batch #5200, batch_size 1, seq length 2500]\tLoss: 4.691965\n",
      "5225it [09:58,  8.76it/s]Train epoch: 1 [batch #5225, batch_size 1, seq length 2500]\tLoss: 4.255394\n",
      "5250it [10:01,  8.62it/s]Train epoch: 1 [batch #5250, batch_size 1, seq length 2500]\tLoss: 4.317948\n",
      "5275it [10:03,  8.77it/s]Train epoch: 1 [batch #5275, batch_size 1, seq length 2500]\tLoss: 4.525612\n",
      "5300it [10:06,  8.72it/s]Train epoch: 1 [batch #5300, batch_size 1, seq length 2500]\tLoss: 4.350947\n",
      "5325it [10:09,  8.74it/s]Train epoch: 1 [batch #5325, batch_size 1, seq length 2500]\tLoss: 4.067136\n",
      "5350it [10:12,  8.73it/s]Train epoch: 1 [batch #5350, batch_size 1, seq length 2500]\tLoss: 4.394018\n",
      "5375it [10:15,  8.70it/s]Train epoch: 1 [batch #5375, batch_size 1, seq length 2500]\tLoss: 4.525493\n",
      "5400it [10:18,  8.77it/s]Train epoch: 1 [batch #5400, batch_size 1, seq length 2500]\tLoss: 4.661386\n",
      "5425it [10:21,  8.76it/s]Train epoch: 1 [batch #5425, batch_size 1, seq length 2500]\tLoss: 4.571939\n",
      "5450it [10:23,  8.69it/s]Train epoch: 1 [batch #5450, batch_size 1, seq length 2500]\tLoss: 4.514837\n",
      "5475it [10:26,  8.76it/s]Train epoch: 1 [batch #5475, batch_size 1, seq length 2500]\tLoss: 4.428893\n",
      "5500it [10:29,  8.75it/s]Train epoch: 1 [batch #5500, batch_size 1, seq length 2500]\tLoss: 4.568860\n",
      "5525it [10:32,  8.77it/s]Train epoch: 1 [batch #5525, batch_size 1, seq length 2500]\tLoss: 4.344042\n",
      "5550it [10:35,  8.72it/s]Train epoch: 1 [batch #5550, batch_size 1, seq length 2500]\tLoss: 4.175922\n",
      "5575it [10:38,  8.77it/s]Train epoch: 1 [batch #5575, batch_size 1, seq length 2500]\tLoss: 4.084617\n",
      "5600it [10:41,  8.76it/s]Train epoch: 1 [batch #5600, batch_size 1, seq length 2500]\tLoss: 4.257505\n",
      "5625it [10:43,  8.73it/s]Train epoch: 1 [batch #5625, batch_size 1, seq length 2500]\tLoss: 4.291224\n",
      "5650it [10:46,  8.74it/s]Train epoch: 1 [batch #5650, batch_size 1, seq length 2500]\tLoss: 4.138559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5675it [10:49,  8.76it/s]Train epoch: 1 [batch #5675, batch_size 1, seq length 2500]\tLoss: 4.200680\n",
      "5700it [10:52,  8.76it/s]Train epoch: 1 [batch #5700, batch_size 1, seq length 2500]\tLoss: 4.341815\n",
      "5725it [10:55,  8.78it/s]Train epoch: 1 [batch #5725, batch_size 1, seq length 2500]\tLoss: 4.232312\n",
      "5750it [10:58,  8.70it/s]Train epoch: 1 [batch #5750, batch_size 1, seq length 2500]\tLoss: 4.064595\n",
      "5775it [11:01,  8.76it/s]Train epoch: 1 [batch #5775, batch_size 1, seq length 2500]\tLoss: 4.713098\n",
      "5800it [11:03,  8.77it/s]Train epoch: 1 [batch #5800, batch_size 1, seq length 2500]\tLoss: 4.219302\n",
      "5825it [11:06,  8.78it/s]Train epoch: 1 [batch #5825, batch_size 1, seq length 2500]\tLoss: 4.550444\n",
      "5850it [11:09,  8.70it/s]Train epoch: 1 [batch #5850, batch_size 1, seq length 2500]\tLoss: 4.349020\n",
      "5875it [11:12,  8.76it/s]Train epoch: 1 [batch #5875, batch_size 1, seq length 2500]\tLoss: 4.143244\n",
      "5900it [11:15,  8.75it/s]Train epoch: 1 [batch #5900, batch_size 1, seq length 2500]\tLoss: 4.610048\n",
      "5925it [11:18,  8.74it/s]Train epoch: 1 [batch #5925, batch_size 1, seq length 2500]\tLoss: 4.330930\n",
      "5950it [11:21,  8.73it/s]Train epoch: 1 [batch #5950, batch_size 1, seq length 2500]\tLoss: 4.650394\n",
      "5975it [11:23,  8.75it/s]Train epoch: 1 [batch #5975, batch_size 1, seq length 2500]\tLoss: 4.425895\n",
      "6000it [11:26,  8.76it/s]Train epoch: 1 [batch #6000, batch_size 1, seq length 2500]\tLoss: 4.329041\n",
      "6025it [11:29,  8.75it/s]Train epoch: 1 [batch #6025, batch_size 1, seq length 2500]\tLoss: 4.455695\n",
      "6050it [11:32,  8.76it/s]Train epoch: 1 [batch #6050, batch_size 1, seq length 2500]\tLoss: 4.213810\n",
      "6075it [11:35,  8.67it/s]Train epoch: 1 [batch #6075, batch_size 1, seq length 2500]\tLoss: 4.281845\n",
      "6100it [11:38,  8.73it/s]Train epoch: 1 [batch #6100, batch_size 1, seq length 2500]\tLoss: 4.130791\n",
      "6125it [11:41,  8.71it/s]Train epoch: 1 [batch #6125, batch_size 1, seq length 2500]\tLoss: 4.357897\n",
      "6150it [11:44,  8.77it/s]Train epoch: 1 [batch #6150, batch_size 1, seq length 2500]\tLoss: 4.155009\n",
      "6175it [11:46,  8.74it/s]Train epoch: 1 [batch #6175, batch_size 1, seq length 2500]\tLoss: 4.475310\n",
      "6200it [11:49,  8.48it/s]Train epoch: 1 [batch #6200, batch_size 1, seq length 2500]\tLoss: 4.067111\n",
      "6225it [11:52,  8.77it/s]Train epoch: 1 [batch #6225, batch_size 1, seq length 2500]\tLoss: 4.290427\n",
      "6250it [11:55,  8.74it/s]Train epoch: 1 [batch #6250, batch_size 1, seq length 2500]\tLoss: 4.513151\n",
      "6275it [11:58,  8.76it/s]Train epoch: 1 [batch #6275, batch_size 1, seq length 2500]\tLoss: 4.471044\n",
      "6300it [12:01,  8.75it/s]Train epoch: 1 [batch #6300, batch_size 1, seq length 2500]\tLoss: 4.319762\n",
      "6325it [12:04,  8.75it/s]Train epoch: 1 [batch #6325, batch_size 1, seq length 2500]\tLoss: 4.054792\n",
      "6350it [12:06,  8.72it/s]Train epoch: 1 [batch #6350, batch_size 1, seq length 2500]\tLoss: 4.322092\n",
      "6375it [12:09,  8.71it/s]Train epoch: 1 [batch #6375, batch_size 1, seq length 2500]\tLoss: 4.275539\n",
      "6400it [12:12,  8.73it/s]Train epoch: 1 [batch #6400, batch_size 1, seq length 2500]\tLoss: 4.174328\n",
      "6425it [12:15,  8.72it/s]Train epoch: 1 [batch #6425, batch_size 1, seq length 2500]\tLoss: 4.544315\n",
      "6450it [12:18,  8.74it/s]Train epoch: 1 [batch #6450, batch_size 1, seq length 2500]\tLoss: 4.319418\n",
      "6475it [12:21,  8.67it/s]Train epoch: 1 [batch #6475, batch_size 1, seq length 2500]\tLoss: 4.247354\n",
      "6500it [12:24,  8.70it/s]Train epoch: 1 [batch #6500, batch_size 1, seq length 2500]\tLoss: 4.208363\n",
      "6525it [12:27,  8.76it/s]Train epoch: 1 [batch #6525, batch_size 1, seq length 2500]\tLoss: 4.380718\n",
      "6550it [12:29,  8.74it/s]Train epoch: 1 [batch #6550, batch_size 1, seq length 2500]\tLoss: 4.327589\n",
      "6575it [12:32,  8.73it/s]Train epoch: 1 [batch #6575, batch_size 1, seq length 2500]\tLoss: 4.674283\n",
      "6600it [12:35,  8.72it/s]Train epoch: 1 [batch #6600, batch_size 1, seq length 2500]\tLoss: 4.254039\n",
      "6625it [12:38,  8.75it/s]Train epoch: 1 [batch #6625, batch_size 1, seq length 2500]\tLoss: 4.189914\n",
      "6650it [12:41,  8.77it/s]Train epoch: 1 [batch #6650, batch_size 1, seq length 2500]\tLoss: 4.380914\n",
      "6675it [12:44,  8.68it/s]Train epoch: 1 [batch #6675, batch_size 1, seq length 2500]\tLoss: 4.425586\n",
      "6700it [12:47,  8.76it/s]Train epoch: 1 [batch #6700, batch_size 1, seq length 2500]\tLoss: 4.561649\n",
      "6725it [12:49,  8.77it/s]Train epoch: 1 [batch #6725, batch_size 1, seq length 2500]\tLoss: 4.230174\n",
      "6750it [12:52,  8.76it/s]Train epoch: 1 [batch #6750, batch_size 1, seq length 2500]\tLoss: 4.311143\n",
      "6775it [12:55,  8.77it/s]Train epoch: 1 [batch #6775, batch_size 1, seq length 2500]\tLoss: 4.306223\n",
      "6800it [12:58,  8.73it/s]Train epoch: 1 [batch #6800, batch_size 1, seq length 2500]\tLoss: 4.410608\n",
      "6825it [13:01,  8.75it/s]Train epoch: 1 [batch #6825, batch_size 1, seq length 2500]\tLoss: 4.161506\n",
      "6850it [13:04,  8.69it/s]Train epoch: 1 [batch #6850, batch_size 1, seq length 2500]\tLoss: 4.338753\n",
      "6875it [13:07,  8.74it/s]Train epoch: 1 [batch #6875, batch_size 1, seq length 2500]\tLoss: 3.974847\n",
      "6900it [13:10,  8.65it/s]Train epoch: 1 [batch #6900, batch_size 1, seq length 2500]\tLoss: 4.312609\n",
      "6925it [13:12,  8.69it/s]Train epoch: 1 [batch #6925, batch_size 1, seq length 2500]\tLoss: 4.386239\n",
      "6950it [13:15,  8.76it/s]Train epoch: 1 [batch #6950, batch_size 1, seq length 2500]\tLoss: 4.494514\n",
      "6975it [13:18,  8.74it/s]Train epoch: 1 [batch #6975, batch_size 1, seq length 2500]\tLoss: 4.362077\n",
      "7000it [13:21,  8.71it/s]Train epoch: 1 [batch #7000, batch_size 1, seq length 2500]\tLoss: 4.384469\n",
      "7025it [13:24,  8.73it/s]Train epoch: 1 [batch #7025, batch_size 1, seq length 2500]\tLoss: 4.395938\n",
      "7050it [13:27,  8.73it/s]Train epoch: 1 [batch #7050, batch_size 1, seq length 2500]\tLoss: 4.333797\n",
      "7075it [13:30,  8.72it/s]Train epoch: 1 [batch #7075, batch_size 1, seq length 2500]\tLoss: 4.254444\n",
      "7100it [13:32,  8.57it/s]Train epoch: 1 [batch #7100, batch_size 1, seq length 2500]\tLoss: 4.211952\n",
      "7125it [13:35,  8.76it/s]Train epoch: 1 [batch #7125, batch_size 1, seq length 2500]\tLoss: 4.332237\n",
      "7150it [13:38,  8.75it/s]Train epoch: 1 [batch #7150, batch_size 1, seq length 2500]\tLoss: 4.146663\n",
      "7175it [13:41,  8.72it/s]Train epoch: 1 [batch #7175, batch_size 1, seq length 2500]\tLoss: 4.585127\n",
      "7200it [13:44,  8.70it/s]Train epoch: 1 [batch #7200, batch_size 1, seq length 2500]\tLoss: 4.130975\n",
      "7225it [13:47,  8.75it/s]Train epoch: 1 [batch #7225, batch_size 1, seq length 2500]\tLoss: 4.481472\n",
      "7250it [13:50,  8.74it/s]Train epoch: 1 [batch #7250, batch_size 1, seq length 2500]\tLoss: 4.474417\n",
      "7275it [13:53,  8.77it/s]Train epoch: 1 [batch #7275, batch_size 1, seq length 2500]\tLoss: 4.322250\n",
      "7300it [13:55,  8.76it/s]Train epoch: 1 [batch #7300, batch_size 1, seq length 2500]\tLoss: 4.336959\n",
      "7325it [13:58,  8.74it/s]Train epoch: 1 [batch #7325, batch_size 1, seq length 2500]\tLoss: 4.838926\n",
      "7350it [14:01,  8.74it/s]Train epoch: 1 [batch #7350, batch_size 1, seq length 2500]\tLoss: 4.335827\n",
      "7375it [14:04,  8.71it/s]Train epoch: 1 [batch #7375, batch_size 1, seq length 2500]\tLoss: 4.492930\n",
      "7400it [14:07,  8.75it/s]Train epoch: 1 [batch #7400, batch_size 1, seq length 2500]\tLoss: 4.185353\n",
      "7425it [14:10,  8.73it/s]Train epoch: 1 [batch #7425, batch_size 1, seq length 2500]\tLoss: 4.478185\n",
      "7450it [14:13,  8.73it/s]Train epoch: 1 [batch #7450, batch_size 1, seq length 2500]\tLoss: 4.304659\n",
      "7475it [14:15,  8.74it/s]Train epoch: 1 [batch #7475, batch_size 1, seq length 2500]\tLoss: 4.284301\n",
      "7500it [14:18,  8.71it/s]Train epoch: 1 [batch #7500, batch_size 1, seq length 2500]\tLoss: 4.357299\n",
      "7525it [14:21,  8.72it/s]Train epoch: 1 [batch #7525, batch_size 1, seq length 2500]\tLoss: 4.268160\n",
      "7550it [14:24,  8.71it/s]Train epoch: 1 [batch #7550, batch_size 1, seq length 2500]\tLoss: 4.179697\n",
      "7575it [14:27,  8.68it/s]Train epoch: 1 [batch #7575, batch_size 1, seq length 2500]\tLoss: 4.463082\n",
      "7600it [14:30,  8.70it/s]Train epoch: 1 [batch #7600, batch_size 1, seq length 2500]\tLoss: 4.238750\n",
      "7625it [14:33,  8.73it/s]Train epoch: 1 [batch #7625, batch_size 1, seq length 2500]\tLoss: 4.502360\n",
      "7650it [14:36,  8.71it/s]Train epoch: 1 [batch #7650, batch_size 1, seq length 2500]\tLoss: 4.197380\n",
      "7675it [14:38,  8.71it/s]Train epoch: 1 [batch #7675, batch_size 1, seq length 2500]\tLoss: 4.446057\n",
      "7700it [14:41,  8.73it/s]Train epoch: 1 [batch #7700, batch_size 1, seq length 2500]\tLoss: 4.461665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7725it [14:44,  8.77it/s]Train epoch: 1 [batch #7725, batch_size 1, seq length 2500]\tLoss: 4.303960\n",
      "7750it [14:47,  8.74it/s]Train epoch: 1 [batch #7750, batch_size 1, seq length 2500]\tLoss: 4.220704\n",
      "7775it [14:50,  8.77it/s]Train epoch: 1 [batch #7775, batch_size 1, seq length 2500]\tLoss: 3.973820\n",
      "7800it [14:53,  8.71it/s]Train epoch: 1 [batch #7800, batch_size 1, seq length 2500]\tLoss: 4.252188\n",
      "7825it [14:56,  8.75it/s]Train epoch: 1 [batch #7825, batch_size 1, seq length 2500]\tLoss: 4.408794\n",
      "7850it [14:58,  8.68it/s]Train epoch: 1 [batch #7850, batch_size 1, seq length 2500]\tLoss: 3.711835\n",
      "7875it [15:01,  8.68it/s]Train epoch: 1 [batch #7875, batch_size 1, seq length 2500]\tLoss: 4.460346\n",
      "7900it [15:04,  8.74it/s]Train epoch: 1 [batch #7900, batch_size 1, seq length 2500]\tLoss: 4.082240\n",
      "7925it [15:07,  8.73it/s]Train epoch: 1 [batch #7925, batch_size 1, seq length 2500]\tLoss: 4.558390\n",
      "7950it [15:10,  8.76it/s]Train epoch: 1 [batch #7950, batch_size 1, seq length 2500]\tLoss: 4.674925\n",
      "7975it [15:13,  8.72it/s]Train epoch: 1 [batch #7975, batch_size 1, seq length 2500]\tLoss: 4.171678\n",
      "8000it [15:16,  8.72it/s]Train epoch: 1 [batch #8000, batch_size 1, seq length 2500]\tLoss: 4.298754\n",
      "8025it [15:18,  8.71it/s]Train epoch: 1 [batch #8025, batch_size 1, seq length 2500]\tLoss: 4.118262\n",
      "8050it [15:21,  8.68it/s]Train epoch: 1 [batch #8050, batch_size 1, seq length 2500]\tLoss: 4.277259\n",
      "8075it [15:24,  8.73it/s]Train epoch: 1 [batch #8075, batch_size 1, seq length 2500]\tLoss: 4.438488\n",
      "8100it [15:27,  8.74it/s]Train epoch: 1 [batch #8100, batch_size 1, seq length 2500]\tLoss: 4.032054\n",
      "8125it [15:30,  8.74it/s]Train epoch: 1 [batch #8125, batch_size 1, seq length 2500]\tLoss: 4.636696\n",
      "8150it [15:33,  8.76it/s]Train epoch: 1 [batch #8150, batch_size 1, seq length 2500]\tLoss: 4.403560\n",
      "8175it [15:36,  8.73it/s]Train epoch: 1 [batch #8175, batch_size 1, seq length 2500]\tLoss: 3.951974\n",
      "8200it [15:39,  8.72it/s]Train epoch: 1 [batch #8200, batch_size 1, seq length 2500]\tLoss: 4.097242\n",
      "8225it [15:41,  8.75it/s]Train epoch: 1 [batch #8225, batch_size 1, seq length 2500]\tLoss: 4.300916\n",
      "8250it [15:44,  8.73it/s]Train epoch: 1 [batch #8250, batch_size 1, seq length 2500]\tLoss: 4.071758\n",
      "8275it [15:47,  8.71it/s]Train epoch: 1 [batch #8275, batch_size 1, seq length 2500]\tLoss: 4.173526\n",
      "8300it [15:50,  8.75it/s]Train epoch: 1 [batch #8300, batch_size 1, seq length 2500]\tLoss: 4.175834\n",
      "8325it [15:53,  8.75it/s]Train epoch: 1 [batch #8325, batch_size 1, seq length 2500]\tLoss: 4.617764\n",
      "8350it [15:56,  8.72it/s]Train epoch: 1 [batch #8350, batch_size 1, seq length 2500]\tLoss: 4.157430\n",
      "8375it [15:59,  8.66it/s]Train epoch: 1 [batch #8375, batch_size 1, seq length 2500]\tLoss: 4.468407\n",
      "8400it [16:01,  8.71it/s]Train epoch: 1 [batch #8400, batch_size 1, seq length 2500]\tLoss: 4.094948\n",
      "8425it [16:04,  8.76it/s]Train epoch: 1 [batch #8425, batch_size 1, seq length 2500]\tLoss: 4.340666\n",
      "8450it [16:07,  8.73it/s]Train epoch: 1 [batch #8450, batch_size 1, seq length 2500]\tLoss: 4.261041\n",
      "8475it [16:10,  8.76it/s]Train epoch: 1 [batch #8475, batch_size 1, seq length 2500]\tLoss: 4.519173\n",
      "8500it [16:13,  8.76it/s]Train epoch: 1 [batch #8500, batch_size 1, seq length 2500]\tLoss: 4.130676\n",
      "8525it [16:16,  8.75it/s]Train epoch: 1 [batch #8525, batch_size 1, seq length 2500]\tLoss: 4.097982\n",
      "8550it [16:19,  8.74it/s]Train epoch: 1 [batch #8550, batch_size 1, seq length 2500]\tLoss: 4.360845\n",
      "8575it [16:22,  8.74it/s]Train epoch: 1 [batch #8575, batch_size 1, seq length 2500]\tLoss: 4.183808\n",
      "8600it [16:24,  8.71it/s]Train epoch: 1 [batch #8600, batch_size 1, seq length 2500]\tLoss: 4.224455\n",
      "8625it [16:27,  8.77it/s]Train epoch: 1 [batch #8625, batch_size 1, seq length 2500]\tLoss: 4.453693\n",
      "8650it [16:30,  8.68it/s]Train epoch: 1 [batch #8650, batch_size 1, seq length 2500]\tLoss: 4.197076\n",
      "8675it [16:33,  8.64it/s]Train epoch: 1 [batch #8675, batch_size 1, seq length 2500]\tLoss: 4.628327\n",
      "8700it [16:36,  8.75it/s]Train epoch: 1 [batch #8700, batch_size 1, seq length 2500]\tLoss: 4.206419\n",
      "8725it [16:39,  8.74it/s]Train epoch: 1 [batch #8725, batch_size 1, seq length 2500]\tLoss: 4.289200\n",
      "8750it [16:42,  8.73it/s]Train epoch: 1 [batch #8750, batch_size 1, seq length 2500]\tLoss: 3.958235\n",
      "8775it [16:44,  8.64it/s]Train epoch: 1 [batch #8775, batch_size 1, seq length 2500]\tLoss: 4.603638\n",
      "8800it [16:47,  8.77it/s]Train epoch: 1 [batch #8800, batch_size 1, seq length 2500]\tLoss: 4.168513\n",
      "8825it [16:50,  8.73it/s]Train epoch: 1 [batch #8825, batch_size 1, seq length 2500]\tLoss: 4.507432\n",
      "8850it [16:53,  8.75it/s]Train epoch: 1 [batch #8850, batch_size 1, seq length 2500]\tLoss: 4.417908\n",
      "8875it [16:56,  8.77it/s]Train epoch: 1 [batch #8875, batch_size 1, seq length 2500]\tLoss: 4.535280\n",
      "8900it [16:59,  8.71it/s]Train epoch: 1 [batch #8900, batch_size 1, seq length 2500]\tLoss: 4.505345\n",
      "8925it [17:02,  8.74it/s]Train epoch: 1 [batch #8925, batch_size 1, seq length 2500]\tLoss: 4.260476\n",
      "8950it [17:05,  8.69it/s]Train epoch: 1 [batch #8950, batch_size 1, seq length 2500]\tLoss: 4.377828\n",
      "8975it [17:07,  8.73it/s]Train epoch: 1 [batch #8975, batch_size 1, seq length 2500]\tLoss: 4.205874\n",
      "9000it [17:10,  8.73it/s]Train epoch: 1 [batch #9000, batch_size 1, seq length 2500]\tLoss: 4.111126\n",
      "9025it [17:13,  8.73it/s]Train epoch: 1 [batch #9025, batch_size 1, seq length 2500]\tLoss: 4.443587\n",
      "9050it [17:16,  8.75it/s]Train epoch: 1 [batch #9050, batch_size 1, seq length 2500]\tLoss: 3.951661\n",
      "9075it [17:19,  8.74it/s]Train epoch: 1 [batch #9075, batch_size 1, seq length 2500]\tLoss: 4.356874\n",
      "9100it [17:22,  8.76it/s]Train epoch: 1 [batch #9100, batch_size 1, seq length 2500]\tLoss: 4.285825\n",
      "9125it [17:25,  8.76it/s]Train epoch: 1 [batch #9125, batch_size 1, seq length 2500]\tLoss: 4.312380\n",
      "9150it [17:27,  8.74it/s]Train epoch: 1 [batch #9150, batch_size 1, seq length 2500]\tLoss: 4.354753\n",
      "9175it [17:30,  8.72it/s]Train epoch: 1 [batch #9175, batch_size 1, seq length 2500]\tLoss: 4.314343\n",
      "9200it [17:33,  8.70it/s]Train epoch: 1 [batch #9200, batch_size 1, seq length 2500]\tLoss: 4.508522\n",
      "9225it [17:36,  8.75it/s]Train epoch: 1 [batch #9225, batch_size 1, seq length 2500]\tLoss: 4.231498\n",
      "9250it [17:39,  8.76it/s]Train epoch: 1 [batch #9250, batch_size 1, seq length 2500]\tLoss: 3.944914\n",
      "9275it [17:42,  8.75it/s]Train epoch: 1 [batch #9275, batch_size 1, seq length 2500]\tLoss: 4.326549\n",
      "9300it [17:45,  8.72it/s]Train epoch: 1 [batch #9300, batch_size 1, seq length 2500]\tLoss: 4.740499\n",
      "9325it [17:47,  8.73it/s]Train epoch: 1 [batch #9325, batch_size 1, seq length 2500]\tLoss: 4.251290\n",
      "9350it [17:50,  8.74it/s]Train epoch: 1 [batch #9350, batch_size 1, seq length 2500]\tLoss: 4.398228\n",
      "9375it [17:53,  8.76it/s]Train epoch: 1 [batch #9375, batch_size 1, seq length 2500]\tLoss: 4.242024\n",
      "9400it [17:56,  8.74it/s]Train epoch: 1 [batch #9400, batch_size 1, seq length 2500]\tLoss: 4.290799\n",
      "9425it [17:59,  8.71it/s]Train epoch: 1 [batch #9425, batch_size 1, seq length 2500]\tLoss: 4.486837\n",
      "9450it [18:02,  8.74it/s]Train epoch: 1 [batch #9450, batch_size 1, seq length 2500]\tLoss: 4.211957\n",
      "9475it [18:05,  8.74it/s]Train epoch: 1 [batch #9475, batch_size 1, seq length 2500]\tLoss: 4.122542\n",
      "9500it [18:08,  8.74it/s]Train epoch: 1 [batch #9500, batch_size 1, seq length 2500]\tLoss: 4.526556\n",
      "9525it [18:10,  8.76it/s]Train epoch: 1 [batch #9525, batch_size 1, seq length 2500]\tLoss: 4.125007\n",
      "9550it [18:13,  8.70it/s]Train epoch: 1 [batch #9550, batch_size 1, seq length 2500]\tLoss: 4.247005\n",
      "9575it [18:16,  8.73it/s]Train epoch: 1 [batch #9575, batch_size 1, seq length 2500]\tLoss: 4.094047\n",
      "9600it [18:19,  8.77it/s]Train epoch: 1 [batch #9600, batch_size 1, seq length 2500]\tLoss: 4.409817\n",
      "9625it [18:22,  8.76it/s]Train epoch: 1 [batch #9625, batch_size 1, seq length 2500]\tLoss: 4.123132\n",
      "9650it [18:25,  8.71it/s]Train epoch: 1 [batch #9650, batch_size 1, seq length 2500]\tLoss: 4.189215\n",
      "9675it [18:28,  8.72it/s]Train epoch: 1 [batch #9675, batch_size 1, seq length 2500]\tLoss: 4.197728\n",
      "9700it [18:30,  8.74it/s]Train epoch: 1 [batch #9700, batch_size 1, seq length 2500]\tLoss: 4.247467\n",
      "9725it [18:33,  8.74it/s]Train epoch: 1 [batch #9725, batch_size 1, seq length 2500]\tLoss: 4.574867\n",
      "9750it [18:36,  8.75it/s]Train epoch: 1 [batch #9750, batch_size 1, seq length 2500]\tLoss: 4.311756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9775it [18:39,  8.73it/s]Train epoch: 1 [batch #9775, batch_size 1, seq length 2500]\tLoss: 4.081959\n",
      "9800it [18:42,  8.72it/s]Train epoch: 1 [batch #9800, batch_size 1, seq length 2500]\tLoss: 4.102430\n",
      "9825it [18:45,  8.72it/s]Train epoch: 1 [batch #9825, batch_size 1, seq length 2500]\tLoss: 4.093848\n",
      "9850it [18:48,  8.71it/s]Train epoch: 1 [batch #9850, batch_size 1, seq length 2500]\tLoss: 4.654862\n",
      "9875it [18:50,  8.76it/s]Train epoch: 1 [batch #9875, batch_size 1, seq length 2500]\tLoss: 4.550035\n",
      "9900it [18:53,  8.71it/s]Train epoch: 1 [batch #9900, batch_size 1, seq length 2500]\tLoss: 4.257348\n",
      "9925it [18:56,  8.72it/s]Train epoch: 1 [batch #9925, batch_size 1, seq length 2500]\tLoss: 4.230067\n",
      "9950it [18:59,  8.74it/s]Train epoch: 1 [batch #9950, batch_size 1, seq length 2500]\tLoss: 4.355558\n",
      "9975it [19:02,  8.73it/s]Train epoch: 1 [batch #9975, batch_size 1, seq length 2500]\tLoss: 4.188785\n",
      "10000it [19:05,  8.73it/s]Train epoch: 1 [batch #10000, batch_size 1, seq length 2500]\tLoss: 4.338994\n",
      "10025it [19:08,  8.74it/s]Train epoch: 1 [batch #10025, batch_size 1, seq length 2500]\tLoss: 4.090655\n",
      "10050it [19:11,  8.71it/s]Train epoch: 1 [batch #10050, batch_size 1, seq length 2500]\tLoss: 4.297112\n",
      "10075it [19:13,  8.70it/s]Train epoch: 1 [batch #10075, batch_size 1, seq length 2500]\tLoss: 4.151879\n",
      "10100it [19:16,  8.70it/s]Train epoch: 1 [batch #10100, batch_size 1, seq length 2500]\tLoss: 4.314421\n",
      "10125it [19:19,  8.73it/s]Train epoch: 1 [batch #10125, batch_size 1, seq length 2500]\tLoss: 4.364644\n",
      "10150it [19:22,  8.73it/s]Train epoch: 1 [batch #10150, batch_size 1, seq length 2500]\tLoss: 4.000129\n",
      "10175it [19:25,  8.64it/s]Train epoch: 1 [batch #10175, batch_size 1, seq length 2500]\tLoss: 4.226607\n",
      "10200it [19:28,  8.74it/s]Train epoch: 1 [batch #10200, batch_size 1, seq length 2500]\tLoss: 4.159562\n",
      "10225it [19:31,  8.78it/s]Train epoch: 1 [batch #10225, batch_size 1, seq length 2500]\tLoss: 4.218456\n",
      "10250it [19:33,  8.76it/s]Train epoch: 1 [batch #10250, batch_size 1, seq length 2500]\tLoss: 4.209486\n",
      "10275it [19:36,  8.77it/s]Train epoch: 1 [batch #10275, batch_size 1, seq length 2500]\tLoss: 4.408386\n",
      "10300it [19:39,  8.72it/s]Train epoch: 1 [batch #10300, batch_size 1, seq length 2500]\tLoss: 4.393289\n",
      "10325it [19:42,  8.76it/s]Train epoch: 1 [batch #10325, batch_size 1, seq length 2500]\tLoss: 4.343595\n",
      "10350it [19:45,  8.71it/s]Train epoch: 1 [batch #10350, batch_size 1, seq length 2500]\tLoss: 4.333765\n",
      "10375it [19:48,  8.77it/s]Train epoch: 1 [batch #10375, batch_size 1, seq length 2500]\tLoss: 4.166956\n",
      "10400it [19:51,  8.76it/s]Train epoch: 1 [batch #10400, batch_size 1, seq length 2500]\tLoss: 4.503959\n",
      "10425it [19:54,  8.74it/s]Train epoch: 1 [batch #10425, batch_size 1, seq length 2500]\tLoss: 4.411376\n",
      "10450it [19:56,  8.73it/s]Train epoch: 1 [batch #10450, batch_size 1, seq length 2500]\tLoss: 4.457060\n",
      "10475it [19:59,  8.76it/s]Train epoch: 1 [batch #10475, batch_size 1, seq length 2500]\tLoss: 4.322103\n",
      "10500it [20:02,  8.78it/s]Train epoch: 1 [batch #10500, batch_size 1, seq length 2500]\tLoss: 4.290700\n",
      "10525it [20:05,  8.56it/s]Train epoch: 1 [batch #10525, batch_size 1, seq length 2500]\tLoss: 4.374751\n",
      "10550it [20:08,  8.67it/s]Train epoch: 1 [batch #10550, batch_size 1, seq length 2500]\tLoss: 4.176888\n",
      "10575it [20:11,  8.73it/s]Train epoch: 1 [batch #10575, batch_size 1, seq length 2500]\tLoss: 4.404155\n",
      "10600it [20:14,  8.68it/s]Train epoch: 1 [batch #10600, batch_size 1, seq length 2500]\tLoss: 4.058891\n",
      "10625it [20:16,  8.74it/s]Train epoch: 1 [batch #10625, batch_size 1, seq length 2500]\tLoss: 4.170265\n",
      "10650it [20:19,  8.76it/s]Train epoch: 1 [batch #10650, batch_size 1, seq length 2500]\tLoss: 4.251051\n",
      "10675it [20:22,  8.76it/s]Train epoch: 1 [batch #10675, batch_size 1, seq length 2500]\tLoss: 4.463517\n",
      "10700it [20:25,  8.75it/s]Train epoch: 1 [batch #10700, batch_size 1, seq length 2500]\tLoss: 4.359140\n",
      "10725it [20:28,  8.75it/s]Train epoch: 1 [batch #10725, batch_size 1, seq length 2500]\tLoss: 4.385255\n",
      "10750it [20:31,  8.73it/s]Train epoch: 1 [batch #10750, batch_size 1, seq length 2500]\tLoss: 4.181347\n",
      "10775it [20:34,  8.71it/s]Train epoch: 1 [batch #10775, batch_size 1, seq length 2500]\tLoss: 4.072576\n",
      "10800it [20:37,  8.77it/s]Train epoch: 1 [batch #10800, batch_size 1, seq length 2500]\tLoss: 3.983530\n",
      "10825it [20:39,  8.72it/s]Train epoch: 1 [batch #10825, batch_size 1, seq length 2500]\tLoss: 4.200534\n",
      "10850it [20:42,  8.73it/s]Train epoch: 1 [batch #10850, batch_size 1, seq length 2500]\tLoss: 4.065822\n",
      "10875it [20:45,  8.71it/s]Train epoch: 1 [batch #10875, batch_size 1, seq length 2500]\tLoss: 3.912406\n",
      "10900it [20:48,  8.74it/s]Train epoch: 1 [batch #10900, batch_size 1, seq length 2500]\tLoss: 4.132195\n",
      "10925it [20:51,  8.74it/s]Train epoch: 1 [batch #10925, batch_size 1, seq length 2500]\tLoss: 4.192742\n",
      "10950it [20:54,  8.76it/s]Train epoch: 1 [batch #10950, batch_size 1, seq length 2500]\tLoss: 4.224076\n",
      "10975it [20:57,  8.76it/s]Train epoch: 1 [batch #10975, batch_size 1, seq length 2500]\tLoss: 4.137079\n",
      "11000it [20:59,  8.74it/s]Train epoch: 1 [batch #11000, batch_size 1, seq length 2500]\tLoss: 4.237083\n",
      "11025it [21:02,  8.77it/s]Train epoch: 1 [batch #11025, batch_size 1, seq length 2500]\tLoss: 4.438824\n",
      "11050it [21:05,  8.71it/s]Train epoch: 1 [batch #11050, batch_size 1, seq length 2500]\tLoss: 4.310293\n",
      "11075it [21:08,  8.63it/s]Train epoch: 1 [batch #11075, batch_size 1, seq length 2500]\tLoss: 4.534387\n",
      "11100it [21:11,  8.67it/s]Train epoch: 1 [batch #11100, batch_size 1, seq length 2500]\tLoss: 3.929271\n",
      "11125it [21:14,  8.75it/s]Train epoch: 1 [batch #11125, batch_size 1, seq length 2500]\tLoss: 4.124081\n",
      "11150it [21:17,  8.75it/s]Train epoch: 1 [batch #11150, batch_size 1, seq length 2500]\tLoss: 4.286760\n",
      "11175it [21:19,  8.76it/s]Train epoch: 1 [batch #11175, batch_size 1, seq length 2500]\tLoss: 4.233538\n",
      "11200it [21:22,  8.75it/s]Train epoch: 1 [batch #11200, batch_size 1, seq length 2500]\tLoss: 4.327833\n",
      "11225it [21:25,  8.76it/s]Train epoch: 1 [batch #11225, batch_size 1, seq length 2500]\tLoss: 4.090659\n",
      "11250it [21:28,  8.74it/s]Train epoch: 1 [batch #11250, batch_size 1, seq length 2500]\tLoss: 4.378981\n",
      "11275it [21:31,  8.73it/s]Train epoch: 1 [batch #11275, batch_size 1, seq length 2500]\tLoss: 3.990578\n",
      "11300it [21:34,  8.68it/s]Train epoch: 1 [batch #11300, batch_size 1, seq length 2500]\tLoss: 4.228583\n",
      "11325it [21:37,  8.68it/s]Train epoch: 1 [batch #11325, batch_size 1, seq length 2500]\tLoss: 4.282923\n",
      "11350it [21:40,  8.74it/s]Train epoch: 1 [batch #11350, batch_size 1, seq length 2500]\tLoss: 4.082733\n",
      "11375it [21:42,  8.74it/s]Train epoch: 1 [batch #11375, batch_size 1, seq length 2500]\tLoss: 4.328723\n",
      "11400it [21:45,  8.75it/s]Train epoch: 1 [batch #11400, batch_size 1, seq length 2500]\tLoss: 3.995558\n",
      "11425it [21:48,  8.74it/s]Train epoch: 1 [batch #11425, batch_size 1, seq length 2500]\tLoss: 3.620442\n",
      "11450it [21:51,  8.75it/s]Train epoch: 1 [batch #11450, batch_size 1, seq length 2500]\tLoss: 4.573373\n",
      "11475it [21:54,  8.76it/s]Train epoch: 1 [batch #11475, batch_size 1, seq length 2500]\tLoss: 4.348556\n",
      "11500it [21:57,  8.71it/s]Train epoch: 1 [batch #11500, batch_size 1, seq length 2500]\tLoss: 4.394920\n",
      "11525it [22:00,  8.73it/s]Train epoch: 1 [batch #11525, batch_size 1, seq length 2500]\tLoss: 4.075427\n",
      "11550it [22:02,  8.77it/s]Train epoch: 1 [batch #11550, batch_size 1, seq length 2500]\tLoss: 4.320585\n",
      "11575it [22:05,  8.77it/s]Train epoch: 1 [batch #11575, batch_size 1, seq length 2500]\tLoss: 4.089063\n",
      "11600it [22:08,  8.72it/s]Train epoch: 1 [batch #11600, batch_size 1, seq length 2500]\tLoss: 4.098594\n",
      "11625it [22:11,  8.75it/s]Train epoch: 1 [batch #11625, batch_size 1, seq length 2500]\tLoss: 4.257376\n",
      "11650it [22:14,  8.75it/s]Train epoch: 1 [batch #11650, batch_size 1, seq length 2500]\tLoss: 4.065232\n",
      "11675it [22:17,  8.76it/s]Train epoch: 1 [batch #11675, batch_size 1, seq length 2500]\tLoss: 4.238578\n",
      "11700it [22:20,  8.70it/s]Train epoch: 1 [batch #11700, batch_size 1, seq length 2500]\tLoss: 4.440303\n",
      "11725it [22:22,  8.67it/s]Train epoch: 1 [batch #11725, batch_size 1, seq length 2500]\tLoss: 4.287017\n",
      "11750it [22:25,  8.76it/s]Train epoch: 1 [batch #11750, batch_size 1, seq length 2500]\tLoss: 4.345897\n",
      "11775it [22:28,  8.65it/s]Train epoch: 1 [batch #11775, batch_size 1, seq length 2500]\tLoss: 4.268947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11800it [22:31,  8.71it/s]Train epoch: 1 [batch #11800, batch_size 1, seq length 2500]\tLoss: 4.368128\n",
      "11825it [22:34,  8.77it/s]Train epoch: 1 [batch #11825, batch_size 1, seq length 2500]\tLoss: 4.169784\n",
      "11850it [22:37,  8.76it/s]Train epoch: 1 [batch #11850, batch_size 1, seq length 2500]\tLoss: 4.192299\n",
      "11875it [22:40,  8.75it/s]Train epoch: 1 [batch #11875, batch_size 1, seq length 2500]\tLoss: 4.343331\n",
      "11900it [22:43,  8.71it/s]Train epoch: 1 [batch #11900, batch_size 1, seq length 2500]\tLoss: 4.441648\n",
      "11925it [22:45,  8.72it/s]Train epoch: 1 [batch #11925, batch_size 1, seq length 2500]\tLoss: 4.271894\n",
      "11950it [22:48,  8.78it/s]Train epoch: 1 [batch #11950, batch_size 1, seq length 2500]\tLoss: 4.397728\n",
      "11975it [22:51,  8.75it/s]Train epoch: 1 [batch #11975, batch_size 1, seq length 2500]\tLoss: 3.963632\n",
      "12000it [22:54,  8.72it/s]Train epoch: 1 [batch #12000, batch_size 1, seq length 2500]\tLoss: 4.021213\n",
      "12025it [22:57,  8.76it/s]Train epoch: 1 [batch #12025, batch_size 1, seq length 2500]\tLoss: 4.205895\n",
      "12050it [23:00,  8.69it/s]Train epoch: 1 [batch #12050, batch_size 1, seq length 2500]\tLoss: 4.298083\n",
      "12075it [23:03,  8.75it/s]Train epoch: 1 [batch #12075, batch_size 1, seq length 2500]\tLoss: 4.568142\n",
      "12100it [23:05,  8.77it/s]Train epoch: 1 [batch #12100, batch_size 1, seq length 2500]\tLoss: 4.060266\n",
      "12125it [23:08,  8.74it/s]Train epoch: 1 [batch #12125, batch_size 1, seq length 2500]\tLoss: 4.520193\n",
      "12150it [23:11,  8.64it/s]Train epoch: 1 [batch #12150, batch_size 1, seq length 2500]\tLoss: 4.208811\n",
      "12175it [23:14,  8.71it/s]Train epoch: 1 [batch #12175, batch_size 1, seq length 2500]\tLoss: 4.245666\n",
      "12200it [23:17,  8.74it/s]Train epoch: 1 [batch #12200, batch_size 1, seq length 2500]\tLoss: 4.328973\n",
      "12225it [23:20,  8.65it/s]Train epoch: 1 [batch #12225, batch_size 1, seq length 2500]\tLoss: 4.164654\n",
      "12250it [23:23,  8.66it/s]Train epoch: 1 [batch #12250, batch_size 1, seq length 2500]\tLoss: 4.256628\n",
      "12275it [23:26,  8.75it/s]Train epoch: 1 [batch #12275, batch_size 1, seq length 2500]\tLoss: 4.168646\n",
      "12300it [23:28,  8.72it/s]Train epoch: 1 [batch #12300, batch_size 1, seq length 2500]\tLoss: 4.257711\n",
      "12325it [23:31,  8.76it/s]Train epoch: 1 [batch #12325, batch_size 1, seq length 2500]\tLoss: 4.134183\n",
      "12350it [23:34,  8.75it/s]Train epoch: 1 [batch #12350, batch_size 1, seq length 2500]\tLoss: 4.390761\n",
      "12375it [23:37,  8.74it/s]Train epoch: 1 [batch #12375, batch_size 1, seq length 2500]\tLoss: 3.827039\n",
      "12400it [23:40,  8.68it/s]Train epoch: 1 [batch #12400, batch_size 1, seq length 2500]\tLoss: 4.026249\n",
      "12425it [23:43,  8.72it/s]Train epoch: 1 [batch #12425, batch_size 1, seq length 2500]\tLoss: 4.350839\n",
      "12450it [23:46,  8.75it/s]Train epoch: 1 [batch #12450, batch_size 1, seq length 2500]\tLoss: 4.013679\n",
      "12475it [23:48,  8.75it/s]Train epoch: 1 [batch #12475, batch_size 1, seq length 2500]\tLoss: 4.005657\n",
      "12500it [23:51,  8.65it/s]Train epoch: 1 [batch #12500, batch_size 1, seq length 2500]\tLoss: 4.080610\n",
      "12525it [23:54,  8.75it/s]Train epoch: 1 [batch #12525, batch_size 1, seq length 2500]\tLoss: 4.026001\n",
      "12550it [23:57,  8.71it/s]Train epoch: 1 [batch #12550, batch_size 1, seq length 2500]\tLoss: 4.292400\n",
      "12575it [24:00,  8.76it/s]Train epoch: 1 [batch #12575, batch_size 1, seq length 2500]\tLoss: 4.159343\n",
      "12600it [24:03,  8.70it/s]Train epoch: 1 [batch #12600, batch_size 1, seq length 2500]\tLoss: 4.185908\n",
      "12625it [24:06,  8.77it/s]Train epoch: 1 [batch #12625, batch_size 1, seq length 2500]\tLoss: 4.300942\n",
      "12650it [24:09,  8.75it/s]Train epoch: 1 [batch #12650, batch_size 1, seq length 2500]\tLoss: 4.619746\n",
      "12675it [24:11,  8.71it/s]Train epoch: 1 [batch #12675, batch_size 1, seq length 2500]\tLoss: 4.273769\n",
      "12700it [24:14,  8.69it/s]Train epoch: 1 [batch #12700, batch_size 1, seq length 2500]\tLoss: 4.188846\n",
      "12725it [24:17,  8.73it/s]Train epoch: 1 [batch #12725, batch_size 1, seq length 2500]\tLoss: 4.322321\n",
      "12750it [24:20,  8.74it/s]Train epoch: 1 [batch #12750, batch_size 1, seq length 2500]\tLoss: 4.284164\n",
      "12775it [24:23,  8.74it/s]Train epoch: 1 [batch #12775, batch_size 1, seq length 2500]\tLoss: 4.324849\n",
      "12800it [24:26,  8.73it/s]Train epoch: 1 [batch #12800, batch_size 1, seq length 2500]\tLoss: 3.926142\n",
      "12825it [24:29,  8.65it/s]Train epoch: 1 [batch #12825, batch_size 1, seq length 2500]\tLoss: 4.149711\n",
      "12850it [24:31,  8.77it/s]Train epoch: 1 [batch #12850, batch_size 1, seq length 2500]\tLoss: 4.254880\n",
      "12875it [24:34,  8.72it/s]Train epoch: 1 [batch #12875, batch_size 1, seq length 2500]\tLoss: 4.118086\n",
      "12900it [24:37,  8.69it/s]Train epoch: 1 [batch #12900, batch_size 1, seq length 2500]\tLoss: 4.434374\n",
      "12925it [24:40,  8.67it/s]Train epoch: 1 [batch #12925, batch_size 1, seq length 2500]\tLoss: 3.942459\n",
      "12950it [24:43,  8.75it/s]Train epoch: 1 [batch #12950, batch_size 1, seq length 2500]\tLoss: 4.125151\n",
      "12975it [24:46,  8.71it/s]Train epoch: 1 [batch #12975, batch_size 1, seq length 2500]\tLoss: 4.184851\n",
      "13000it [24:49,  8.74it/s]Train epoch: 1 [batch #13000, batch_size 1, seq length 2500]\tLoss: 4.071880\n",
      "13025it [24:52,  8.67it/s]Train epoch: 1 [batch #13025, batch_size 1, seq length 2500]\tLoss: 4.207421\n",
      "13050it [24:54,  8.69it/s]Train epoch: 1 [batch #13050, batch_size 1, seq length 2500]\tLoss: 4.389061\n",
      "13075it [24:57,  8.78it/s]Train epoch: 1 [batch #13075, batch_size 1, seq length 2500]\tLoss: 4.410740\n",
      "13100it [25:00,  8.74it/s]Train epoch: 1 [batch #13100, batch_size 1, seq length 2500]\tLoss: 4.564165\n",
      "13125it [25:03,  8.77it/s]Train epoch: 1 [batch #13125, batch_size 1, seq length 2500]\tLoss: 4.404232\n",
      "13150it [25:06,  8.73it/s]Train epoch: 1 [batch #13150, batch_size 1, seq length 2500]\tLoss: 4.371243\n",
      "13175it [25:09,  8.76it/s]Train epoch: 1 [batch #13175, batch_size 1, seq length 2500]\tLoss: 4.347160\n",
      "13200it [25:12,  8.68it/s]Train epoch: 1 [batch #13200, batch_size 1, seq length 2500]\tLoss: 4.322093\n",
      "13225it [25:14,  8.71it/s]Train epoch: 1 [batch #13225, batch_size 1, seq length 2500]\tLoss: 4.227948\n",
      "13250it [25:17,  8.69it/s]Train epoch: 1 [batch #13250, batch_size 1, seq length 2500]\tLoss: 4.083128\n",
      "13275it [25:20,  8.75it/s]Train epoch: 1 [batch #13275, batch_size 1, seq length 2500]\tLoss: 4.415594\n",
      "13300it [25:23,  8.74it/s]Train epoch: 1 [batch #13300, batch_size 1, seq length 2500]\tLoss: 4.208096\n",
      "13325it [25:26,  8.71it/s]Train epoch: 1 [batch #13325, batch_size 1, seq length 2500]\tLoss: 4.235027\n",
      "13350it [25:29,  8.75it/s]Train epoch: 1 [batch #13350, batch_size 1, seq length 2500]\tLoss: 4.339087\n",
      "13375it [25:32,  8.70it/s]Train epoch: 1 [batch #13375, batch_size 1, seq length 2500]\tLoss: 3.952070\n",
      "13400it [25:35,  8.71it/s]Train epoch: 1 [batch #13400, batch_size 1, seq length 2500]\tLoss: 4.231443\n",
      "13425it [25:37,  8.74it/s]Train epoch: 1 [batch #13425, batch_size 1, seq length 2500]\tLoss: 4.183950\n",
      "13450it [25:40,  8.71it/s]Train epoch: 1 [batch #13450, batch_size 1, seq length 2500]\tLoss: 4.342909\n",
      "13475it [25:43,  8.73it/s]Train epoch: 1 [batch #13475, batch_size 1, seq length 2500]\tLoss: 4.278234\n",
      "13500it [25:46,  8.61it/s]Train epoch: 1 [batch #13500, batch_size 1, seq length 2500]\tLoss: 4.105533\n",
      "13525it [25:49,  8.76it/s]Train epoch: 1 [batch #13525, batch_size 1, seq length 2500]\tLoss: 4.050230\n",
      "13550it [25:52,  8.73it/s]Train epoch: 1 [batch #13550, batch_size 1, seq length 2500]\tLoss: 4.004130\n",
      "13575it [25:55,  8.77it/s]Train epoch: 1 [batch #13575, batch_size 1, seq length 2500]\tLoss: 4.267302\n",
      "13600it [25:57,  8.77it/s]Train epoch: 1 [batch #13600, batch_size 1, seq length 2500]\tLoss: 4.326033\n",
      "13625it [26:00,  8.74it/s]Train epoch: 1 [batch #13625, batch_size 1, seq length 2500]\tLoss: 4.076180\n",
      "13650it [26:03,  8.75it/s]Train epoch: 1 [batch #13650, batch_size 1, seq length 2500]\tLoss: 3.552022\n",
      "13675it [26:06,  8.75it/s]Train epoch: 1 [batch #13675, batch_size 1, seq length 2500]\tLoss: 3.903465\n",
      "13700it [26:09,  8.70it/s]Train epoch: 1 [batch #13700, batch_size 1, seq length 2500]\tLoss: 4.174656\n",
      "13725it [26:12,  8.70it/s]Train epoch: 1 [batch #13725, batch_size 1, seq length 2500]\tLoss: 4.289097\n",
      "13750it [26:15,  8.70it/s]Train epoch: 1 [batch #13750, batch_size 1, seq length 2500]\tLoss: 4.136461\n",
      "13775it [26:18,  8.67it/s]Train epoch: 1 [batch #13775, batch_size 1, seq length 2500]\tLoss: 4.221494\n",
      "13800it [26:20,  8.74it/s]Train epoch: 1 [batch #13800, batch_size 1, seq length 2500]\tLoss: 4.202097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13825it [26:23,  8.76it/s]Train epoch: 1 [batch #13825, batch_size 1, seq length 2500]\tLoss: 4.070901\n",
      "13850it [26:26,  8.75it/s]Train epoch: 1 [batch #13850, batch_size 1, seq length 2500]\tLoss: 4.367612\n",
      "13875it [26:29,  8.77it/s]Train epoch: 1 [batch #13875, batch_size 1, seq length 2500]\tLoss: 4.043797\n",
      "13900it [26:32,  8.66it/s]Train epoch: 1 [batch #13900, batch_size 1, seq length 2500]\tLoss: 4.231759\n",
      "13925it [26:35,  8.71it/s]Train epoch: 1 [batch #13925, batch_size 1, seq length 2500]\tLoss: 4.221299\n",
      "13950it [26:38,  8.65it/s]Train epoch: 1 [batch #13950, batch_size 1, seq length 2500]\tLoss: 3.854926\n",
      "13975it [26:40,  8.70it/s]Train epoch: 1 [batch #13975, batch_size 1, seq length 2500]\tLoss: 4.346175\n",
      "14000it [26:43,  8.70it/s]Train epoch: 1 [batch #14000, batch_size 1, seq length 2500]\tLoss: 4.086641\n",
      "14025it [26:46,  8.71it/s]Train epoch: 1 [batch #14025, batch_size 1, seq length 2500]\tLoss: 4.245008\n",
      "14050it [26:49,  8.71it/s]Train epoch: 1 [batch #14050, batch_size 1, seq length 2500]\tLoss: 4.354936\n",
      "14075it [26:52,  8.73it/s]Train epoch: 1 [batch #14075, batch_size 1, seq length 2500]\tLoss: 4.357556\n",
      "14100it [26:55,  8.71it/s]Train epoch: 1 [batch #14100, batch_size 1, seq length 2500]\tLoss: 4.075446\n",
      "14125it [26:58,  8.72it/s]Train epoch: 1 [batch #14125, batch_size 1, seq length 2500]\tLoss: 4.269858\n",
      "14150it [27:01,  8.77it/s]Train epoch: 1 [batch #14150, batch_size 1, seq length 2500]\tLoss: 4.465178\n",
      "14175it [27:03,  8.72it/s]Train epoch: 1 [batch #14175, batch_size 1, seq length 2500]\tLoss: 4.285376\n",
      "14200it [27:06,  8.76it/s]Train epoch: 1 [batch #14200, batch_size 1, seq length 2500]\tLoss: 4.157497\n",
      "14225it [27:09,  8.74it/s]Train epoch: 1 [batch #14225, batch_size 1, seq length 2500]\tLoss: 4.137675\n",
      "14250it [27:12,  8.73it/s]Train epoch: 1 [batch #14250, batch_size 1, seq length 2500]\tLoss: 3.854764\n",
      "14275it [27:15,  8.71it/s]Train epoch: 1 [batch #14275, batch_size 1, seq length 2500]\tLoss: 4.240114\n",
      "14300it [27:18,  8.74it/s]Train epoch: 1 [batch #14300, batch_size 1, seq length 2500]\tLoss: 3.976409\n",
      "14325it [27:21,  8.65it/s]Train epoch: 1 [batch #14325, batch_size 1, seq length 2500]\tLoss: 3.950716\n",
      "14350it [27:23,  8.76it/s]Train epoch: 1 [batch #14350, batch_size 1, seq length 2500]\tLoss: 4.088112\n",
      "14375it [27:26,  8.73it/s]Train epoch: 1 [batch #14375, batch_size 1, seq length 2500]\tLoss: 4.418194\n",
      "14400it [27:29,  8.77it/s]Train epoch: 1 [batch #14400, batch_size 1, seq length 2500]\tLoss: 3.986150\n",
      "14425it [27:32,  8.74it/s]Train epoch: 1 [batch #14425, batch_size 1, seq length 2500]\tLoss: 4.361953\n",
      "14450it [27:35,  8.73it/s]Train epoch: 1 [batch #14450, batch_size 1, seq length 2500]\tLoss: 4.360124\n",
      "14475it [27:38,  8.67it/s]Train epoch: 1 [batch #14475, batch_size 1, seq length 2500]\tLoss: 3.826040\n",
      "14500it [27:41,  8.64it/s]Train epoch: 1 [batch #14500, batch_size 1, seq length 2500]\tLoss: 4.129933\n",
      "14525it [27:44,  8.75it/s]Train epoch: 1 [batch #14525, batch_size 1, seq length 2500]\tLoss: 4.015918\n",
      "14550it [27:46,  8.73it/s]Train epoch: 1 [batch #14550, batch_size 1, seq length 2500]\tLoss: 4.042656\n",
      "14575it [27:49,  8.77it/s]Train epoch: 1 [batch #14575, batch_size 1, seq length 2500]\tLoss: 4.157625\n",
      "14600it [27:52,  8.66it/s]Train epoch: 1 [batch #14600, batch_size 1, seq length 2500]\tLoss: 4.287247\n",
      "14625it [27:55,  8.62it/s]Train epoch: 1 [batch #14625, batch_size 1, seq length 2500]\tLoss: 4.318314\n",
      "14650it [27:58,  8.59it/s]Train epoch: 1 [batch #14650, batch_size 1, seq length 2500]\tLoss: 4.515634\n",
      "14675it [28:01,  8.74it/s]Train epoch: 1 [batch #14675, batch_size 1, seq length 2500]\tLoss: 4.252612\n",
      "14700it [28:04,  8.77it/s]Train epoch: 1 [batch #14700, batch_size 1, seq length 2500]\tLoss: 4.343335\n",
      "14725it [28:06,  8.65it/s]Train epoch: 1 [batch #14725, batch_size 1, seq length 2500]\tLoss: 4.125204\n",
      "14750it [28:09,  8.76it/s]Train epoch: 1 [batch #14750, batch_size 1, seq length 2500]\tLoss: 4.070433\n",
      "14775it [28:12,  8.73it/s]Train epoch: 1 [batch #14775, batch_size 1, seq length 2500]\tLoss: 4.644571\n",
      "14800it [28:15,  8.71it/s]Train epoch: 1 [batch #14800, batch_size 1, seq length 2500]\tLoss: 4.250175\n",
      "14825it [28:18,  8.76it/s]Train epoch: 1 [batch #14825, batch_size 1, seq length 2500]\tLoss: 4.025065\n",
      "14850it [28:21,  8.64it/s]Train epoch: 1 [batch #14850, batch_size 1, seq length 2500]\tLoss: 3.864739\n",
      "14875it [28:24,  8.73it/s]Train epoch: 1 [batch #14875, batch_size 1, seq length 2500]\tLoss: 4.241214\n",
      "14900it [28:27,  8.71it/s]Train epoch: 1 [batch #14900, batch_size 1, seq length 2500]\tLoss: 4.188840\n",
      "14925it [28:29,  8.74it/s]Train epoch: 1 [batch #14925, batch_size 1, seq length 2500]\tLoss: 4.061202\n",
      "14950it [28:32,  8.76it/s]Train epoch: 1 [batch #14950, batch_size 1, seq length 2500]\tLoss: 4.241351\n",
      "14975it [28:35,  8.72it/s]Train epoch: 1 [batch #14975, batch_size 1, seq length 2500]\tLoss: 4.235153\n",
      "15000it [28:38,  8.74it/s]Train epoch: 1 [batch #15000, batch_size 1, seq length 2500]\tLoss: 4.092516\n",
      "15025it [28:41,  8.78it/s]Train epoch: 1 [batch #15025, batch_size 1, seq length 2500]\tLoss: 4.371573\n",
      "15050it [28:44,  8.72it/s]Train epoch: 1 [batch #15050, batch_size 1, seq length 2500]\tLoss: 4.142605\n",
      "15075it [28:47,  8.75it/s]Train epoch: 1 [batch #15075, batch_size 1, seq length 2500]\tLoss: 3.837159\n",
      "15100it [28:49,  8.68it/s]Train epoch: 1 [batch #15100, batch_size 1, seq length 2500]\tLoss: 3.956622\n",
      "15125it [28:52,  8.74it/s]Train epoch: 1 [batch #15125, batch_size 1, seq length 2500]\tLoss: 4.433718\n",
      "15150it [28:55,  8.76it/s]Train epoch: 1 [batch #15150, batch_size 1, seq length 2500]\tLoss: 4.092497\n",
      "15175it [28:58,  8.76it/s]Train epoch: 1 [batch #15175, batch_size 1, seq length 2500]\tLoss: 3.829702\n",
      "15200it [29:01,  8.70it/s]Train epoch: 1 [batch #15200, batch_size 1, seq length 2500]\tLoss: 4.144380\n",
      "15225it [29:04,  8.74it/s]Train epoch: 1 [batch #15225, batch_size 1, seq length 2500]\tLoss: 4.001235\n",
      "15250it [29:07,  8.76it/s]Train epoch: 1 [batch #15250, batch_size 1, seq length 2500]\tLoss: 4.102716\n",
      "15275it [29:10,  8.70it/s]Train epoch: 1 [batch #15275, batch_size 1, seq length 2500]\tLoss: 4.034695\n",
      "15300it [29:12,  8.63it/s]Train epoch: 1 [batch #15300, batch_size 1, seq length 2500]\tLoss: 4.050576\n",
      "15325it [29:15,  8.74it/s]Train epoch: 1 [batch #15325, batch_size 1, seq length 2500]\tLoss: 4.032337\n",
      "15350it [29:18,  8.74it/s]Train epoch: 1 [batch #15350, batch_size 1, seq length 2500]\tLoss: 4.530128\n",
      "15375it [29:21,  8.75it/s]Train epoch: 1 [batch #15375, batch_size 1, seq length 2500]\tLoss: 4.222738\n",
      "15400it [29:24,  8.76it/s]Train epoch: 1 [batch #15400, batch_size 1, seq length 2500]\tLoss: 4.256492\n",
      "15425it [29:27,  8.72it/s]Train epoch: 1 [batch #15425, batch_size 1, seq length 2500]\tLoss: 4.472773\n",
      "15450it [29:30,  8.77it/s]Train epoch: 1 [batch #15450, batch_size 1, seq length 2500]\tLoss: 4.335112\n",
      "15475it [29:32,  8.75it/s]Train epoch: 1 [batch #15475, batch_size 1, seq length 2500]\tLoss: 3.853966\n",
      "15500it [29:35,  8.75it/s]Train epoch: 1 [batch #15500, batch_size 1, seq length 2500]\tLoss: 4.004926\n",
      "15525it [29:38,  8.77it/s]Train epoch: 1 [batch #15525, batch_size 1, seq length 2500]\tLoss: 4.327642\n",
      "15550it [29:41,  8.75it/s]Train epoch: 1 [batch #15550, batch_size 1, seq length 2500]\tLoss: 4.424276\n",
      "15575it [29:44,  8.76it/s]Train epoch: 1 [batch #15575, batch_size 1, seq length 2500]\tLoss: 4.204785\n",
      "15600it [29:47,  8.71it/s]Train epoch: 1 [batch #15600, batch_size 1, seq length 2500]\tLoss: 3.972121\n",
      "15625it [29:50,  8.73it/s]Train epoch: 1 [batch #15625, batch_size 1, seq length 2500]\tLoss: 3.959594\n",
      "15650it [29:53,  8.68it/s]Train epoch: 1 [batch #15650, batch_size 1, seq length 2500]\tLoss: 4.383274\n",
      "15675it [29:55,  8.71it/s]Train epoch: 1 [batch #15675, batch_size 1, seq length 2500]\tLoss: 4.187025\n",
      "15700it [29:58,  8.72it/s]Train epoch: 1 [batch #15700, batch_size 1, seq length 2500]\tLoss: 4.145151\n",
      "15725it [30:01,  8.74it/s]Train epoch: 1 [batch #15725, batch_size 1, seq length 2500]\tLoss: 4.166046\n",
      "15750it [30:04,  8.72it/s]Train epoch: 1 [batch #15750, batch_size 1, seq length 2500]\tLoss: 3.952369\n",
      "15775it [30:07,  8.63it/s]Train epoch: 1 [batch #15775, batch_size 1, seq length 2500]\tLoss: 4.251947\n",
      "15800it [30:10,  8.69it/s]Train epoch: 1 [batch #15800, batch_size 1, seq length 2500]\tLoss: 4.035652\n",
      "15825it [30:13,  8.72it/s]Train epoch: 1 [batch #15825, batch_size 1, seq length 2500]\tLoss: 4.171294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15850it [30:15,  8.75it/s]Train epoch: 1 [batch #15850, batch_size 1, seq length 2500]\tLoss: 4.211969\n",
      "15875it [30:18,  8.75it/s]Train epoch: 1 [batch #15875, batch_size 1, seq length 2500]\tLoss: 4.233729\n",
      "15900it [30:21,  8.67it/s]Train epoch: 1 [batch #15900, batch_size 1, seq length 2500]\tLoss: 3.806042\n",
      "15925it [30:24,  8.69it/s]Train epoch: 1 [batch #15925, batch_size 1, seq length 2500]\tLoss: 4.332624\n",
      "15950it [30:27,  8.74it/s]Train epoch: 1 [batch #15950, batch_size 1, seq length 2500]\tLoss: 4.134038\n",
      "15975it [30:30,  8.74it/s]Train epoch: 1 [batch #15975, batch_size 1, seq length 2500]\tLoss: 3.876029\n",
      "16000it [30:33,  8.75it/s]Train epoch: 1 [batch #16000, batch_size 1, seq length 2500]\tLoss: 4.025480\n",
      "16025it [30:35,  8.76it/s]Train epoch: 1 [batch #16025, batch_size 1, seq length 2500]\tLoss: 4.010137\n",
      "16050it [30:38,  8.75it/s]Train epoch: 1 [batch #16050, batch_size 1, seq length 2500]\tLoss: 4.355393\n",
      "16075it [30:41,  8.67it/s]Train epoch: 1 [batch #16075, batch_size 1, seq length 2500]\tLoss: 4.063454\n",
      "16100it [30:44,  8.76it/s]Train epoch: 1 [batch #16100, batch_size 1, seq length 2500]\tLoss: 4.384369\n",
      "16125it [30:47,  8.75it/s]Train epoch: 1 [batch #16125, batch_size 1, seq length 2500]\tLoss: 3.857172\n",
      "16150it [30:50,  8.64it/s]Train epoch: 1 [batch #16150, batch_size 1, seq length 2500]\tLoss: 4.210598\n",
      "16175it [30:53,  8.70it/s]Train epoch: 1 [batch #16175, batch_size 1, seq length 2500]\tLoss: 4.477304\n",
      "16200it [30:56,  8.60it/s]Train epoch: 1 [batch #16200, batch_size 1, seq length 2500]\tLoss: 4.087076\n",
      "16225it [30:58,  8.73it/s]Train epoch: 1 [batch #16225, batch_size 1, seq length 2500]\tLoss: 4.360591\n",
      "16250it [31:01,  8.69it/s]Train epoch: 1 [batch #16250, batch_size 1, seq length 2500]\tLoss: 4.016176\n",
      "16275it [31:04,  8.70it/s]Train epoch: 1 [batch #16275, batch_size 1, seq length 2500]\tLoss: 4.136236\n",
      "16300it [31:07,  8.68it/s]Train epoch: 1 [batch #16300, batch_size 1, seq length 2500]\tLoss: 4.222282\n",
      "16325it [31:10,  8.74it/s]Train epoch: 1 [batch #16325, batch_size 1, seq length 2500]\tLoss: 4.070888\n",
      "16350it [31:13,  8.61it/s]Train epoch: 1 [batch #16350, batch_size 1, seq length 2500]\tLoss: 4.122833\n",
      "16375it [31:16,  8.78it/s]Train epoch: 1 [batch #16375, batch_size 1, seq length 2500]\tLoss: 4.152073\n",
      "16400it [31:19,  8.76it/s]Train epoch: 1 [batch #16400, batch_size 1, seq length 2500]\tLoss: 4.108542\n",
      "16425it [31:21,  8.77it/s]Train epoch: 1 [batch #16425, batch_size 1, seq length 2500]\tLoss: 4.198916\n",
      "16450it [31:24,  8.77it/s]Train epoch: 1 [batch #16450, batch_size 1, seq length 2500]\tLoss: 4.016149\n",
      "16475it [31:27,  8.77it/s]Train epoch: 1 [batch #16475, batch_size 1, seq length 2500]\tLoss: 4.384820\n",
      "16500it [31:30,  8.70it/s]Train epoch: 1 [batch #16500, batch_size 1, seq length 2500]\tLoss: 4.016857\n",
      "16525it [31:33,  8.63it/s]Train epoch: 1 [batch #16525, batch_size 1, seq length 2500]\tLoss: 4.003918\n",
      "16550it [31:36,  8.70it/s]Train epoch: 1 [batch #16550, batch_size 1, seq length 2500]\tLoss: 4.099958\n",
      "16575it [31:39,  8.71it/s]Train epoch: 1 [batch #16575, batch_size 1, seq length 2500]\tLoss: 4.136708\n",
      "16600it [31:41,  8.74it/s]Train epoch: 1 [batch #16600, batch_size 1, seq length 2500]\tLoss: 4.206671\n",
      "16625it [31:44,  8.70it/s]Train epoch: 1 [batch #16625, batch_size 1, seq length 2500]\tLoss: 4.117351\n",
      "16650it [31:47,  8.43it/s]Train epoch: 1 [batch #16650, batch_size 1, seq length 2500]\tLoss: 4.572576\n",
      "16675it [31:50,  8.71it/s]Train epoch: 1 [batch #16675, batch_size 1, seq length 2500]\tLoss: 4.183313\n",
      "16700it [31:53,  8.75it/s]Train epoch: 1 [batch #16700, batch_size 1, seq length 2500]\tLoss: 3.915154\n",
      "16725it [31:56,  8.76it/s]Train epoch: 1 [batch #16725, batch_size 1, seq length 2500]\tLoss: 4.153483\n",
      "16750it [31:59,  8.67it/s]Train epoch: 1 [batch #16750, batch_size 1, seq length 2500]\tLoss: 4.018069\n",
      "16775it [32:02,  8.74it/s]Train epoch: 1 [batch #16775, batch_size 1, seq length 2500]\tLoss: 4.116264\n",
      "16800it [32:04,  8.65it/s]Train epoch: 1 [batch #16800, batch_size 1, seq length 2500]\tLoss: 4.297043\n",
      "16825it [32:07,  8.74it/s]Train epoch: 1 [batch #16825, batch_size 1, seq length 2500]\tLoss: 3.946660\n",
      "16850it [32:10,  8.58it/s]Train epoch: 1 [batch #16850, batch_size 1, seq length 2500]\tLoss: 4.286706\n",
      "16875it [32:13,  8.74it/s]Train epoch: 1 [batch #16875, batch_size 1, seq length 2500]\tLoss: 4.368113\n",
      "16900it [32:16,  8.72it/s]Train epoch: 1 [batch #16900, batch_size 1, seq length 2500]\tLoss: 3.879260\n",
      "16925it [32:19,  8.71it/s]Train epoch: 1 [batch #16925, batch_size 1, seq length 2500]\tLoss: 3.598273\n",
      "16950it [32:22,  8.77it/s]Train epoch: 1 [batch #16950, batch_size 1, seq length 2500]\tLoss: 4.232116\n",
      "16975it [32:25,  8.74it/s]Train epoch: 1 [batch #16975, batch_size 1, seq length 2500]\tLoss: 3.866562\n",
      "17000it [32:27,  8.66it/s]Train epoch: 1 [batch #17000, batch_size 1, seq length 2500]\tLoss: 4.187511\n",
      "17025it [32:30,  8.73it/s]Train epoch: 1 [batch #17025, batch_size 1, seq length 2500]\tLoss: 4.291543\n",
      "17050it [32:33,  8.64it/s]Train epoch: 1 [batch #17050, batch_size 1, seq length 2500]\tLoss: 3.992621\n",
      "17075it [32:36,  8.66it/s]Train epoch: 1 [batch #17075, batch_size 1, seq length 2500]\tLoss: 4.343781\n",
      "17100it [32:39,  8.74it/s]Train epoch: 1 [batch #17100, batch_size 1, seq length 2500]\tLoss: 4.189743\n",
      "17125it [32:42,  8.76it/s]Train epoch: 1 [batch #17125, batch_size 1, seq length 2500]\tLoss: 4.339500\n",
      "17150it [32:45,  8.57it/s]Train epoch: 1 [batch #17150, batch_size 1, seq length 2500]\tLoss: 4.089602\n",
      "17175it [32:47,  8.73it/s]Train epoch: 1 [batch #17175, batch_size 1, seq length 2500]\tLoss: 3.923314\n",
      "17200it [32:50,  8.76it/s]Train epoch: 1 [batch #17200, batch_size 1, seq length 2500]\tLoss: 4.153985\n",
      "17225it [32:53,  8.67it/s]Train epoch: 1 [batch #17225, batch_size 1, seq length 2500]\tLoss: 4.046875\n",
      "17250it [32:56,  8.72it/s]Train epoch: 1 [batch #17250, batch_size 1, seq length 2500]\tLoss: 4.063354\n",
      "17275it [32:59,  8.72it/s]Train epoch: 1 [batch #17275, batch_size 1, seq length 2500]\tLoss: 4.395044\n",
      "17300it [33:02,  8.27it/s]Train epoch: 1 [batch #17300, batch_size 1, seq length 2500]\tLoss: 4.132551\n",
      "17325it [33:05,  8.78it/s]Train epoch: 1 [batch #17325, batch_size 1, seq length 2500]\tLoss: 4.094030\n",
      "17350it [33:08,  8.71it/s]Train epoch: 1 [batch #17350, batch_size 1, seq length 2500]\tLoss: 4.211416\n",
      "17375it [33:10,  8.74it/s]Train epoch: 1 [batch #17375, batch_size 1, seq length 2500]\tLoss: 3.969892\n",
      "17400it [33:13,  8.71it/s]Train epoch: 1 [batch #17400, batch_size 1, seq length 2500]\tLoss: 3.934883\n",
      "17425it [33:16,  8.74it/s]Train epoch: 1 [batch #17425, batch_size 1, seq length 2500]\tLoss: 4.088783\n",
      "17450it [33:19,  8.73it/s]Train epoch: 1 [batch #17450, batch_size 1, seq length 2500]\tLoss: 3.993900\n",
      "17475it [33:22,  8.75it/s]Train epoch: 1 [batch #17475, batch_size 1, seq length 2500]\tLoss: 3.994514\n",
      "17500it [33:25,  8.74it/s]Train epoch: 1 [batch #17500, batch_size 1, seq length 2500]\tLoss: 3.985487\n",
      "17525it [33:28,  8.71it/s]Train epoch: 1 [batch #17525, batch_size 1, seq length 2500]\tLoss: 3.969537\n",
      "17550it [33:30,  8.62it/s]Train epoch: 1 [batch #17550, batch_size 1, seq length 2500]\tLoss: 3.899571\n",
      "17575it [33:33,  8.76it/s]Train epoch: 1 [batch #17575, batch_size 1, seq length 2500]\tLoss: 4.038610\n",
      "17600it [33:36,  8.70it/s]Train epoch: 1 [batch #17600, batch_size 1, seq length 2500]\tLoss: 3.871783\n",
      "17625it [33:39,  8.67it/s]Train epoch: 1 [batch #17625, batch_size 1, seq length 2500]\tLoss: 4.213444\n",
      "17650it [33:42,  8.75it/s]Train epoch: 1 [batch #17650, batch_size 1, seq length 2500]\tLoss: 4.366165\n",
      "17675it [33:45,  8.72it/s]Train epoch: 1 [batch #17675, batch_size 1, seq length 2500]\tLoss: 4.241707\n",
      "17700it [33:48,  8.74it/s]Train epoch: 1 [batch #17700, batch_size 1, seq length 2500]\tLoss: 4.237302\n",
      "17725it [33:51,  8.75it/s]Train epoch: 1 [batch #17725, batch_size 1, seq length 2500]\tLoss: 4.390042\n",
      "17750it [33:53,  8.72it/s]Train epoch: 1 [batch #17750, batch_size 1, seq length 2500]\tLoss: 4.123159\n",
      "17775it [33:56,  8.72it/s]Train epoch: 1 [batch #17775, batch_size 1, seq length 2500]\tLoss: 3.672368\n",
      "17800it [33:59,  8.65it/s]Train epoch: 1 [batch #17800, batch_size 1, seq length 2500]\tLoss: 4.086265\n",
      "17825it [34:02,  8.76it/s]Train epoch: 1 [batch #17825, batch_size 1, seq length 2500]\tLoss: 4.361689\n",
      "17850it [34:05,  8.76it/s]Train epoch: 1 [batch #17850, batch_size 1, seq length 2500]\tLoss: 3.770892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17875it [34:08,  8.76it/s]Train epoch: 1 [batch #17875, batch_size 1, seq length 2500]\tLoss: 4.383589\n",
      "17900it [34:11,  8.72it/s]Train epoch: 1 [batch #17900, batch_size 1, seq length 2500]\tLoss: 4.048276\n",
      "17925it [34:13,  8.73it/s]Train epoch: 1 [batch #17925, batch_size 1, seq length 2500]\tLoss: 4.038152\n",
      "17950it [34:16,  8.68it/s]Train epoch: 1 [batch #17950, batch_size 1, seq length 2500]\tLoss: 4.162688\n",
      "17975it [34:19,  8.69it/s]Train epoch: 1 [batch #17975, batch_size 1, seq length 2500]\tLoss: 3.894172\n",
      "18000it [34:22,  8.73it/s]Train epoch: 1 [batch #18000, batch_size 1, seq length 2500]\tLoss: 3.865625\n",
      "18025it [34:25,  8.68it/s]Train epoch: 1 [batch #18025, batch_size 1, seq length 2500]\tLoss: 3.857873\n",
      "18050it [34:28,  8.71it/s]Train epoch: 1 [batch #18050, batch_size 1, seq length 2500]\tLoss: 4.107501\n",
      "18075it [34:31,  8.72it/s]Train epoch: 1 [batch #18075, batch_size 1, seq length 2500]\tLoss: 4.252159\n",
      "18100it [34:34,  8.75it/s]Train epoch: 1 [batch #18100, batch_size 1, seq length 2500]\tLoss: 4.240186\n",
      "18125it [34:36,  8.75it/s]Train epoch: 1 [batch #18125, batch_size 1, seq length 2500]\tLoss: 4.398118\n",
      "18150it [34:39,  8.71it/s]Train epoch: 1 [batch #18150, batch_size 1, seq length 2500]\tLoss: 4.138687\n",
      "18175it [34:42,  8.73it/s]Train epoch: 1 [batch #18175, batch_size 1, seq length 2500]\tLoss: 3.987019\n",
      "18200it [34:45,  8.75it/s]Train epoch: 1 [batch #18200, batch_size 1, seq length 2500]\tLoss: 4.139313\n",
      "18225it [34:48,  8.73it/s]Train epoch: 1 [batch #18225, batch_size 1, seq length 2500]\tLoss: 3.933803\n",
      "18250it [34:51,  8.76it/s]Train epoch: 1 [batch #18250, batch_size 1, seq length 2500]\tLoss: 4.232941\n",
      "18275it [34:54,  8.74it/s]Train epoch: 1 [batch #18275, batch_size 1, seq length 2500]\tLoss: 4.331669\n",
      "18300it [34:56,  8.74it/s]Train epoch: 1 [batch #18300, batch_size 1, seq length 2500]\tLoss: 4.132600\n",
      "18325it [34:59,  8.75it/s]Train epoch: 1 [batch #18325, batch_size 1, seq length 2500]\tLoss: 4.026400\n",
      "18350it [35:02,  8.76it/s]Train epoch: 1 [batch #18350, batch_size 1, seq length 2500]\tLoss: 4.202677\n",
      "18375it [35:05,  8.73it/s]Train epoch: 1 [batch #18375, batch_size 1, seq length 2500]\tLoss: 4.418131\n",
      "18400it [35:08,  8.74it/s]Train epoch: 1 [batch #18400, batch_size 1, seq length 2500]\tLoss: 4.025514\n",
      "18425it [35:11,  8.74it/s]Train epoch: 1 [batch #18425, batch_size 1, seq length 2500]\tLoss: 4.324811\n",
      "18450it [35:14,  8.76it/s]Train epoch: 1 [batch #18450, batch_size 1, seq length 2500]\tLoss: 3.634299\n",
      "18475it [35:16,  8.76it/s]Train epoch: 1 [batch #18475, batch_size 1, seq length 2500]\tLoss: 3.971186\n",
      "18500it [35:19,  8.75it/s]Train epoch: 1 [batch #18500, batch_size 1, seq length 2500]\tLoss: 4.086640\n",
      "18525it [35:22,  8.77it/s]Train epoch: 1 [batch #18525, batch_size 1, seq length 2500]\tLoss: 4.341562\n",
      "18550it [35:25,  8.77it/s]Train epoch: 1 [batch #18550, batch_size 1, seq length 2500]\tLoss: 4.058530\n",
      "18575it [35:28,  8.70it/s]Train epoch: 1 [batch #18575, batch_size 1, seq length 2500]\tLoss: 4.093902\n",
      "18600it [35:31,  8.72it/s]Train epoch: 1 [batch #18600, batch_size 1, seq length 2500]\tLoss: 4.084158\n",
      "18625it [35:34,  8.65it/s]Train epoch: 1 [batch #18625, batch_size 1, seq length 2500]\tLoss: 4.041368\n",
      "18650it [35:36,  8.76it/s]Train epoch: 1 [batch #18650, batch_size 1, seq length 2500]\tLoss: 4.213180\n",
      "18675it [35:39,  8.77it/s]Train epoch: 1 [batch #18675, batch_size 1, seq length 2500]\tLoss: 3.742001\n",
      "18700it [35:42,  8.73it/s]Train epoch: 1 [batch #18700, batch_size 1, seq length 2500]\tLoss: 4.017721\n",
      "18725it [35:45,  8.74it/s]Train epoch: 1 [batch #18725, batch_size 1, seq length 2500]\tLoss: 4.121643\n",
      "18750it [35:48,  8.75it/s]Train epoch: 1 [batch #18750, batch_size 1, seq length 2500]\tLoss: 3.886627\n",
      "18775it [35:51,  8.75it/s]Train epoch: 1 [batch #18775, batch_size 1, seq length 2500]\tLoss: 4.066530\n",
      "18800it [35:54,  8.78it/s]Train epoch: 1 [batch #18800, batch_size 1, seq length 2500]\tLoss: 4.058229\n",
      "18825it [35:56,  8.70it/s]Train epoch: 1 [batch #18825, batch_size 1, seq length 2500]\tLoss: 3.957275\n",
      "18850it [35:59,  8.77it/s]Train epoch: 1 [batch #18850, batch_size 1, seq length 2500]\tLoss: 4.314604\n",
      "18875it [36:02,  8.76it/s]Train epoch: 1 [batch #18875, batch_size 1, seq length 2500]\tLoss: 3.797812\n",
      "18900it [36:05,  8.75it/s]Train epoch: 1 [batch #18900, batch_size 1, seq length 2500]\tLoss: 4.322289\n",
      "18925it [36:08,  8.76it/s]Train epoch: 1 [batch #18925, batch_size 1, seq length 2500]\tLoss: 3.865848\n",
      "18950it [36:11,  8.77it/s]Train epoch: 1 [batch #18950, batch_size 1, seq length 2500]\tLoss: 4.148041\n",
      "18975it [36:14,  8.67it/s]Train epoch: 1 [batch #18975, batch_size 1, seq length 2500]\tLoss: 4.094850\n",
      "19000it [36:16,  8.77it/s]Train epoch: 1 [batch #19000, batch_size 1, seq length 2500]\tLoss: 4.275452\n",
      "19025it [36:19,  8.74it/s]Train epoch: 1 [batch #19025, batch_size 1, seq length 2500]\tLoss: 4.419224\n",
      "19050it [36:22,  8.77it/s]Train epoch: 1 [batch #19050, batch_size 1, seq length 2500]\tLoss: 3.846110\n",
      "19075it [36:25,  8.73it/s]Train epoch: 1 [batch #19075, batch_size 1, seq length 2500]\tLoss: 3.630689\n",
      "19100it [36:28,  8.76it/s]Train epoch: 1 [batch #19100, batch_size 1, seq length 2500]\tLoss: 4.188640\n",
      "19125it [36:31,  8.76it/s]Train epoch: 1 [batch #19125, batch_size 1, seq length 2500]\tLoss: 4.193176\n",
      "19150it [36:34,  8.74it/s]Train epoch: 1 [batch #19150, batch_size 1, seq length 2500]\tLoss: 4.332761\n",
      "19175it [36:37,  8.71it/s]Train epoch: 1 [batch #19175, batch_size 1, seq length 2500]\tLoss: 4.212999\n",
      "19200it [36:39,  8.76it/s]Train epoch: 1 [batch #19200, batch_size 1, seq length 2500]\tLoss: 4.012063\n",
      "19225it [36:42,  8.76it/s]Train epoch: 1 [batch #19225, batch_size 1, seq length 2500]\tLoss: 4.208044\n",
      "19250it [36:45,  8.73it/s]Train epoch: 1 [batch #19250, batch_size 1, seq length 2500]\tLoss: 3.984592\n",
      "19275it [36:48,  8.74it/s]Train epoch: 1 [batch #19275, batch_size 1, seq length 2500]\tLoss: 4.158702\n",
      "19300it [36:51,  8.77it/s]Train epoch: 1 [batch #19300, batch_size 1, seq length 2500]\tLoss: 4.044767\n",
      "19325it [36:54,  8.69it/s]Train epoch: 1 [batch #19325, batch_size 1, seq length 2500]\tLoss: 4.260573\n",
      "19350it [36:57,  8.76it/s]Train epoch: 1 [batch #19350, batch_size 1, seq length 2500]\tLoss: 4.028597\n",
      "19375it [36:59,  8.74it/s]Train epoch: 1 [batch #19375, batch_size 1, seq length 2500]\tLoss: 4.289438\n",
      "19400it [37:02,  8.71it/s]Train epoch: 1 [batch #19400, batch_size 1, seq length 2500]\tLoss: 4.197787\n",
      "19425it [37:05,  8.75it/s]Train epoch: 1 [batch #19425, batch_size 1, seq length 2500]\tLoss: 4.176966\n",
      "19450it [37:08,  8.76it/s]Train epoch: 1 [batch #19450, batch_size 1, seq length 2500]\tLoss: 4.123236\n",
      "19475it [37:11,  8.76it/s]Train epoch: 1 [batch #19475, batch_size 1, seq length 2500]\tLoss: 3.889144\n",
      "19500it [37:14,  8.72it/s]Train epoch: 1 [batch #19500, batch_size 1, seq length 2500]\tLoss: 3.671334\n",
      "19525it [37:17,  8.73it/s]Train epoch: 1 [batch #19525, batch_size 1, seq length 2500]\tLoss: 4.362942\n",
      "19550it [37:19,  8.76it/s]Train epoch: 1 [batch #19550, batch_size 1, seq length 2500]\tLoss: 4.017252\n",
      "19575it [37:22,  8.69it/s]Train epoch: 1 [batch #19575, batch_size 1, seq length 2500]\tLoss: 4.019187\n",
      "19600it [37:25,  8.76it/s]Train epoch: 1 [batch #19600, batch_size 1, seq length 2500]\tLoss: 3.803180\n",
      "19625it [37:28,  8.76it/s]Train epoch: 1 [batch #19625, batch_size 1, seq length 2500]\tLoss: 3.916474\n",
      "19650it [37:31,  8.78it/s]Train epoch: 1 [batch #19650, batch_size 1, seq length 2500]\tLoss: 3.989604\n",
      "19675it [37:34,  8.68it/s]Train epoch: 1 [batch #19675, batch_size 1, seq length 2500]\tLoss: 3.790021\n",
      "19700it [37:37,  8.72it/s]Train epoch: 1 [batch #19700, batch_size 1, seq length 2500]\tLoss: 3.953183\n",
      "19725it [37:39,  8.77it/s]Train epoch: 1 [batch #19725, batch_size 1, seq length 2500]\tLoss: 4.057726\n",
      "19750it [37:42,  8.74it/s]Train epoch: 1 [batch #19750, batch_size 1, seq length 2500]\tLoss: 4.440341\n",
      "19775it [37:45,  8.74it/s]Train epoch: 1 [batch #19775, batch_size 1, seq length 2500]\tLoss: 3.950594\n",
      "19800it [37:48,  8.74it/s]Train epoch: 1 [batch #19800, batch_size 1, seq length 2500]\tLoss: 4.144950\n",
      "19825it [37:51,  8.76it/s]Train epoch: 1 [batch #19825, batch_size 1, seq length 2500]\tLoss: 3.779619\n",
      "19850it [37:54,  8.73it/s]Train epoch: 1 [batch #19850, batch_size 1, seq length 2500]\tLoss: 3.714290\n",
      "19875it [37:57,  8.77it/s]Train epoch: 1 [batch #19875, batch_size 1, seq length 2500]\tLoss: 3.889351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19900it [38:00,  8.75it/s]Train epoch: 1 [batch #19900, batch_size 1, seq length 2500]\tLoss: 4.093207\n",
      "19925it [38:02,  8.71it/s]Train epoch: 1 [batch #19925, batch_size 1, seq length 2500]\tLoss: 4.162754\n",
      "19950it [38:05,  8.76it/s]Train epoch: 1 [batch #19950, batch_size 1, seq length 2500]\tLoss: 4.303162\n",
      "19975it [38:08,  8.76it/s]Train epoch: 1 [batch #19975, batch_size 1, seq length 2500]\tLoss: 4.029770\n",
      "20000it [38:11,  8.71it/s]Train epoch: 1 [batch #20000, batch_size 1, seq length 2500]\tLoss: 3.710202\n",
      "20025it [38:14,  8.70it/s]Train epoch: 1 [batch #20025, batch_size 1, seq length 2500]\tLoss: 4.138903\n",
      "20050it [38:17,  8.69it/s]Train epoch: 1 [batch #20050, batch_size 1, seq length 2500]\tLoss: 3.977814\n",
      "20075it [38:20,  8.75it/s]Train epoch: 1 [batch #20075, batch_size 1, seq length 2500]\tLoss: 4.132895\n",
      "20100it [38:22,  8.74it/s]Train epoch: 1 [batch #20100, batch_size 1, seq length 2500]\tLoss: 3.966901\n",
      "20125it [38:25,  8.74it/s]Train epoch: 1 [batch #20125, batch_size 1, seq length 2500]\tLoss: 4.269377\n",
      "20150it [38:28,  8.73it/s]Train epoch: 1 [batch #20150, batch_size 1, seq length 2500]\tLoss: 4.192296\n",
      "20175it [38:31,  8.74it/s]Train epoch: 1 [batch #20175, batch_size 1, seq length 2500]\tLoss: 4.046683\n",
      "20200it [38:34,  8.73it/s]Train epoch: 1 [batch #20200, batch_size 1, seq length 2500]\tLoss: 4.104662\n",
      "20225it [38:37,  8.78it/s]Train epoch: 1 [batch #20225, batch_size 1, seq length 2500]\tLoss: 3.993042\n",
      "20250it [38:40,  8.75it/s]Train epoch: 1 [batch #20250, batch_size 1, seq length 2500]\tLoss: 3.811950\n",
      "20275it [38:42,  8.68it/s]Train epoch: 1 [batch #20275, batch_size 1, seq length 2500]\tLoss: 4.090874\n",
      "20300it [38:45,  8.74it/s]Train epoch: 1 [batch #20300, batch_size 1, seq length 2500]\tLoss: 4.060176\n",
      "20325it [38:48,  8.76it/s]Train epoch: 1 [batch #20325, batch_size 1, seq length 2500]\tLoss: 4.124819\n",
      "20350it [38:51,  8.77it/s]Train epoch: 1 [batch #20350, batch_size 1, seq length 2500]\tLoss: 4.018040\n",
      "20375it [38:54,  8.77it/s]Train epoch: 1 [batch #20375, batch_size 1, seq length 2500]\tLoss: 4.212154\n",
      "20400it [38:57,  8.70it/s]Train epoch: 1 [batch #20400, batch_size 1, seq length 2500]\tLoss: 3.975852\n",
      "20425it [39:00,  8.72it/s]Train epoch: 1 [batch #20425, batch_size 1, seq length 2500]\tLoss: 3.746592\n",
      "20450it [39:02,  8.77it/s]Train epoch: 1 [batch #20450, batch_size 1, seq length 2500]\tLoss: 4.397419\n",
      "20475it [39:05,  8.67it/s]Train epoch: 1 [batch #20475, batch_size 1, seq length 2500]\tLoss: 3.970771\n",
      "20500it [39:08,  8.74it/s]Train epoch: 1 [batch #20500, batch_size 1, seq length 2500]\tLoss: 4.003537\n",
      "20525it [39:11,  8.74it/s]Train epoch: 1 [batch #20525, batch_size 1, seq length 2500]\tLoss: 4.193469\n",
      "20550it [39:14,  8.72it/s]Train epoch: 1 [batch #20550, batch_size 1, seq length 2500]\tLoss: 4.086952\n",
      "20575it [39:17,  8.74it/s]Train epoch: 1 [batch #20575, batch_size 1, seq length 2500]\tLoss: 3.946120\n",
      "20600it [39:20,  8.73it/s]Train epoch: 1 [batch #20600, batch_size 1, seq length 2500]\tLoss: 4.289793\n",
      "20625it [39:22,  8.75it/s]Train epoch: 1 [batch #20625, batch_size 1, seq length 2500]\tLoss: 4.141533\n",
      "20650it [39:25,  8.74it/s]Train epoch: 1 [batch #20650, batch_size 1, seq length 2500]\tLoss: 4.144792\n",
      "20675it [39:28,  8.76it/s]Train epoch: 1 [batch #20675, batch_size 1, seq length 2500]\tLoss: 4.116536\n",
      "20700it [39:31,  8.76it/s]Train epoch: 1 [batch #20700, batch_size 1, seq length 2500]\tLoss: 4.204031\n",
      "20725it [39:34,  8.76it/s]Train epoch: 1 [batch #20725, batch_size 1, seq length 2500]\tLoss: 4.067255\n",
      "20750it [39:37,  8.75it/s]Train epoch: 1 [batch #20750, batch_size 1, seq length 2500]\tLoss: 4.215715\n",
      "20775it [39:40,  8.54it/s]Train epoch: 1 [batch #20775, batch_size 1, seq length 2500]\tLoss: 3.692173\n",
      "20800it [39:43,  8.74it/s]Train epoch: 1 [batch #20800, batch_size 1, seq length 2500]\tLoss: 3.860511\n",
      "20825it [39:45,  8.77it/s]Train epoch: 1 [batch #20825, batch_size 1, seq length 2500]\tLoss: 4.166355\n",
      "20850it [39:48,  8.76it/s]Train epoch: 1 [batch #20850, batch_size 1, seq length 2500]\tLoss: 4.179871\n",
      "20875it [39:51,  8.72it/s]Train epoch: 1 [batch #20875, batch_size 1, seq length 2500]\tLoss: 3.663703\n",
      "20900it [39:54,  8.74it/s]Train epoch: 1 [batch #20900, batch_size 1, seq length 2500]\tLoss: 3.865957\n",
      "20925it [39:57,  8.70it/s]Train epoch: 1 [batch #20925, batch_size 1, seq length 2500]\tLoss: 4.080320\n",
      "20950it [40:00,  8.75it/s]Train epoch: 1 [batch #20950, batch_size 1, seq length 2500]\tLoss: 3.870641\n",
      "20975it [40:03,  8.71it/s]Train epoch: 1 [batch #20975, batch_size 1, seq length 2500]\tLoss: 3.803420\n",
      "21000it [40:05,  8.75it/s]Train epoch: 1 [batch #21000, batch_size 1, seq length 2500]\tLoss: 3.777326\n",
      "21025it [40:08,  8.74it/s]Train epoch: 1 [batch #21025, batch_size 1, seq length 2500]\tLoss: 4.204779\n",
      "21050it [40:11,  8.75it/s]Train epoch: 1 [batch #21050, batch_size 1, seq length 2500]\tLoss: 3.902078\n",
      "21075it [40:14,  8.76it/s]Train epoch: 1 [batch #21075, batch_size 1, seq length 2500]\tLoss: 3.941277\n",
      "21100it [40:17,  8.75it/s]Train epoch: 1 [batch #21100, batch_size 1, seq length 2500]\tLoss: 3.959377\n",
      "21125it [40:20,  8.69it/s]Train epoch: 1 [batch #21125, batch_size 1, seq length 2500]\tLoss: 4.075364\n",
      "21150it [40:23,  8.73it/s]Train epoch: 1 [batch #21150, batch_size 1, seq length 2500]\tLoss: 4.247733\n",
      "21175it [40:26,  8.73it/s]Train epoch: 1 [batch #21175, batch_size 1, seq length 2500]\tLoss: 4.178514\n",
      "21200it [40:28,  8.76it/s]Train epoch: 1 [batch #21200, batch_size 1, seq length 2500]\tLoss: 4.069960\n",
      "21225it [40:31,  8.73it/s]Train epoch: 1 [batch #21225, batch_size 1, seq length 2500]\tLoss: 4.026097\n",
      "21250it [40:34,  8.76it/s]Train epoch: 1 [batch #21250, batch_size 1, seq length 2500]\tLoss: 4.251587\n",
      "21275it [40:37,  8.74it/s]Train epoch: 1 [batch #21275, batch_size 1, seq length 2500]\tLoss: 4.143301\n",
      "21300it [40:40,  8.71it/s]Train epoch: 1 [batch #21300, batch_size 1, seq length 2500]\tLoss: 4.200356\n",
      "21325it [40:43,  8.75it/s]Train epoch: 1 [batch #21325, batch_size 1, seq length 2500]\tLoss: 3.884294\n",
      "21350it [40:46,  8.71it/s]Train epoch: 1 [batch #21350, batch_size 1, seq length 2500]\tLoss: 3.988853\n",
      "21375it [40:48,  8.72it/s]Train epoch: 1 [batch #21375, batch_size 1, seq length 2500]\tLoss: 3.826237\n",
      "21400it [40:51,  8.72it/s]Train epoch: 1 [batch #21400, batch_size 1, seq length 2500]\tLoss: 4.012788\n",
      "21425it [40:54,  8.74it/s]Train epoch: 1 [batch #21425, batch_size 1, seq length 2500]\tLoss: 4.278733\n",
      "21450it [40:57,  8.69it/s]Train epoch: 1 [batch #21450, batch_size 1, seq length 2500]\tLoss: 3.820384\n",
      "21475it [41:00,  8.74it/s]Train epoch: 1 [batch #21475, batch_size 1, seq length 2500]\tLoss: 4.179841\n",
      "21500it [41:03,  8.71it/s]Train epoch: 1 [batch #21500, batch_size 1, seq length 2500]\tLoss: 4.091441\n",
      "21525it [41:06,  8.71it/s]Train epoch: 1 [batch #21525, batch_size 1, seq length 2500]\tLoss: 4.289632\n",
      "21550it [41:09,  8.63it/s]Train epoch: 1 [batch #21550, batch_size 1, seq length 2500]\tLoss: 4.308143\n",
      "21575it [41:11,  8.74it/s]Train epoch: 1 [batch #21575, batch_size 1, seq length 2500]\tLoss: 4.097641\n",
      "21600it [41:14,  8.75it/s]Train epoch: 1 [batch #21600, batch_size 1, seq length 2500]\tLoss: 3.942652\n",
      "21625it [41:17,  8.77it/s]Train epoch: 1 [batch #21625, batch_size 1, seq length 2500]\tLoss: 3.749431\n",
      "21650it [41:20,  8.52it/s]Train epoch: 1 [batch #21650, batch_size 1, seq length 2500]\tLoss: 3.706551\n",
      "21675it [41:23,  8.76it/s]Train epoch: 1 [batch #21675, batch_size 1, seq length 2500]\tLoss: 4.126016\n",
      "21700it [41:26,  8.60it/s]Train epoch: 1 [batch #21700, batch_size 1, seq length 2500]\tLoss: 4.152988\n",
      "21725it [41:29,  8.75it/s]Train epoch: 1 [batch #21725, batch_size 1, seq length 2500]\tLoss: 4.232294\n",
      "21750it [41:31,  8.77it/s]Train epoch: 1 [batch #21750, batch_size 1, seq length 2500]\tLoss: 3.940388\n",
      "21775it [41:34,  8.73it/s]Train epoch: 1 [batch #21775, batch_size 1, seq length 2500]\tLoss: 3.959533\n",
      "21800it [41:37,  8.70it/s]Train epoch: 1 [batch #21800, batch_size 1, seq length 2500]\tLoss: 4.149811\n",
      "21825it [41:40,  8.71it/s]Train epoch: 1 [batch #21825, batch_size 1, seq length 2500]\tLoss: 4.035705\n",
      "21850it [41:43,  8.71it/s]Train epoch: 1 [batch #21850, batch_size 1, seq length 2500]\tLoss: 4.052783\n",
      "21875it [41:46,  8.71it/s]Train epoch: 1 [batch #21875, batch_size 1, seq length 2500]\tLoss: 3.757709\n",
      "21900it [41:49,  8.73it/s]Train epoch: 1 [batch #21900, batch_size 1, seq length 2500]\tLoss: 4.031758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21925it [41:51,  8.75it/s]Train epoch: 1 [batch #21925, batch_size 1, seq length 2500]\tLoss: 4.021320\n",
      "21950it [41:54,  8.77it/s]Train epoch: 1 [batch #21950, batch_size 1, seq length 2500]\tLoss: 4.108654\n",
      "21975it [41:57,  8.72it/s]Train epoch: 1 [batch #21975, batch_size 1, seq length 2500]\tLoss: 3.660456\n",
      "22000it [42:00,  8.74it/s]Train epoch: 1 [batch #22000, batch_size 1, seq length 2500]\tLoss: 3.880665\n",
      "22025it [42:03,  8.70it/s]Train epoch: 1 [batch #22025, batch_size 1, seq length 2500]\tLoss: 4.109351\n",
      "22050it [42:06,  8.75it/s]Train epoch: 1 [batch #22050, batch_size 1, seq length 2500]\tLoss: 4.194391\n",
      "22075it [42:09,  8.73it/s]Train epoch: 1 [batch #22075, batch_size 1, seq length 2500]\tLoss: 4.303753\n",
      "22100it [42:12,  8.70it/s]Train epoch: 1 [batch #22100, batch_size 1, seq length 2500]\tLoss: 4.044667\n",
      "22125it [42:14,  8.74it/s]Train epoch: 1 [batch #22125, batch_size 1, seq length 2500]\tLoss: 3.771454\n",
      "22150it [42:17,  8.76it/s]Train epoch: 1 [batch #22150, batch_size 1, seq length 2500]\tLoss: 4.175364\n",
      "22175it [42:20,  8.73it/s]Train epoch: 1 [batch #22175, batch_size 1, seq length 2500]\tLoss: 4.088564\n",
      "22200it [42:23,  8.77it/s]Train epoch: 1 [batch #22200, batch_size 1, seq length 2500]\tLoss: 4.139151\n",
      "22225it [42:26,  8.57it/s]Train epoch: 1 [batch #22225, batch_size 1, seq length 2500]\tLoss: 3.759764\n",
      "22250it [42:29,  8.73it/s]Train epoch: 1 [batch #22250, batch_size 1, seq length 2500]\tLoss: 4.307061\n",
      "22275it [42:32,  8.71it/s]Train epoch: 1 [batch #22275, batch_size 1, seq length 2500]\tLoss: 3.971011\n",
      "22300it [42:34,  8.74it/s]Train epoch: 1 [batch #22300, batch_size 1, seq length 2500]\tLoss: 4.170650\n",
      "22325it [42:37,  8.72it/s]Train epoch: 1 [batch #22325, batch_size 1, seq length 2500]\tLoss: 4.419508\n",
      "22350it [42:40,  8.77it/s]Train epoch: 1 [batch #22350, batch_size 1, seq length 2500]\tLoss: 3.920131\n",
      "22375it [42:43,  8.74it/s]Train epoch: 1 [batch #22375, batch_size 1, seq length 2500]\tLoss: 4.133410\n",
      "22400it [42:46,  8.71it/s]Train epoch: 1 [batch #22400, batch_size 1, seq length 2500]\tLoss: 4.110236\n",
      "22425it [42:49,  8.72it/s]Train epoch: 1 [batch #22425, batch_size 1, seq length 2500]\tLoss: 4.075481\n",
      "22450it [42:52,  8.72it/s]Train epoch: 1 [batch #22450, batch_size 1, seq length 2500]\tLoss: 3.842074\n",
      "22475it [42:54,  8.75it/s]Train epoch: 1 [batch #22475, batch_size 1, seq length 2500]\tLoss: 3.931045\n",
      "22500it [42:57,  8.78it/s]Train epoch: 1 [batch #22500, batch_size 1, seq length 2500]\tLoss: 3.940538\n",
      "22525it [43:00,  8.74it/s]Train epoch: 1 [batch #22525, batch_size 1, seq length 2500]\tLoss: 3.910468\n",
      "22550it [43:03,  8.77it/s]Train epoch: 1 [batch #22550, batch_size 1, seq length 2500]\tLoss: 4.259521\n",
      "22575it [43:06,  8.74it/s]Train epoch: 1 [batch #22575, batch_size 1, seq length 2500]\tLoss: 4.298680\n",
      "22600it [43:09,  8.69it/s]Train epoch: 1 [batch #22600, batch_size 1, seq length 2500]\tLoss: 3.947413\n",
      "22625it [43:12,  8.78it/s]Train epoch: 1 [batch #22625, batch_size 1, seq length 2500]\tLoss: 3.891806\n",
      "22650it [43:15,  8.76it/s]Train epoch: 1 [batch #22650, batch_size 1, seq length 2500]\tLoss: 4.397178\n",
      "22675it [43:17,  8.76it/s]Train epoch: 1 [batch #22675, batch_size 1, seq length 2500]\tLoss: 4.067642\n",
      "22700it [43:20,  8.65it/s]Train epoch: 1 [batch #22700, batch_size 1, seq length 2500]\tLoss: 3.995178\n",
      "22725it [43:23,  8.72it/s]Train epoch: 1 [batch #22725, batch_size 1, seq length 2500]\tLoss: 3.971706\n",
      "22750it [43:26,  8.73it/s]Train epoch: 1 [batch #22750, batch_size 1, seq length 2500]\tLoss: 4.020332\n",
      "22775it [43:29,  8.74it/s]Train epoch: 1 [batch #22775, batch_size 1, seq length 2500]\tLoss: 4.130077\n",
      "22800it [43:32,  8.73it/s]Train epoch: 1 [batch #22800, batch_size 1, seq length 2500]\tLoss: 4.097829\n",
      "22825it [43:35,  8.70it/s]Train epoch: 1 [batch #22825, batch_size 1, seq length 2500]\tLoss: 4.294308\n",
      "22850it [43:37,  8.74it/s]Train epoch: 1 [batch #22850, batch_size 1, seq length 2500]\tLoss: 3.873002\n",
      "22875it [43:40,  8.67it/s]Train epoch: 1 [batch #22875, batch_size 1, seq length 2500]\tLoss: 3.953822\n",
      "22900it [43:43,  8.76it/s]Train epoch: 1 [batch #22900, batch_size 1, seq length 2500]\tLoss: 4.150965\n",
      "22925it [43:46,  8.74it/s]Train epoch: 1 [batch #22925, batch_size 1, seq length 2500]\tLoss: 4.107637\n",
      "22950it [43:49,  8.74it/s]Train epoch: 1 [batch #22950, batch_size 1, seq length 2500]\tLoss: 4.290653\n",
      "22975it [43:52,  8.75it/s]Train epoch: 1 [batch #22975, batch_size 1, seq length 2500]\tLoss: 4.205648\n",
      "23000it [43:55,  8.71it/s]Train epoch: 1 [batch #23000, batch_size 1, seq length 2500]\tLoss: 4.112018\n",
      "23025it [43:57,  8.70it/s]Train epoch: 1 [batch #23025, batch_size 1, seq length 2500]\tLoss: 4.099102\n",
      "23050it [44:00,  8.62it/s]Train epoch: 1 [batch #23050, batch_size 1, seq length 2500]\tLoss: 4.133519\n",
      "23075it [44:03,  8.63it/s]Train epoch: 1 [batch #23075, batch_size 1, seq length 2500]\tLoss: 3.666940\n",
      "23100it [44:06,  8.71it/s]Train epoch: 1 [batch #23100, batch_size 1, seq length 2500]\tLoss: 4.068437\n",
      "23125it [44:09,  8.70it/s]Train epoch: 1 [batch #23125, batch_size 1, seq length 2500]\tLoss: 3.923224\n",
      "23150it [44:12,  8.77it/s]Train epoch: 1 [batch #23150, batch_size 1, seq length 2500]\tLoss: 4.144796\n",
      "23175it [44:15,  8.69it/s]Train epoch: 1 [batch #23175, batch_size 1, seq length 2500]\tLoss: 4.069100\n",
      "23200it [44:18,  8.75it/s]Train epoch: 1 [batch #23200, batch_size 1, seq length 2500]\tLoss: 3.963960\n",
      "23225it [44:20,  8.77it/s]Train epoch: 1 [batch #23225, batch_size 1, seq length 2500]\tLoss: 3.708736\n",
      "23250it [44:23,  8.77it/s]Train epoch: 1 [batch #23250, batch_size 1, seq length 2500]\tLoss: 3.942415\n",
      "23275it [44:26,  8.73it/s]Train epoch: 1 [batch #23275, batch_size 1, seq length 2500]\tLoss: 3.811615\n",
      "23300it [44:29,  8.70it/s]Train epoch: 1 [batch #23300, batch_size 1, seq length 2500]\tLoss: 4.117646\n",
      "23325it [44:32,  8.75it/s]Train epoch: 1 [batch #23325, batch_size 1, seq length 2500]\tLoss: 3.856000\n",
      "23350it [44:35,  8.75it/s]Train epoch: 1 [batch #23350, batch_size 1, seq length 2500]\tLoss: 3.834535\n",
      "23375it [44:38,  8.74it/s]Train epoch: 1 [batch #23375, batch_size 1, seq length 2500]\tLoss: 3.612980\n",
      "23400it [44:40,  8.76it/s]Train epoch: 1 [batch #23400, batch_size 1, seq length 2500]\tLoss: 4.307890\n",
      "23425it [44:43,  8.75it/s]Train epoch: 1 [batch #23425, batch_size 1, seq length 2500]\tLoss: 4.301143\n",
      "23450it [44:46,  8.72it/s]Train epoch: 1 [batch #23450, batch_size 1, seq length 2500]\tLoss: 4.266580\n",
      "23475it [44:49,  8.77it/s]Train epoch: 1 [batch #23475, batch_size 1, seq length 2500]\tLoss: 4.261440\n",
      "23500it [44:52,  8.72it/s]Train epoch: 1 [batch #23500, batch_size 1, seq length 2500]\tLoss: 4.341039\n",
      "23525it [44:55,  8.73it/s]Train epoch: 1 [batch #23525, batch_size 1, seq length 2500]\tLoss: 4.325998\n",
      "23550it [44:58,  8.72it/s]Train epoch: 1 [batch #23550, batch_size 1, seq length 2500]\tLoss: 4.196467\n",
      "23575it [45:00,  8.75it/s]Train epoch: 1 [batch #23575, batch_size 1, seq length 2500]\tLoss: 4.192681\n",
      "23600it [45:03,  8.66it/s]Train epoch: 1 [batch #23600, batch_size 1, seq length 2500]\tLoss: 3.759656\n",
      "23625it [45:06,  8.73it/s]Train epoch: 1 [batch #23625, batch_size 1, seq length 2500]\tLoss: 3.361878\n",
      "23650it [45:09,  8.72it/s]Train epoch: 1 [batch #23650, batch_size 1, seq length 2500]\tLoss: 4.028837\n",
      "23675it [45:12,  8.78it/s]Train epoch: 1 [batch #23675, batch_size 1, seq length 2500]\tLoss: 4.093579\n",
      "23700it [45:15,  8.66it/s]Train epoch: 1 [batch #23700, batch_size 1, seq length 2500]\tLoss: 3.983495\n",
      "23725it [45:18,  8.58it/s]Train epoch: 1 [batch #23725, batch_size 1, seq length 2500]\tLoss: 3.866523\n",
      "23750it [45:20,  8.73it/s]Train epoch: 1 [batch #23750, batch_size 1, seq length 2500]\tLoss: 4.146843\n",
      "23775it [45:23,  8.74it/s]Train epoch: 1 [batch #23775, batch_size 1, seq length 2500]\tLoss: 3.900666\n",
      "23800it [45:26,  8.76it/s]Train epoch: 1 [batch #23800, batch_size 1, seq length 2500]\tLoss: 3.973349\n",
      "23825it [45:29,  8.68it/s]Train epoch: 1 [batch #23825, batch_size 1, seq length 2500]\tLoss: 4.356454\n",
      "23850it [45:32,  8.74it/s]Train epoch: 1 [batch #23850, batch_size 1, seq length 2500]\tLoss: 4.149925\n",
      "23875it [45:35,  8.71it/s]Train epoch: 1 [batch #23875, batch_size 1, seq length 2500]\tLoss: 4.008663\n",
      "23900it [45:38,  8.70it/s]Train epoch: 1 [batch #23900, batch_size 1, seq length 2500]\tLoss: 3.953047\n",
      "23925it [45:41,  8.68it/s]Train epoch: 1 [batch #23925, batch_size 1, seq length 2500]\tLoss: 4.175011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23950it [45:43,  8.70it/s]Train epoch: 1 [batch #23950, batch_size 1, seq length 2500]\tLoss: 4.011568\n",
      "23975it [45:46,  8.77it/s]Train epoch: 1 [batch #23975, batch_size 1, seq length 2500]\tLoss: 4.011647\n",
      "24000it [45:49,  8.76it/s]Train epoch: 1 [batch #24000, batch_size 1, seq length 2500]\tLoss: 4.045380\n",
      "24025it [45:52,  8.75it/s]Train epoch: 1 [batch #24025, batch_size 1, seq length 2500]\tLoss: 3.948375\n",
      "24050it [45:55,  8.78it/s]Train epoch: 1 [batch #24050, batch_size 1, seq length 2500]\tLoss: 4.054010\n",
      "24075it [45:58,  8.71it/s]Train epoch: 1 [batch #24075, batch_size 1, seq length 2500]\tLoss: 4.177779\n",
      "24100it [46:01,  8.77it/s]Train epoch: 1 [batch #24100, batch_size 1, seq length 2500]\tLoss: 4.291668\n",
      "24125it [46:03,  8.77it/s]Train epoch: 1 [batch #24125, batch_size 1, seq length 2500]\tLoss: 4.310221\n",
      "24150it [46:06,  8.76it/s]Train epoch: 1 [batch #24150, batch_size 1, seq length 2500]\tLoss: 4.434085\n",
      "24175it [46:09,  8.74it/s]Train epoch: 1 [batch #24175, batch_size 1, seq length 2500]\tLoss: 3.906450\n",
      "24200it [46:12,  8.67it/s]Train epoch: 1 [batch #24200, batch_size 1, seq length 2500]\tLoss: 4.131478\n",
      "24225it [46:15,  8.48it/s]Train epoch: 1 [batch #24225, batch_size 1, seq length 2500]\tLoss: 4.095537\n",
      "24250it [46:18,  8.74it/s]Train epoch: 1 [batch #24250, batch_size 1, seq length 2500]\tLoss: 3.881202\n",
      "24275it [46:21,  8.77it/s]Train epoch: 1 [batch #24275, batch_size 1, seq length 2500]\tLoss: 4.256326\n",
      "24300it [46:24,  8.76it/s]Train epoch: 1 [batch #24300, batch_size 1, seq length 2500]\tLoss: 4.240015\n",
      "24325it [46:26,  8.72it/s]Train epoch: 1 [batch #24325, batch_size 1, seq length 2500]\tLoss: 4.372461\n",
      "24350it [46:29,  8.77it/s]Train epoch: 1 [batch #24350, batch_size 1, seq length 2500]\tLoss: 4.019542\n",
      "24375it [46:32,  8.75it/s]Train epoch: 1 [batch #24375, batch_size 1, seq length 2500]\tLoss: 4.081427\n",
      "24400it [46:35,  8.68it/s]Train epoch: 1 [batch #24400, batch_size 1, seq length 2500]\tLoss: 4.078053\n",
      "24425it [46:38,  8.64it/s]Train epoch: 1 [batch #24425, batch_size 1, seq length 2500]\tLoss: 3.591460\n",
      "24450it [46:41,  8.70it/s]Train epoch: 1 [batch #24450, batch_size 1, seq length 2500]\tLoss: 3.928028\n",
      "24475it [46:44,  8.77it/s]Train epoch: 1 [batch #24475, batch_size 1, seq length 2500]\tLoss: 3.888623\n",
      "24500it [46:46,  8.73it/s]Train epoch: 1 [batch #24500, batch_size 1, seq length 2500]\tLoss: 3.636483\n",
      "24525it [46:49,  8.70it/s]Train epoch: 1 [batch #24525, batch_size 1, seq length 2500]\tLoss: 3.929525\n",
      "24550it [46:52,  8.71it/s]Train epoch: 1 [batch #24550, batch_size 1, seq length 2500]\tLoss: 4.140813\n",
      "24575it [46:55,  8.78it/s]Train epoch: 1 [batch #24575, batch_size 1, seq length 2500]\tLoss: 3.745274\n",
      "24600it [46:58,  8.75it/s]Train epoch: 1 [batch #24600, batch_size 1, seq length 2500]\tLoss: 3.742351\n",
      "24625it [47:01,  8.69it/s]Train epoch: 1 [batch #24625, batch_size 1, seq length 2500]\tLoss: 3.904825\n",
      "24650it [47:04,  8.76it/s]Train epoch: 1 [batch #24650, batch_size 1, seq length 2500]\tLoss: 4.322342\n",
      "24675it [47:07,  8.74it/s]Train epoch: 1 [batch #24675, batch_size 1, seq length 2500]\tLoss: 3.685524\n",
      "24700it [47:09,  8.74it/s]Train epoch: 1 [batch #24700, batch_size 1, seq length 2500]\tLoss: 3.911641\n",
      "24725it [47:12,  8.74it/s]Train epoch: 1 [batch #24725, batch_size 1, seq length 2500]\tLoss: 3.873253\n",
      "24750it [47:15,  8.76it/s]Train epoch: 1 [batch #24750, batch_size 1, seq length 2500]\tLoss: 3.922883\n",
      "24775it [47:18,  8.72it/s]Train epoch: 1 [batch #24775, batch_size 1, seq length 2500]\tLoss: 4.271573\n",
      "24800it [47:21,  8.69it/s]Train epoch: 1 [batch #24800, batch_size 1, seq length 2500]\tLoss: 4.006154\n",
      "24825it [47:24,  8.75it/s]Train epoch: 1 [batch #24825, batch_size 1, seq length 2500]\tLoss: 4.132135\n",
      "24850it [47:27,  8.74it/s]Train epoch: 1 [batch #24850, batch_size 1, seq length 2500]\tLoss: 3.889206\n",
      "24875it [47:29,  8.77it/s]Train epoch: 1 [batch #24875, batch_size 1, seq length 2500]\tLoss: 3.632133\n",
      "24900it [47:32,  8.74it/s]Train epoch: 1 [batch #24900, batch_size 1, seq length 2500]\tLoss: 4.134075\n",
      "24925it [47:35,  8.76it/s]Train epoch: 1 [batch #24925, batch_size 1, seq length 2500]\tLoss: 3.957715\n",
      "24950it [47:38,  8.60it/s]Train epoch: 1 [batch #24950, batch_size 1, seq length 2500]\tLoss: 3.976358\n",
      "24975it [47:41,  8.75it/s]Train epoch: 1 [batch #24975, batch_size 1, seq length 2500]\tLoss: 3.980399\n",
      "25000it [47:44,  8.63it/s]Train epoch: 1 [batch #25000, batch_size 1, seq length 2500]\tLoss: 3.851195\n",
      "25025it [47:47,  8.68it/s]Train epoch: 1 [batch #25025, batch_size 1, seq length 2500]\tLoss: 3.903174\n",
      "25050it [47:50,  8.72it/s]Train epoch: 1 [batch #25050, batch_size 1, seq length 2500]\tLoss: 4.001708\n",
      "25075it [47:52,  8.77it/s]Train epoch: 1 [batch #25075, batch_size 1, seq length 2500]\tLoss: 3.702632\n",
      "25100it [47:55,  8.76it/s]Train epoch: 1 [batch #25100, batch_size 1, seq length 2500]\tLoss: 4.129132\n",
      "25125it [47:58,  8.73it/s]Train epoch: 1 [batch #25125, batch_size 1, seq length 2500]\tLoss: 4.093237\n",
      "25150it [48:01,  8.73it/s]Train epoch: 1 [batch #25150, batch_size 1, seq length 2500]\tLoss: 3.867182\n",
      "25175it [48:04,  8.65it/s]Train epoch: 1 [batch #25175, batch_size 1, seq length 2500]\tLoss: 3.884017\n",
      "25200it [48:07,  8.78it/s]Train epoch: 1 [batch #25200, batch_size 1, seq length 2500]\tLoss: 4.111106\n",
      "25225it [48:10,  8.75it/s]Train epoch: 1 [batch #25225, batch_size 1, seq length 2500]\tLoss: 4.075338\n",
      "25250it [48:12,  8.69it/s]Train epoch: 1 [batch #25250, batch_size 1, seq length 2500]\tLoss: 3.533397\n",
      "25275it [48:15,  8.74it/s]Train epoch: 1 [batch #25275, batch_size 1, seq length 2500]\tLoss: 4.201415\n",
      "25300it [48:18,  8.72it/s]Train epoch: 1 [batch #25300, batch_size 1, seq length 2500]\tLoss: 3.922994\n",
      "25325it [48:21,  8.77it/s]Train epoch: 1 [batch #25325, batch_size 1, seq length 2500]\tLoss: 3.954723\n",
      "25350it [48:24,  8.69it/s]Train epoch: 1 [batch #25350, batch_size 1, seq length 2500]\tLoss: 3.803505\n",
      "25375it [48:27,  8.77it/s]Train epoch: 1 [batch #25375, batch_size 1, seq length 2500]\tLoss: 3.896586\n",
      "25400it [48:30,  8.75it/s]Train epoch: 1 [batch #25400, batch_size 1, seq length 2500]\tLoss: 3.816098\n",
      "25425it [48:33,  8.67it/s]Train epoch: 1 [batch #25425, batch_size 1, seq length 2500]\tLoss: 4.078323\n",
      "25450it [48:35,  8.75it/s]Train epoch: 1 [batch #25450, batch_size 1, seq length 2500]\tLoss: 4.251127\n",
      "25475it [48:38,  8.77it/s]Train epoch: 1 [batch #25475, batch_size 1, seq length 2500]\tLoss: 4.077050\n",
      "25500it [48:41,  8.73it/s]Train epoch: 1 [batch #25500, batch_size 1, seq length 2500]\tLoss: 4.047251\n",
      "25525it [48:44,  8.73it/s]Train epoch: 1 [batch #25525, batch_size 1, seq length 2500]\tLoss: 3.914029\n",
      "25550it [48:47,  8.72it/s]Train epoch: 1 [batch #25550, batch_size 1, seq length 2500]\tLoss: 4.166881\n",
      "25575it [48:50,  8.67it/s]Train epoch: 1 [batch #25575, batch_size 1, seq length 2500]\tLoss: 4.016016\n",
      "25600it [48:53,  8.74it/s]Train epoch: 1 [batch #25600, batch_size 1, seq length 2500]\tLoss: 4.294307\n",
      "25625it [48:55,  8.73it/s]Train epoch: 1 [batch #25625, batch_size 1, seq length 2500]\tLoss: 3.694015\n",
      "25650it [48:58,  8.71it/s]Train epoch: 1 [batch #25650, batch_size 1, seq length 2500]\tLoss: 4.001082\n",
      "25675it [49:01,  8.71it/s]Train epoch: 1 [batch #25675, batch_size 1, seq length 2500]\tLoss: 4.201141\n",
      "25700it [49:04,  8.68it/s]Train epoch: 1 [batch #25700, batch_size 1, seq length 2500]\tLoss: 3.792168\n",
      "25725it [49:07,  8.75it/s]Train epoch: 1 [batch #25725, batch_size 1, seq length 2500]\tLoss: 3.854196\n",
      "25750it [49:10,  8.77it/s]Train epoch: 1 [batch #25750, batch_size 1, seq length 2500]\tLoss: 3.966794\n",
      "25775it [49:13,  8.77it/s]Train epoch: 1 [batch #25775, batch_size 1, seq length 2500]\tLoss: 4.238221\n",
      "25800it [49:16,  8.75it/s]Train epoch: 1 [batch #25800, batch_size 1, seq length 2500]\tLoss: 4.028735\n",
      "25825it [49:18,  8.70it/s]Train epoch: 1 [batch #25825, batch_size 1, seq length 2500]\tLoss: 4.381050\n",
      "25850it [49:21,  8.73it/s]Train epoch: 1 [batch #25850, batch_size 1, seq length 2500]\tLoss: 3.995898\n",
      "25875it [49:24,  8.69it/s]Train epoch: 1 [batch #25875, batch_size 1, seq length 2500]\tLoss: 3.735570\n",
      "25900it [49:27,  8.73it/s]Train epoch: 1 [batch #25900, batch_size 1, seq length 2500]\tLoss: 3.847435\n",
      "25925it [49:30,  8.74it/s]Train epoch: 1 [batch #25925, batch_size 1, seq length 2500]\tLoss: 4.211145\n",
      "25950it [49:33,  8.76it/s]Train epoch: 1 [batch #25950, batch_size 1, seq length 2500]\tLoss: 4.127797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25975it [49:36,  8.76it/s]Train epoch: 1 [batch #25975, batch_size 1, seq length 2500]\tLoss: 4.044070\n",
      "26000it [49:38,  8.71it/s]Train epoch: 1 [batch #26000, batch_size 1, seq length 2500]\tLoss: 4.075023\n",
      "26025it [49:41,  8.74it/s]Train epoch: 1 [batch #26025, batch_size 1, seq length 2500]\tLoss: 4.092997\n",
      "26050it [49:44,  8.77it/s]Train epoch: 1 [batch #26050, batch_size 1, seq length 2500]\tLoss: 4.089799\n",
      "26075it [49:47,  8.71it/s]Train epoch: 1 [batch #26075, batch_size 1, seq length 2500]\tLoss: 3.948472\n",
      "26100it [49:50,  8.70it/s]Train epoch: 1 [batch #26100, batch_size 1, seq length 2500]\tLoss: 3.865171\n",
      "26125it [49:53,  8.79it/s]Train epoch: 1 [batch #26125, batch_size 1, seq length 2500]\tLoss: 4.136982\n",
      "26150it [49:56,  8.75it/s]Train epoch: 1 [batch #26150, batch_size 1, seq length 2500]\tLoss: 3.899660\n",
      "26175it [49:58,  8.72it/s]Train epoch: 1 [batch #26175, batch_size 1, seq length 2500]\tLoss: 3.511761\n",
      "26200it [50:01,  8.71it/s]Train epoch: 1 [batch #26200, batch_size 1, seq length 2500]\tLoss: 4.068217\n",
      "26225it [50:04,  8.78it/s]Train epoch: 1 [batch #26225, batch_size 1, seq length 2500]\tLoss: 3.806091\n",
      "26250it [50:07,  8.76it/s]Train epoch: 1 [batch #26250, batch_size 1, seq length 2500]\tLoss: 4.017332\n",
      "26275it [50:10,  8.76it/s]Train epoch: 1 [batch #26275, batch_size 1, seq length 2500]\tLoss: 4.002041\n",
      "26300it [50:13,  8.76it/s]Train epoch: 1 [batch #26300, batch_size 1, seq length 2500]\tLoss: 4.176659\n",
      "26325it [50:16,  8.76it/s]Train epoch: 1 [batch #26325, batch_size 1, seq length 2500]\tLoss: 3.898296\n",
      "26350it [50:18,  8.70it/s]Train epoch: 1 [batch #26350, batch_size 1, seq length 2500]\tLoss: 4.042610\n",
      "26375it [50:21,  8.68it/s]Train epoch: 1 [batch #26375, batch_size 1, seq length 2500]\tLoss: 4.134077\n",
      "26400it [50:24,  8.76it/s]Train epoch: 1 [batch #26400, batch_size 1, seq length 2500]\tLoss: 4.102571\n",
      "26425it [50:27,  8.77it/s]Train epoch: 1 [batch #26425, batch_size 1, seq length 2500]\tLoss: 4.009705\n",
      "26450it [50:30,  8.68it/s]Train epoch: 1 [batch #26450, batch_size 1, seq length 2500]\tLoss: 3.816917\n",
      "26475it [50:33,  8.74it/s]Train epoch: 1 [batch #26475, batch_size 1, seq length 2500]\tLoss: 4.050983\n",
      "26500it [50:36,  8.77it/s]Train epoch: 1 [batch #26500, batch_size 1, seq length 2500]\tLoss: 3.787394\n",
      "26525it [50:39,  8.74it/s]Train epoch: 1 [batch #26525, batch_size 1, seq length 2500]\tLoss: 3.771983\n",
      "26550it [50:41,  8.77it/s]Train epoch: 1 [batch #26550, batch_size 1, seq length 2500]\tLoss: 3.886601\n",
      "26575it [50:44,  8.75it/s]Train epoch: 1 [batch #26575, batch_size 1, seq length 2500]\tLoss: 3.741297\n",
      "26600it [50:47,  8.71it/s]Train epoch: 1 [batch #26600, batch_size 1, seq length 2500]\tLoss: 3.978514\n",
      "26625it [50:50,  8.71it/s]Train epoch: 1 [batch #26625, batch_size 1, seq length 2500]\tLoss: 3.972520\n",
      "26650it [50:53,  8.73it/s]Train epoch: 1 [batch #26650, batch_size 1, seq length 2500]\tLoss: 3.712567\n",
      "26675it [50:56,  8.75it/s]Train epoch: 1 [batch #26675, batch_size 1, seq length 2500]\tLoss: 4.160184\n",
      "26700it [50:59,  8.75it/s]Train epoch: 1 [batch #26700, batch_size 1, seq length 2500]\tLoss: 3.979302\n",
      "26725it [51:01,  8.74it/s]Train epoch: 1 [batch #26725, batch_size 1, seq length 2500]\tLoss: 3.899782\n",
      "26750it [51:04,  8.77it/s]Train epoch: 1 [batch #26750, batch_size 1, seq length 2500]\tLoss: 3.853827\n",
      "26775it [51:07,  8.74it/s]Train epoch: 1 [batch #26775, batch_size 1, seq length 2500]\tLoss: 3.724393\n",
      "26800it [51:10,  8.73it/s]Train epoch: 1 [batch #26800, batch_size 1, seq length 2500]\tLoss: 4.026956\n",
      "26825it [51:13,  8.72it/s]Train epoch: 1 [batch #26825, batch_size 1, seq length 2500]\tLoss: 3.875409\n",
      "26850it [51:16,  8.78it/s]Train epoch: 1 [batch #26850, batch_size 1, seq length 2500]\tLoss: 4.122399\n",
      "26875it [51:19,  8.55it/s]Train epoch: 1 [batch #26875, batch_size 1, seq length 2500]\tLoss: 3.954891\n",
      "26900it [51:22,  8.74it/s]Train epoch: 1 [batch #26900, batch_size 1, seq length 2500]\tLoss: 3.906794\n",
      "26925it [51:24,  8.75it/s]Train epoch: 1 [batch #26925, batch_size 1, seq length 2500]\tLoss: 4.116965\n",
      "26950it [51:27,  8.72it/s]Train epoch: 1 [batch #26950, batch_size 1, seq length 2500]\tLoss: 4.055791\n",
      "26975it [51:30,  8.76it/s]Train epoch: 1 [batch #26975, batch_size 1, seq length 2500]\tLoss: 4.097325\n",
      "27000it [51:33,  8.78it/s]Train epoch: 1 [batch #27000, batch_size 1, seq length 2500]\tLoss: 3.970685\n",
      "27025it [51:36,  8.70it/s]Train epoch: 1 [batch #27025, batch_size 1, seq length 2500]\tLoss: 4.009352\n",
      "27050it [51:39,  8.72it/s]Train epoch: 1 [batch #27050, batch_size 1, seq length 2500]\tLoss: 3.877464\n",
      "27075it [51:42,  8.75it/s]Train epoch: 1 [batch #27075, batch_size 1, seq length 2500]\tLoss: 3.928392\n",
      "27100it [51:44,  8.71it/s]Train epoch: 1 [batch #27100, batch_size 1, seq length 2500]\tLoss: 4.231093\n",
      "27125it [51:47,  8.77it/s]Train epoch: 1 [batch #27125, batch_size 1, seq length 2500]\tLoss: 3.997494\n",
      "27150it [51:50,  8.73it/s]Train epoch: 1 [batch #27150, batch_size 1, seq length 2500]\tLoss: 4.064160\n",
      "27175it [51:53,  8.74it/s]Train epoch: 1 [batch #27175, batch_size 1, seq length 2500]\tLoss: 3.940952\n",
      "27200it [51:56,  8.77it/s]Train epoch: 1 [batch #27200, batch_size 1, seq length 2500]\tLoss: 3.861734\n",
      "27225it [51:59,  8.65it/s]Train epoch: 1 [batch #27225, batch_size 1, seq length 2500]\tLoss: 4.032227\n",
      "27250it [52:02,  8.74it/s]Train epoch: 1 [batch #27250, batch_size 1, seq length 2500]\tLoss: 3.929387\n",
      "27275it [52:04,  8.77it/s]Train epoch: 1 [batch #27275, batch_size 1, seq length 2500]\tLoss: 3.993432\n",
      "27300it [52:07,  8.76it/s]Train epoch: 1 [batch #27300, batch_size 1, seq length 2500]\tLoss: 4.421861\n",
      "27325it [52:10,  8.74it/s]Train epoch: 1 [batch #27325, batch_size 1, seq length 2500]\tLoss: 4.045964\n",
      "27350it [52:13,  8.71it/s]Train epoch: 1 [batch #27350, batch_size 1, seq length 2500]\tLoss: 3.756479\n",
      "27375it [52:16,  8.74it/s]Train epoch: 1 [batch #27375, batch_size 1, seq length 2500]\tLoss: 3.885488\n",
      "27400it [52:19,  8.77it/s]Train epoch: 1 [batch #27400, batch_size 1, seq length 2500]\tLoss: 3.729387\n",
      "27425it [52:22,  8.74it/s]Train epoch: 1 [batch #27425, batch_size 1, seq length 2500]\tLoss: 4.046534\n",
      "27450it [52:24,  8.72it/s]Train epoch: 1 [batch #27450, batch_size 1, seq length 2500]\tLoss: 3.884966\n",
      "27475it [52:27,  8.73it/s]Train epoch: 1 [batch #27475, batch_size 1, seq length 2500]\tLoss: 4.069749\n",
      "27500it [52:30,  8.74it/s]Train epoch: 1 [batch #27500, batch_size 1, seq length 2500]\tLoss: 3.858837\n",
      "27525it [52:33,  8.74it/s]Train epoch: 1 [batch #27525, batch_size 1, seq length 2500]\tLoss: 4.044348\n",
      "27550it [52:36,  8.77it/s]Train epoch: 1 [batch #27550, batch_size 1, seq length 2500]\tLoss: 3.884688\n",
      "27575it [52:39,  8.74it/s]Train epoch: 1 [batch #27575, batch_size 1, seq length 2500]\tLoss: 3.497935\n",
      "27600it [52:42,  8.77it/s]Train epoch: 1 [batch #27600, batch_size 1, seq length 2500]\tLoss: 3.898018\n",
      "27625it [52:45,  8.65it/s]Train epoch: 1 [batch #27625, batch_size 1, seq length 2500]\tLoss: 3.877540\n",
      "27650it [52:47,  8.70it/s]Train epoch: 1 [batch #27650, batch_size 1, seq length 2500]\tLoss: 4.018606\n",
      "27675it [52:50,  8.77it/s]Train epoch: 1 [batch #27675, batch_size 1, seq length 2500]\tLoss: 3.945488\n",
      "27700it [52:53,  8.74it/s]Train epoch: 1 [batch #27700, batch_size 1, seq length 2500]\tLoss: 3.615296\n",
      "27725it [52:56,  8.77it/s]Train epoch: 1 [batch #27725, batch_size 1, seq length 2500]\tLoss: 4.147443\n",
      "27750it [52:59,  8.75it/s]Train epoch: 1 [batch #27750, batch_size 1, seq length 2500]\tLoss: 3.929471\n",
      "27775it [53:02,  8.71it/s]Train epoch: 1 [batch #27775, batch_size 1, seq length 2500]\tLoss: 3.872256\n",
      "27800it [53:05,  8.70it/s]Train epoch: 1 [batch #27800, batch_size 1, seq length 2500]\tLoss: 3.928764\n",
      "27825it [53:07,  8.74it/s]Train epoch: 1 [batch #27825, batch_size 1, seq length 2500]\tLoss: 4.052934\n",
      "27850it [53:10,  8.78it/s]Train epoch: 1 [batch #27850, batch_size 1, seq length 2500]\tLoss: 4.124943\n",
      "27875it [53:13,  8.76it/s]Train epoch: 1 [batch #27875, batch_size 1, seq length 2500]\tLoss: 3.964556\n",
      "27900it [53:16,  8.73it/s]Train epoch: 1 [batch #27900, batch_size 1, seq length 2500]\tLoss: 3.939417\n",
      "27925it [53:19,  8.51it/s]Train epoch: 1 [batch #27925, batch_size 1, seq length 2500]\tLoss: 4.264181\n",
      "27950it [53:22,  8.74it/s]Train epoch: 1 [batch #27950, batch_size 1, seq length 2500]\tLoss: 3.842438\n",
      "27975it [53:25,  8.73it/s]Train epoch: 1 [batch #27975, batch_size 1, seq length 2500]\tLoss: 3.741547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000it [53:28,  8.70it/s]Train epoch: 1 [batch #28000, batch_size 1, seq length 2500]\tLoss: 3.967477\n",
      "28025it [53:30,  8.72it/s]Train epoch: 1 [batch #28025, batch_size 1, seq length 2500]\tLoss: 3.951873\n",
      "28050it [53:33,  8.75it/s]Train epoch: 1 [batch #28050, batch_size 1, seq length 2500]\tLoss: 4.147994\n",
      "28075it [53:36,  8.75it/s]Train epoch: 1 [batch #28075, batch_size 1, seq length 2500]\tLoss: 3.762037\n",
      "28100it [53:39,  8.75it/s]Train epoch: 1 [batch #28100, batch_size 1, seq length 2500]\tLoss: 3.807482\n",
      "28125it [53:42,  8.73it/s]Train epoch: 1 [batch #28125, batch_size 1, seq length 2500]\tLoss: 4.319221\n",
      "28150it [53:45,  8.77it/s]Train epoch: 1 [batch #28150, batch_size 1, seq length 2500]\tLoss: 3.960928\n",
      "28175it [53:48,  8.74it/s]Train epoch: 1 [batch #28175, batch_size 1, seq length 2500]\tLoss: 3.764779\n",
      "28200it [53:50,  8.70it/s]Train epoch: 1 [batch #28200, batch_size 1, seq length 2500]\tLoss: 3.971049\n",
      "28225it [53:53,  8.67it/s]Train epoch: 1 [batch #28225, batch_size 1, seq length 2500]\tLoss: 4.032955\n",
      "28250it [53:56,  8.77it/s]Train epoch: 1 [batch #28250, batch_size 1, seq length 2500]\tLoss: 3.683167\n",
      "28275it [53:59,  8.73it/s]Train epoch: 1 [batch #28275, batch_size 1, seq length 2500]\tLoss: 4.394901\n",
      "28300it [54:02,  8.67it/s]Train epoch: 1 [batch #28300, batch_size 1, seq length 2500]\tLoss: 3.981841\n",
      "28325it [54:05,  8.77it/s]Train epoch: 1 [batch #28325, batch_size 1, seq length 2500]\tLoss: 3.653887\n",
      "28350it [54:08,  8.70it/s]Train epoch: 1 [batch #28350, batch_size 1, seq length 2500]\tLoss: 3.864502\n",
      "28375it [54:10,  8.76it/s]Train epoch: 1 [batch #28375, batch_size 1, seq length 2500]\tLoss: 3.565084\n",
      "28400it [54:13,  8.72it/s]Train epoch: 1 [batch #28400, batch_size 1, seq length 2500]\tLoss: 3.750150\n",
      "28425it [54:16,  8.74it/s]Train epoch: 1 [batch #28425, batch_size 1, seq length 2500]\tLoss: 3.926652\n",
      "28450it [54:19,  8.76it/s]Train epoch: 1 [batch #28450, batch_size 1, seq length 2500]\tLoss: 4.037854\n",
      "28475it [54:22,  8.63it/s]Train epoch: 1 [batch #28475, batch_size 1, seq length 2500]\tLoss: 3.817505\n",
      "28500it [54:25,  8.76it/s]Train epoch: 1 [batch #28500, batch_size 1, seq length 2500]\tLoss: 3.899633\n",
      "28525it [54:28,  8.74it/s]Train epoch: 1 [batch #28525, batch_size 1, seq length 2500]\tLoss: 3.745546\n",
      "28550it [54:31,  8.71it/s]Train epoch: 1 [batch #28550, batch_size 1, seq length 2500]\tLoss: 3.888021\n",
      "28575it [54:33,  8.71it/s]Train epoch: 1 [batch #28575, batch_size 1, seq length 2500]\tLoss: 3.944634\n",
      "28600it [54:36,  8.76it/s]Train epoch: 1 [batch #28600, batch_size 1, seq length 2500]\tLoss: 4.154582\n",
      "28625it [54:39,  8.72it/s]Train epoch: 1 [batch #28625, batch_size 1, seq length 2500]\tLoss: 4.124671\n",
      "28650it [54:42,  8.67it/s]Train epoch: 1 [batch #28650, batch_size 1, seq length 2500]\tLoss: 3.984536\n",
      "28675it [54:45,  8.75it/s]Train epoch: 1 [batch #28675, batch_size 1, seq length 2500]\tLoss: 4.142220\n",
      "28700it [54:48,  8.71it/s]Train epoch: 1 [batch #28700, batch_size 1, seq length 2500]\tLoss: 3.798923\n",
      "28725it [54:51,  8.76it/s]Train epoch: 1 [batch #28725, batch_size 1, seq length 2500]\tLoss: 4.014179\n",
      "28750it [54:53,  8.71it/s]Train epoch: 1 [batch #28750, batch_size 1, seq length 2500]\tLoss: 3.910841\n",
      "28775it [54:56,  8.71it/s]Train epoch: 1 [batch #28775, batch_size 1, seq length 2500]\tLoss: 3.839139\n",
      "28800it [54:59,  8.75it/s]Train epoch: 1 [batch #28800, batch_size 1, seq length 2500]\tLoss: 3.964481\n",
      "28825it [55:02,  8.58it/s]Train epoch: 1 [batch #28825, batch_size 1, seq length 2500]\tLoss: 4.285339\n",
      "28850it [55:05,  8.68it/s]Train epoch: 1 [batch #28850, batch_size 1, seq length 2500]\tLoss: 4.107260\n",
      "28875it [55:08,  8.72it/s]Train epoch: 1 [batch #28875, batch_size 1, seq length 2500]\tLoss: 3.789696\n",
      "28900it [55:11,  8.77it/s]Train epoch: 1 [batch #28900, batch_size 1, seq length 2500]\tLoss: 4.044547\n",
      "28925it [55:14,  8.74it/s]Train epoch: 1 [batch #28925, batch_size 1, seq length 2500]\tLoss: 3.726186\n",
      "28950it [55:16,  8.72it/s]Train epoch: 1 [batch #28950, batch_size 1, seq length 2500]\tLoss: 3.860214\n",
      "28975it [55:19,  8.73it/s]Train epoch: 1 [batch #28975, batch_size 1, seq length 2500]\tLoss: 4.182841\n",
      "29000it [55:22,  8.58it/s]Train epoch: 1 [batch #29000, batch_size 1, seq length 2500]\tLoss: 4.143628\n",
      "29025it [55:25,  8.76it/s]Train epoch: 1 [batch #29025, batch_size 1, seq length 2500]\tLoss: 3.821124\n",
      "29050it [55:28,  8.75it/s]Train epoch: 1 [batch #29050, batch_size 1, seq length 2500]\tLoss: 4.100089\n",
      "29075it [55:31,  8.68it/s]Train epoch: 1 [batch #29075, batch_size 1, seq length 2500]\tLoss: 3.947176\n",
      "29100it [55:34,  8.74it/s]Train epoch: 1 [batch #29100, batch_size 1, seq length 2500]\tLoss: 3.877498\n",
      "29125it [55:37,  8.63it/s]Train epoch: 1 [batch #29125, batch_size 1, seq length 2500]\tLoss: 3.797496\n",
      "29150it [55:39,  8.77it/s]Train epoch: 1 [batch #29150, batch_size 1, seq length 2500]\tLoss: 4.035543\n",
      "29175it [55:42,  8.78it/s]Train epoch: 1 [batch #29175, batch_size 1, seq length 2500]\tLoss: 3.723143\n",
      "29200it [55:45,  8.76it/s]Train epoch: 1 [batch #29200, batch_size 1, seq length 2500]\tLoss: 3.858620\n",
      "29225it [55:48,  8.74it/s]Train epoch: 1 [batch #29225, batch_size 1, seq length 2500]\tLoss: 3.982797\n",
      "29250it [55:51,  8.73it/s]Train epoch: 1 [batch #29250, batch_size 1, seq length 2500]\tLoss: 3.886242\n",
      "29275it [55:54,  8.65it/s]Train epoch: 1 [batch #29275, batch_size 1, seq length 2500]\tLoss: 3.652241\n",
      "29300it [55:57,  8.69it/s]Train epoch: 1 [batch #29300, batch_size 1, seq length 2500]\tLoss: 4.347476\n",
      "29325it [55:59,  8.73it/s]Train epoch: 1 [batch #29325, batch_size 1, seq length 2500]\tLoss: 3.988802\n",
      "29350it [56:02,  8.75it/s]Train epoch: 1 [batch #29350, batch_size 1, seq length 2500]\tLoss: 3.908270\n",
      "29375it [56:05,  8.71it/s]Train epoch: 1 [batch #29375, batch_size 1, seq length 2500]\tLoss: 4.335801\n",
      "29400it [56:08,  8.67it/s]Train epoch: 1 [batch #29400, batch_size 1, seq length 2500]\tLoss: 4.174347\n",
      "29425it [56:11,  8.70it/s]Train epoch: 1 [batch #29425, batch_size 1, seq length 2500]\tLoss: 4.199638\n",
      "29450it [56:14,  8.73it/s]Train epoch: 1 [batch #29450, batch_size 1, seq length 2500]\tLoss: 3.830595\n",
      "29475it [56:17,  8.70it/s]Train epoch: 1 [batch #29475, batch_size 1, seq length 2500]\tLoss: 3.830712\n",
      "29500it [56:20,  8.68it/s]Train epoch: 1 [batch #29500, batch_size 1, seq length 2500]\tLoss: 3.911082\n",
      "29525it [56:22,  8.68it/s]Train epoch: 1 [batch #29525, batch_size 1, seq length 2500]\tLoss: 4.066902\n",
      "29550it [56:25,  8.70it/s]Train epoch: 1 [batch #29550, batch_size 1, seq length 2500]\tLoss: 3.872008\n",
      "29575it [56:28,  8.73it/s]Train epoch: 1 [batch #29575, batch_size 1, seq length 2500]\tLoss: 3.719407\n",
      "29600it [56:31,  8.70it/s]Train epoch: 1 [batch #29600, batch_size 1, seq length 2500]\tLoss: 3.919564\n",
      "29625it [56:34,  8.74it/s]Train epoch: 1 [batch #29625, batch_size 1, seq length 2500]\tLoss: 3.660962\n",
      "29650it [56:37,  8.71it/s]Train epoch: 1 [batch #29650, batch_size 1, seq length 2500]\tLoss: 4.016105\n",
      "29675it [56:40,  8.72it/s]Train epoch: 1 [batch #29675, batch_size 1, seq length 2500]\tLoss: 3.814413\n",
      "29700it [56:43,  8.76it/s]Train epoch: 1 [batch #29700, batch_size 1, seq length 2500]\tLoss: 4.023743\n",
      "29725it [56:45,  8.73it/s]Train epoch: 1 [batch #29725, batch_size 1, seq length 2500]\tLoss: 3.559311\n",
      "29750it [56:48,  8.73it/s]Train epoch: 1 [batch #29750, batch_size 1, seq length 2500]\tLoss: 4.155854\n",
      "29775it [56:51,  8.71it/s]Train epoch: 1 [batch #29775, batch_size 1, seq length 2500]\tLoss: 3.789486\n",
      "29800it [56:54,  8.73it/s]Train epoch: 1 [batch #29800, batch_size 1, seq length 2500]\tLoss: 3.975829\n",
      "29825it [56:57,  8.75it/s]Train epoch: 1 [batch #29825, batch_size 1, seq length 2500]\tLoss: 3.789816\n",
      "29850it [57:00,  8.77it/s]Train epoch: 1 [batch #29850, batch_size 1, seq length 2500]\tLoss: 3.951355\n",
      "29875it [57:03,  8.75it/s]Train epoch: 1 [batch #29875, batch_size 1, seq length 2500]\tLoss: 4.015291\n",
      "29900it [57:05,  8.69it/s]Train epoch: 1 [batch #29900, batch_size 1, seq length 2500]\tLoss: 4.105450\n",
      "29925it [57:08,  8.67it/s]Train epoch: 1 [batch #29925, batch_size 1, seq length 2500]\tLoss: 3.778429\n",
      "29950it [57:11,  8.53it/s]Train epoch: 1 [batch #29950, batch_size 1, seq length 2500]\tLoss: 3.821894\n",
      "29975it [57:14,  8.76it/s]Train epoch: 1 [batch #29975, batch_size 1, seq length 2500]\tLoss: 3.631021\n",
      "30000it [57:17,  8.72it/s]Train epoch: 1 [batch #30000, batch_size 1, seq length 2500]\tLoss: 3.983381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30025it [57:20,  8.77it/s]Train epoch: 1 [batch #30025, batch_size 1, seq length 2500]\tLoss: 4.070884\n",
      "30050it [57:23,  8.52it/s]Train epoch: 1 [batch #30050, batch_size 1, seq length 2500]\tLoss: 3.858470\n",
      "30075it [57:26,  8.69it/s]Train epoch: 1 [batch #30075, batch_size 1, seq length 2500]\tLoss: 3.886108\n",
      "30100it [57:28,  8.77it/s]Train epoch: 1 [batch #30100, batch_size 1, seq length 2500]\tLoss: 4.048114\n",
      "30125it [57:31,  8.69it/s]Train epoch: 1 [batch #30125, batch_size 1, seq length 2500]\tLoss: 3.524446\n",
      "30150it [57:34,  8.66it/s]Train epoch: 1 [batch #30150, batch_size 1, seq length 2500]\tLoss: 4.098637\n",
      "30175it [57:37,  8.75it/s]Train epoch: 1 [batch #30175, batch_size 1, seq length 2500]\tLoss: 4.059208\n",
      "30200it [57:40,  8.75it/s]Train epoch: 1 [batch #30200, batch_size 1, seq length 2500]\tLoss: 3.725020\n",
      "30225it [57:43,  8.76it/s]Train epoch: 1 [batch #30225, batch_size 1, seq length 2500]\tLoss: 3.801372\n",
      "30250it [57:46,  8.76it/s]Train epoch: 1 [batch #30250, batch_size 1, seq length 2500]\tLoss: 3.869103\n",
      "30275it [57:48,  8.75it/s]Train epoch: 1 [batch #30275, batch_size 1, seq length 2500]\tLoss: 3.769223\n",
      "30300it [57:51,  8.74it/s]Train epoch: 1 [batch #30300, batch_size 1, seq length 2500]\tLoss: 4.114668\n",
      "30325it [57:54,  8.72it/s]Train epoch: 1 [batch #30325, batch_size 1, seq length 2500]\tLoss: 3.704340\n",
      "30350it [57:57,  8.74it/s]Train epoch: 1 [batch #30350, batch_size 1, seq length 2500]\tLoss: 3.966638\n",
      "30375it [58:00,  8.70it/s]Train epoch: 1 [batch #30375, batch_size 1, seq length 2500]\tLoss: 4.151861\n",
      "30400it [58:03,  8.78it/s]Train epoch: 1 [batch #30400, batch_size 1, seq length 2500]\tLoss: 3.846286\n",
      "30425it [58:06,  8.72it/s]Train epoch: 1 [batch #30425, batch_size 1, seq length 2500]\tLoss: 3.785305\n",
      "30450it [58:08,  8.72it/s]Train epoch: 1 [batch #30450, batch_size 1, seq length 2500]\tLoss: 3.924165\n",
      "30475it [58:11,  8.74it/s]Train epoch: 1 [batch #30475, batch_size 1, seq length 2500]\tLoss: 3.983078\n",
      "30500it [58:14,  8.71it/s]Train epoch: 1 [batch #30500, batch_size 1, seq length 2500]\tLoss: 3.937924\n",
      "30525it [58:17,  8.68it/s]Train epoch: 1 [batch #30525, batch_size 1, seq length 2500]\tLoss: 3.889661\n",
      "30550it [58:20,  8.67it/s]Train epoch: 1 [batch #30550, batch_size 1, seq length 2500]\tLoss: 4.018821\n",
      "30575it [58:23,  8.76it/s]Train epoch: 1 [batch #30575, batch_size 1, seq length 2500]\tLoss: 3.678724\n",
      "30600it [58:26,  8.75it/s]Train epoch: 1 [batch #30600, batch_size 1, seq length 2500]\tLoss: 3.696520\n",
      "30625it [58:29,  8.64it/s]Train epoch: 1 [batch #30625, batch_size 1, seq length 2500]\tLoss: 4.125589\n",
      "30650it [58:31,  8.73it/s]Train epoch: 1 [batch #30650, batch_size 1, seq length 2500]\tLoss: 3.866083\n",
      "30675it [58:34,  8.67it/s]Train epoch: 1 [batch #30675, batch_size 1, seq length 2500]\tLoss: 3.878976\n",
      "30700it [58:37,  8.70it/s]Train epoch: 1 [batch #30700, batch_size 1, seq length 2500]\tLoss: 4.302796\n",
      "30725it [58:40,  8.76it/s]Train epoch: 1 [batch #30725, batch_size 1, seq length 2500]\tLoss: 4.030231\n",
      "30750it [58:43,  8.75it/s]Train epoch: 1 [batch #30750, batch_size 1, seq length 2500]\tLoss: 3.991777\n",
      "30775it [58:46,  8.72it/s]Train epoch: 1 [batch #30775, batch_size 1, seq length 2500]\tLoss: 4.195681\n",
      "30800it [58:49,  8.77it/s]Train epoch: 1 [batch #30800, batch_size 1, seq length 2500]\tLoss: 3.821640\n",
      "30825it [58:51,  8.71it/s]Train epoch: 1 [batch #30825, batch_size 1, seq length 2500]\tLoss: 4.124261\n",
      "30850it [58:54,  8.76it/s]Train epoch: 1 [batch #30850, batch_size 1, seq length 2500]\tLoss: 3.863760\n",
      "30875it [58:57,  8.75it/s]Train epoch: 1 [batch #30875, batch_size 1, seq length 2500]\tLoss: 4.066788\n",
      "30900it [59:00,  8.68it/s]Train epoch: 1 [batch #30900, batch_size 1, seq length 2500]\tLoss: 4.006229\n",
      "30925it [59:03,  8.75it/s]Train epoch: 1 [batch #30925, batch_size 1, seq length 2500]\tLoss: 3.735409\n",
      "30950it [59:06,  8.74it/s]Train epoch: 1 [batch #30950, batch_size 1, seq length 2500]\tLoss: 4.042703\n",
      "30975it [59:09,  8.75it/s]Train epoch: 1 [batch #30975, batch_size 1, seq length 2500]\tLoss: 3.699485\n",
      "31000it [59:12,  8.72it/s]Train epoch: 1 [batch #31000, batch_size 1, seq length 2500]\tLoss: 3.753075\n",
      "31025it [59:14,  8.73it/s]Train epoch: 1 [batch #31025, batch_size 1, seq length 2500]\tLoss: 3.709618\n",
      "31050it [59:17,  8.73it/s]Train epoch: 1 [batch #31050, batch_size 1, seq length 2500]\tLoss: 4.034690\n",
      "31075it [59:20,  8.74it/s]Train epoch: 1 [batch #31075, batch_size 1, seq length 2500]\tLoss: 4.161135\n",
      "31100it [59:23,  8.69it/s]Train epoch: 1 [batch #31100, batch_size 1, seq length 2500]\tLoss: 3.829748\n",
      "31125it [59:26,  8.71it/s]Train epoch: 1 [batch #31125, batch_size 1, seq length 2500]\tLoss: 4.215398\n",
      "31150it [59:29,  8.69it/s]Train epoch: 1 [batch #31150, batch_size 1, seq length 2500]\tLoss: 3.727033\n",
      "31175it [59:32,  8.64it/s]Train epoch: 1 [batch #31175, batch_size 1, seq length 2500]\tLoss: 3.933818\n",
      "31200it [59:34,  8.74it/s]Train epoch: 1 [batch #31200, batch_size 1, seq length 2500]\tLoss: 4.136875\n",
      "31225it [59:37,  8.68it/s]Train epoch: 1 [batch #31225, batch_size 1, seq length 2500]\tLoss: 3.949296\n",
      "31250it [59:40,  8.75it/s]Train epoch: 1 [batch #31250, batch_size 1, seq length 2500]\tLoss: 3.543047\n",
      "31275it [59:43,  8.71it/s]Train epoch: 1 [batch #31275, batch_size 1, seq length 2500]\tLoss: 3.967633\n",
      "31300it [59:46,  8.73it/s]Train epoch: 1 [batch #31300, batch_size 1, seq length 2500]\tLoss: 3.857499\n",
      "31325it [59:49,  8.76it/s]Train epoch: 1 [batch #31325, batch_size 1, seq length 2500]\tLoss: 4.120258\n",
      "31350it [59:52,  8.74it/s]Train epoch: 1 [batch #31350, batch_size 1, seq length 2500]\tLoss: 3.924809\n",
      "31375it [59:55,  8.73it/s]Train epoch: 1 [batch #31375, batch_size 1, seq length 2500]\tLoss: 3.941343\n",
      "31400it [59:57,  8.75it/s]Train epoch: 1 [batch #31400, batch_size 1, seq length 2500]\tLoss: 3.781223\n",
      "31425it [1:00:00,  8.76it/s]Train epoch: 1 [batch #31425, batch_size 1, seq length 2500]\tLoss: 3.794475\n",
      "31450it [1:00:03,  8.73it/s]Train epoch: 1 [batch #31450, batch_size 1, seq length 2500]\tLoss: 4.003096\n",
      "31475it [1:00:06,  8.75it/s]Train epoch: 1 [batch #31475, batch_size 1, seq length 2500]\tLoss: 4.243302\n",
      "31500it [1:00:09,  8.75it/s]Train epoch: 1 [batch #31500, batch_size 1, seq length 2500]\tLoss: 3.894465\n",
      "31525it [1:00:12,  8.76it/s]Train epoch: 1 [batch #31525, batch_size 1, seq length 2500]\tLoss: 3.993282\n",
      "31550it [1:00:15,  8.73it/s]Train epoch: 1 [batch #31550, batch_size 1, seq length 2500]\tLoss: 3.900567\n",
      "31575it [1:00:17,  8.61it/s]Train epoch: 1 [batch #31575, batch_size 1, seq length 2500]\tLoss: 4.116457\n",
      "31600it [1:00:20,  8.77it/s]Train epoch: 1 [batch #31600, batch_size 1, seq length 2500]\tLoss: 3.822224\n",
      "31625it [1:00:23,  8.71it/s]Train epoch: 1 [batch #31625, batch_size 1, seq length 2500]\tLoss: 4.023720\n",
      "31650it [1:00:26,  8.77it/s]Train epoch: 1 [batch #31650, batch_size 1, seq length 2500]\tLoss: 3.626842\n",
      "31675it [1:00:29,  8.72it/s]Train epoch: 1 [batch #31675, batch_size 1, seq length 2500]\tLoss: 3.886198\n",
      "31700it [1:00:32,  8.73it/s]Train epoch: 1 [batch #31700, batch_size 1, seq length 2500]\tLoss: 3.731385\n",
      "31725it [1:00:35,  8.74it/s]Train epoch: 1 [batch #31725, batch_size 1, seq length 2500]\tLoss: 3.828865\n",
      "31750it [1:00:38,  8.75it/s]Train epoch: 1 [batch #31750, batch_size 1, seq length 2500]\tLoss: 4.152501\n",
      "31775it [1:00:40,  8.78it/s]Train epoch: 1 [batch #31775, batch_size 1, seq length 2500]\tLoss: 3.859819\n",
      "31800it [1:00:43,  8.54it/s]Train epoch: 1 [batch #31800, batch_size 1, seq length 2500]\tLoss: 4.202926\n",
      "31825it [1:00:46,  8.63it/s]Train epoch: 1 [batch #31825, batch_size 1, seq length 2500]\tLoss: 4.023856\n",
      "31850it [1:00:49,  8.49it/s]Train epoch: 1 [batch #31850, batch_size 1, seq length 2500]\tLoss: 3.884200\n",
      "31875it [1:00:52,  8.73it/s]Train epoch: 1 [batch #31875, batch_size 1, seq length 2500]\tLoss: 3.853628\n",
      "31900it [1:00:55,  8.72it/s]Train epoch: 1 [batch #31900, batch_size 1, seq length 2500]\tLoss: 3.989917\n",
      "31925it [1:00:58,  8.70it/s]Train epoch: 1 [batch #31925, batch_size 1, seq length 2500]\tLoss: 4.063560\n",
      "31950it [1:01:00,  8.55it/s]Train epoch: 1 [batch #31950, batch_size 1, seq length 2500]\tLoss: 3.912792\n",
      "31975it [1:01:03,  8.69it/s]Train epoch: 1 [batch #31975, batch_size 1, seq length 2500]\tLoss: 3.930618\n",
      "32000it [1:01:06,  8.74it/s]Train epoch: 1 [batch #32000, batch_size 1, seq length 2500]\tLoss: 4.139168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32025it [1:01:09,  8.69it/s]Train epoch: 1 [batch #32025, batch_size 1, seq length 2500]\tLoss: 3.754302\n",
      "32050it [1:01:12,  8.55it/s]Train epoch: 1 [batch #32050, batch_size 1, seq length 2500]\tLoss: 3.678712\n",
      "32075it [1:01:15,  8.76it/s]Train epoch: 1 [batch #32075, batch_size 1, seq length 2500]\tLoss: 3.956982\n",
      "32100it [1:01:18,  8.69it/s]Train epoch: 1 [batch #32100, batch_size 1, seq length 2500]\tLoss: 3.968782\n",
      "32125it [1:01:21,  8.72it/s]Train epoch: 1 [batch #32125, batch_size 1, seq length 2500]\tLoss: 4.036400\n",
      "32150it [1:01:23,  8.76it/s]Train epoch: 1 [batch #32150, batch_size 1, seq length 2500]\tLoss: 3.834102\n",
      "32175it [1:01:26,  8.67it/s]Train epoch: 1 [batch #32175, batch_size 1, seq length 2500]\tLoss: 3.805365\n",
      "32200it [1:01:29,  8.73it/s]Train epoch: 1 [batch #32200, batch_size 1, seq length 2500]\tLoss: 3.768674\n",
      "32225it [1:01:32,  8.59it/s]Train epoch: 1 [batch #32225, batch_size 1, seq length 2500]\tLoss: 4.054152\n",
      "32250it [1:01:35,  8.57it/s]Train epoch: 1 [batch #32250, batch_size 1, seq length 2500]\tLoss: 3.764041\n",
      "32275it [1:01:38,  8.74it/s]Train epoch: 1 [batch #32275, batch_size 1, seq length 2500]\tLoss: 3.752638\n",
      "32300it [1:01:41,  8.72it/s]Train epoch: 1 [batch #32300, batch_size 1, seq length 2500]\tLoss: 4.202101\n",
      "32325it [1:01:44,  8.72it/s]Train epoch: 1 [batch #32325, batch_size 1, seq length 2500]\tLoss: 4.207608\n",
      "32350it [1:01:46,  8.74it/s]Train epoch: 1 [batch #32350, batch_size 1, seq length 2500]\tLoss: 3.784218\n",
      "32375it [1:01:49,  8.76it/s]Train epoch: 1 [batch #32375, batch_size 1, seq length 2500]\tLoss: 3.829781\n",
      "32400it [1:01:52,  8.76it/s]Train epoch: 1 [batch #32400, batch_size 1, seq length 2500]\tLoss: 3.831077\n",
      "32425it [1:01:55,  8.73it/s]Train epoch: 1 [batch #32425, batch_size 1, seq length 2500]\tLoss: 3.790797\n",
      "32450it [1:01:58,  8.78it/s]Train epoch: 1 [batch #32450, batch_size 1, seq length 2500]\tLoss: 3.848115\n",
      "32475it [1:02:01,  8.56it/s]Train epoch: 1 [batch #32475, batch_size 1, seq length 2500]\tLoss: 3.790628\n",
      "32500it [1:02:04,  8.59it/s]Train epoch: 1 [batch #32500, batch_size 1, seq length 2500]\tLoss: 3.619293\n",
      "32525it [1:02:06,  8.73it/s]Train epoch: 1 [batch #32525, batch_size 1, seq length 2500]\tLoss: 3.756986\n",
      "32550it [1:02:09,  8.69it/s]Train epoch: 1 [batch #32550, batch_size 1, seq length 2500]\tLoss: 3.908485\n",
      "32575it [1:02:12,  8.72it/s]Train epoch: 1 [batch #32575, batch_size 1, seq length 2500]\tLoss: 4.049346\n",
      "32600it [1:02:15,  8.75it/s]Train epoch: 1 [batch #32600, batch_size 1, seq length 2500]\tLoss: 3.915430\n",
      "32625it [1:02:18,  8.76it/s]Train epoch: 1 [batch #32625, batch_size 1, seq length 2500]\tLoss: 3.750206\n",
      "32650it [1:02:21,  8.76it/s]Train epoch: 1 [batch #32650, batch_size 1, seq length 2500]\tLoss: 3.911218\n",
      "32675it [1:02:24,  8.76it/s]Train epoch: 1 [batch #32675, batch_size 1, seq length 2500]\tLoss: 3.864374\n",
      "32700it [1:02:26,  8.74it/s]Train epoch: 1 [batch #32700, batch_size 1, seq length 2500]\tLoss: 3.948872\n",
      "32725it [1:02:29,  8.58it/s]Train epoch: 1 [batch #32725, batch_size 1, seq length 2500]\tLoss: 4.036785\n",
      "32750it [1:02:32,  8.72it/s]Train epoch: 1 [batch #32750, batch_size 1, seq length 2500]\tLoss: 4.162167\n",
      "32775it [1:02:35,  8.78it/s]Train epoch: 1 [batch #32775, batch_size 1, seq length 2500]\tLoss: 3.802852\n",
      "32800it [1:02:38,  8.75it/s]Train epoch: 1 [batch #32800, batch_size 1, seq length 2500]\tLoss: 3.667106\n",
      "32825it [1:02:41,  8.72it/s]Train epoch: 1 [batch #32825, batch_size 1, seq length 2500]\tLoss: 3.612452\n",
      "32850it [1:02:44,  8.66it/s]Train epoch: 1 [batch #32850, batch_size 1, seq length 2500]\tLoss: 3.901283\n",
      "32875it [1:02:47,  8.70it/s]Train epoch: 1 [batch #32875, batch_size 1, seq length 2500]\tLoss: 3.917715\n",
      "32900it [1:02:49,  8.73it/s]Train epoch: 1 [batch #32900, batch_size 1, seq length 2500]\tLoss: 4.146540\n",
      "32925it [1:02:52,  8.70it/s]Train epoch: 1 [batch #32925, batch_size 1, seq length 2500]\tLoss: 3.784284\n",
      "32950it [1:02:55,  8.72it/s]Train epoch: 1 [batch #32950, batch_size 1, seq length 2500]\tLoss: 3.930856\n",
      "32975it [1:02:58,  8.76it/s]Train epoch: 1 [batch #32975, batch_size 1, seq length 2500]\tLoss: 4.048343\n",
      "33000it [1:03:01,  8.76it/s]Train epoch: 1 [batch #33000, batch_size 1, seq length 2500]\tLoss: 3.666557\n",
      "33025it [1:03:04,  8.71it/s]Train epoch: 1 [batch #33025, batch_size 1, seq length 2500]\tLoss: 4.030426\n",
      "33050it [1:03:07,  8.73it/s]Train epoch: 1 [batch #33050, batch_size 1, seq length 2500]\tLoss: 3.764366\n",
      "33075it [1:03:09,  8.76it/s]Train epoch: 1 [batch #33075, batch_size 1, seq length 2500]\tLoss: 3.909612\n",
      "33100it [1:03:12,  8.70it/s]Train epoch: 1 [batch #33100, batch_size 1, seq length 2500]\tLoss: 3.916284\n",
      "33125it [1:03:15,  8.72it/s]Train epoch: 1 [batch #33125, batch_size 1, seq length 2500]\tLoss: 3.947647\n",
      "33150it [1:03:18,  8.75it/s]Train epoch: 1 [batch #33150, batch_size 1, seq length 2500]\tLoss: 4.068569\n",
      "33175it [1:03:21,  8.68it/s]Train epoch: 1 [batch #33175, batch_size 1, seq length 2500]\tLoss: 3.909262\n",
      "33200it [1:03:24,  8.71it/s]Train epoch: 1 [batch #33200, batch_size 1, seq length 2500]\tLoss: 3.713925\n",
      "33225it [1:03:27,  8.72it/s]Train epoch: 1 [batch #33225, batch_size 1, seq length 2500]\tLoss: 3.738679\n",
      "33250it [1:03:29,  8.67it/s]Train epoch: 1 [batch #33250, batch_size 1, seq length 2500]\tLoss: 4.140872\n",
      "33275it [1:03:32,  8.61it/s]Train epoch: 1 [batch #33275, batch_size 1, seq length 2500]\tLoss: 3.675427\n",
      "33300it [1:03:35,  8.73it/s]Train epoch: 1 [batch #33300, batch_size 1, seq length 2500]\tLoss: 4.269893\n",
      "33325it [1:03:38,  8.71it/s]Train epoch: 1 [batch #33325, batch_size 1, seq length 2500]\tLoss: 3.993614\n",
      "33350it [1:03:41,  8.76it/s]Train epoch: 1 [batch #33350, batch_size 1, seq length 2500]\tLoss: 4.097415\n",
      "33375it [1:03:44,  8.72it/s]Train epoch: 1 [batch #33375, batch_size 1, seq length 2500]\tLoss: 3.607493\n",
      "33400it [1:03:47,  8.77it/s]Train epoch: 1 [batch #33400, batch_size 1, seq length 2500]\tLoss: 3.893512\n",
      "33425it [1:03:50,  8.76it/s]Train epoch: 1 [batch #33425, batch_size 1, seq length 2500]\tLoss: 3.717282\n",
      "33450it [1:03:52,  8.75it/s]Train epoch: 1 [batch #33450, batch_size 1, seq length 2500]\tLoss: 4.197896\n",
      "33475it [1:03:55,  8.74it/s]Train epoch: 1 [batch #33475, batch_size 1, seq length 2500]\tLoss: 4.109355\n",
      "33500it [1:03:58,  8.72it/s]Train epoch: 1 [batch #33500, batch_size 1, seq length 2500]\tLoss: 4.038097\n",
      "33525it [1:04:01,  8.73it/s]Train epoch: 1 [batch #33525, batch_size 1, seq length 2500]\tLoss: 4.008358\n",
      "33550it [1:04:04,  8.74it/s]Train epoch: 1 [batch #33550, batch_size 1, seq length 2500]\tLoss: 4.017753\n",
      "33575it [1:04:07,  8.74it/s]Train epoch: 1 [batch #33575, batch_size 1, seq length 2500]\tLoss: 4.031508\n",
      "33600it [1:04:10,  8.73it/s]Train epoch: 1 [batch #33600, batch_size 1, seq length 2500]\tLoss: 3.502332\n",
      "33625it [1:04:12,  8.76it/s]Train epoch: 1 [batch #33625, batch_size 1, seq length 2500]\tLoss: 4.194660\n",
      "33650it [1:04:15,  8.74it/s]Train epoch: 1 [batch #33650, batch_size 1, seq length 2500]\tLoss: 3.717346\n",
      "33675it [1:04:18,  8.70it/s]Train epoch: 1 [batch #33675, batch_size 1, seq length 2500]\tLoss: 3.911775\n",
      "33700it [1:04:21,  8.74it/s]Train epoch: 1 [batch #33700, batch_size 1, seq length 2500]\tLoss: 4.176342\n",
      "33725it [1:04:24,  8.71it/s]Train epoch: 1 [batch #33725, batch_size 1, seq length 2500]\tLoss: 3.655903\n",
      "33750it [1:04:27,  8.73it/s]Train epoch: 1 [batch #33750, batch_size 1, seq length 2500]\tLoss: 3.874041\n",
      "33775it [1:04:30,  8.76it/s]Train epoch: 1 [batch #33775, batch_size 1, seq length 2500]\tLoss: 3.738355\n",
      "33800it [1:04:33,  8.71it/s]Train epoch: 1 [batch #33800, batch_size 1, seq length 2500]\tLoss: 3.884501\n",
      "33825it [1:04:35,  8.77it/s]Train epoch: 1 [batch #33825, batch_size 1, seq length 2500]\tLoss: 4.147035\n",
      "33850it [1:04:38,  8.77it/s]Train epoch: 1 [batch #33850, batch_size 1, seq length 2500]\tLoss: 4.009895\n",
      "33875it [1:04:41,  8.70it/s]Train epoch: 1 [batch #33875, batch_size 1, seq length 2500]\tLoss: 4.032866\n",
      "33900it [1:04:44,  8.76it/s]Train epoch: 1 [batch #33900, batch_size 1, seq length 2500]\tLoss: 3.601832\n",
      "33925it [1:04:47,  8.73it/s]Train epoch: 1 [batch #33925, batch_size 1, seq length 2500]\tLoss: 4.062806\n",
      "33950it [1:04:50,  8.77it/s]Train epoch: 1 [batch #33950, batch_size 1, seq length 2500]\tLoss: 3.745498\n",
      "33975it [1:04:53,  8.76it/s]Train epoch: 1 [batch #33975, batch_size 1, seq length 2500]\tLoss: 3.721956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34000it [1:04:55,  8.70it/s]Train epoch: 1 [batch #34000, batch_size 1, seq length 2500]\tLoss: 4.166617\n",
      "34025it [1:04:58,  8.76it/s]Train epoch: 1 [batch #34025, batch_size 1, seq length 2500]\tLoss: 3.874213\n",
      "34050it [1:05:01,  8.69it/s]Train epoch: 1 [batch #34050, batch_size 1, seq length 2500]\tLoss: 4.274565\n",
      "34075it [1:05:04,  8.73it/s]Train epoch: 1 [batch #34075, batch_size 1, seq length 2500]\tLoss: 3.835767\n",
      "34100it [1:05:07,  8.74it/s]Train epoch: 1 [batch #34100, batch_size 1, seq length 2500]\tLoss: 3.871525\n",
      "34125it [1:05:10,  8.75it/s]Train epoch: 1 [batch #34125, batch_size 1, seq length 2500]\tLoss: 3.447203\n",
      "34150it [1:05:13,  8.76it/s]Train epoch: 1 [batch #34150, batch_size 1, seq length 2500]\tLoss: 4.122451\n",
      "34175it [1:05:15,  8.71it/s]Train epoch: 1 [batch #34175, batch_size 1, seq length 2500]\tLoss: 3.699572\n",
      "34200it [1:05:18,  8.74it/s]Train epoch: 1 [batch #34200, batch_size 1, seq length 2500]\tLoss: 3.873318\n",
      "34225it [1:05:21,  8.77it/s]Train epoch: 1 [batch #34225, batch_size 1, seq length 2500]\tLoss: 3.752405\n",
      "34250it [1:05:24,  8.68it/s]Train epoch: 1 [batch #34250, batch_size 1, seq length 2500]\tLoss: 3.953657\n",
      "34275it [1:05:27,  8.74it/s]Train epoch: 1 [batch #34275, batch_size 1, seq length 2500]\tLoss: 3.532378\n",
      "34300it [1:05:30,  8.72it/s]Train epoch: 1 [batch #34300, batch_size 1, seq length 2500]\tLoss: 3.932316\n",
      "34325it [1:05:33,  8.76it/s]Train epoch: 1 [batch #34325, batch_size 1, seq length 2500]\tLoss: 4.214113\n",
      "34350it [1:05:35,  8.76it/s]Train epoch: 1 [batch #34350, batch_size 1, seq length 2500]\tLoss: 4.206056\n",
      "34375it [1:05:38,  8.78it/s]Train epoch: 1 [batch #34375, batch_size 1, seq length 2500]\tLoss: 3.982885\n",
      "34400it [1:05:41,  8.75it/s]Train epoch: 1 [batch #34400, batch_size 1, seq length 2500]\tLoss: 4.191692\n",
      "34425it [1:05:44,  8.75it/s]Train epoch: 1 [batch #34425, batch_size 1, seq length 2500]\tLoss: 3.788050\n",
      "34450it [1:05:47,  8.78it/s]Train epoch: 1 [batch #34450, batch_size 1, seq length 2500]\tLoss: 3.511060\n",
      "34475it [1:05:50,  8.76it/s]Train epoch: 1 [batch #34475, batch_size 1, seq length 2500]\tLoss: 4.145185\n",
      "34500it [1:05:53,  8.76it/s]Train epoch: 1 [batch #34500, batch_size 1, seq length 2500]\tLoss: 3.771286\n",
      "34525it [1:05:55,  8.73it/s]Train epoch: 1 [batch #34525, batch_size 1, seq length 2500]\tLoss: 3.984470\n",
      "34550it [1:05:58,  8.73it/s]Train epoch: 1 [batch #34550, batch_size 1, seq length 2500]\tLoss: 3.934859\n",
      "34575it [1:06:01,  8.71it/s]Train epoch: 1 [batch #34575, batch_size 1, seq length 2500]\tLoss: 4.053390\n",
      "34600it [1:06:04,  8.75it/s]Train epoch: 1 [batch #34600, batch_size 1, seq length 2500]\tLoss: 3.685174\n",
      "34625it [1:06:07,  8.75it/s]Train epoch: 1 [batch #34625, batch_size 1, seq length 2500]\tLoss: 3.678027\n",
      "34650it [1:06:10,  8.72it/s]Train epoch: 1 [batch #34650, batch_size 1, seq length 2500]\tLoss: 3.660083\n",
      "34675it [1:06:13,  8.76it/s]Train epoch: 1 [batch #34675, batch_size 1, seq length 2500]\tLoss: 3.918879\n",
      "34700it [1:06:15,  8.77it/s]Train epoch: 1 [batch #34700, batch_size 1, seq length 2500]\tLoss: 4.047609\n",
      "34725it [1:06:18,  8.69it/s]Train epoch: 1 [batch #34725, batch_size 1, seq length 2500]\tLoss: 3.955251\n",
      "34750it [1:06:21,  8.75it/s]Train epoch: 1 [batch #34750, batch_size 1, seq length 2500]\tLoss: 3.872741\n",
      "34775it [1:06:24,  8.74it/s]Train epoch: 1 [batch #34775, batch_size 1, seq length 2500]\tLoss: 4.075041\n",
      "34800it [1:06:27,  8.77it/s]Train epoch: 1 [batch #34800, batch_size 1, seq length 2500]\tLoss: 4.028361\n",
      "34825it [1:06:30,  8.74it/s]Train epoch: 1 [batch #34825, batch_size 1, seq length 2500]\tLoss: 3.994359\n",
      "34850it [1:06:33,  8.72it/s]Train epoch: 1 [batch #34850, batch_size 1, seq length 2500]\tLoss: 3.661474\n",
      "34875it [1:06:35,  8.75it/s]Train epoch: 1 [batch #34875, batch_size 1, seq length 2500]\tLoss: 3.969458\n",
      "34900it [1:06:38,  8.73it/s]Train epoch: 1 [batch #34900, batch_size 1, seq length 2500]\tLoss: 4.018501\n",
      "34925it [1:06:41,  8.79it/s]Train epoch: 1 [batch #34925, batch_size 1, seq length 2500]\tLoss: 3.644889\n",
      "34950it [1:06:44,  8.76it/s]Train epoch: 1 [batch #34950, batch_size 1, seq length 2500]\tLoss: 4.025147\n",
      "34975it [1:06:47,  8.78it/s]Train epoch: 1 [batch #34975, batch_size 1, seq length 2500]\tLoss: 3.698274\n",
      "35000it [1:06:50,  8.74it/s]Train epoch: 1 [batch #35000, batch_size 1, seq length 2500]\tLoss: 4.021232\n",
      "35025it [1:06:53,  8.77it/s]Train epoch: 1 [batch #35025, batch_size 1, seq length 2500]\tLoss: 3.872242\n",
      "35050it [1:06:56,  8.75it/s]Train epoch: 1 [batch #35050, batch_size 1, seq length 2500]\tLoss: 3.892649\n",
      "35075it [1:06:58,  8.72it/s]Train epoch: 1 [batch #35075, batch_size 1, seq length 2500]\tLoss: 3.664224\n",
      "35100it [1:07:01,  8.77it/s]Train epoch: 1 [batch #35100, batch_size 1, seq length 2500]\tLoss: 3.858424\n",
      "35125it [1:07:04,  8.77it/s]Train epoch: 1 [batch #35125, batch_size 1, seq length 2500]\tLoss: 3.582968\n",
      "35150it [1:07:07,  8.70it/s]Train epoch: 1 [batch #35150, batch_size 1, seq length 2500]\tLoss: 3.646352\n",
      "35175it [1:07:10,  8.76it/s]Train epoch: 1 [batch #35175, batch_size 1, seq length 2500]\tLoss: 4.381821\n",
      "35200it [1:07:13,  8.78it/s]Train epoch: 1 [batch #35200, batch_size 1, seq length 2500]\tLoss: 3.860198\n",
      "35225it [1:07:16,  8.75it/s]Train epoch: 1 [batch #35225, batch_size 1, seq length 2500]\tLoss: 4.061171\n",
      "35250it [1:07:18,  8.75it/s]Train epoch: 1 [batch #35250, batch_size 1, seq length 2500]\tLoss: 3.589874\n",
      "35275it [1:07:21,  8.64it/s]Train epoch: 1 [batch #35275, batch_size 1, seq length 2500]\tLoss: 4.008228\n",
      "35300it [1:07:24,  8.77it/s]Train epoch: 1 [batch #35300, batch_size 1, seq length 2500]\tLoss: 3.834351\n",
      "35325it [1:07:27,  8.74it/s]Train epoch: 1 [batch #35325, batch_size 1, seq length 2500]\tLoss: 4.197514\n",
      "35350it [1:07:30,  8.70it/s]Train epoch: 1 [batch #35350, batch_size 1, seq length 2500]\tLoss: 4.104192\n",
      "35375it [1:07:33,  8.69it/s]Train epoch: 1 [batch #35375, batch_size 1, seq length 2500]\tLoss: 4.049327\n",
      "35400it [1:07:36,  8.74it/s]Train epoch: 1 [batch #35400, batch_size 1, seq length 2500]\tLoss: 3.878057\n",
      "35425it [1:07:38,  8.73it/s]Train epoch: 1 [batch #35425, batch_size 1, seq length 2500]\tLoss: 3.789388\n",
      "35450it [1:07:41,  8.75it/s]Train epoch: 1 [batch #35450, batch_size 1, seq length 2500]\tLoss: 3.949113\n",
      "35475it [1:07:44,  8.74it/s]Train epoch: 1 [batch #35475, batch_size 1, seq length 2500]\tLoss: 3.975820\n",
      "35500it [1:07:47,  8.72it/s]Train epoch: 1 [batch #35500, batch_size 1, seq length 2500]\tLoss: 3.688648\n",
      "35525it [1:07:50,  8.74it/s]Train epoch: 1 [batch #35525, batch_size 1, seq length 2500]\tLoss: 3.708111\n",
      "35550it [1:07:53,  8.73it/s]Train epoch: 1 [batch #35550, batch_size 1, seq length 2500]\tLoss: 3.931429\n",
      "35575it [1:07:56,  8.75it/s]Train epoch: 1 [batch #35575, batch_size 1, seq length 2500]\tLoss: 3.929179\n",
      "35600it [1:07:58,  8.71it/s]Train epoch: 1 [batch #35600, batch_size 1, seq length 2500]\tLoss: 4.129331\n",
      "35625it [1:08:01,  8.52it/s]Train epoch: 1 [batch #35625, batch_size 1, seq length 2500]\tLoss: 3.474461\n",
      "35650it [1:08:04,  8.72it/s]Train epoch: 1 [batch #35650, batch_size 1, seq length 2500]\tLoss: 4.065601\n",
      "35675it [1:08:07,  8.75it/s]Train epoch: 1 [batch #35675, batch_size 1, seq length 2500]\tLoss: 4.150907\n",
      "35700it [1:08:10,  8.75it/s]Train epoch: 1 [batch #35700, batch_size 1, seq length 2500]\tLoss: 4.149090\n",
      "35725it [1:08:13,  8.75it/s]Train epoch: 1 [batch #35725, batch_size 1, seq length 2500]\tLoss: 3.998804\n",
      "35750it [1:08:16,  8.77it/s]Train epoch: 1 [batch #35750, batch_size 1, seq length 2500]\tLoss: 3.690821\n",
      "35775it [1:08:19,  8.74it/s]Train epoch: 1 [batch #35775, batch_size 1, seq length 2500]\tLoss: 4.139523\n",
      "35800it [1:08:21,  8.73it/s]Train epoch: 1 [batch #35800, batch_size 1, seq length 2500]\tLoss: 4.059713\n",
      "35825it [1:08:24,  8.77it/s]Train epoch: 1 [batch #35825, batch_size 1, seq length 2500]\tLoss: 4.133251\n",
      "35850it [1:08:27,  8.73it/s]Train epoch: 1 [batch #35850, batch_size 1, seq length 2500]\tLoss: 4.061361\n",
      "35875it [1:08:30,  8.72it/s]Train epoch: 1 [batch #35875, batch_size 1, seq length 2500]\tLoss: 3.748286\n",
      "35900it [1:08:33,  8.76it/s]Train epoch: 1 [batch #35900, batch_size 1, seq length 2500]\tLoss: 3.999675\n",
      "35925it [1:08:36,  8.71it/s]Train epoch: 1 [batch #35925, batch_size 1, seq length 2500]\tLoss: 3.647221\n",
      "35950it [1:08:39,  8.72it/s]Train epoch: 1 [batch #35950, batch_size 1, seq length 2500]\tLoss: 4.104678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35975it [1:08:41,  8.73it/s]Train epoch: 1 [batch #35975, batch_size 1, seq length 2500]\tLoss: 4.104888\n",
      "36000it [1:08:44,  8.77it/s]Train epoch: 1 [batch #36000, batch_size 1, seq length 2500]\tLoss: 3.809476\n",
      "36025it [1:08:47,  8.73it/s]Train epoch: 1 [batch #36025, batch_size 1, seq length 2500]\tLoss: 3.953438\n",
      "36050it [1:08:50,  8.75it/s]Train epoch: 1 [batch #36050, batch_size 1, seq length 2500]\tLoss: 3.634803\n",
      "36075it [1:08:53,  8.75it/s]Train epoch: 1 [batch #36075, batch_size 1, seq length 2500]\tLoss: 4.086722\n",
      "36100it [1:08:56,  8.73it/s]Train epoch: 1 [batch #36100, batch_size 1, seq length 2500]\tLoss: 3.734090\n",
      "36125it [1:08:59,  8.77it/s]Train epoch: 1 [batch #36125, batch_size 1, seq length 2500]\tLoss: 4.134974\n",
      "36150it [1:09:01,  8.76it/s]Train epoch: 1 [batch #36150, batch_size 1, seq length 2500]\tLoss: 3.721964\n",
      "36175it [1:09:04,  8.66it/s]Train epoch: 1 [batch #36175, batch_size 1, seq length 2500]\tLoss: 3.766118\n",
      "36200it [1:09:07,  8.77it/s]Train epoch: 1 [batch #36200, batch_size 1, seq length 2500]\tLoss: 3.806199\n",
      "36225it [1:09:10,  8.77it/s]Train epoch: 1 [batch #36225, batch_size 1, seq length 2500]\tLoss: 4.047733\n",
      "36250it [1:09:13,  8.74it/s]Train epoch: 1 [batch #36250, batch_size 1, seq length 2500]\tLoss: 4.201083\n",
      "36275it [1:09:16,  8.75it/s]Train epoch: 1 [batch #36275, batch_size 1, seq length 2500]\tLoss: 4.101970\n",
      "36300it [1:09:19,  8.73it/s]Train epoch: 1 [batch #36300, batch_size 1, seq length 2500]\tLoss: 3.776979\n",
      "36325it [1:09:21,  8.74it/s]Train epoch: 1 [batch #36325, batch_size 1, seq length 2500]\tLoss: 3.934590\n",
      "36350it [1:09:24,  8.75it/s]Train epoch: 1 [batch #36350, batch_size 1, seq length 2500]\tLoss: 3.954336\n",
      "36375it [1:09:27,  8.71it/s]Train epoch: 1 [batch #36375, batch_size 1, seq length 2500]\tLoss: 3.749367\n",
      "36400it [1:09:30,  8.77it/s]Train epoch: 1 [batch #36400, batch_size 1, seq length 2500]\tLoss: 3.951365\n",
      "36425it [1:09:33,  8.71it/s]Train epoch: 1 [batch #36425, batch_size 1, seq length 2500]\tLoss: 3.962086\n",
      "36450it [1:09:36,  8.77it/s]Train epoch: 1 [batch #36450, batch_size 1, seq length 2500]\tLoss: 4.132313\n",
      "36475it [1:09:39,  8.75it/s]Train epoch: 1 [batch #36475, batch_size 1, seq length 2500]\tLoss: 3.809737\n",
      "36500it [1:09:42,  8.72it/s]Train epoch: 1 [batch #36500, batch_size 1, seq length 2500]\tLoss: 4.034877\n",
      "36525it [1:09:44,  8.77it/s]Train epoch: 1 [batch #36525, batch_size 1, seq length 2500]\tLoss: 3.977914\n",
      "36550it [1:09:47,  8.74it/s]Train epoch: 1 [batch #36550, batch_size 1, seq length 2500]\tLoss: 3.737898\n",
      "36575it [1:09:50,  8.76it/s]Train epoch: 1 [batch #36575, batch_size 1, seq length 2500]\tLoss: 3.819753\n",
      "36600it [1:09:53,  8.68it/s]Train epoch: 1 [batch #36600, batch_size 1, seq length 2500]\tLoss: 4.413982\n",
      "36625it [1:09:56,  8.69it/s]Train epoch: 1 [batch #36625, batch_size 1, seq length 2500]\tLoss: 3.774915\n",
      "36650it [1:09:59,  8.71it/s]Train epoch: 1 [batch #36650, batch_size 1, seq length 2500]\tLoss: 3.884984\n",
      "36675it [1:10:02,  8.73it/s]Train epoch: 1 [batch #36675, batch_size 1, seq length 2500]\tLoss: 3.787361\n",
      "36700it [1:10:04,  8.59it/s]Train epoch: 1 [batch #36700, batch_size 1, seq length 2500]\tLoss: 3.771659\n",
      "36725it [1:10:07,  8.67it/s]Train epoch: 1 [batch #36725, batch_size 1, seq length 2500]\tLoss: 4.001610\n",
      "36750it [1:10:10,  8.76it/s]Train epoch: 1 [batch #36750, batch_size 1, seq length 2500]\tLoss: 3.983249\n",
      "36775it [1:10:13,  8.75it/s]Train epoch: 1 [batch #36775, batch_size 1, seq length 2500]\tLoss: 3.817314\n",
      "36800it [1:10:16,  8.72it/s]Train epoch: 1 [batch #36800, batch_size 1, seq length 2500]\tLoss: 3.921173\n",
      "36825it [1:10:19,  8.66it/s]Train epoch: 1 [batch #36825, batch_size 1, seq length 2500]\tLoss: 3.935510\n",
      "36850it [1:10:22,  8.76it/s]Train epoch: 1 [batch #36850, batch_size 1, seq length 2500]\tLoss: 3.970212\n",
      "36875it [1:10:24,  8.75it/s]Train epoch: 1 [batch #36875, batch_size 1, seq length 2500]\tLoss: 3.971788\n",
      "36900it [1:10:27,  8.72it/s]Train epoch: 1 [batch #36900, batch_size 1, seq length 2500]\tLoss: 3.973003\n",
      "36925it [1:10:30,  8.57it/s]Train epoch: 1 [batch #36925, batch_size 1, seq length 2500]\tLoss: 3.976933\n",
      "36950it [1:10:33,  8.75it/s]Train epoch: 1 [batch #36950, batch_size 1, seq length 2500]\tLoss: 3.915799\n",
      "36975it [1:10:36,  8.72it/s]Train epoch: 1 [batch #36975, batch_size 1, seq length 2500]\tLoss: 3.897690\n",
      "37000it [1:10:39,  8.75it/s]Train epoch: 1 [batch #37000, batch_size 1, seq length 2500]\tLoss: 3.971743\n",
      "37025it [1:10:42,  8.74it/s]Train epoch: 1 [batch #37025, batch_size 1, seq length 2500]\tLoss: 4.032598\n",
      "37050it [1:10:45,  8.74it/s]Train epoch: 1 [batch #37050, batch_size 1, seq length 2500]\tLoss: 3.736940\n",
      "37075it [1:10:47,  8.69it/s]Train epoch: 1 [batch #37075, batch_size 1, seq length 2500]\tLoss: 4.062822\n",
      "37100it [1:10:50,  8.72it/s]Train epoch: 1 [batch #37100, batch_size 1, seq length 2500]\tLoss: 4.199833\n",
      "37125it [1:10:53,  8.75it/s]Train epoch: 1 [batch #37125, batch_size 1, seq length 2500]\tLoss: 3.860610\n",
      "37150it [1:10:56,  8.76it/s]Train epoch: 1 [batch #37150, batch_size 1, seq length 2500]\tLoss: 4.144931\n",
      "37175it [1:10:59,  8.76it/s]Train epoch: 1 [batch #37175, batch_size 1, seq length 2500]\tLoss: 3.697563\n",
      "37200it [1:11:02,  8.75it/s]Train epoch: 1 [batch #37200, batch_size 1, seq length 2500]\tLoss: 4.082832\n",
      "37225it [1:11:05,  8.75it/s]Train epoch: 1 [batch #37225, batch_size 1, seq length 2500]\tLoss: 3.480371\n",
      "37250it [1:11:07,  8.72it/s]Train epoch: 1 [batch #37250, batch_size 1, seq length 2500]\tLoss: 3.982392\n",
      "37275it [1:11:10,  8.76it/s]Train epoch: 1 [batch #37275, batch_size 1, seq length 2500]\tLoss: 3.954330\n",
      "37300it [1:11:13,  8.69it/s]Train epoch: 1 [batch #37300, batch_size 1, seq length 2500]\tLoss: 3.937548\n",
      "37325it [1:11:16,  8.71it/s]Train epoch: 1 [batch #37325, batch_size 1, seq length 2500]\tLoss: 3.814452\n",
      "37350it [1:11:19,  8.60it/s]Train epoch: 1 [batch #37350, batch_size 1, seq length 2500]\tLoss: 3.780465\n",
      "37375it [1:11:22,  8.57it/s]Train epoch: 1 [batch #37375, batch_size 1, seq length 2500]\tLoss: 3.449561\n",
      "37400it [1:11:25,  8.71it/s]Train epoch: 1 [batch #37400, batch_size 1, seq length 2500]\tLoss: 4.233569\n",
      "37425it [1:11:28,  8.72it/s]Train epoch: 1 [batch #37425, batch_size 1, seq length 2500]\tLoss: 4.067623\n",
      "37450it [1:11:30,  8.58it/s]Train epoch: 1 [batch #37450, batch_size 1, seq length 2500]\tLoss: 4.228285\n",
      "37475it [1:11:33,  8.73it/s]Train epoch: 1 [batch #37475, batch_size 1, seq length 2500]\tLoss: 3.607108\n",
      "37500it [1:11:36,  8.71it/s]Train epoch: 1 [batch #37500, batch_size 1, seq length 2500]\tLoss: 3.679876\n",
      "37525it [1:11:39,  8.76it/s]Train epoch: 1 [batch #37525, batch_size 1, seq length 2500]\tLoss: 4.155780\n",
      "37550it [1:11:42,  8.51it/s]Train epoch: 1 [batch #37550, batch_size 1, seq length 2500]\tLoss: 3.895314\n",
      "37575it [1:11:45,  8.75it/s]Train epoch: 1 [batch #37575, batch_size 1, seq length 2500]\tLoss: 4.107008\n",
      "37600it [1:11:48,  8.73it/s]Train epoch: 1 [batch #37600, batch_size 1, seq length 2500]\tLoss: 3.875686\n",
      "37625it [1:11:51,  8.77it/s]Train epoch: 1 [batch #37625, batch_size 1, seq length 2500]\tLoss: 3.816510\n",
      "37650it [1:11:53,  8.69it/s]Train epoch: 1 [batch #37650, batch_size 1, seq length 2500]\tLoss: 3.944873\n",
      "37675it [1:11:56,  8.74it/s]Train epoch: 1 [batch #37675, batch_size 1, seq length 2500]\tLoss: 3.802333\n",
      "37700it [1:11:59,  8.73it/s]Train epoch: 1 [batch #37700, batch_size 1, seq length 2500]\tLoss: 3.484742\n",
      "37725it [1:12:02,  8.75it/s]Train epoch: 1 [batch #37725, batch_size 1, seq length 2500]\tLoss: 4.013001\n",
      "37750it [1:12:05,  8.53it/s]Train epoch: 1 [batch #37750, batch_size 1, seq length 2500]\tLoss: 3.603688\n",
      "37775it [1:12:08,  8.75it/s]Train epoch: 1 [batch #37775, batch_size 1, seq length 2500]\tLoss: 3.549201\n",
      "37800it [1:12:11,  8.73it/s]Train epoch: 1 [batch #37800, batch_size 1, seq length 2500]\tLoss: 4.058422\n",
      "37825it [1:12:13,  8.74it/s]Train epoch: 1 [batch #37825, batch_size 1, seq length 2500]\tLoss: 4.002636\n",
      "37850it [1:12:16,  8.75it/s]Train epoch: 1 [batch #37850, batch_size 1, seq length 2500]\tLoss: 3.615302\n",
      "37875it [1:12:19,  8.63it/s]Train epoch: 1 [batch #37875, batch_size 1, seq length 2500]\tLoss: 3.921765\n",
      "37900it [1:12:22,  8.70it/s]Train epoch: 1 [batch #37900, batch_size 1, seq length 2500]\tLoss: 3.855042\n",
      "37925it [1:12:25,  8.72it/s]Train epoch: 1 [batch #37925, batch_size 1, seq length 2500]\tLoss: 3.810827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37950it [1:12:28,  8.71it/s]Train epoch: 1 [batch #37950, batch_size 1, seq length 2500]\tLoss: 3.958133\n",
      "37975it [1:12:31,  8.78it/s]Train epoch: 1 [batch #37975, batch_size 1, seq length 2500]\tLoss: 4.043414\n",
      "38000it [1:12:34,  8.71it/s]Train epoch: 1 [batch #38000, batch_size 1, seq length 2500]\tLoss: 3.950381\n",
      "38025it [1:12:36,  8.76it/s]Train epoch: 1 [batch #38025, batch_size 1, seq length 2500]\tLoss: 4.305240\n",
      "38050it [1:12:39,  8.78it/s]Train epoch: 1 [batch #38050, batch_size 1, seq length 2500]\tLoss: 3.909521\n",
      "38075it [1:12:42,  8.72it/s]Train epoch: 1 [batch #38075, batch_size 1, seq length 2500]\tLoss: 4.167792\n",
      "38100it [1:12:45,  8.62it/s]Train epoch: 1 [batch #38100, batch_size 1, seq length 2500]\tLoss: 3.801891\n",
      "38125it [1:12:48,  8.72it/s]Train epoch: 1 [batch #38125, batch_size 1, seq length 2500]\tLoss: 3.546558\n",
      "38150it [1:12:51,  8.76it/s]Train epoch: 1 [batch #38150, batch_size 1, seq length 2500]\tLoss: 3.860259\n",
      "38175it [1:12:54,  8.73it/s]Train epoch: 1 [batch #38175, batch_size 1, seq length 2500]\tLoss: 4.014294\n",
      "38200it [1:12:56,  8.69it/s]Train epoch: 1 [batch #38200, batch_size 1, seq length 2500]\tLoss: 3.837497\n",
      "38225it [1:12:59,  8.73it/s]Train epoch: 1 [batch #38225, batch_size 1, seq length 2500]\tLoss: 3.779606\n",
      "38250it [1:13:02,  8.75it/s]Train epoch: 1 [batch #38250, batch_size 1, seq length 2500]\tLoss: 4.151337\n",
      "38275it [1:13:05,  8.75it/s]Train epoch: 1 [batch #38275, batch_size 1, seq length 2500]\tLoss: 4.036651\n",
      "38300it [1:13:08,  8.73it/s]Train epoch: 1 [batch #38300, batch_size 1, seq length 2500]\tLoss: 4.172276\n",
      "38325it [1:13:11,  8.76it/s]Train epoch: 1 [batch #38325, batch_size 1, seq length 2500]\tLoss: 3.778310\n",
      "38350it [1:13:14,  8.71it/s]Train epoch: 1 [batch #38350, batch_size 1, seq length 2500]\tLoss: 3.779147\n",
      "38375it [1:13:17,  8.72it/s]Train epoch: 1 [batch #38375, batch_size 1, seq length 2500]\tLoss: 3.822218\n",
      "38400it [1:13:19,  8.71it/s]Train epoch: 1 [batch #38400, batch_size 1, seq length 2500]\tLoss: 3.780237\n",
      "38425it [1:13:22,  8.72it/s]Train epoch: 1 [batch #38425, batch_size 1, seq length 2500]\tLoss: 3.661412\n",
      "38450it [1:13:25,  8.69it/s]Train epoch: 1 [batch #38450, batch_size 1, seq length 2500]\tLoss: 4.061141\n",
      "38475it [1:13:28,  8.70it/s]Train epoch: 1 [batch #38475, batch_size 1, seq length 2500]\tLoss: 4.051295\n",
      "38500it [1:13:31,  8.63it/s]Train epoch: 1 [batch #38500, batch_size 1, seq length 2500]\tLoss: 4.015157\n",
      "38525it [1:13:34,  8.73it/s]Train epoch: 1 [batch #38525, batch_size 1, seq length 2500]\tLoss: 3.927184\n",
      "38550it [1:13:37,  8.54it/s]Train epoch: 1 [batch #38550, batch_size 1, seq length 2500]\tLoss: 3.842839\n",
      "38575it [1:13:39,  8.71it/s]Train epoch: 1 [batch #38575, batch_size 1, seq length 2500]\tLoss: 3.614594\n",
      "38600it [1:13:42,  8.70it/s]Train epoch: 1 [batch #38600, batch_size 1, seq length 2500]\tLoss: 3.985490\n",
      "38625it [1:13:45,  8.72it/s]Train epoch: 1 [batch #38625, batch_size 1, seq length 2500]\tLoss: 4.118522\n",
      "38650it [1:13:48,  8.67it/s]Train epoch: 1 [batch #38650, batch_size 1, seq length 2500]\tLoss: 4.202897\n",
      "38675it [1:13:51,  8.69it/s]Train epoch: 1 [batch #38675, batch_size 1, seq length 2500]\tLoss: 3.839108\n",
      "38700it [1:13:54,  8.72it/s]Train epoch: 1 [batch #38700, batch_size 1, seq length 2500]\tLoss: 4.007037\n",
      "38725it [1:13:57,  8.77it/s]Train epoch: 1 [batch #38725, batch_size 1, seq length 2500]\tLoss: 4.221355\n",
      "38750it [1:14:00,  8.76it/s]Train epoch: 1 [batch #38750, batch_size 1, seq length 2500]\tLoss: 3.781347\n",
      "38775it [1:14:02,  8.74it/s]Train epoch: 1 [batch #38775, batch_size 1, seq length 2500]\tLoss: 3.832009\n",
      "38800it [1:14:05,  8.76it/s]Train epoch: 1 [batch #38800, batch_size 1, seq length 2500]\tLoss: 3.777726\n",
      "38825it [1:14:08,  8.69it/s]Train epoch: 1 [batch #38825, batch_size 1, seq length 2500]\tLoss: 3.735274\n",
      "38850it [1:14:11,  8.72it/s]Train epoch: 1 [batch #38850, batch_size 1, seq length 2500]\tLoss: 3.968078\n",
      "38875it [1:14:14,  8.62it/s]Train epoch: 1 [batch #38875, batch_size 1, seq length 2500]\tLoss: 4.018213\n",
      "38900it [1:14:17,  8.74it/s]Train epoch: 1 [batch #38900, batch_size 1, seq length 2500]\tLoss: 4.037417\n",
      "38925it [1:14:20,  8.73it/s]Train epoch: 1 [batch #38925, batch_size 1, seq length 2500]\tLoss: 3.891926\n",
      "38950it [1:14:23,  8.77it/s]Train epoch: 1 [batch #38950, batch_size 1, seq length 2500]\tLoss: 3.774675\n",
      "38975it [1:14:25,  8.74it/s]Train epoch: 1 [batch #38975, batch_size 1, seq length 2500]\tLoss: 3.953989\n",
      "39000it [1:14:28,  8.75it/s]Train epoch: 1 [batch #39000, batch_size 1, seq length 2500]\tLoss: 3.724739\n",
      "39025it [1:14:31,  8.72it/s]Train epoch: 1 [batch #39025, batch_size 1, seq length 2500]\tLoss: 4.058173\n",
      "39050it [1:14:34,  8.68it/s]Train epoch: 1 [batch #39050, batch_size 1, seq length 2500]\tLoss: 4.080493\n",
      "39075it [1:14:37,  8.73it/s]Train epoch: 1 [batch #39075, batch_size 1, seq length 2500]\tLoss: 3.727498\n",
      "39100it [1:14:40,  8.72it/s]Train epoch: 1 [batch #39100, batch_size 1, seq length 2500]\tLoss: 3.995489\n",
      "39125it [1:14:43,  8.75it/s]Train epoch: 1 [batch #39125, batch_size 1, seq length 2500]\tLoss: 3.775397\n",
      "39150it [1:14:45,  8.70it/s]Train epoch: 1 [batch #39150, batch_size 1, seq length 2500]\tLoss: 3.960594\n",
      "39175it [1:14:48,  8.75it/s]Train epoch: 1 [batch #39175, batch_size 1, seq length 2500]\tLoss: 4.226118\n",
      "39200it [1:14:51,  8.75it/s]Train epoch: 1 [batch #39200, batch_size 1, seq length 2500]\tLoss: 3.345763\n",
      "39225it [1:14:54,  8.74it/s]Train epoch: 1 [batch #39225, batch_size 1, seq length 2500]\tLoss: 3.499613\n",
      "39250it [1:14:57,  8.63it/s]Train epoch: 1 [batch #39250, batch_size 1, seq length 2500]\tLoss: 4.070832\n",
      "39275it [1:15:00,  8.64it/s]Train epoch: 1 [batch #39275, batch_size 1, seq length 2500]\tLoss: 3.647980\n",
      "39300it [1:15:03,  8.71it/s]Train epoch: 1 [batch #39300, batch_size 1, seq length 2500]\tLoss: 3.861472\n",
      "39325it [1:15:06,  8.75it/s]Train epoch: 1 [batch #39325, batch_size 1, seq length 2500]\tLoss: 3.584444\n",
      "39350it [1:15:08,  8.75it/s]Train epoch: 1 [batch #39350, batch_size 1, seq length 2500]\tLoss: 4.077751\n",
      "39375it [1:15:11,  8.70it/s]Train epoch: 1 [batch #39375, batch_size 1, seq length 2500]\tLoss: 4.181005\n",
      "39400it [1:15:14,  8.74it/s]Train epoch: 1 [batch #39400, batch_size 1, seq length 2500]\tLoss: 3.816688\n",
      "39425it [1:15:17,  8.70it/s]Train epoch: 1 [batch #39425, batch_size 1, seq length 2500]\tLoss: 4.047033\n",
      "39450it [1:15:20,  8.76it/s]Train epoch: 1 [batch #39450, batch_size 1, seq length 2500]\tLoss: 3.844753\n",
      "39475it [1:15:23,  8.74it/s]Train epoch: 1 [batch #39475, batch_size 1, seq length 2500]\tLoss: 3.713711\n",
      "39500it [1:15:26,  8.67it/s]Train epoch: 1 [batch #39500, batch_size 1, seq length 2500]\tLoss: 3.780133\n",
      "39525it [1:15:29,  8.73it/s]Train epoch: 1 [batch #39525, batch_size 1, seq length 2500]\tLoss: 3.713803\n",
      "39550it [1:15:31,  8.71it/s]Train epoch: 1 [batch #39550, batch_size 1, seq length 2500]\tLoss: 3.637467\n",
      "39575it [1:15:34,  8.75it/s]Train epoch: 1 [batch #39575, batch_size 1, seq length 2500]\tLoss: 3.648124\n",
      "39600it [1:15:37,  8.73it/s]Train epoch: 1 [batch #39600, batch_size 1, seq length 2500]\tLoss: 4.109102\n",
      "39625it [1:15:40,  8.76it/s]Train epoch: 1 [batch #39625, batch_size 1, seq length 2500]\tLoss: 4.043441\n",
      "39650it [1:15:43,  8.74it/s]Train epoch: 1 [batch #39650, batch_size 1, seq length 2500]\tLoss: 4.111656\n",
      "39675it [1:15:46,  8.74it/s]Train epoch: 1 [batch #39675, batch_size 1, seq length 2500]\tLoss: 3.776489\n",
      "39700it [1:15:49,  8.77it/s]Train epoch: 1 [batch #39700, batch_size 1, seq length 2500]\tLoss: 4.204377\n",
      "39725it [1:15:51,  8.75it/s]Train epoch: 1 [batch #39725, batch_size 1, seq length 2500]\tLoss: 3.494689\n",
      "39750it [1:15:54,  8.70it/s]Train epoch: 1 [batch #39750, batch_size 1, seq length 2500]\tLoss: 3.680374\n",
      "39775it [1:15:57,  8.74it/s]Train epoch: 1 [batch #39775, batch_size 1, seq length 2500]\tLoss: 3.888163\n",
      "39800it [1:16:00,  8.72it/s]Train epoch: 1 [batch #39800, batch_size 1, seq length 2500]\tLoss: 3.642851\n",
      "39825it [1:16:03,  8.75it/s]Train epoch: 1 [batch #39825, batch_size 1, seq length 2500]\tLoss: 3.699426\n",
      "39850it [1:16:06,  8.74it/s]Train epoch: 1 [batch #39850, batch_size 1, seq length 2500]\tLoss: 3.773851\n",
      "39875it [1:16:09,  8.72it/s]Train epoch: 1 [batch #39875, batch_size 1, seq length 2500]\tLoss: 3.879218\n",
      "39900it [1:16:12,  8.75it/s]Train epoch: 1 [batch #39900, batch_size 1, seq length 2500]\tLoss: 3.813813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39925it [1:16:14,  8.65it/s]Train epoch: 1 [batch #39925, batch_size 1, seq length 2500]\tLoss: 3.782115\n",
      "39950it [1:16:17,  8.72it/s]Train epoch: 1 [batch #39950, batch_size 1, seq length 2500]\tLoss: 3.778755\n",
      "39975it [1:16:20,  8.74it/s]Train epoch: 1 [batch #39975, batch_size 1, seq length 2500]\tLoss: 3.787757\n",
      "40000it [1:16:23,  8.73it/s]Train epoch: 1 [batch #40000, batch_size 1, seq length 2500]\tLoss: 3.731463\n",
      "40025it [1:16:26,  8.71it/s]Train epoch: 1 [batch #40025, batch_size 1, seq length 2500]\tLoss: 3.817517\n",
      "40050it [1:16:29,  8.73it/s]Train epoch: 1 [batch #40050, batch_size 1, seq length 2500]\tLoss: 3.909291\n",
      "40075it [1:16:32,  8.76it/s]Train epoch: 1 [batch #40075, batch_size 1, seq length 2500]\tLoss: 3.993175\n",
      "40100it [1:16:34,  8.74it/s]Train epoch: 1 [batch #40100, batch_size 1, seq length 2500]\tLoss: 3.154105\n",
      "40125it [1:16:37,  8.67it/s]Train epoch: 1 [batch #40125, batch_size 1, seq length 2500]\tLoss: 3.726166\n",
      "40150it [1:16:40,  8.68it/s]Train epoch: 1 [batch #40150, batch_size 1, seq length 2500]\tLoss: 4.106155\n",
      "40175it [1:16:43,  8.72it/s]Train epoch: 1 [batch #40175, batch_size 1, seq length 2500]\tLoss: 3.733791\n",
      "40200it [1:16:46,  8.75it/s]Train epoch: 1 [batch #40200, batch_size 1, seq length 2500]\tLoss: 3.841988\n",
      "40225it [1:16:49,  8.69it/s]Train epoch: 1 [batch #40225, batch_size 1, seq length 2500]\tLoss: 3.928337\n",
      "40250it [1:16:52,  8.75it/s]Train epoch: 1 [batch #40250, batch_size 1, seq length 2500]\tLoss: 3.748484\n",
      "40275it [1:16:55,  8.75it/s]Train epoch: 1 [batch #40275, batch_size 1, seq length 2500]\tLoss: 3.913621\n",
      "40300it [1:16:57,  8.71it/s]Train epoch: 1 [batch #40300, batch_size 1, seq length 2500]\tLoss: 4.064729\n",
      "40325it [1:17:00,  8.70it/s]Train epoch: 1 [batch #40325, batch_size 1, seq length 2500]\tLoss: 4.012409\n",
      "40350it [1:17:03,  8.75it/s]Train epoch: 1 [batch #40350, batch_size 1, seq length 2500]\tLoss: 3.888570\n",
      "40375it [1:17:06,  8.70it/s]Train epoch: 1 [batch #40375, batch_size 1, seq length 2500]\tLoss: 4.104288\n",
      "40400it [1:17:09,  8.73it/s]Train epoch: 1 [batch #40400, batch_size 1, seq length 2500]\tLoss: 3.222068\n",
      "40425it [1:17:12,  8.66it/s]Train epoch: 1 [batch #40425, batch_size 1, seq length 2500]\tLoss: 3.625601\n",
      "40450it [1:17:15,  8.68it/s]Train epoch: 1 [batch #40450, batch_size 1, seq length 2500]\tLoss: 3.887720\n",
      "40475it [1:17:18,  8.68it/s]Train epoch: 1 [batch #40475, batch_size 1, seq length 2500]\tLoss: 3.946426\n",
      "40500it [1:17:20,  8.74it/s]Train epoch: 1 [batch #40500, batch_size 1, seq length 2500]\tLoss: 4.033739\n",
      "40525it [1:17:23,  8.72it/s]Train epoch: 1 [batch #40525, batch_size 1, seq length 2500]\tLoss: 4.016093\n",
      "40550it [1:17:26,  8.74it/s]Train epoch: 1 [batch #40550, batch_size 1, seq length 2500]\tLoss: 3.759536\n",
      "40575it [1:17:29,  8.70it/s]Train epoch: 1 [batch #40575, batch_size 1, seq length 2500]\tLoss: 3.913927\n",
      "40600it [1:17:32,  8.74it/s]Train epoch: 1 [batch #40600, batch_size 1, seq length 2500]\tLoss: 3.540673\n",
      "40625it [1:17:35,  8.69it/s]Train epoch: 1 [batch #40625, batch_size 1, seq length 2500]\tLoss: 4.163363\n",
      "40650it [1:17:38,  8.72it/s]Train epoch: 1 [batch #40650, batch_size 1, seq length 2500]\tLoss: 3.768242\n",
      "40675it [1:17:41,  8.74it/s]Train epoch: 1 [batch #40675, batch_size 1, seq length 2500]\tLoss: 3.907288\n",
      "40700it [1:17:43,  8.58it/s]Train epoch: 1 [batch #40700, batch_size 1, seq length 2500]\tLoss: 3.391502\n",
      "40725it [1:17:46,  8.63it/s]Train epoch: 1 [batch #40725, batch_size 1, seq length 2500]\tLoss: 3.898115\n",
      "40750it [1:17:49,  8.76it/s]Train epoch: 1 [batch #40750, batch_size 1, seq length 2500]\tLoss: 4.014708\n",
      "40775it [1:17:52,  8.56it/s]Train epoch: 1 [batch #40775, batch_size 1, seq length 2500]\tLoss: 3.674116\n",
      "40800it [1:17:55,  8.62it/s]Train epoch: 1 [batch #40800, batch_size 1, seq length 2500]\tLoss: 4.079967\n",
      "40825it [1:17:58,  8.72it/s]Train epoch: 1 [batch #40825, batch_size 1, seq length 2500]\tLoss: 3.451782\n",
      "40850it [1:18:01,  8.67it/s]Train epoch: 1 [batch #40850, batch_size 1, seq length 2500]\tLoss: 3.703185\n",
      "40875it [1:18:04,  8.74it/s]Train epoch: 1 [batch #40875, batch_size 1, seq length 2500]\tLoss: 3.974066\n",
      "40900it [1:18:06,  8.72it/s]Train epoch: 1 [batch #40900, batch_size 1, seq length 2500]\tLoss: 4.030319\n",
      "40925it [1:18:09,  8.69it/s]Train epoch: 1 [batch #40925, batch_size 1, seq length 2500]\tLoss: 4.049884\n",
      "40950it [1:18:12,  8.61it/s]Train epoch: 1 [batch #40950, batch_size 1, seq length 2500]\tLoss: 3.591791\n",
      "40975it [1:18:15,  8.68it/s]Train epoch: 1 [batch #40975, batch_size 1, seq length 2500]\tLoss: 3.829015\n",
      "41000it [1:18:18,  8.71it/s]Train epoch: 1 [batch #41000, batch_size 1, seq length 2500]\tLoss: 3.680895\n",
      "41025it [1:18:21,  8.76it/s]Train epoch: 1 [batch #41025, batch_size 1, seq length 2500]\tLoss: 3.900005\n",
      "41050it [1:18:24,  8.73it/s]Train epoch: 1 [batch #41050, batch_size 1, seq length 2500]\tLoss: 4.077048\n",
      "41075it [1:18:27,  8.74it/s]Train epoch: 1 [batch #41075, batch_size 1, seq length 2500]\tLoss: 4.182596\n",
      "41100it [1:18:29,  8.72it/s]Train epoch: 1 [batch #41100, batch_size 1, seq length 2500]\tLoss: 3.705726\n",
      "41125it [1:18:32,  8.73it/s]Train epoch: 1 [batch #41125, batch_size 1, seq length 2500]\tLoss: 3.989179\n",
      "41150it [1:18:35,  8.62it/s]Train epoch: 1 [batch #41150, batch_size 1, seq length 2500]\tLoss: 3.424143\n",
      "41175it [1:18:38,  8.60it/s]Train epoch: 1 [batch #41175, batch_size 1, seq length 2500]\tLoss: 3.943348\n",
      "41200it [1:18:41,  8.74it/s]Train epoch: 1 [batch #41200, batch_size 1, seq length 2500]\tLoss: 3.764801\n",
      "41225it [1:18:44,  8.45it/s]Train epoch: 1 [batch #41225, batch_size 1, seq length 2500]\tLoss: 3.815236\n",
      "41250it [1:18:47,  8.75it/s]Train epoch: 1 [batch #41250, batch_size 1, seq length 2500]\tLoss: 3.995024\n",
      "41275it [1:18:50,  8.76it/s]Train epoch: 1 [batch #41275, batch_size 1, seq length 2500]\tLoss: 3.984766\n",
      "41300it [1:18:52,  8.74it/s]Train epoch: 1 [batch #41300, batch_size 1, seq length 2500]\tLoss: 3.820617\n",
      "41325it [1:18:55,  8.73it/s]Train epoch: 1 [batch #41325, batch_size 1, seq length 2500]\tLoss: 4.199806\n",
      "41350it [1:18:58,  8.73it/s]Train epoch: 1 [batch #41350, batch_size 1, seq length 2500]\tLoss: 3.809114\n",
      "41375it [1:19:01,  8.75it/s]Train epoch: 1 [batch #41375, batch_size 1, seq length 2500]\tLoss: 3.838591\n",
      "41400it [1:19:04,  8.68it/s]Train epoch: 1 [batch #41400, batch_size 1, seq length 2500]\tLoss: 4.099800\n",
      "41425it [1:19:07,  8.76it/s]Train epoch: 1 [batch #41425, batch_size 1, seq length 2500]\tLoss: 3.846168\n",
      "41450it [1:19:10,  8.67it/s]Train epoch: 1 [batch #41450, batch_size 1, seq length 2500]\tLoss: 3.923419\n",
      "41475it [1:19:13,  8.73it/s]Train epoch: 1 [batch #41475, batch_size 1, seq length 2500]\tLoss: 3.758086\n",
      "41500it [1:19:15,  8.77it/s]Train epoch: 1 [batch #41500, batch_size 1, seq length 2500]\tLoss: 3.818607\n",
      "41525it [1:19:18,  8.73it/s]Train epoch: 1 [batch #41525, batch_size 1, seq length 2500]\tLoss: 4.033357\n",
      "41550it [1:19:21,  8.78it/s]Train epoch: 1 [batch #41550, batch_size 1, seq length 2500]\tLoss: 3.941849\n",
      "41575it [1:19:24,  8.73it/s]Train epoch: 1 [batch #41575, batch_size 1, seq length 2500]\tLoss: 3.825292\n",
      "41600it [1:19:27,  8.76it/s]Train epoch: 1 [batch #41600, batch_size 1, seq length 2500]\tLoss: 4.022095\n",
      "41625it [1:19:30,  8.76it/s]Train epoch: 1 [batch #41625, batch_size 1, seq length 2500]\tLoss: 3.250220\n",
      "41650it [1:19:33,  8.63it/s]Train epoch: 1 [batch #41650, batch_size 1, seq length 2500]\tLoss: 3.721051\n",
      "41675it [1:19:35,  8.74it/s]Train epoch: 1 [batch #41675, batch_size 1, seq length 2500]\tLoss: 3.876870\n",
      "41700it [1:19:38,  8.50it/s]Train epoch: 1 [batch #41700, batch_size 1, seq length 2500]\tLoss: 3.736333\n",
      "41725it [1:19:41,  8.69it/s]Train epoch: 1 [batch #41725, batch_size 1, seq length 2500]\tLoss: 3.772936\n",
      "41750it [1:19:44,  8.74it/s]Train epoch: 1 [batch #41750, batch_size 1, seq length 2500]\tLoss: 3.946398\n",
      "41775it [1:19:47,  8.73it/s]Train epoch: 1 [batch #41775, batch_size 1, seq length 2500]\tLoss: 3.778977\n",
      "41800it [1:19:50,  8.70it/s]Train epoch: 1 [batch #41800, batch_size 1, seq length 2500]\tLoss: 4.012503\n",
      "41825it [1:19:53,  8.70it/s]Train epoch: 1 [batch #41825, batch_size 1, seq length 2500]\tLoss: 3.978982\n",
      "41850it [1:19:56,  8.74it/s]Train epoch: 1 [batch #41850, batch_size 1, seq length 2500]\tLoss: 3.770919\n",
      "41875it [1:19:58,  8.74it/s]Train epoch: 1 [batch #41875, batch_size 1, seq length 2500]\tLoss: 3.593589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41900it [1:20:01,  8.74it/s]Train epoch: 1 [batch #41900, batch_size 1, seq length 2500]\tLoss: 3.850043\n",
      "41925it [1:20:04,  8.75it/s]Train epoch: 1 [batch #41925, batch_size 1, seq length 2500]\tLoss: 3.817957\n",
      "41950it [1:20:07,  8.72it/s]Train epoch: 1 [batch #41950, batch_size 1, seq length 2500]\tLoss: 3.759072\n",
      "41975it [1:20:10,  8.73it/s]Train epoch: 1 [batch #41975, batch_size 1, seq length 2500]\tLoss: 3.795016\n",
      "42000it [1:20:13,  8.69it/s]Train epoch: 1 [batch #42000, batch_size 1, seq length 2500]\tLoss: 3.586740\n",
      "42025it [1:20:16,  8.73it/s]Train epoch: 1 [batch #42025, batch_size 1, seq length 2500]\tLoss: 3.718359\n",
      "42050it [1:20:18,  8.74it/s]Train epoch: 1 [batch #42050, batch_size 1, seq length 2500]\tLoss: 3.747262\n",
      "42075it [1:20:21,  8.72it/s]Train epoch: 1 [batch #42075, batch_size 1, seq length 2500]\tLoss: 3.726550\n",
      "42100it [1:20:24,  8.75it/s]Train epoch: 1 [batch #42100, batch_size 1, seq length 2500]\tLoss: 3.356101\n",
      "42125it [1:20:27,  8.73it/s]Train epoch: 1 [batch #42125, batch_size 1, seq length 2500]\tLoss: 3.905049\n",
      "42150it [1:20:30,  8.74it/s]Train epoch: 1 [batch #42150, batch_size 1, seq length 2500]\tLoss: 3.664841\n",
      "42175it [1:20:33,  8.72it/s]Train epoch: 1 [batch #42175, batch_size 1, seq length 2500]\tLoss: 4.032547\n",
      "42200it [1:20:36,  8.73it/s]Train epoch: 1 [batch #42200, batch_size 1, seq length 2500]\tLoss: 4.024506\n",
      "42225it [1:20:39,  8.71it/s]Train epoch: 1 [batch #42225, batch_size 1, seq length 2500]\tLoss: 3.649324\n",
      "42250it [1:20:41,  8.75it/s]Train epoch: 1 [batch #42250, batch_size 1, seq length 2500]\tLoss: 3.905118\n",
      "42275it [1:20:44,  8.71it/s]Train epoch: 1 [batch #42275, batch_size 1, seq length 2500]\tLoss: 3.852657\n",
      "42300it [1:20:47,  8.73it/s]Train epoch: 1 [batch #42300, batch_size 1, seq length 2500]\tLoss: 3.807436\n",
      "42325it [1:20:50,  8.69it/s]Train epoch: 1 [batch #42325, batch_size 1, seq length 2500]\tLoss: 3.850845\n",
      "42350it [1:20:53,  8.66it/s]Train epoch: 1 [batch #42350, batch_size 1, seq length 2500]\tLoss: 3.832985\n",
      "42375it [1:20:56,  8.68it/s]Train epoch: 1 [batch #42375, batch_size 1, seq length 2500]\tLoss: 3.934875\n",
      "42400it [1:20:59,  8.72it/s]Train epoch: 1 [batch #42400, batch_size 1, seq length 2500]\tLoss: 3.896768\n",
      "42425it [1:21:01,  8.70it/s]Train epoch: 1 [batch #42425, batch_size 1, seq length 2500]\tLoss: 3.670058\n",
      "42450it [1:21:04,  8.70it/s]Train epoch: 1 [batch #42450, batch_size 1, seq length 2500]\tLoss: 3.293771\n",
      "42475it [1:21:07,  8.69it/s]Train epoch: 1 [batch #42475, batch_size 1, seq length 2500]\tLoss: 3.739547\n",
      "42500it [1:21:10,  8.64it/s]Train epoch: 1 [batch #42500, batch_size 1, seq length 2500]\tLoss: 3.627024\n",
      "42525it [1:21:13,  8.55it/s]Train epoch: 1 [batch #42525, batch_size 1, seq length 2500]\tLoss: 3.729302\n",
      "42550it [1:21:16,  8.73it/s]Train epoch: 1 [batch #42550, batch_size 1, seq length 2500]\tLoss: 3.723356\n",
      "42575it [1:21:19,  8.76it/s]Train epoch: 1 [batch #42575, batch_size 1, seq length 2500]\tLoss: 3.491982\n",
      "42600it [1:21:22,  8.75it/s]Train epoch: 1 [batch #42600, batch_size 1, seq length 2500]\tLoss: 3.494373\n",
      "42625it [1:21:24,  8.71it/s]Train epoch: 1 [batch #42625, batch_size 1, seq length 2500]\tLoss: 3.729607\n",
      "42650it [1:21:27,  8.72it/s]Train epoch: 1 [batch #42650, batch_size 1, seq length 2500]\tLoss: 3.737060\n",
      "42675it [1:21:30,  8.74it/s]Train epoch: 1 [batch #42675, batch_size 1, seq length 2500]\tLoss: 3.767447\n",
      "42700it [1:21:33,  8.74it/s]Train epoch: 1 [batch #42700, batch_size 1, seq length 2500]\tLoss: 3.865555\n",
      "42725it [1:21:36,  8.67it/s]Train epoch: 1 [batch #42725, batch_size 1, seq length 2500]\tLoss: 4.016517\n",
      "42750it [1:21:39,  8.71it/s]Train epoch: 1 [batch #42750, batch_size 1, seq length 2500]\tLoss: 3.778440\n",
      "42775it [1:21:42,  8.77it/s]Train epoch: 1 [batch #42775, batch_size 1, seq length 2500]\tLoss: 3.738921\n",
      "42800it [1:21:45,  8.70it/s]Train epoch: 1 [batch #42800, batch_size 1, seq length 2500]\tLoss: 3.895329\n",
      "42825it [1:21:47,  8.74it/s]Train epoch: 1 [batch #42825, batch_size 1, seq length 2500]\tLoss: 4.120169\n",
      "42850it [1:21:50,  8.75it/s]Train epoch: 1 [batch #42850, batch_size 1, seq length 2500]\tLoss: 4.242984\n",
      "42875it [1:21:53,  8.64it/s]Train epoch: 1 [batch #42875, batch_size 1, seq length 2500]\tLoss: 3.721403\n",
      "42900it [1:21:56,  8.74it/s]Train epoch: 1 [batch #42900, batch_size 1, seq length 2500]\tLoss: 3.947347\n",
      "42925it [1:21:59,  8.76it/s]Train epoch: 1 [batch #42925, batch_size 1, seq length 2500]\tLoss: 3.783267\n",
      "42950it [1:22:02,  8.71it/s]Train epoch: 1 [batch #42950, batch_size 1, seq length 2500]\tLoss: 4.097229\n",
      "42975it [1:22:05,  8.64it/s]Train epoch: 1 [batch #42975, batch_size 1, seq length 2500]\tLoss: 3.846495\n",
      "43000it [1:22:07,  8.76it/s]Train epoch: 1 [batch #43000, batch_size 1, seq length 2500]\tLoss: 3.806421\n",
      "43025it [1:22:10,  8.74it/s]Train epoch: 1 [batch #43025, batch_size 1, seq length 2500]\tLoss: 3.753883\n",
      "43050it [1:22:13,  8.66it/s]Train epoch: 1 [batch #43050, batch_size 1, seq length 2500]\tLoss: 3.762243\n",
      "43075it [1:22:16,  8.71it/s]Train epoch: 1 [batch #43075, batch_size 1, seq length 2500]\tLoss: 4.023557\n",
      "43100it [1:22:19,  8.67it/s]Train epoch: 1 [batch #43100, batch_size 1, seq length 2500]\tLoss: 3.902093\n",
      "43125it [1:22:22,  8.74it/s]Train epoch: 1 [batch #43125, batch_size 1, seq length 2500]\tLoss: 3.632616\n",
      "43150it [1:22:25,  8.72it/s]Train epoch: 1 [batch #43150, batch_size 1, seq length 2500]\tLoss: 3.826440\n",
      "43175it [1:22:28,  8.69it/s]Train epoch: 1 [batch #43175, batch_size 1, seq length 2500]\tLoss: 3.892444\n",
      "43200it [1:22:30,  8.68it/s]Train epoch: 1 [batch #43200, batch_size 1, seq length 2500]\tLoss: 3.998124\n",
      "43225it [1:22:33,  8.72it/s]Train epoch: 1 [batch #43225, batch_size 1, seq length 2500]\tLoss: 3.667836\n",
      "43250it [1:22:36,  8.74it/s]Train epoch: 1 [batch #43250, batch_size 1, seq length 2500]\tLoss: 4.252574\n",
      "43275it [1:22:39,  8.73it/s]Train epoch: 1 [batch #43275, batch_size 1, seq length 2500]\tLoss: 3.745251\n",
      "43300it [1:22:42,  8.73it/s]Train epoch: 1 [batch #43300, batch_size 1, seq length 2500]\tLoss: 3.583728\n",
      "43325it [1:22:45,  8.66it/s]Train epoch: 1 [batch #43325, batch_size 1, seq length 2500]\tLoss: 3.919810\n",
      "43350it [1:22:48,  8.47it/s]Train epoch: 1 [batch #43350, batch_size 1, seq length 2500]\tLoss: 3.532082\n",
      "43375it [1:22:51,  8.64it/s]Train epoch: 1 [batch #43375, batch_size 1, seq length 2500]\tLoss: 4.033390\n",
      "43400it [1:22:53,  8.73it/s]Train epoch: 1 [batch #43400, batch_size 1, seq length 2500]\tLoss: 3.978955\n",
      "43425it [1:22:56,  8.64it/s]Train epoch: 1 [batch #43425, batch_size 1, seq length 2500]\tLoss: 3.535771\n",
      "43450it [1:22:59,  8.77it/s]Train epoch: 1 [batch #43450, batch_size 1, seq length 2500]\tLoss: 3.712815\n",
      "43475it [1:23:02,  8.76it/s]Train epoch: 1 [batch #43475, batch_size 1, seq length 2500]\tLoss: 3.502431\n",
      "43500it [1:23:05,  8.73it/s]Train epoch: 1 [batch #43500, batch_size 1, seq length 2500]\tLoss: 3.529917\n",
      "43525it [1:23:08,  8.58it/s]Train epoch: 1 [batch #43525, batch_size 1, seq length 2500]\tLoss: 3.705296\n",
      "43550it [1:23:11,  8.72it/s]Train epoch: 1 [batch #43550, batch_size 1, seq length 2500]\tLoss: 3.562814\n",
      "43575it [1:23:14,  8.69it/s]Train epoch: 1 [batch #43575, batch_size 1, seq length 2500]\tLoss: 3.903864\n",
      "43600it [1:23:16,  8.73it/s]Train epoch: 1 [batch #43600, batch_size 1, seq length 2500]\tLoss: 3.434375\n",
      "43625it [1:23:19,  8.73it/s]Train epoch: 1 [batch #43625, batch_size 1, seq length 2500]\tLoss: 3.927340\n",
      "43650it [1:23:22,  8.68it/s]Train epoch: 1 [batch #43650, batch_size 1, seq length 2500]\tLoss: 3.847494\n",
      "43675it [1:23:25,  8.44it/s]Train epoch: 1 [batch #43675, batch_size 1, seq length 2500]\tLoss: 3.964134\n",
      "43700it [1:23:28,  8.72it/s]Train epoch: 1 [batch #43700, batch_size 1, seq length 2500]\tLoss: 3.834546\n",
      "43725it [1:23:31,  8.68it/s]Train epoch: 1 [batch #43725, batch_size 1, seq length 2500]\tLoss: 4.005160\n",
      "43750it [1:23:34,  8.71it/s]Train epoch: 1 [batch #43750, batch_size 1, seq length 2500]\tLoss: 3.933506\n",
      "43775it [1:23:37,  8.66it/s]Train epoch: 1 [batch #43775, batch_size 1, seq length 2500]\tLoss: 3.853716\n",
      "43800it [1:23:39,  8.71it/s]Train epoch: 1 [batch #43800, batch_size 1, seq length 2500]\tLoss: 3.807951\n",
      "43825it [1:23:42,  8.71it/s]Train epoch: 1 [batch #43825, batch_size 1, seq length 2500]\tLoss: 4.021677\n",
      "43850it [1:23:45,  8.75it/s]Train epoch: 1 [batch #43850, batch_size 1, seq length 2500]\tLoss: 3.610832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43875it [1:23:48,  8.73it/s]Train epoch: 1 [batch #43875, batch_size 1, seq length 2500]\tLoss: 3.729657\n",
      "43900it [1:23:51,  8.77it/s]Train epoch: 1 [batch #43900, batch_size 1, seq length 2500]\tLoss: 3.847683\n",
      "43925it [1:23:54,  8.75it/s]Train epoch: 1 [batch #43925, batch_size 1, seq length 2500]\tLoss: 3.689304\n",
      "43950it [1:23:57,  8.76it/s]Train epoch: 1 [batch #43950, batch_size 1, seq length 2500]\tLoss: 3.664882\n",
      "43975it [1:23:59,  8.74it/s]Train epoch: 1 [batch #43975, batch_size 1, seq length 2500]\tLoss: 3.730921\n",
      "44000it [1:24:02,  8.73it/s]Train epoch: 1 [batch #44000, batch_size 1, seq length 2500]\tLoss: 3.924051\n",
      "44025it [1:24:05,  8.70it/s]Train epoch: 1 [batch #44025, batch_size 1, seq length 2500]\tLoss: 3.854318\n",
      "44050it [1:24:08,  8.73it/s]Train epoch: 1 [batch #44050, batch_size 1, seq length 2500]\tLoss: 3.998862\n",
      "44075it [1:24:11,  8.71it/s]Train epoch: 1 [batch #44075, batch_size 1, seq length 2500]\tLoss: 3.841119\n",
      "44100it [1:24:14,  8.73it/s]Train epoch: 1 [batch #44100, batch_size 1, seq length 2500]\tLoss: 3.713602\n",
      "44125it [1:24:17,  8.64it/s]Train epoch: 1 [batch #44125, batch_size 1, seq length 2500]\tLoss: 3.759026\n",
      "44150it [1:24:20,  8.72it/s]Train epoch: 1 [batch #44150, batch_size 1, seq length 2500]\tLoss: 3.923216\n",
      "44175it [1:24:22,  8.74it/s]Train epoch: 1 [batch #44175, batch_size 1, seq length 2500]\tLoss: 3.798467\n",
      "44200it [1:24:25,  8.71it/s]Train epoch: 1 [batch #44200, batch_size 1, seq length 2500]\tLoss: 3.547800\n",
      "44225it [1:24:28,  8.74it/s]Train epoch: 1 [batch #44225, batch_size 1, seq length 2500]\tLoss: 3.729713\n",
      "44250it [1:24:31,  8.69it/s]Train epoch: 1 [batch #44250, batch_size 1, seq length 2500]\tLoss: 3.849049\n",
      "44275it [1:24:34,  8.61it/s]Train epoch: 1 [batch #44275, batch_size 1, seq length 2500]\tLoss: 3.705512\n",
      "44300it [1:24:37,  8.71it/s]Train epoch: 1 [batch #44300, batch_size 1, seq length 2500]\tLoss: 3.910013\n",
      "44325it [1:24:40,  8.73it/s]Train epoch: 1 [batch #44325, batch_size 1, seq length 2500]\tLoss: 3.870011\n",
      "44350it [1:24:43,  8.76it/s]Train epoch: 1 [batch #44350, batch_size 1, seq length 2500]\tLoss: 3.669919\n",
      "44375it [1:24:45,  8.71it/s]Train epoch: 1 [batch #44375, batch_size 1, seq length 2500]\tLoss: 3.701103\n",
      "44400it [1:24:48,  8.71it/s]Train epoch: 1 [batch #44400, batch_size 1, seq length 2500]\tLoss: 3.846061\n",
      "44425it [1:24:51,  8.60it/s]Train epoch: 1 [batch #44425, batch_size 1, seq length 2500]\tLoss: 3.829585\n",
      "44450it [1:24:54,  8.73it/s]Train epoch: 1 [batch #44450, batch_size 1, seq length 2500]\tLoss: 3.800687\n",
      "44475it [1:24:57,  8.70it/s]Train epoch: 1 [batch #44475, batch_size 1, seq length 2500]\tLoss: 4.048378\n",
      "44500it [1:25:00,  8.70it/s]Train epoch: 1 [batch #44500, batch_size 1, seq length 2500]\tLoss: 3.923464\n",
      "44525it [1:25:03,  8.77it/s]Train epoch: 1 [batch #44525, batch_size 1, seq length 2500]\tLoss: 3.873238\n",
      "44550it [1:25:06,  8.69it/s]Train epoch: 1 [batch #44550, batch_size 1, seq length 2500]\tLoss: 3.900175\n",
      "44575it [1:25:08,  8.69it/s]Train epoch: 1 [batch #44575, batch_size 1, seq length 2500]\tLoss: 3.482691\n",
      "44600it [1:25:11,  8.63it/s]Train epoch: 1 [batch #44600, batch_size 1, seq length 2500]\tLoss: 3.944941\n",
      "44625it [1:25:14,  8.70it/s]Train epoch: 1 [batch #44625, batch_size 1, seq length 2500]\tLoss: 3.579440\n",
      "44650it [1:25:17,  8.72it/s]Train epoch: 1 [batch #44650, batch_size 1, seq length 2500]\tLoss: 3.668727\n",
      "44675it [1:25:20,  8.76it/s]Train epoch: 1 [batch #44675, batch_size 1, seq length 2500]\tLoss: 3.978053\n",
      "44700it [1:25:23,  8.66it/s]Train epoch: 1 [batch #44700, batch_size 1, seq length 2500]\tLoss: 3.961435\n",
      "44725it [1:25:26,  8.73it/s]Train epoch: 1 [batch #44725, batch_size 1, seq length 2500]\tLoss: 3.894421\n",
      "44750it [1:25:29,  8.72it/s]Train epoch: 1 [batch #44750, batch_size 1, seq length 2500]\tLoss: 4.067255\n",
      "44775it [1:25:31,  8.74it/s]Train epoch: 1 [batch #44775, batch_size 1, seq length 2500]\tLoss: 3.850159\n",
      "44800it [1:25:34,  8.65it/s]Train epoch: 1 [batch #44800, batch_size 1, seq length 2500]\tLoss: 3.802424\n",
      "44825it [1:25:37,  8.69it/s]Train epoch: 1 [batch #44825, batch_size 1, seq length 2500]\tLoss: 3.817934\n",
      "44850it [1:25:40,  8.67it/s]Train epoch: 1 [batch #44850, batch_size 1, seq length 2500]\tLoss: 3.714979\n",
      "44875it [1:25:43,  8.68it/s]Train epoch: 1 [batch #44875, batch_size 1, seq length 2500]\tLoss: 3.681953\n",
      "44900it [1:25:46,  8.75it/s]Train epoch: 1 [batch #44900, batch_size 1, seq length 2500]\tLoss: 3.693159\n",
      "44925it [1:25:49,  8.75it/s]Train epoch: 1 [batch #44925, batch_size 1, seq length 2500]\tLoss: 3.470453\n",
      "44950it [1:25:52,  8.68it/s]Train epoch: 1 [batch #44950, batch_size 1, seq length 2500]\tLoss: 3.700491\n",
      "44975it [1:25:54,  8.71it/s]Train epoch: 1 [batch #44975, batch_size 1, seq length 2500]\tLoss: 4.007064\n",
      "45000it [1:25:57,  8.63it/s]Train epoch: 1 [batch #45000, batch_size 1, seq length 2500]\tLoss: 4.067368\n",
      "45025it [1:26:00,  8.72it/s]Train epoch: 1 [batch #45025, batch_size 1, seq length 2500]\tLoss: 4.036012\n",
      "45050it [1:26:03,  8.60it/s]Train epoch: 1 [batch #45050, batch_size 1, seq length 2500]\tLoss: 4.070488\n",
      "45075it [1:26:06,  8.72it/s]Train epoch: 1 [batch #45075, batch_size 1, seq length 2500]\tLoss: 3.815259\n",
      "45100it [1:26:09,  8.74it/s]Train epoch: 1 [batch #45100, batch_size 1, seq length 2500]\tLoss: 3.796042\n",
      "45125it [1:26:12,  8.70it/s]Train epoch: 1 [batch #45125, batch_size 1, seq length 2500]\tLoss: 4.047947\n",
      "45150it [1:26:15,  8.72it/s]Train epoch: 1 [batch #45150, batch_size 1, seq length 2500]\tLoss: 3.414544\n",
      "45175it [1:26:17,  8.75it/s]Train epoch: 1 [batch #45175, batch_size 1, seq length 2500]\tLoss: 3.682303\n",
      "45200it [1:26:20,  8.66it/s]Train epoch: 1 [batch #45200, batch_size 1, seq length 2500]\tLoss: 3.914795\n",
      "45225it [1:26:23,  8.62it/s]Train epoch: 1 [batch #45225, batch_size 1, seq length 2500]\tLoss: 3.681830\n",
      "45250it [1:26:26,  8.72it/s]Train epoch: 1 [batch #45250, batch_size 1, seq length 2500]\tLoss: 3.771580\n",
      "45275it [1:26:29,  8.51it/s]Train epoch: 1 [batch #45275, batch_size 1, seq length 2500]\tLoss: 3.840817\n",
      "45300it [1:26:32,  8.73it/s]Train epoch: 1 [batch #45300, batch_size 1, seq length 2500]\tLoss: 3.787472\n",
      "45325it [1:26:35,  8.69it/s]Train epoch: 1 [batch #45325, batch_size 1, seq length 2500]\tLoss: 3.720370\n",
      "45350it [1:26:38,  8.69it/s]Train epoch: 1 [batch #45350, batch_size 1, seq length 2500]\tLoss: 3.543934\n",
      "45375it [1:26:40,  8.74it/s]Train epoch: 1 [batch #45375, batch_size 1, seq length 2500]\tLoss: 3.643648\n",
      "45400it [1:26:43,  8.71it/s]Train epoch: 1 [batch #45400, batch_size 1, seq length 2500]\tLoss: 3.734041\n",
      "45425it [1:26:46,  8.74it/s]Train epoch: 1 [batch #45425, batch_size 1, seq length 2500]\tLoss: 4.165914\n",
      "45450it [1:26:49,  8.71it/s]Train epoch: 1 [batch #45450, batch_size 1, seq length 2500]\tLoss: 3.483762\n",
      "45475it [1:26:52,  8.70it/s]Train epoch: 1 [batch #45475, batch_size 1, seq length 2500]\tLoss: 3.850902\n",
      "45500it [1:26:55,  8.66it/s]Train epoch: 1 [batch #45500, batch_size 1, seq length 2500]\tLoss: 3.932446\n",
      "45525it [1:26:58,  8.72it/s]Train epoch: 1 [batch #45525, batch_size 1, seq length 2500]\tLoss: 4.066857\n",
      "45550it [1:27:01,  8.66it/s]Train epoch: 1 [batch #45550, batch_size 1, seq length 2500]\tLoss: 4.035972\n",
      "45575it [1:27:03,  8.71it/s]Train epoch: 1 [batch #45575, batch_size 1, seq length 2500]\tLoss: 3.489236\n",
      "45600it [1:27:06,  8.71it/s]Train epoch: 1 [batch #45600, batch_size 1, seq length 2500]\tLoss: 3.882007\n",
      "45625it [1:27:09,  8.64it/s]Train epoch: 1 [batch #45625, batch_size 1, seq length 2500]\tLoss: 3.755126\n",
      "45650it [1:27:12,  8.71it/s]Train epoch: 1 [batch #45650, batch_size 1, seq length 2500]\tLoss: 3.818906\n",
      "45675it [1:27:15,  8.71it/s]Train epoch: 1 [batch #45675, batch_size 1, seq length 2500]\tLoss: 3.928766\n",
      "45700it [1:27:18,  8.76it/s]Train epoch: 1 [batch #45700, batch_size 1, seq length 2500]\tLoss: 3.581437\n",
      "45725it [1:27:21,  8.74it/s]Train epoch: 1 [batch #45725, batch_size 1, seq length 2500]\tLoss: 4.046677\n",
      "45750it [1:27:24,  8.69it/s]Train epoch: 1 [batch #45750, batch_size 1, seq length 2500]\tLoss: 3.665835\n",
      "45775it [1:27:26,  8.71it/s]Train epoch: 1 [batch #45775, batch_size 1, seq length 2500]\tLoss: 3.784207\n",
      "45800it [1:27:29,  8.62it/s]Train epoch: 1 [batch #45800, batch_size 1, seq length 2500]\tLoss: 3.968482\n",
      "45825it [1:27:32,  8.70it/s]Train epoch: 1 [batch #45825, batch_size 1, seq length 2500]\tLoss: 3.836876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45850it [1:27:35,  8.71it/s]Train epoch: 1 [batch #45850, batch_size 1, seq length 2500]\tLoss: 3.837820\n",
      "45875it [1:27:38,  8.71it/s]Train epoch: 1 [batch #45875, batch_size 1, seq length 2500]\tLoss: 3.881599\n",
      "45900it [1:27:41,  8.71it/s]Train epoch: 1 [batch #45900, batch_size 1, seq length 2500]\tLoss: 3.999672\n",
      "45925it [1:27:44,  8.62it/s]Train epoch: 1 [batch #45925, batch_size 1, seq length 2500]\tLoss: 3.446391\n",
      "45950it [1:27:47,  8.72it/s]Train epoch: 1 [batch #45950, batch_size 1, seq length 2500]\tLoss: 3.730847\n",
      "45975it [1:27:49,  8.73it/s]Train epoch: 1 [batch #45975, batch_size 1, seq length 2500]\tLoss: 4.014566\n",
      "46000it [1:27:52,  8.72it/s]Train epoch: 1 [batch #46000, batch_size 1, seq length 2500]\tLoss: 3.730897\n",
      "46025it [1:27:55,  8.68it/s]Train epoch: 1 [batch #46025, batch_size 1, seq length 2500]\tLoss: 3.788294\n",
      "46050it [1:27:58,  8.71it/s]Train epoch: 1 [batch #46050, batch_size 1, seq length 2500]\tLoss: 3.889346\n",
      "46075it [1:28:01,  8.74it/s]Train epoch: 1 [batch #46075, batch_size 1, seq length 2500]\tLoss: 3.889986\n",
      "46100it [1:28:04,  8.74it/s]Train epoch: 1 [batch #46100, batch_size 1, seq length 2500]\tLoss: 3.901466\n",
      "46125it [1:28:07,  8.74it/s]Train epoch: 1 [batch #46125, batch_size 1, seq length 2500]\tLoss: 3.711034\n",
      "46150it [1:28:10,  8.72it/s]Train epoch: 1 [batch #46150, batch_size 1, seq length 2500]\tLoss: 3.587914\n",
      "46175it [1:28:12,  8.66it/s]Train epoch: 1 [batch #46175, batch_size 1, seq length 2500]\tLoss: 3.851988\n",
      "46200it [1:28:15,  8.71it/s]Train epoch: 1 [batch #46200, batch_size 1, seq length 2500]\tLoss: 3.810139\n",
      "46225it [1:28:18,  8.71it/s]Train epoch: 1 [batch #46225, batch_size 1, seq length 2500]\tLoss: 3.967954\n",
      "46250it [1:28:21,  8.69it/s]Train epoch: 1 [batch #46250, batch_size 1, seq length 2500]\tLoss: 3.699636\n",
      "46275it [1:28:24,  8.71it/s]Train epoch: 1 [batch #46275, batch_size 1, seq length 2500]\tLoss: 3.729891\n",
      "46300it [1:28:27,  8.64it/s]Train epoch: 1 [batch #46300, batch_size 1, seq length 2500]\tLoss: 3.854555\n",
      "46325it [1:28:30,  8.58it/s]Train epoch: 1 [batch #46325, batch_size 1, seq length 2500]\tLoss: 4.018708\n",
      "46350it [1:28:33,  8.71it/s]Train epoch: 1 [batch #46350, batch_size 1, seq length 2500]\tLoss: 3.838992\n",
      "46375it [1:28:35,  8.65it/s]Train epoch: 1 [batch #46375, batch_size 1, seq length 2500]\tLoss: 3.600428\n",
      "46400it [1:28:38,  8.64it/s]Train epoch: 1 [batch #46400, batch_size 1, seq length 2500]\tLoss: 3.959979\n",
      "46425it [1:28:41,  8.72it/s]Train epoch: 1 [batch #46425, batch_size 1, seq length 2500]\tLoss: 3.919254\n",
      "46450it [1:28:44,  8.58it/s]Train epoch: 1 [batch #46450, batch_size 1, seq length 2500]\tLoss: 4.005793\n",
      "46475it [1:28:47,  8.69it/s]Train epoch: 1 [batch #46475, batch_size 1, seq length 2500]\tLoss: 3.818423\n",
      "46500it [1:28:50,  8.72it/s]Train epoch: 1 [batch #46500, batch_size 1, seq length 2500]\tLoss: 3.769152\n",
      "46525it [1:28:53,  8.68it/s]Train epoch: 1 [batch #46525, batch_size 1, seq length 2500]\tLoss: 3.826111\n",
      "46550it [1:28:56,  8.56it/s]Train epoch: 1 [batch #46550, batch_size 1, seq length 2500]\tLoss: 3.492882\n",
      "46575it [1:28:58,  8.69it/s]Train epoch: 1 [batch #46575, batch_size 1, seq length 2500]\tLoss: 3.971125\n",
      "46600it [1:29:01,  8.71it/s]Train epoch: 1 [batch #46600, batch_size 1, seq length 2500]\tLoss: 3.848403\n",
      "46625it [1:29:04,  8.66it/s]Train epoch: 1 [batch #46625, batch_size 1, seq length 2500]\tLoss: 3.849644\n",
      "46650it [1:29:07,  8.71it/s]Train epoch: 1 [batch #46650, batch_size 1, seq length 2500]\tLoss: 3.636167\n",
      "46675it [1:29:10,  8.65it/s]Train epoch: 1 [batch #46675, batch_size 1, seq length 2500]\tLoss: 3.581460\n",
      "46700it [1:29:13,  8.49it/s]Train epoch: 1 [batch #46700, batch_size 1, seq length 2500]\tLoss: 3.563406\n",
      "46725it [1:29:16,  8.74it/s]Train epoch: 1 [batch #46725, batch_size 1, seq length 2500]\tLoss: 3.803026\n",
      "46750it [1:29:19,  8.73it/s]Train epoch: 1 [batch #46750, batch_size 1, seq length 2500]\tLoss: 3.984105\n",
      "46775it [1:29:21,  8.74it/s]Train epoch: 1 [batch #46775, batch_size 1, seq length 2500]\tLoss: 3.780355\n",
      "46800it [1:29:24,  8.67it/s]Train epoch: 1 [batch #46800, batch_size 1, seq length 2500]\tLoss: 3.957576\n",
      "46825it [1:29:27,  8.66it/s]Train epoch: 1 [batch #46825, batch_size 1, seq length 2500]\tLoss: 3.791140\n",
      "46850it [1:29:30,  8.66it/s]Train epoch: 1 [batch #46850, batch_size 1, seq length 2500]\tLoss: 3.806275\n",
      "46875it [1:29:33,  8.70it/s]Train epoch: 1 [batch #46875, batch_size 1, seq length 2500]\tLoss: 3.808173\n",
      "46900it [1:29:36,  8.75it/s]Train epoch: 1 [batch #46900, batch_size 1, seq length 2500]\tLoss: 3.769003\n",
      "46925it [1:29:39,  8.66it/s]Train epoch: 1 [batch #46925, batch_size 1, seq length 2500]\tLoss: 3.484059\n",
      "46950it [1:29:42,  8.70it/s]Train epoch: 1 [batch #46950, batch_size 1, seq length 2500]\tLoss: 3.590315\n",
      "46975it [1:29:44,  8.74it/s]Train epoch: 1 [batch #46975, batch_size 1, seq length 2500]\tLoss: 3.423402\n",
      "47000it [1:29:47,  8.72it/s]Train epoch: 1 [batch #47000, batch_size 1, seq length 2500]\tLoss: 3.959756\n",
      "47025it [1:29:50,  8.64it/s]Train epoch: 1 [batch #47025, batch_size 1, seq length 2500]\tLoss: 3.871724\n",
      "47050it [1:29:53,  8.63it/s]Train epoch: 1 [batch #47050, batch_size 1, seq length 2500]\tLoss: 3.855516\n",
      "47075it [1:29:56,  8.73it/s]Train epoch: 1 [batch #47075, batch_size 1, seq length 2500]\tLoss: 3.845256\n",
      "47100it [1:29:59,  8.72it/s]Train epoch: 1 [batch #47100, batch_size 1, seq length 2500]\tLoss: 3.954545\n",
      "47125it [1:30:02,  8.67it/s]Train epoch: 1 [batch #47125, batch_size 1, seq length 2500]\tLoss: 3.585609\n",
      "47150it [1:30:05,  8.57it/s]Train epoch: 1 [batch #47150, batch_size 1, seq length 2500]\tLoss: 3.651973\n",
      "47175it [1:30:08,  8.50it/s]Train epoch: 1 [batch #47175, batch_size 1, seq length 2500]\tLoss: 3.416963\n",
      "47200it [1:30:10,  8.73it/s]Train epoch: 1 [batch #47200, batch_size 1, seq length 2500]\tLoss: 4.059891\n",
      "47225it [1:30:13,  8.70it/s]Train epoch: 1 [batch #47225, batch_size 1, seq length 2500]\tLoss: 3.942362\n",
      "47250it [1:30:16,  8.74it/s]Train epoch: 1 [batch #47250, batch_size 1, seq length 2500]\tLoss: 3.859545\n",
      "47275it [1:30:19,  8.75it/s]Train epoch: 1 [batch #47275, batch_size 1, seq length 2500]\tLoss: 4.121219\n",
      "47300it [1:30:22,  8.70it/s]Train epoch: 1 [batch #47300, batch_size 1, seq length 2500]\tLoss: 3.852057\n",
      "47325it [1:30:25,  8.73it/s]Train epoch: 1 [batch #47325, batch_size 1, seq length 2500]\tLoss: 3.575259\n",
      "47350it [1:30:28,  8.70it/s]Train epoch: 1 [batch #47350, batch_size 1, seq length 2500]\tLoss: 3.534211\n",
      "47375it [1:30:31,  8.68it/s]Train epoch: 1 [batch #47375, batch_size 1, seq length 2500]\tLoss: 3.709096\n",
      "47400it [1:30:33,  8.67it/s]Train epoch: 1 [batch #47400, batch_size 1, seq length 2500]\tLoss: 4.162017\n",
      "47425it [1:30:36,  8.72it/s]Train epoch: 1 [batch #47425, batch_size 1, seq length 2500]\tLoss: 3.652698\n",
      "47450it [1:30:39,  8.75it/s]Train epoch: 1 [batch #47450, batch_size 1, seq length 2500]\tLoss: 3.964725\n",
      "47475it [1:30:42,  8.75it/s]Train epoch: 1 [batch #47475, batch_size 1, seq length 2500]\tLoss: 3.961722\n",
      "47500it [1:30:45,  8.71it/s]Train epoch: 1 [batch #47500, batch_size 1, seq length 2500]\tLoss: 3.623194\n",
      "47525it [1:30:48,  8.58it/s]Train epoch: 1 [batch #47525, batch_size 1, seq length 2500]\tLoss: 3.931452\n",
      "47550it [1:30:51,  8.70it/s]Train epoch: 1 [batch #47550, batch_size 1, seq length 2500]\tLoss: 3.633609\n",
      "47575it [1:30:54,  8.69it/s]Train epoch: 1 [batch #47575, batch_size 1, seq length 2500]\tLoss: 3.635984\n",
      "47600it [1:30:56,  8.71it/s]Train epoch: 1 [batch #47600, batch_size 1, seq length 2500]\tLoss: 3.745344\n",
      "47625it [1:30:59,  8.71it/s]Train epoch: 1 [batch #47625, batch_size 1, seq length 2500]\tLoss: 3.672353\n",
      "47650it [1:31:02,  8.69it/s]Train epoch: 1 [batch #47650, batch_size 1, seq length 2500]\tLoss: 3.685148\n",
      "47675it [1:31:05,  8.72it/s]Train epoch: 1 [batch #47675, batch_size 1, seq length 2500]\tLoss: 3.951984\n",
      "47700it [1:31:08,  8.70it/s]Train epoch: 1 [batch #47700, batch_size 1, seq length 2500]\tLoss: 3.798151\n",
      "47725it [1:31:11,  8.55it/s]Train epoch: 1 [batch #47725, batch_size 1, seq length 2500]\tLoss: 3.802388\n",
      "47750it [1:31:14,  8.73it/s]Train epoch: 1 [batch #47750, batch_size 1, seq length 2500]\tLoss: 3.726965\n",
      "47775it [1:31:17,  8.72it/s]Train epoch: 1 [batch #47775, batch_size 1, seq length 2500]\tLoss: 3.775825\n",
      "47800it [1:31:19,  8.63it/s]Train epoch: 1 [batch #47800, batch_size 1, seq length 2500]\tLoss: 4.187369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47825it [1:31:22,  8.66it/s]Train epoch: 1 [batch #47825, batch_size 1, seq length 2500]\tLoss: 3.609024\n",
      "47850it [1:31:25,  8.64it/s]Train epoch: 1 [batch #47850, batch_size 1, seq length 2500]\tLoss: 3.817931\n",
      "47875it [1:31:28,  8.65it/s]Train epoch: 1 [batch #47875, batch_size 1, seq length 2500]\tLoss: 3.784035\n",
      "47900it [1:31:31,  8.76it/s]Train epoch: 1 [batch #47900, batch_size 1, seq length 2500]\tLoss: 3.605065\n",
      "47925it [1:31:34,  8.71it/s]Train epoch: 1 [batch #47925, batch_size 1, seq length 2500]\tLoss: 3.884572\n",
      "47950it [1:31:37,  8.69it/s]Train epoch: 1 [batch #47950, batch_size 1, seq length 2500]\tLoss: 3.466283\n",
      "47975it [1:31:40,  8.70it/s]Train epoch: 1 [batch #47975, batch_size 1, seq length 2500]\tLoss: 3.956780\n",
      "48000it [1:31:42,  8.72it/s]Train epoch: 1 [batch #48000, batch_size 1, seq length 2500]\tLoss: 3.710868\n",
      "48025it [1:31:45,  8.73it/s]Train epoch: 1 [batch #48025, batch_size 1, seq length 2500]\tLoss: 4.083096\n",
      "48050it [1:31:48,  8.68it/s]Train epoch: 1 [batch #48050, batch_size 1, seq length 2500]\tLoss: 3.683531\n",
      "48075it [1:31:51,  8.71it/s]Train epoch: 1 [batch #48075, batch_size 1, seq length 2500]\tLoss: 4.133905\n",
      "48100it [1:31:54,  8.70it/s]Train epoch: 1 [batch #48100, batch_size 1, seq length 2500]\tLoss: 3.644919\n",
      "48125it [1:31:57,  8.74it/s]Train epoch: 1 [batch #48125, batch_size 1, seq length 2500]\tLoss: 3.810684\n",
      "48150it [1:32:00,  8.64it/s]Train epoch: 1 [batch #48150, batch_size 1, seq length 2500]\tLoss: 3.680536\n",
      "48175it [1:32:03,  8.69it/s]Train epoch: 1 [batch #48175, batch_size 1, seq length 2500]\tLoss: 3.779807\n",
      "48200it [1:32:05,  8.73it/s]Train epoch: 1 [batch #48200, batch_size 1, seq length 2500]\tLoss: 3.987996\n",
      "48225it [1:32:08,  8.69it/s]Train epoch: 1 [batch #48225, batch_size 1, seq length 2500]\tLoss: 3.729316\n",
      "48250it [1:32:11,  8.67it/s]Train epoch: 1 [batch #48250, batch_size 1, seq length 2500]\tLoss: 3.774381\n",
      "48275it [1:32:14,  8.71it/s]Train epoch: 1 [batch #48275, batch_size 1, seq length 2500]\tLoss: 3.818672\n",
      "48300it [1:32:17,  8.75it/s]Train epoch: 1 [batch #48300, batch_size 1, seq length 2500]\tLoss: 4.140775\n",
      "48325it [1:32:20,  8.76it/s]Train epoch: 1 [batch #48325, batch_size 1, seq length 2500]\tLoss: 3.824588\n",
      "48350it [1:32:23,  8.72it/s]Train epoch: 1 [batch #48350, batch_size 1, seq length 2500]\tLoss: 4.034036\n",
      "48375it [1:32:26,  8.69it/s]Train epoch: 1 [batch #48375, batch_size 1, seq length 2500]\tLoss: 4.176851\n",
      "48400it [1:32:28,  8.68it/s]Train epoch: 1 [batch #48400, batch_size 1, seq length 2500]\tLoss: 3.907428\n",
      "48425it [1:32:31,  8.73it/s]Train epoch: 1 [batch #48425, batch_size 1, seq length 2500]\tLoss: 3.865645\n",
      "48450it [1:32:34,  8.73it/s]Train epoch: 1 [batch #48450, batch_size 1, seq length 2500]\tLoss: 3.841985\n",
      "48475it [1:32:37,  8.70it/s]Train epoch: 1 [batch #48475, batch_size 1, seq length 2500]\tLoss: 3.708989\n",
      "48500it [1:32:40,  8.68it/s]Train epoch: 1 [batch #48500, batch_size 1, seq length 2500]\tLoss: 3.852090\n",
      "48525it [1:32:43,  8.68it/s]Train epoch: 1 [batch #48525, batch_size 1, seq length 2500]\tLoss: 3.558218\n",
      "48550it [1:32:46,  8.71it/s]Train epoch: 1 [batch #48550, batch_size 1, seq length 2500]\tLoss: 3.597014\n",
      "48575it [1:32:49,  8.64it/s]Train epoch: 1 [batch #48575, batch_size 1, seq length 2500]\tLoss: 4.022838\n",
      "48600it [1:32:51,  8.74it/s]Train epoch: 1 [batch #48600, batch_size 1, seq length 2500]\tLoss: 3.946177\n",
      "48625it [1:32:54,  8.67it/s]Train epoch: 1 [batch #48625, batch_size 1, seq length 2500]\tLoss: 3.922761\n",
      "48650it [1:32:57,  8.74it/s]Train epoch: 1 [batch #48650, batch_size 1, seq length 2500]\tLoss: 3.673011\n",
      "48675it [1:33:00,  8.70it/s]Train epoch: 1 [batch #48675, batch_size 1, seq length 2500]\tLoss: 3.562983\n",
      "48700it [1:33:03,  8.75it/s]Train epoch: 1 [batch #48700, batch_size 1, seq length 2500]\tLoss: 3.684285\n",
      "48725it [1:33:06,  8.65it/s]Train epoch: 1 [batch #48725, batch_size 1, seq length 2500]\tLoss: 3.712917\n",
      "48750it [1:33:09,  8.71it/s]Train epoch: 1 [batch #48750, batch_size 1, seq length 2500]\tLoss: 3.682369\n",
      "48775it [1:33:12,  8.68it/s]Train epoch: 1 [batch #48775, batch_size 1, seq length 2500]\tLoss: 3.835963\n",
      "48800it [1:33:14,  8.63it/s]Train epoch: 1 [batch #48800, batch_size 1, seq length 2500]\tLoss: 3.935193\n",
      "48825it [1:33:17,  8.66it/s]Train epoch: 1 [batch #48825, batch_size 1, seq length 2500]\tLoss: 3.826455\n",
      "48850it [1:33:20,  8.60it/s]Train epoch: 1 [batch #48850, batch_size 1, seq length 2500]\tLoss: 3.922307\n",
      "48875it [1:33:23,  8.72it/s]Train epoch: 1 [batch #48875, batch_size 1, seq length 2500]\tLoss: 3.959590\n",
      "48900it [1:33:26,  8.74it/s]Train epoch: 1 [batch #48900, batch_size 1, seq length 2500]\tLoss: 3.548773\n",
      "48925it [1:33:29,  8.76it/s]Train epoch: 1 [batch #48925, batch_size 1, seq length 2500]\tLoss: 3.813137\n",
      "48950it [1:33:32,  8.64it/s]Train epoch: 1 [batch #48950, batch_size 1, seq length 2500]\tLoss: 3.687832\n",
      "48975it [1:33:35,  8.70it/s]Train epoch: 1 [batch #48975, batch_size 1, seq length 2500]\tLoss: 4.028984\n",
      "49000it [1:33:37,  8.68it/s]Train epoch: 1 [batch #49000, batch_size 1, seq length 2500]\tLoss: 4.019368\n",
      "49025it [1:33:40,  8.74it/s]Train epoch: 1 [batch #49025, batch_size 1, seq length 2500]\tLoss: 3.715130\n",
      "49050it [1:33:43,  8.67it/s]Train epoch: 1 [batch #49050, batch_size 1, seq length 2500]\tLoss: 3.943731\n",
      "49075it [1:33:46,  8.67it/s]Train epoch: 1 [batch #49075, batch_size 1, seq length 2500]\tLoss: 3.522133\n",
      "49100it [1:33:49,  8.68it/s]Train epoch: 1 [batch #49100, batch_size 1, seq length 2500]\tLoss: 3.733990\n",
      "49125it [1:33:52,  8.49it/s]Train epoch: 1 [batch #49125, batch_size 1, seq length 2500]\tLoss: 3.836058\n",
      "49150it [1:33:55,  8.71it/s]Train epoch: 1 [batch #49150, batch_size 1, seq length 2500]\tLoss: 3.713017\n",
      "49175it [1:33:58,  8.71it/s]Train epoch: 1 [batch #49175, batch_size 1, seq length 2500]\tLoss: 3.893999\n",
      "49200it [1:34:00,  8.75it/s]Train epoch: 1 [batch #49200, batch_size 1, seq length 2500]\tLoss: 3.987868\n",
      "49225it [1:34:03,  8.70it/s]Train epoch: 1 [batch #49225, batch_size 1, seq length 2500]\tLoss: 3.575593\n",
      "49250it [1:34:06,  8.69it/s]Train epoch: 1 [batch #49250, batch_size 1, seq length 2500]\tLoss: 3.762389\n",
      "49275it [1:34:09,  8.69it/s]Train epoch: 1 [batch #49275, batch_size 1, seq length 2500]\tLoss: 3.575772\n",
      "49300it [1:34:12,  8.67it/s]Train epoch: 1 [batch #49300, batch_size 1, seq length 2500]\tLoss: 3.752165\n",
      "49325it [1:34:15,  8.70it/s]Train epoch: 1 [batch #49325, batch_size 1, seq length 2500]\tLoss: 3.570081\n",
      "49350it [1:34:18,  8.64it/s]Train epoch: 1 [batch #49350, batch_size 1, seq length 2500]\tLoss: 3.817915\n",
      "49375it [1:34:21,  8.76it/s]Train epoch: 1 [batch #49375, batch_size 1, seq length 2500]\tLoss: 4.048551\n",
      "49400it [1:34:23,  8.70it/s]Train epoch: 1 [batch #49400, batch_size 1, seq length 2500]\tLoss: 4.089968\n",
      "49425it [1:34:26,  8.72it/s]Train epoch: 1 [batch #49425, batch_size 1, seq length 2500]\tLoss: 3.891136\n",
      "49450it [1:34:29,  8.72it/s]Train epoch: 1 [batch #49450, batch_size 1, seq length 2500]\tLoss: 3.880015\n",
      "49475it [1:34:32,  8.71it/s]Train epoch: 1 [batch #49475, batch_size 1, seq length 2500]\tLoss: 3.524344\n",
      "49500it [1:34:35,  8.65it/s]Train epoch: 1 [batch #49500, batch_size 1, seq length 2500]\tLoss: 3.532321\n",
      "49525it [1:34:38,  8.66it/s]Train epoch: 1 [batch #49525, batch_size 1, seq length 2500]\tLoss: 3.722214\n",
      "49550it [1:34:41,  8.70it/s]Train epoch: 1 [batch #49550, batch_size 1, seq length 2500]\tLoss: 3.559380\n",
      "49575it [1:34:44,  8.69it/s]Train epoch: 1 [batch #49575, batch_size 1, seq length 2500]\tLoss: 3.958749\n",
      "49600it [1:34:46,  8.72it/s]Train epoch: 1 [batch #49600, batch_size 1, seq length 2500]\tLoss: 3.696197\n",
      "49625it [1:34:49,  8.71it/s]Train epoch: 1 [batch #49625, batch_size 1, seq length 2500]\tLoss: 3.877523\n",
      "49650it [1:34:52,  8.74it/s]Train epoch: 1 [batch #49650, batch_size 1, seq length 2500]\tLoss: 3.926680\n",
      "49675it [1:34:55,  8.70it/s]Train epoch: 1 [batch #49675, batch_size 1, seq length 2500]\tLoss: 3.620236\n",
      "49700it [1:34:58,  8.71it/s]Train epoch: 1 [batch #49700, batch_size 1, seq length 2500]\tLoss: 4.002373\n",
      "49725it [1:35:01,  8.75it/s]Train epoch: 1 [batch #49725, batch_size 1, seq length 2500]\tLoss: 3.845525\n",
      "49750it [1:35:04,  8.73it/s]Train epoch: 1 [batch #49750, batch_size 1, seq length 2500]\tLoss: 3.944360\n",
      "49775it [1:35:07,  8.73it/s]Train epoch: 1 [batch #49775, batch_size 1, seq length 2500]\tLoss: 3.595268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49800it [1:35:09,  8.68it/s]Train epoch: 1 [batch #49800, batch_size 1, seq length 2500]\tLoss: 4.030414\n",
      "49825it [1:35:12,  8.67it/s]Train epoch: 1 [batch #49825, batch_size 1, seq length 2500]\tLoss: 3.699570\n",
      "49850it [1:35:15,  8.67it/s]Train epoch: 1 [batch #49850, batch_size 1, seq length 2500]\tLoss: 3.837201\n",
      "49875it [1:35:18,  8.67it/s]Train epoch: 1 [batch #49875, batch_size 1, seq length 2500]\tLoss: 3.914132\n",
      "49900it [1:35:21,  8.69it/s]Train epoch: 1 [batch #49900, batch_size 1, seq length 2500]\tLoss: 4.067384\n",
      "49925it [1:35:24,  8.75it/s]Train epoch: 1 [batch #49925, batch_size 1, seq length 2500]\tLoss: 3.662518\n",
      "49950it [1:35:27,  8.69it/s]Train epoch: 1 [batch #49950, batch_size 1, seq length 2500]\tLoss: 3.463134\n",
      "49975it [1:35:30,  8.69it/s]Train epoch: 1 [batch #49975, batch_size 1, seq length 2500]\tLoss: 3.412302\n",
      "50000it [1:35:33,  8.75it/s]Train epoch: 1 [batch #50000, batch_size 1, seq length 2500]\tLoss: 3.673886\n",
      "50025it [1:35:35,  8.72it/s]Train epoch: 1 [batch #50025, batch_size 1, seq length 2500]\tLoss: 3.719830\n",
      "50050it [1:35:38,  8.73it/s]Train epoch: 1 [batch #50050, batch_size 1, seq length 2500]\tLoss: 3.786455\n",
      "50075it [1:35:41,  8.76it/s]Train epoch: 1 [batch #50075, batch_size 1, seq length 2500]\tLoss: 4.014669\n",
      "50100it [1:35:44,  8.63it/s]Train epoch: 1 [batch #50100, batch_size 1, seq length 2500]\tLoss: 4.091304\n",
      "50125it [1:35:47,  8.69it/s]Train epoch: 1 [batch #50125, batch_size 1, seq length 2500]\tLoss: 3.613989\n",
      "50150it [1:35:50,  8.76it/s]Train epoch: 1 [batch #50150, batch_size 1, seq length 2500]\tLoss: 3.984121\n",
      "50175it [1:35:53,  8.68it/s]Train epoch: 1 [batch #50175, batch_size 1, seq length 2500]\tLoss: 4.034742\n",
      "50200it [1:35:56,  8.65it/s]Train epoch: 1 [batch #50200, batch_size 1, seq length 2500]\tLoss: 3.948356\n",
      "50225it [1:35:58,  8.66it/s]Train epoch: 1 [batch #50225, batch_size 1, seq length 2500]\tLoss: 3.901956\n",
      "50250it [1:36:01,  8.77it/s]Train epoch: 1 [batch #50250, batch_size 1, seq length 2500]\tLoss: 3.717602\n",
      "50275it [1:36:04,  8.71it/s]Train epoch: 1 [batch #50275, batch_size 1, seq length 2500]\tLoss: 3.716048\n",
      "50300it [1:36:07,  8.72it/s]Train epoch: 1 [batch #50300, batch_size 1, seq length 2500]\tLoss: 4.083026\n",
      "50325it [1:36:10,  8.72it/s]Train epoch: 1 [batch #50325, batch_size 1, seq length 2500]\tLoss: 3.761922\n",
      "50350it [1:36:13,  8.70it/s]Train epoch: 1 [batch #50350, batch_size 1, seq length 2500]\tLoss: 3.631068\n",
      "50375it [1:36:16,  8.65it/s]Train epoch: 1 [batch #50375, batch_size 1, seq length 2500]\tLoss: 3.700220\n",
      "50400it [1:36:18,  8.69it/s]Train epoch: 1 [batch #50400, batch_size 1, seq length 2500]\tLoss: 3.465035\n",
      "50425it [1:36:21,  8.71it/s]Train epoch: 1 [batch #50425, batch_size 1, seq length 2500]\tLoss: 3.783958\n",
      "50450it [1:36:24,  8.69it/s]Train epoch: 1 [batch #50450, batch_size 1, seq length 2500]\tLoss: 3.294098\n",
      "50475it [1:36:27,  8.63it/s]Train epoch: 1 [batch #50475, batch_size 1, seq length 2500]\tLoss: 3.847517\n",
      "50500it [1:36:30,  8.74it/s]Train epoch: 1 [batch #50500, batch_size 1, seq length 2500]\tLoss: 3.542167\n",
      "50525it [1:36:33,  8.64it/s]Train epoch: 1 [batch #50525, batch_size 1, seq length 2500]\tLoss: 3.848845\n",
      "50550it [1:36:36,  8.67it/s]Train epoch: 1 [batch #50550, batch_size 1, seq length 2500]\tLoss: 3.860563\n",
      "50575it [1:36:39,  8.68it/s]Train epoch: 1 [batch #50575, batch_size 1, seq length 2500]\tLoss: 3.852247\n",
      "50600it [1:36:41,  8.65it/s]Train epoch: 1 [batch #50600, batch_size 1, seq length 2500]\tLoss: 3.968704\n",
      "50625it [1:36:44,  8.76it/s]Train epoch: 1 [batch #50625, batch_size 1, seq length 2500]\tLoss: 3.244428\n",
      "50650it [1:36:47,  8.69it/s]Train epoch: 1 [batch #50650, batch_size 1, seq length 2500]\tLoss: 4.005945\n",
      "50675it [1:36:50,  8.73it/s]Train epoch: 1 [batch #50675, batch_size 1, seq length 2500]\tLoss: 3.920883\n",
      "50700it [1:36:53,  8.76it/s]Train epoch: 1 [batch #50700, batch_size 1, seq length 2500]\tLoss: 3.582953\n",
      "50725it [1:36:56,  8.75it/s]Train epoch: 1 [batch #50725, batch_size 1, seq length 2500]\tLoss: 3.853109\n",
      "50750it [1:36:59,  8.68it/s]Train epoch: 1 [batch #50750, batch_size 1, seq length 2500]\tLoss: 3.759981\n",
      "50775it [1:37:02,  8.72it/s]Train epoch: 1 [batch #50775, batch_size 1, seq length 2500]\tLoss: 3.645392\n",
      "50800it [1:37:04,  8.69it/s]Train epoch: 1 [batch #50800, batch_size 1, seq length 2500]\tLoss: 3.683394\n",
      "50825it [1:37:07,  8.75it/s]Train epoch: 1 [batch #50825, batch_size 1, seq length 2500]\tLoss: 3.628565\n",
      "50850it [1:37:10,  8.64it/s]Train epoch: 1 [batch #50850, batch_size 1, seq length 2500]\tLoss: 3.731174\n",
      "50875it [1:37:13,  8.75it/s]Train epoch: 1 [batch #50875, batch_size 1, seq length 2500]\tLoss: 3.463756\n",
      "50900it [1:37:16,  8.73it/s]Train epoch: 1 [batch #50900, batch_size 1, seq length 2500]\tLoss: 3.843469\n",
      "50925it [1:37:19,  8.67it/s]Train epoch: 1 [batch #50925, batch_size 1, seq length 2500]\tLoss: 3.934879\n",
      "50950it [1:37:22,  8.77it/s]Train epoch: 1 [batch #50950, batch_size 1, seq length 2500]\tLoss: 3.644779\n",
      "50975it [1:37:25,  8.67it/s]Train epoch: 1 [batch #50975, batch_size 1, seq length 2500]\tLoss: 3.223105\n",
      "51000it [1:37:27,  8.74it/s]Train epoch: 1 [batch #51000, batch_size 1, seq length 2500]\tLoss: 3.755343\n",
      "51025it [1:37:30,  8.70it/s]Train epoch: 1 [batch #51025, batch_size 1, seq length 2500]\tLoss: 3.823545\n",
      "51050it [1:37:33,  8.71it/s]Train epoch: 1 [batch #51050, batch_size 1, seq length 2500]\tLoss: 3.756297\n",
      "51075it [1:37:36,  8.73it/s]Train epoch: 1 [batch #51075, batch_size 1, seq length 2500]\tLoss: 3.582365\n",
      "51100it [1:37:39,  8.71it/s]Train epoch: 1 [batch #51100, batch_size 1, seq length 2500]\tLoss: 3.922376\n",
      "51125it [1:37:42,  8.72it/s]Train epoch: 1 [batch #51125, batch_size 1, seq length 2500]\tLoss: 3.753623\n",
      "51150it [1:37:45,  8.68it/s]Train epoch: 1 [batch #51150, batch_size 1, seq length 2500]\tLoss: 3.555641\n",
      "51175it [1:37:47,  8.69it/s]Train epoch: 1 [batch #51175, batch_size 1, seq length 2500]\tLoss: 3.799146\n",
      "51200it [1:37:50,  8.66it/s]Train epoch: 1 [batch #51200, batch_size 1, seq length 2500]\tLoss: 3.885450\n",
      "51225it [1:37:53,  8.67it/s]Train epoch: 1 [batch #51225, batch_size 1, seq length 2500]\tLoss: 3.876150\n",
      "51250it [1:37:56,  8.74it/s]Train epoch: 1 [batch #51250, batch_size 1, seq length 2500]\tLoss: 3.402761\n",
      "51275it [1:37:59,  8.71it/s]Train epoch: 1 [batch #51275, batch_size 1, seq length 2500]\tLoss: 3.788285\n",
      "51300it [1:38:02,  8.65it/s]Train epoch: 1 [batch #51300, batch_size 1, seq length 2500]\tLoss: 3.490418\n",
      "51325it [1:38:05,  8.71it/s]Train epoch: 1 [batch #51325, batch_size 1, seq length 2500]\tLoss: 3.753612\n",
      "51350it [1:38:08,  8.73it/s]Train epoch: 1 [batch #51350, batch_size 1, seq length 2500]\tLoss: 3.872864\n",
      "51375it [1:38:10,  8.75it/s]Train epoch: 1 [batch #51375, batch_size 1, seq length 2500]\tLoss: 3.857405\n",
      "51400it [1:38:13,  8.68it/s]Train epoch: 1 [batch #51400, batch_size 1, seq length 2500]\tLoss: 4.127418\n",
      "51425it [1:38:16,  8.72it/s]Train epoch: 1 [batch #51425, batch_size 1, seq length 2500]\tLoss: 3.954840\n",
      "51450it [1:38:19,  8.74it/s]Train epoch: 1 [batch #51450, batch_size 1, seq length 2500]\tLoss: 3.830349\n",
      "51475it [1:38:22,  8.74it/s]Train epoch: 1 [batch #51475, batch_size 1, seq length 2500]\tLoss: 3.709196\n",
      "51500it [1:38:25,  8.67it/s]Train epoch: 1 [batch #51500, batch_size 1, seq length 2500]\tLoss: 3.916737\n",
      "51525it [1:38:28,  8.70it/s]Train epoch: 1 [batch #51525, batch_size 1, seq length 2500]\tLoss: 3.711349\n",
      "51550it [1:38:31,  8.75it/s]Train epoch: 1 [batch #51550, batch_size 1, seq length 2500]\tLoss: 3.758902\n",
      "51575it [1:38:33,  8.73it/s]Train epoch: 1 [batch #51575, batch_size 1, seq length 2500]\tLoss: 3.634162\n",
      "51600it [1:38:36,  8.68it/s]Train epoch: 1 [batch #51600, batch_size 1, seq length 2500]\tLoss: 3.654201\n",
      "51625it [1:38:39,  8.70it/s]Train epoch: 1 [batch #51625, batch_size 1, seq length 2500]\tLoss: 4.205519\n",
      "51650it [1:38:42,  8.75it/s]Train epoch: 1 [batch #51650, batch_size 1, seq length 2500]\tLoss: 3.285238\n",
      "51675it [1:38:45,  8.66it/s]Train epoch: 1 [batch #51675, batch_size 1, seq length 2500]\tLoss: 4.000058\n",
      "51700it [1:38:48,  8.72it/s]Train epoch: 1 [batch #51700, batch_size 1, seq length 2500]\tLoss: 3.684649\n",
      "51725it [1:38:51,  8.71it/s]Train epoch: 1 [batch #51725, batch_size 1, seq length 2500]\tLoss: 3.742535\n",
      "51750it [1:38:54,  8.76it/s]Train epoch: 1 [batch #51750, batch_size 1, seq length 2500]\tLoss: 3.935127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51775it [1:38:56,  8.66it/s]Train epoch: 1 [batch #51775, batch_size 1, seq length 2500]\tLoss: 3.981422\n",
      "51800it [1:38:59,  8.74it/s]Train epoch: 1 [batch #51800, batch_size 1, seq length 2500]\tLoss: 3.624950\n",
      "51825it [1:39:02,  8.67it/s]Train epoch: 1 [batch #51825, batch_size 1, seq length 2500]\tLoss: 3.763153\n",
      "51850it [1:39:05,  8.73it/s]Train epoch: 1 [batch #51850, batch_size 1, seq length 2500]\tLoss: 3.585386\n",
      "51875it [1:39:08,  8.73it/s]Train epoch: 1 [batch #51875, batch_size 1, seq length 2500]\tLoss: 4.001599\n",
      "51900it [1:39:11,  8.70it/s]Train epoch: 1 [batch #51900, batch_size 1, seq length 2500]\tLoss: 3.696651\n",
      "51925it [1:39:14,  8.76it/s]Train epoch: 1 [batch #51925, batch_size 1, seq length 2500]\tLoss: 3.956711\n",
      "51950it [1:39:17,  8.72it/s]Train epoch: 1 [batch #51950, batch_size 1, seq length 2500]\tLoss: 3.794947\n",
      "51975it [1:39:19,  8.71it/s]Train epoch: 1 [batch #51975, batch_size 1, seq length 2500]\tLoss: 3.784581\n",
      "52000it [1:39:22,  8.69it/s]Train epoch: 1 [batch #52000, batch_size 1, seq length 2500]\tLoss: 3.512126\n",
      "52025it [1:39:25,  8.74it/s]Train epoch: 1 [batch #52025, batch_size 1, seq length 2500]\tLoss: 3.863421\n",
      "52050it [1:39:28,  8.68it/s]Train epoch: 1 [batch #52050, batch_size 1, seq length 2500]\tLoss: 3.987762\n",
      "52075it [1:39:31,  8.62it/s]Train epoch: 1 [batch #52075, batch_size 1, seq length 2500]\tLoss: 4.176171\n",
      "52100it [1:39:34,  8.73it/s]Train epoch: 1 [batch #52100, batch_size 1, seq length 2500]\tLoss: 3.725421\n",
      "52125it [1:39:37,  8.74it/s]Train epoch: 1 [batch #52125, batch_size 1, seq length 2500]\tLoss: 3.910918\n",
      "52150it [1:39:39,  8.73it/s]Train epoch: 1 [batch #52150, batch_size 1, seq length 2500]\tLoss: 4.025467\n",
      "52175it [1:39:42,  8.73it/s]Train epoch: 1 [batch #52175, batch_size 1, seq length 2500]\tLoss: 4.003516\n",
      "52200it [1:39:45,  8.69it/s]Train epoch: 1 [batch #52200, batch_size 1, seq length 2500]\tLoss: 3.783550\n",
      "52225it [1:39:48,  8.67it/s]Train epoch: 1 [batch #52225, batch_size 1, seq length 2500]\tLoss: 3.654139\n",
      "52250it [1:39:51,  8.75it/s]Train epoch: 1 [batch #52250, batch_size 1, seq length 2500]\tLoss: 3.517852\n",
      "52275it [1:39:54,  8.71it/s]Train epoch: 1 [batch #52275, batch_size 1, seq length 2500]\tLoss: 3.815249\n",
      "52300it [1:39:57,  8.69it/s]Train epoch: 1 [batch #52300, batch_size 1, seq length 2500]\tLoss: 3.761737\n",
      "52325it [1:40:00,  8.73it/s]Train epoch: 1 [batch #52325, batch_size 1, seq length 2500]\tLoss: 3.784717\n",
      "52350it [1:40:02,  8.65it/s]Train epoch: 1 [batch #52350, batch_size 1, seq length 2500]\tLoss: 3.323373\n",
      "52375it [1:40:05,  8.74it/s]Train epoch: 1 [batch #52375, batch_size 1, seq length 2500]\tLoss: 3.615929\n",
      "52400it [1:40:08,  8.70it/s]Train epoch: 1 [batch #52400, batch_size 1, seq length 2500]\tLoss: 3.740613\n",
      "52425it [1:40:11,  8.72it/s]Train epoch: 1 [batch #52425, batch_size 1, seq length 2500]\tLoss: 3.704891\n",
      "52450it [1:40:14,  8.70it/s]Train epoch: 1 [batch #52450, batch_size 1, seq length 2500]\tLoss: 3.575577\n",
      "52465it [1:40:16,  8.72it/s]\n",
      "Epoch 1: 4.0328\n",
      "0it [00:00, ?it/s]Train epoch: 2 [batch #0, batch_size 1, seq length 2500]\tLoss: 3.803342\n",
      "25it [00:02,  8.75it/s]Train epoch: 2 [batch #25, batch_size 1, seq length 2500]\tLoss: 3.856383\n",
      "50it [00:05,  8.68it/s]Train epoch: 2 [batch #50, batch_size 1, seq length 2500]\tLoss: 3.732160\n",
      "75it [00:08,  8.66it/s]Train epoch: 2 [batch #75, batch_size 1, seq length 2500]\tLoss: 4.004438\n",
      "100it [00:11,  8.64it/s]Train epoch: 2 [batch #100, batch_size 1, seq length 2500]\tLoss: 3.913183\n",
      "125it [00:14,  8.68it/s]Train epoch: 2 [batch #125, batch_size 1, seq length 2500]\tLoss: 3.441464\n",
      "150it [00:17,  8.70it/s]Train epoch: 2 [batch #150, batch_size 1, seq length 2500]\tLoss: 3.477710\n",
      "175it [00:20,  8.67it/s]Train epoch: 2 [batch #175, batch_size 1, seq length 2500]\tLoss: 3.754174\n",
      "200it [00:22,  8.70it/s]Train epoch: 2 [batch #200, batch_size 1, seq length 2500]\tLoss: 3.887441\n",
      "225it [00:25,  8.65it/s]Train epoch: 2 [batch #225, batch_size 1, seq length 2500]\tLoss: 3.662942\n",
      "250it [00:28,  8.72it/s]Train epoch: 2 [batch #250, batch_size 1, seq length 2500]\tLoss: 3.742373\n",
      "275it [00:31,  8.76it/s]Train epoch: 2 [batch #275, batch_size 1, seq length 2500]\tLoss: 3.850740\n",
      "300it [00:34,  8.68it/s]Train epoch: 2 [batch #300, batch_size 1, seq length 2500]\tLoss: 3.988631\n",
      "325it [00:37,  8.70it/s]Train epoch: 2 [batch #325, batch_size 1, seq length 2500]\tLoss: 3.987786\n",
      "350it [00:40,  8.74it/s]Train epoch: 2 [batch #350, batch_size 1, seq length 2500]\tLoss: 3.778189\n",
      "375it [00:43,  8.65it/s]Train epoch: 2 [batch #375, batch_size 1, seq length 2500]\tLoss: 4.042548\n",
      "400it [00:45,  8.70it/s]Train epoch: 2 [batch #400, batch_size 1, seq length 2500]\tLoss: 3.753179\n",
      "425it [00:48,  8.66it/s]Train epoch: 2 [batch #425, batch_size 1, seq length 2500]\tLoss: 3.878836\n",
      "450it [00:51,  8.67it/s]Train epoch: 2 [batch #450, batch_size 1, seq length 2500]\tLoss: 3.792537\n",
      "475it [00:54,  8.71it/s]Train epoch: 2 [batch #475, batch_size 1, seq length 2500]\tLoss: 3.951943\n",
      "500it [00:57,  8.69it/s]Train epoch: 2 [batch #500, batch_size 1, seq length 2500]\tLoss: 3.606946\n",
      "525it [01:00,  8.67it/s]Train epoch: 2 [batch #525, batch_size 1, seq length 2500]\tLoss: 3.713027\n",
      "550it [01:03,  8.70it/s]Train epoch: 2 [batch #550, batch_size 1, seq length 2500]\tLoss: 3.801465\n",
      "575it [01:06,  8.65it/s]Train epoch: 2 [batch #575, batch_size 1, seq length 2500]\tLoss: 3.514907\n",
      "600it [01:08,  8.71it/s]Train epoch: 2 [batch #600, batch_size 1, seq length 2500]\tLoss: 3.395627\n",
      "625it [01:11,  8.74it/s]Train epoch: 2 [batch #625, batch_size 1, seq length 2500]\tLoss: 3.776134\n",
      "650it [01:14,  8.73it/s]Train epoch: 2 [batch #650, batch_size 1, seq length 2500]\tLoss: 3.704773\n",
      "675it [01:17,  8.75it/s]Train epoch: 2 [batch #675, batch_size 1, seq length 2500]\tLoss: 3.551618\n",
      "700it [01:20,  8.69it/s]Train epoch: 2 [batch #700, batch_size 1, seq length 2500]\tLoss: 3.970202\n",
      "725it [01:23,  8.71it/s]Train epoch: 2 [batch #725, batch_size 1, seq length 2500]\tLoss: 3.603460\n",
      "750it [01:26,  8.71it/s]Train epoch: 2 [batch #750, batch_size 1, seq length 2500]\tLoss: 3.959990\n",
      "775it [01:29,  8.68it/s]Train epoch: 2 [batch #775, batch_size 1, seq length 2500]\tLoss: 3.906051\n",
      "800it [01:31,  8.58it/s]Train epoch: 2 [batch #800, batch_size 1, seq length 2500]\tLoss: 4.005990\n",
      "825it [01:34,  8.67it/s]Train epoch: 2 [batch #825, batch_size 1, seq length 2500]\tLoss: 3.895863\n",
      "850it [01:37,  8.72it/s]Train epoch: 2 [batch #850, batch_size 1, seq length 2500]\tLoss: 3.386623\n",
      "875it [01:40,  8.76it/s]Train epoch: 2 [batch #875, batch_size 1, seq length 2500]\tLoss: 3.879692\n",
      "900it [01:43,  8.67it/s]Train epoch: 2 [batch #900, batch_size 1, seq length 2500]\tLoss: 3.855936\n",
      "925it [01:46,  8.70it/s]Train epoch: 2 [batch #925, batch_size 1, seq length 2500]\tLoss: 3.535606\n",
      "950it [01:49,  8.71it/s]Train epoch: 2 [batch #950, batch_size 1, seq length 2500]\tLoss: 3.873696\n",
      "975it [01:52,  8.75it/s]Train epoch: 2 [batch #975, batch_size 1, seq length 2500]\tLoss: 3.676661\n",
      "1000it [01:54,  8.74it/s]Train epoch: 2 [batch #1000, batch_size 1, seq length 2500]\tLoss: 3.746292\n",
      "1025it [01:57,  8.71it/s]Train epoch: 2 [batch #1025, batch_size 1, seq length 2500]\tLoss: 3.717451\n",
      "1050it [02:00,  8.60it/s]Train epoch: 2 [batch #1050, batch_size 1, seq length 2500]\tLoss: 3.852202\n",
      "1075it [02:03,  8.71it/s]Train epoch: 2 [batch #1075, batch_size 1, seq length 2500]\tLoss: 3.688186\n",
      "1100it [02:06,  8.73it/s]Train epoch: 2 [batch #1100, batch_size 1, seq length 2500]\tLoss: 3.837264\n",
      "1125it [02:09,  8.74it/s]Train epoch: 2 [batch #1125, batch_size 1, seq length 2500]\tLoss: 4.114137\n",
      "1150it [02:12,  8.71it/s]Train epoch: 2 [batch #1150, batch_size 1, seq length 2500]\tLoss: 3.627371\n",
      "1175it [02:15,  8.75it/s]Train epoch: 2 [batch #1175, batch_size 1, seq length 2500]\tLoss: 3.730862\n",
      "1200it [02:17,  8.72it/s]Train epoch: 2 [batch #1200, batch_size 1, seq length 2500]\tLoss: 4.007352\n",
      "1225it [02:20,  8.64it/s]Train epoch: 2 [batch #1225, batch_size 1, seq length 2500]\tLoss: 3.809575\n",
      "1250it [02:23,  8.65it/s]Train epoch: 2 [batch #1250, batch_size 1, seq length 2500]\tLoss: 3.480305\n",
      "1275it [02:26,  8.70it/s]Train epoch: 2 [batch #1275, batch_size 1, seq length 2500]\tLoss: 3.599578\n",
      "1300it [02:29,  8.72it/s]Train epoch: 2 [batch #1300, batch_size 1, seq length 2500]\tLoss: 3.884748\n",
      "1325it [02:32,  8.74it/s]Train epoch: 2 [batch #1325, batch_size 1, seq length 2500]\tLoss: 3.716314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350it [02:35,  8.74it/s]Train epoch: 2 [batch #1350, batch_size 1, seq length 2500]\tLoss: 3.492120\n",
      "1375it [02:38,  8.76it/s]Train epoch: 2 [batch #1375, batch_size 1, seq length 2500]\tLoss: 3.721943\n",
      "1400it [02:40,  8.73it/s]Train epoch: 2 [batch #1400, batch_size 1, seq length 2500]\tLoss: 4.037695\n",
      "1425it [02:43,  8.72it/s]Train epoch: 2 [batch #1425, batch_size 1, seq length 2500]\tLoss: 3.897647\n",
      "1450it [02:46,  8.70it/s]Train epoch: 2 [batch #1450, batch_size 1, seq length 2500]\tLoss: 3.599718\n",
      "1475it [02:49,  8.68it/s]Train epoch: 2 [batch #1475, batch_size 1, seq length 2500]\tLoss: 3.960217\n",
      "1500it [02:52,  8.68it/s]Train epoch: 2 [batch #1500, batch_size 1, seq length 2500]\tLoss: 3.713136\n",
      "1525it [02:55,  8.66it/s]Train epoch: 2 [batch #1525, batch_size 1, seq length 2500]\tLoss: 3.637207\n",
      "1550it [02:58,  8.73it/s]Train epoch: 2 [batch #1550, batch_size 1, seq length 2500]\tLoss: 3.534902\n",
      "1575it [03:01,  8.71it/s]Train epoch: 2 [batch #1575, batch_size 1, seq length 2500]\tLoss: 3.544875\n",
      "1600it [03:03,  8.69it/s]Train epoch: 2 [batch #1600, batch_size 1, seq length 2500]\tLoss: 3.669597\n",
      "1625it [03:06,  8.66it/s]Train epoch: 2 [batch #1625, batch_size 1, seq length 2500]\tLoss: 3.556976\n",
      "1650it [03:09,  8.71it/s]Train epoch: 2 [batch #1650, batch_size 1, seq length 2500]\tLoss: 3.708569\n",
      "1675it [03:12,  8.72it/s]Train epoch: 2 [batch #1675, batch_size 1, seq length 2500]\tLoss: 3.778408\n",
      "1700it [03:15,  8.75it/s]Train epoch: 2 [batch #1700, batch_size 1, seq length 2500]\tLoss: 3.776866\n",
      "1725it [03:18,  8.68it/s]Train epoch: 2 [batch #1725, batch_size 1, seq length 2500]\tLoss: 3.851666\n",
      "1750it [03:21,  8.71it/s]Train epoch: 2 [batch #1750, batch_size 1, seq length 2500]\tLoss: 3.766155\n",
      "1775it [03:24,  8.67it/s]Train epoch: 2 [batch #1775, batch_size 1, seq length 2500]\tLoss: 3.507716\n",
      "1800it [03:26,  8.73it/s]Train epoch: 2 [batch #1800, batch_size 1, seq length 2500]\tLoss: 3.706918\n",
      "1825it [03:29,  8.73it/s]Train epoch: 2 [batch #1825, batch_size 1, seq length 2500]\tLoss: 3.712688\n",
      "1850it [03:32,  8.69it/s]Train epoch: 2 [batch #1850, batch_size 1, seq length 2500]\tLoss: 3.870533\n",
      "1875it [03:35,  8.74it/s]Train epoch: 2 [batch #1875, batch_size 1, seq length 2500]\tLoss: 3.544768\n",
      "1900it [03:38,  8.76it/s]Train epoch: 2 [batch #1900, batch_size 1, seq length 2500]\tLoss: 3.520539\n",
      "1925it [03:41,  8.73it/s]Train epoch: 2 [batch #1925, batch_size 1, seq length 2500]\tLoss: 3.891105\n",
      "1950it [03:44,  8.74it/s]Train epoch: 2 [batch #1950, batch_size 1, seq length 2500]\tLoss: 3.548843\n",
      "1975it [03:47,  8.67it/s]Train epoch: 2 [batch #1975, batch_size 1, seq length 2500]\tLoss: 3.725586\n",
      "2000it [03:49,  8.69it/s]Train epoch: 2 [batch #2000, batch_size 1, seq length 2500]\tLoss: 3.742801\n",
      "2025it [03:52,  8.69it/s]Train epoch: 2 [batch #2025, batch_size 1, seq length 2500]\tLoss: 3.606113\n",
      "2050it [03:55,  8.68it/s]Train epoch: 2 [batch #2050, batch_size 1, seq length 2500]\tLoss: 3.645890\n",
      "2075it [03:58,  8.68it/s]Train epoch: 2 [batch #2075, batch_size 1, seq length 2500]\tLoss: 3.850155\n",
      "2100it [04:01,  8.68it/s]Train epoch: 2 [batch #2100, batch_size 1, seq length 2500]\tLoss: 3.742724\n",
      "2125it [04:04,  8.69it/s]Train epoch: 2 [batch #2125, batch_size 1, seq length 2500]\tLoss: 3.603639\n",
      "2150it [04:07,  8.69it/s]Train epoch: 2 [batch #2150, batch_size 1, seq length 2500]\tLoss: 3.923145\n",
      "2175it [04:10,  8.64it/s]Train epoch: 2 [batch #2175, batch_size 1, seq length 2500]\tLoss: 3.478607\n",
      "2200it [04:12,  8.66it/s]Train epoch: 2 [batch #2200, batch_size 1, seq length 2500]\tLoss: 3.463229\n",
      "2225it [04:15,  8.70it/s]Train epoch: 2 [batch #2225, batch_size 1, seq length 2500]\tLoss: 3.378696\n",
      "2250it [04:18,  8.73it/s]Train epoch: 2 [batch #2250, batch_size 1, seq length 2500]\tLoss: 3.925527\n",
      "2275it [04:21,  8.73it/s]Train epoch: 2 [batch #2275, batch_size 1, seq length 2500]\tLoss: 3.717839\n",
      "2300it [04:24,  8.64it/s]Train epoch: 2 [batch #2300, batch_size 1, seq length 2500]\tLoss: 3.763047\n",
      "2325it [04:27,  8.74it/s]Train epoch: 2 [batch #2325, batch_size 1, seq length 2500]\tLoss: 3.988493\n",
      "2350it [04:30,  8.69it/s]Train epoch: 2 [batch #2350, batch_size 1, seq length 2500]\tLoss: 3.782477\n",
      "2375it [04:32,  8.76it/s]Train epoch: 2 [batch #2375, batch_size 1, seq length 2500]\tLoss: 3.821773\n",
      "2400it [04:35,  8.70it/s]Train epoch: 2 [batch #2400, batch_size 1, seq length 2500]\tLoss: 3.859634\n",
      "2425it [04:38,  8.72it/s]Train epoch: 2 [batch #2425, batch_size 1, seq length 2500]\tLoss: 3.540147\n",
      "2450it [04:41,  8.68it/s]Train epoch: 2 [batch #2450, batch_size 1, seq length 2500]\tLoss: 3.742952\n",
      "2475it [04:44,  8.72it/s]Train epoch: 2 [batch #2475, batch_size 1, seq length 2500]\tLoss: 4.239368\n",
      "2500it [04:47,  8.71it/s]Train epoch: 2 [batch #2500, batch_size 1, seq length 2500]\tLoss: 4.072016\n",
      "2525it [04:50,  8.62it/s]Train epoch: 2 [batch #2525, batch_size 1, seq length 2500]\tLoss: 3.803169\n",
      "2550it [04:53,  8.73it/s]Train epoch: 2 [batch #2550, batch_size 1, seq length 2500]\tLoss: 3.710468\n",
      "2575it [04:55,  8.64it/s]Train epoch: 2 [batch #2575, batch_size 1, seq length 2500]\tLoss: 3.915991\n",
      "2600it [04:58,  8.67it/s]Train epoch: 2 [batch #2600, batch_size 1, seq length 2500]\tLoss: 3.749494\n",
      "2625it [05:01,  8.71it/s]Train epoch: 2 [batch #2625, batch_size 1, seq length 2500]\tLoss: 3.991697\n",
      "2650it [05:04,  8.67it/s]Train epoch: 2 [batch #2650, batch_size 1, seq length 2500]\tLoss: 3.899215\n",
      "2675it [05:07,  8.44it/s]Train epoch: 2 [batch #2675, batch_size 1, seq length 2500]\tLoss: 3.597811\n",
      "2700it [05:10,  8.77it/s]Train epoch: 2 [batch #2700, batch_size 1, seq length 2500]\tLoss: 4.028639\n",
      "2725it [05:13,  8.66it/s]Train epoch: 2 [batch #2725, batch_size 1, seq length 2500]\tLoss: 3.824094\n",
      "2750it [05:16,  8.70it/s]Train epoch: 2 [batch #2750, batch_size 1, seq length 2500]\tLoss: 3.560560\n",
      "2775it [05:19,  8.62it/s]Train epoch: 2 [batch #2775, batch_size 1, seq length 2500]\tLoss: 3.697838\n",
      "2800it [05:21,  8.69it/s]Train epoch: 2 [batch #2800, batch_size 1, seq length 2500]\tLoss: 3.702697\n",
      "2825it [05:24,  8.65it/s]Train epoch: 2 [batch #2825, batch_size 1, seq length 2500]\tLoss: 3.792922\n",
      "2850it [05:27,  8.74it/s]Train epoch: 2 [batch #2850, batch_size 1, seq length 2500]\tLoss: 3.869520\n",
      "2875it [05:30,  8.74it/s]Train epoch: 2 [batch #2875, batch_size 1, seq length 2500]\tLoss: 3.423380\n",
      "2900it [05:33,  8.70it/s]Train epoch: 2 [batch #2900, batch_size 1, seq length 2500]\tLoss: 3.821227\n",
      "2925it [05:36,  8.73it/s]Train epoch: 2 [batch #2925, batch_size 1, seq length 2500]\tLoss: 3.520646\n",
      "2950it [05:39,  8.69it/s]Train epoch: 2 [batch #2950, batch_size 1, seq length 2500]\tLoss: 3.674325\n",
      "2975it [05:42,  8.74it/s]Train epoch: 2 [batch #2975, batch_size 1, seq length 2500]\tLoss: 3.882114\n",
      "3000it [05:44,  8.64it/s]Train epoch: 2 [batch #3000, batch_size 1, seq length 2500]\tLoss: 3.576021\n",
      "3025it [05:47,  8.64it/s]Train epoch: 2 [batch #3025, batch_size 1, seq length 2500]\tLoss: 3.526543\n",
      "3050it [05:50,  8.69it/s]Train epoch: 2 [batch #3050, batch_size 1, seq length 2500]\tLoss: 3.509744\n",
      "3075it [05:53,  8.69it/s]Train epoch: 2 [batch #3075, batch_size 1, seq length 2500]\tLoss: 3.317640\n",
      "3100it [05:56,  8.70it/s]Train epoch: 2 [batch #3100, batch_size 1, seq length 2500]\tLoss: 3.667110\n",
      "3125it [05:59,  8.63it/s]Train epoch: 2 [batch #3125, batch_size 1, seq length 2500]\tLoss: 3.845974\n",
      "3150it [06:02,  8.67it/s]Train epoch: 2 [batch #3150, batch_size 1, seq length 2500]\tLoss: 3.820896\n",
      "3175it [06:05,  8.75it/s]Train epoch: 2 [batch #3175, batch_size 1, seq length 2500]\tLoss: 3.404264\n",
      "3200it [06:07,  8.68it/s]Train epoch: 2 [batch #3200, batch_size 1, seq length 2500]\tLoss: 3.877105\n",
      "3225it [06:10,  8.65it/s]Train epoch: 2 [batch #3225, batch_size 1, seq length 2500]\tLoss: 3.948626\n",
      "3250it [06:13,  8.71it/s]Train epoch: 2 [batch #3250, batch_size 1, seq length 2500]\tLoss: 3.766848\n",
      "3275it [06:16,  8.69it/s]Train epoch: 2 [batch #3275, batch_size 1, seq length 2500]\tLoss: 3.599919\n",
      "3300it [06:19,  8.74it/s]Train epoch: 2 [batch #3300, batch_size 1, seq length 2500]\tLoss: 3.833130\n",
      "3325it [06:22,  8.69it/s]Train epoch: 2 [batch #3325, batch_size 1, seq length 2500]\tLoss: 4.073261\n",
      "3350it [06:25,  8.64it/s]Train epoch: 2 [batch #3350, batch_size 1, seq length 2500]\tLoss: 3.583888\n",
      "3375it [06:28,  8.69it/s]Train epoch: 2 [batch #3375, batch_size 1, seq length 2500]\tLoss: 4.215664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400it [06:30,  8.77it/s]Train epoch: 2 [batch #3400, batch_size 1, seq length 2500]\tLoss: 3.622709\n",
      "3425it [06:33,  8.65it/s]Train epoch: 2 [batch #3425, batch_size 1, seq length 2500]\tLoss: 3.903265\n",
      "3450it [06:36,  8.63it/s]Train epoch: 2 [batch #3450, batch_size 1, seq length 2500]\tLoss: 3.588281\n",
      "3475it [06:39,  8.66it/s]Train epoch: 2 [batch #3475, batch_size 1, seq length 2500]\tLoss: 3.448420\n",
      "3500it [06:42,  8.69it/s]Train epoch: 2 [batch #3500, batch_size 1, seq length 2500]\tLoss: 3.420777\n",
      "3525it [06:45,  8.75it/s]Train epoch: 2 [batch #3525, batch_size 1, seq length 2500]\tLoss: 3.921030\n",
      "3550it [06:48,  8.62it/s]Train epoch: 2 [batch #3550, batch_size 1, seq length 2500]\tLoss: 3.521313\n",
      "3575it [06:51,  8.73it/s]Train epoch: 2 [batch #3575, batch_size 1, seq length 2500]\tLoss: 3.452945\n",
      "3600it [06:53,  8.73it/s]Train epoch: 2 [batch #3600, batch_size 1, seq length 2500]\tLoss: 3.833765\n",
      "3625it [06:56,  8.65it/s]Train epoch: 2 [batch #3625, batch_size 1, seq length 2500]\tLoss: 3.774481\n",
      "3650it [06:59,  8.62it/s]Train epoch: 2 [batch #3650, batch_size 1, seq length 2500]\tLoss: 3.772845\n",
      "3675it [07:02,  8.72it/s]Train epoch: 2 [batch #3675, batch_size 1, seq length 2500]\tLoss: 3.589996\n",
      "3700it [07:05,  8.76it/s]Train epoch: 2 [batch #3700, batch_size 1, seq length 2500]\tLoss: 3.910268\n",
      "3725it [07:08,  8.58it/s]Train epoch: 2 [batch #3725, batch_size 1, seq length 2500]\tLoss: 3.789964\n",
      "3750it [07:11,  8.72it/s]Train epoch: 2 [batch #3750, batch_size 1, seq length 2500]\tLoss: 4.011819\n",
      "3775it [07:14,  8.70it/s]Train epoch: 2 [batch #3775, batch_size 1, seq length 2500]\tLoss: 3.621674\n",
      "3800it [07:16,  8.73it/s]Train epoch: 2 [batch #3800, batch_size 1, seq length 2500]\tLoss: 3.493465\n",
      "3825it [07:19,  8.66it/s]Train epoch: 2 [batch #3825, batch_size 1, seq length 2500]\tLoss: 3.364814\n",
      "3850it [07:22,  8.68it/s]Train epoch: 2 [batch #3850, batch_size 1, seq length 2500]\tLoss: 3.862532\n",
      "3875it [07:25,  8.76it/s]Train epoch: 2 [batch #3875, batch_size 1, seq length 2500]\tLoss: 3.662071\n",
      "3900it [07:28,  8.75it/s]Train epoch: 2 [batch #3900, batch_size 1, seq length 2500]\tLoss: 3.700245\n",
      "3925it [07:31,  8.75it/s]Train epoch: 2 [batch #3925, batch_size 1, seq length 2500]\tLoss: 3.326648\n",
      "3950it [07:34,  8.73it/s]Train epoch: 2 [batch #3950, batch_size 1, seq length 2500]\tLoss: 3.980286\n",
      "3975it [07:37,  8.68it/s]Train epoch: 2 [batch #3975, batch_size 1, seq length 2500]\tLoss: 3.662999\n",
      "4000it [07:39,  8.77it/s]Train epoch: 2 [batch #4000, batch_size 1, seq length 2500]\tLoss: 3.875239\n",
      "4025it [07:42,  8.65it/s]Train epoch: 2 [batch #4025, batch_size 1, seq length 2500]\tLoss: 3.800281\n",
      "4050it [07:45,  8.70it/s]Train epoch: 2 [batch #4050, batch_size 1, seq length 2500]\tLoss: 3.869699\n",
      "4075it [07:48,  8.70it/s]Train epoch: 2 [batch #4075, batch_size 1, seq length 2500]\tLoss: 3.487925\n",
      "4100it [07:51,  8.69it/s]Train epoch: 2 [batch #4100, batch_size 1, seq length 2500]\tLoss: 3.577632\n",
      "4125it [07:54,  8.76it/s]Train epoch: 2 [batch #4125, batch_size 1, seq length 2500]\tLoss: 3.760792\n",
      "4150it [07:57,  8.67it/s]Train epoch: 2 [batch #4150, batch_size 1, seq length 2500]\tLoss: 3.775092\n",
      "4175it [08:00,  8.67it/s]Train epoch: 2 [batch #4175, batch_size 1, seq length 2500]\tLoss: 3.889865\n",
      "4200it [08:02,  8.68it/s]Train epoch: 2 [batch #4200, batch_size 1, seq length 2500]\tLoss: 3.669175\n",
      "4225it [08:05,  8.69it/s]Train epoch: 2 [batch #4225, batch_size 1, seq length 2500]\tLoss: 3.866196\n",
      "4250it [08:08,  8.62it/s]Train epoch: 2 [batch #4250, batch_size 1, seq length 2500]\tLoss: 3.679525\n",
      "4275it [08:11,  8.75it/s]Train epoch: 2 [batch #4275, batch_size 1, seq length 2500]\tLoss: 3.540430\n",
      "4300it [08:14,  8.73it/s]Train epoch: 2 [batch #4300, batch_size 1, seq length 2500]\tLoss: 3.717450\n",
      "4325it [08:17,  8.72it/s]Train epoch: 2 [batch #4325, batch_size 1, seq length 2500]\tLoss: 3.953556\n",
      "4350it [08:20,  8.76it/s]Train epoch: 2 [batch #4350, batch_size 1, seq length 2500]\tLoss: 3.787423\n",
      "4375it [08:23,  8.68it/s]Train epoch: 2 [batch #4375, batch_size 1, seq length 2500]\tLoss: 4.065369\n",
      "4400it [08:25,  8.73it/s]Train epoch: 2 [batch #4400, batch_size 1, seq length 2500]\tLoss: 3.775550\n",
      "4425it [08:28,  8.67it/s]Train epoch: 2 [batch #4425, batch_size 1, seq length 2500]\tLoss: 3.713122\n",
      "4450it [08:31,  8.59it/s]Train epoch: 2 [batch #4450, batch_size 1, seq length 2500]\tLoss: 4.052555\n",
      "4475it [08:34,  8.66it/s]Train epoch: 2 [batch #4475, batch_size 1, seq length 2500]\tLoss: 3.811881\n",
      "4500it [08:37,  8.75it/s]Train epoch: 2 [batch #4500, batch_size 1, seq length 2500]\tLoss: 3.974293\n",
      "4525it [08:40,  8.74it/s]Train epoch: 2 [batch #4525, batch_size 1, seq length 2500]\tLoss: 4.184024\n",
      "4550it [08:43,  8.73it/s]Train epoch: 2 [batch #4550, batch_size 1, seq length 2500]\tLoss: 3.922092\n",
      "4575it [08:46,  8.69it/s]Train epoch: 2 [batch #4575, batch_size 1, seq length 2500]\tLoss: 3.881663\n",
      "4600it [08:48,  8.73it/s]Train epoch: 2 [batch #4600, batch_size 1, seq length 2500]\tLoss: 4.150722\n",
      "4625it [08:51,  8.65it/s]Train epoch: 2 [batch #4625, batch_size 1, seq length 2500]\tLoss: 3.721855\n",
      "4650it [08:54,  8.66it/s]Train epoch: 2 [batch #4650, batch_size 1, seq length 2500]\tLoss: 3.713718\n",
      "4675it [08:57,  8.71it/s]Train epoch: 2 [batch #4675, batch_size 1, seq length 2500]\tLoss: 3.638481\n",
      "4700it [09:00,  8.69it/s]Train epoch: 2 [batch #4700, batch_size 1, seq length 2500]\tLoss: 3.805430\n",
      "4725it [09:03,  8.63it/s]Train epoch: 2 [batch #4725, batch_size 1, seq length 2500]\tLoss: 3.449194\n",
      "4750it [09:06,  8.73it/s]Train epoch: 2 [batch #4750, batch_size 1, seq length 2500]\tLoss: 3.685308\n",
      "4775it [09:09,  8.59it/s]Train epoch: 2 [batch #4775, batch_size 1, seq length 2500]\tLoss: 3.983199\n",
      "4800it [09:11,  8.71it/s]Train epoch: 2 [batch #4800, batch_size 1, seq length 2500]\tLoss: 3.790495\n",
      "4825it [09:14,  8.67it/s]Train epoch: 2 [batch #4825, batch_size 1, seq length 2500]\tLoss: 3.958364\n",
      "4850it [09:17,  8.77it/s]Train epoch: 2 [batch #4850, batch_size 1, seq length 2500]\tLoss: 3.739667\n",
      "4875it [09:20,  8.63it/s]Train epoch: 2 [batch #4875, batch_size 1, seq length 2500]\tLoss: 3.595093\n",
      "4900it [09:23,  8.74it/s]Train epoch: 2 [batch #4900, batch_size 1, seq length 2500]\tLoss: 4.202018\n",
      "4925it [09:26,  8.62it/s]Train epoch: 2 [batch #4925, batch_size 1, seq length 2500]\tLoss: 3.851104\n",
      "4950it [09:29,  8.69it/s]Train epoch: 2 [batch #4950, batch_size 1, seq length 2500]\tLoss: 3.903163\n",
      "4975it [09:32,  8.69it/s]Train epoch: 2 [batch #4975, batch_size 1, seq length 2500]\tLoss: 3.869989\n",
      "5000it [09:34,  8.69it/s]Train epoch: 2 [batch #5000, batch_size 1, seq length 2500]\tLoss: 3.683562\n",
      "5025it [09:37,  8.69it/s]Train epoch: 2 [batch #5025, batch_size 1, seq length 2500]\tLoss: 3.740332\n",
      "5050it [09:40,  8.69it/s]Train epoch: 2 [batch #5050, batch_size 1, seq length 2500]\tLoss: 3.660671\n",
      "5075it [09:43,  8.75it/s]Train epoch: 2 [batch #5075, batch_size 1, seq length 2500]\tLoss: 3.742325\n",
      "5100it [09:46,  8.75it/s]Train epoch: 2 [batch #5100, batch_size 1, seq length 2500]\tLoss: 3.696360\n",
      "5125it [09:49,  8.73it/s]Train epoch: 2 [batch #5125, batch_size 1, seq length 2500]\tLoss: 3.615931\n",
      "5150it [09:52,  8.69it/s]Train epoch: 2 [batch #5150, batch_size 1, seq length 2500]\tLoss: 3.718435\n",
      "5175it [09:55,  8.64it/s]Train epoch: 2 [batch #5175, batch_size 1, seq length 2500]\tLoss: 3.980191\n",
      "5200it [09:57,  8.67it/s]Train epoch: 2 [batch #5200, batch_size 1, seq length 2500]\tLoss: 3.795903\n",
      "5225it [10:00,  8.74it/s]Train epoch: 2 [batch #5225, batch_size 1, seq length 2500]\tLoss: 3.781283\n",
      "5250it [10:03,  8.70it/s]Train epoch: 2 [batch #5250, batch_size 1, seq length 2500]\tLoss: 3.604351\n",
      "5275it [10:06,  8.71it/s]Train epoch: 2 [batch #5275, batch_size 1, seq length 2500]\tLoss: 3.730290\n",
      "5300it [10:09,  8.75it/s]Train epoch: 2 [batch #5300, batch_size 1, seq length 2500]\tLoss: 3.705108\n",
      "5325it [10:12,  8.67it/s]Train epoch: 2 [batch #5325, batch_size 1, seq length 2500]\tLoss: 3.384638\n",
      "5350it [10:15,  8.73it/s]Train epoch: 2 [batch #5350, batch_size 1, seq length 2500]\tLoss: 3.663722\n",
      "5375it [10:18,  8.71it/s]Train epoch: 2 [batch #5375, batch_size 1, seq length 2500]\tLoss: 3.965763\n",
      "5400it [10:20,  8.72it/s]Train epoch: 2 [batch #5400, batch_size 1, seq length 2500]\tLoss: 3.973332\n",
      "5425it [10:23,  8.65it/s]Train epoch: 2 [batch #5425, batch_size 1, seq length 2500]\tLoss: 3.868777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5450it [10:26,  8.73it/s]Train epoch: 2 [batch #5450, batch_size 1, seq length 2500]\tLoss: 3.862110\n",
      "5475it [10:29,  8.67it/s]Train epoch: 2 [batch #5475, batch_size 1, seq length 2500]\tLoss: 3.870238\n",
      "5500it [10:32,  8.70it/s]Train epoch: 2 [batch #5500, batch_size 1, seq length 2500]\tLoss: 3.594200\n",
      "5525it [10:35,  8.75it/s]Train epoch: 2 [batch #5525, batch_size 1, seq length 2500]\tLoss: 3.770989\n",
      "5550it [10:38,  8.74it/s]Train epoch: 2 [batch #5550, batch_size 1, seq length 2500]\tLoss: 4.082079\n",
      "5575it [10:40,  8.71it/s]Train epoch: 2 [batch #5575, batch_size 1, seq length 2500]\tLoss: 3.908759\n",
      "5600it [10:43,  8.65it/s]Train epoch: 2 [batch #5600, batch_size 1, seq length 2500]\tLoss: 3.471921\n",
      "5625it [10:46,  8.72it/s]Train epoch: 2 [batch #5625, batch_size 1, seq length 2500]\tLoss: 3.640383\n",
      "5650it [10:49,  8.74it/s]Train epoch: 2 [batch #5650, batch_size 1, seq length 2500]\tLoss: 3.694877\n",
      "5675it [10:52,  8.70it/s]Train epoch: 2 [batch #5675, batch_size 1, seq length 2500]\tLoss: 3.891463\n",
      "5700it [10:55,  8.72it/s]Train epoch: 2 [batch #5700, batch_size 1, seq length 2500]\tLoss: 3.493632\n",
      "5725it [10:58,  8.69it/s]Train epoch: 2 [batch #5725, batch_size 1, seq length 2500]\tLoss: 3.638387\n",
      "5750it [11:01,  8.74it/s]Train epoch: 2 [batch #5750, batch_size 1, seq length 2500]\tLoss: 3.728443\n",
      "5775it [11:04,  8.67it/s]Train epoch: 2 [batch #5775, batch_size 1, seq length 2500]\tLoss: 3.978269\n",
      "5800it [11:06,  8.74it/s]Train epoch: 2 [batch #5800, batch_size 1, seq length 2500]\tLoss: 3.675958\n",
      "5825it [11:09,  8.76it/s]Train epoch: 2 [batch #5825, batch_size 1, seq length 2500]\tLoss: 3.915302\n",
      "5850it [11:12,  8.67it/s]Train epoch: 2 [batch #5850, batch_size 1, seq length 2500]\tLoss: 3.973381\n",
      "5875it [11:15,  8.69it/s]Train epoch: 2 [batch #5875, batch_size 1, seq length 2500]\tLoss: 3.866638\n",
      "5900it [11:18,  8.75it/s]Train epoch: 2 [batch #5900, batch_size 1, seq length 2500]\tLoss: 3.642983\n",
      "5925it [11:21,  8.70it/s]Train epoch: 2 [batch #5925, batch_size 1, seq length 2500]\tLoss: 3.826884\n",
      "5950it [11:24,  8.71it/s]Train epoch: 2 [batch #5950, batch_size 1, seq length 2500]\tLoss: 3.570706\n",
      "5975it [11:27,  8.64it/s]Train epoch: 2 [batch #5975, batch_size 1, seq length 2500]\tLoss: 3.998789\n",
      "6000it [11:29,  8.74it/s]Train epoch: 2 [batch #6000, batch_size 1, seq length 2500]\tLoss: 3.391324\n",
      "6025it [11:32,  8.69it/s]Train epoch: 2 [batch #6025, batch_size 1, seq length 2500]\tLoss: 3.638414\n",
      "6050it [11:35,  8.74it/s]Train epoch: 2 [batch #6050, batch_size 1, seq length 2500]\tLoss: 3.861039\n",
      "6075it [11:38,  8.63it/s]Train epoch: 2 [batch #6075, batch_size 1, seq length 2500]\tLoss: 3.616952\n",
      "6100it [11:41,  8.76it/s]Train epoch: 2 [batch #6100, batch_size 1, seq length 2500]\tLoss: 3.388679\n",
      "6125it [11:44,  8.69it/s]Train epoch: 2 [batch #6125, batch_size 1, seq length 2500]\tLoss: 3.924159\n",
      "6150it [11:47,  8.75it/s]Train epoch: 2 [batch #6150, batch_size 1, seq length 2500]\tLoss: 3.597411\n",
      "6175it [11:50,  8.76it/s]Train epoch: 2 [batch #6175, batch_size 1, seq length 2500]\tLoss: 3.834911\n",
      "6200it [11:52,  8.70it/s]Train epoch: 2 [batch #6200, batch_size 1, seq length 2500]\tLoss: 3.759403\n",
      "6225it [11:55,  8.64it/s]Train epoch: 2 [batch #6225, batch_size 1, seq length 2500]\tLoss: 3.954064\n",
      "6250it [11:58,  8.73it/s]Train epoch: 2 [batch #6250, batch_size 1, seq length 2500]\tLoss: 3.951613\n",
      "6275it [12:01,  8.76it/s]Train epoch: 2 [batch #6275, batch_size 1, seq length 2500]\tLoss: 3.465710\n",
      "6300it [12:04,  8.71it/s]Train epoch: 2 [batch #6300, batch_size 1, seq length 2500]\tLoss: 3.989723\n",
      "6325it [12:07,  8.70it/s]Train epoch: 2 [batch #6325, batch_size 1, seq length 2500]\tLoss: 3.840713\n",
      "6350it [12:10,  8.69it/s]Train epoch: 2 [batch #6350, batch_size 1, seq length 2500]\tLoss: 3.523834\n",
      "6375it [12:13,  8.73it/s]Train epoch: 2 [batch #6375, batch_size 1, seq length 2500]\tLoss: 3.648347\n",
      "6400it [12:15,  8.69it/s]Train epoch: 2 [batch #6400, batch_size 1, seq length 2500]\tLoss: 3.796096\n",
      "6425it [12:18,  8.67it/s]Train epoch: 2 [batch #6425, batch_size 1, seq length 2500]\tLoss: 3.739419\n",
      "6450it [12:21,  8.73it/s]Train epoch: 2 [batch #6450, batch_size 1, seq length 2500]\tLoss: 4.007787\n",
      "6475it [12:24,  8.70it/s]Train epoch: 2 [batch #6475, batch_size 1, seq length 2500]\tLoss: 3.832159\n",
      "6500it [12:27,  8.72it/s]Train epoch: 2 [batch #6500, batch_size 1, seq length 2500]\tLoss: 3.820073\n",
      "6525it [12:30,  8.71it/s]Train epoch: 2 [batch #6525, batch_size 1, seq length 2500]\tLoss: 3.921763\n",
      "6550it [12:33,  8.73it/s]Train epoch: 2 [batch #6550, batch_size 1, seq length 2500]\tLoss: 3.992125\n",
      "6575it [12:36,  8.69it/s]Train epoch: 2 [batch #6575, batch_size 1, seq length 2500]\tLoss: 3.681736\n",
      "6600it [12:38,  8.72it/s]Train epoch: 2 [batch #6600, batch_size 1, seq length 2500]\tLoss: 3.775651\n",
      "6625it [12:41,  8.72it/s]Train epoch: 2 [batch #6625, batch_size 1, seq length 2500]\tLoss: 3.810346\n",
      "6650it [12:44,  8.72it/s]Train epoch: 2 [batch #6650, batch_size 1, seq length 2500]\tLoss: 3.475410\n",
      "6675it [12:47,  8.59it/s]Train epoch: 2 [batch #6675, batch_size 1, seq length 2500]\tLoss: 3.588809\n",
      "6700it [12:50,  8.70it/s]Train epoch: 2 [batch #6700, batch_size 1, seq length 2500]\tLoss: 3.921955\n",
      "6725it [12:53,  8.72it/s]Train epoch: 2 [batch #6725, batch_size 1, seq length 2500]\tLoss: 3.841740\n",
      "6750it [12:56,  8.70it/s]Train epoch: 2 [batch #6750, batch_size 1, seq length 2500]\tLoss: 3.574105\n",
      "6775it [12:59,  8.73it/s]Train epoch: 2 [batch #6775, batch_size 1, seq length 2500]\tLoss: 4.034963\n",
      "6800it [13:01,  8.70it/s]Train epoch: 2 [batch #6800, batch_size 1, seq length 2500]\tLoss: 3.847260\n",
      "6825it [13:04,  8.59it/s]Train epoch: 2 [batch #6825, batch_size 1, seq length 2500]\tLoss: 3.695484\n",
      "6850it [13:07,  8.66it/s]Train epoch: 2 [batch #6850, batch_size 1, seq length 2500]\tLoss: 3.580777\n",
      "6875it [13:10,  8.66it/s]Train epoch: 2 [batch #6875, batch_size 1, seq length 2500]\tLoss: 3.902253\n",
      "6900it [13:13,  8.72it/s]Train epoch: 2 [batch #6900, batch_size 1, seq length 2500]\tLoss: 3.723933\n",
      "6925it [13:16,  8.67it/s]Train epoch: 2 [batch #6925, batch_size 1, seq length 2500]\tLoss: 3.704471\n",
      "6950it [13:19,  8.64it/s]Train epoch: 2 [batch #6950, batch_size 1, seq length 2500]\tLoss: 3.354357\n",
      "6975it [13:22,  8.68it/s]Train epoch: 2 [batch #6975, batch_size 1, seq length 2500]\tLoss: 3.909607\n",
      "7000it [13:24,  8.74it/s]Train epoch: 2 [batch #7000, batch_size 1, seq length 2500]\tLoss: 3.778718\n",
      "7025it [13:27,  8.72it/s]Train epoch: 2 [batch #7025, batch_size 1, seq length 2500]\tLoss: 4.017982\n",
      "7050it [13:30,  8.69it/s]Train epoch: 2 [batch #7050, batch_size 1, seq length 2500]\tLoss: 3.792297\n",
      "7075it [13:33,  8.53it/s]Train epoch: 2 [batch #7075, batch_size 1, seq length 2500]\tLoss: 3.767194\n",
      "7100it [13:36,  8.66it/s]Train epoch: 2 [batch #7100, batch_size 1, seq length 2500]\tLoss: 3.807346\n",
      "7125it [13:39,  8.73it/s]Train epoch: 2 [batch #7125, batch_size 1, seq length 2500]\tLoss: 3.923122\n",
      "7150it [13:42,  8.72it/s]Train epoch: 2 [batch #7150, batch_size 1, seq length 2500]\tLoss: 3.616304\n",
      "7175it [13:45,  8.74it/s]Train epoch: 2 [batch #7175, batch_size 1, seq length 2500]\tLoss: 3.835622\n",
      "7200it [13:47,  8.68it/s]Train epoch: 2 [batch #7200, batch_size 1, seq length 2500]\tLoss: 3.940639\n",
      "7225it [13:50,  8.68it/s]Train epoch: 2 [batch #7225, batch_size 1, seq length 2500]\tLoss: 3.984382\n",
      "7250it [13:53,  8.66it/s]Train epoch: 2 [batch #7250, batch_size 1, seq length 2500]\tLoss: 3.959829\n",
      "7275it [13:56,  8.74it/s]Train epoch: 2 [batch #7275, batch_size 1, seq length 2500]\tLoss: 3.594063\n",
      "7300it [13:59,  8.70it/s]Train epoch: 2 [batch #7300, batch_size 1, seq length 2500]\tLoss: 3.422925\n",
      "7325it [14:02,  8.73it/s]Train epoch: 2 [batch #7325, batch_size 1, seq length 2500]\tLoss: 3.660160\n",
      "7350it [14:05,  8.67it/s]Train epoch: 2 [batch #7350, batch_size 1, seq length 2500]\tLoss: 3.940555\n",
      "7375it [14:08,  8.66it/s]Train epoch: 2 [batch #7375, batch_size 1, seq length 2500]\tLoss: 3.399182\n",
      "7400it [14:10,  8.77it/s]Train epoch: 2 [batch #7400, batch_size 1, seq length 2500]\tLoss: 3.880170\n",
      "7425it [14:13,  8.72it/s]Train epoch: 2 [batch #7425, batch_size 1, seq length 2500]\tLoss: 3.826995\n",
      "7450it [14:16,  8.74it/s]Train epoch: 2 [batch #7450, batch_size 1, seq length 2500]\tLoss: 3.689503\n",
      "7475it [14:19,  8.71it/s]Train epoch: 2 [batch #7475, batch_size 1, seq length 2500]\tLoss: 3.557732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500it [14:22,  8.71it/s]Train epoch: 2 [batch #7500, batch_size 1, seq length 2500]\tLoss: 3.500791\n",
      "7525it [14:25,  8.76it/s]Train epoch: 2 [batch #7525, batch_size 1, seq length 2500]\tLoss: 3.695122\n",
      "7550it [14:28,  8.66it/s]Train epoch: 2 [batch #7550, batch_size 1, seq length 2500]\tLoss: 3.559068\n",
      "7575it [14:31,  8.68it/s]Train epoch: 2 [batch #7575, batch_size 1, seq length 2500]\tLoss: 3.571972\n",
      "7600it [14:33,  8.67it/s]Train epoch: 2 [batch #7600, batch_size 1, seq length 2500]\tLoss: 3.705924\n",
      "7625it [14:36,  8.66it/s]Train epoch: 2 [batch #7625, batch_size 1, seq length 2500]\tLoss: 3.811884\n",
      "7650it [14:39,  8.72it/s]Train epoch: 2 [batch #7650, batch_size 1, seq length 2500]\tLoss: 3.639472\n",
      "7675it [14:42,  8.69it/s]Train epoch: 2 [batch #7675, batch_size 1, seq length 2500]\tLoss: 3.916719\n",
      "7700it [14:45,  8.73it/s]Train epoch: 2 [batch #7700, batch_size 1, seq length 2500]\tLoss: 3.620471\n",
      "7725it [14:48,  8.75it/s]Train epoch: 2 [batch #7725, batch_size 1, seq length 2500]\tLoss: 3.851847\n",
      "7750it [14:51,  8.70it/s]Train epoch: 2 [batch #7750, batch_size 1, seq length 2500]\tLoss: 3.857118\n",
      "7775it [14:53,  8.69it/s]Train epoch: 2 [batch #7775, batch_size 1, seq length 2500]\tLoss: 3.576535\n",
      "7800it [14:56,  8.69it/s]Train epoch: 2 [batch #7800, batch_size 1, seq length 2500]\tLoss: 3.728381\n",
      "7825it [14:59,  8.66it/s]Train epoch: 2 [batch #7825, batch_size 1, seq length 2500]\tLoss: 3.962616\n",
      "7850it [15:02,  8.73it/s]Train epoch: 2 [batch #7850, batch_size 1, seq length 2500]\tLoss: 3.580996\n",
      "7875it [15:05,  8.76it/s]Train epoch: 2 [batch #7875, batch_size 1, seq length 2500]\tLoss: 3.600342\n",
      "7900it [15:08,  8.72it/s]Train epoch: 2 [batch #7900, batch_size 1, seq length 2500]\tLoss: 3.573493\n",
      "7925it [15:11,  8.67it/s]Train epoch: 2 [batch #7925, batch_size 1, seq length 2500]\tLoss: 3.944731\n",
      "7950it [15:14,  8.67it/s]Train epoch: 2 [batch #7950, batch_size 1, seq length 2500]\tLoss: 3.631608\n",
      "7975it [15:17,  8.74it/s]Train epoch: 2 [batch #7975, batch_size 1, seq length 2500]\tLoss: 3.529104\n",
      "8000it [15:19,  8.70it/s]Train epoch: 2 [batch #8000, batch_size 1, seq length 2500]\tLoss: 3.602367\n",
      "8025it [15:22,  8.70it/s]Train epoch: 2 [batch #8025, batch_size 1, seq length 2500]\tLoss: 3.813841\n",
      "8050it [15:25,  8.47it/s]Train epoch: 2 [batch #8050, batch_size 1, seq length 2500]\tLoss: 3.999037\n",
      "8075it [15:28,  8.71it/s]Train epoch: 2 [batch #8075, batch_size 1, seq length 2500]\tLoss: 3.762781\n",
      "8100it [15:31,  8.64it/s]Train epoch: 2 [batch #8100, batch_size 1, seq length 2500]\tLoss: 3.770056\n",
      "8125it [15:34,  8.74it/s]Train epoch: 2 [batch #8125, batch_size 1, seq length 2500]\tLoss: 3.629491\n",
      "8150it [15:37,  8.68it/s]Train epoch: 2 [batch #8150, batch_size 1, seq length 2500]\tLoss: 3.685852\n",
      "8175it [15:40,  8.65it/s]Train epoch: 2 [batch #8175, batch_size 1, seq length 2500]\tLoss: 3.737865\n",
      "8200it [15:42,  8.68it/s]Train epoch: 2 [batch #8200, batch_size 1, seq length 2500]\tLoss: 3.353729\n",
      "8225it [15:45,  8.72it/s]Train epoch: 2 [batch #8225, batch_size 1, seq length 2500]\tLoss: 3.821356\n",
      "8250it [15:48,  8.75it/s]Train epoch: 2 [batch #8250, batch_size 1, seq length 2500]\tLoss: 3.931594\n",
      "8275it [15:51,  8.73it/s]Train epoch: 2 [batch #8275, batch_size 1, seq length 2500]\tLoss: 3.431282\n",
      "8300it [15:54,  8.61it/s]Train epoch: 2 [batch #8300, batch_size 1, seq length 2500]\tLoss: 3.572470\n",
      "8325it [15:57,  8.49it/s]Train epoch: 2 [batch #8325, batch_size 1, seq length 2500]\tLoss: 3.729705\n",
      "8350it [16:00,  8.64it/s]Train epoch: 2 [batch #8350, batch_size 1, seq length 2500]\tLoss: 3.726333\n",
      "8375it [16:03,  8.71it/s]Train epoch: 2 [batch #8375, batch_size 1, seq length 2500]\tLoss: 3.536441\n",
      "8400it [16:05,  8.65it/s]Train epoch: 2 [batch #8400, batch_size 1, seq length 2500]\tLoss: 3.739937\n",
      "8425it [16:08,  8.77it/s]Train epoch: 2 [batch #8425, batch_size 1, seq length 2500]\tLoss: 3.839162\n",
      "8450it [16:11,  8.67it/s]Train epoch: 2 [batch #8450, batch_size 1, seq length 2500]\tLoss: 3.817601\n",
      "8475it [16:14,  8.70it/s]Train epoch: 2 [batch #8475, batch_size 1, seq length 2500]\tLoss: 3.790884\n",
      "8500it [16:17,  8.68it/s]Train epoch: 2 [batch #8500, batch_size 1, seq length 2500]\tLoss: 3.889580\n",
      "8525it [16:20,  8.75it/s]Train epoch: 2 [batch #8525, batch_size 1, seq length 2500]\tLoss: 3.485447\n",
      "8550it [16:23,  8.63it/s]Train epoch: 2 [batch #8550, batch_size 1, seq length 2500]\tLoss: 3.575431\n",
      "8575it [16:26,  8.67it/s]Train epoch: 2 [batch #8575, batch_size 1, seq length 2500]\tLoss: 3.661031\n",
      "8600it [16:28,  8.76it/s]Train epoch: 2 [batch #8600, batch_size 1, seq length 2500]\tLoss: 4.024371\n",
      "8625it [16:31,  8.71it/s]Train epoch: 2 [batch #8625, batch_size 1, seq length 2500]\tLoss: 3.856525\n",
      "8650it [16:34,  8.65it/s]Train epoch: 2 [batch #8650, batch_size 1, seq length 2500]\tLoss: 3.739928\n",
      "8675it [16:37,  8.65it/s]Train epoch: 2 [batch #8675, batch_size 1, seq length 2500]\tLoss: 3.610989\n",
      "8700it [16:40,  8.70it/s]Train epoch: 2 [batch #8700, batch_size 1, seq length 2500]\tLoss: 3.787713\n",
      "8725it [16:43,  8.64it/s]Train epoch: 2 [batch #8725, batch_size 1, seq length 2500]\tLoss: 3.606409\n",
      "8750it [16:46,  8.72it/s]Train epoch: 2 [batch #8750, batch_size 1, seq length 2500]\tLoss: 3.798044\n",
      "8775it [16:49,  8.75it/s]Train epoch: 2 [batch #8775, batch_size 1, seq length 2500]\tLoss: 3.956815\n",
      "8800it [16:51,  8.70it/s]Train epoch: 2 [batch #8800, batch_size 1, seq length 2500]\tLoss: 3.944799\n",
      "8825it [16:54,  8.73it/s]Train epoch: 2 [batch #8825, batch_size 1, seq length 2500]\tLoss: 3.787434\n",
      "8850it [16:57,  8.73it/s]Train epoch: 2 [batch #8850, batch_size 1, seq length 2500]\tLoss: 3.793921\n",
      "8875it [17:00,  8.73it/s]Train epoch: 2 [batch #8875, batch_size 1, seq length 2500]\tLoss: 3.637077\n",
      "8900it [17:03,  8.73it/s]Train epoch: 2 [batch #8900, batch_size 1, seq length 2500]\tLoss: 3.653785\n",
      "8925it [17:06,  8.73it/s]Train epoch: 2 [batch #8925, batch_size 1, seq length 2500]\tLoss: 3.921400\n",
      "8950it [17:09,  8.68it/s]Train epoch: 2 [batch #8950, batch_size 1, seq length 2500]\tLoss: 3.257170\n",
      "8975it [17:12,  8.76it/s]Train epoch: 2 [batch #8975, batch_size 1, seq length 2500]\tLoss: 3.698893\n",
      "9000it [17:14,  8.63it/s]Train epoch: 2 [batch #9000, batch_size 1, seq length 2500]\tLoss: 3.866718\n",
      "9025it [17:17,  8.68it/s]Train epoch: 2 [batch #9025, batch_size 1, seq length 2500]\tLoss: 3.879026\n",
      "9050it [17:20,  8.73it/s]Train epoch: 2 [batch #9050, batch_size 1, seq length 2500]\tLoss: 3.700602\n",
      "9075it [17:23,  8.66it/s]Train epoch: 2 [batch #9075, batch_size 1, seq length 2500]\tLoss: 3.616400\n",
      "9100it [17:26,  8.74it/s]Train epoch: 2 [batch #9100, batch_size 1, seq length 2500]\tLoss: 3.879281\n",
      "9125it [17:29,  8.73it/s]Train epoch: 2 [batch #9125, batch_size 1, seq length 2500]\tLoss: 3.832115\n",
      "9150it [17:32,  8.70it/s]Train epoch: 2 [batch #9150, batch_size 1, seq length 2500]\tLoss: 3.912665\n",
      "9175it [17:35,  8.75it/s]Train epoch: 2 [batch #9175, batch_size 1, seq length 2500]\tLoss: 3.468854\n",
      "9200it [17:37,  8.74it/s]Train epoch: 2 [batch #9200, batch_size 1, seq length 2500]\tLoss: 3.667419\n",
      "9225it [17:40,  8.76it/s]Train epoch: 2 [batch #9225, batch_size 1, seq length 2500]\tLoss: 3.856097\n",
      "9250it [17:43,  8.72it/s]Train epoch: 2 [batch #9250, batch_size 1, seq length 2500]\tLoss: 3.960332\n",
      "9275it [17:46,  8.67it/s]Train epoch: 2 [batch #9275, batch_size 1, seq length 2500]\tLoss: 3.890674\n",
      "9300it [17:49,  8.65it/s]Train epoch: 2 [batch #9300, batch_size 1, seq length 2500]\tLoss: 3.657494\n",
      "9325it [17:52,  8.71it/s]Train epoch: 2 [batch #9325, batch_size 1, seq length 2500]\tLoss: 3.550057\n",
      "9350it [17:55,  8.73it/s]Train epoch: 2 [batch #9350, batch_size 1, seq length 2500]\tLoss: 3.823544\n",
      "9375it [17:58,  8.71it/s]Train epoch: 2 [batch #9375, batch_size 1, seq length 2500]\tLoss: 3.574092\n",
      "9400it [18:00,  8.69it/s]Train epoch: 2 [batch #9400, batch_size 1, seq length 2500]\tLoss: 3.930120\n",
      "9425it [18:03,  8.72it/s]Train epoch: 2 [batch #9425, batch_size 1, seq length 2500]\tLoss: 3.790859\n",
      "9450it [18:06,  8.61it/s]Train epoch: 2 [batch #9450, batch_size 1, seq length 2500]\tLoss: 3.946694\n",
      "9475it [18:09,  8.71it/s]Train epoch: 2 [batch #9475, batch_size 1, seq length 2500]\tLoss: 3.802675\n",
      "9500it [18:12,  8.67it/s]Train epoch: 2 [batch #9500, batch_size 1, seq length 2500]\tLoss: 4.127123\n",
      "9525it [18:15,  8.70it/s]Train epoch: 2 [batch #9525, batch_size 1, seq length 2500]\tLoss: 3.550465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9550it [18:18,  8.63it/s]Train epoch: 2 [batch #9550, batch_size 1, seq length 2500]\tLoss: 3.898183\n",
      "9575it [18:21,  8.63it/s]Train epoch: 2 [batch #9575, batch_size 1, seq length 2500]\tLoss: 3.685140\n",
      "9600it [18:24,  8.72it/s]Train epoch: 2 [batch #9600, batch_size 1, seq length 2500]\tLoss: 3.708323\n",
      "9625it [18:26,  8.66it/s]Train epoch: 2 [batch #9625, batch_size 1, seq length 2500]\tLoss: 4.028068\n",
      "9650it [18:29,  8.72it/s]Train epoch: 2 [batch #9650, batch_size 1, seq length 2500]\tLoss: 3.900948\n",
      "9675it [18:32,  8.69it/s]Train epoch: 2 [batch #9675, batch_size 1, seq length 2500]\tLoss: 3.636788\n",
      "9700it [18:35,  8.71it/s]Train epoch: 2 [batch #9700, batch_size 1, seq length 2500]\tLoss: 3.571142\n",
      "9725it [18:38,  8.77it/s]Train epoch: 2 [batch #9725, batch_size 1, seq length 2500]\tLoss: 3.505645\n",
      "9750it [18:41,  8.71it/s]Train epoch: 2 [batch #9750, batch_size 1, seq length 2500]\tLoss: 3.938789\n",
      "9775it [18:44,  8.58it/s]Train epoch: 2 [batch #9775, batch_size 1, seq length 2500]\tLoss: 3.482710\n",
      "9800it [18:46,  8.74it/s]Train epoch: 2 [batch #9800, batch_size 1, seq length 2500]\tLoss: 3.697621\n",
      "9825it [18:49,  8.70it/s]Train epoch: 2 [batch #9825, batch_size 1, seq length 2500]\tLoss: 3.833254\n",
      "9850it [18:52,  8.73it/s]Train epoch: 2 [batch #9850, batch_size 1, seq length 2500]\tLoss: 3.659832\n",
      "9875it [18:55,  8.70it/s]Train epoch: 2 [batch #9875, batch_size 1, seq length 2500]\tLoss: 3.631311\n",
      "9900it [18:58,  8.69it/s]Train epoch: 2 [batch #9900, batch_size 1, seq length 2500]\tLoss: 3.592866\n",
      "9925it [19:01,  8.66it/s]Train epoch: 2 [batch #9925, batch_size 1, seq length 2500]\tLoss: 3.687525\n",
      "9950it [19:04,  8.69it/s]Train epoch: 2 [batch #9950, batch_size 1, seq length 2500]\tLoss: 3.744500\n",
      "9975it [19:07,  8.62it/s]Train epoch: 2 [batch #9975, batch_size 1, seq length 2500]\tLoss: 3.759991\n",
      "10000it [19:10,  8.66it/s]Train epoch: 2 [batch #10000, batch_size 1, seq length 2500]\tLoss: 3.360517\n",
      "10025it [19:12,  8.66it/s]Train epoch: 2 [batch #10025, batch_size 1, seq length 2500]\tLoss: 3.954484\n",
      "10050it [19:15,  8.67it/s]Train epoch: 2 [batch #10050, batch_size 1, seq length 2500]\tLoss: 3.543573\n",
      "10075it [19:18,  8.71it/s]Train epoch: 2 [batch #10075, batch_size 1, seq length 2500]\tLoss: 3.965985\n",
      "10100it [19:21,  8.73it/s]Train epoch: 2 [batch #10100, batch_size 1, seq length 2500]\tLoss: 3.923685\n",
      "10125it [19:24,  8.75it/s]Train epoch: 2 [batch #10125, batch_size 1, seq length 2500]\tLoss: 3.847103\n",
      "10150it [19:27,  8.68it/s]Train epoch: 2 [batch #10150, batch_size 1, seq length 2500]\tLoss: 3.643399\n",
      "10175it [19:30,  8.72it/s]Train epoch: 2 [batch #10175, batch_size 1, seq length 2500]\tLoss: 4.016590\n",
      "10200it [19:32,  8.69it/s]Train epoch: 2 [batch #10200, batch_size 1, seq length 2500]\tLoss: 3.529403\n",
      "10225it [19:35,  8.69it/s]Train epoch: 2 [batch #10225, batch_size 1, seq length 2500]\tLoss: 3.760885\n",
      "10250it [19:38,  8.70it/s]Train epoch: 2 [batch #10250, batch_size 1, seq length 2500]\tLoss: 3.750551\n",
      "10275it [19:41,  8.76it/s]Train epoch: 2 [batch #10275, batch_size 1, seq length 2500]\tLoss: 3.694501\n",
      "10300it [19:44,  8.68it/s]Train epoch: 2 [batch #10300, batch_size 1, seq length 2500]\tLoss: 3.797222\n",
      "10325it [19:47,  8.72it/s]Train epoch: 2 [batch #10325, batch_size 1, seq length 2500]\tLoss: 3.920317\n",
      "10350it [19:50,  8.74it/s]Train epoch: 2 [batch #10350, batch_size 1, seq length 2500]\tLoss: 3.626740\n",
      "10375it [19:53,  8.66it/s]Train epoch: 2 [batch #10375, batch_size 1, seq length 2500]\tLoss: 3.816877\n",
      "10400it [19:55,  8.75it/s]Train epoch: 2 [batch #10400, batch_size 1, seq length 2500]\tLoss: 3.519554\n",
      "10425it [19:58,  8.75it/s]Train epoch: 2 [batch #10425, batch_size 1, seq length 2500]\tLoss: 3.835978\n",
      "10450it [20:01,  8.74it/s]Train epoch: 2 [batch #10450, batch_size 1, seq length 2500]\tLoss: 3.665605\n",
      "10475it [20:04,  8.73it/s]Train epoch: 2 [batch #10475, batch_size 1, seq length 2500]\tLoss: 3.993200\n",
      "10500it [20:07,  8.76it/s]Train epoch: 2 [batch #10500, batch_size 1, seq length 2500]\tLoss: 3.655907\n",
      "10525it [20:10,  8.72it/s]Train epoch: 2 [batch #10525, batch_size 1, seq length 2500]\tLoss: 3.940337\n",
      "10550it [20:13,  8.72it/s]Train epoch: 2 [batch #10550, batch_size 1, seq length 2500]\tLoss: 3.862207\n",
      "10575it [20:16,  8.72it/s]Train epoch: 2 [batch #10575, batch_size 1, seq length 2500]\tLoss: 3.991425\n",
      "10600it [20:18,  8.74it/s]Train epoch: 2 [batch #10600, batch_size 1, seq length 2500]\tLoss: 3.984915\n",
      "10625it [20:21,  8.68it/s]Train epoch: 2 [batch #10625, batch_size 1, seq length 2500]\tLoss: 3.760146\n",
      "10650it [20:24,  8.61it/s]Train epoch: 2 [batch #10650, batch_size 1, seq length 2500]\tLoss: 3.880320\n",
      "10675it [20:27,  8.78it/s]Train epoch: 2 [batch #10675, batch_size 1, seq length 2500]\tLoss: 3.900760\n",
      "10700it [20:30,  8.71it/s]Train epoch: 2 [batch #10700, batch_size 1, seq length 2500]\tLoss: 3.621255\n",
      "10725it [20:33,  8.66it/s]Train epoch: 2 [batch #10725, batch_size 1, seq length 2500]\tLoss: 3.893909\n",
      "10750it [20:36,  8.75it/s]Train epoch: 2 [batch #10750, batch_size 1, seq length 2500]\tLoss: 3.785914\n",
      "10775it [20:38,  8.74it/s]Train epoch: 2 [batch #10775, batch_size 1, seq length 2500]\tLoss: 3.733818\n",
      "10800it [20:41,  8.70it/s]Train epoch: 2 [batch #10800, batch_size 1, seq length 2500]\tLoss: 3.611338\n",
      "10825it [20:44,  8.72it/s]Train epoch: 2 [batch #10825, batch_size 1, seq length 2500]\tLoss: 3.753499\n",
      "10850it [20:47,  8.76it/s]Train epoch: 2 [batch #10850, batch_size 1, seq length 2500]\tLoss: 3.775290\n",
      "10875it [20:50,  8.75it/s]Train epoch: 2 [batch #10875, batch_size 1, seq length 2500]\tLoss: 3.669597\n",
      "10900it [20:53,  8.72it/s]Train epoch: 2 [batch #10900, batch_size 1, seq length 2500]\tLoss: 3.898720\n",
      "10925it [20:56,  8.76it/s]Train epoch: 2 [batch #10925, batch_size 1, seq length 2500]\tLoss: 3.769196\n",
      "10950it [20:59,  8.71it/s]Train epoch: 2 [batch #10950, batch_size 1, seq length 2500]\tLoss: 3.439094\n",
      "10975it [21:01,  8.69it/s]Train epoch: 2 [batch #10975, batch_size 1, seq length 2500]\tLoss: 3.450990\n",
      "11000it [21:04,  8.70it/s]Train epoch: 2 [batch #11000, batch_size 1, seq length 2500]\tLoss: 4.001279\n",
      "11025it [21:07,  8.74it/s]Train epoch: 2 [batch #11025, batch_size 1, seq length 2500]\tLoss: 3.549988\n",
      "11050it [21:10,  8.74it/s]Train epoch: 2 [batch #11050, batch_size 1, seq length 2500]\tLoss: 3.758129\n",
      "11075it [21:13,  8.67it/s]Train epoch: 2 [batch #11075, batch_size 1, seq length 2500]\tLoss: 3.795073\n",
      "11100it [21:16,  8.72it/s]Train epoch: 2 [batch #11100, batch_size 1, seq length 2500]\tLoss: 3.675726\n",
      "11125it [21:19,  8.70it/s]Train epoch: 2 [batch #11125, batch_size 1, seq length 2500]\tLoss: 3.634733\n",
      "11150it [21:22,  8.67it/s]Train epoch: 2 [batch #11150, batch_size 1, seq length 2500]\tLoss: 3.318862\n",
      "11175it [21:24,  8.64it/s]Train epoch: 2 [batch #11175, batch_size 1, seq length 2500]\tLoss: 3.947206\n",
      "11200it [21:27,  8.74it/s]Train epoch: 2 [batch #11200, batch_size 1, seq length 2500]\tLoss: 3.629632\n",
      "11225it [21:30,  8.73it/s]Train epoch: 2 [batch #11225, batch_size 1, seq length 2500]\tLoss: 3.839986\n",
      "11250it [21:33,  8.70it/s]Train epoch: 2 [batch #11250, batch_size 1, seq length 2500]\tLoss: 3.660057\n",
      "11275it [21:36,  8.71it/s]Train epoch: 2 [batch #11275, batch_size 1, seq length 2500]\tLoss: 3.711480\n",
      "11300it [21:39,  8.66it/s]Train epoch: 2 [batch #11300, batch_size 1, seq length 2500]\tLoss: 3.620269\n",
      "11325it [21:42,  8.65it/s]Train epoch: 2 [batch #11325, batch_size 1, seq length 2500]\tLoss: 3.597388\n",
      "11350it [21:44,  8.77it/s]Train epoch: 2 [batch #11350, batch_size 1, seq length 2500]\tLoss: 3.880166\n",
      "11375it [21:47,  8.76it/s]Train epoch: 2 [batch #11375, batch_size 1, seq length 2500]\tLoss: 3.512693\n",
      "11400it [21:50,  8.70it/s]Train epoch: 2 [batch #11400, batch_size 1, seq length 2500]\tLoss: 3.585912\n",
      "11425it [21:53,  8.75it/s]Train epoch: 2 [batch #11425, batch_size 1, seq length 2500]\tLoss: 4.096927\n",
      "11450it [21:56,  8.69it/s]Train epoch: 2 [batch #11450, batch_size 1, seq length 2500]\tLoss: 3.718815\n",
      "11475it [21:59,  8.72it/s]Train epoch: 2 [batch #11475, batch_size 1, seq length 2500]\tLoss: 3.831170\n",
      "11500it [22:02,  8.68it/s]Train epoch: 2 [batch #11500, batch_size 1, seq length 2500]\tLoss: 4.012564\n",
      "11525it [22:05,  8.73it/s]Train epoch: 2 [batch #11525, batch_size 1, seq length 2500]\tLoss: 3.866855\n",
      "11550it [22:07,  8.70it/s]Train epoch: 2 [batch #11550, batch_size 1, seq length 2500]\tLoss: 3.661352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11575it [22:10,  8.69it/s]Train epoch: 2 [batch #11575, batch_size 1, seq length 2500]\tLoss: 3.495923\n",
      "11600it [22:13,  8.70it/s]Train epoch: 2 [batch #11600, batch_size 1, seq length 2500]\tLoss: 3.430445\n",
      "11625it [22:16,  8.77it/s]Train epoch: 2 [batch #11625, batch_size 1, seq length 2500]\tLoss: 3.587700\n",
      "11650it [22:19,  8.66it/s]Train epoch: 2 [batch #11650, batch_size 1, seq length 2500]\tLoss: 3.276347\n",
      "11675it [22:22,  8.75it/s]Train epoch: 2 [batch #11675, batch_size 1, seq length 2500]\tLoss: 3.740163\n",
      "11700it [22:25,  8.74it/s]Train epoch: 2 [batch #11700, batch_size 1, seq length 2500]\tLoss: 3.454843\n",
      "11725it [22:28,  8.48it/s]Train epoch: 2 [batch #11725, batch_size 1, seq length 2500]\tLoss: 3.617367\n",
      "11750it [22:30,  8.74it/s]Train epoch: 2 [batch #11750, batch_size 1, seq length 2500]\tLoss: 3.760509\n",
      "11775it [22:33,  8.73it/s]Train epoch: 2 [batch #11775, batch_size 1, seq length 2500]\tLoss: 3.844023\n",
      "11800it [22:36,  8.67it/s]Train epoch: 2 [batch #11800, batch_size 1, seq length 2500]\tLoss: 3.546724\n",
      "11825it [22:39,  8.73it/s]Train epoch: 2 [batch #11825, batch_size 1, seq length 2500]\tLoss: 3.802205\n",
      "11850it [22:42,  8.70it/s]Train epoch: 2 [batch #11850, batch_size 1, seq length 2500]\tLoss: 4.095479\n",
      "11875it [22:45,  8.70it/s]Train epoch: 2 [batch #11875, batch_size 1, seq length 2500]\tLoss: 3.828913\n",
      "11900it [22:48,  8.45it/s]Train epoch: 2 [batch #11900, batch_size 1, seq length 2500]\tLoss: 3.643710\n",
      "11925it [22:51,  8.67it/s]Train epoch: 2 [batch #11925, batch_size 1, seq length 2500]\tLoss: 3.782673\n",
      "11950it [22:53,  8.74it/s]Train epoch: 2 [batch #11950, batch_size 1, seq length 2500]\tLoss: 3.727575\n",
      "11975it [22:56,  8.72it/s]Train epoch: 2 [batch #11975, batch_size 1, seq length 2500]\tLoss: 4.087601\n",
      "12000it [22:59,  8.73it/s]Train epoch: 2 [batch #12000, batch_size 1, seq length 2500]\tLoss: 3.633548\n",
      "12025it [23:02,  8.75it/s]Train epoch: 2 [batch #12025, batch_size 1, seq length 2500]\tLoss: 4.045897\n",
      "12050it [23:05,  8.78it/s]Train epoch: 2 [batch #12050, batch_size 1, seq length 2500]\tLoss: 4.150997\n",
      "12075it [23:08,  8.69it/s]Train epoch: 2 [batch #12075, batch_size 1, seq length 2500]\tLoss: 3.722182\n",
      "12100it [23:11,  8.60it/s]Train epoch: 2 [batch #12100, batch_size 1, seq length 2500]\tLoss: 3.767215\n",
      "12125it [23:14,  8.70it/s]Train epoch: 2 [batch #12125, batch_size 1, seq length 2500]\tLoss: 3.905441\n",
      "12150it [23:16,  8.62it/s]Train epoch: 2 [batch #12150, batch_size 1, seq length 2500]\tLoss: 3.645320\n",
      "12175it [23:19,  8.71it/s]Train epoch: 2 [batch #12175, batch_size 1, seq length 2500]\tLoss: 3.644121\n",
      "12200it [23:22,  8.70it/s]Train epoch: 2 [batch #12200, batch_size 1, seq length 2500]\tLoss: 3.613145\n",
      "12225it [23:25,  8.74it/s]Train epoch: 2 [batch #12225, batch_size 1, seq length 2500]\tLoss: 3.536049\n",
      "12250it [23:28,  8.75it/s]Train epoch: 2 [batch #12250, batch_size 1, seq length 2500]\tLoss: 3.831944\n",
      "12275it [23:31,  8.69it/s]Train epoch: 2 [batch #12275, batch_size 1, seq length 2500]\tLoss: 3.672175\n",
      "12300it [23:34,  8.69it/s]Train epoch: 2 [batch #12300, batch_size 1, seq length 2500]\tLoss: 3.773860\n",
      "12325it [23:37,  8.70it/s]Train epoch: 2 [batch #12325, batch_size 1, seq length 2500]\tLoss: 3.447928\n",
      "12350it [23:39,  8.76it/s]Train epoch: 2 [batch #12350, batch_size 1, seq length 2500]\tLoss: 4.018470\n",
      "12375it [23:42,  8.70it/s]Train epoch: 2 [batch #12375, batch_size 1, seq length 2500]\tLoss: 3.899940\n",
      "12400it [23:45,  8.76it/s]Train epoch: 2 [batch #12400, batch_size 1, seq length 2500]\tLoss: 3.396865\n",
      "12425it [23:48,  8.77it/s]Train epoch: 2 [batch #12425, batch_size 1, seq length 2500]\tLoss: 3.870412\n",
      "12450it [23:51,  8.51it/s]Train epoch: 2 [batch #12450, batch_size 1, seq length 2500]\tLoss: 3.638425\n",
      "12475it [23:54,  8.69it/s]Train epoch: 2 [batch #12475, batch_size 1, seq length 2500]\tLoss: 3.433184\n",
      "12500it [23:57,  8.72it/s]Train epoch: 2 [batch #12500, batch_size 1, seq length 2500]\tLoss: 4.002890\n",
      "12525it [24:00,  8.73it/s]Train epoch: 2 [batch #12525, batch_size 1, seq length 2500]\tLoss: 3.996144\n",
      "12550it [24:02,  8.74it/s]Train epoch: 2 [batch #12550, batch_size 1, seq length 2500]\tLoss: 3.766751\n",
      "12575it [24:05,  8.72it/s]Train epoch: 2 [batch #12575, batch_size 1, seq length 2500]\tLoss: 3.766949\n",
      "12600it [24:08,  8.68it/s]Train epoch: 2 [batch #12600, batch_size 1, seq length 2500]\tLoss: 3.629472\n",
      "12625it [24:11,  8.69it/s]Train epoch: 2 [batch #12625, batch_size 1, seq length 2500]\tLoss: 3.903255\n",
      "12650it [24:14,  8.61it/s]Train epoch: 2 [batch #12650, batch_size 1, seq length 2500]\tLoss: 3.735454\n",
      "12675it [24:17,  8.76it/s]Train epoch: 2 [batch #12675, batch_size 1, seq length 2500]\tLoss: 3.665305\n",
      "12700it [24:20,  8.73it/s]Train epoch: 2 [batch #12700, batch_size 1, seq length 2500]\tLoss: 3.818990\n",
      "12725it [24:23,  8.70it/s]Train epoch: 2 [batch #12725, batch_size 1, seq length 2500]\tLoss: 3.749385\n",
      "12750it [24:25,  8.73it/s]Train epoch: 2 [batch #12750, batch_size 1, seq length 2500]\tLoss: 3.715884\n",
      "12775it [24:28,  8.73it/s]Train epoch: 2 [batch #12775, batch_size 1, seq length 2500]\tLoss: 3.419499\n",
      "12800it [24:31,  8.72it/s]Train epoch: 2 [batch #12800, batch_size 1, seq length 2500]\tLoss: 3.727987\n",
      "12825it [24:34,  8.69it/s]Train epoch: 2 [batch #12825, batch_size 1, seq length 2500]\tLoss: 3.432633\n",
      "12850it [24:37,  8.74it/s]Train epoch: 2 [batch #12850, batch_size 1, seq length 2500]\tLoss: 3.877323\n",
      "12875it [24:40,  8.73it/s]Train epoch: 2 [batch #12875, batch_size 1, seq length 2500]\tLoss: 3.625420\n",
      "12900it [24:43,  8.68it/s]Train epoch: 2 [batch #12900, batch_size 1, seq length 2500]\tLoss: 3.828389\n",
      "12925it [24:46,  8.69it/s]Train epoch: 2 [batch #12925, batch_size 1, seq length 2500]\tLoss: 3.846507\n",
      "12950it [24:48,  8.72it/s]Train epoch: 2 [batch #12950, batch_size 1, seq length 2500]\tLoss: 3.548132\n",
      "12975it [24:51,  8.69it/s]Train epoch: 2 [batch #12975, batch_size 1, seq length 2500]\tLoss: 3.804322\n",
      "13000it [24:54,  8.71it/s]Train epoch: 2 [batch #13000, batch_size 1, seq length 2500]\tLoss: 3.682866\n",
      "13025it [24:57,  8.73it/s]Train epoch: 2 [batch #13025, batch_size 1, seq length 2500]\tLoss: 3.704250\n",
      "13050it [25:00,  8.74it/s]Train epoch: 2 [batch #13050, batch_size 1, seq length 2500]\tLoss: 3.534903\n",
      "13075it [25:03,  8.71it/s]Train epoch: 2 [batch #13075, batch_size 1, seq length 2500]\tLoss: 3.906177\n",
      "13100it [25:06,  8.73it/s]Train epoch: 2 [batch #13100, batch_size 1, seq length 2500]\tLoss: 3.636769\n",
      "13125it [25:08,  8.69it/s]Train epoch: 2 [batch #13125, batch_size 1, seq length 2500]\tLoss: 3.571368\n",
      "13150it [25:11,  8.64it/s]Train epoch: 2 [batch #13150, batch_size 1, seq length 2500]\tLoss: 4.009647\n",
      "13175it [25:14,  8.75it/s]Train epoch: 2 [batch #13175, batch_size 1, seq length 2500]\tLoss: 3.753984\n",
      "13200it [25:17,  8.73it/s]Train epoch: 2 [batch #13200, batch_size 1, seq length 2500]\tLoss: 3.466961\n",
      "13225it [25:20,  8.69it/s]Train epoch: 2 [batch #13225, batch_size 1, seq length 2500]\tLoss: 3.640123\n",
      "13250it [25:23,  8.66it/s]Train epoch: 2 [batch #13250, batch_size 1, seq length 2500]\tLoss: 3.203751\n",
      "13275it [25:26,  8.70it/s]Train epoch: 2 [batch #13275, batch_size 1, seq length 2500]\tLoss: 3.481159\n",
      "13300it [25:29,  8.63it/s]Train epoch: 2 [batch #13300, batch_size 1, seq length 2500]\tLoss: 3.884491\n",
      "13325it [25:31,  8.68it/s]Train epoch: 2 [batch #13325, batch_size 1, seq length 2500]\tLoss: 4.052386\n",
      "13350it [25:34,  8.74it/s]Train epoch: 2 [batch #13350, batch_size 1, seq length 2500]\tLoss: 3.928814\n",
      "13375it [25:37,  8.77it/s]Train epoch: 2 [batch #13375, batch_size 1, seq length 2500]\tLoss: 3.801418\n",
      "13400it [25:40,  8.68it/s]Train epoch: 2 [batch #13400, batch_size 1, seq length 2500]\tLoss: 3.767495\n",
      "13425it [25:43,  8.75it/s]Train epoch: 2 [batch #13425, batch_size 1, seq length 2500]\tLoss: 3.790449\n",
      "13450it [25:46,  8.64it/s]Train epoch: 2 [batch #13450, batch_size 1, seq length 2500]\tLoss: 3.563955\n",
      "13475it [25:49,  8.75it/s]Train epoch: 2 [batch #13475, batch_size 1, seq length 2500]\tLoss: 3.645223\n",
      "13500it [25:52,  8.74it/s]Train epoch: 2 [batch #13500, batch_size 1, seq length 2500]\tLoss: 3.834205\n",
      "13525it [25:54,  8.72it/s]Train epoch: 2 [batch #13525, batch_size 1, seq length 2500]\tLoss: 3.980448\n",
      "13550it [25:57,  8.72it/s]Train epoch: 2 [batch #13550, batch_size 1, seq length 2500]\tLoss: 3.401395\n",
      "13575it [26:00,  8.62it/s]Train epoch: 2 [batch #13575, batch_size 1, seq length 2500]\tLoss: 3.668053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13600it [26:03,  8.76it/s]Train epoch: 2 [batch #13600, batch_size 1, seq length 2500]\tLoss: 3.880486\n",
      "13625it [26:06,  8.72it/s]Train epoch: 2 [batch #13625, batch_size 1, seq length 2500]\tLoss: 3.716029\n",
      "13650it [26:09,  8.67it/s]Train epoch: 2 [batch #13650, batch_size 1, seq length 2500]\tLoss: 3.862413\n",
      "13675it [26:12,  8.73it/s]Train epoch: 2 [batch #13675, batch_size 1, seq length 2500]\tLoss: 3.917724\n",
      "13700it [26:15,  8.67it/s]Train epoch: 2 [batch #13700, batch_size 1, seq length 2500]\tLoss: 3.957574\n",
      "13725it [26:17,  8.76it/s]Train epoch: 2 [batch #13725, batch_size 1, seq length 2500]\tLoss: 3.565857\n",
      "13750it [26:20,  8.70it/s]Train epoch: 2 [batch #13750, batch_size 1, seq length 2500]\tLoss: 3.984387\n",
      "13775it [26:23,  8.76it/s]Train epoch: 2 [batch #13775, batch_size 1, seq length 2500]\tLoss: 3.787829\n",
      "13800it [26:26,  8.66it/s]Train epoch: 2 [batch #13800, batch_size 1, seq length 2500]\tLoss: 3.506674\n",
      "13825it [26:29,  8.73it/s]Train epoch: 2 [batch #13825, batch_size 1, seq length 2500]\tLoss: 3.596739\n",
      "13850it [26:32,  8.74it/s]Train epoch: 2 [batch #13850, batch_size 1, seq length 2500]\tLoss: 3.920044\n",
      "13875it [26:35,  8.67it/s]Train epoch: 2 [batch #13875, batch_size 1, seq length 2500]\tLoss: 3.543416\n",
      "13900it [26:38,  8.68it/s]Train epoch: 2 [batch #13900, batch_size 1, seq length 2500]\tLoss: 3.632731\n",
      "13925it [26:40,  8.69it/s]Train epoch: 2 [batch #13925, batch_size 1, seq length 2500]\tLoss: 3.562519\n",
      "13950it [26:43,  8.59it/s]Train epoch: 2 [batch #13950, batch_size 1, seq length 2500]\tLoss: 3.793090\n",
      "13975it [26:46,  8.62it/s]Train epoch: 2 [batch #13975, batch_size 1, seq length 2500]\tLoss: 3.840697\n",
      "14000it [26:49,  8.69it/s]Train epoch: 2 [batch #14000, batch_size 1, seq length 2500]\tLoss: 3.818138\n",
      "14025it [26:52,  8.47it/s]Train epoch: 2 [batch #14025, batch_size 1, seq length 2500]\tLoss: 3.562588\n",
      "14050it [26:55,  8.70it/s]Train epoch: 2 [batch #14050, batch_size 1, seq length 2500]\tLoss: 3.669978\n",
      "14075it [26:58,  8.61it/s]Train epoch: 2 [batch #14075, batch_size 1, seq length 2500]\tLoss: 3.691112\n",
      "14100it [27:01,  8.56it/s]Train epoch: 2 [batch #14100, batch_size 1, seq length 2500]\tLoss: 3.611346\n",
      "14125it [27:03,  8.70it/s]Train epoch: 2 [batch #14125, batch_size 1, seq length 2500]\tLoss: 3.442989\n",
      "14150it [27:06,  8.75it/s]Train epoch: 2 [batch #14150, batch_size 1, seq length 2500]\tLoss: 3.769184\n",
      "14175it [27:09,  8.68it/s]Train epoch: 2 [batch #14175, batch_size 1, seq length 2500]\tLoss: 3.848628\n",
      "14200it [27:12,  8.69it/s]Train epoch: 2 [batch #14200, batch_size 1, seq length 2500]\tLoss: 3.988437\n",
      "14225it [27:15,  8.67it/s]Train epoch: 2 [batch #14225, batch_size 1, seq length 2500]\tLoss: 3.611421\n",
      "14250it [27:18,  8.66it/s]Train epoch: 2 [batch #14250, batch_size 1, seq length 2500]\tLoss: 4.197382\n",
      "14275it [27:21,  8.74it/s]Train epoch: 2 [batch #14275, batch_size 1, seq length 2500]\tLoss: 3.779551\n",
      "14300it [27:24,  8.74it/s]Train epoch: 2 [batch #14300, batch_size 1, seq length 2500]\tLoss: 3.873915\n",
      "14325it [27:26,  8.74it/s]Train epoch: 2 [batch #14325, batch_size 1, seq length 2500]\tLoss: 3.335633\n",
      "14350it [27:29,  8.68it/s]Train epoch: 2 [batch #14350, batch_size 1, seq length 2500]\tLoss: 3.894035\n",
      "14375it [27:32,  8.70it/s]Train epoch: 2 [batch #14375, batch_size 1, seq length 2500]\tLoss: 3.595241\n",
      "14400it [27:35,  8.75it/s]Train epoch: 2 [batch #14400, batch_size 1, seq length 2500]\tLoss: 3.429023\n",
      "14425it [27:38,  8.71it/s]Train epoch: 2 [batch #14425, batch_size 1, seq length 2500]\tLoss: 3.724896\n",
      "14450it [27:41,  8.70it/s]Train epoch: 2 [batch #14450, batch_size 1, seq length 2500]\tLoss: 3.418517\n",
      "14475it [27:44,  8.73it/s]Train epoch: 2 [batch #14475, batch_size 1, seq length 2500]\tLoss: 3.453128\n",
      "14500it [27:47,  8.72it/s]Train epoch: 2 [batch #14500, batch_size 1, seq length 2500]\tLoss: 3.486553\n",
      "14525it [27:49,  8.72it/s]Train epoch: 2 [batch #14525, batch_size 1, seq length 2500]\tLoss: 3.752401\n",
      "14550it [27:52,  8.72it/s]Train epoch: 2 [batch #14550, batch_size 1, seq length 2500]\tLoss: 3.605358\n",
      "14575it [27:55,  8.74it/s]Train epoch: 2 [batch #14575, batch_size 1, seq length 2500]\tLoss: 3.561726\n",
      "14600it [27:58,  8.72it/s]Train epoch: 2 [batch #14600, batch_size 1, seq length 2500]\tLoss: 3.929648\n",
      "14625it [28:01,  8.65it/s]Train epoch: 2 [batch #14625, batch_size 1, seq length 2500]\tLoss: 3.810381\n",
      "14650it [28:04,  8.72it/s]Train epoch: 2 [batch #14650, batch_size 1, seq length 2500]\tLoss: 3.597214\n",
      "14675it [28:07,  8.71it/s]Train epoch: 2 [batch #14675, batch_size 1, seq length 2500]\tLoss: 3.808329\n",
      "14700it [28:09,  8.69it/s]Train epoch: 2 [batch #14700, batch_size 1, seq length 2500]\tLoss: 3.805870\n",
      "14725it [28:12,  8.69it/s]Train epoch: 2 [batch #14725, batch_size 1, seq length 2500]\tLoss: 3.682981\n",
      "14750it [28:15,  8.71it/s]Train epoch: 2 [batch #14750, batch_size 1, seq length 2500]\tLoss: 3.868496\n",
      "14775it [28:18,  8.68it/s]Train epoch: 2 [batch #14775, batch_size 1, seq length 2500]\tLoss: 4.005050\n",
      "14800it [28:21,  8.70it/s]Train epoch: 2 [batch #14800, batch_size 1, seq length 2500]\tLoss: 3.400367\n",
      "14825it [28:24,  8.74it/s]Train epoch: 2 [batch #14825, batch_size 1, seq length 2500]\tLoss: 3.767498\n",
      "14850it [28:27,  8.75it/s]Train epoch: 2 [batch #14850, batch_size 1, seq length 2500]\tLoss: 3.709470\n",
      "14875it [28:30,  8.76it/s]Train epoch: 2 [batch #14875, batch_size 1, seq length 2500]\tLoss: 3.793626\n",
      "14900it [28:32,  8.71it/s]Train epoch: 2 [batch #14900, batch_size 1, seq length 2500]\tLoss: 3.853764\n",
      "14925it [28:35,  8.73it/s]Train epoch: 2 [batch #14925, batch_size 1, seq length 2500]\tLoss: 3.623133\n",
      "14950it [28:38,  8.74it/s]Train epoch: 2 [batch #14950, batch_size 1, seq length 2500]\tLoss: 3.568733\n",
      "14975it [28:41,  8.74it/s]Train epoch: 2 [batch #14975, batch_size 1, seq length 2500]\tLoss: 3.904538\n",
      "15000it [28:44,  8.71it/s]Train epoch: 2 [batch #15000, batch_size 1, seq length 2500]\tLoss: 3.896099\n",
      "15025it [28:47,  8.72it/s]Train epoch: 2 [batch #15025, batch_size 1, seq length 2500]\tLoss: 3.783860\n",
      "15050it [28:50,  8.76it/s]Train epoch: 2 [batch #15050, batch_size 1, seq length 2500]\tLoss: 3.737864\n",
      "15075it [28:53,  8.76it/s]Train epoch: 2 [batch #15075, batch_size 1, seq length 2500]\tLoss: 3.855514\n",
      "15100it [28:55,  8.71it/s]Train epoch: 2 [batch #15100, batch_size 1, seq length 2500]\tLoss: 3.624402\n",
      "15125it [28:58,  8.79it/s]Train epoch: 2 [batch #15125, batch_size 1, seq length 2500]\tLoss: 4.161717\n",
      "15150it [29:01,  8.76it/s]Train epoch: 2 [batch #15150, batch_size 1, seq length 2500]\tLoss: 3.660708\n",
      "15175it [29:04,  8.71it/s]Train epoch: 2 [batch #15175, batch_size 1, seq length 2500]\tLoss: 3.777057\n",
      "15200it [29:07,  8.74it/s]Train epoch: 2 [batch #15200, batch_size 1, seq length 2500]\tLoss: 3.781191\n",
      "15225it [29:10,  8.77it/s]Train epoch: 2 [batch #15225, batch_size 1, seq length 2500]\tLoss: 3.723144\n",
      "15250it [29:13,  8.71it/s]Train epoch: 2 [batch #15250, batch_size 1, seq length 2500]\tLoss: 3.589095\n",
      "15275it [29:15,  8.72it/s]Train epoch: 2 [batch #15275, batch_size 1, seq length 2500]\tLoss: 3.922185\n",
      "15300it [29:18,  8.73it/s]Train epoch: 2 [batch #15300, batch_size 1, seq length 2500]\tLoss: 3.507367\n",
      "15325it [29:21,  8.73it/s]Train epoch: 2 [batch #15325, batch_size 1, seq length 2500]\tLoss: 3.727419\n",
      "15350it [29:24,  8.68it/s]Train epoch: 2 [batch #15350, batch_size 1, seq length 2500]\tLoss: 3.842218\n",
      "15375it [29:27,  8.74it/s]Train epoch: 2 [batch #15375, batch_size 1, seq length 2500]\tLoss: 3.556840\n",
      "15400it [29:30,  8.72it/s]Train epoch: 2 [batch #15400, batch_size 1, seq length 2500]\tLoss: 3.500557\n",
      "15425it [29:33,  8.74it/s]Train epoch: 2 [batch #15425, batch_size 1, seq length 2500]\tLoss: 3.495412\n",
      "15450it [29:36,  8.68it/s]Train epoch: 2 [batch #15450, batch_size 1, seq length 2500]\tLoss: 3.640469\n",
      "15475it [29:38,  8.43it/s]Train epoch: 2 [batch #15475, batch_size 1, seq length 2500]\tLoss: 3.849515\n",
      "15500it [29:41,  8.75it/s]Train epoch: 2 [batch #15500, batch_size 1, seq length 2500]\tLoss: 3.602334\n",
      "15525it [29:44,  8.60it/s]Train epoch: 2 [batch #15525, batch_size 1, seq length 2500]\tLoss: 3.976783\n",
      "15550it [29:47,  8.68it/s]Train epoch: 2 [batch #15550, batch_size 1, seq length 2500]\tLoss: 3.946071\n",
      "15575it [29:50,  8.64it/s]Train epoch: 2 [batch #15575, batch_size 1, seq length 2500]\tLoss: 3.812308\n",
      "15600it [29:53,  8.72it/s]Train epoch: 2 [batch #15600, batch_size 1, seq length 2500]\tLoss: 3.607605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625it [29:56,  8.61it/s]Train epoch: 2 [batch #15625, batch_size 1, seq length 2500]\tLoss: 3.842924\n",
      "15650it [29:59,  8.55it/s]Train epoch: 2 [batch #15650, batch_size 1, seq length 2500]\tLoss: 3.549496\n",
      "15675it [30:01,  8.76it/s]Train epoch: 2 [batch #15675, batch_size 1, seq length 2500]\tLoss: 3.767890\n",
      "15700it [30:04,  8.64it/s]Train epoch: 2 [batch #15700, batch_size 1, seq length 2500]\tLoss: 3.756682\n",
      "15725it [30:07,  8.60it/s]Train epoch: 2 [batch #15725, batch_size 1, seq length 2500]\tLoss: 3.256477\n",
      "15750it [30:10,  8.76it/s]Train epoch: 2 [batch #15750, batch_size 1, seq length 2500]\tLoss: 3.575523\n",
      "15775it [30:13,  8.64it/s]Train epoch: 2 [batch #15775, batch_size 1, seq length 2500]\tLoss: 3.599713\n",
      "15800it [30:16,  8.73it/s]Train epoch: 2 [batch #15800, batch_size 1, seq length 2500]\tLoss: 3.629969\n",
      "15825it [30:19,  8.74it/s]Train epoch: 2 [batch #15825, batch_size 1, seq length 2500]\tLoss: 3.586845\n",
      "15850it [30:22,  8.72it/s]Train epoch: 2 [batch #15850, batch_size 1, seq length 2500]\tLoss: 3.621960\n",
      "15875it [30:24,  8.69it/s]Train epoch: 2 [batch #15875, batch_size 1, seq length 2500]\tLoss: 3.691431\n",
      "15900it [30:27,  8.69it/s]Train epoch: 2 [batch #15900, batch_size 1, seq length 2500]\tLoss: 3.510032\n",
      "15925it [30:30,  8.54it/s]Train epoch: 2 [batch #15925, batch_size 1, seq length 2500]\tLoss: 3.768254\n",
      "15950it [30:33,  8.71it/s]Train epoch: 2 [batch #15950, batch_size 1, seq length 2500]\tLoss: 3.303983\n",
      "15975it [30:36,  8.69it/s]Train epoch: 2 [batch #15975, batch_size 1, seq length 2500]\tLoss: 3.698106\n",
      "16000it [30:39,  8.74it/s]Train epoch: 2 [batch #16000, batch_size 1, seq length 2500]\tLoss: 3.221755\n",
      "16025it [30:42,  8.75it/s]Train epoch: 2 [batch #16025, batch_size 1, seq length 2500]\tLoss: 3.700158\n",
      "16050it [30:45,  8.68it/s]Train epoch: 2 [batch #16050, batch_size 1, seq length 2500]\tLoss: 3.610914\n",
      "16075it [30:47,  8.68it/s]Train epoch: 2 [batch #16075, batch_size 1, seq length 2500]\tLoss: 3.462466\n",
      "16100it [30:50,  8.69it/s]Train epoch: 2 [batch #16100, batch_size 1, seq length 2500]\tLoss: 3.635408\n",
      "16125it [30:53,  8.71it/s]Train epoch: 2 [batch #16125, batch_size 1, seq length 2500]\tLoss: 3.893255\n",
      "16150it [30:56,  8.74it/s]Train epoch: 2 [batch #16150, batch_size 1, seq length 2500]\tLoss: 3.660821\n",
      "16175it [30:59,  8.68it/s]Train epoch: 2 [batch #16175, batch_size 1, seq length 2500]\tLoss: 3.902916\n",
      "16200it [31:02,  8.72it/s]Train epoch: 2 [batch #16200, batch_size 1, seq length 2500]\tLoss: 3.569144\n",
      "16225it [31:05,  8.65it/s]Train epoch: 2 [batch #16225, batch_size 1, seq length 2500]\tLoss: 3.662114\n",
      "16250it [31:08,  8.74it/s]Train epoch: 2 [batch #16250, batch_size 1, seq length 2500]\tLoss: 3.610959\n",
      "16275it [31:10,  8.57it/s]Train epoch: 2 [batch #16275, batch_size 1, seq length 2500]\tLoss: 3.828376\n",
      "16300it [31:13,  8.72it/s]Train epoch: 2 [batch #16300, batch_size 1, seq length 2500]\tLoss: 3.652854\n",
      "16325it [31:16,  8.68it/s]Train epoch: 2 [batch #16325, batch_size 1, seq length 2500]\tLoss: 3.820713\n",
      "16350it [31:19,  8.71it/s]Train epoch: 2 [batch #16350, batch_size 1, seq length 2500]\tLoss: 3.517107\n",
      "16375it [31:22,  8.76it/s]Train epoch: 2 [batch #16375, batch_size 1, seq length 2500]\tLoss: 3.913778\n",
      "16400it [31:25,  8.73it/s]Train epoch: 2 [batch #16400, batch_size 1, seq length 2500]\tLoss: 3.688522\n",
      "16425it [31:28,  8.63it/s]Train epoch: 2 [batch #16425, batch_size 1, seq length 2500]\tLoss: 3.579334\n",
      "16450it [31:31,  8.75it/s]Train epoch: 2 [batch #16450, batch_size 1, seq length 2500]\tLoss: 3.864495\n",
      "16475it [31:33,  8.73it/s]Train epoch: 2 [batch #16475, batch_size 1, seq length 2500]\tLoss: 3.698135\n",
      "16500it [31:36,  8.59it/s]Train epoch: 2 [batch #16500, batch_size 1, seq length 2500]\tLoss: 3.695093\n",
      "16525it [31:39,  8.70it/s]Train epoch: 2 [batch #16525, batch_size 1, seq length 2500]\tLoss: 3.744451\n",
      "16550it [31:42,  8.74it/s]Train epoch: 2 [batch #16550, batch_size 1, seq length 2500]\tLoss: 3.602355\n",
      "16575it [31:45,  8.72it/s]Train epoch: 2 [batch #16575, batch_size 1, seq length 2500]\tLoss: 3.652753\n",
      "16600it [31:48,  8.59it/s]Train epoch: 2 [batch #16600, batch_size 1, seq length 2500]\tLoss: 3.496746\n",
      "16625it [31:51,  8.72it/s]Train epoch: 2 [batch #16625, batch_size 1, seq length 2500]\tLoss: 3.703344\n",
      "16650it [31:54,  8.75it/s]Train epoch: 2 [batch #16650, batch_size 1, seq length 2500]\tLoss: 4.036049\n",
      "16675it [31:56,  8.71it/s]Train epoch: 2 [batch #16675, batch_size 1, seq length 2500]\tLoss: 3.794533\n",
      "16700it [31:59,  8.77it/s]Train epoch: 2 [batch #16700, batch_size 1, seq length 2500]\tLoss: 3.617481\n",
      "16725it [32:02,  8.73it/s]Train epoch: 2 [batch #16725, batch_size 1, seq length 2500]\tLoss: 4.002368\n",
      "16750it [32:05,  8.72it/s]Train epoch: 2 [batch #16750, batch_size 1, seq length 2500]\tLoss: 3.825681\n",
      "16775it [32:08,  8.67it/s]Train epoch: 2 [batch #16775, batch_size 1, seq length 2500]\tLoss: 3.829980\n",
      "16800it [32:11,  8.75it/s]Train epoch: 2 [batch #16800, batch_size 1, seq length 2500]\tLoss: 3.389452\n",
      "16825it [32:14,  8.67it/s]Train epoch: 2 [batch #16825, batch_size 1, seq length 2500]\tLoss: 3.607141\n",
      "16850it [32:17,  8.68it/s]Train epoch: 2 [batch #16850, batch_size 1, seq length 2500]\tLoss: 3.569978\n",
      "16875it [32:19,  8.70it/s]Train epoch: 2 [batch #16875, batch_size 1, seq length 2500]\tLoss: 3.906590\n",
      "16900it [32:22,  8.70it/s]Train epoch: 2 [batch #16900, batch_size 1, seq length 2500]\tLoss: 3.766083\n",
      "16925it [32:25,  8.77it/s]Train epoch: 2 [batch #16925, batch_size 1, seq length 2500]\tLoss: 3.751299\n",
      "16950it [32:28,  8.70it/s]Train epoch: 2 [batch #16950, batch_size 1, seq length 2500]\tLoss: 3.433552\n",
      "16975it [32:31,  8.64it/s]Train epoch: 2 [batch #16975, batch_size 1, seq length 2500]\tLoss: 3.968911\n",
      "17000it [32:34,  8.74it/s]Train epoch: 2 [batch #17000, batch_size 1, seq length 2500]\tLoss: 3.637578\n",
      "17025it [32:37,  8.71it/s]Train epoch: 2 [batch #17025, batch_size 1, seq length 2500]\tLoss: 3.840589\n",
      "17050it [32:40,  8.64it/s]Train epoch: 2 [batch #17050, batch_size 1, seq length 2500]\tLoss: 3.907562\n",
      "17075it [32:42,  8.71it/s]Train epoch: 2 [batch #17075, batch_size 1, seq length 2500]\tLoss: 3.808612\n",
      "17100it [32:45,  8.69it/s]Train epoch: 2 [batch #17100, batch_size 1, seq length 2500]\tLoss: 3.830824\n",
      "17125it [32:48,  8.63it/s]Train epoch: 2 [batch #17125, batch_size 1, seq length 2500]\tLoss: 3.591912\n",
      "17150it [32:51,  8.69it/s]Train epoch: 2 [batch #17150, batch_size 1, seq length 2500]\tLoss: 3.445621\n",
      "17175it [32:54,  8.68it/s]Train epoch: 2 [batch #17175, batch_size 1, seq length 2500]\tLoss: 3.458351\n",
      "17200it [32:57,  8.69it/s]Train epoch: 2 [batch #17200, batch_size 1, seq length 2500]\tLoss: 3.731344\n",
      "17225it [33:00,  8.69it/s]Train epoch: 2 [batch #17225, batch_size 1, seq length 2500]\tLoss: 3.595492\n",
      "17250it [33:03,  8.73it/s]Train epoch: 2 [batch #17250, batch_size 1, seq length 2500]\tLoss: 3.864383\n",
      "17275it [33:05,  8.68it/s]Train epoch: 2 [batch #17275, batch_size 1, seq length 2500]\tLoss: 4.017895\n",
      "17300it [33:08,  8.71it/s]Train epoch: 2 [batch #17300, batch_size 1, seq length 2500]\tLoss: 3.582378\n",
      "17325it [33:11,  8.70it/s]Train epoch: 2 [batch #17325, batch_size 1, seq length 2500]\tLoss: 3.512002\n",
      "17350it [33:14,  8.67it/s]Train epoch: 2 [batch #17350, batch_size 1, seq length 2500]\tLoss: 3.937550\n",
      "17375it [33:17,  8.74it/s]Train epoch: 2 [batch #17375, batch_size 1, seq length 2500]\tLoss: 3.827152\n",
      "17400it [33:20,  8.72it/s]Train epoch: 2 [batch #17400, batch_size 1, seq length 2500]\tLoss: 3.774539\n",
      "17425it [33:23,  8.76it/s]Train epoch: 2 [batch #17425, batch_size 1, seq length 2500]\tLoss: 3.706072\n",
      "17450it [33:25,  8.73it/s]Train epoch: 2 [batch #17450, batch_size 1, seq length 2500]\tLoss: 3.870851\n",
      "17475it [33:28,  8.75it/s]Train epoch: 2 [batch #17475, batch_size 1, seq length 2500]\tLoss: 3.733911\n",
      "17500it [33:31,  8.75it/s]Train epoch: 2 [batch #17500, batch_size 1, seq length 2500]\tLoss: 3.474053\n",
      "17525it [33:34,  8.73it/s]Train epoch: 2 [batch #17525, batch_size 1, seq length 2500]\tLoss: 3.468182\n",
      "17550it [33:37,  8.73it/s]Train epoch: 2 [batch #17550, batch_size 1, seq length 2500]\tLoss: 3.727669\n",
      "17575it [33:40,  8.76it/s]Train epoch: 2 [batch #17575, batch_size 1, seq length 2500]\tLoss: 3.737624\n",
      "17600it [33:43,  8.70it/s]Train epoch: 2 [batch #17600, batch_size 1, seq length 2500]\tLoss: 3.564120\n",
      "17625it [33:46,  8.73it/s]Train epoch: 2 [batch #17625, batch_size 1, seq length 2500]\tLoss: 3.717555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17650it [33:48,  8.77it/s]Train epoch: 2 [batch #17650, batch_size 1, seq length 2500]\tLoss: 3.851153\n",
      "17675it [33:51,  8.75it/s]Train epoch: 2 [batch #17675, batch_size 1, seq length 2500]\tLoss: 3.720352\n",
      "17700it [33:54,  8.56it/s]Train epoch: 2 [batch #17700, batch_size 1, seq length 2500]\tLoss: 3.659832\n",
      "17725it [33:57,  8.73it/s]Train epoch: 2 [batch #17725, batch_size 1, seq length 2500]\tLoss: 3.651109\n",
      "17750it [34:00,  8.65it/s]Train epoch: 2 [batch #17750, batch_size 1, seq length 2500]\tLoss: 3.729425\n",
      "17775it [34:03,  8.70it/s]Train epoch: 2 [batch #17775, batch_size 1, seq length 2500]\tLoss: 3.941981\n",
      "17800it [34:06,  8.72it/s]Train epoch: 2 [batch #17800, batch_size 1, seq length 2500]\tLoss: 3.590267\n",
      "17825it [34:09,  8.53it/s]Train epoch: 2 [batch #17825, batch_size 1, seq length 2500]\tLoss: 3.281004\n",
      "17850it [34:11,  8.73it/s]Train epoch: 2 [batch #17850, batch_size 1, seq length 2500]\tLoss: 3.592220\n",
      "17875it [34:14,  8.68it/s]Train epoch: 2 [batch #17875, batch_size 1, seq length 2500]\tLoss: 3.690869\n",
      "17900it [34:17,  8.78it/s]Train epoch: 2 [batch #17900, batch_size 1, seq length 2500]\tLoss: 3.907521\n",
      "17925it [34:20,  8.71it/s]Train epoch: 2 [batch #17925, batch_size 1, seq length 2500]\tLoss: 3.446284\n",
      "17950it [34:23,  8.71it/s]Train epoch: 2 [batch #17950, batch_size 1, seq length 2500]\tLoss: 3.840355\n",
      "17975it [34:26,  8.74it/s]Train epoch: 2 [batch #17975, batch_size 1, seq length 2500]\tLoss: 3.442061\n",
      "18000it [34:29,  8.57it/s]Train epoch: 2 [batch #18000, batch_size 1, seq length 2500]\tLoss: 3.564565\n",
      "18025it [34:32,  8.66it/s]Train epoch: 2 [batch #18025, batch_size 1, seq length 2500]\tLoss: 3.475694\n",
      "18050it [34:34,  8.70it/s]Train epoch: 2 [batch #18050, batch_size 1, seq length 2500]\tLoss: 3.558615\n",
      "18075it [34:37,  8.72it/s]Train epoch: 2 [batch #18075, batch_size 1, seq length 2500]\tLoss: 3.852478\n",
      "18100it [34:40,  8.66it/s]Train epoch: 2 [batch #18100, batch_size 1, seq length 2500]\tLoss: 3.354475\n",
      "18125it [34:43,  8.71it/s]Train epoch: 2 [batch #18125, batch_size 1, seq length 2500]\tLoss: 3.711993\n",
      "18150it [34:46,  8.68it/s]Train epoch: 2 [batch #18150, batch_size 1, seq length 2500]\tLoss: 3.709397\n",
      "18175it [34:49,  8.73it/s]Train epoch: 2 [batch #18175, batch_size 1, seq length 2500]\tLoss: 3.761514\n",
      "18200it [34:52,  8.75it/s]Train epoch: 2 [batch #18200, batch_size 1, seq length 2500]\tLoss: 3.575559\n",
      "18225it [34:55,  8.72it/s]Train epoch: 2 [batch #18225, batch_size 1, seq length 2500]\tLoss: 3.608037\n",
      "18250it [34:57,  8.74it/s]Train epoch: 2 [batch #18250, batch_size 1, seq length 2500]\tLoss: 3.803755\n",
      "18275it [35:00,  8.73it/s]Train epoch: 2 [batch #18275, batch_size 1, seq length 2500]\tLoss: 3.721997\n",
      "18300it [35:03,  8.71it/s]Train epoch: 2 [batch #18300, batch_size 1, seq length 2500]\tLoss: 3.252818\n",
      "18325it [35:06,  8.72it/s]Train epoch: 2 [batch #18325, batch_size 1, seq length 2500]\tLoss: 3.939842\n",
      "18350it [35:09,  8.76it/s]Train epoch: 2 [batch #18350, batch_size 1, seq length 2500]\tLoss: 3.583886\n",
      "18375it [35:12,  8.68it/s]Train epoch: 2 [batch #18375, batch_size 1, seq length 2500]\tLoss: 3.949049\n",
      "18400it [35:15,  8.70it/s]Train epoch: 2 [batch #18400, batch_size 1, seq length 2500]\tLoss: 3.521292\n",
      "18425it [35:18,  8.65it/s]Train epoch: 2 [batch #18425, batch_size 1, seq length 2500]\tLoss: 3.883265\n",
      "18450it [35:20,  8.68it/s]Train epoch: 2 [batch #18450, batch_size 1, seq length 2500]\tLoss: 3.853592\n",
      "18475it [35:23,  8.72it/s]Train epoch: 2 [batch #18475, batch_size 1, seq length 2500]\tLoss: 3.603794\n",
      "18500it [35:26,  8.70it/s]Train epoch: 2 [batch #18500, batch_size 1, seq length 2500]\tLoss: 3.573113\n",
      "18525it [35:29,  8.70it/s]Train epoch: 2 [batch #18525, batch_size 1, seq length 2500]\tLoss: 3.820436\n",
      "18550it [35:32,  8.66it/s]Train epoch: 2 [batch #18550, batch_size 1, seq length 2500]\tLoss: 4.031538\n",
      "18575it [35:35,  8.72it/s]Train epoch: 2 [batch #18575, batch_size 1, seq length 2500]\tLoss: 3.821237\n",
      "18600it [35:38,  8.72it/s]Train epoch: 2 [batch #18600, batch_size 1, seq length 2500]\tLoss: 3.759503\n",
      "18625it [35:40,  8.74it/s]Train epoch: 2 [batch #18625, batch_size 1, seq length 2500]\tLoss: 3.447438\n",
      "18650it [35:43,  8.66it/s]Train epoch: 2 [batch #18650, batch_size 1, seq length 2500]\tLoss: 3.933171\n",
      "18675it [35:46,  8.70it/s]Train epoch: 2 [batch #18675, batch_size 1, seq length 2500]\tLoss: 3.715336\n",
      "18700it [35:49,  8.76it/s]Train epoch: 2 [batch #18700, batch_size 1, seq length 2500]\tLoss: 3.816510\n",
      "18725it [35:52,  8.74it/s]Train epoch: 2 [batch #18725, batch_size 1, seq length 2500]\tLoss: 4.165575\n",
      "18750it [35:55,  8.62it/s]Train epoch: 2 [batch #18750, batch_size 1, seq length 2500]\tLoss: 3.585114\n",
      "18775it [35:58,  8.72it/s]Train epoch: 2 [batch #18775, batch_size 1, seq length 2500]\tLoss: 3.552543\n",
      "18800it [36:01,  8.66it/s]Train epoch: 2 [batch #18800, batch_size 1, seq length 2500]\tLoss: 3.851761\n",
      "18825it [36:03,  8.72it/s]Train epoch: 2 [batch #18825, batch_size 1, seq length 2500]\tLoss: 3.824023\n",
      "18850it [36:06,  8.75it/s]Train epoch: 2 [batch #18850, batch_size 1, seq length 2500]\tLoss: 4.115960\n",
      "18875it [36:09,  8.72it/s]Train epoch: 2 [batch #18875, batch_size 1, seq length 2500]\tLoss: 3.456087\n",
      "18900it [36:12,  8.74it/s]Train epoch: 2 [batch #18900, batch_size 1, seq length 2500]\tLoss: 3.716287\n",
      "18925it [36:15,  8.70it/s]Train epoch: 2 [batch #18925, batch_size 1, seq length 2500]\tLoss: 3.732060\n",
      "18950it [36:18,  8.63it/s]Train epoch: 2 [batch #18950, batch_size 1, seq length 2500]\tLoss: 3.832185\n",
      "18975it [36:21,  8.68it/s]Train epoch: 2 [batch #18975, batch_size 1, seq length 2500]\tLoss: 3.600974\n",
      "19000it [36:24,  8.68it/s]Train epoch: 2 [batch #19000, batch_size 1, seq length 2500]\tLoss: 3.980326\n",
      "19025it [36:26,  8.63it/s]Train epoch: 2 [batch #19025, batch_size 1, seq length 2500]\tLoss: 3.426374\n",
      "19050it [36:29,  8.72it/s]Train epoch: 2 [batch #19050, batch_size 1, seq length 2500]\tLoss: 3.931346\n",
      "19075it [36:32,  8.65it/s]Train epoch: 2 [batch #19075, batch_size 1, seq length 2500]\tLoss: 3.522801\n",
      "19100it [36:35,  8.73it/s]Train epoch: 2 [batch #19100, batch_size 1, seq length 2500]\tLoss: 3.498450\n",
      "19125it [36:38,  8.69it/s]Train epoch: 2 [batch #19125, batch_size 1, seq length 2500]\tLoss: 3.558360\n",
      "19150it [36:41,  8.70it/s]Train epoch: 2 [batch #19150, batch_size 1, seq length 2500]\tLoss: 3.549568\n",
      "19175it [36:44,  8.64it/s]Train epoch: 2 [batch #19175, batch_size 1, seq length 2500]\tLoss: 3.856709\n",
      "19200it [36:47,  8.68it/s]Train epoch: 2 [batch #19200, batch_size 1, seq length 2500]\tLoss: 3.742254\n",
      "19225it [36:49,  8.77it/s]Train epoch: 2 [batch #19225, batch_size 1, seq length 2500]\tLoss: 3.728409\n",
      "19250it [36:52,  8.74it/s]Train epoch: 2 [batch #19250, batch_size 1, seq length 2500]\tLoss: 3.778576\n",
      "19275it [36:55,  8.72it/s]Train epoch: 2 [batch #19275, batch_size 1, seq length 2500]\tLoss: 3.692370\n",
      "19300it [36:58,  8.75it/s]Train epoch: 2 [batch #19300, batch_size 1, seq length 2500]\tLoss: 3.633174\n",
      "19325it [37:01,  8.75it/s]Train epoch: 2 [batch #19325, batch_size 1, seq length 2500]\tLoss: 4.069465\n",
      "19350it [37:04,  8.69it/s]Train epoch: 2 [batch #19350, batch_size 1, seq length 2500]\tLoss: 3.351809\n",
      "19375it [37:07,  8.70it/s]Train epoch: 2 [batch #19375, batch_size 1, seq length 2500]\tLoss: 3.616868\n",
      "19400it [37:10,  8.76it/s]Train epoch: 2 [batch #19400, batch_size 1, seq length 2500]\tLoss: 3.605407\n",
      "19425it [37:12,  8.74it/s]Train epoch: 2 [batch #19425, batch_size 1, seq length 2500]\tLoss: 3.328368\n",
      "19450it [37:15,  8.75it/s]Train epoch: 2 [batch #19450, batch_size 1, seq length 2500]\tLoss: 3.364794\n",
      "19475it [37:18,  8.75it/s]Train epoch: 2 [batch #19475, batch_size 1, seq length 2500]\tLoss: 3.679965\n",
      "19500it [37:21,  8.74it/s]Train epoch: 2 [batch #19500, batch_size 1, seq length 2500]\tLoss: 3.390157\n",
      "19525it [37:24,  8.62it/s]Train epoch: 2 [batch #19525, batch_size 1, seq length 2500]\tLoss: 3.226019\n",
      "19550it [37:27,  8.72it/s]Train epoch: 2 [batch #19550, batch_size 1, seq length 2500]\tLoss: 3.855220\n",
      "19575it [37:30,  8.59it/s]Train epoch: 2 [batch #19575, batch_size 1, seq length 2500]\tLoss: 3.452873\n",
      "19600it [37:32,  8.72it/s]Train epoch: 2 [batch #19600, batch_size 1, seq length 2500]\tLoss: 3.495861\n",
      "19625it [37:35,  8.70it/s]Train epoch: 2 [batch #19625, batch_size 1, seq length 2500]\tLoss: 3.514561\n",
      "19650it [37:38,  8.57it/s]Train epoch: 2 [batch #19650, batch_size 1, seq length 2500]\tLoss: 3.681631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19675it [37:41,  8.76it/s]Train epoch: 2 [batch #19675, batch_size 1, seq length 2500]\tLoss: 3.693984\n",
      "19700it [37:44,  8.73it/s]Train epoch: 2 [batch #19700, batch_size 1, seq length 2500]\tLoss: 3.651012\n",
      "19725it [37:47,  8.71it/s]Train epoch: 2 [batch #19725, batch_size 1, seq length 2500]\tLoss: 3.273237\n",
      "19750it [37:50,  8.67it/s]Train epoch: 2 [batch #19750, batch_size 1, seq length 2500]\tLoss: 3.661398\n",
      "19775it [37:53,  8.70it/s]Train epoch: 2 [batch #19775, batch_size 1, seq length 2500]\tLoss: 3.905738\n",
      "19800it [37:55,  8.72it/s]Train epoch: 2 [batch #19800, batch_size 1, seq length 2500]\tLoss: 3.712088\n",
      "19825it [37:58,  8.77it/s]Train epoch: 2 [batch #19825, batch_size 1, seq length 2500]\tLoss: 3.539512\n",
      "19850it [38:01,  8.73it/s]Train epoch: 2 [batch #19850, batch_size 1, seq length 2500]\tLoss: 3.780112\n",
      "19875it [38:04,  8.76it/s]Train epoch: 2 [batch #19875, batch_size 1, seq length 2500]\tLoss: 3.421761\n",
      "19900it [38:07,  8.72it/s]Train epoch: 2 [batch #19900, batch_size 1, seq length 2500]\tLoss: 4.037701\n",
      "19925it [38:10,  8.77it/s]Train epoch: 2 [batch #19925, batch_size 1, seq length 2500]\tLoss: 3.399452\n",
      "19950it [38:13,  8.68it/s]Train epoch: 2 [batch #19950, batch_size 1, seq length 2500]\tLoss: 3.392044\n",
      "19975it [38:16,  8.61it/s]Train epoch: 2 [batch #19975, batch_size 1, seq length 2500]\tLoss: 3.132780\n",
      "20000it [38:18,  8.74it/s]Train epoch: 2 [batch #20000, batch_size 1, seq length 2500]\tLoss: 3.496281\n",
      "20025it [38:21,  8.71it/s]Train epoch: 2 [batch #20025, batch_size 1, seq length 2500]\tLoss: 3.885537\n",
      "20050it [38:24,  8.71it/s]Train epoch: 2 [batch #20050, batch_size 1, seq length 2500]\tLoss: 3.820356\n",
      "20075it [38:27,  8.68it/s]Train epoch: 2 [batch #20075, batch_size 1, seq length 2500]\tLoss: 3.518289\n",
      "20100it [38:30,  8.75it/s]Train epoch: 2 [batch #20100, batch_size 1, seq length 2500]\tLoss: 3.792856\n",
      "20125it [38:33,  8.74it/s]Train epoch: 2 [batch #20125, batch_size 1, seq length 2500]\tLoss: 3.550883\n",
      "20150it [38:36,  8.70it/s]Train epoch: 2 [batch #20150, batch_size 1, seq length 2500]\tLoss: 3.811514\n",
      "20175it [38:38,  8.68it/s]Train epoch: 2 [batch #20175, batch_size 1, seq length 2500]\tLoss: 3.580491\n",
      "20200it [38:41,  8.71it/s]Train epoch: 2 [batch #20200, batch_size 1, seq length 2500]\tLoss: 3.736500\n",
      "20225it [38:44,  8.65it/s]Train epoch: 2 [batch #20225, batch_size 1, seq length 2500]\tLoss: 3.503316\n",
      "20250it [38:47,  8.65it/s]Train epoch: 2 [batch #20250, batch_size 1, seq length 2500]\tLoss: 3.499785\n",
      "20275it [38:50,  8.68it/s]Train epoch: 2 [batch #20275, batch_size 1, seq length 2500]\tLoss: 3.776606\n",
      "20300it [38:53,  8.73it/s]Train epoch: 2 [batch #20300, batch_size 1, seq length 2500]\tLoss: 3.790121\n",
      "20325it [38:56,  8.52it/s]Train epoch: 2 [batch #20325, batch_size 1, seq length 2500]\tLoss: 3.918093\n",
      "20350it [38:59,  8.70it/s]Train epoch: 2 [batch #20350, batch_size 1, seq length 2500]\tLoss: 3.805281\n",
      "20375it [39:01,  8.66it/s]Train epoch: 2 [batch #20375, batch_size 1, seq length 2500]\tLoss: 3.847846\n",
      "20400it [39:04,  8.70it/s]Train epoch: 2 [batch #20400, batch_size 1, seq length 2500]\tLoss: 3.642863\n",
      "20425it [39:07,  8.66it/s]Train epoch: 2 [batch #20425, batch_size 1, seq length 2500]\tLoss: 3.772917\n",
      "20450it [39:10,  8.75it/s]Train epoch: 2 [batch #20450, batch_size 1, seq length 2500]\tLoss: 3.673770\n",
      "20475it [39:13,  8.73it/s]Train epoch: 2 [batch #20475, batch_size 1, seq length 2500]\tLoss: 3.700019\n",
      "20500it [39:16,  8.70it/s]Train epoch: 2 [batch #20500, batch_size 1, seq length 2500]\tLoss: 3.839341\n",
      "20525it [39:19,  8.64it/s]Train epoch: 2 [batch #20525, batch_size 1, seq length 2500]\tLoss: 3.714717\n",
      "20550it [39:22,  8.70it/s]Train epoch: 2 [batch #20550, batch_size 1, seq length 2500]\tLoss: 3.308563\n",
      "20575it [39:24,  8.71it/s]Train epoch: 2 [batch #20575, batch_size 1, seq length 2500]\tLoss: 3.838501\n",
      "20600it [39:27,  8.59it/s]Train epoch: 2 [batch #20600, batch_size 1, seq length 2500]\tLoss: 3.769230\n",
      "20625it [39:30,  8.67it/s]Train epoch: 2 [batch #20625, batch_size 1, seq length 2500]\tLoss: 3.984434\n",
      "20650it [39:33,  8.71it/s]Train epoch: 2 [batch #20650, batch_size 1, seq length 2500]\tLoss: 3.637588\n",
      "20675it [39:36,  8.71it/s]Train epoch: 2 [batch #20675, batch_size 1, seq length 2500]\tLoss: 3.581947\n",
      "20700it [39:39,  8.67it/s]Train epoch: 2 [batch #20700, batch_size 1, seq length 2500]\tLoss: 3.665013\n",
      "20725it [39:42,  8.74it/s]Train epoch: 2 [batch #20725, batch_size 1, seq length 2500]\tLoss: 3.642452\n",
      "20750it [39:45,  8.61it/s]Train epoch: 2 [batch #20750, batch_size 1, seq length 2500]\tLoss: 3.945825\n",
      "20775it [39:47,  8.71it/s]Train epoch: 2 [batch #20775, batch_size 1, seq length 2500]\tLoss: 3.509331\n",
      "20800it [39:50,  8.75it/s]Train epoch: 2 [batch #20800, batch_size 1, seq length 2500]\tLoss: 3.774599\n",
      "20825it [39:53,  8.71it/s]Train epoch: 2 [batch #20825, batch_size 1, seq length 2500]\tLoss: 3.533049\n",
      "20850it [39:56,  8.70it/s]Train epoch: 2 [batch #20850, batch_size 1, seq length 2500]\tLoss: 3.432226\n",
      "20875it [39:59,  8.73it/s]Train epoch: 2 [batch #20875, batch_size 1, seq length 2500]\tLoss: 3.688074\n",
      "20900it [40:02,  8.69it/s]Train epoch: 2 [batch #20900, batch_size 1, seq length 2500]\tLoss: 3.577716\n",
      "20925it [40:05,  8.70it/s]Train epoch: 2 [batch #20925, batch_size 1, seq length 2500]\tLoss: 3.649858\n",
      "20950it [40:08,  8.76it/s]Train epoch: 2 [batch #20950, batch_size 1, seq length 2500]\tLoss: 3.725506\n",
      "20975it [40:10,  8.69it/s]Train epoch: 2 [batch #20975, batch_size 1, seq length 2500]\tLoss: 3.739103\n",
      "21000it [40:13,  8.70it/s]Train epoch: 2 [batch #21000, batch_size 1, seq length 2500]\tLoss: 3.758562\n",
      "21025it [40:16,  8.75it/s]Train epoch: 2 [batch #21025, batch_size 1, seq length 2500]\tLoss: 3.671958\n",
      "21050it [40:19,  8.77it/s]Train epoch: 2 [batch #21050, batch_size 1, seq length 2500]\tLoss: 3.705283\n",
      "21075it [40:22,  8.75it/s]Train epoch: 2 [batch #21075, batch_size 1, seq length 2500]\tLoss: 3.248112\n",
      "21100it [40:25,  8.68it/s]Train epoch: 2 [batch #21100, batch_size 1, seq length 2500]\tLoss: 3.780104\n",
      "21125it [40:28,  8.75it/s]Train epoch: 2 [batch #21125, batch_size 1, seq length 2500]\tLoss: 3.832691\n",
      "21150it [40:30,  8.71it/s]Train epoch: 2 [batch #21150, batch_size 1, seq length 2500]\tLoss: 3.409149\n",
      "21175it [40:33,  8.72it/s]Train epoch: 2 [batch #21175, batch_size 1, seq length 2500]\tLoss: 3.757607\n",
      "21200it [40:36,  8.75it/s]Train epoch: 2 [batch #21200, batch_size 1, seq length 2500]\tLoss: 3.738955\n",
      "21225it [40:39,  8.72it/s]Train epoch: 2 [batch #21225, batch_size 1, seq length 2500]\tLoss: 3.615371\n",
      "21250it [40:42,  8.54it/s]Train epoch: 2 [batch #21250, batch_size 1, seq length 2500]\tLoss: 3.979977\n",
      "21275it [40:45,  8.75it/s]Train epoch: 2 [batch #21275, batch_size 1, seq length 2500]\tLoss: 3.481004\n",
      "21300it [40:48,  8.70it/s]Train epoch: 2 [batch #21300, batch_size 1, seq length 2500]\tLoss: 3.729248\n",
      "21325it [40:51,  8.72it/s]Train epoch: 2 [batch #21325, batch_size 1, seq length 2500]\tLoss: 3.427137\n",
      "21350it [40:53,  8.74it/s]Train epoch: 2 [batch #21350, batch_size 1, seq length 2500]\tLoss: 3.465252\n",
      "21375it [40:56,  8.68it/s]Train epoch: 2 [batch #21375, batch_size 1, seq length 2500]\tLoss: 3.503366\n",
      "21400it [40:59,  8.71it/s]Train epoch: 2 [batch #21400, batch_size 1, seq length 2500]\tLoss: 3.574908\n",
      "21425it [41:02,  8.75it/s]Train epoch: 2 [batch #21425, batch_size 1, seq length 2500]\tLoss: 3.912115\n",
      "21450it [41:05,  8.67it/s]Train epoch: 2 [batch #21450, batch_size 1, seq length 2500]\tLoss: 3.664052\n",
      "21475it [41:08,  8.73it/s]Train epoch: 2 [batch #21475, batch_size 1, seq length 2500]\tLoss: 4.184693\n",
      "21500it [41:11,  8.75it/s]Train epoch: 2 [batch #21500, batch_size 1, seq length 2500]\tLoss: 3.669218\n",
      "21525it [41:14,  8.71it/s]Train epoch: 2 [batch #21525, batch_size 1, seq length 2500]\tLoss: 3.736847\n",
      "21550it [41:16,  8.74it/s]Train epoch: 2 [batch #21550, batch_size 1, seq length 2500]\tLoss: 3.787332\n",
      "21575it [41:19,  8.68it/s]Train epoch: 2 [batch #21575, batch_size 1, seq length 2500]\tLoss: 3.742247\n",
      "21600it [41:22,  8.63it/s]Train epoch: 2 [batch #21600, batch_size 1, seq length 2500]\tLoss: 3.676031\n",
      "21625it [41:25,  8.69it/s]Train epoch: 2 [batch #21625, batch_size 1, seq length 2500]\tLoss: 3.733495\n",
      "21650it [41:28,  8.67it/s]Train epoch: 2 [batch #21650, batch_size 1, seq length 2500]\tLoss: 3.725790\n",
      "21675it [41:31,  8.75it/s]Train epoch: 2 [batch #21675, batch_size 1, seq length 2500]\tLoss: 3.603912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21700it [41:34,  8.72it/s]Train epoch: 2 [batch #21700, batch_size 1, seq length 2500]\tLoss: 3.728074\n",
      "21725it [41:36,  8.76it/s]Train epoch: 2 [batch #21725, batch_size 1, seq length 2500]\tLoss: 3.704374\n",
      "21750it [41:39,  8.71it/s]Train epoch: 2 [batch #21750, batch_size 1, seq length 2500]\tLoss: 3.454640\n",
      "21775it [41:42,  8.68it/s]Train epoch: 2 [batch #21775, batch_size 1, seq length 2500]\tLoss: 3.811277\n",
      "21800it [41:45,  8.56it/s]Train epoch: 2 [batch #21800, batch_size 1, seq length 2500]\tLoss: 3.469814\n",
      "21825it [41:48,  8.72it/s]Train epoch: 2 [batch #21825, batch_size 1, seq length 2500]\tLoss: 3.589027\n",
      "21850it [41:51,  8.73it/s]Train epoch: 2 [batch #21850, batch_size 1, seq length 2500]\tLoss: 3.737224\n",
      "21875it [41:54,  8.71it/s]Train epoch: 2 [batch #21875, batch_size 1, seq length 2500]\tLoss: 3.448757\n",
      "21900it [41:57,  8.69it/s]Train epoch: 2 [batch #21900, batch_size 1, seq length 2500]\tLoss: 3.580101\n",
      "21925it [41:59,  8.72it/s]Train epoch: 2 [batch #21925, batch_size 1, seq length 2500]\tLoss: 3.821180\n",
      "21950it [42:02,  8.75it/s]Train epoch: 2 [batch #21950, batch_size 1, seq length 2500]\tLoss: 3.630379\n",
      "21975it [42:05,  8.64it/s]Train epoch: 2 [batch #21975, batch_size 1, seq length 2500]\tLoss: 3.745025\n",
      "22000it [42:08,  8.63it/s]Train epoch: 2 [batch #22000, batch_size 1, seq length 2500]\tLoss: 3.737144\n",
      "22025it [42:11,  8.73it/s]Train epoch: 2 [batch #22025, batch_size 1, seq length 2500]\tLoss: 3.491524\n",
      "22050it [42:14,  8.74it/s]Train epoch: 2 [batch #22050, batch_size 1, seq length 2500]\tLoss: 3.541380\n",
      "22075it [42:17,  8.73it/s]Train epoch: 2 [batch #22075, batch_size 1, seq length 2500]\tLoss: 3.784751\n",
      "22100it [42:20,  8.78it/s]Train epoch: 2 [batch #22100, batch_size 1, seq length 2500]\tLoss: 3.356039\n",
      "22125it [42:22,  8.69it/s]Train epoch: 2 [batch #22125, batch_size 1, seq length 2500]\tLoss: 4.227042\n",
      "22150it [42:25,  8.76it/s]Train epoch: 2 [batch #22150, batch_size 1, seq length 2500]\tLoss: 3.894024\n",
      "22175it [42:28,  8.62it/s]Train epoch: 2 [batch #22175, batch_size 1, seq length 2500]\tLoss: 3.667337\n",
      "22200it [42:31,  8.73it/s]Train epoch: 2 [batch #22200, batch_size 1, seq length 2500]\tLoss: 3.351168\n",
      "22225it [42:34,  8.74it/s]Train epoch: 2 [batch #22225, batch_size 1, seq length 2500]\tLoss: 3.646854\n",
      "22250it [42:37,  8.73it/s]Train epoch: 2 [batch #22250, batch_size 1, seq length 2500]\tLoss: 3.278102\n",
      "22275it [42:40,  8.73it/s]Train epoch: 2 [batch #22275, batch_size 1, seq length 2500]\tLoss: 3.237155\n",
      "22300it [42:43,  8.69it/s]Train epoch: 2 [batch #22300, batch_size 1, seq length 2500]\tLoss: 3.807263\n",
      "22325it [42:45,  8.68it/s]Train epoch: 2 [batch #22325, batch_size 1, seq length 2500]\tLoss: 3.304641\n",
      "22350it [42:48,  8.71it/s]Train epoch: 2 [batch #22350, batch_size 1, seq length 2500]\tLoss: 3.737551\n",
      "22375it [42:51,  8.70it/s]Train epoch: 2 [batch #22375, batch_size 1, seq length 2500]\tLoss: 3.790283\n",
      "22400it [42:54,  8.68it/s]Train epoch: 2 [batch #22400, batch_size 1, seq length 2500]\tLoss: 3.690017\n",
      "22425it [42:57,  8.73it/s]Train epoch: 2 [batch #22425, batch_size 1, seq length 2500]\tLoss: 3.620600\n",
      "22450it [43:00,  8.75it/s]Train epoch: 2 [batch #22450, batch_size 1, seq length 2500]\tLoss: 3.742924\n",
      "22475it [43:03,  8.70it/s]Train epoch: 2 [batch #22475, batch_size 1, seq length 2500]\tLoss: 3.856594\n",
      "22500it [43:05,  8.74it/s]Train epoch: 2 [batch #22500, batch_size 1, seq length 2500]\tLoss: 3.684934\n",
      "22525it [43:08,  8.68it/s]Train epoch: 2 [batch #22525, batch_size 1, seq length 2500]\tLoss: 3.835408\n",
      "22550it [43:11,  8.76it/s]Train epoch: 2 [batch #22550, batch_size 1, seq length 2500]\tLoss: 3.443924\n",
      "22575it [43:14,  8.74it/s]Train epoch: 2 [batch #22575, batch_size 1, seq length 2500]\tLoss: 3.823120\n",
      "22600it [43:17,  8.68it/s]Train epoch: 2 [batch #22600, batch_size 1, seq length 2500]\tLoss: 3.751219\n",
      "22625it [43:20,  8.75it/s]Train epoch: 2 [batch #22625, batch_size 1, seq length 2500]\tLoss: 3.801227\n",
      "22650it [43:23,  8.73it/s]Train epoch: 2 [batch #22650, batch_size 1, seq length 2500]\tLoss: 3.472895\n",
      "22675it [43:26,  8.70it/s]Train epoch: 2 [batch #22675, batch_size 1, seq length 2500]\tLoss: 3.689433\n",
      "22700it [43:28,  8.71it/s]Train epoch: 2 [batch #22700, batch_size 1, seq length 2500]\tLoss: 3.740900\n",
      "22725it [43:31,  8.73it/s]Train epoch: 2 [batch #22725, batch_size 1, seq length 2500]\tLoss: 4.011161\n",
      "22750it [43:34,  8.66it/s]Train epoch: 2 [batch #22750, batch_size 1, seq length 2500]\tLoss: 3.515837\n",
      "22775it [43:37,  8.70it/s]Train epoch: 2 [batch #22775, batch_size 1, seq length 2500]\tLoss: 3.847497\n",
      "22800it [43:40,  8.67it/s]Train epoch: 2 [batch #22800, batch_size 1, seq length 2500]\tLoss: 3.781289\n",
      "22825it [43:43,  8.73it/s]Train epoch: 2 [batch #22825, batch_size 1, seq length 2500]\tLoss: 3.748211\n",
      "22850it [43:46,  8.70it/s]Train epoch: 2 [batch #22850, batch_size 1, seq length 2500]\tLoss: 3.834304\n",
      "22875it [43:49,  8.74it/s]Train epoch: 2 [batch #22875, batch_size 1, seq length 2500]\tLoss: 3.313093\n",
      "22900it [43:51,  8.76it/s]Train epoch: 2 [batch #22900, batch_size 1, seq length 2500]\tLoss: 3.784045\n",
      "22925it [43:54,  8.73it/s]Train epoch: 2 [batch #22925, batch_size 1, seq length 2500]\tLoss: 3.605420\n",
      "22950it [43:57,  8.75it/s]Train epoch: 2 [batch #22950, batch_size 1, seq length 2500]\tLoss: 3.615961\n",
      "22975it [44:00,  8.63it/s]Train epoch: 2 [batch #22975, batch_size 1, seq length 2500]\tLoss: 3.785641\n",
      "23000it [44:03,  8.66it/s]Train epoch: 2 [batch #23000, batch_size 1, seq length 2500]\tLoss: 3.737285\n",
      "23025it [44:06,  8.65it/s]Train epoch: 2 [batch #23025, batch_size 1, seq length 2500]\tLoss: 3.918600\n",
      "23050it [44:09,  8.73it/s]Train epoch: 2 [batch #23050, batch_size 1, seq length 2500]\tLoss: 3.707658\n",
      "23075it [44:12,  8.64it/s]Train epoch: 2 [batch #23075, batch_size 1, seq length 2500]\tLoss: 3.641665\n",
      "23100it [44:14,  8.72it/s]Train epoch: 2 [batch #23100, batch_size 1, seq length 2500]\tLoss: 3.462111\n",
      "23125it [44:17,  8.70it/s]Train epoch: 2 [batch #23125, batch_size 1, seq length 2500]\tLoss: 3.454793\n",
      "23150it [44:20,  8.72it/s]Train epoch: 2 [batch #23150, batch_size 1, seq length 2500]\tLoss: 3.763652\n",
      "23175it [44:23,  8.68it/s]Train epoch: 2 [batch #23175, batch_size 1, seq length 2500]\tLoss: 3.648180\n",
      "23200it [44:26,  8.74it/s]Train epoch: 2 [batch #23200, batch_size 1, seq length 2500]\tLoss: 3.901250\n",
      "23225it [44:29,  8.73it/s]Train epoch: 2 [batch #23225, batch_size 1, seq length 2500]\tLoss: 3.406416\n",
      "23250it [44:32,  8.72it/s]Train epoch: 2 [batch #23250, batch_size 1, seq length 2500]\tLoss: 3.791453\n",
      "23275it [44:35,  8.70it/s]Train epoch: 2 [batch #23275, batch_size 1, seq length 2500]\tLoss: 3.609013\n",
      "23300it [44:37,  8.77it/s]Train epoch: 2 [batch #23300, batch_size 1, seq length 2500]\tLoss: 4.112868\n",
      "23325it [44:40,  8.69it/s]Train epoch: 2 [batch #23325, batch_size 1, seq length 2500]\tLoss: 4.139863\n",
      "23350it [44:43,  8.69it/s]Train epoch: 2 [batch #23350, batch_size 1, seq length 2500]\tLoss: 3.856962\n",
      "23375it [44:46,  8.74it/s]Train epoch: 2 [batch #23375, batch_size 1, seq length 2500]\tLoss: 3.859771\n",
      "23400it [44:49,  8.68it/s]Train epoch: 2 [batch #23400, batch_size 1, seq length 2500]\tLoss: 3.477448\n",
      "23425it [44:52,  8.73it/s]Train epoch: 2 [batch #23425, batch_size 1, seq length 2500]\tLoss: 3.661413\n",
      "23450it [44:55,  8.74it/s]Train epoch: 2 [batch #23450, batch_size 1, seq length 2500]\tLoss: 3.892933\n",
      "23475it [44:58,  8.69it/s]Train epoch: 2 [batch #23475, batch_size 1, seq length 2500]\tLoss: 3.792065\n",
      "23500it [45:00,  8.74it/s]Train epoch: 2 [batch #23500, batch_size 1, seq length 2500]\tLoss: 3.632629\n",
      "23525it [45:03,  8.75it/s]Train epoch: 2 [batch #23525, batch_size 1, seq length 2500]\tLoss: 3.296874\n",
      "23550it [45:06,  8.72it/s]Train epoch: 2 [batch #23550, batch_size 1, seq length 2500]\tLoss: 3.188143\n",
      "23575it [45:09,  8.71it/s]Train epoch: 2 [batch #23575, batch_size 1, seq length 2500]\tLoss: 3.573811\n",
      "23600it [45:12,  8.75it/s]Train epoch: 2 [batch #23600, batch_size 1, seq length 2500]\tLoss: 3.610893\n",
      "23625it [45:15,  8.75it/s]Train epoch: 2 [batch #23625, batch_size 1, seq length 2500]\tLoss: 3.413991\n",
      "23650it [45:18,  8.69it/s]Train epoch: 2 [batch #23650, batch_size 1, seq length 2500]\tLoss: 3.880973\n",
      "23675it [45:21,  8.68it/s]Train epoch: 2 [batch #23675, batch_size 1, seq length 2500]\tLoss: 3.890639\n",
      "23700it [45:23,  8.74it/s]Train epoch: 2 [batch #23700, batch_size 1, seq length 2500]\tLoss: 3.213583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23725it [45:26,  8.73it/s]Train epoch: 2 [batch #23725, batch_size 1, seq length 2500]\tLoss: 3.802282\n",
      "23750it [45:29,  8.56it/s]Train epoch: 2 [batch #23750, batch_size 1, seq length 2500]\tLoss: 3.095107\n",
      "23775it [45:32,  8.74it/s]Train epoch: 2 [batch #23775, batch_size 1, seq length 2500]\tLoss: 3.776327\n",
      "23800it [45:35,  8.72it/s]Train epoch: 2 [batch #23800, batch_size 1, seq length 2500]\tLoss: 3.727679\n",
      "23825it [45:38,  8.71it/s]Train epoch: 2 [batch #23825, batch_size 1, seq length 2500]\tLoss: 3.740196\n",
      "23850it [45:41,  8.68it/s]Train epoch: 2 [batch #23850, batch_size 1, seq length 2500]\tLoss: 3.960318\n",
      "23875it [45:44,  8.69it/s]Train epoch: 2 [batch #23875, batch_size 1, seq length 2500]\tLoss: 3.743118\n",
      "23900it [45:46,  8.71it/s]Train epoch: 2 [batch #23900, batch_size 1, seq length 2500]\tLoss: 3.632449\n",
      "23925it [45:49,  8.74it/s]Train epoch: 2 [batch #23925, batch_size 1, seq length 2500]\tLoss: 3.708359\n",
      "23950it [45:52,  8.66it/s]Train epoch: 2 [batch #23950, batch_size 1, seq length 2500]\tLoss: 3.767467\n",
      "23975it [45:55,  8.62it/s]Train epoch: 2 [batch #23975, batch_size 1, seq length 2500]\tLoss: 3.583168\n",
      "24000it [45:58,  8.70it/s]Train epoch: 2 [batch #24000, batch_size 1, seq length 2500]\tLoss: 3.770878\n",
      "24025it [46:01,  8.54it/s]Train epoch: 2 [batch #24025, batch_size 1, seq length 2500]\tLoss: 3.741277\n",
      "24050it [46:04,  8.70it/s]Train epoch: 2 [batch #24050, batch_size 1, seq length 2500]\tLoss: 3.544183\n",
      "24075it [46:07,  8.70it/s]Train epoch: 2 [batch #24075, batch_size 1, seq length 2500]\tLoss: 3.863467\n",
      "24100it [46:09,  8.60it/s]Train epoch: 2 [batch #24100, batch_size 1, seq length 2500]\tLoss: 3.630600\n",
      "24125it [46:12,  8.62it/s]Train epoch: 2 [batch #24125, batch_size 1, seq length 2500]\tLoss: 3.535490\n",
      "24150it [46:15,  8.65it/s]Train epoch: 2 [batch #24150, batch_size 1, seq length 2500]\tLoss: 3.843339\n",
      "24175it [46:18,  8.68it/s]Train epoch: 2 [batch #24175, batch_size 1, seq length 2500]\tLoss: 3.364602\n",
      "24200it [46:21,  8.71it/s]Train epoch: 2 [batch #24200, batch_size 1, seq length 2500]\tLoss: 3.707329\n",
      "24225it [46:24,  8.70it/s]Train epoch: 2 [batch #24225, batch_size 1, seq length 2500]\tLoss: 3.654480\n",
      "24250it [46:27,  8.50it/s]Train epoch: 2 [batch #24250, batch_size 1, seq length 2500]\tLoss: 3.673420\n",
      "24275it [46:30,  8.71it/s]Train epoch: 2 [batch #24275, batch_size 1, seq length 2500]\tLoss: 4.048050\n",
      "24300it [46:32,  8.73it/s]Train epoch: 2 [batch #24300, batch_size 1, seq length 2500]\tLoss: 3.844343\n",
      "24325it [46:35,  8.66it/s]Train epoch: 2 [batch #24325, batch_size 1, seq length 2500]\tLoss: 3.895248\n",
      "24350it [46:38,  8.76it/s]Train epoch: 2 [batch #24350, batch_size 1, seq length 2500]\tLoss: 3.448006\n",
      "24375it [46:41,  8.66it/s]Train epoch: 2 [batch #24375, batch_size 1, seq length 2500]\tLoss: 3.855219\n",
      "24400it [46:44,  8.75it/s]Train epoch: 2 [batch #24400, batch_size 1, seq length 2500]\tLoss: 3.506394\n",
      "24425it [46:47,  8.74it/s]Train epoch: 2 [batch #24425, batch_size 1, seq length 2500]\tLoss: 3.604328\n",
      "24450it [46:50,  8.74it/s]Train epoch: 2 [batch #24450, batch_size 1, seq length 2500]\tLoss: 3.484080\n",
      "24475it [46:53,  8.71it/s]Train epoch: 2 [batch #24475, batch_size 1, seq length 2500]\tLoss: 3.666407\n",
      "24500it [46:55,  8.68it/s]Train epoch: 2 [batch #24500, batch_size 1, seq length 2500]\tLoss: 3.702822\n",
      "24525it [46:58,  8.74it/s]Train epoch: 2 [batch #24525, batch_size 1, seq length 2500]\tLoss: 3.607744\n",
      "24550it [47:01,  8.62it/s]Train epoch: 2 [batch #24550, batch_size 1, seq length 2500]\tLoss: 3.550419\n",
      "24575it [47:04,  8.72it/s]Train epoch: 2 [batch #24575, batch_size 1, seq length 2500]\tLoss: 3.989783\n",
      "24600it [47:07,  8.74it/s]Train epoch: 2 [batch #24600, batch_size 1, seq length 2500]\tLoss: 3.667607\n",
      "24625it [47:10,  8.73it/s]Train epoch: 2 [batch #24625, batch_size 1, seq length 2500]\tLoss: 3.467624\n",
      "24650it [47:13,  8.76it/s]Train epoch: 2 [batch #24650, batch_size 1, seq length 2500]\tLoss: 3.652316\n",
      "24675it [47:15,  8.71it/s]Train epoch: 2 [batch #24675, batch_size 1, seq length 2500]\tLoss: 3.799921\n",
      "24700it [47:18,  8.55it/s]Train epoch: 2 [batch #24700, batch_size 1, seq length 2500]\tLoss: 3.912131\n",
      "24725it [47:21,  8.68it/s]Train epoch: 2 [batch #24725, batch_size 1, seq length 2500]\tLoss: 3.619178\n",
      "24750it [47:24,  8.69it/s]Train epoch: 2 [batch #24750, batch_size 1, seq length 2500]\tLoss: 3.633178\n",
      "24775it [47:27,  8.65it/s]Train epoch: 2 [batch #24775, batch_size 1, seq length 2500]\tLoss: 3.382615\n",
      "24800it [47:30,  8.71it/s]Train epoch: 2 [batch #24800, batch_size 1, seq length 2500]\tLoss: 3.501796\n",
      "24825it [47:33,  8.72it/s]Train epoch: 2 [batch #24825, batch_size 1, seq length 2500]\tLoss: 3.706367\n",
      "24850it [47:36,  8.70it/s]Train epoch: 2 [batch #24850, batch_size 1, seq length 2500]\tLoss: 3.741467\n",
      "24875it [47:38,  8.73it/s]Train epoch: 2 [batch #24875, batch_size 1, seq length 2500]\tLoss: 3.376715\n",
      "24900it [47:41,  8.55it/s]Train epoch: 2 [batch #24900, batch_size 1, seq length 2500]\tLoss: 3.638237\n",
      "24925it [47:44,  8.64it/s]Train epoch: 2 [batch #24925, batch_size 1, seq length 2500]\tLoss: 3.535553\n",
      "24950it [47:47,  8.70it/s]Train epoch: 2 [batch #24950, batch_size 1, seq length 2500]\tLoss: 3.671978\n",
      "24975it [47:50,  8.66it/s]Train epoch: 2 [batch #24975, batch_size 1, seq length 2500]\tLoss: 4.054797\n",
      "25000it [47:53,  8.69it/s]Train epoch: 2 [batch #25000, batch_size 1, seq length 2500]\tLoss: 3.793136\n",
      "25025it [47:56,  8.73it/s]Train epoch: 2 [batch #25025, batch_size 1, seq length 2500]\tLoss: 3.712647\n",
      "25050it [47:59,  8.70it/s]Train epoch: 2 [batch #25050, batch_size 1, seq length 2500]\tLoss: 3.611653\n",
      "25075it [48:02,  8.66it/s]Train epoch: 2 [batch #25075, batch_size 1, seq length 2500]\tLoss: 3.709993\n",
      "25100it [48:04,  8.74it/s]Train epoch: 2 [batch #25100, batch_size 1, seq length 2500]\tLoss: 3.717211\n",
      "25125it [48:07,  8.75it/s]Train epoch: 2 [batch #25125, batch_size 1, seq length 2500]\tLoss: 3.556922\n",
      "25150it [48:10,  8.73it/s]Train epoch: 2 [batch #25150, batch_size 1, seq length 2500]\tLoss: 3.734313\n",
      "25175it [48:13,  8.61it/s]Train epoch: 2 [batch #25175, batch_size 1, seq length 2500]\tLoss: 3.764309\n",
      "25200it [48:16,  8.69it/s]Train epoch: 2 [batch #25200, batch_size 1, seq length 2500]\tLoss: 3.727905\n",
      "25225it [48:19,  8.72it/s]Train epoch: 2 [batch #25225, batch_size 1, seq length 2500]\tLoss: 3.688666\n",
      "25250it [48:22,  8.66it/s]Train epoch: 2 [batch #25250, batch_size 1, seq length 2500]\tLoss: 3.776953\n",
      "25275it [48:24,  8.71it/s]Train epoch: 2 [batch #25275, batch_size 1, seq length 2500]\tLoss: 3.890565\n",
      "25300it [48:27,  8.67it/s]Train epoch: 2 [batch #25300, batch_size 1, seq length 2500]\tLoss: 3.650911\n",
      "25325it [48:30,  8.60it/s]Train epoch: 2 [batch #25325, batch_size 1, seq length 2500]\tLoss: 3.654028\n",
      "25350it [48:33,  8.75it/s]Train epoch: 2 [batch #25350, batch_size 1, seq length 2500]\tLoss: 3.737582\n",
      "25375it [48:36,  8.76it/s]Train epoch: 2 [batch #25375, batch_size 1, seq length 2500]\tLoss: 3.735207\n",
      "25400it [48:39,  8.72it/s]Train epoch: 2 [batch #25400, batch_size 1, seq length 2500]\tLoss: 3.586849\n",
      "25425it [48:42,  8.67it/s]Train epoch: 2 [batch #25425, batch_size 1, seq length 2500]\tLoss: 3.384162\n",
      "25450it [48:45,  8.68it/s]Train epoch: 2 [batch #25450, batch_size 1, seq length 2500]\tLoss: 3.369554\n",
      "25475it [48:47,  8.71it/s]Train epoch: 2 [batch #25475, batch_size 1, seq length 2500]\tLoss: 4.029168\n",
      "25500it [48:50,  8.62it/s]Train epoch: 2 [batch #25500, batch_size 1, seq length 2500]\tLoss: 3.530964\n",
      "25525it [48:53,  8.75it/s]Train epoch: 2 [batch #25525, batch_size 1, seq length 2500]\tLoss: 3.656203\n",
      "25550it [48:56,  8.68it/s]Train epoch: 2 [batch #25550, batch_size 1, seq length 2500]\tLoss: 3.688011\n",
      "25575it [48:59,  8.76it/s]Train epoch: 2 [batch #25575, batch_size 1, seq length 2500]\tLoss: 3.969618\n",
      "25600it [49:02,  8.74it/s]Train epoch: 2 [batch #25600, batch_size 1, seq length 2500]\tLoss: 3.663327\n",
      "25625it [49:05,  8.64it/s]Train epoch: 2 [batch #25625, batch_size 1, seq length 2500]\tLoss: 3.593155\n",
      "25650it [49:08,  8.73it/s]Train epoch: 2 [batch #25650, batch_size 1, seq length 2500]\tLoss: 3.909841\n",
      "25675it [49:10,  8.69it/s]Train epoch: 2 [batch #25675, batch_size 1, seq length 2500]\tLoss: 3.500308\n",
      "25700it [49:13,  8.69it/s]Train epoch: 2 [batch #25700, batch_size 1, seq length 2500]\tLoss: 3.538757\n",
      "25725it [49:16,  8.71it/s]Train epoch: 2 [batch #25725, batch_size 1, seq length 2500]\tLoss: 3.763471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25750it [49:19,  8.63it/s]Train epoch: 2 [batch #25750, batch_size 1, seq length 2500]\tLoss: 3.707770\n",
      "25775it [49:22,  8.73it/s]Train epoch: 2 [batch #25775, batch_size 1, seq length 2500]\tLoss: 3.540738\n",
      "25800it [49:25,  8.67it/s]Train epoch: 2 [batch #25800, batch_size 1, seq length 2500]\tLoss: 3.641691\n",
      "25825it [49:28,  8.71it/s]Train epoch: 2 [batch #25825, batch_size 1, seq length 2500]\tLoss: 3.855627\n",
      "25850it [49:31,  8.73it/s]Train epoch: 2 [batch #25850, batch_size 1, seq length 2500]\tLoss: 3.876431\n",
      "25875it [49:33,  8.76it/s]Train epoch: 2 [batch #25875, batch_size 1, seq length 2500]\tLoss: 3.586913\n",
      "25900it [49:36,  8.75it/s]Train epoch: 2 [batch #25900, batch_size 1, seq length 2500]\tLoss: 3.744166\n",
      "25925it [49:39,  8.60it/s]Train epoch: 2 [batch #25925, batch_size 1, seq length 2500]\tLoss: 3.280267\n",
      "25950it [49:42,  8.71it/s]Train epoch: 2 [batch #25950, batch_size 1, seq length 2500]\tLoss: 3.646016\n",
      "25975it [49:45,  8.71it/s]Train epoch: 2 [batch #25975, batch_size 1, seq length 2500]\tLoss: 3.661465\n",
      "26000it [49:48,  8.71it/s]Train epoch: 2 [batch #26000, batch_size 1, seq length 2500]\tLoss: 3.687605\n",
      "26025it [49:51,  8.71it/s]Train epoch: 2 [batch #26025, batch_size 1, seq length 2500]\tLoss: 3.810521\n",
      "26050it [49:54,  8.71it/s]Train epoch: 2 [batch #26050, batch_size 1, seq length 2500]\tLoss: 3.749974\n",
      "26075it [49:56,  8.74it/s]Train epoch: 2 [batch #26075, batch_size 1, seq length 2500]\tLoss: 3.422400\n",
      "26100it [49:59,  8.70it/s]Train epoch: 2 [batch #26100, batch_size 1, seq length 2500]\tLoss: 3.743944\n",
      "26125it [50:02,  8.73it/s]Train epoch: 2 [batch #26125, batch_size 1, seq length 2500]\tLoss: 3.536518\n",
      "26150it [50:05,  8.71it/s]Train epoch: 2 [batch #26150, batch_size 1, seq length 2500]\tLoss: 3.414286\n",
      "26175it [50:08,  8.76it/s]Train epoch: 2 [batch #26175, batch_size 1, seq length 2500]\tLoss: 3.470279\n",
      "26200it [50:11,  8.74it/s]Train epoch: 2 [batch #26200, batch_size 1, seq length 2500]\tLoss: 3.837981\n",
      "26225it [50:14,  8.74it/s]Train epoch: 2 [batch #26225, batch_size 1, seq length 2500]\tLoss: 3.629635\n",
      "26250it [50:17,  8.66it/s]Train epoch: 2 [batch #26250, batch_size 1, seq length 2500]\tLoss: 3.629175\n",
      "26275it [50:19,  8.71it/s]Train epoch: 2 [batch #26275, batch_size 1, seq length 2500]\tLoss: 3.748788\n",
      "26300it [50:22,  8.71it/s]Train epoch: 2 [batch #26300, batch_size 1, seq length 2500]\tLoss: 3.514811\n",
      "26325it [50:25,  8.72it/s]Train epoch: 2 [batch #26325, batch_size 1, seq length 2500]\tLoss: 3.358347\n",
      "26350it [50:28,  8.67it/s]Train epoch: 2 [batch #26350, batch_size 1, seq length 2500]\tLoss: 3.578534\n",
      "26375it [50:31,  8.67it/s]Train epoch: 2 [batch #26375, batch_size 1, seq length 2500]\tLoss: 3.566261\n",
      "26400it [50:34,  8.67it/s]Train epoch: 2 [batch #26400, batch_size 1, seq length 2500]\tLoss: 3.680197\n",
      "26425it [50:37,  8.72it/s]Train epoch: 2 [batch #26425, batch_size 1, seq length 2500]\tLoss: 3.813403\n",
      "26450it [50:39,  8.72it/s]Train epoch: 2 [batch #26450, batch_size 1, seq length 2500]\tLoss: 3.974819\n",
      "26475it [50:42,  8.73it/s]Train epoch: 2 [batch #26475, batch_size 1, seq length 2500]\tLoss: 3.331674\n",
      "26500it [50:45,  8.75it/s]Train epoch: 2 [batch #26500, batch_size 1, seq length 2500]\tLoss: 3.470762\n",
      "26525it [50:48,  8.68it/s]Train epoch: 2 [batch #26525, batch_size 1, seq length 2500]\tLoss: 3.705938\n",
      "26550it [50:51,  8.73it/s]Train epoch: 2 [batch #26550, batch_size 1, seq length 2500]\tLoss: 3.865414\n",
      "26575it [50:54,  8.72it/s]Train epoch: 2 [batch #26575, batch_size 1, seq length 2500]\tLoss: 3.467198\n",
      "26600it [50:57,  8.72it/s]Train epoch: 2 [batch #26600, batch_size 1, seq length 2500]\tLoss: 3.766436\n",
      "26625it [51:00,  8.69it/s]Train epoch: 2 [batch #26625, batch_size 1, seq length 2500]\tLoss: 4.004196\n",
      "26650it [51:02,  8.72it/s]Train epoch: 2 [batch #26650, batch_size 1, seq length 2500]\tLoss: 3.791331\n",
      "26675it [51:05,  8.74it/s]Train epoch: 2 [batch #26675, batch_size 1, seq length 2500]\tLoss: 3.711959\n",
      "26700it [51:08,  8.66it/s]Train epoch: 2 [batch #26700, batch_size 1, seq length 2500]\tLoss: 3.783340\n",
      "26725it [51:11,  8.69it/s]Train epoch: 2 [batch #26725, batch_size 1, seq length 2500]\tLoss: 3.800497\n",
      "26750it [51:14,  8.71it/s]Train epoch: 2 [batch #26750, batch_size 1, seq length 2500]\tLoss: 3.866829\n",
      "26775it [51:17,  8.73it/s]Train epoch: 2 [batch #26775, batch_size 1, seq length 2500]\tLoss: 3.660524\n",
      "26800it [51:20,  8.74it/s]Train epoch: 2 [batch #26800, batch_size 1, seq length 2500]\tLoss: 3.672480\n",
      "26825it [51:23,  8.71it/s]Train epoch: 2 [batch #26825, batch_size 1, seq length 2500]\tLoss: 3.888470\n",
      "26850it [51:25,  8.73it/s]Train epoch: 2 [batch #26850, batch_size 1, seq length 2500]\tLoss: 3.936439\n",
      "26875it [51:28,  8.75it/s]Train epoch: 2 [batch #26875, batch_size 1, seq length 2500]\tLoss: 3.722435\n",
      "26900it [51:31,  8.75it/s]Train epoch: 2 [batch #26900, batch_size 1, seq length 2500]\tLoss: 3.386506\n",
      "26925it [51:34,  8.71it/s]Train epoch: 2 [batch #26925, batch_size 1, seq length 2500]\tLoss: 3.532435\n",
      "26950it [51:37,  8.75it/s]Train epoch: 2 [batch #26950, batch_size 1, seq length 2500]\tLoss: 3.426550\n",
      "26975it [51:40,  8.69it/s]Train epoch: 2 [batch #26975, batch_size 1, seq length 2500]\tLoss: 3.839685\n",
      "27000it [51:43,  8.68it/s]Train epoch: 2 [batch #27000, batch_size 1, seq length 2500]\tLoss: 3.999985\n",
      "27025it [51:45,  8.68it/s]Train epoch: 2 [batch #27025, batch_size 1, seq length 2500]\tLoss: 3.437705\n",
      "27050it [51:48,  8.76it/s]Train epoch: 2 [batch #27050, batch_size 1, seq length 2500]\tLoss: 3.803174\n",
      "27075it [51:51,  8.77it/s]Train epoch: 2 [batch #27075, batch_size 1, seq length 2500]\tLoss: 3.769632\n",
      "27100it [51:54,  8.72it/s]Train epoch: 2 [batch #27100, batch_size 1, seq length 2500]\tLoss: 3.807687\n",
      "27125it [51:57,  8.65it/s]Train epoch: 2 [batch #27125, batch_size 1, seq length 2500]\tLoss: 3.890271\n",
      "27150it [52:00,  8.70it/s]Train epoch: 2 [batch #27150, batch_size 1, seq length 2500]\tLoss: 3.934928\n",
      "27175it [52:03,  8.74it/s]Train epoch: 2 [batch #27175, batch_size 1, seq length 2500]\tLoss: 3.761623\n",
      "27200it [52:06,  8.63it/s]Train epoch: 2 [batch #27200, batch_size 1, seq length 2500]\tLoss: 3.753323\n",
      "27225it [52:08,  8.69it/s]Train epoch: 2 [batch #27225, batch_size 1, seq length 2500]\tLoss: 3.795524\n",
      "27250it [52:11,  8.67it/s]Train epoch: 2 [batch #27250, batch_size 1, seq length 2500]\tLoss: 3.741230\n",
      "27275it [52:14,  8.70it/s]Train epoch: 2 [batch #27275, batch_size 1, seq length 2500]\tLoss: 3.452314\n",
      "27300it [52:17,  8.69it/s]Train epoch: 2 [batch #27300, batch_size 1, seq length 2500]\tLoss: 3.657083\n",
      "27325it [52:20,  8.71it/s]Train epoch: 2 [batch #27325, batch_size 1, seq length 2500]\tLoss: 3.602250\n",
      "27350it [52:23,  8.71it/s]Train epoch: 2 [batch #27350, batch_size 1, seq length 2500]\tLoss: 3.566820\n",
      "27375it [52:26,  8.73it/s]Train epoch: 2 [batch #27375, batch_size 1, seq length 2500]\tLoss: 3.988419\n",
      "27400it [52:29,  8.73it/s]Train epoch: 2 [batch #27400, batch_size 1, seq length 2500]\tLoss: 3.377556\n",
      "27425it [52:31,  8.74it/s]Train epoch: 2 [batch #27425, batch_size 1, seq length 2500]\tLoss: 3.499993\n",
      "27450it [52:34,  8.69it/s]Train epoch: 2 [batch #27450, batch_size 1, seq length 2500]\tLoss: 3.864804\n",
      "27475it [52:37,  8.71it/s]Train epoch: 2 [batch #27475, batch_size 1, seq length 2500]\tLoss: 3.512499\n",
      "27500it [52:40,  8.69it/s]Train epoch: 2 [batch #27500, batch_size 1, seq length 2500]\tLoss: 3.793757\n",
      "27525it [52:43,  8.75it/s]Train epoch: 2 [batch #27525, batch_size 1, seq length 2500]\tLoss: 3.406398\n",
      "27550it [52:46,  8.75it/s]Train epoch: 2 [batch #27550, batch_size 1, seq length 2500]\tLoss: 3.617589\n",
      "27575it [52:49,  8.66it/s]Train epoch: 2 [batch #27575, batch_size 1, seq length 2500]\tLoss: 3.516915\n",
      "27600it [52:52,  8.72it/s]Train epoch: 2 [batch #27600, batch_size 1, seq length 2500]\tLoss: 3.428229\n",
      "27625it [52:54,  8.73it/s]Train epoch: 2 [batch #27625, batch_size 1, seq length 2500]\tLoss: 3.406457\n",
      "27650it [52:57,  8.74it/s]Train epoch: 2 [batch #27650, batch_size 1, seq length 2500]\tLoss: 3.815566\n",
      "27675it [53:00,  8.70it/s]Train epoch: 2 [batch #27675, batch_size 1, seq length 2500]\tLoss: 3.628660\n",
      "27700it [53:03,  8.74it/s]Train epoch: 2 [batch #27700, batch_size 1, seq length 2500]\tLoss: 3.586530\n",
      "27725it [53:06,  8.67it/s]Train epoch: 2 [batch #27725, batch_size 1, seq length 2500]\tLoss: 3.897500\n",
      "27750it [53:09,  8.66it/s]Train epoch: 2 [batch #27750, batch_size 1, seq length 2500]\tLoss: 3.703855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27775it [53:12,  8.65it/s]Train epoch: 2 [batch #27775, batch_size 1, seq length 2500]\tLoss: 3.590992\n",
      "27800it [53:15,  8.77it/s]Train epoch: 2 [batch #27800, batch_size 1, seq length 2500]\tLoss: 3.744948\n",
      "27825it [53:17,  8.77it/s]Train epoch: 2 [batch #27825, batch_size 1, seq length 2500]\tLoss: 3.837189\n",
      "27850it [53:20,  8.77it/s]Train epoch: 2 [batch #27850, batch_size 1, seq length 2500]\tLoss: 3.885462\n",
      "27875it [53:23,  8.64it/s]Train epoch: 2 [batch #27875, batch_size 1, seq length 2500]\tLoss: 3.722035\n",
      "27900it [53:26,  8.71it/s]Train epoch: 2 [batch #27900, batch_size 1, seq length 2500]\tLoss: 3.654234\n",
      "27925it [53:29,  8.74it/s]Train epoch: 2 [batch #27925, batch_size 1, seq length 2500]\tLoss: 3.816855\n",
      "27950it [53:32,  8.71it/s]Train epoch: 2 [batch #27950, batch_size 1, seq length 2500]\tLoss: 3.589918\n",
      "27975it [53:35,  8.70it/s]Train epoch: 2 [batch #27975, batch_size 1, seq length 2500]\tLoss: 3.368419\n",
      "28000it [53:37,  8.72it/s]Train epoch: 2 [batch #28000, batch_size 1, seq length 2500]\tLoss: 3.734553\n",
      "28025it [53:40,  8.76it/s]Train epoch: 2 [batch #28025, batch_size 1, seq length 2500]\tLoss: 3.699222\n",
      "28050it [53:43,  8.68it/s]Train epoch: 2 [batch #28050, batch_size 1, seq length 2500]\tLoss: 3.279462\n",
      "28075it [53:46,  8.73it/s]Train epoch: 2 [batch #28075, batch_size 1, seq length 2500]\tLoss: 3.545018\n",
      "28100it [53:49,  8.68it/s]Train epoch: 2 [batch #28100, batch_size 1, seq length 2500]\tLoss: 3.687190\n",
      "28125it [53:52,  8.73it/s]Train epoch: 2 [batch #28125, batch_size 1, seq length 2500]\tLoss: 3.615864\n",
      "28150it [53:55,  8.73it/s]Train epoch: 2 [batch #28150, batch_size 1, seq length 2500]\tLoss: 3.738732\n",
      "28175it [53:58,  8.70it/s]Train epoch: 2 [batch #28175, batch_size 1, seq length 2500]\tLoss: 3.839491\n",
      "28200it [54:00,  8.72it/s]Train epoch: 2 [batch #28200, batch_size 1, seq length 2500]\tLoss: 3.445356\n",
      "28225it [54:03,  8.64it/s]Train epoch: 2 [batch #28225, batch_size 1, seq length 2500]\tLoss: 3.513795\n",
      "28250it [54:06,  8.70it/s]Train epoch: 2 [batch #28250, batch_size 1, seq length 2500]\tLoss: 3.696602\n",
      "28275it [54:09,  8.64it/s]Train epoch: 2 [batch #28275, batch_size 1, seq length 2500]\tLoss: 3.736644\n",
      "28300it [54:12,  8.75it/s]Train epoch: 2 [batch #28300, batch_size 1, seq length 2500]\tLoss: 3.800133\n",
      "28325it [54:15,  8.64it/s]Train epoch: 2 [batch #28325, batch_size 1, seq length 2500]\tLoss: 3.666783\n",
      "28350it [54:18,  8.73it/s]Train epoch: 2 [batch #28350, batch_size 1, seq length 2500]\tLoss: 3.490364\n",
      "28375it [54:21,  8.70it/s]Train epoch: 2 [batch #28375, batch_size 1, seq length 2500]\tLoss: 3.719827\n",
      "28400it [54:23,  8.73it/s]Train epoch: 2 [batch #28400, batch_size 1, seq length 2500]\tLoss: 3.564530\n",
      "28425it [54:26,  8.73it/s]Train epoch: 2 [batch #28425, batch_size 1, seq length 2500]\tLoss: 3.532000\n",
      "28450it [54:29,  8.69it/s]Train epoch: 2 [batch #28450, batch_size 1, seq length 2500]\tLoss: 3.757339\n",
      "28475it [54:32,  8.71it/s]Train epoch: 2 [batch #28475, batch_size 1, seq length 2500]\tLoss: 3.426764\n",
      "28500it [54:35,  8.69it/s]Train epoch: 2 [batch #28500, batch_size 1, seq length 2500]\tLoss: 3.707175\n",
      "28525it [54:38,  8.71it/s]Train epoch: 2 [batch #28525, batch_size 1, seq length 2500]\tLoss: 3.618850\n",
      "28550it [54:41,  8.65it/s]Train epoch: 2 [batch #28550, batch_size 1, seq length 2500]\tLoss: 3.962523\n",
      "28575it [54:44,  8.69it/s]Train epoch: 2 [batch #28575, batch_size 1, seq length 2500]\tLoss: 3.436717\n",
      "28600it [54:46,  8.45it/s]Train epoch: 2 [batch #28600, batch_size 1, seq length 2500]\tLoss: 3.346503\n",
      "28625it [54:49,  8.67it/s]Train epoch: 2 [batch #28625, batch_size 1, seq length 2500]\tLoss: 3.608221\n",
      "28650it [54:52,  8.76it/s]Train epoch: 2 [batch #28650, batch_size 1, seq length 2500]\tLoss: 4.074584\n",
      "28675it [54:55,  8.69it/s]Train epoch: 2 [batch #28675, batch_size 1, seq length 2500]\tLoss: 3.337020\n",
      "28700it [54:58,  8.75it/s]Train epoch: 2 [batch #28700, batch_size 1, seq length 2500]\tLoss: 3.650663\n",
      "28725it [55:01,  8.69it/s]Train epoch: 2 [batch #28725, batch_size 1, seq length 2500]\tLoss: 3.880211\n",
      "28750it [55:04,  8.71it/s]Train epoch: 2 [batch #28750, batch_size 1, seq length 2500]\tLoss: 3.059605\n",
      "28775it [55:07,  8.75it/s]Train epoch: 2 [batch #28775, batch_size 1, seq length 2500]\tLoss: 3.867812\n",
      "28800it [55:09,  8.71it/s]Train epoch: 2 [batch #28800, batch_size 1, seq length 2500]\tLoss: 3.928267\n",
      "28825it [55:12,  8.64it/s]Train epoch: 2 [batch #28825, batch_size 1, seq length 2500]\tLoss: 3.649609\n",
      "28850it [55:15,  8.70it/s]Train epoch: 2 [batch #28850, batch_size 1, seq length 2500]\tLoss: 3.643992\n",
      "28875it [55:18,  8.76it/s]Train epoch: 2 [batch #28875, batch_size 1, seq length 2500]\tLoss: 3.638617\n",
      "28900it [55:21,  8.65it/s]Train epoch: 2 [batch #28900, batch_size 1, seq length 2500]\tLoss: 3.679845\n",
      "28925it [55:24,  8.72it/s]Train epoch: 2 [batch #28925, batch_size 1, seq length 2500]\tLoss: 3.922851\n",
      "28950it [55:27,  8.74it/s]Train epoch: 2 [batch #28950, batch_size 1, seq length 2500]\tLoss: 3.654228\n",
      "28975it [55:30,  8.68it/s]Train epoch: 2 [batch #28975, batch_size 1, seq length 2500]\tLoss: 3.440862\n",
      "29000it [55:32,  8.73it/s]Train epoch: 2 [batch #29000, batch_size 1, seq length 2500]\tLoss: 3.774556\n",
      "29025it [55:35,  8.76it/s]Train epoch: 2 [batch #29025, batch_size 1, seq length 2500]\tLoss: 3.574586\n",
      "29050it [55:38,  8.75it/s]Train epoch: 2 [batch #29050, batch_size 1, seq length 2500]\tLoss: 4.057145\n",
      "29075it [55:41,  8.66it/s]Train epoch: 2 [batch #29075, batch_size 1, seq length 2500]\tLoss: 3.402660\n",
      "29100it [55:44,  8.69it/s]Train epoch: 2 [batch #29100, batch_size 1, seq length 2500]\tLoss: 3.674997\n",
      "29125it [55:47,  8.68it/s]Train epoch: 2 [batch #29125, batch_size 1, seq length 2500]\tLoss: 3.833332\n",
      "29150it [55:50,  8.70it/s]Train epoch: 2 [batch #29150, batch_size 1, seq length 2500]\tLoss: 3.753356\n",
      "29175it [55:53,  8.66it/s]Train epoch: 2 [batch #29175, batch_size 1, seq length 2500]\tLoss: 3.658786\n",
      "29200it [55:55,  8.70it/s]Train epoch: 2 [batch #29200, batch_size 1, seq length 2500]\tLoss: 3.494209\n",
      "29225it [55:58,  8.67it/s]Train epoch: 2 [batch #29225, batch_size 1, seq length 2500]\tLoss: 3.947628\n",
      "29250it [56:01,  8.67it/s]Train epoch: 2 [batch #29250, batch_size 1, seq length 2500]\tLoss: 3.805952\n",
      "29275it [56:04,  8.65it/s]Train epoch: 2 [batch #29275, batch_size 1, seq length 2500]\tLoss: 3.691887\n",
      "29300it [56:07,  8.64it/s]Train epoch: 2 [batch #29300, batch_size 1, seq length 2500]\tLoss: 3.539801\n",
      "29325it [56:10,  8.73it/s]Train epoch: 2 [batch #29325, batch_size 1, seq length 2500]\tLoss: 3.655334\n",
      "29350it [56:13,  8.68it/s]Train epoch: 2 [batch #29350, batch_size 1, seq length 2500]\tLoss: 3.769761\n",
      "29375it [56:16,  8.73it/s]Train epoch: 2 [batch #29375, batch_size 1, seq length 2500]\tLoss: 3.160345\n",
      "29400it [56:18,  8.47it/s]Train epoch: 2 [batch #29400, batch_size 1, seq length 2500]\tLoss: 3.474626\n",
      "29425it [56:21,  8.72it/s]Train epoch: 2 [batch #29425, batch_size 1, seq length 2500]\tLoss: 3.729397\n",
      "29450it [56:24,  8.71it/s]Train epoch: 2 [batch #29450, batch_size 1, seq length 2500]\tLoss: 3.603318\n",
      "29475it [56:27,  8.64it/s]Train epoch: 2 [batch #29475, batch_size 1, seq length 2500]\tLoss: 3.713286\n",
      "29500it [56:30,  8.70it/s]Train epoch: 2 [batch #29500, batch_size 1, seq length 2500]\tLoss: 3.688492\n",
      "29525it [56:33,  8.67it/s]Train epoch: 2 [batch #29525, batch_size 1, seq length 2500]\tLoss: 3.660291\n",
      "29550it [56:36,  8.72it/s]Train epoch: 2 [batch #29550, batch_size 1, seq length 2500]\tLoss: 3.737706\n",
      "29575it [56:39,  8.76it/s]Train epoch: 2 [batch #29575, batch_size 1, seq length 2500]\tLoss: 3.472785\n",
      "29600it [56:41,  8.69it/s]Train epoch: 2 [batch #29600, batch_size 1, seq length 2500]\tLoss: 3.727877\n",
      "29625it [56:44,  8.76it/s]Train epoch: 2 [batch #29625, batch_size 1, seq length 2500]\tLoss: 3.689233\n",
      "29650it [56:47,  8.61it/s]Train epoch: 2 [batch #29650, batch_size 1, seq length 2500]\tLoss: 3.773581\n",
      "29675it [56:50,  8.70it/s]Train epoch: 2 [batch #29675, batch_size 1, seq length 2500]\tLoss: 3.538803\n",
      "29700it [56:53,  8.64it/s]Train epoch: 2 [batch #29700, batch_size 1, seq length 2500]\tLoss: 3.814428\n",
      "29725it [56:56,  8.72it/s]Train epoch: 2 [batch #29725, batch_size 1, seq length 2500]\tLoss: 3.780343\n",
      "29750it [56:59,  8.71it/s]Train epoch: 2 [batch #29750, batch_size 1, seq length 2500]\tLoss: 3.340633\n",
      "29775it [57:02,  8.73it/s]Train epoch: 2 [batch #29775, batch_size 1, seq length 2500]\tLoss: 3.639477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29800it [57:04,  8.56it/s]Train epoch: 2 [batch #29800, batch_size 1, seq length 2500]\tLoss: 3.512925\n",
      "29825it [57:07,  8.69it/s]Train epoch: 2 [batch #29825, batch_size 1, seq length 2500]\tLoss: 3.554788\n",
      "29850it [57:10,  8.72it/s]Train epoch: 2 [batch #29850, batch_size 1, seq length 2500]\tLoss: 3.726556\n",
      "29875it [57:13,  8.73it/s]Train epoch: 2 [batch #29875, batch_size 1, seq length 2500]\tLoss: 4.021722\n",
      "29900it [57:16,  8.72it/s]Train epoch: 2 [batch #29900, batch_size 1, seq length 2500]\tLoss: 3.272618\n",
      "29925it [57:19,  8.65it/s]Train epoch: 2 [batch #29925, batch_size 1, seq length 2500]\tLoss: 3.348160\n",
      "29950it [57:22,  8.69it/s]Train epoch: 2 [batch #29950, batch_size 1, seq length 2500]\tLoss: 3.598898\n",
      "29975it [57:25,  8.75it/s]Train epoch: 2 [batch #29975, batch_size 1, seq length 2500]\tLoss: 3.407531\n",
      "30000it [57:27,  8.72it/s]Train epoch: 2 [batch #30000, batch_size 1, seq length 2500]\tLoss: 3.951473\n",
      "30025it [57:30,  8.71it/s]Train epoch: 2 [batch #30025, batch_size 1, seq length 2500]\tLoss: 3.769935\n",
      "30050it [57:33,  8.69it/s]Train epoch: 2 [batch #30050, batch_size 1, seq length 2500]\tLoss: 3.730234\n",
      "30075it [57:36,  8.68it/s]Train epoch: 2 [batch #30075, batch_size 1, seq length 2500]\tLoss: 3.656387\n",
      "30100it [57:39,  8.72it/s]Train epoch: 2 [batch #30100, batch_size 1, seq length 2500]\tLoss: 3.745377\n",
      "30125it [57:42,  8.67it/s]Train epoch: 2 [batch #30125, batch_size 1, seq length 2500]\tLoss: 3.841765\n",
      "30150it [57:45,  8.75it/s]Train epoch: 2 [batch #30150, batch_size 1, seq length 2500]\tLoss: 3.734438\n",
      "30175it [57:48,  8.76it/s]Train epoch: 2 [batch #30175, batch_size 1, seq length 2500]\tLoss: 3.645066\n",
      "30200it [57:50,  8.63it/s]Train epoch: 2 [batch #30200, batch_size 1, seq length 2500]\tLoss: 3.483319\n",
      "30225it [57:53,  8.70it/s]Train epoch: 2 [batch #30225, batch_size 1, seq length 2500]\tLoss: 3.742759\n",
      "30250it [57:56,  8.70it/s]Train epoch: 2 [batch #30250, batch_size 1, seq length 2500]\tLoss: 3.407509\n",
      "30275it [57:59,  8.73it/s]Train epoch: 2 [batch #30275, batch_size 1, seq length 2500]\tLoss: 3.477290\n",
      "30300it [58:02,  8.66it/s]Train epoch: 2 [batch #30300, batch_size 1, seq length 2500]\tLoss: 3.356248\n",
      "30325it [58:05,  8.72it/s]Train epoch: 2 [batch #30325, batch_size 1, seq length 2500]\tLoss: 3.350002\n",
      "30350it [58:08,  8.74it/s]Train epoch: 2 [batch #30350, batch_size 1, seq length 2500]\tLoss: 3.591060\n",
      "30375it [58:11,  8.72it/s]Train epoch: 2 [batch #30375, batch_size 1, seq length 2500]\tLoss: 3.659343\n",
      "30400it [58:13,  8.65it/s]Train epoch: 2 [batch #30400, batch_size 1, seq length 2500]\tLoss: 3.800868\n",
      "30425it [58:16,  8.70it/s]Train epoch: 2 [batch #30425, batch_size 1, seq length 2500]\tLoss: 3.454146\n",
      "30450it [58:19,  8.66it/s]Train epoch: 2 [batch #30450, batch_size 1, seq length 2500]\tLoss: 3.644077\n",
      "30475it [58:22,  8.71it/s]Train epoch: 2 [batch #30475, batch_size 1, seq length 2500]\tLoss: 3.526967\n",
      "30500it [58:25,  8.74it/s]Train epoch: 2 [batch #30500, batch_size 1, seq length 2500]\tLoss: 3.867617\n",
      "30525it [58:28,  8.71it/s]Train epoch: 2 [batch #30525, batch_size 1, seq length 2500]\tLoss: 3.776711\n",
      "30550it [58:31,  8.76it/s]Train epoch: 2 [batch #30550, batch_size 1, seq length 2500]\tLoss: 3.767115\n",
      "30575it [58:34,  8.69it/s]Train epoch: 2 [batch #30575, batch_size 1, seq length 2500]\tLoss: 3.330161\n",
      "30600it [58:36,  8.73it/s]Train epoch: 2 [batch #30600, batch_size 1, seq length 2500]\tLoss: 3.552679\n",
      "30625it [58:39,  8.74it/s]Train epoch: 2 [batch #30625, batch_size 1, seq length 2500]\tLoss: 3.712296\n",
      "30650it [58:42,  8.69it/s]Train epoch: 2 [batch #30650, batch_size 1, seq length 2500]\tLoss: 3.678550\n",
      "30675it [58:45,  8.71it/s]Train epoch: 2 [batch #30675, batch_size 1, seq length 2500]\tLoss: 3.180639\n",
      "30700it [58:48,  8.50it/s]Train epoch: 2 [batch #30700, batch_size 1, seq length 2500]\tLoss: 3.577841\n",
      "30725it [58:51,  8.62it/s]Train epoch: 2 [batch #30725, batch_size 1, seq length 2500]\tLoss: 3.663469\n",
      "30750it [58:54,  8.71it/s]Train epoch: 2 [batch #30750, batch_size 1, seq length 2500]\tLoss: 3.773411\n",
      "30775it [58:57,  8.73it/s]Train epoch: 2 [batch #30775, batch_size 1, seq length 2500]\tLoss: 3.619346\n",
      "30800it [58:59,  8.69it/s]Train epoch: 2 [batch #30800, batch_size 1, seq length 2500]\tLoss: 3.744312\n",
      "30825it [59:02,  8.76it/s]Train epoch: 2 [batch #30825, batch_size 1, seq length 2500]\tLoss: 3.601317\n",
      "30850it [59:05,  8.73it/s]Train epoch: 2 [batch #30850, batch_size 1, seq length 2500]\tLoss: 3.739957\n",
      "30875it [59:08,  8.70it/s]Train epoch: 2 [batch #30875, batch_size 1, seq length 2500]\tLoss: 3.636447\n",
      "30900it [59:11,  8.71it/s]Train epoch: 2 [batch #30900, batch_size 1, seq length 2500]\tLoss: 3.782186\n",
      "30925it [59:14,  8.64it/s]Train epoch: 2 [batch #30925, batch_size 1, seq length 2500]\tLoss: 3.431027\n",
      "30950it [59:17,  8.62it/s]Train epoch: 2 [batch #30950, batch_size 1, seq length 2500]\tLoss: 3.581423\n",
      "30975it [59:20,  8.70it/s]Train epoch: 2 [batch #30975, batch_size 1, seq length 2500]\tLoss: 3.665122\n",
      "31000it [59:22,  8.75it/s]Train epoch: 2 [batch #31000, batch_size 1, seq length 2500]\tLoss: 3.297231\n",
      "31025it [59:25,  8.67it/s]Train epoch: 2 [batch #31025, batch_size 1, seq length 2500]\tLoss: 3.470134\n",
      "31050it [59:28,  8.74it/s]Train epoch: 2 [batch #31050, batch_size 1, seq length 2500]\tLoss: 3.921022\n",
      "31075it [59:31,  8.63it/s]Train epoch: 2 [batch #31075, batch_size 1, seq length 2500]\tLoss: 3.343276\n",
      "31100it [59:34,  8.69it/s]Train epoch: 2 [batch #31100, batch_size 1, seq length 2500]\tLoss: 3.845697\n",
      "31125it [59:37,  8.74it/s]Train epoch: 2 [batch #31125, batch_size 1, seq length 2500]\tLoss: 3.770535\n",
      "31150it [59:40,  8.72it/s]Train epoch: 2 [batch #31150, batch_size 1, seq length 2500]\tLoss: 3.512281\n",
      "31175it [59:43,  8.73it/s]Train epoch: 2 [batch #31175, batch_size 1, seq length 2500]\tLoss: 3.759579\n",
      "31200it [59:45,  8.70it/s]Train epoch: 2 [batch #31200, batch_size 1, seq length 2500]\tLoss: 3.613337\n",
      "31225it [59:48,  8.76it/s]Train epoch: 2 [batch #31225, batch_size 1, seq length 2500]\tLoss: 3.518227\n",
      "31250it [59:51,  8.66it/s]Train epoch: 2 [batch #31250, batch_size 1, seq length 2500]\tLoss: 3.976636\n",
      "31275it [59:54,  8.71it/s]Train epoch: 2 [batch #31275, batch_size 1, seq length 2500]\tLoss: 3.802930\n",
      "31300it [59:57,  8.63it/s]Train epoch: 2 [batch #31300, batch_size 1, seq length 2500]\tLoss: 3.840382\n",
      "31325it [1:00:00,  8.67it/s]Train epoch: 2 [batch #31325, batch_size 1, seq length 2500]\tLoss: 3.709695\n",
      "31350it [1:00:03,  8.69it/s]Train epoch: 2 [batch #31350, batch_size 1, seq length 2500]\tLoss: 3.518323\n",
      "31375it [1:00:06,  8.69it/s]Train epoch: 2 [batch #31375, batch_size 1, seq length 2500]\tLoss: 3.565087\n",
      "31400it [1:00:08,  8.70it/s]Train epoch: 2 [batch #31400, batch_size 1, seq length 2500]\tLoss: 3.660437\n",
      "31425it [1:00:11,  8.67it/s]Train epoch: 2 [batch #31425, batch_size 1, seq length 2500]\tLoss: 3.907847\n",
      "31450it [1:00:14,  8.72it/s]Train epoch: 2 [batch #31450, batch_size 1, seq length 2500]\tLoss: 3.523558\n",
      "31475it [1:00:17,  8.70it/s]Train epoch: 2 [batch #31475, batch_size 1, seq length 2500]\tLoss: 4.076736\n",
      "31500it [1:00:20,  8.76it/s]Train epoch: 2 [batch #31500, batch_size 1, seq length 2500]\tLoss: 3.683254\n",
      "31525it [1:00:23,  8.72it/s]Train epoch: 2 [batch #31525, batch_size 1, seq length 2500]\tLoss: 3.495150\n",
      "31550it [1:00:26,  8.65it/s]Train epoch: 2 [batch #31550, batch_size 1, seq length 2500]\tLoss: 3.701566\n",
      "31575it [1:00:29,  8.72it/s]Train epoch: 2 [batch #31575, batch_size 1, seq length 2500]\tLoss: 3.901260\n",
      "31600it [1:00:31,  8.69it/s]Train epoch: 2 [batch #31600, batch_size 1, seq length 2500]\tLoss: 3.750739\n",
      "31625it [1:00:34,  8.76it/s]Train epoch: 2 [batch #31625, batch_size 1, seq length 2500]\tLoss: 3.668138\n",
      "31650it [1:00:37,  8.68it/s]Train epoch: 2 [batch #31650, batch_size 1, seq length 2500]\tLoss: 3.924260\n",
      "31675it [1:00:40,  8.64it/s]Train epoch: 2 [batch #31675, batch_size 1, seq length 2500]\tLoss: 3.787520\n",
      "31700it [1:00:43,  8.76it/s]Train epoch: 2 [batch #31700, batch_size 1, seq length 2500]\tLoss: 3.498187\n",
      "31725it [1:00:46,  8.68it/s]Train epoch: 2 [batch #31725, batch_size 1, seq length 2500]\tLoss: 3.816720\n",
      "31750it [1:00:49,  8.72it/s]Train epoch: 2 [batch #31750, batch_size 1, seq length 2500]\tLoss: 3.580647\n",
      "31775it [1:00:52,  8.72it/s]Train epoch: 2 [batch #31775, batch_size 1, seq length 2500]\tLoss: 3.738944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31800it [1:00:54,  8.65it/s]Train epoch: 2 [batch #31800, batch_size 1, seq length 2500]\tLoss: 3.568609\n",
      "31825it [1:00:57,  8.73it/s]Train epoch: 2 [batch #31825, batch_size 1, seq length 2500]\tLoss: 3.853307\n",
      "31850it [1:01:00,  8.68it/s]Train epoch: 2 [batch #31850, batch_size 1, seq length 2500]\tLoss: 3.687139\n",
      "31875it [1:01:03,  8.75it/s]Train epoch: 2 [batch #31875, batch_size 1, seq length 2500]\tLoss: 3.496810\n",
      "31900it [1:01:06,  8.73it/s]Train epoch: 2 [batch #31900, batch_size 1, seq length 2500]\tLoss: 3.694700\n",
      "31925it [1:01:09,  8.70it/s]Train epoch: 2 [batch #31925, batch_size 1, seq length 2500]\tLoss: 3.570139\n",
      "31950it [1:01:12,  8.69it/s]Train epoch: 2 [batch #31950, batch_size 1, seq length 2500]\tLoss: 3.932966\n",
      "31975it [1:01:15,  8.64it/s]Train epoch: 2 [batch #31975, batch_size 1, seq length 2500]\tLoss: 3.830690\n",
      "32000it [1:01:17,  8.72it/s]Train epoch: 2 [batch #32000, batch_size 1, seq length 2500]\tLoss: 3.813432\n",
      "32025it [1:01:20,  8.73it/s]Train epoch: 2 [batch #32025, batch_size 1, seq length 2500]\tLoss: 3.370499\n",
      "32050it [1:01:23,  8.73it/s]Train epoch: 2 [batch #32050, batch_size 1, seq length 2500]\tLoss: 3.933833\n",
      "32075it [1:01:26,  8.74it/s]Train epoch: 2 [batch #32075, batch_size 1, seq length 2500]\tLoss: 3.913896\n",
      "32100it [1:01:29,  8.73it/s]Train epoch: 2 [batch #32100, batch_size 1, seq length 2500]\tLoss: 3.572009\n",
      "32125it [1:01:32,  8.67it/s]Train epoch: 2 [batch #32125, batch_size 1, seq length 2500]\tLoss: 3.687113\n",
      "32150it [1:01:35,  8.73it/s]Train epoch: 2 [batch #32150, batch_size 1, seq length 2500]\tLoss: 3.580730\n",
      "32175it [1:01:38,  8.69it/s]Train epoch: 2 [batch #32175, batch_size 1, seq length 2500]\tLoss: 3.988205\n",
      "32200it [1:01:40,  8.77it/s]Train epoch: 2 [batch #32200, batch_size 1, seq length 2500]\tLoss: 3.616924\n",
      "32225it [1:01:43,  8.75it/s]Train epoch: 2 [batch #32225, batch_size 1, seq length 2500]\tLoss: 4.038865\n",
      "32250it [1:01:46,  8.74it/s]Train epoch: 2 [batch #32250, batch_size 1, seq length 2500]\tLoss: 3.510981\n",
      "32275it [1:01:49,  8.69it/s]Train epoch: 2 [batch #32275, batch_size 1, seq length 2500]\tLoss: 3.661531\n",
      "32300it [1:01:52,  8.72it/s]Train epoch: 2 [batch #32300, batch_size 1, seq length 2500]\tLoss: 3.887431\n",
      "32325it [1:01:55,  8.73it/s]Train epoch: 2 [batch #32325, batch_size 1, seq length 2500]\tLoss: 3.697889\n",
      "32350it [1:01:58,  8.69it/s]Train epoch: 2 [batch #32350, batch_size 1, seq length 2500]\tLoss: 3.707414\n",
      "32375it [1:02:01,  8.65it/s]Train epoch: 2 [batch #32375, batch_size 1, seq length 2500]\tLoss: 3.668139\n",
      "32400it [1:02:03,  8.70it/s]Train epoch: 2 [batch #32400, batch_size 1, seq length 2500]\tLoss: 3.785702\n",
      "32425it [1:02:06,  8.75it/s]Train epoch: 2 [batch #32425, batch_size 1, seq length 2500]\tLoss: 3.295984\n",
      "32450it [1:02:09,  8.73it/s]Train epoch: 2 [batch #32450, batch_size 1, seq length 2500]\tLoss: 3.662327\n",
      "32475it [1:02:12,  8.71it/s]Train epoch: 2 [batch #32475, batch_size 1, seq length 2500]\tLoss: 3.891594\n",
      "32500it [1:02:15,  8.72it/s]Train epoch: 2 [batch #32500, batch_size 1, seq length 2500]\tLoss: 3.499532\n",
      "32525it [1:02:18,  8.71it/s]Train epoch: 2 [batch #32525, batch_size 1, seq length 2500]\tLoss: 3.783486\n",
      "32550it [1:02:21,  8.69it/s]Train epoch: 2 [batch #32550, batch_size 1, seq length 2500]\tLoss: 3.697324\n",
      "32575it [1:02:24,  8.73it/s]Train epoch: 2 [batch #32575, batch_size 1, seq length 2500]\tLoss: 3.731903\n",
      "32600it [1:02:26,  8.74it/s]Train epoch: 2 [batch #32600, batch_size 1, seq length 2500]\tLoss: 3.504998\n",
      "32625it [1:02:29,  8.70it/s]Train epoch: 2 [batch #32625, batch_size 1, seq length 2500]\tLoss: 3.603027\n",
      "32650it [1:02:32,  8.76it/s]Train epoch: 2 [batch #32650, batch_size 1, seq length 2500]\tLoss: 3.928401\n",
      "32675it [1:02:35,  8.69it/s]Train epoch: 2 [batch #32675, batch_size 1, seq length 2500]\tLoss: 3.489792\n",
      "32700it [1:02:38,  8.72it/s]Train epoch: 2 [batch #32700, batch_size 1, seq length 2500]\tLoss: 3.997873\n",
      "32725it [1:02:41,  8.69it/s]Train epoch: 2 [batch #32725, batch_size 1, seq length 2500]\tLoss: 3.608263\n",
      "32750it [1:02:44,  8.74it/s]Train epoch: 2 [batch #32750, batch_size 1, seq length 2500]\tLoss: 3.436261\n",
      "32775it [1:02:47,  8.69it/s]Train epoch: 2 [batch #32775, batch_size 1, seq length 2500]\tLoss: 3.925456\n",
      "32800it [1:02:49,  8.72it/s]Train epoch: 2 [batch #32800, batch_size 1, seq length 2500]\tLoss: 3.399554\n",
      "32825it [1:02:52,  8.71it/s]Train epoch: 2 [batch #32825, batch_size 1, seq length 2500]\tLoss: 3.939648\n",
      "32850it [1:02:55,  8.73it/s]Train epoch: 2 [batch #32850, batch_size 1, seq length 2500]\tLoss: 3.578373\n",
      "32875it [1:02:58,  8.69it/s]Train epoch: 2 [batch #32875, batch_size 1, seq length 2500]\tLoss: 3.581141\n",
      "32900it [1:03:01,  8.68it/s]Train epoch: 2 [batch #32900, batch_size 1, seq length 2500]\tLoss: 3.803572\n",
      "32925it [1:03:04,  8.73it/s]Train epoch: 2 [batch #32925, batch_size 1, seq length 2500]\tLoss: 3.678309\n",
      "32950it [1:03:07,  8.76it/s]Train epoch: 2 [batch #32950, batch_size 1, seq length 2500]\tLoss: 3.997003\n",
      "32975it [1:03:10,  8.67it/s]Train epoch: 2 [batch #32975, batch_size 1, seq length 2500]\tLoss: 3.646126\n",
      "33000it [1:03:12,  8.66it/s]Train epoch: 2 [batch #33000, batch_size 1, seq length 2500]\tLoss: 3.505820\n",
      "33025it [1:03:15,  8.65it/s]Train epoch: 2 [batch #33025, batch_size 1, seq length 2500]\tLoss: 3.510035\n",
      "33050it [1:03:18,  8.71it/s]Train epoch: 2 [batch #33050, batch_size 1, seq length 2500]\tLoss: 4.140546\n",
      "33075it [1:03:21,  8.72it/s]Train epoch: 2 [batch #33075, batch_size 1, seq length 2500]\tLoss: 3.571669\n",
      "33100it [1:03:24,  8.71it/s]Train epoch: 2 [batch #33100, batch_size 1, seq length 2500]\tLoss: 3.676508\n",
      "33125it [1:03:27,  8.64it/s]Train epoch: 2 [batch #33125, batch_size 1, seq length 2500]\tLoss: 3.389776\n",
      "33150it [1:03:30,  8.66it/s]Train epoch: 2 [batch #33150, batch_size 1, seq length 2500]\tLoss: 3.697384\n",
      "33175it [1:03:33,  8.73it/s]Train epoch: 2 [batch #33175, batch_size 1, seq length 2500]\tLoss: 3.604955\n",
      "33200it [1:03:35,  8.74it/s]Train epoch: 2 [batch #33200, batch_size 1, seq length 2500]\tLoss: 3.677838\n",
      "33225it [1:03:38,  8.74it/s]Train epoch: 2 [batch #33225, batch_size 1, seq length 2500]\tLoss: 3.448257\n",
      "33250it [1:03:41,  8.72it/s]Train epoch: 2 [batch #33250, batch_size 1, seq length 2500]\tLoss: 3.529467\n",
      "33275it [1:03:44,  8.71it/s]Train epoch: 2 [batch #33275, batch_size 1, seq length 2500]\tLoss: 3.790665\n",
      "33300it [1:03:47,  8.64it/s]Train epoch: 2 [batch #33300, batch_size 1, seq length 2500]\tLoss: 3.839977\n",
      "33325it [1:03:50,  8.75it/s]Train epoch: 2 [batch #33325, batch_size 1, seq length 2500]\tLoss: 3.498241\n",
      "33350it [1:03:53,  8.65it/s]Train epoch: 2 [batch #33350, batch_size 1, seq length 2500]\tLoss: 3.373135\n",
      "33375it [1:03:56,  8.71it/s]Train epoch: 2 [batch #33375, batch_size 1, seq length 2500]\tLoss: 4.169424\n",
      "33400it [1:03:58,  8.72it/s]Train epoch: 2 [batch #33400, batch_size 1, seq length 2500]\tLoss: 3.463378\n",
      "33425it [1:04:01,  8.76it/s]Train epoch: 2 [batch #33425, batch_size 1, seq length 2500]\tLoss: 3.939125\n",
      "33450it [1:04:04,  8.73it/s]Train epoch: 2 [batch #33450, batch_size 1, seq length 2500]\tLoss: 3.763853\n",
      "33475it [1:04:07,  8.67it/s]Train epoch: 2 [batch #33475, batch_size 1, seq length 2500]\tLoss: 3.814328\n",
      "33500it [1:04:10,  8.65it/s]Train epoch: 2 [batch #33500, batch_size 1, seq length 2500]\tLoss: 3.737152\n",
      "33525it [1:04:13,  8.69it/s]Train epoch: 2 [batch #33525, batch_size 1, seq length 2500]\tLoss: 3.684251\n",
      "33550it [1:04:16,  8.70it/s]Train epoch: 2 [batch #33550, batch_size 1, seq length 2500]\tLoss: 3.717523\n",
      "33575it [1:04:19,  8.69it/s]Train epoch: 2 [batch #33575, batch_size 1, seq length 2500]\tLoss: 3.471427\n",
      "33600it [1:04:21,  8.71it/s]Train epoch: 2 [batch #33600, batch_size 1, seq length 2500]\tLoss: 3.479692\n",
      "33625it [1:04:24,  8.73it/s]Train epoch: 2 [batch #33625, batch_size 1, seq length 2500]\tLoss: 3.380062\n",
      "33650it [1:04:27,  8.65it/s]Train epoch: 2 [batch #33650, batch_size 1, seq length 2500]\tLoss: 3.722785\n",
      "33675it [1:04:30,  8.67it/s]Train epoch: 2 [batch #33675, batch_size 1, seq length 2500]\tLoss: 3.558324\n",
      "33700it [1:04:33,  8.73it/s]Train epoch: 2 [batch #33700, batch_size 1, seq length 2500]\tLoss: 3.830817\n",
      "33725it [1:04:36,  8.69it/s]Train epoch: 2 [batch #33725, batch_size 1, seq length 2500]\tLoss: 3.484338\n",
      "33750it [1:04:39,  8.65it/s]Train epoch: 2 [batch #33750, batch_size 1, seq length 2500]\tLoss: 3.744835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33775it [1:04:42,  8.72it/s]Train epoch: 2 [batch #33775, batch_size 1, seq length 2500]\tLoss: 3.606811\n",
      "33800it [1:04:44,  8.66it/s]Train epoch: 2 [batch #33800, batch_size 1, seq length 2500]\tLoss: 3.799477\n",
      "33825it [1:04:47,  8.71it/s]Train epoch: 2 [batch #33825, batch_size 1, seq length 2500]\tLoss: 3.757381\n",
      "33850it [1:04:50,  8.70it/s]Train epoch: 2 [batch #33850, batch_size 1, seq length 2500]\tLoss: 3.740815\n",
      "33875it [1:04:53,  8.69it/s]Train epoch: 2 [batch #33875, batch_size 1, seq length 2500]\tLoss: 3.613107\n",
      "33900it [1:04:56,  8.69it/s]Train epoch: 2 [batch #33900, batch_size 1, seq length 2500]\tLoss: 3.505749\n",
      "33925it [1:04:59,  8.74it/s]Train epoch: 2 [batch #33925, batch_size 1, seq length 2500]\tLoss: 3.841606\n",
      "33950it [1:05:02,  8.73it/s]Train epoch: 2 [batch #33950, batch_size 1, seq length 2500]\tLoss: 3.710217\n",
      "33975it [1:05:05,  8.72it/s]Train epoch: 2 [batch #33975, batch_size 1, seq length 2500]\tLoss: 3.653042\n",
      "34000it [1:05:07,  8.74it/s]Train epoch: 2 [batch #34000, batch_size 1, seq length 2500]\tLoss: 4.162991\n",
      "34025it [1:05:10,  8.71it/s]Train epoch: 2 [batch #34025, batch_size 1, seq length 2500]\tLoss: 3.624278\n",
      "34050it [1:05:13,  8.71it/s]Train epoch: 2 [batch #34050, batch_size 1, seq length 2500]\tLoss: 3.654206\n",
      "34075it [1:05:16,  8.73it/s]Train epoch: 2 [batch #34075, batch_size 1, seq length 2500]\tLoss: 3.654729\n",
      "34100it [1:05:19,  8.68it/s]Train epoch: 2 [batch #34100, batch_size 1, seq length 2500]\tLoss: 3.695817\n",
      "34125it [1:05:22,  8.72it/s]Train epoch: 2 [batch #34125, batch_size 1, seq length 2500]\tLoss: 3.697140\n",
      "34150it [1:05:25,  8.68it/s]Train epoch: 2 [batch #34150, batch_size 1, seq length 2500]\tLoss: 3.837419\n",
      "34175it [1:05:28,  8.68it/s]Train epoch: 2 [batch #34175, batch_size 1, seq length 2500]\tLoss: 3.863070\n",
      "34200it [1:05:30,  8.76it/s]Train epoch: 2 [batch #34200, batch_size 1, seq length 2500]\tLoss: 3.423352\n",
      "34225it [1:05:33,  8.74it/s]Train epoch: 2 [batch #34225, batch_size 1, seq length 2500]\tLoss: 3.544196\n",
      "34250it [1:05:36,  8.74it/s]Train epoch: 2 [batch #34250, batch_size 1, seq length 2500]\tLoss: 3.425884\n",
      "34275it [1:05:39,  8.76it/s]Train epoch: 2 [batch #34275, batch_size 1, seq length 2500]\tLoss: 3.509762\n",
      "34300it [1:05:42,  8.73it/s]Train epoch: 2 [batch #34300, batch_size 1, seq length 2500]\tLoss: 3.808677\n",
      "34325it [1:05:45,  8.73it/s]Train epoch: 2 [batch #34325, batch_size 1, seq length 2500]\tLoss: 3.620408\n",
      "34350it [1:05:48,  8.65it/s]Train epoch: 2 [batch #34350, batch_size 1, seq length 2500]\tLoss: 3.810032\n",
      "34375it [1:05:50,  8.73it/s]Train epoch: 2 [batch #34375, batch_size 1, seq length 2500]\tLoss: 3.697934\n",
      "34400it [1:05:53,  8.69it/s]Train epoch: 2 [batch #34400, batch_size 1, seq length 2500]\tLoss: 3.806181\n",
      "34425it [1:05:56,  8.71it/s]Train epoch: 2 [batch #34425, batch_size 1, seq length 2500]\tLoss: 3.481171\n",
      "34450it [1:05:59,  8.72it/s]Train epoch: 2 [batch #34450, batch_size 1, seq length 2500]\tLoss: 3.354961\n",
      "34475it [1:06:02,  8.64it/s]Train epoch: 2 [batch #34475, batch_size 1, seq length 2500]\tLoss: 3.399682\n",
      "34500it [1:06:05,  8.71it/s]Train epoch: 2 [batch #34500, batch_size 1, seq length 2500]\tLoss: 3.416423\n",
      "34525it [1:06:08,  8.76it/s]Train epoch: 2 [batch #34525, batch_size 1, seq length 2500]\tLoss: 3.733012\n",
      "34550it [1:06:11,  8.69it/s]Train epoch: 2 [batch #34550, batch_size 1, seq length 2500]\tLoss: 3.462729\n",
      "34575it [1:06:13,  8.74it/s]Train epoch: 2 [batch #34575, batch_size 1, seq length 2500]\tLoss: 3.468980\n",
      "34600it [1:06:16,  8.71it/s]Train epoch: 2 [batch #34600, batch_size 1, seq length 2500]\tLoss: 3.720481\n",
      "34625it [1:06:19,  8.75it/s]Train epoch: 2 [batch #34625, batch_size 1, seq length 2500]\tLoss: 3.912639\n",
      "34650it [1:06:22,  8.67it/s]Train epoch: 2 [batch #34650, batch_size 1, seq length 2500]\tLoss: 3.511593\n",
      "34675it [1:06:25,  8.73it/s]Train epoch: 2 [batch #34675, batch_size 1, seq length 2500]\tLoss: 3.639069\n",
      "34700it [1:06:28,  8.75it/s]Train epoch: 2 [batch #34700, batch_size 1, seq length 2500]\tLoss: 3.391863\n",
      "34725it [1:06:31,  8.74it/s]Train epoch: 2 [batch #34725, batch_size 1, seq length 2500]\tLoss: 3.994658\n",
      "34750it [1:06:34,  8.73it/s]Train epoch: 2 [batch #34750, batch_size 1, seq length 2500]\tLoss: 3.623412\n",
      "34775it [1:06:36,  8.66it/s]Train epoch: 2 [batch #34775, batch_size 1, seq length 2500]\tLoss: 3.731798\n",
      "34800it [1:06:39,  8.70it/s]Train epoch: 2 [batch #34800, batch_size 1, seq length 2500]\tLoss: 3.520205\n",
      "34825it [1:06:42,  8.71it/s]Train epoch: 2 [batch #34825, batch_size 1, seq length 2500]\tLoss: 3.684755\n",
      "34850it [1:06:45,  8.65it/s]Train epoch: 2 [batch #34850, batch_size 1, seq length 2500]\tLoss: 3.626803\n",
      "34875it [1:06:48,  8.63it/s]Train epoch: 2 [batch #34875, batch_size 1, seq length 2500]\tLoss: 3.516031\n",
      "34900it [1:06:51,  8.76it/s]Train epoch: 2 [batch #34900, batch_size 1, seq length 2500]\tLoss: 3.226743\n",
      "34925it [1:06:54,  8.75it/s]Train epoch: 2 [batch #34925, batch_size 1, seq length 2500]\tLoss: 3.506715\n",
      "34950it [1:06:57,  8.73it/s]Train epoch: 2 [batch #34950, batch_size 1, seq length 2500]\tLoss: 3.561079\n",
      "34975it [1:06:59,  8.76it/s]Train epoch: 2 [batch #34975, batch_size 1, seq length 2500]\tLoss: 3.620045\n",
      "35000it [1:07:02,  8.76it/s]Train epoch: 2 [batch #35000, batch_size 1, seq length 2500]\tLoss: 3.407497\n",
      "35025it [1:07:05,  8.69it/s]Train epoch: 2 [batch #35025, batch_size 1, seq length 2500]\tLoss: 3.808655\n",
      "35050it [1:07:08,  8.62it/s]Train epoch: 2 [batch #35050, batch_size 1, seq length 2500]\tLoss: 3.601572\n",
      "35075it [1:07:11,  8.67it/s]Train epoch: 2 [batch #35075, batch_size 1, seq length 2500]\tLoss: 3.816679\n",
      "35100it [1:07:14,  8.67it/s]Train epoch: 2 [batch #35100, batch_size 1, seq length 2500]\tLoss: 3.744902\n",
      "35125it [1:07:17,  8.74it/s]Train epoch: 2 [batch #35125, batch_size 1, seq length 2500]\tLoss: 4.009152\n",
      "35150it [1:07:19,  8.67it/s]Train epoch: 2 [batch #35150, batch_size 1, seq length 2500]\tLoss: 3.955179\n",
      "35175it [1:07:22,  8.66it/s]Train epoch: 2 [batch #35175, batch_size 1, seq length 2500]\tLoss: 3.703285\n",
      "35200it [1:07:25,  8.69it/s]Train epoch: 2 [batch #35200, batch_size 1, seq length 2500]\tLoss: 3.449727\n",
      "35225it [1:07:28,  8.69it/s]Train epoch: 2 [batch #35225, batch_size 1, seq length 2500]\tLoss: 3.632731\n",
      "35250it [1:07:31,  8.75it/s]Train epoch: 2 [batch #35250, batch_size 1, seq length 2500]\tLoss: 3.544203\n",
      "35275it [1:07:34,  8.78it/s]Train epoch: 2 [batch #35275, batch_size 1, seq length 2500]\tLoss: 3.719498\n",
      "35300it [1:07:37,  8.65it/s]Train epoch: 2 [batch #35300, batch_size 1, seq length 2500]\tLoss: 3.735182\n",
      "35325it [1:07:40,  8.72it/s]Train epoch: 2 [batch #35325, batch_size 1, seq length 2500]\tLoss: 3.957854\n",
      "35350it [1:07:42,  8.74it/s]Train epoch: 2 [batch #35350, batch_size 1, seq length 2500]\tLoss: 3.692588\n",
      "35375it [1:07:45,  8.75it/s]Train epoch: 2 [batch #35375, batch_size 1, seq length 2500]\tLoss: 3.614567\n",
      "35400it [1:07:48,  8.72it/s]Train epoch: 2 [batch #35400, batch_size 1, seq length 2500]\tLoss: 3.882404\n",
      "35425it [1:07:51,  8.72it/s]Train epoch: 2 [batch #35425, batch_size 1, seq length 2500]\tLoss: 4.114268\n",
      "35450it [1:07:54,  8.73it/s]Train epoch: 2 [batch #35450, batch_size 1, seq length 2500]\tLoss: 3.659647\n",
      "35475it [1:07:57,  8.71it/s]Train epoch: 2 [batch #35475, batch_size 1, seq length 2500]\tLoss: 3.589191\n",
      "35500it [1:08:00,  8.69it/s]Train epoch: 2 [batch #35500, batch_size 1, seq length 2500]\tLoss: 3.558615\n",
      "35525it [1:08:03,  8.71it/s]Train epoch: 2 [batch #35525, batch_size 1, seq length 2500]\tLoss: 3.600371\n",
      "35550it [1:08:05,  8.70it/s]Train epoch: 2 [batch #35550, batch_size 1, seq length 2500]\tLoss: 3.636175\n",
      "35575it [1:08:08,  8.71it/s]Train epoch: 2 [batch #35575, batch_size 1, seq length 2500]\tLoss: 3.671475\n",
      "35600it [1:08:11,  8.60it/s]Train epoch: 2 [batch #35600, batch_size 1, seq length 2500]\tLoss: 3.606849\n",
      "35625it [1:08:14,  8.74it/s]Train epoch: 2 [batch #35625, batch_size 1, seq length 2500]\tLoss: 3.723505\n",
      "35650it [1:08:17,  8.77it/s]Train epoch: 2 [batch #35650, batch_size 1, seq length 2500]\tLoss: 3.634438\n",
      "35675it [1:08:20,  8.73it/s]Train epoch: 2 [batch #35675, batch_size 1, seq length 2500]\tLoss: 3.529346\n",
      "35700it [1:08:23,  8.72it/s]Train epoch: 2 [batch #35700, batch_size 1, seq length 2500]\tLoss: 3.802326\n",
      "35725it [1:08:26,  8.73it/s]Train epoch: 2 [batch #35725, batch_size 1, seq length 2500]\tLoss: 3.764188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35750it [1:08:28,  8.66it/s]Train epoch: 2 [batch #35750, batch_size 1, seq length 2500]\tLoss: 3.759350\n",
      "35775it [1:08:31,  8.76it/s]Train epoch: 2 [batch #35775, batch_size 1, seq length 2500]\tLoss: 3.633176\n",
      "35800it [1:08:34,  8.75it/s]Train epoch: 2 [batch #35800, batch_size 1, seq length 2500]\tLoss: 3.818776\n",
      "35825it [1:08:37,  8.74it/s]Train epoch: 2 [batch #35825, batch_size 1, seq length 2500]\tLoss: 3.663749\n",
      "35850it [1:08:40,  8.60it/s]Train epoch: 2 [batch #35850, batch_size 1, seq length 2500]\tLoss: 3.470676\n",
      "35875it [1:08:43,  8.69it/s]Train epoch: 2 [batch #35875, batch_size 1, seq length 2500]\tLoss: 3.692592\n",
      "35900it [1:08:46,  8.72it/s]Train epoch: 2 [batch #35900, batch_size 1, seq length 2500]\tLoss: 3.803280\n",
      "35925it [1:08:48,  8.73it/s]Train epoch: 2 [batch #35925, batch_size 1, seq length 2500]\tLoss: 3.910355\n",
      "35950it [1:08:51,  8.71it/s]Train epoch: 2 [batch #35950, batch_size 1, seq length 2500]\tLoss: 3.656722\n",
      "35975it [1:08:54,  8.73it/s]Train epoch: 2 [batch #35975, batch_size 1, seq length 2500]\tLoss: 3.835567\n",
      "36000it [1:08:57,  8.68it/s]Train epoch: 2 [batch #36000, batch_size 1, seq length 2500]\tLoss: 3.854120\n",
      "36025it [1:09:00,  8.70it/s]Train epoch: 2 [batch #36025, batch_size 1, seq length 2500]\tLoss: 3.554128\n",
      "36050it [1:09:03,  8.66it/s]Train epoch: 2 [batch #36050, batch_size 1, seq length 2500]\tLoss: 3.385309\n",
      "36075it [1:09:06,  8.67it/s]Train epoch: 2 [batch #36075, batch_size 1, seq length 2500]\tLoss: 3.528362\n",
      "36100it [1:09:09,  8.72it/s]Train epoch: 2 [batch #36100, batch_size 1, seq length 2500]\tLoss: 3.642689\n",
      "36125it [1:09:11,  8.70it/s]Train epoch: 2 [batch #36125, batch_size 1, seq length 2500]\tLoss: 3.313451\n",
      "36150it [1:09:14,  8.73it/s]Train epoch: 2 [batch #36150, batch_size 1, seq length 2500]\tLoss: 3.578188\n",
      "36175it [1:09:17,  8.74it/s]Train epoch: 2 [batch #36175, batch_size 1, seq length 2500]\tLoss: 2.939124\n",
      "36200it [1:09:20,  8.76it/s]Train epoch: 2 [batch #36200, batch_size 1, seq length 2500]\tLoss: 3.406623\n",
      "36225it [1:09:23,  8.73it/s]Train epoch: 2 [batch #36225, batch_size 1, seq length 2500]\tLoss: 3.664336\n",
      "36250it [1:09:26,  8.62it/s]Train epoch: 2 [batch #36250, batch_size 1, seq length 2500]\tLoss: 3.642891\n",
      "36275it [1:09:29,  8.71it/s]Train epoch: 2 [batch #36275, batch_size 1, seq length 2500]\tLoss: 3.804376\n",
      "36300it [1:09:32,  8.74it/s]Train epoch: 2 [batch #36300, batch_size 1, seq length 2500]\tLoss: 3.622820\n",
      "36325it [1:09:34,  8.67it/s]Train epoch: 2 [batch #36325, batch_size 1, seq length 2500]\tLoss: 3.441890\n",
      "36350it [1:09:37,  8.72it/s]Train epoch: 2 [batch #36350, batch_size 1, seq length 2500]\tLoss: 3.789515\n",
      "36375it [1:09:40,  8.74it/s]Train epoch: 2 [batch #36375, batch_size 1, seq length 2500]\tLoss: 4.053739\n",
      "36400it [1:09:43,  8.59it/s]Train epoch: 2 [batch #36400, batch_size 1, seq length 2500]\tLoss: 3.314681\n",
      "36425it [1:09:46,  8.75it/s]Train epoch: 2 [batch #36425, batch_size 1, seq length 2500]\tLoss: 3.180920\n",
      "36450it [1:09:49,  8.73it/s]Train epoch: 2 [batch #36450, batch_size 1, seq length 2500]\tLoss: 3.736640\n",
      "36475it [1:09:52,  8.72it/s]Train epoch: 2 [batch #36475, batch_size 1, seq length 2500]\tLoss: 3.714435\n",
      "36500it [1:09:55,  8.71it/s]Train epoch: 2 [batch #36500, batch_size 1, seq length 2500]\tLoss: 3.672571\n",
      "36525it [1:09:57,  8.66it/s]Train epoch: 2 [batch #36525, batch_size 1, seq length 2500]\tLoss: 3.693537\n",
      "36550it [1:10:00,  8.75it/s]Train epoch: 2 [batch #36550, batch_size 1, seq length 2500]\tLoss: 3.695992\n",
      "36575it [1:10:03,  8.60it/s]Train epoch: 2 [batch #36575, batch_size 1, seq length 2500]\tLoss: 3.434254\n",
      "36600it [1:10:06,  8.69it/s]Train epoch: 2 [batch #36600, batch_size 1, seq length 2500]\tLoss: 3.494041\n",
      "36625it [1:10:09,  8.70it/s]Train epoch: 2 [batch #36625, batch_size 1, seq length 2500]\tLoss: 3.629911\n",
      "36650it [1:10:12,  8.75it/s]Train epoch: 2 [batch #36650, batch_size 1, seq length 2500]\tLoss: 3.753630\n",
      "36675it [1:10:15,  8.69it/s]Train epoch: 2 [batch #36675, batch_size 1, seq length 2500]\tLoss: 3.813543\n",
      "36700it [1:10:18,  8.65it/s]Train epoch: 2 [batch #36700, batch_size 1, seq length 2500]\tLoss: 3.561938\n",
      "36725it [1:10:20,  8.74it/s]Train epoch: 2 [batch #36725, batch_size 1, seq length 2500]\tLoss: 3.504534\n",
      "36750it [1:10:23,  8.63it/s]Train epoch: 2 [batch #36750, batch_size 1, seq length 2500]\tLoss: 3.687196\n",
      "36775it [1:10:26,  8.71it/s]Train epoch: 2 [batch #36775, batch_size 1, seq length 2500]\tLoss: 3.502117\n",
      "36800it [1:10:29,  8.71it/s]Train epoch: 2 [batch #36800, batch_size 1, seq length 2500]\tLoss: 3.610726\n",
      "36825it [1:10:32,  8.71it/s]Train epoch: 2 [batch #36825, batch_size 1, seq length 2500]\tLoss: 3.923888\n",
      "36850it [1:10:35,  8.70it/s]Train epoch: 2 [batch #36850, batch_size 1, seq length 2500]\tLoss: 3.605918\n",
      "36875it [1:10:38,  8.71it/s]Train epoch: 2 [batch #36875, batch_size 1, seq length 2500]\tLoss: 3.545921\n",
      "36900it [1:10:41,  8.70it/s]Train epoch: 2 [batch #36900, batch_size 1, seq length 2500]\tLoss: 3.603412\n",
      "36925it [1:10:43,  8.74it/s]Train epoch: 2 [batch #36925, batch_size 1, seq length 2500]\tLoss: 3.774273\n",
      "36950it [1:10:46,  8.72it/s]Train epoch: 2 [batch #36950, batch_size 1, seq length 2500]\tLoss: 3.663634\n",
      "36975it [1:10:49,  8.73it/s]Train epoch: 2 [batch #36975, batch_size 1, seq length 2500]\tLoss: 3.623763\n",
      "37000it [1:10:52,  8.64it/s]Train epoch: 2 [batch #37000, batch_size 1, seq length 2500]\tLoss: 3.488639\n",
      "37025it [1:10:55,  8.68it/s]Train epoch: 2 [batch #37025, batch_size 1, seq length 2500]\tLoss: 3.827756\n",
      "37050it [1:10:58,  8.75it/s]Train epoch: 2 [batch #37050, batch_size 1, seq length 2500]\tLoss: 3.870775\n",
      "37075it [1:11:01,  8.61it/s]Train epoch: 2 [batch #37075, batch_size 1, seq length 2500]\tLoss: 3.770830\n",
      "37100it [1:11:04,  8.72it/s]Train epoch: 2 [batch #37100, batch_size 1, seq length 2500]\tLoss: 3.990979\n",
      "37125it [1:11:06,  8.71it/s]Train epoch: 2 [batch #37125, batch_size 1, seq length 2500]\tLoss: 3.488505\n",
      "37150it [1:11:09,  8.74it/s]Train epoch: 2 [batch #37150, batch_size 1, seq length 2500]\tLoss: 3.939613\n",
      "37175it [1:11:12,  8.67it/s]Train epoch: 2 [batch #37175, batch_size 1, seq length 2500]\tLoss: 3.736111\n",
      "37200it [1:11:15,  8.65it/s]Train epoch: 2 [batch #37200, batch_size 1, seq length 2500]\tLoss: 3.717181\n",
      "37225it [1:11:18,  8.70it/s]Train epoch: 2 [batch #37225, batch_size 1, seq length 2500]\tLoss: 3.640465\n",
      "37250it [1:11:21,  8.75it/s]Train epoch: 2 [batch #37250, batch_size 1, seq length 2500]\tLoss: 3.574464\n",
      "37275it [1:11:24,  8.71it/s]Train epoch: 2 [batch #37275, batch_size 1, seq length 2500]\tLoss: 3.420169\n",
      "37300it [1:11:27,  8.75it/s]Train epoch: 2 [batch #37300, batch_size 1, seq length 2500]\tLoss: 3.421211\n",
      "37325it [1:11:29,  8.76it/s]Train epoch: 2 [batch #37325, batch_size 1, seq length 2500]\tLoss: 3.812018\n",
      "37350it [1:11:32,  8.68it/s]Train epoch: 2 [batch #37350, batch_size 1, seq length 2500]\tLoss: 3.618753\n",
      "37375it [1:11:35,  8.65it/s]Train epoch: 2 [batch #37375, batch_size 1, seq length 2500]\tLoss: 3.723933\n",
      "37400it [1:11:38,  8.77it/s]Train epoch: 2 [batch #37400, batch_size 1, seq length 2500]\tLoss: 3.589776\n",
      "37425it [1:11:41,  8.70it/s]Train epoch: 2 [batch #37425, batch_size 1, seq length 2500]\tLoss: 3.738111\n",
      "37450it [1:11:44,  8.72it/s]Train epoch: 2 [batch #37450, batch_size 1, seq length 2500]\tLoss: 3.828991\n",
      "37475it [1:11:47,  8.68it/s]Train epoch: 2 [batch #37475, batch_size 1, seq length 2500]\tLoss: 3.546407\n",
      "37500it [1:11:49,  8.66it/s]Train epoch: 2 [batch #37500, batch_size 1, seq length 2500]\tLoss: 3.848542\n",
      "37525it [1:11:52,  8.69it/s]Train epoch: 2 [batch #37525, batch_size 1, seq length 2500]\tLoss: 3.714387\n",
      "37550it [1:11:55,  8.61it/s]Train epoch: 2 [batch #37550, batch_size 1, seq length 2500]\tLoss: 3.726846\n",
      "37575it [1:11:58,  8.74it/s]Train epoch: 2 [batch #37575, batch_size 1, seq length 2500]\tLoss: 3.757659\n",
      "37600it [1:12:01,  8.71it/s]Train epoch: 2 [batch #37600, batch_size 1, seq length 2500]\tLoss: 3.616386\n",
      "37625it [1:12:04,  8.65it/s]Train epoch: 2 [batch #37625, batch_size 1, seq length 2500]\tLoss: 3.875643\n",
      "37650it [1:12:07,  8.69it/s]Train epoch: 2 [batch #37650, batch_size 1, seq length 2500]\tLoss: 3.821288\n",
      "37675it [1:12:10,  8.72it/s]Train epoch: 2 [batch #37675, batch_size 1, seq length 2500]\tLoss: 3.944141\n",
      "37700it [1:12:13,  8.64it/s]Train epoch: 2 [batch #37700, batch_size 1, seq length 2500]\tLoss: 3.751267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37725it [1:12:15,  8.73it/s]Train epoch: 2 [batch #37725, batch_size 1, seq length 2500]\tLoss: 3.908550\n",
      "37750it [1:12:18,  8.71it/s]Train epoch: 2 [batch #37750, batch_size 1, seq length 2500]\tLoss: 3.458938\n",
      "37775it [1:12:21,  8.72it/s]Train epoch: 2 [batch #37775, batch_size 1, seq length 2500]\tLoss: 3.682839\n",
      "37800it [1:12:24,  8.74it/s]Train epoch: 2 [batch #37800, batch_size 1, seq length 2500]\tLoss: 3.618964\n",
      "37825it [1:12:27,  8.59it/s]Train epoch: 2 [batch #37825, batch_size 1, seq length 2500]\tLoss: 3.484174\n",
      "37850it [1:12:30,  8.70it/s]Train epoch: 2 [batch #37850, batch_size 1, seq length 2500]\tLoss: 3.379553\n",
      "37875it [1:12:33,  8.67it/s]Train epoch: 2 [batch #37875, batch_size 1, seq length 2500]\tLoss: 3.779469\n",
      "37900it [1:12:36,  8.75it/s]Train epoch: 2 [batch #37900, batch_size 1, seq length 2500]\tLoss: 3.896674\n",
      "37925it [1:12:38,  8.73it/s]Train epoch: 2 [batch #37925, batch_size 1, seq length 2500]\tLoss: 3.339880\n",
      "37950it [1:12:41,  8.66it/s]Train epoch: 2 [batch #37950, batch_size 1, seq length 2500]\tLoss: 3.821310\n",
      "37975it [1:12:44,  8.72it/s]Train epoch: 2 [batch #37975, batch_size 1, seq length 2500]\tLoss: 4.231597\n",
      "38000it [1:12:47,  8.46it/s]Train epoch: 2 [batch #38000, batch_size 1, seq length 2500]\tLoss: 4.187938\n",
      "38025it [1:12:50,  8.67it/s]Train epoch: 2 [batch #38025, batch_size 1, seq length 2500]\tLoss: 3.741857\n",
      "38050it [1:12:53,  8.77it/s]Train epoch: 2 [batch #38050, batch_size 1, seq length 2500]\tLoss: 3.555251\n",
      "38075it [1:12:56,  8.75it/s]Train epoch: 2 [batch #38075, batch_size 1, seq length 2500]\tLoss: 3.913781\n",
      "38100it [1:12:59,  8.75it/s]Train epoch: 2 [batch #38100, batch_size 1, seq length 2500]\tLoss: 3.492780\n",
      "38125it [1:13:01,  8.69it/s]Train epoch: 2 [batch #38125, batch_size 1, seq length 2500]\tLoss: 3.708047\n",
      "38150it [1:13:04,  8.68it/s]Train epoch: 2 [batch #38150, batch_size 1, seq length 2500]\tLoss: 3.662159\n",
      "38175it [1:13:07,  8.74it/s]Train epoch: 2 [batch #38175, batch_size 1, seq length 2500]\tLoss: 3.571164\n",
      "38200it [1:13:10,  8.73it/s]Train epoch: 2 [batch #38200, batch_size 1, seq length 2500]\tLoss: 3.586177\n",
      "38225it [1:13:13,  8.68it/s]Train epoch: 2 [batch #38225, batch_size 1, seq length 2500]\tLoss: 3.103893\n",
      "38250it [1:13:16,  8.71it/s]Train epoch: 2 [batch #38250, batch_size 1, seq length 2500]\tLoss: 4.175446\n",
      "38275it [1:13:19,  8.76it/s]Train epoch: 2 [batch #38275, batch_size 1, seq length 2500]\tLoss: 3.814637\n",
      "38300it [1:13:22,  8.62it/s]Train epoch: 2 [batch #38300, batch_size 1, seq length 2500]\tLoss: 3.419298\n",
      "38325it [1:13:24,  8.73it/s]Train epoch: 2 [batch #38325, batch_size 1, seq length 2500]\tLoss: 3.611526\n",
      "38350it [1:13:27,  8.49it/s]Train epoch: 2 [batch #38350, batch_size 1, seq length 2500]\tLoss: 3.408834\n",
      "38375it [1:13:30,  8.70it/s]Train epoch: 2 [batch #38375, batch_size 1, seq length 2500]\tLoss: 3.613902\n",
      "38400it [1:13:33,  8.69it/s]Train epoch: 2 [batch #38400, batch_size 1, seq length 2500]\tLoss: 3.683861\n",
      "38425it [1:13:36,  8.65it/s]Train epoch: 2 [batch #38425, batch_size 1, seq length 2500]\tLoss: 3.724284\n",
      "38450it [1:13:39,  8.72it/s]Train epoch: 2 [batch #38450, batch_size 1, seq length 2500]\tLoss: 3.708799\n",
      "38475it [1:13:42,  8.73it/s]Train epoch: 2 [batch #38475, batch_size 1, seq length 2500]\tLoss: 3.715193\n",
      "38500it [1:13:45,  8.67it/s]Train epoch: 2 [batch #38500, batch_size 1, seq length 2500]\tLoss: 4.018483\n",
      "38525it [1:13:47,  8.72it/s]Train epoch: 2 [batch #38525, batch_size 1, seq length 2500]\tLoss: 3.730032\n",
      "38550it [1:13:50,  8.72it/s]Train epoch: 2 [batch #38550, batch_size 1, seq length 2500]\tLoss: 3.613819\n",
      "38575it [1:13:53,  8.72it/s]Train epoch: 2 [batch #38575, batch_size 1, seq length 2500]\tLoss: 3.413449\n",
      "38600it [1:13:56,  8.67it/s]Train epoch: 2 [batch #38600, batch_size 1, seq length 2500]\tLoss: 3.624942\n",
      "38625it [1:13:59,  8.76it/s]Train epoch: 2 [batch #38625, batch_size 1, seq length 2500]\tLoss: 3.736294\n",
      "38650it [1:14:02,  8.72it/s]Train epoch: 2 [batch #38650, batch_size 1, seq length 2500]\tLoss: 3.581121\n",
      "38675it [1:14:05,  8.71it/s]Train epoch: 2 [batch #38675, batch_size 1, seq length 2500]\tLoss: 3.692270\n",
      "38700it [1:14:07,  8.72it/s]Train epoch: 2 [batch #38700, batch_size 1, seq length 2500]\tLoss: 3.567875\n",
      "38725it [1:14:10,  8.69it/s]Train epoch: 2 [batch #38725, batch_size 1, seq length 2500]\tLoss: 3.797074\n",
      "38750it [1:14:13,  8.72it/s]Train epoch: 2 [batch #38750, batch_size 1, seq length 2500]\tLoss: 3.713708\n",
      "38775it [1:14:16,  8.69it/s]Train epoch: 2 [batch #38775, batch_size 1, seq length 2500]\tLoss: 3.882229\n",
      "38800it [1:14:19,  8.71it/s]Train epoch: 2 [batch #38800, batch_size 1, seq length 2500]\tLoss: 3.875580\n",
      "38825it [1:14:22,  8.74it/s]Train epoch: 2 [batch #38825, batch_size 1, seq length 2500]\tLoss: 3.793975\n",
      "38850it [1:14:25,  8.75it/s]Train epoch: 2 [batch #38850, batch_size 1, seq length 2500]\tLoss: 3.669937\n",
      "38875it [1:14:28,  8.73it/s]Train epoch: 2 [batch #38875, batch_size 1, seq length 2500]\tLoss: 3.743786\n",
      "38900it [1:14:30,  8.74it/s]Train epoch: 2 [batch #38900, batch_size 1, seq length 2500]\tLoss: 3.765250\n",
      "38925it [1:14:33,  8.73it/s]Train epoch: 2 [batch #38925, batch_size 1, seq length 2500]\tLoss: 3.609437\n",
      "38950it [1:14:36,  8.69it/s]Train epoch: 2 [batch #38950, batch_size 1, seq length 2500]\tLoss: 3.875694\n",
      "38975it [1:14:39,  8.74it/s]Train epoch: 2 [batch #38975, batch_size 1, seq length 2500]\tLoss: 3.475890\n",
      "39000it [1:14:42,  8.70it/s]Train epoch: 2 [batch #39000, batch_size 1, seq length 2500]\tLoss: 3.910926\n",
      "39025it [1:14:45,  8.66it/s]Train epoch: 2 [batch #39025, batch_size 1, seq length 2500]\tLoss: 3.972127\n",
      "39050it [1:14:48,  8.63it/s]Train epoch: 2 [batch #39050, batch_size 1, seq length 2500]\tLoss: 3.650906\n",
      "39075it [1:14:51,  8.69it/s]Train epoch: 2 [batch #39075, batch_size 1, seq length 2500]\tLoss: 3.667229\n",
      "39100it [1:14:53,  8.78it/s]Train epoch: 2 [batch #39100, batch_size 1, seq length 2500]\tLoss: 3.377380\n",
      "39125it [1:14:56,  8.67it/s]Train epoch: 2 [batch #39125, batch_size 1, seq length 2500]\tLoss: 3.738449\n",
      "39150it [1:14:59,  8.75it/s]Train epoch: 2 [batch #39150, batch_size 1, seq length 2500]\tLoss: 3.532112\n",
      "39175it [1:15:02,  8.71it/s]Train epoch: 2 [batch #39175, batch_size 1, seq length 2500]\tLoss: 3.895633\n",
      "39200it [1:15:05,  8.73it/s]Train epoch: 2 [batch #39200, batch_size 1, seq length 2500]\tLoss: 3.365027\n",
      "39225it [1:15:08,  8.73it/s]Train epoch: 2 [batch #39225, batch_size 1, seq length 2500]\tLoss: 3.693669\n",
      "39250it [1:15:11,  8.66it/s]Train epoch: 2 [batch #39250, batch_size 1, seq length 2500]\tLoss: 3.361021\n",
      "39275it [1:15:14,  8.64it/s]Train epoch: 2 [batch #39275, batch_size 1, seq length 2500]\tLoss: 3.878179\n",
      "39300it [1:15:16,  8.73it/s]Train epoch: 2 [batch #39300, batch_size 1, seq length 2500]\tLoss: 3.785904\n",
      "39325it [1:15:19,  8.67it/s]Train epoch: 2 [batch #39325, batch_size 1, seq length 2500]\tLoss: 3.540523\n",
      "39350it [1:15:22,  8.67it/s]Train epoch: 2 [batch #39350, batch_size 1, seq length 2500]\tLoss: 3.540255\n",
      "39375it [1:15:25,  8.63it/s]Train epoch: 2 [batch #39375, batch_size 1, seq length 2500]\tLoss: 3.910630\n",
      "39400it [1:15:28,  8.66it/s]Train epoch: 2 [batch #39400, batch_size 1, seq length 2500]\tLoss: 3.599575\n",
      "39425it [1:15:31,  8.66it/s]Train epoch: 2 [batch #39425, batch_size 1, seq length 2500]\tLoss: 3.468335\n",
      "39450it [1:15:34,  8.75it/s]Train epoch: 2 [batch #39450, batch_size 1, seq length 2500]\tLoss: 3.677215\n",
      "39475it [1:15:37,  8.77it/s]Train epoch: 2 [batch #39475, batch_size 1, seq length 2500]\tLoss: 3.336424\n",
      "39500it [1:15:39,  8.69it/s]Train epoch: 2 [batch #39500, batch_size 1, seq length 2500]\tLoss: 3.643806\n",
      "39525it [1:15:42,  8.63it/s]Train epoch: 2 [batch #39525, batch_size 1, seq length 2500]\tLoss: 3.633517\n",
      "39550it [1:15:45,  8.73it/s]Train epoch: 2 [batch #39550, batch_size 1, seq length 2500]\tLoss: 3.673891\n",
      "39575it [1:15:48,  8.68it/s]Train epoch: 2 [batch #39575, batch_size 1, seq length 2500]\tLoss: 3.698973\n",
      "39600it [1:15:51,  8.76it/s]Train epoch: 2 [batch #39600, batch_size 1, seq length 2500]\tLoss: 3.530127\n",
      "39625it [1:15:54,  8.60it/s]Train epoch: 2 [batch #39625, batch_size 1, seq length 2500]\tLoss: 3.730059\n",
      "39650it [1:15:57,  8.75it/s]Train epoch: 2 [batch #39650, batch_size 1, seq length 2500]\tLoss: 3.739191\n",
      "39675it [1:16:00,  8.65it/s]Train epoch: 2 [batch #39675, batch_size 1, seq length 2500]\tLoss: 3.635337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39700it [1:16:03,  8.75it/s]Train epoch: 2 [batch #39700, batch_size 1, seq length 2500]\tLoss: 3.558083\n",
      "39725it [1:16:05,  8.67it/s]Train epoch: 2 [batch #39725, batch_size 1, seq length 2500]\tLoss: 3.572798\n",
      "39750it [1:16:08,  8.67it/s]Train epoch: 2 [batch #39750, batch_size 1, seq length 2500]\tLoss: 3.798083\n",
      "39775it [1:16:11,  8.67it/s]Train epoch: 2 [batch #39775, batch_size 1, seq length 2500]\tLoss: 3.496719\n",
      "39800it [1:16:14,  8.69it/s]Train epoch: 2 [batch #39800, batch_size 1, seq length 2500]\tLoss: 3.727773\n",
      "39825it [1:16:17,  8.74it/s]Train epoch: 2 [batch #39825, batch_size 1, seq length 2500]\tLoss: 4.149377\n",
      "39850it [1:16:20,  8.72it/s]Train epoch: 2 [batch #39850, batch_size 1, seq length 2500]\tLoss: 3.422015\n",
      "39875it [1:16:23,  8.76it/s]Train epoch: 2 [batch #39875, batch_size 1, seq length 2500]\tLoss: 3.499421\n",
      "39900it [1:16:26,  8.72it/s]Train epoch: 2 [batch #39900, batch_size 1, seq length 2500]\tLoss: 3.331962\n",
      "39925it [1:16:28,  8.63it/s]Train epoch: 2 [batch #39925, batch_size 1, seq length 2500]\tLoss: 3.651275\n",
      "39950it [1:16:31,  8.67it/s]Train epoch: 2 [batch #39950, batch_size 1, seq length 2500]\tLoss: 3.725786\n",
      "39975it [1:16:34,  8.74it/s]Train epoch: 2 [batch #39975, batch_size 1, seq length 2500]\tLoss: 3.882897\n",
      "40000it [1:16:37,  8.67it/s]Train epoch: 2 [batch #40000, batch_size 1, seq length 2500]\tLoss: 3.421737\n",
      "40025it [1:16:40,  8.69it/s]Train epoch: 2 [batch #40025, batch_size 1, seq length 2500]\tLoss: 3.507816\n",
      "40050it [1:16:43,  8.75it/s]Train epoch: 2 [batch #40050, batch_size 1, seq length 2500]\tLoss: 3.742081\n",
      "40075it [1:16:46,  8.75it/s]Train epoch: 2 [batch #40075, batch_size 1, seq length 2500]\tLoss: 3.737659\n",
      "40100it [1:16:49,  8.72it/s]Train epoch: 2 [batch #40100, batch_size 1, seq length 2500]\tLoss: 3.411968\n",
      "40125it [1:16:51,  8.52it/s]Train epoch: 2 [batch #40125, batch_size 1, seq length 2500]\tLoss: 3.680512\n",
      "40150it [1:16:54,  8.61it/s]Train epoch: 2 [batch #40150, batch_size 1, seq length 2500]\tLoss: 3.803548\n",
      "40175it [1:16:57,  8.64it/s]Train epoch: 2 [batch #40175, batch_size 1, seq length 2500]\tLoss: 3.625562\n",
      "40200it [1:17:00,  8.70it/s]Train epoch: 2 [batch #40200, batch_size 1, seq length 2500]\tLoss: 3.655389\n",
      "40225it [1:17:03,  8.71it/s]Train epoch: 2 [batch #40225, batch_size 1, seq length 2500]\tLoss: 3.765356\n",
      "40250it [1:17:06,  8.66it/s]Train epoch: 2 [batch #40250, batch_size 1, seq length 2500]\tLoss: 3.669875\n",
      "40275it [1:17:09,  8.69it/s]Train epoch: 2 [batch #40275, batch_size 1, seq length 2500]\tLoss: 3.417133\n",
      "40300it [1:17:12,  8.66it/s]Train epoch: 2 [batch #40300, batch_size 1, seq length 2500]\tLoss: 4.007261\n",
      "40325it [1:17:14,  8.71it/s]Train epoch: 2 [batch #40325, batch_size 1, seq length 2500]\tLoss: 3.575243\n",
      "40350it [1:17:17,  8.68it/s]Train epoch: 2 [batch #40350, batch_size 1, seq length 2500]\tLoss: 3.898555\n",
      "40375it [1:17:20,  8.67it/s]Train epoch: 2 [batch #40375, batch_size 1, seq length 2500]\tLoss: 3.635916\n",
      "40400it [1:17:23,  8.64it/s]Train epoch: 2 [batch #40400, batch_size 1, seq length 2500]\tLoss: 3.576524\n",
      "40425it [1:17:26,  8.69it/s]Train epoch: 2 [batch #40425, batch_size 1, seq length 2500]\tLoss: 3.544920\n",
      "40450it [1:17:29,  8.77it/s]Train epoch: 2 [batch #40450, batch_size 1, seq length 2500]\tLoss: 3.785625\n",
      "40475it [1:17:32,  8.75it/s]Train epoch: 2 [batch #40475, batch_size 1, seq length 2500]\tLoss: 3.546686\n",
      "40500it [1:17:35,  8.71it/s]Train epoch: 2 [batch #40500, batch_size 1, seq length 2500]\tLoss: 3.763240\n",
      "40525it [1:17:37,  8.68it/s]Train epoch: 2 [batch #40525, batch_size 1, seq length 2500]\tLoss: 3.618338\n",
      "40550it [1:17:40,  8.75it/s]Train epoch: 2 [batch #40550, batch_size 1, seq length 2500]\tLoss: 3.911390\n",
      "40575it [1:17:43,  8.73it/s]Train epoch: 2 [batch #40575, batch_size 1, seq length 2500]\tLoss: 3.677174\n",
      "40600it [1:17:46,  8.62it/s]Train epoch: 2 [batch #40600, batch_size 1, seq length 2500]\tLoss: 3.442652\n",
      "40625it [1:17:49,  8.72it/s]Train epoch: 2 [batch #40625, batch_size 1, seq length 2500]\tLoss: 3.730467\n",
      "40650it [1:17:52,  8.73it/s]Train epoch: 2 [batch #40650, batch_size 1, seq length 2500]\tLoss: 3.697444\n",
      "40675it [1:17:55,  8.69it/s]Train epoch: 2 [batch #40675, batch_size 1, seq length 2500]\tLoss: 4.089799\n",
      "40700it [1:17:58,  8.76it/s]Train epoch: 2 [batch #40700, batch_size 1, seq length 2500]\tLoss: 3.580754\n",
      "40725it [1:18:00,  8.73it/s]Train epoch: 2 [batch #40725, batch_size 1, seq length 2500]\tLoss: 3.914963\n",
      "40750it [1:18:03,  8.63it/s]Train epoch: 2 [batch #40750, batch_size 1, seq length 2500]\tLoss: 3.644306\n",
      "40775it [1:18:06,  8.77it/s]Train epoch: 2 [batch #40775, batch_size 1, seq length 2500]\tLoss: 3.729498\n",
      "40800it [1:18:09,  8.72it/s]Train epoch: 2 [batch #40800, batch_size 1, seq length 2500]\tLoss: 3.858567\n",
      "40825it [1:18:12,  8.70it/s]Train epoch: 2 [batch #40825, batch_size 1, seq length 2500]\tLoss: 3.783164\n",
      "40850it [1:18:15,  8.69it/s]Train epoch: 2 [batch #40850, batch_size 1, seq length 2500]\tLoss: 3.592984\n",
      "40875it [1:18:18,  8.66it/s]Train epoch: 2 [batch #40875, batch_size 1, seq length 2500]\tLoss: 3.724184\n",
      "40900it [1:18:21,  8.75it/s]Train epoch: 2 [batch #40900, batch_size 1, seq length 2500]\tLoss: 3.717471\n",
      "40925it [1:18:23,  8.77it/s]Train epoch: 2 [batch #40925, batch_size 1, seq length 2500]\tLoss: 3.237227\n",
      "40950it [1:18:26,  8.74it/s]Train epoch: 2 [batch #40950, batch_size 1, seq length 2500]\tLoss: 3.606650\n",
      "40975it [1:18:29,  8.73it/s]Train epoch: 2 [batch #40975, batch_size 1, seq length 2500]\tLoss: 3.622540\n",
      "41000it [1:18:32,  8.57it/s]Train epoch: 2 [batch #41000, batch_size 1, seq length 2500]\tLoss: 3.205225\n",
      "41025it [1:18:35,  8.69it/s]Train epoch: 2 [batch #41025, batch_size 1, seq length 2500]\tLoss: 3.695661\n",
      "41050it [1:18:38,  8.72it/s]Train epoch: 2 [batch #41050, batch_size 1, seq length 2500]\tLoss: 3.758205\n",
      "41075it [1:18:41,  8.47it/s]Train epoch: 2 [batch #41075, batch_size 1, seq length 2500]\tLoss: 3.395347\n",
      "41100it [1:18:44,  8.75it/s]Train epoch: 2 [batch #41100, batch_size 1, seq length 2500]\tLoss: 4.008261\n",
      "41125it [1:18:46,  8.76it/s]Train epoch: 2 [batch #41125, batch_size 1, seq length 2500]\tLoss: 3.741912\n",
      "41150it [1:18:49,  8.72it/s]Train epoch: 2 [batch #41150, batch_size 1, seq length 2500]\tLoss: 3.720262\n",
      "41175it [1:18:52,  8.60it/s]Train epoch: 2 [batch #41175, batch_size 1, seq length 2500]\tLoss: 3.937998\n",
      "41200it [1:18:55,  8.66it/s]Train epoch: 2 [batch #41200, batch_size 1, seq length 2500]\tLoss: 3.589716\n",
      "41225it [1:18:58,  8.65it/s]Train epoch: 2 [batch #41225, batch_size 1, seq length 2500]\tLoss: 3.682384\n",
      "41250it [1:19:01,  8.69it/s]Train epoch: 2 [batch #41250, batch_size 1, seq length 2500]\tLoss: 3.498273\n",
      "41275it [1:19:04,  8.74it/s]Train epoch: 2 [batch #41275, batch_size 1, seq length 2500]\tLoss: 3.869386\n",
      "41300it [1:19:07,  8.74it/s]Train epoch: 2 [batch #41300, batch_size 1, seq length 2500]\tLoss: 4.076518\n",
      "41325it [1:19:10,  8.73it/s]Train epoch: 2 [batch #41325, batch_size 1, seq length 2500]\tLoss: 3.553206\n",
      "41350it [1:19:12,  8.73it/s]Train epoch: 2 [batch #41350, batch_size 1, seq length 2500]\tLoss: 3.919935\n",
      "41375it [1:19:15,  8.66it/s]Train epoch: 2 [batch #41375, batch_size 1, seq length 2500]\tLoss: 4.038210\n",
      "41400it [1:19:18,  8.69it/s]Train epoch: 2 [batch #41400, batch_size 1, seq length 2500]\tLoss: 3.979037\n",
      "41425it [1:19:21,  8.56it/s]Train epoch: 2 [batch #41425, batch_size 1, seq length 2500]\tLoss: 3.327990\n",
      "41450it [1:19:24,  8.58it/s]Train epoch: 2 [batch #41450, batch_size 1, seq length 2500]\tLoss: 3.479158\n",
      "41475it [1:19:27,  8.73it/s]Train epoch: 2 [batch #41475, batch_size 1, seq length 2500]\tLoss: 3.805856\n",
      "41500it [1:19:30,  8.73it/s]Train epoch: 2 [batch #41500, batch_size 1, seq length 2500]\tLoss: 4.149789\n",
      "41525it [1:19:33,  8.77it/s]Train epoch: 2 [batch #41525, batch_size 1, seq length 2500]\tLoss: 3.457301\n",
      "41550it [1:19:35,  8.62it/s]Train epoch: 2 [batch #41550, batch_size 1, seq length 2500]\tLoss: 3.643086\n",
      "41575it [1:19:38,  8.68it/s]Train epoch: 2 [batch #41575, batch_size 1, seq length 2500]\tLoss: 3.753727\n",
      "41600it [1:19:41,  8.69it/s]Train epoch: 2 [batch #41600, batch_size 1, seq length 2500]\tLoss: 3.770965\n",
      "41625it [1:19:44,  8.75it/s]Train epoch: 2 [batch #41625, batch_size 1, seq length 2500]\tLoss: 3.465784\n",
      "41650it [1:19:47,  8.73it/s]Train epoch: 2 [batch #41650, batch_size 1, seq length 2500]\tLoss: 3.511532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41675it [1:19:50,  8.72it/s]Train epoch: 2 [batch #41675, batch_size 1, seq length 2500]\tLoss: 3.783499\n",
      "41700it [1:19:53,  8.75it/s]Train epoch: 2 [batch #41700, batch_size 1, seq length 2500]\tLoss: 3.432263\n",
      "41725it [1:19:55,  8.67it/s]Train epoch: 2 [batch #41725, batch_size 1, seq length 2500]\tLoss: 3.590672\n",
      "41750it [1:19:58,  8.67it/s]Train epoch: 2 [batch #41750, batch_size 1, seq length 2500]\tLoss: 3.752150\n",
      "41775it [1:20:01,  8.73it/s]Train epoch: 2 [batch #41775, batch_size 1, seq length 2500]\tLoss: 3.705088\n",
      "41800it [1:20:04,  8.67it/s]Train epoch: 2 [batch #41800, batch_size 1, seq length 2500]\tLoss: 3.465673\n",
      "41825it [1:20:07,  8.73it/s]Train epoch: 2 [batch #41825, batch_size 1, seq length 2500]\tLoss: 3.714503\n",
      "41850it [1:20:10,  8.69it/s]Train epoch: 2 [batch #41850, batch_size 1, seq length 2500]\tLoss: 3.477883\n",
      "41875it [1:20:13,  8.73it/s]Train epoch: 2 [batch #41875, batch_size 1, seq length 2500]\tLoss: 3.754886\n",
      "41900it [1:20:16,  8.70it/s]Train epoch: 2 [batch #41900, batch_size 1, seq length 2500]\tLoss: 3.571570\n",
      "41925it [1:20:18,  8.66it/s]Train epoch: 2 [batch #41925, batch_size 1, seq length 2500]\tLoss: 3.532924\n",
      "41950it [1:20:21,  8.65it/s]Train epoch: 2 [batch #41950, batch_size 1, seq length 2500]\tLoss: 3.703508\n",
      "41975it [1:20:24,  8.71it/s]Train epoch: 2 [batch #41975, batch_size 1, seq length 2500]\tLoss: 3.413971\n",
      "42000it [1:20:27,  8.72it/s]Train epoch: 2 [batch #42000, batch_size 1, seq length 2500]\tLoss: 4.034485\n",
      "42025it [1:20:30,  8.71it/s]Train epoch: 2 [batch #42025, batch_size 1, seq length 2500]\tLoss: 3.635795\n",
      "42050it [1:20:33,  8.69it/s]Train epoch: 2 [batch #42050, batch_size 1, seq length 2500]\tLoss: 3.792120\n",
      "42075it [1:20:36,  8.69it/s]Train epoch: 2 [batch #42075, batch_size 1, seq length 2500]\tLoss: 3.427131\n",
      "42100it [1:20:39,  8.74it/s]Train epoch: 2 [batch #42100, batch_size 1, seq length 2500]\tLoss: 3.749095\n",
      "42125it [1:20:41,  8.70it/s]Train epoch: 2 [batch #42125, batch_size 1, seq length 2500]\tLoss: 3.518099\n",
      "42150it [1:20:44,  8.66it/s]Train epoch: 2 [batch #42150, batch_size 1, seq length 2500]\tLoss: 3.419384\n",
      "42175it [1:20:47,  8.74it/s]Train epoch: 2 [batch #42175, batch_size 1, seq length 2500]\tLoss: 3.480878\n",
      "42200it [1:20:50,  8.56it/s]Train epoch: 2 [batch #42200, batch_size 1, seq length 2500]\tLoss: 3.696016\n",
      "42225it [1:20:53,  8.74it/s]Train epoch: 2 [batch #42225, batch_size 1, seq length 2500]\tLoss: 3.806641\n",
      "42250it [1:20:56,  8.70it/s]Train epoch: 2 [batch #42250, batch_size 1, seq length 2500]\tLoss: 3.776970\n",
      "42275it [1:20:59,  8.69it/s]Train epoch: 2 [batch #42275, batch_size 1, seq length 2500]\tLoss: 3.213811\n",
      "42300it [1:21:02,  8.61it/s]Train epoch: 2 [batch #42300, batch_size 1, seq length 2500]\tLoss: 3.436487\n",
      "42325it [1:21:05,  8.52it/s]Train epoch: 2 [batch #42325, batch_size 1, seq length 2500]\tLoss: 3.801881\n",
      "42350it [1:21:07,  8.70it/s]Train epoch: 2 [batch #42350, batch_size 1, seq length 2500]\tLoss: 3.660874\n",
      "42375it [1:21:10,  8.68it/s]Train epoch: 2 [batch #42375, batch_size 1, seq length 2500]\tLoss: 3.730891\n",
      "42400it [1:21:13,  8.67it/s]Train epoch: 2 [batch #42400, batch_size 1, seq length 2500]\tLoss: 3.503378\n",
      "42425it [1:21:16,  8.61it/s]Train epoch: 2 [batch #42425, batch_size 1, seq length 2500]\tLoss: 3.812586\n",
      "42450it [1:21:19,  8.70it/s]Train epoch: 2 [batch #42450, batch_size 1, seq length 2500]\tLoss: 3.867095\n",
      "42475it [1:21:22,  8.63it/s]Train epoch: 2 [batch #42475, batch_size 1, seq length 2500]\tLoss: 3.258316\n",
      "42500it [1:21:25,  8.69it/s]Train epoch: 2 [batch #42500, batch_size 1, seq length 2500]\tLoss: 3.997994\n",
      "42525it [1:21:28,  8.75it/s]Train epoch: 2 [batch #42525, batch_size 1, seq length 2500]\tLoss: 3.727697\n",
      "42550it [1:21:30,  8.73it/s]Train epoch: 2 [batch #42550, batch_size 1, seq length 2500]\tLoss: 3.627877\n",
      "42575it [1:21:33,  8.64it/s]Train epoch: 2 [batch #42575, batch_size 1, seq length 2500]\tLoss: 3.587201\n",
      "42600it [1:21:36,  8.67it/s]Train epoch: 2 [batch #42600, batch_size 1, seq length 2500]\tLoss: 3.844685\n",
      "42625it [1:21:39,  8.77it/s]Train epoch: 2 [batch #42625, batch_size 1, seq length 2500]\tLoss: 3.708707\n",
      "42650it [1:21:42,  8.72it/s]Train epoch: 2 [batch #42650, batch_size 1, seq length 2500]\tLoss: 3.461285\n",
      "42675it [1:21:45,  8.63it/s]Train epoch: 2 [batch #42675, batch_size 1, seq length 2500]\tLoss: 3.692024\n",
      "42700it [1:21:48,  8.72it/s]Train epoch: 2 [batch #42700, batch_size 1, seq length 2500]\tLoss: 3.294783\n",
      "42725it [1:21:50,  8.66it/s]Train epoch: 2 [batch #42725, batch_size 1, seq length 2500]\tLoss: 3.663529\n",
      "42750it [1:21:53,  8.71it/s]Train epoch: 2 [batch #42750, batch_size 1, seq length 2500]\tLoss: 3.776972\n",
      "42775it [1:21:56,  8.73it/s]Train epoch: 2 [batch #42775, batch_size 1, seq length 2500]\tLoss: 3.885428\n",
      "42800it [1:21:59,  8.66it/s]Train epoch: 2 [batch #42800, batch_size 1, seq length 2500]\tLoss: 3.581464\n",
      "42825it [1:22:02,  8.62it/s]Train epoch: 2 [batch #42825, batch_size 1, seq length 2500]\tLoss: 3.530695\n",
      "42850it [1:22:05,  8.64it/s]Train epoch: 2 [batch #42850, batch_size 1, seq length 2500]\tLoss: 3.436792\n",
      "42875it [1:22:08,  8.73it/s]Train epoch: 2 [batch #42875, batch_size 1, seq length 2500]\tLoss: 3.696069\n",
      "42900it [1:22:11,  8.64it/s]Train epoch: 2 [batch #42900, batch_size 1, seq length 2500]\tLoss: 3.711438\n",
      "42925it [1:22:13,  8.72it/s]Train epoch: 2 [batch #42925, batch_size 1, seq length 2500]\tLoss: 4.140413\n",
      "42950it [1:22:16,  8.73it/s]Train epoch: 2 [batch #42950, batch_size 1, seq length 2500]\tLoss: 3.575697\n",
      "42975it [1:22:19,  8.71it/s]Train epoch: 2 [batch #42975, batch_size 1, seq length 2500]\tLoss: 3.694495\n",
      "43000it [1:22:22,  8.71it/s]Train epoch: 2 [batch #43000, batch_size 1, seq length 2500]\tLoss: 3.551650\n",
      "43025it [1:22:25,  8.67it/s]Train epoch: 2 [batch #43025, batch_size 1, seq length 2500]\tLoss: 3.893004\n",
      "43050it [1:22:28,  8.72it/s]Train epoch: 2 [batch #43050, batch_size 1, seq length 2500]\tLoss: 3.539517\n",
      "43075it [1:22:31,  8.69it/s]Train epoch: 2 [batch #43075, batch_size 1, seq length 2500]\tLoss: 3.547459\n",
      "43100it [1:22:34,  8.69it/s]Train epoch: 2 [batch #43100, batch_size 1, seq length 2500]\tLoss: 3.724424\n",
      "43125it [1:22:36,  8.72it/s]Train epoch: 2 [batch #43125, batch_size 1, seq length 2500]\tLoss: 3.725421\n",
      "43150it [1:22:39,  8.69it/s]Train epoch: 2 [batch #43150, batch_size 1, seq length 2500]\tLoss: 3.672720\n",
      "43175it [1:22:42,  8.69it/s]Train epoch: 2 [batch #43175, batch_size 1, seq length 2500]\tLoss: 3.731375\n",
      "43200it [1:22:45,  8.74it/s]Train epoch: 2 [batch #43200, batch_size 1, seq length 2500]\tLoss: 3.717251\n",
      "43225it [1:22:48,  8.63it/s]Train epoch: 2 [batch #43225, batch_size 1, seq length 2500]\tLoss: 3.645324\n",
      "43250it [1:22:51,  8.46it/s]Train epoch: 2 [batch #43250, batch_size 1, seq length 2500]\tLoss: 3.601370\n",
      "43275it [1:22:54,  8.66it/s]Train epoch: 2 [batch #43275, batch_size 1, seq length 2500]\tLoss: 3.643206\n",
      "43300it [1:22:57,  8.64it/s]Train epoch: 2 [batch #43300, batch_size 1, seq length 2500]\tLoss: 3.914912\n",
      "43325it [1:22:59,  8.70it/s]Train epoch: 2 [batch #43325, batch_size 1, seq length 2500]\tLoss: 3.500138\n",
      "43350it [1:23:02,  8.73it/s]Train epoch: 2 [batch #43350, batch_size 1, seq length 2500]\tLoss: 3.490210\n",
      "43375it [1:23:05,  8.68it/s]Train epoch: 2 [batch #43375, batch_size 1, seq length 2500]\tLoss: 3.659112\n",
      "43400it [1:23:08,  8.69it/s]Train epoch: 2 [batch #43400, batch_size 1, seq length 2500]\tLoss: 3.528635\n",
      "43425it [1:23:11,  8.66it/s]Train epoch: 2 [batch #43425, batch_size 1, seq length 2500]\tLoss: 3.839655\n",
      "43450it [1:23:14,  8.71it/s]Train epoch: 2 [batch #43450, batch_size 1, seq length 2500]\tLoss: 3.679220\n",
      "43475it [1:23:17,  8.70it/s]Train epoch: 2 [batch #43475, batch_size 1, seq length 2500]\tLoss: 3.544466\n",
      "43500it [1:23:20,  8.74it/s]Train epoch: 2 [batch #43500, batch_size 1, seq length 2500]\tLoss: 3.386167\n",
      "43525it [1:23:22,  8.73it/s]Train epoch: 2 [batch #43525, batch_size 1, seq length 2500]\tLoss: 3.744657\n",
      "43550it [1:23:25,  8.68it/s]Train epoch: 2 [batch #43550, batch_size 1, seq length 2500]\tLoss: 3.912810\n",
      "43575it [1:23:28,  8.72it/s]Train epoch: 2 [batch #43575, batch_size 1, seq length 2500]\tLoss: 3.691243\n",
      "43600it [1:23:31,  8.73it/s]Train epoch: 2 [batch #43600, batch_size 1, seq length 2500]\tLoss: 3.602645\n",
      "43625it [1:23:34,  8.66it/s]Train epoch: 2 [batch #43625, batch_size 1, seq length 2500]\tLoss: 3.567582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43650it [1:23:37,  8.71it/s]Train epoch: 2 [batch #43650, batch_size 1, seq length 2500]\tLoss: 3.137499\n",
      "43675it [1:23:40,  8.74it/s]Train epoch: 2 [batch #43675, batch_size 1, seq length 2500]\tLoss: 3.937801\n",
      "43700it [1:23:43,  8.69it/s]Train epoch: 2 [batch #43700, batch_size 1, seq length 2500]\tLoss: 4.040718\n",
      "43725it [1:23:45,  8.69it/s]Train epoch: 2 [batch #43725, batch_size 1, seq length 2500]\tLoss: 4.009103\n",
      "43750it [1:23:48,  8.71it/s]Train epoch: 2 [batch #43750, batch_size 1, seq length 2500]\tLoss: 3.541886\n",
      "43775it [1:23:51,  8.64it/s]Train epoch: 2 [batch #43775, batch_size 1, seq length 2500]\tLoss: 3.695303\n",
      "43800it [1:23:54,  8.69it/s]Train epoch: 2 [batch #43800, batch_size 1, seq length 2500]\tLoss: 3.564059\n",
      "43825it [1:23:57,  8.75it/s]Train epoch: 2 [batch #43825, batch_size 1, seq length 2500]\tLoss: 3.748502\n",
      "43850it [1:24:00,  8.68it/s]Train epoch: 2 [batch #43850, batch_size 1, seq length 2500]\tLoss: 3.633777\n",
      "43875it [1:24:03,  8.75it/s]Train epoch: 2 [batch #43875, batch_size 1, seq length 2500]\tLoss: 3.675041\n",
      "43900it [1:24:06,  8.73it/s]Train epoch: 2 [batch #43900, batch_size 1, seq length 2500]\tLoss: 3.858125\n",
      "43925it [1:24:08,  8.69it/s]Train epoch: 2 [batch #43925, batch_size 1, seq length 2500]\tLoss: 3.752348\n",
      "43950it [1:24:11,  8.73it/s]Train epoch: 2 [batch #43950, batch_size 1, seq length 2500]\tLoss: 3.442481\n",
      "43975it [1:24:14,  8.72it/s]Train epoch: 2 [batch #43975, batch_size 1, seq length 2500]\tLoss: 3.869565\n",
      "44000it [1:24:17,  8.73it/s]Train epoch: 2 [batch #44000, batch_size 1, seq length 2500]\tLoss: 4.039410\n",
      "44025it [1:24:20,  8.66it/s]Train epoch: 2 [batch #44025, batch_size 1, seq length 2500]\tLoss: 3.805559\n",
      "44050it [1:24:23,  8.69it/s]Train epoch: 2 [batch #44050, batch_size 1, seq length 2500]\tLoss: 3.960126\n",
      "44075it [1:24:26,  8.50it/s]Train epoch: 2 [batch #44075, batch_size 1, seq length 2500]\tLoss: 3.759705\n",
      "44100it [1:24:29,  8.65it/s]Train epoch: 2 [batch #44100, batch_size 1, seq length 2500]\tLoss: 3.189264\n",
      "44125it [1:24:31,  8.70it/s]Train epoch: 2 [batch #44125, batch_size 1, seq length 2500]\tLoss: 3.561370\n",
      "44150it [1:24:34,  8.68it/s]Train epoch: 2 [batch #44150, batch_size 1, seq length 2500]\tLoss: 3.527493\n",
      "44175it [1:24:37,  8.70it/s]Train epoch: 2 [batch #44175, batch_size 1, seq length 2500]\tLoss: 3.559024\n",
      "44200it [1:24:40,  8.69it/s]Train epoch: 2 [batch #44200, batch_size 1, seq length 2500]\tLoss: 3.920704\n",
      "44225it [1:24:43,  8.70it/s]Train epoch: 2 [batch #44225, batch_size 1, seq length 2500]\tLoss: 3.568757\n",
      "44250it [1:24:46,  8.71it/s]Train epoch: 2 [batch #44250, batch_size 1, seq length 2500]\tLoss: 3.711069\n",
      "44275it [1:24:49,  8.57it/s]Train epoch: 2 [batch #44275, batch_size 1, seq length 2500]\tLoss: 3.229022\n",
      "44300it [1:24:52,  8.72it/s]Train epoch: 2 [batch #44300, batch_size 1, seq length 2500]\tLoss: 3.535786\n",
      "44325it [1:24:54,  8.64it/s]Train epoch: 2 [batch #44325, batch_size 1, seq length 2500]\tLoss: 3.641376\n",
      "44350it [1:24:57,  8.68it/s]Train epoch: 2 [batch #44350, batch_size 1, seq length 2500]\tLoss: 3.830068\n",
      "44375it [1:25:00,  8.67it/s]Train epoch: 2 [batch #44375, batch_size 1, seq length 2500]\tLoss: 3.618422\n",
      "44400it [1:25:03,  8.68it/s]Train epoch: 2 [batch #44400, batch_size 1, seq length 2500]\tLoss: 3.120701\n",
      "44425it [1:25:06,  8.72it/s]Train epoch: 2 [batch #44425, batch_size 1, seq length 2500]\tLoss: 3.586655\n",
      "44450it [1:25:09,  8.67it/s]Train epoch: 2 [batch #44450, batch_size 1, seq length 2500]\tLoss: 3.900403\n",
      "44475it [1:25:12,  8.63it/s]Train epoch: 2 [batch #44475, batch_size 1, seq length 2500]\tLoss: 3.781254\n",
      "44500it [1:25:15,  8.69it/s]Train epoch: 2 [batch #44500, batch_size 1, seq length 2500]\tLoss: 3.736275\n",
      "44525it [1:25:17,  8.69it/s]Train epoch: 2 [batch #44525, batch_size 1, seq length 2500]\tLoss: 3.330062\n",
      "44550it [1:25:20,  8.74it/s]Train epoch: 2 [batch #44550, batch_size 1, seq length 2500]\tLoss: 3.525623\n",
      "44575it [1:25:23,  8.71it/s]Train epoch: 2 [batch #44575, batch_size 1, seq length 2500]\tLoss: 3.171788\n",
      "44600it [1:25:26,  8.61it/s]Train epoch: 2 [batch #44600, batch_size 1, seq length 2500]\tLoss: 3.796508\n",
      "44625it [1:25:29,  8.48it/s]Train epoch: 2 [batch #44625, batch_size 1, seq length 2500]\tLoss: 3.414944\n",
      "44650it [1:25:32,  8.65it/s]Train epoch: 2 [batch #44650, batch_size 1, seq length 2500]\tLoss: 3.707515\n",
      "44675it [1:25:35,  8.73it/s]Train epoch: 2 [batch #44675, batch_size 1, seq length 2500]\tLoss: 3.738223\n",
      "44700it [1:25:38,  8.61it/s]Train epoch: 2 [batch #44700, batch_size 1, seq length 2500]\tLoss: 4.225709\n",
      "44725it [1:25:41,  8.76it/s]Train epoch: 2 [batch #44725, batch_size 1, seq length 2500]\tLoss: 3.557095\n",
      "44750it [1:25:43,  8.57it/s]Train epoch: 2 [batch #44750, batch_size 1, seq length 2500]\tLoss: 3.557629\n",
      "44775it [1:25:46,  8.68it/s]Train epoch: 2 [batch #44775, batch_size 1, seq length 2500]\tLoss: 3.639033\n",
      "44800it [1:25:49,  8.69it/s]Train epoch: 2 [batch #44800, batch_size 1, seq length 2500]\tLoss: 3.418384\n",
      "44825it [1:25:52,  8.68it/s]Train epoch: 2 [batch #44825, batch_size 1, seq length 2500]\tLoss: 3.580597\n",
      "44850it [1:25:55,  8.72it/s]Train epoch: 2 [batch #44850, batch_size 1, seq length 2500]\tLoss: 3.432971\n",
      "44875it [1:25:58,  8.66it/s]Train epoch: 2 [batch #44875, batch_size 1, seq length 2500]\tLoss: 3.739644\n",
      "44900it [1:26:01,  8.71it/s]Train epoch: 2 [batch #44900, batch_size 1, seq length 2500]\tLoss: 3.376831\n",
      "44925it [1:26:04,  8.67it/s]Train epoch: 2 [batch #44925, batch_size 1, seq length 2500]\tLoss: 3.876747\n",
      "44950it [1:26:06,  8.69it/s]Train epoch: 2 [batch #44950, batch_size 1, seq length 2500]\tLoss: 3.701806\n",
      "44975it [1:26:09,  8.72it/s]Train epoch: 2 [batch #44975, batch_size 1, seq length 2500]\tLoss: 3.591772\n",
      "45000it [1:26:12,  8.69it/s]Train epoch: 2 [batch #45000, batch_size 1, seq length 2500]\tLoss: 3.687119\n",
      "45025it [1:26:15,  8.59it/s]Train epoch: 2 [batch #45025, batch_size 1, seq length 2500]\tLoss: 3.472574\n",
      "45050it [1:26:18,  8.65it/s]Train epoch: 2 [batch #45050, batch_size 1, seq length 2500]\tLoss: 3.904231\n",
      "45075it [1:26:21,  8.69it/s]Train epoch: 2 [batch #45075, batch_size 1, seq length 2500]\tLoss: 3.462483\n",
      "45100it [1:26:24,  8.68it/s]Train epoch: 2 [batch #45100, batch_size 1, seq length 2500]\tLoss: 3.922907\n",
      "45125it [1:26:27,  8.73it/s]Train epoch: 2 [batch #45125, batch_size 1, seq length 2500]\tLoss: 3.840554\n",
      "45150it [1:26:30,  8.74it/s]Train epoch: 2 [batch #45150, batch_size 1, seq length 2500]\tLoss: 3.466570\n",
      "45175it [1:26:32,  8.66it/s]Train epoch: 2 [batch #45175, batch_size 1, seq length 2500]\tLoss: 3.535698\n",
      "45200it [1:26:35,  8.74it/s]Train epoch: 2 [batch #45200, batch_size 1, seq length 2500]\tLoss: 3.715651\n",
      "45225it [1:26:38,  8.69it/s]Train epoch: 2 [batch #45225, batch_size 1, seq length 2500]\tLoss: 3.657546\n",
      "45250it [1:26:41,  8.67it/s]Train epoch: 2 [batch #45250, batch_size 1, seq length 2500]\tLoss: 3.612273\n",
      "45275it [1:26:44,  8.61it/s]Train epoch: 2 [batch #45275, batch_size 1, seq length 2500]\tLoss: 3.514734\n",
      "45300it [1:26:47,  8.70it/s]Train epoch: 2 [batch #45300, batch_size 1, seq length 2500]\tLoss: 3.395936\n",
      "45325it [1:26:50,  8.63it/s]Train epoch: 2 [batch #45325, batch_size 1, seq length 2500]\tLoss: 3.533186\n",
      "45350it [1:26:53,  8.57it/s]Train epoch: 2 [batch #45350, batch_size 1, seq length 2500]\tLoss: 3.507656\n",
      "45375it [1:26:55,  8.65it/s]Train epoch: 2 [batch #45375, batch_size 1, seq length 2500]\tLoss: 3.561518\n",
      "45400it [1:26:58,  8.57it/s]Train epoch: 2 [batch #45400, batch_size 1, seq length 2500]\tLoss: 3.756935\n",
      "45425it [1:27:01,  8.67it/s]Train epoch: 2 [batch #45425, batch_size 1, seq length 2500]\tLoss: 3.752007\n",
      "45450it [1:27:04,  8.75it/s]Train epoch: 2 [batch #45450, batch_size 1, seq length 2500]\tLoss: 3.886127\n",
      "45475it [1:27:07,  8.64it/s]Train epoch: 2 [batch #45475, batch_size 1, seq length 2500]\tLoss: 3.735554\n",
      "45500it [1:27:10,  8.70it/s]Train epoch: 2 [batch #45500, batch_size 1, seq length 2500]\tLoss: 3.601147\n",
      "45525it [1:27:13,  8.68it/s]Train epoch: 2 [batch #45525, batch_size 1, seq length 2500]\tLoss: 3.979685\n",
      "45550it [1:27:16,  8.69it/s]Train epoch: 2 [batch #45550, batch_size 1, seq length 2500]\tLoss: 3.741487\n",
      "45575it [1:27:19,  8.66it/s]Train epoch: 2 [batch #45575, batch_size 1, seq length 2500]\tLoss: 3.556671\n",
      "45600it [1:27:21,  8.65it/s]Train epoch: 2 [batch #45600, batch_size 1, seq length 2500]\tLoss: 3.555614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45625it [1:27:24,  8.66it/s]Train epoch: 2 [batch #45625, batch_size 1, seq length 2500]\tLoss: 3.584618\n",
      "45650it [1:27:27,  8.66it/s]Train epoch: 2 [batch #45650, batch_size 1, seq length 2500]\tLoss: 3.472336\n",
      "45675it [1:27:30,  8.75it/s]Train epoch: 2 [batch #45675, batch_size 1, seq length 2500]\tLoss: 3.825874\n",
      "45700it [1:27:33,  8.55it/s]Train epoch: 2 [batch #45700, batch_size 1, seq length 2500]\tLoss: 3.351336\n",
      "45725it [1:27:36,  8.72it/s]Train epoch: 2 [batch #45725, batch_size 1, seq length 2500]\tLoss: 3.570833\n",
      "45750it [1:27:39,  8.70it/s]Train epoch: 2 [batch #45750, batch_size 1, seq length 2500]\tLoss: 3.256263\n",
      "45775it [1:27:42,  8.70it/s]Train epoch: 2 [batch #45775, batch_size 1, seq length 2500]\tLoss: 3.501242\n",
      "45800it [1:27:44,  8.66it/s]Train epoch: 2 [batch #45800, batch_size 1, seq length 2500]\tLoss: 3.657807\n",
      "45825it [1:27:47,  8.68it/s]Train epoch: 2 [batch #45825, batch_size 1, seq length 2500]\tLoss: 3.813671\n",
      "45850it [1:27:50,  8.74it/s]Train epoch: 2 [batch #45850, batch_size 1, seq length 2500]\tLoss: 3.437587\n",
      "45875it [1:27:53,  8.70it/s]Train epoch: 2 [batch #45875, batch_size 1, seq length 2500]\tLoss: 3.650325\n",
      "45900it [1:27:56,  8.72it/s]Train epoch: 2 [batch #45900, batch_size 1, seq length 2500]\tLoss: 3.595958\n",
      "45925it [1:27:59,  8.68it/s]Train epoch: 2 [batch #45925, batch_size 1, seq length 2500]\tLoss: 3.715632\n",
      "45950it [1:28:02,  8.65it/s]Train epoch: 2 [batch #45950, batch_size 1, seq length 2500]\tLoss: 3.670577\n",
      "45975it [1:28:05,  8.70it/s]Train epoch: 2 [batch #45975, batch_size 1, seq length 2500]\tLoss: 3.788420\n",
      "46000it [1:28:08,  8.68it/s]Train epoch: 2 [batch #46000, batch_size 1, seq length 2500]\tLoss: 3.775805\n",
      "46025it [1:28:10,  8.69it/s]Train epoch: 2 [batch #46025, batch_size 1, seq length 2500]\tLoss: 3.684255\n",
      "46050it [1:28:13,  8.64it/s]Train epoch: 2 [batch #46050, batch_size 1, seq length 2500]\tLoss: 3.610917\n",
      "46075it [1:28:16,  8.70it/s]Train epoch: 2 [batch #46075, batch_size 1, seq length 2500]\tLoss: 3.519834\n",
      "46100it [1:28:19,  8.68it/s]Train epoch: 2 [batch #46100, batch_size 1, seq length 2500]\tLoss: 3.628948\n",
      "46125it [1:28:22,  8.52it/s]Train epoch: 2 [batch #46125, batch_size 1, seq length 2500]\tLoss: 3.671214\n",
      "46150it [1:28:25,  8.60it/s]Train epoch: 2 [batch #46150, batch_size 1, seq length 2500]\tLoss: 3.702954\n",
      "46175it [1:28:28,  8.68it/s]Train epoch: 2 [batch #46175, batch_size 1, seq length 2500]\tLoss: 3.670357\n",
      "46200it [1:28:31,  8.69it/s]Train epoch: 2 [batch #46200, batch_size 1, seq length 2500]\tLoss: 3.907242\n",
      "46225it [1:28:34,  8.70it/s]Train epoch: 2 [batch #46225, batch_size 1, seq length 2500]\tLoss: 3.983586\n",
      "46250it [1:28:37,  8.63it/s]Train epoch: 2 [batch #46250, batch_size 1, seq length 2500]\tLoss: 3.536263\n",
      "46275it [1:28:39,  8.70it/s]Train epoch: 2 [batch #46275, batch_size 1, seq length 2500]\tLoss: 3.743735\n",
      "46300it [1:28:42,  8.61it/s]Train epoch: 2 [batch #46300, batch_size 1, seq length 2500]\tLoss: 3.755624\n",
      "46325it [1:28:45,  8.67it/s]Train epoch: 2 [batch #46325, batch_size 1, seq length 2500]\tLoss: 3.174613\n",
      "46350it [1:28:48,  8.56it/s]Train epoch: 2 [batch #46350, batch_size 1, seq length 2500]\tLoss: 3.520124\n",
      "46375it [1:28:51,  8.41it/s]Train epoch: 2 [batch #46375, batch_size 1, seq length 2500]\tLoss: 3.463618\n",
      "46400it [1:28:54,  8.68it/s]Train epoch: 2 [batch #46400, batch_size 1, seq length 2500]\tLoss: 3.440145\n",
      "46425it [1:28:57,  8.70it/s]Train epoch: 2 [batch #46425, batch_size 1, seq length 2500]\tLoss: 3.927663\n",
      "46450it [1:29:00,  8.64it/s]Train epoch: 2 [batch #46450, batch_size 1, seq length 2500]\tLoss: 3.651742\n",
      "46475it [1:29:03,  8.58it/s]Train epoch: 2 [batch #46475, batch_size 1, seq length 2500]\tLoss: 3.673972\n",
      "46500it [1:29:05,  8.68it/s]Train epoch: 2 [batch #46500, batch_size 1, seq length 2500]\tLoss: 3.794508\n",
      "46525it [1:29:08,  8.66it/s]Train epoch: 2 [batch #46525, batch_size 1, seq length 2500]\tLoss: 3.695971\n",
      "46550it [1:29:11,  8.71it/s]Train epoch: 2 [batch #46550, batch_size 1, seq length 2500]\tLoss: 3.979623\n",
      "46575it [1:29:14,  8.67it/s]Train epoch: 2 [batch #46575, batch_size 1, seq length 2500]\tLoss: 3.671755\n",
      "46600it [1:29:17,  8.65it/s]Train epoch: 2 [batch #46600, batch_size 1, seq length 2500]\tLoss: 3.786889\n",
      "46625it [1:29:20,  8.65it/s]Train epoch: 2 [batch #46625, batch_size 1, seq length 2500]\tLoss: 3.547360\n",
      "46650it [1:29:23,  8.65it/s]Train epoch: 2 [batch #46650, batch_size 1, seq length 2500]\tLoss: 3.643604\n",
      "46675it [1:29:26,  8.64it/s]Train epoch: 2 [batch #46675, batch_size 1, seq length 2500]\tLoss: 3.767076\n",
      "46700it [1:29:29,  8.66it/s]Train epoch: 2 [batch #46700, batch_size 1, seq length 2500]\tLoss: 3.608052\n",
      "46725it [1:29:31,  8.60it/s]Train epoch: 2 [batch #46725, batch_size 1, seq length 2500]\tLoss: 3.811198\n",
      "46750it [1:29:34,  8.71it/s]Train epoch: 2 [batch #46750, batch_size 1, seq length 2500]\tLoss: 3.820003\n",
      "46775it [1:29:37,  8.68it/s]Train epoch: 2 [batch #46775, batch_size 1, seq length 2500]\tLoss: 3.395364\n",
      "46800it [1:29:40,  8.68it/s]Train epoch: 2 [batch #46800, batch_size 1, seq length 2500]\tLoss: 3.835317\n",
      "46825it [1:29:43,  8.71it/s]Train epoch: 2 [batch #46825, batch_size 1, seq length 2500]\tLoss: 3.652502\n",
      "46850it [1:29:46,  8.66it/s]Train epoch: 2 [batch #46850, batch_size 1, seq length 2500]\tLoss: 3.520609\n",
      "46875it [1:29:49,  8.67it/s]Train epoch: 2 [batch #46875, batch_size 1, seq length 2500]\tLoss: 3.773716\n",
      "46900it [1:29:52,  8.60it/s]Train epoch: 2 [batch #46900, batch_size 1, seq length 2500]\tLoss: 3.410870\n",
      "46925it [1:29:54,  8.72it/s]Train epoch: 2 [batch #46925, batch_size 1, seq length 2500]\tLoss: 3.551297\n",
      "46950it [1:29:57,  8.65it/s]Train epoch: 2 [batch #46950, batch_size 1, seq length 2500]\tLoss: 3.611943\n",
      "46975it [1:30:00,  8.65it/s]Train epoch: 2 [batch #46975, batch_size 1, seq length 2500]\tLoss: 3.799898\n",
      "47000it [1:30:03,  8.63it/s]Train epoch: 2 [batch #47000, batch_size 1, seq length 2500]\tLoss: 3.579901\n",
      "47025it [1:30:06,  8.70it/s]Train epoch: 2 [batch #47025, batch_size 1, seq length 2500]\tLoss: 3.533713\n",
      "47050it [1:30:09,  8.67it/s]Train epoch: 2 [batch #47050, batch_size 1, seq length 2500]\tLoss: 3.298711\n",
      "47075it [1:30:12,  8.74it/s]Train epoch: 2 [batch #47075, batch_size 1, seq length 2500]\tLoss: 3.840094\n",
      "47100it [1:30:15,  8.41it/s]Train epoch: 2 [batch #47100, batch_size 1, seq length 2500]\tLoss: 3.728496\n",
      "47125it [1:30:18,  8.70it/s]Train epoch: 2 [batch #47125, batch_size 1, seq length 2500]\tLoss: 3.739945\n",
      "47150it [1:30:20,  8.68it/s]Train epoch: 2 [batch #47150, batch_size 1, seq length 2500]\tLoss: 3.819935\n",
      "47175it [1:30:23,  8.64it/s]Train epoch: 2 [batch #47175, batch_size 1, seq length 2500]\tLoss: 3.458936\n",
      "47200it [1:30:26,  8.68it/s]Train epoch: 2 [batch #47200, batch_size 1, seq length 2500]\tLoss: 3.600655\n",
      "47225it [1:30:29,  8.74it/s]Train epoch: 2 [batch #47225, batch_size 1, seq length 2500]\tLoss: 3.415599\n",
      "47250it [1:30:32,  8.49it/s]Train epoch: 2 [batch #47250, batch_size 1, seq length 2500]\tLoss: 3.538293\n",
      "47275it [1:30:35,  8.70it/s]Train epoch: 2 [batch #47275, batch_size 1, seq length 2500]\tLoss: 3.631478\n",
      "47300it [1:30:38,  8.72it/s]Train epoch: 2 [batch #47300, batch_size 1, seq length 2500]\tLoss: 3.617923\n",
      "47325it [1:30:41,  8.70it/s]Train epoch: 2 [batch #47325, batch_size 1, seq length 2500]\tLoss: 3.741150\n",
      "47350it [1:30:44,  8.65it/s]Train epoch: 2 [batch #47350, batch_size 1, seq length 2500]\tLoss: 3.514976\n",
      "47375it [1:30:46,  8.68it/s]Train epoch: 2 [batch #47375, batch_size 1, seq length 2500]\tLoss: 3.465011\n",
      "47400it [1:30:49,  8.63it/s]Train epoch: 2 [batch #47400, batch_size 1, seq length 2500]\tLoss: 3.688146\n",
      "47425it [1:30:52,  8.55it/s]Train epoch: 2 [batch #47425, batch_size 1, seq length 2500]\tLoss: 3.715119\n",
      "47450it [1:30:55,  8.74it/s]Train epoch: 2 [batch #47450, batch_size 1, seq length 2500]\tLoss: 3.841395\n",
      "47475it [1:30:58,  8.64it/s]Train epoch: 2 [batch #47475, batch_size 1, seq length 2500]\tLoss: 3.646543\n",
      "47500it [1:31:01,  8.60it/s]Train epoch: 2 [batch #47500, batch_size 1, seq length 2500]\tLoss: 3.975717\n",
      "47525it [1:31:04,  8.72it/s]Train epoch: 2 [batch #47525, batch_size 1, seq length 2500]\tLoss: 3.900266\n",
      "47550it [1:31:07,  8.66it/s]Train epoch: 2 [batch #47550, batch_size 1, seq length 2500]\tLoss: 3.742466\n",
      "47575it [1:31:09,  8.72it/s]Train epoch: 2 [batch #47575, batch_size 1, seq length 2500]\tLoss: 3.760917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47600it [1:31:12,  8.59it/s]Train epoch: 2 [batch #47600, batch_size 1, seq length 2500]\tLoss: 3.372465\n",
      "47625it [1:31:15,  8.68it/s]Train epoch: 2 [batch #47625, batch_size 1, seq length 2500]\tLoss: 3.932456\n",
      "47650it [1:31:18,  8.61it/s]Train epoch: 2 [batch #47650, batch_size 1, seq length 2500]\tLoss: 3.788424\n",
      "47675it [1:31:21,  8.70it/s]Train epoch: 2 [batch #47675, batch_size 1, seq length 2500]\tLoss: 3.479214\n",
      "47700it [1:31:24,  8.58it/s]Train epoch: 2 [batch #47700, batch_size 1, seq length 2500]\tLoss: 3.754094\n",
      "47725it [1:31:27,  8.69it/s]Train epoch: 2 [batch #47725, batch_size 1, seq length 2500]\tLoss: 3.855500\n",
      "47750it [1:31:30,  8.69it/s]Train epoch: 2 [batch #47750, batch_size 1, seq length 2500]\tLoss: 3.572557\n",
      "47775it [1:31:33,  8.62it/s]Train epoch: 2 [batch #47775, batch_size 1, seq length 2500]\tLoss: 3.614751\n",
      "47800it [1:31:35,  8.61it/s]Train epoch: 2 [batch #47800, batch_size 1, seq length 2500]\tLoss: 3.612116\n",
      "47825it [1:31:38,  8.67it/s]Train epoch: 2 [batch #47825, batch_size 1, seq length 2500]\tLoss: 3.775626\n",
      "47850it [1:31:41,  8.63it/s]Train epoch: 2 [batch #47850, batch_size 1, seq length 2500]\tLoss: 3.618254\n",
      "47875it [1:31:44,  8.65it/s]Train epoch: 2 [batch #47875, batch_size 1, seq length 2500]\tLoss: 3.841093\n",
      "47900it [1:31:47,  8.54it/s]Train epoch: 2 [batch #47900, batch_size 1, seq length 2500]\tLoss: 3.608813\n",
      "47925it [1:31:50,  8.76it/s]Train epoch: 2 [batch #47925, batch_size 1, seq length 2500]\tLoss: 3.751296\n",
      "47950it [1:31:53,  8.68it/s]Train epoch: 2 [batch #47950, batch_size 1, seq length 2500]\tLoss: 3.826008\n",
      "47975it [1:31:56,  8.64it/s]Train epoch: 2 [batch #47975, batch_size 1, seq length 2500]\tLoss: 3.482727\n",
      "48000it [1:31:58,  8.69it/s]Train epoch: 2 [batch #48000, batch_size 1, seq length 2500]\tLoss: 3.551612\n",
      "48025it [1:32:01,  8.74it/s]Train epoch: 2 [batch #48025, batch_size 1, seq length 2500]\tLoss: 3.742548\n",
      "48050it [1:32:04,  8.68it/s]Train epoch: 2 [batch #48050, batch_size 1, seq length 2500]\tLoss: 3.425678\n",
      "48075it [1:32:07,  8.71it/s]Train epoch: 2 [batch #48075, batch_size 1, seq length 2500]\tLoss: 3.157091\n",
      "48100it [1:32:10,  8.68it/s]Train epoch: 2 [batch #48100, batch_size 1, seq length 2500]\tLoss: 3.396471\n",
      "48125it [1:32:13,  8.65it/s]Train epoch: 2 [batch #48125, batch_size 1, seq length 2500]\tLoss: 3.372371\n",
      "48150it [1:32:16,  8.68it/s]Train epoch: 2 [batch #48150, batch_size 1, seq length 2500]\tLoss: 3.513072\n",
      "48175it [1:32:19,  8.69it/s]Train epoch: 2 [batch #48175, batch_size 1, seq length 2500]\tLoss: 3.429121\n",
      "48200it [1:32:21,  8.65it/s]Train epoch: 2 [batch #48200, batch_size 1, seq length 2500]\tLoss: 3.589804\n",
      "48225it [1:32:24,  8.72it/s]Train epoch: 2 [batch #48225, batch_size 1, seq length 2500]\tLoss: 3.687116\n",
      "48250it [1:32:27,  8.69it/s]Train epoch: 2 [batch #48250, batch_size 1, seq length 2500]\tLoss: 3.644739\n",
      "48275it [1:32:30,  8.73it/s]Train epoch: 2 [batch #48275, batch_size 1, seq length 2500]\tLoss: 3.441556\n",
      "48300it [1:32:33,  8.71it/s]Train epoch: 2 [batch #48300, batch_size 1, seq length 2500]\tLoss: 3.677988\n",
      "48325it [1:32:36,  8.66it/s]Train epoch: 2 [batch #48325, batch_size 1, seq length 2500]\tLoss: 3.641335\n",
      "48350it [1:32:39,  8.56it/s]Train epoch: 2 [batch #48350, batch_size 1, seq length 2500]\tLoss: 3.756832\n",
      "48375it [1:32:42,  8.72it/s]Train epoch: 2 [batch #48375, batch_size 1, seq length 2500]\tLoss: 3.545760\n",
      "48400it [1:32:45,  8.67it/s]Train epoch: 2 [batch #48400, batch_size 1, seq length 2500]\tLoss: 3.599047\n",
      "48425it [1:32:47,  8.63it/s]Train epoch: 2 [batch #48425, batch_size 1, seq length 2500]\tLoss: 3.672381\n",
      "48450it [1:32:50,  8.69it/s]Train epoch: 2 [batch #48450, batch_size 1, seq length 2500]\tLoss: 3.844392\n",
      "48475it [1:32:53,  8.69it/s]Train epoch: 2 [batch #48475, batch_size 1, seq length 2500]\tLoss: 3.735986\n",
      "48500it [1:32:56,  8.71it/s]Train epoch: 2 [batch #48500, batch_size 1, seq length 2500]\tLoss: 3.587468\n",
      "48525it [1:32:59,  8.48it/s]Train epoch: 2 [batch #48525, batch_size 1, seq length 2500]\tLoss: 3.501307\n",
      "48550it [1:33:02,  8.65it/s]Train epoch: 2 [batch #48550, batch_size 1, seq length 2500]\tLoss: 3.617140\n",
      "48575it [1:33:05,  8.74it/s]Train epoch: 2 [batch #48575, batch_size 1, seq length 2500]\tLoss: 3.766588\n",
      "48600it [1:33:08,  8.69it/s]Train epoch: 2 [batch #48600, batch_size 1, seq length 2500]\tLoss: 3.669342\n",
      "48625it [1:33:10,  8.67it/s]Train epoch: 2 [batch #48625, batch_size 1, seq length 2500]\tLoss: 3.447900\n",
      "48650it [1:33:13,  8.65it/s]Train epoch: 2 [batch #48650, batch_size 1, seq length 2500]\tLoss: 3.822487\n",
      "48675it [1:33:16,  8.71it/s]Train epoch: 2 [batch #48675, batch_size 1, seq length 2500]\tLoss: 3.598665\n",
      "48700it [1:33:19,  8.63it/s]Train epoch: 2 [batch #48700, batch_size 1, seq length 2500]\tLoss: 3.722110\n",
      "48725it [1:33:22,  8.74it/s]Train epoch: 2 [batch #48725, batch_size 1, seq length 2500]\tLoss: 3.571028\n",
      "48750it [1:33:25,  8.67it/s]Train epoch: 2 [batch #48750, batch_size 1, seq length 2500]\tLoss: 3.593580\n",
      "48775it [1:33:28,  8.69it/s]Train epoch: 2 [batch #48775, batch_size 1, seq length 2500]\tLoss: 3.966873\n",
      "48800it [1:33:31,  8.67it/s]Train epoch: 2 [batch #48800, batch_size 1, seq length 2500]\tLoss: 3.895300\n",
      "48825it [1:33:34,  8.67it/s]Train epoch: 2 [batch #48825, batch_size 1, seq length 2500]\tLoss: 3.438306\n",
      "48850it [1:33:36,  8.67it/s]Train epoch: 2 [batch #48850, batch_size 1, seq length 2500]\tLoss: 3.600850\n",
      "48875it [1:33:39,  8.75it/s]Train epoch: 2 [batch #48875, batch_size 1, seq length 2500]\tLoss: 3.723976\n",
      "48900it [1:33:42,  8.73it/s]Train epoch: 2 [batch #48900, batch_size 1, seq length 2500]\tLoss: 3.758384\n",
      "48925it [1:33:45,  8.59it/s]Train epoch: 2 [batch #48925, batch_size 1, seq length 2500]\tLoss: 3.544849\n",
      "48950it [1:33:48,  8.68it/s]Train epoch: 2 [batch #48950, batch_size 1, seq length 2500]\tLoss: 3.840783\n",
      "48975it [1:33:51,  8.73it/s]Train epoch: 2 [batch #48975, batch_size 1, seq length 2500]\tLoss: 3.866311\n",
      "49000it [1:33:54,  8.67it/s]Train epoch: 2 [batch #49000, batch_size 1, seq length 2500]\tLoss: 3.724202\n",
      "49025it [1:33:57,  8.62it/s]Train epoch: 2 [batch #49025, batch_size 1, seq length 2500]\tLoss: 3.810785\n",
      "49050it [1:33:59,  8.72it/s]Train epoch: 2 [batch #49050, batch_size 1, seq length 2500]\tLoss: 3.793195\n",
      "49075it [1:34:02,  8.66it/s]Train epoch: 2 [batch #49075, batch_size 1, seq length 2500]\tLoss: 3.935081\n",
      "49100it [1:34:05,  8.58it/s]Train epoch: 2 [batch #49100, batch_size 1, seq length 2500]\tLoss: 3.811857\n",
      "49125it [1:34:08,  8.64it/s]Train epoch: 2 [batch #49125, batch_size 1, seq length 2500]\tLoss: 3.774690\n",
      "49150it [1:34:11,  8.62it/s]Train epoch: 2 [batch #49150, batch_size 1, seq length 2500]\tLoss: 3.760864\n",
      "49175it [1:34:14,  8.66it/s]Train epoch: 2 [batch #49175, batch_size 1, seq length 2500]\tLoss: 3.404228\n",
      "49200it [1:34:17,  8.68it/s]Train epoch: 2 [batch #49200, batch_size 1, seq length 2500]\tLoss: 3.267608\n",
      "49225it [1:34:20,  8.66it/s]Train epoch: 2 [batch #49225, batch_size 1, seq length 2500]\tLoss: 3.592245\n",
      "49250it [1:34:23,  8.68it/s]Train epoch: 2 [batch #49250, batch_size 1, seq length 2500]\tLoss: 3.640399\n",
      "49275it [1:34:25,  8.74it/s]Train epoch: 2 [batch #49275, batch_size 1, seq length 2500]\tLoss: 4.036442\n",
      "49300it [1:34:28,  8.66it/s]Train epoch: 2 [batch #49300, batch_size 1, seq length 2500]\tLoss: 3.759291\n",
      "49325it [1:34:31,  8.72it/s]Train epoch: 2 [batch #49325, batch_size 1, seq length 2500]\tLoss: 3.501182\n",
      "49350it [1:34:34,  8.68it/s]Train epoch: 2 [batch #49350, batch_size 1, seq length 2500]\tLoss: 3.226515\n",
      "49375it [1:34:37,  8.74it/s]Train epoch: 2 [batch #49375, batch_size 1, seq length 2500]\tLoss: 3.786418\n",
      "49400it [1:34:40,  8.59it/s]Train epoch: 2 [batch #49400, batch_size 1, seq length 2500]\tLoss: 3.796774\n",
      "49425it [1:34:43,  8.74it/s]Train epoch: 2 [batch #49425, batch_size 1, seq length 2500]\tLoss: 3.838718\n",
      "49450it [1:34:46,  8.69it/s]Train epoch: 2 [batch #49450, batch_size 1, seq length 2500]\tLoss: 3.976371\n",
      "49475it [1:34:48,  8.72it/s]Train epoch: 2 [batch #49475, batch_size 1, seq length 2500]\tLoss: 3.779051\n",
      "49500it [1:34:51,  8.67it/s]Train epoch: 2 [batch #49500, batch_size 1, seq length 2500]\tLoss: 3.689099\n",
      "49525it [1:34:54,  8.65it/s]Train epoch: 2 [batch #49525, batch_size 1, seq length 2500]\tLoss: 3.596287\n",
      "49550it [1:34:57,  8.70it/s]Train epoch: 2 [batch #49550, batch_size 1, seq length 2500]\tLoss: 3.464962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49575it [1:35:00,  8.63it/s]Train epoch: 2 [batch #49575, batch_size 1, seq length 2500]\tLoss: 3.452865\n",
      "49600it [1:35:03,  8.73it/s]Train epoch: 2 [batch #49600, batch_size 1, seq length 2500]\tLoss: 3.884214\n",
      "49625it [1:35:06,  8.64it/s]Train epoch: 2 [batch #49625, batch_size 1, seq length 2500]\tLoss: 3.648499\n",
      "49650it [1:35:09,  8.71it/s]Train epoch: 2 [batch #49650, batch_size 1, seq length 2500]\tLoss: 3.651543\n",
      "49675it [1:35:11,  8.67it/s]Train epoch: 2 [batch #49675, batch_size 1, seq length 2500]\tLoss: 3.833459\n",
      "49700it [1:35:14,  8.59it/s]Train epoch: 2 [batch #49700, batch_size 1, seq length 2500]\tLoss: 3.472161\n",
      "49725it [1:35:17,  8.57it/s]Train epoch: 2 [batch #49725, batch_size 1, seq length 2500]\tLoss: 3.929347\n",
      "49750it [1:35:20,  8.66it/s]Train epoch: 2 [batch #49750, batch_size 1, seq length 2500]\tLoss: 3.989534\n",
      "49775it [1:35:23,  8.71it/s]Train epoch: 2 [batch #49775, batch_size 1, seq length 2500]\tLoss: 3.665997\n",
      "49800it [1:35:26,  8.72it/s]Train epoch: 2 [batch #49800, batch_size 1, seq length 2500]\tLoss: 3.582470\n",
      "49825it [1:35:29,  8.55it/s]Train epoch: 2 [batch #49825, batch_size 1, seq length 2500]\tLoss: 3.587388\n",
      "49850it [1:35:32,  8.72it/s]Train epoch: 2 [batch #49850, batch_size 1, seq length 2500]\tLoss: 3.679688\n",
      "49875it [1:35:34,  8.70it/s]Train epoch: 2 [batch #49875, batch_size 1, seq length 2500]\tLoss: 3.652500\n",
      "49900it [1:35:37,  8.75it/s]Train epoch: 2 [batch #49900, batch_size 1, seq length 2500]\tLoss: 3.541333\n",
      "49925it [1:35:40,  8.71it/s]Train epoch: 2 [batch #49925, batch_size 1, seq length 2500]\tLoss: 3.494446\n",
      "49950it [1:35:43,  8.67it/s]Train epoch: 2 [batch #49950, batch_size 1, seq length 2500]\tLoss: 3.837570\n",
      "49975it [1:35:46,  8.69it/s]Train epoch: 2 [batch #49975, batch_size 1, seq length 2500]\tLoss: 3.785493\n",
      "50000it [1:35:49,  8.73it/s]Train epoch: 2 [batch #50000, batch_size 1, seq length 2500]\tLoss: 3.713345\n",
      "50025it [1:35:52,  8.75it/s]Train epoch: 2 [batch #50025, batch_size 1, seq length 2500]\tLoss: 3.725242\n",
      "50050it [1:35:55,  8.62it/s]Train epoch: 2 [batch #50050, batch_size 1, seq length 2500]\tLoss: 3.373258\n",
      "50075it [1:35:58,  8.69it/s]Train epoch: 2 [batch #50075, batch_size 1, seq length 2500]\tLoss: 3.789349\n",
      "50100it [1:36:00,  8.68it/s]Train epoch: 2 [batch #50100, batch_size 1, seq length 2500]\tLoss: 3.454120\n",
      "50125it [1:36:03,  8.59it/s]Train epoch: 2 [batch #50125, batch_size 1, seq length 2500]\tLoss: 3.960013\n",
      "50150it [1:36:06,  8.75it/s]Train epoch: 2 [batch #50150, batch_size 1, seq length 2500]\tLoss: 3.707769\n",
      "50175it [1:36:09,  8.75it/s]Train epoch: 2 [batch #50175, batch_size 1, seq length 2500]\tLoss: 3.218807\n",
      "50200it [1:36:12,  8.69it/s]Train epoch: 2 [batch #50200, batch_size 1, seq length 2500]\tLoss: 3.900023\n",
      "50225it [1:36:15,  8.68it/s]Train epoch: 2 [batch #50225, batch_size 1, seq length 2500]\tLoss: 3.926009\n",
      "50250it [1:36:18,  8.68it/s]Train epoch: 2 [batch #50250, batch_size 1, seq length 2500]\tLoss: 3.421190\n",
      "50275it [1:36:21,  8.72it/s]Train epoch: 2 [batch #50275, batch_size 1, seq length 2500]\tLoss: 3.775719\n",
      "50300it [1:36:23,  8.54it/s]Train epoch: 2 [batch #50300, batch_size 1, seq length 2500]\tLoss: 3.697227\n",
      "50325it [1:36:26,  8.73it/s]Train epoch: 2 [batch #50325, batch_size 1, seq length 2500]\tLoss: 3.684870\n",
      "50350it [1:36:29,  8.66it/s]Train epoch: 2 [batch #50350, batch_size 1, seq length 2500]\tLoss: 3.380621\n",
      "50375it [1:36:32,  8.65it/s]Train epoch: 2 [batch #50375, batch_size 1, seq length 2500]\tLoss: 3.783601\n",
      "50400it [1:36:35,  8.66it/s]Train epoch: 2 [batch #50400, batch_size 1, seq length 2500]\tLoss: 3.963311\n",
      "50425it [1:36:38,  8.71it/s]Train epoch: 2 [batch #50425, batch_size 1, seq length 2500]\tLoss: 3.554660\n",
      "50450it [1:36:41,  8.65it/s]Train epoch: 2 [batch #50450, batch_size 1, seq length 2500]\tLoss: 3.539797\n",
      "50475it [1:36:44,  8.62it/s]Train epoch: 2 [batch #50475, batch_size 1, seq length 2500]\tLoss: 3.582113\n",
      "50500it [1:36:46,  8.67it/s]Train epoch: 2 [batch #50500, batch_size 1, seq length 2500]\tLoss: 3.844358\n",
      "50525it [1:36:49,  8.61it/s]Train epoch: 2 [batch #50525, batch_size 1, seq length 2500]\tLoss: 3.890576\n",
      "50550it [1:36:52,  8.73it/s]Train epoch: 2 [batch #50550, batch_size 1, seq length 2500]\tLoss: 3.387461\n",
      "50575it [1:36:55,  8.73it/s]Train epoch: 2 [batch #50575, batch_size 1, seq length 2500]\tLoss: 3.668809\n",
      "50600it [1:36:58,  8.72it/s]Train epoch: 2 [batch #50600, batch_size 1, seq length 2500]\tLoss: 3.744925\n",
      "50625it [1:37:01,  8.73it/s]Train epoch: 2 [batch #50625, batch_size 1, seq length 2500]\tLoss: 3.816320\n",
      "50650it [1:37:04,  8.70it/s]Train epoch: 2 [batch #50650, batch_size 1, seq length 2500]\tLoss: 4.109893\n",
      "50675it [1:37:07,  8.62it/s]Train epoch: 2 [batch #50675, batch_size 1, seq length 2500]\tLoss: 3.513561\n",
      "50700it [1:37:09,  8.67it/s]Train epoch: 2 [batch #50700, batch_size 1, seq length 2500]\tLoss: 3.533030\n",
      "50725it [1:37:12,  8.75it/s]Train epoch: 2 [batch #50725, batch_size 1, seq length 2500]\tLoss: 3.576150\n",
      "50750it [1:37:15,  8.70it/s]Train epoch: 2 [batch #50750, batch_size 1, seq length 2500]\tLoss: 3.639385\n",
      "50775it [1:37:18,  8.71it/s]Train epoch: 2 [batch #50775, batch_size 1, seq length 2500]\tLoss: 3.565787\n",
      "50800it [1:37:21,  8.70it/s]Train epoch: 2 [batch #50800, batch_size 1, seq length 2500]\tLoss: 3.671485\n",
      "50825it [1:37:24,  8.61it/s]Train epoch: 2 [batch #50825, batch_size 1, seq length 2500]\tLoss: 3.644421\n",
      "50850it [1:37:27,  8.67it/s]Train epoch: 2 [batch #50850, batch_size 1, seq length 2500]\tLoss: 3.782975\n",
      "50875it [1:37:30,  8.70it/s]Train epoch: 2 [batch #50875, batch_size 1, seq length 2500]\tLoss: 3.474874\n",
      "50900it [1:37:32,  8.70it/s]Train epoch: 2 [batch #50900, batch_size 1, seq length 2500]\tLoss: 3.810693\n",
      "50925it [1:37:35,  8.64it/s]Train epoch: 2 [batch #50925, batch_size 1, seq length 2500]\tLoss: 3.451374\n",
      "50950it [1:37:38,  8.66it/s]Train epoch: 2 [batch #50950, batch_size 1, seq length 2500]\tLoss: 3.817527\n",
      "50975it [1:37:41,  8.73it/s]Train epoch: 2 [batch #50975, batch_size 1, seq length 2500]\tLoss: 3.421397\n",
      "51000it [1:37:44,  8.68it/s]Train epoch: 2 [batch #51000, batch_size 1, seq length 2500]\tLoss: 3.777015\n",
      "51025it [1:37:47,  8.70it/s]Train epoch: 2 [batch #51025, batch_size 1, seq length 2500]\tLoss: 3.769972\n",
      "51050it [1:37:50,  8.66it/s]Train epoch: 2 [batch #51050, batch_size 1, seq length 2500]\tLoss: 3.790606\n",
      "51075it [1:37:53,  8.64it/s]Train epoch: 2 [batch #51075, batch_size 1, seq length 2500]\tLoss: 3.884474\n",
      "51100it [1:37:56,  8.58it/s]Train epoch: 2 [batch #51100, batch_size 1, seq length 2500]\tLoss: 3.415997\n",
      "51125it [1:37:58,  8.75it/s]Train epoch: 2 [batch #51125, batch_size 1, seq length 2500]\tLoss: 3.729144\n",
      "51150it [1:38:01,  8.71it/s]Train epoch: 2 [batch #51150, batch_size 1, seq length 2500]\tLoss: 3.566263\n",
      "51175it [1:38:04,  8.75it/s]Train epoch: 2 [batch #51175, batch_size 1, seq length 2500]\tLoss: 3.801140\n",
      "51200it [1:38:07,  8.73it/s]Train epoch: 2 [batch #51200, batch_size 1, seq length 2500]\tLoss: 3.560968\n",
      "51225it [1:38:10,  8.67it/s]Train epoch: 2 [batch #51225, batch_size 1, seq length 2500]\tLoss: 3.594392\n",
      "51250it [1:38:13,  8.64it/s]Train epoch: 2 [batch #51250, batch_size 1, seq length 2500]\tLoss: 3.895056\n",
      "51275it [1:38:16,  8.72it/s]Train epoch: 2 [batch #51275, batch_size 1, seq length 2500]\tLoss: 3.771760\n",
      "51300it [1:38:19,  8.68it/s]Train epoch: 2 [batch #51300, batch_size 1, seq length 2500]\tLoss: 3.619486\n",
      "51325it [1:38:21,  8.70it/s]Train epoch: 2 [batch #51325, batch_size 1, seq length 2500]\tLoss: 3.962379\n",
      "51350it [1:38:24,  8.64it/s]Train epoch: 2 [batch #51350, batch_size 1, seq length 2500]\tLoss: 3.853162\n",
      "51375it [1:38:27,  8.72it/s]Train epoch: 2 [batch #51375, batch_size 1, seq length 2500]\tLoss: 3.712684\n",
      "51400it [1:38:30,  8.60it/s]Train epoch: 2 [batch #51400, batch_size 1, seq length 2500]\tLoss: 3.676435\n",
      "51425it [1:38:33,  8.71it/s]Train epoch: 2 [batch #51425, batch_size 1, seq length 2500]\tLoss: 3.628073\n",
      "51450it [1:38:36,  8.68it/s]Train epoch: 2 [batch #51450, batch_size 1, seq length 2500]\tLoss: 3.925879\n",
      "51475it [1:38:39,  8.61it/s]Train epoch: 2 [batch #51475, batch_size 1, seq length 2500]\tLoss: 3.678122\n",
      "51500it [1:38:42,  8.67it/s]Train epoch: 2 [batch #51500, batch_size 1, seq length 2500]\tLoss: 3.720364\n",
      "51525it [1:38:45,  8.73it/s]Train epoch: 2 [batch #51525, batch_size 1, seq length 2500]\tLoss: 3.931208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51550it [1:38:47,  8.66it/s]Train epoch: 2 [batch #51550, batch_size 1, seq length 2500]\tLoss: 3.294826\n",
      "51575it [1:38:50,  8.73it/s]Train epoch: 2 [batch #51575, batch_size 1, seq length 2500]\tLoss: 3.780065\n",
      "51600it [1:38:53,  8.73it/s]Train epoch: 2 [batch #51600, batch_size 1, seq length 2500]\tLoss: 3.927114\n",
      "51625it [1:38:56,  8.64it/s]Train epoch: 2 [batch #51625, batch_size 1, seq length 2500]\tLoss: 3.658709\n",
      "51650it [1:38:59,  8.74it/s]Train epoch: 2 [batch #51650, batch_size 1, seq length 2500]\tLoss: 3.269287\n",
      "51675it [1:39:02,  8.70it/s]Train epoch: 2 [batch #51675, batch_size 1, seq length 2500]\tLoss: 3.412725\n",
      "51700it [1:39:05,  8.70it/s]Train epoch: 2 [batch #51700, batch_size 1, seq length 2500]\tLoss: 3.929023\n",
      "51725it [1:39:08,  8.75it/s]Train epoch: 2 [batch #51725, batch_size 1, seq length 2500]\tLoss: 3.544384\n",
      "51750it [1:39:10,  8.72it/s]Train epoch: 2 [batch #51750, batch_size 1, seq length 2500]\tLoss: 3.608389\n",
      "51775it [1:39:13,  8.69it/s]Train epoch: 2 [batch #51775, batch_size 1, seq length 2500]\tLoss: 3.958359\n",
      "51800it [1:39:16,  8.72it/s]Train epoch: 2 [batch #51800, batch_size 1, seq length 2500]\tLoss: 3.789526\n",
      "51825it [1:39:19,  8.67it/s]Train epoch: 2 [batch #51825, batch_size 1, seq length 2500]\tLoss: 3.907911\n",
      "51850it [1:39:22,  8.71it/s]Train epoch: 2 [batch #51850, batch_size 1, seq length 2500]\tLoss: 3.564881\n",
      "51875it [1:39:25,  8.68it/s]Train epoch: 2 [batch #51875, batch_size 1, seq length 2500]\tLoss: 3.291104\n",
      "51900it [1:39:28,  8.66it/s]Train epoch: 2 [batch #51900, batch_size 1, seq length 2500]\tLoss: 3.622023\n",
      "51925it [1:39:31,  8.76it/s]Train epoch: 2 [batch #51925, batch_size 1, seq length 2500]\tLoss: 3.659545\n",
      "51950it [1:39:34,  8.68it/s]Train epoch: 2 [batch #51950, batch_size 1, seq length 2500]\tLoss: 3.828021\n",
      "51975it [1:39:36,  8.64it/s]Train epoch: 2 [batch #51975, batch_size 1, seq length 2500]\tLoss: 3.286199\n",
      "52000it [1:39:39,  8.58it/s]Train epoch: 2 [batch #52000, batch_size 1, seq length 2500]\tLoss: 3.620607\n",
      "52025it [1:39:42,  8.65it/s]Train epoch: 2 [batch #52025, batch_size 1, seq length 2500]\tLoss: 3.796229\n",
      "52050it [1:39:45,  8.67it/s]Train epoch: 2 [batch #52050, batch_size 1, seq length 2500]\tLoss: 3.799707\n",
      "52075it [1:39:48,  8.69it/s]Train epoch: 2 [batch #52075, batch_size 1, seq length 2500]\tLoss: 3.424059\n",
      "52100it [1:39:51,  8.60it/s]Train epoch: 2 [batch #52100, batch_size 1, seq length 2500]\tLoss: 3.957751\n",
      "52125it [1:39:54,  8.73it/s]Train epoch: 2 [batch #52125, batch_size 1, seq length 2500]\tLoss: 3.146460\n",
      "52150it [1:39:57,  8.67it/s]Train epoch: 2 [batch #52150, batch_size 1, seq length 2500]\tLoss: 3.808458\n",
      "52175it [1:39:59,  8.71it/s]Train epoch: 2 [batch #52175, batch_size 1, seq length 2500]\tLoss: 3.728244\n",
      "52200it [1:40:02,  8.71it/s]Train epoch: 2 [batch #52200, batch_size 1, seq length 2500]\tLoss: 3.733625\n",
      "52225it [1:40:05,  8.66it/s]Train epoch: 2 [batch #52225, batch_size 1, seq length 2500]\tLoss: 3.639127\n",
      "52250it [1:40:08,  8.62it/s]Train epoch: 2 [batch #52250, batch_size 1, seq length 2500]\tLoss: 3.855119\n",
      "52275it [1:40:11,  8.69it/s]Train epoch: 2 [batch #52275, batch_size 1, seq length 2500]\tLoss: 3.599079\n",
      "52300it [1:40:14,  8.70it/s]Train epoch: 2 [batch #52300, batch_size 1, seq length 2500]\tLoss: 3.606760\n",
      "52325it [1:40:17,  8.68it/s]Train epoch: 2 [batch #52325, batch_size 1, seq length 2500]\tLoss: 3.733948\n",
      "52350it [1:40:20,  8.58it/s]Train epoch: 2 [batch #52350, batch_size 1, seq length 2500]\tLoss: 3.879110\n",
      "52375it [1:40:22,  8.72it/s]Train epoch: 2 [batch #52375, batch_size 1, seq length 2500]\tLoss: 3.517597\n",
      "52400it [1:40:25,  8.69it/s]Train epoch: 2 [batch #52400, batch_size 1, seq length 2500]\tLoss: 3.798947\n",
      "52425it [1:40:28,  8.64it/s]Train epoch: 2 [batch #52425, batch_size 1, seq length 2500]\tLoss: 3.808098\n",
      "52450it [1:40:31,  8.69it/s]Train epoch: 2 [batch #52450, batch_size 1, seq length 2500]\tLoss: 3.821616\n",
      "52465it [1:40:33,  8.70it/s]\n",
      "Epoch 2: 3.6927\n",
      "Save pretrained model --> ./outputs/debug3/pretrain\n",
      "loading lookups...\n",
      "BertForMedical(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (redefined_word_embeddings): Embedding(100000, 128, padding_idx=0)\n",
      "      (redefined_position_embeddings): Embedding(2500, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (bert_pool): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (bert_attention): Linear(in_features=128, out_features=8921, bias=False)\n",
      "  (bert_classifier): Linear(in_features=128, out_features=8921, bias=True)\n",
      ")\n",
      "EPOCH 0\n",
      "0it [00:00, ?it/s]Train epoch: 0 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.696504\n",
      "25it [00:04,  5.48it/s]Train epoch: 0 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.626512\n",
      "50it [00:09,  5.51it/s]Train epoch: 0 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.493118\n",
      "75it [00:13,  5.36it/s]Train epoch: 0 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.358516\n",
      "100it [00:18,  5.48it/s]Train epoch: 0 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.248080\n",
      "125it [00:22,  5.30it/s]Train epoch: 0 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.168652\n",
      "150it [00:27,  5.38it/s]Train epoch: 0 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.115692\n",
      "175it [00:32,  5.35it/s]Train epoch: 0 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.082256\n",
      "200it [00:36,  5.34it/s]Train epoch: 0 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.060320\n",
      "225it [00:41,  5.28it/s]Train epoch: 0 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.046905\n",
      "250it [00:46,  5.29it/s]Train epoch: 0 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.036670\n",
      "275it [00:51,  5.29it/s]Train epoch: 0 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.029552\n",
      "300it [00:55,  5.15it/s]Train epoch: 0 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.025399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325it [01:00,  5.22it/s]Train epoch: 0 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.021363\n",
      "350it [01:05,  5.16it/s]Train epoch: 0 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.019520\n",
      "375it [01:10,  5.17it/s]Train epoch: 0 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.017212\n",
      "400it [01:15,  5.23it/s]Train epoch: 0 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.015251\n",
      "425it [01:19,  5.18it/s]Train epoch: 0 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.014084\n",
      "450it [01:24,  5.27it/s]Train epoch: 0 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.012679\n",
      "475it [01:29,  5.09it/s]Train epoch: 0 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.012752\n",
      "500it [01:34,  5.21it/s]Train epoch: 0 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.010983\n",
      "525it [01:39,  5.22it/s]Train epoch: 0 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.011062\n",
      "550it [01:44,  5.13it/s]Train epoch: 0 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.010160\n",
      "575it [01:48,  5.19it/s]Train epoch: 0 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.009805\n",
      "600it [01:53,  5.03it/s]Train epoch: 0 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.010015\n",
      "625it [01:58,  5.11it/s]Train epoch: 0 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.009226\n",
      "650it [02:03,  5.06it/s]Train epoch: 0 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.008632\n",
      "675it [02:08,  5.10it/s]Train epoch: 0 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.007838\n",
      "700it [02:13,  4.98it/s]Train epoch: 0 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.008344\n",
      "725it [02:18,  5.03it/s]Train epoch: 0 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.008271\n",
      "750it [02:23,  4.93it/s]Train epoch: 0 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.007783\n",
      "775it [02:28,  5.15it/s]Train epoch: 0 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.008326\n",
      "800it [02:33,  5.04it/s]Train epoch: 0 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.007933\n",
      "825it [02:37,  5.21it/s]Train epoch: 0 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.008060\n",
      "850it [02:42,  5.07it/s]Train epoch: 0 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.008147\n",
      "875it [02:47,  5.04it/s]Train epoch: 0 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.007494\n",
      "900it [02:52,  5.07it/s]Train epoch: 0 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.007510\n",
      "925it [02:57,  5.05it/s]Train epoch: 0 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.007224\n",
      "950it [03:02,  5.03it/s]Train epoch: 0 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.007056\n",
      "975it [03:07,  5.11it/s]Train epoch: 0 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.006238\n",
      "1000it [03:12,  5.08it/s]Train epoch: 0 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.007395\n",
      "1025it [03:17,  5.08it/s]Train epoch: 0 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.008584\n",
      "1050it [03:22,  5.07it/s]Train epoch: 0 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.006951\n",
      "1075it [03:27,  4.99it/s]Train epoch: 0 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.007046\n",
      "1100it [03:32,  5.01it/s]Train epoch: 0 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.007220\n",
      "1125it [03:37,  5.08it/s]Train epoch: 0 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.007307\n",
      "1150it [03:42,  4.97it/s]Train epoch: 0 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.007346\n",
      "1175it [03:47,  5.04it/s]Train epoch: 0 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.007381\n",
      "1200it [03:52,  4.98it/s]Train epoch: 0 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.007308\n",
      "1225it [03:57,  5.05it/s]Train epoch: 0 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.007490\n",
      "1250it [04:02,  5.03it/s]Train epoch: 0 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.007321\n",
      "1275it [04:07,  5.10it/s]Train epoch: 0 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.006331\n",
      "1300it [04:12,  5.04it/s]Train epoch: 0 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.006250\n",
      "1325it [04:17,  5.01it/s]Train epoch: 0 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.006627\n",
      "1350it [04:22,  5.05it/s]Train epoch: 0 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.008109\n",
      "1375it [04:27,  5.01it/s]Train epoch: 0 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.006736\n",
      "1400it [04:32,  4.98it/s]Train epoch: 0 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.006616\n",
      "1425it [04:37,  4.87it/s]Train epoch: 0 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.006426\n",
      "1450it [04:42,  5.02it/s]Train epoch: 0 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.006608\n",
      "1475it [04:47,  4.93it/s]Train epoch: 0 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.007264\n",
      "1500it [04:52,  4.99it/s]Train epoch: 0 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.008205\n",
      "1525it [04:57,  4.92it/s]Train epoch: 0 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.007535\n",
      "1550it [05:02,  5.05it/s]Train epoch: 0 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.006473\n",
      "1575it [05:07,  4.96it/s]Train epoch: 0 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.007249\n",
      "1600it [05:12,  4.95it/s]Train epoch: 0 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.006518\n",
      "1625it [05:17,  4.91it/s]Train epoch: 0 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.007115\n",
      "1650it [05:22,  5.01it/s]Train epoch: 0 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.007482\n",
      "1675it [05:27,  4.92it/s]Train epoch: 0 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.007006\n",
      "1700it [05:32,  5.01it/s]Train epoch: 0 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.006332\n",
      "1725it [05:37,  5.03it/s]Train epoch: 0 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.005945\n",
      "1750it [05:42,  4.95it/s]Train epoch: 0 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.007781\n",
      "1775it [05:47,  4.96it/s]Train epoch: 0 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.006667\n",
      "1800it [05:53,  4.96it/s]Train epoch: 0 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.006551\n",
      "1825it [05:58,  4.92it/s]Train epoch: 0 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.006121\n",
      "1850it [06:03,  4.90it/s]Train epoch: 0 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.006981\n",
      "1875it [06:08,  4.90it/s]Train epoch: 0 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.007322\n",
      "1900it [06:13,  4.92it/s]Train epoch: 0 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.005981\n",
      "1925it [06:18,  4.95it/s]Train epoch: 0 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.006258\n",
      "1950it [06:23,  4.94it/s]Train epoch: 0 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.006294\n",
      "1975it [06:28,  4.87it/s]Train epoch: 0 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.007192\n",
      "2000it [06:33,  4.88it/s]Train epoch: 0 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.005968\n",
      "2025it [06:38,  4.91it/s]Train epoch: 0 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.007079\n",
      "2050it [06:44,  4.85it/s]Train epoch: 0 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.006453\n",
      "2075it [06:49,  4.91it/s]Train epoch: 0 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.006473\n",
      "2100it [06:54,  4.89it/s]Train epoch: 0 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.006989\n",
      "2125it [06:59,  4.94it/s]Train epoch: 0 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.007423\n",
      "2150it [07:04,  4.84it/s]Train epoch: 0 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.006544\n",
      "2175it [07:09,  4.85it/s]Train epoch: 0 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.007335\n",
      "2200it [07:14,  4.92it/s]Train epoch: 0 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.006905\n",
      "2225it [07:19,  4.99it/s]Train epoch: 0 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.006918\n",
      "2250it [07:24,  4.94it/s]Train epoch: 0 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.006286\n",
      "2275it [07:30,  4.83it/s]Train epoch: 0 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.006906\n",
      "2300it [07:35,  4.88it/s]Train epoch: 0 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.005676\n",
      "2325it [07:40,  4.80it/s]Train epoch: 0 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.006771\n",
      "2350it [07:45,  4.86it/s]Train epoch: 0 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.006701\n",
      "2375it [07:50,  4.81it/s]Train epoch: 0 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.008274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400it [07:55,  4.79it/s]Train epoch: 0 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.007889\n",
      "2425it [08:01,  4.77it/s]Train epoch: 0 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.005951\n",
      "2450it [08:06,  4.85it/s]Train epoch: 0 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.006717\n",
      "2475it [08:11,  4.85it/s]Train epoch: 0 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.007370\n",
      "2500it [08:16,  4.87it/s]Train epoch: 0 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.006532\n",
      "2525it [08:21,  4.82it/s]Train epoch: 0 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.006560\n",
      "2550it [08:26,  4.95it/s]Train epoch: 0 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.008184\n",
      "2575it [08:32,  4.85it/s]Train epoch: 0 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.006653\n",
      "2600it [08:37,  4.82it/s]Train epoch: 0 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.006902\n",
      "2625it [08:42,  4.84it/s]Train epoch: 0 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.006989\n",
      "2650it [08:47,  4.81it/s]Train epoch: 0 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.007262\n",
      "2675it [08:52,  4.77it/s]Train epoch: 0 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.006896\n",
      "2700it [08:57,  4.82it/s]Train epoch: 0 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.006503\n",
      "2725it [09:03,  4.87it/s]Train epoch: 0 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.006876\n",
      "2750it [09:08,  4.80it/s]Train epoch: 0 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.007832\n",
      "2775it [09:13,  4.79it/s]Train epoch: 0 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.007136\n",
      "2800it [09:18,  4.89it/s]Train epoch: 0 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.006806\n",
      "2825it [09:24,  4.79it/s]Train epoch: 0 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.007000\n",
      "2850it [09:29,  4.81it/s]Train epoch: 0 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.006916\n",
      "2875it [09:34,  4.80it/s]Train epoch: 0 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.007544\n",
      "2900it [09:39,  4.82it/s]Train epoch: 0 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.007134\n",
      "2925it [09:44,  4.87it/s]Train epoch: 0 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.007407\n",
      "2950it [09:50,  4.70it/s]Train epoch: 0 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.007289\n",
      "2975it [09:55,  4.82it/s]Train epoch: 0 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.007319\n",
      "3000it [10:00,  4.73it/s]Train epoch: 0 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.007866\n",
      "3025it [10:05,  4.77it/s]Train epoch: 0 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.007691\n",
      "3050it [10:11,  4.77it/s]Train epoch: 0 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.006889\n",
      "3075it [10:16,  4.73it/s]Train epoch: 0 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.007663\n",
      "3100it [10:21,  4.73it/s]Train epoch: 0 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.007556\n",
      "3125it [10:26,  4.78it/s]Train epoch: 0 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.007145\n",
      "3150it [10:32,  4.76it/s]Train epoch: 0 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.006785\n",
      "3175it [10:37,  4.67it/s]Train epoch: 0 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.006694\n",
      "3200it [10:42,  4.77it/s]Train epoch: 0 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.007423\n",
      "3225it [10:47,  4.76it/s]Train epoch: 0 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.007073\n",
      "3250it [10:53,  4.75it/s]Train epoch: 0 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.007341\n",
      "3275it [10:58,  4.74it/s]Train epoch: 0 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.006868\n",
      "3300it [11:03,  4.71it/s]Train epoch: 0 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.008254\n",
      "3325it [11:09,  4.71it/s]Train epoch: 0 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.007388\n",
      "3350it [11:14,  4.69it/s]Train epoch: 0 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.006996\n",
      "3375it [11:19,  4.72it/s]Train epoch: 0 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.008048\n",
      "3400it [11:25,  4.74it/s]Train epoch: 0 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.007551\n",
      "3425it [11:30,  4.72it/s]Train epoch: 0 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.006872\n",
      "3450it [11:35,  4.78it/s]Train epoch: 0 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.007686\n",
      "3475it [11:40,  4.82it/s]Train epoch: 0 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.007019\n",
      "3500it [11:46,  4.70it/s]Train epoch: 0 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.007142\n",
      "3525it [11:51,  4.68it/s]Train epoch: 0 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.007536\n",
      "3550it [11:56,  4.64it/s]Train epoch: 0 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.007697\n",
      "3575it [12:02,  4.76it/s]Train epoch: 0 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.006420\n",
      "3600it [12:07,  4.74it/s]Train epoch: 0 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.008082\n",
      "3625it [12:12,  4.69it/s]Train epoch: 0 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.007348\n",
      "3650it [12:18,  4.70it/s]Train epoch: 0 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.007553\n",
      "3675it [12:23,  4.69it/s]Train epoch: 0 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.007546\n",
      "3700it [12:28,  4.64it/s]Train epoch: 0 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.007504\n",
      "3725it [12:34,  4.61it/s]Train epoch: 0 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.007515\n",
      "3750it [12:39,  4.63it/s]Train epoch: 0 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.008216\n",
      "3775it [12:45,  4.66it/s]Train epoch: 0 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.007340\n",
      "3800it [12:50,  4.56it/s]Train epoch: 0 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.008147\n",
      "3825it [12:55,  4.63it/s]Train epoch: 0 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.007042\n",
      "3850it [13:01,  4.62it/s]Train epoch: 0 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.006694\n",
      "3875it [13:06,  4.65it/s]Train epoch: 0 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.006685\n",
      "3900it [13:11,  4.65it/s]Train epoch: 0 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.007778\n",
      "3925it [13:17,  4.57it/s]Train epoch: 0 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.007195\n",
      "3950it [13:22,  4.53it/s]Train epoch: 0 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.008063\n",
      "3975it [13:28,  4.62it/s]Train epoch: 0 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.008810\n",
      "4000it [13:33,  4.60it/s]Train epoch: 0 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.007072\n",
      "4025it [13:39,  4.67it/s]Train epoch: 0 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.008272\n",
      "4050it [13:44,  4.60it/s]Train epoch: 0 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.007667\n",
      "4075it [13:50,  4.58it/s]Train epoch: 0 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.007813\n",
      "4100it [13:55,  4.60it/s]Train epoch: 0 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.008151\n",
      "4125it [14:01,  4.60it/s]Train epoch: 0 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.008318\n",
      "4150it [14:06,  4.61it/s]Train epoch: 0 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.007116\n",
      "4175it [14:11,  4.72it/s]Train epoch: 0 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.007574\n",
      "4200it [14:16,  4.76it/s]Train epoch: 0 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.008082\n",
      "4225it [14:22,  4.65it/s]Train epoch: 0 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.007119\n",
      "4250it [14:27,  4.85it/s]Train epoch: 0 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.008412\n",
      "4275it [14:32,  4.80it/s]Train epoch: 0 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.007459\n",
      "4300it [14:37,  4.80it/s]Train epoch: 0 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.008103\n",
      "4325it [14:43,  4.78it/s]Train epoch: 0 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.007425\n",
      "4350it [14:48,  4.84it/s]Train epoch: 0 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.008122\n",
      "4375it [14:53,  4.77it/s]Train epoch: 0 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.007742\n",
      "4400it [14:58,  4.80it/s]Train epoch: 0 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.007035\n",
      "4425it [15:03,  4.65it/s]Train epoch: 0 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.007925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4450it [15:09,  4.60it/s]Train epoch: 0 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.006305\n",
      "4475it [15:14,  4.58it/s]Train epoch: 0 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.007949\n",
      "4500it [15:20,  4.61it/s]Train epoch: 0 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.008828\n",
      "4525it [15:25,  4.55it/s]Train epoch: 0 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.007675\n",
      "4550it [15:31,  4.56it/s]Train epoch: 0 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.007410\n",
      "4575it [15:36,  4.66it/s]Train epoch: 0 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.008162\n",
      "4600it [15:42,  4.59it/s]Train epoch: 0 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.007011\n",
      "4625it [15:47,  4.58it/s]Train epoch: 0 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.007317\n",
      "4650it [15:53,  4.52it/s]Train epoch: 0 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.008291\n",
      "4675it [15:58,  4.49it/s]Train epoch: 0 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.007719\n",
      "4700it [16:04,  4.62it/s]Train epoch: 0 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.007167\n",
      "4725it [16:09,  4.60it/s]Train epoch: 0 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.007518\n",
      "4750it [16:15,  4.60it/s]Train epoch: 0 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.008620\n",
      "4775it [16:20,  4.58it/s]Train epoch: 0 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.007790\n",
      "4800it [16:26,  4.56it/s]Train epoch: 0 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.008113\n",
      "4825it [16:31,  4.56it/s]Train epoch: 0 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.006838\n",
      "4850it [16:37,  4.56it/s]Train epoch: 0 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.007935\n",
      "4875it [16:42,  4.55it/s]Train epoch: 0 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.007177\n",
      "4900it [16:48,  4.54it/s]Train epoch: 0 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.007599\n",
      "4925it [16:53,  4.60it/s]Train epoch: 0 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.007328\n",
      "4950it [16:59,  4.44it/s]Train epoch: 0 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.007297\n",
      "4975it [17:04,  4.49it/s]Train epoch: 0 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.007608\n",
      "5000it [17:10,  4.49it/s]Train epoch: 0 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.007811\n",
      "5025it [17:15,  4.48it/s]Train epoch: 0 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.007213\n",
      "5050it [17:21,  4.52it/s]Train epoch: 0 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.007108\n",
      "5075it [17:26,  4.50it/s]Train epoch: 0 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.007450\n",
      "5100it [17:32,  4.53it/s]Train epoch: 0 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.007248\n",
      "5125it [17:37,  4.48it/s]Train epoch: 0 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.007748\n",
      "5150it [17:43,  4.51it/s]Train epoch: 0 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.007620\n",
      "5175it [17:48,  4.58it/s]Train epoch: 0 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.007641\n",
      "5200it [17:54,  4.53it/s]Train epoch: 0 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.006881\n",
      "5225it [18:00,  4.48it/s]Train epoch: 0 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.007697\n",
      "5250it [18:05,  4.56it/s]Train epoch: 0 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.007489\n",
      "5275it [18:11,  4.57it/s]Train epoch: 0 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.007336\n",
      "5300it [18:16,  4.48it/s]Train epoch: 0 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.007064\n",
      "5325it [18:22,  4.52it/s]Train epoch: 0 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.008278\n",
      "5350it [18:27,  4.49it/s]Train epoch: 0 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.008158\n",
      "5375it [18:33,  4.41it/s]Train epoch: 0 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.007284\n",
      "5400it [18:38,  4.48it/s]Train epoch: 0 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.007508\n",
      "5425it [18:44,  4.49it/s]Train epoch: 0 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.007564\n",
      "5450it [18:50,  4.50it/s]Train epoch: 0 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.007665\n",
      "5475it [18:55,  4.55it/s]Train epoch: 0 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.008593\n",
      "5500it [19:01,  4.42it/s]Train epoch: 0 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.008117\n",
      "5525it [19:06,  4.49it/s]Train epoch: 0 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.007096\n",
      "5550it [19:12,  4.45it/s]Train epoch: 0 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.007348\n",
      "5575it [19:18,  4.44it/s]Train epoch: 0 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.007856\n",
      "5600it [19:23,  4.51it/s]Train epoch: 0 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.008428\n",
      "5625it [19:29,  4.36it/s]Train epoch: 0 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.007600\n",
      "5650it [19:34,  4.44it/s]Train epoch: 0 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.007086\n",
      "5675it [19:40,  4.45it/s]Train epoch: 0 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.008359\n",
      "5700it [19:46,  4.48it/s]Train epoch: 0 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.007097\n",
      "5725it [19:51,  4.40it/s]Train epoch: 0 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.007339\n",
      "5750it [19:57,  4.42it/s]Train epoch: 0 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.009015\n",
      "5775it [20:02,  4.46it/s]Train epoch: 0 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.007825\n",
      "5800it [20:08,  4.40it/s]Train epoch: 0 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.008126\n",
      "5825it [20:14,  4.39it/s]Train epoch: 0 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.006772\n",
      "5850it [20:19,  4.38it/s]Train epoch: 0 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.008812\n",
      "5875it [20:25,  4.45it/s]Train epoch: 0 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.008161\n",
      "5900it [20:31,  4.40it/s]Train epoch: 0 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.008698\n",
      "5925it [20:36,  4.50it/s]Train epoch: 0 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.007119\n",
      "5950it [20:42,  4.41it/s]Train epoch: 0 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.006942\n",
      "5975it [20:48,  4.47it/s]Train epoch: 0 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.009004\n",
      "6000it [20:53,  4.40it/s]Train epoch: 0 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.008024\n",
      "6025it [20:59,  4.44it/s]Train epoch: 0 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.008496\n",
      "6050it [21:04,  4.41it/s]Train epoch: 0 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.007541\n",
      "6075it [21:10,  4.32it/s]Train epoch: 0 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.007301\n",
      "6100it [21:16,  4.40it/s]Train epoch: 0 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.007135\n",
      "6125it [21:21,  4.39it/s]Train epoch: 0 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.007395\n",
      "6150it [21:27,  4.42it/s]Train epoch: 0 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.007658\n",
      "6175it [21:33,  4.39it/s]Train epoch: 0 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.008185\n",
      "6200it [21:38,  4.46it/s]Train epoch: 0 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.008051\n",
      "6225it [21:44,  4.47it/s]Train epoch: 0 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.007107\n",
      "6250it [21:50,  4.47it/s]Train epoch: 0 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.007422\n",
      "6275it [21:55,  4.37it/s]Train epoch: 0 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.006925\n",
      "6300it [22:01,  4.38it/s]Train epoch: 0 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.008098\n",
      "6325it [22:07,  4.37it/s]Train epoch: 0 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.008175\n",
      "6350it [22:13,  4.39it/s]Train epoch: 0 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.008395\n",
      "6375it [22:19,  4.29it/s]Train epoch: 0 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.007274\n",
      "6400it [22:24,  4.39it/s]Train epoch: 0 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.007761\n",
      "6425it [22:30,  4.31it/s]Train epoch: 0 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.008517\n",
      "6450it [22:36,  4.39it/s]Train epoch: 0 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.008097\n",
      "6475it [22:41,  4.37it/s]Train epoch: 0 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.007453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500it [22:47,  4.31it/s]Train epoch: 0 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.008218\n",
      "6525it [22:53,  4.34it/s]Train epoch: 0 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.007308\n",
      "6550it [22:59,  4.34it/s]Train epoch: 0 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.007377\n",
      "6575it [23:04,  4.36it/s]Train epoch: 0 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.007621\n",
      "6600it [23:10,  4.45it/s]Train epoch: 0 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.008715\n",
      "6625it [23:16,  4.34it/s]Train epoch: 0 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.007418\n",
      "6650it [23:22,  4.35it/s]Train epoch: 0 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.008600\n",
      "6675it [23:27,  4.29it/s]Train epoch: 0 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.007920\n",
      "6700it [23:33,  4.31it/s]Train epoch: 0 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.008113\n",
      "6725it [23:39,  4.37it/s]Train epoch: 0 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.008025\n",
      "6750it [23:45,  4.33it/s]Train epoch: 0 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.007480\n",
      "6775it [23:50,  4.44it/s]Train epoch: 0 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.008252\n",
      "6800it [23:56,  4.25it/s]Train epoch: 0 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.008191\n",
      "6825it [24:02,  4.29it/s]Train epoch: 0 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.008300\n",
      "6850it [24:08,  4.35it/s]Train epoch: 0 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.007836\n",
      "6875it [24:14,  4.26it/s]Train epoch: 0 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.006839\n",
      "6900it [24:19,  4.27it/s]Train epoch: 0 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.007771\n",
      "6925it [24:25,  4.30it/s]Train epoch: 0 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.007717\n",
      "6950it [24:31,  4.33it/s]Train epoch: 0 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.008293\n",
      "6975it [24:37,  4.28it/s]Train epoch: 0 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.008122\n",
      "7000it [24:43,  4.27it/s]Train epoch: 0 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.007951\n",
      "7025it [24:49,  4.31it/s]Train epoch: 0 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.009055\n",
      "7050it [24:54,  4.29it/s]Train epoch: 0 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.006994\n",
      "7075it [25:00,  4.26it/s]Train epoch: 0 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.007883\n",
      "7100it [25:06,  4.32it/s]Train epoch: 0 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.008237\n",
      "7125it [25:12,  4.30it/s]Train epoch: 0 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.007295\n",
      "7150it [25:18,  4.21it/s]Train epoch: 0 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.008370\n",
      "7175it [25:24,  4.28it/s]Train epoch: 0 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.008042\n",
      "7200it [25:30,  4.18it/s]Train epoch: 0 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.008525\n",
      "7225it [25:35,  4.33it/s]Train epoch: 0 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.007701\n",
      "7250it [25:41,  4.28it/s]Train epoch: 0 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.007918\n",
      "7275it [25:47,  4.18it/s]Train epoch: 0 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.008504\n",
      "7300it [25:53,  4.23it/s]Train epoch: 0 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.008854\n",
      "7325it [25:59,  4.26it/s]Train epoch: 0 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.007636\n",
      "7350it [26:05,  4.27it/s]Train epoch: 0 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.008627\n",
      "7375it [26:11,  4.28it/s]Train epoch: 0 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.008225\n",
      "7400it [26:16,  4.29it/s]Train epoch: 0 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.007569\n",
      "7425it [26:22,  4.26it/s]Train epoch: 0 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.008142\n",
      "7450it [26:28,  4.25it/s]Train epoch: 0 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.008824\n",
      "7475it [26:34,  4.23it/s]Train epoch: 0 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.007749\n",
      "7500it [26:40,  4.19it/s]Train epoch: 0 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.008255\n",
      "7525it [26:46,  4.21it/s]Train epoch: 0 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.007783\n",
      "7550it [26:52,  4.16it/s]Train epoch: 0 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.007667\n",
      "7575it [26:58,  4.23it/s]Train epoch: 0 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.008319\n",
      "7600it [27:04,  4.26it/s]Train epoch: 0 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.009859\n",
      "7625it [27:10,  4.24it/s]Train epoch: 0 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.009480\n",
      "7650it [27:16,  4.20it/s]Train epoch: 0 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.007886\n",
      "7675it [27:22,  4.27it/s]Train epoch: 0 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.007880\n",
      "7700it [27:28,  4.12it/s]Train epoch: 0 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.008142\n",
      "7725it [27:33,  4.22it/s]Train epoch: 0 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.008194\n",
      "7750it [27:39,  4.23it/s]Train epoch: 0 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.008356\n",
      "7775it [27:45,  4.08it/s]Train epoch: 0 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.007868\n",
      "7800it [27:51,  4.23it/s]Train epoch: 0 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.008003\n",
      "7825it [27:57,  4.18it/s]Train epoch: 0 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.008092\n",
      "7850it [28:03,  4.20it/s]Train epoch: 0 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.007837\n",
      "7875it [28:09,  4.14it/s]Train epoch: 0 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.008069\n",
      "7900it [28:15,  4.20it/s]Train epoch: 0 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.008248\n",
      "7925it [28:21,  4.09it/s]Train epoch: 0 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.008283\n",
      "7950it [28:27,  4.19it/s]Train epoch: 0 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.008773\n",
      "7975it [28:33,  4.14it/s]Train epoch: 0 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.008080\n",
      "8000it [28:39,  4.09it/s]Train epoch: 0 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.007825\n",
      "8025it [28:45,  4.19it/s]Train epoch: 0 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.008676\n",
      "8050it [28:51,  4.19it/s]Train epoch: 0 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.007449\n",
      "8075it [28:57,  4.13it/s]Train epoch: 0 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.008249\n",
      "8100it [29:03,  4.24it/s]Train epoch: 0 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.008397\n",
      "8125it [29:09,  4.19it/s]Train epoch: 0 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.008825\n",
      "8150it [29:15,  4.17it/s]Train epoch: 0 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.007881\n",
      "8175it [29:21,  4.12it/s]Train epoch: 0 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.008682\n",
      "8200it [29:27,  4.16it/s]Train epoch: 0 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.007981\n",
      "8225it [29:34,  4.17it/s]Train epoch: 0 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.009731\n",
      "8250it [29:40,  4.12it/s]Train epoch: 0 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.008151\n",
      "8275it [29:46,  4.12it/s]Train epoch: 0 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.009063\n",
      "8300it [29:52,  4.03it/s]Train epoch: 0 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.007935\n",
      "8325it [29:58,  4.11it/s]Train epoch: 0 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.008574\n",
      "8350it [30:04,  4.14it/s]Train epoch: 0 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.007850\n",
      "8375it [30:10,  4.16it/s]Train epoch: 0 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.008597\n",
      "8400it [30:16,  4.07it/s]Train epoch: 0 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.007897\n",
      "8425it [30:22,  4.08it/s]Train epoch: 0 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.008261\n",
      "8450it [30:28,  4.07it/s]Train epoch: 0 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.008512\n",
      "8475it [30:34,  4.00it/s]Train epoch: 0 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.008148\n",
      "8500it [30:41,  4.15it/s]Train epoch: 0 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.009160\n",
      "8525it [30:47,  4.10it/s]Train epoch: 0 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.008439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8550it [30:53,  4.03it/s]Train epoch: 0 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.008765\n",
      "8575it [30:59,  4.11it/s]Train epoch: 0 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.008220\n",
      "8600it [31:05,  4.10it/s]Train epoch: 0 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.008355\n",
      "8625it [31:11,  4.11it/s]Train epoch: 0 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.008472\n",
      "8650it [31:17,  4.05it/s]Train epoch: 0 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.008717\n",
      "8675it [31:24,  4.16it/s]Train epoch: 0 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.009497\n",
      "8700it [31:30,  4.04it/s]Train epoch: 0 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.009337\n",
      "8725it [31:36,  4.06it/s]Train epoch: 0 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.009302\n",
      "8750it [31:42,  4.05it/s]Train epoch: 0 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.008642\n",
      "8775it [31:48,  4.05it/s]Train epoch: 0 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.007950\n",
      "8800it [31:54,  4.08it/s]Train epoch: 0 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.008493\n",
      "8825it [32:00,  3.99it/s]Train epoch: 0 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.008411\n",
      "8850it [32:07,  3.96it/s]Train epoch: 0 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.008919\n",
      "8875it [32:13,  4.00it/s]Train epoch: 0 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.008373\n",
      "8900it [32:19,  3.99it/s]Train epoch: 0 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.008405\n",
      "8925it [32:25,  4.04it/s]Train epoch: 0 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.008586\n",
      "8950it [32:32,  4.04it/s]Train epoch: 0 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.009665\n",
      "8975it [32:38,  3.97it/s]Train epoch: 0 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.009311\n",
      "9000it [32:44,  4.01it/s]Train epoch: 0 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.008226\n",
      "9025it [32:50,  4.03it/s]Train epoch: 0 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.008654\n",
      "9050it [32:56,  3.99it/s]Train epoch: 0 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.008391\n",
      "9075it [33:03,  3.99it/s]Train epoch: 0 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.007491\n",
      "9100it [33:09,  3.94it/s]Train epoch: 0 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.008487\n",
      "9125it [33:15,  3.99it/s]Train epoch: 0 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.008173\n",
      "9150it [33:21,  3.99it/s]Train epoch: 0 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.007886\n",
      "9175it [33:28,  3.99it/s]Train epoch: 0 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.008389\n",
      "9200it [33:34,  4.00it/s]Train epoch: 0 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.008217\n",
      "9225it [33:40,  3.97it/s]Train epoch: 0 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.009655\n",
      "9250it [33:46,  3.99it/s]Train epoch: 0 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.008088\n",
      "9275it [33:53,  4.01it/s]Train epoch: 0 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.008933\n",
      "9300it [33:59,  3.96it/s]Train epoch: 0 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.009607\n",
      "9325it [34:05,  3.96it/s]Train epoch: 0 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.009497\n",
      "9350it [34:12,  3.94it/s]Train epoch: 0 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.009263\n",
      "9375it [34:18,  3.94it/s]Train epoch: 0 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.008674\n",
      "9400it [34:24,  3.93it/s]Train epoch: 0 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.008764\n",
      "9425it [34:31,  3.93it/s]Train epoch: 0 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.008291\n",
      "9450it [34:37,  3.90it/s]Train epoch: 0 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.008323\n",
      "9475it [34:43,  3.96it/s]Train epoch: 0 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.009517\n",
      "9500it [34:50,  3.92it/s]Train epoch: 0 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.008646\n",
      "9525it [34:56,  3.96it/s]Train epoch: 0 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.009063\n",
      "9550it [35:02,  3.95it/s]Train epoch: 0 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.008940\n",
      "9575it [35:09,  3.97it/s]Train epoch: 0 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.008985\n",
      "9600it [35:15,  3.91it/s]Train epoch: 0 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.008898\n",
      "9625it [35:21,  3.91it/s]Train epoch: 0 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.008346\n",
      "9650it [35:28,  3.94it/s]Train epoch: 0 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.008132\n",
      "9675it [35:34,  3.93it/s]Train epoch: 0 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.008867\n",
      "9700it [35:40,  3.91it/s]Train epoch: 0 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.008046\n",
      "9725it [35:47,  3.90it/s]Train epoch: 0 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.009001\n",
      "9750it [35:53,  3.88it/s]Train epoch: 0 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.008703\n",
      "9775it [36:00,  3.90it/s]Train epoch: 0 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.009506\n",
      "9800it [36:06,  3.91it/s]Train epoch: 0 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.009275\n",
      "9825it [36:13,  3.96it/s]Train epoch: 0 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.009182\n",
      "9850it [36:19,  3.79it/s]Train epoch: 0 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.008844\n",
      "9875it [36:25,  3.83it/s]Train epoch: 0 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.009604\n",
      "9900it [36:32,  3.92it/s]Train epoch: 0 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.010239\n",
      "9925it [36:38,  3.85it/s]Train epoch: 0 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.009586\n",
      "9950it [36:45,  3.90it/s]Train epoch: 0 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.009950\n",
      "9975it [36:51,  3.87it/s]Train epoch: 0 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.009276\n",
      "10000it [36:58,  3.90it/s]Train epoch: 0 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.008923\n",
      "10025it [37:04,  3.86it/s]Train epoch: 0 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.008881\n",
      "10050it [37:10,  3.80it/s]Train epoch: 0 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.009701\n",
      "10075it [37:17,  3.88it/s]Train epoch: 0 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.010182\n",
      "10100it [37:23,  3.89it/s]Train epoch: 0 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.009149\n",
      "10125it [37:30,  3.83it/s]Train epoch: 0 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.008970\n",
      "10150it [37:36,  3.74it/s]Train epoch: 0 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.009181\n",
      "10175it [37:43,  3.78it/s]Train epoch: 0 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.008770\n",
      "10200it [37:50,  3.80it/s]Train epoch: 0 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.009393\n",
      "10225it [37:56,  3.78it/s]Train epoch: 0 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.009489\n",
      "10250it [38:03,  3.88it/s]Train epoch: 0 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.009978\n",
      "10275it [38:09,  3.78it/s]Train epoch: 0 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.008944\n",
      "10300it [38:16,  3.75it/s]Train epoch: 0 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.009616\n",
      "10325it [38:23,  3.83it/s]Train epoch: 0 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.009599\n",
      "10350it [38:29,  3.83it/s]Train epoch: 0 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.009399\n",
      "10375it [38:36,  3.76it/s]Train epoch: 0 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.009669\n",
      "10400it [38:42,  3.77it/s]Train epoch: 0 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.009829\n",
      "10425it [38:49,  3.77it/s]Train epoch: 0 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.009352\n",
      "10450it [38:56,  3.69it/s]Train epoch: 0 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.009677\n",
      "10475it [39:03,  3.73it/s]Train epoch: 0 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.008627\n",
      "10500it [39:09,  3.76it/s]Train epoch: 0 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.009656\n",
      "10525it [39:16,  3.73it/s]Train epoch: 0 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.009192\n",
      "10550it [39:23,  3.72it/s]Train epoch: 0 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.009533\n",
      "10575it [39:29,  3.72it/s]Train epoch: 0 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.008931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10600it [39:36,  3.71it/s]Train epoch: 0 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.008830\n",
      "10625it [39:43,  3.73it/s]Train epoch: 0 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.009669\n",
      "10650it [39:50,  3.67it/s]Train epoch: 0 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.009144\n",
      "10675it [39:56,  3.71it/s]Train epoch: 0 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.009609\n",
      "10700it [40:03,  3.69it/s]Train epoch: 0 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.009101\n",
      "10725it [40:10,  3.68it/s]Train epoch: 0 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.008387\n",
      "10750it [40:17,  3.65it/s]Train epoch: 0 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.009625\n",
      "10775it [40:24,  3.62it/s]Train epoch: 0 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.009950\n",
      "10800it [40:30,  3.69it/s]Train epoch: 0 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.010370\n",
      "10825it [40:37,  3.64it/s]Train epoch: 0 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.009868\n",
      "10850it [40:44,  3.68it/s]Train epoch: 0 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.009758\n",
      "10875it [40:51,  3.64it/s]Train epoch: 0 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.010050\n",
      "10900it [40:58,  3.56it/s]Train epoch: 0 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.009565\n",
      "10925it [41:05,  3.61it/s]Train epoch: 0 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.009327\n",
      "10950it [41:12,  3.60it/s]Train epoch: 0 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.009468\n",
      "10975it [41:19,  3.62it/s]Train epoch: 0 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.009360\n",
      "11000it [41:26,  3.60it/s]Train epoch: 0 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.009346\n",
      "11025it [41:33,  3.56it/s]Train epoch: 0 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.009406\n",
      "11050it [41:40,  3.53it/s]Train epoch: 0 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.010308\n",
      "11075it [41:47,  3.62it/s]Train epoch: 0 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.010019\n",
      "11100it [41:54,  3.49it/s]Train epoch: 0 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.010602\n",
      "11125it [42:01,  3.54it/s]Train epoch: 0 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.010140\n",
      "11150it [42:08,  3.55it/s]Train epoch: 0 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.009736\n",
      "11175it [42:15,  3.53it/s]Train epoch: 0 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.010930\n",
      "11200it [42:22,  3.52it/s]Train epoch: 0 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.010047\n",
      "11225it [42:29,  3.49it/s]Train epoch: 0 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.009861\n",
      "11250it [42:36,  3.50it/s]Train epoch: 0 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.010787\n",
      "11275it [42:43,  3.50it/s]Train epoch: 0 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.010464\n",
      "11300it [42:50,  3.45it/s]Train epoch: 0 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.009520\n",
      "11325it [42:57,  3.46it/s]Train epoch: 0 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.010744\n",
      "11350it [43:05,  3.44it/s]Train epoch: 0 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.010878\n",
      "11375it [43:12,  3.44it/s]Train epoch: 0 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.011348\n",
      "11400it [43:19,  3.39it/s]Train epoch: 0 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.009851\n",
      "11425it [43:27,  3.36it/s]Train epoch: 0 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.010537\n",
      "11450it [43:34,  3.36it/s]Train epoch: 0 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.009779\n",
      "11475it [43:41,  3.33it/s]Train epoch: 0 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.011584\n",
      "11500it [43:49,  3.39it/s]Train epoch: 0 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.011060\n",
      "11525it [43:56,  3.38it/s]Train epoch: 0 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.010370\n",
      "11550it [44:04,  3.29it/s]Train epoch: 0 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.010404\n",
      "11575it [44:11,  3.35it/s]Train epoch: 0 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.011246\n",
      "11600it [44:19,  3.29it/s]Train epoch: 0 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.010613\n",
      "11625it [44:27,  3.29it/s]Train epoch: 0 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.009754\n",
      "11650it [44:34,  3.22it/s]Train epoch: 0 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.010657\n",
      "11675it [44:42,  3.24it/s]Train epoch: 0 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.011229\n",
      "11700it [44:50,  3.14it/s]Train epoch: 0 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.011698\n",
      "11725it [44:58,  3.11it/s]Train epoch: 0 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.011626\n",
      "11750it [45:06,  3.11it/s]Train epoch: 0 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.011721\n",
      "11775it [45:14,  3.07it/s]Train epoch: 0 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.011168\n",
      "11800it [45:23,  3.01it/s]Train epoch: 0 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.010874\n",
      "11825it [45:31,  2.93it/s]Train epoch: 0 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.011277\n",
      "11850it [45:40,  2.86it/s]Train epoch: 0 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.011232\n",
      "11875it [45:48,  2.77it/s]Train epoch: 0 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.012253\n",
      "11900it [45:58,  2.62it/s]Train epoch: 0 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.014637\n",
      "11925it [46:08,  2.33it/s]Train epoch: 0 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.012574\n",
      "11930it [46:10,  4.31it/s]\n",
      "epoch loss: 0.013437952432638598\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:54, 30.13it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0018, 0.0034, 0.0029, 0.0031, 0.7400\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1178, 0.4714, 0.1358, 0.2108, 0.9575\n",
      "rec_at_8: 0.1777\n",
      "prec_at_8: 0.3620\n",
      "rec_at_15: 0.2509\n",
      "prec_at_15: 0.2763\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:52, 30.02it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0018, 0.0038, 0.0028, 0.0032, 0.7341\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1157, 0.4722, 0.1329, 0.2075, 0.9563\n",
      "rec_at_8: 0.1700\n",
      "prec_at_8: 0.3620\n",
      "rec_at_15: 0.2400\n",
      "prec_at_15: 0.2782\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 0\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0018, 0.0034, 0.0029, 0.0031, 0.7400\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1178, 0.4714, 0.1358, 0.2108, 0.9575\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0090\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 0\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0018, 0.0038, 0.0028, 0.0032, 0.7341\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1157, 0.4722, 0.1329, 0.2075, 0.9563\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0093\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 1\n",
      "0it [00:00, ?it/s]Train epoch: 1 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.007758\n",
      "25it [00:04,  5.49it/s]Train epoch: 1 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.006409\n",
      "50it [00:09,  5.49it/s]Train epoch: 1 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.005742\n",
      "75it [00:13,  5.34it/s]Train epoch: 1 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.005013\n",
      "100it [00:18,  5.24it/s]Train epoch: 1 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.004937\n",
      "125it [00:22,  5.45it/s]Train epoch: 1 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.005139\n",
      "150it [00:27,  5.35it/s]Train epoch: 1 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.004644\n",
      "175it [00:32,  5.36it/s]Train epoch: 1 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.004998\n",
      "200it [00:37,  5.16it/s]Train epoch: 1 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.004517\n",
      "225it [00:41,  5.30it/s]Train epoch: 1 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.005639\n",
      "250it [00:46,  5.33it/s]Train epoch: 1 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.004747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275it [00:51,  5.20it/s]Train epoch: 1 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.004032\n",
      "300it [00:56,  5.23it/s]Train epoch: 1 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.005114\n",
      "325it [01:00,  5.28it/s]Train epoch: 1 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.004340\n",
      "350it [01:05,  5.29it/s]Train epoch: 1 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.005219\n",
      "375it [01:10,  5.24it/s]Train epoch: 1 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.004749\n",
      "400it [01:15,  5.26it/s]Train epoch: 1 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.004806\n",
      "425it [01:19,  5.07it/s]Train epoch: 1 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.004832\n",
      "450it [01:24,  5.31it/s]Train epoch: 1 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.004786\n",
      "475it [01:29,  5.20it/s]Train epoch: 1 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.005115\n",
      "500it [01:34,  5.17it/s]Train epoch: 1 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.004388\n",
      "525it [01:39,  5.12it/s]Train epoch: 1 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.005191\n",
      "550it [01:43,  5.13it/s]Train epoch: 1 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.004807\n",
      "575it [01:48,  5.24it/s]Train epoch: 1 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.004943\n",
      "600it [01:53,  5.13it/s]Train epoch: 1 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.005168\n",
      "625it [01:58,  5.12it/s]Train epoch: 1 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.004910\n",
      "650it [02:03,  5.12it/s]Train epoch: 1 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.004414\n",
      "675it [02:08,  5.11it/s]Train epoch: 1 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.003936\n",
      "700it [02:13,  5.11it/s]Train epoch: 1 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.004738\n",
      "725it [02:17,  5.18it/s]Train epoch: 1 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.004929\n",
      "750it [02:22,  5.02it/s]Train epoch: 1 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.004623\n",
      "775it [02:27,  5.09it/s]Train epoch: 1 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.005226\n",
      "800it [02:32,  5.14it/s]Train epoch: 1 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.005050\n",
      "825it [02:37,  5.05it/s]Train epoch: 1 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.004755\n",
      "850it [02:42,  5.12it/s]Train epoch: 1 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.005288\n",
      "875it [02:47,  5.14it/s]Train epoch: 1 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.004686\n",
      "900it [02:52,  5.09it/s]Train epoch: 1 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.004891\n",
      "925it [02:57,  5.05it/s]Train epoch: 1 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.004844\n",
      "950it [03:02,  5.03it/s]Train epoch: 1 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.004790\n",
      "975it [03:06,  5.04it/s]Train epoch: 1 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.003893\n",
      "1000it [03:11,  5.06it/s]Train epoch: 1 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.004986\n",
      "1025it [03:16,  5.05it/s]Train epoch: 1 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.006171\n",
      "1050it [03:21,  5.04it/s]Train epoch: 1 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.004504\n",
      "1075it [03:26,  5.03it/s]Train epoch: 1 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.005088\n",
      "1100it [03:31,  5.00it/s]Train epoch: 1 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.004990\n",
      "1125it [03:36,  5.06it/s]Train epoch: 1 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.005209\n",
      "1150it [03:41,  5.00it/s]Train epoch: 1 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.005338\n",
      "1175it [03:46,  5.04it/s]Train epoch: 1 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.005118\n",
      "1200it [03:51,  4.99it/s]Train epoch: 1 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.005144\n",
      "1225it [03:56,  5.01it/s]Train epoch: 1 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.005421\n",
      "1250it [04:01,  5.06it/s]Train epoch: 1 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.005167\n",
      "1275it [04:06,  5.09it/s]Train epoch: 1 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.004508\n",
      "1300it [04:11,  5.05it/s]Train epoch: 1 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.004626\n",
      "1325it [04:16,  4.96it/s]Train epoch: 1 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.004460\n",
      "1350it [04:21,  4.98it/s]Train epoch: 1 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.006018\n",
      "1375it [04:26,  4.98it/s]Train epoch: 1 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.004982\n",
      "1400it [04:31,  4.90it/s]Train epoch: 1 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.004781\n",
      "1425it [04:36,  4.91it/s]Train epoch: 1 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.004533\n",
      "1450it [04:41,  5.02it/s]Train epoch: 1 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.004650\n",
      "1475it [04:46,  5.00it/s]Train epoch: 1 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.005030\n",
      "1500it [04:51,  5.04it/s]Train epoch: 1 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.006324\n",
      "1525it [04:56,  4.93it/s]Train epoch: 1 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.005774\n",
      "1550it [05:01,  4.96it/s]Train epoch: 1 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.004778\n",
      "1575it [05:06,  5.00it/s]Train epoch: 1 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.005297\n",
      "1600it [05:11,  4.94it/s]Train epoch: 1 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.004621\n",
      "1625it [05:16,  4.96it/s]Train epoch: 1 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.005341\n",
      "1650it [05:21,  5.03it/s]Train epoch: 1 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.005429\n",
      "1675it [05:26,  4.96it/s]Train epoch: 1 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.005227\n",
      "1700it [05:31,  4.94it/s]Train epoch: 1 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.004757\n",
      "1725it [05:36,  4.87it/s]Train epoch: 1 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.004245\n",
      "1750it [05:41,  4.98it/s]Train epoch: 1 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.005968\n",
      "1775it [05:46,  4.96it/s]Train epoch: 1 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.005070\n",
      "1800it [05:52,  4.92it/s]Train epoch: 1 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.004787\n",
      "1825it [05:57,  4.99it/s]Train epoch: 1 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.004312\n",
      "1850it [06:02,  4.97it/s]Train epoch: 1 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.005187\n",
      "1875it [06:07,  4.99it/s]Train epoch: 1 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.005380\n",
      "1900it [06:12,  4.93it/s]Train epoch: 1 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.004314\n",
      "1925it [06:17,  4.90it/s]Train epoch: 1 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.004551\n",
      "1950it [06:22,  4.94it/s]Train epoch: 1 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.004565\n",
      "1975it [06:27,  4.93it/s]Train epoch: 1 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.005306\n",
      "2000it [06:32,  4.82it/s]Train epoch: 1 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.004265\n",
      "2025it [06:37,  5.01it/s]Train epoch: 1 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.005297\n",
      "2050it [06:42,  4.94it/s]Train epoch: 1 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.004786\n",
      "2075it [06:47,  4.92it/s]Train epoch: 1 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.004922\n",
      "2100it [06:53,  4.85it/s]Train epoch: 1 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.005179\n",
      "2125it [06:58,  4.93it/s]Train epoch: 1 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.005575\n",
      "2150it [07:03,  4.93it/s]Train epoch: 1 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.004717\n",
      "2175it [07:08,  4.92it/s]Train epoch: 1 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.005573\n",
      "2200it [07:13,  4.92it/s]Train epoch: 1 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.005214\n",
      "2225it [07:18,  4.98it/s]Train epoch: 1 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.005060\n",
      "2250it [07:23,  4.91it/s]Train epoch: 1 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.004709\n",
      "2275it [07:28,  4.88it/s]Train epoch: 1 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.005283\n",
      "2300it [07:33,  4.86it/s]Train epoch: 1 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.004005\n",
      "2325it [07:38,  4.94it/s]Train epoch: 1 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.005092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350it [07:44,  4.86it/s]Train epoch: 1 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.004630\n",
      "2375it [07:49,  4.83it/s]Train epoch: 1 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.006385\n",
      "2400it [07:54,  4.89it/s]Train epoch: 1 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.006099\n",
      "2425it [07:59,  4.62it/s]Train epoch: 1 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.004456\n",
      "2450it [08:04,  4.91it/s]Train epoch: 1 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.004936\n",
      "2475it [08:09,  4.90it/s]Train epoch: 1 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.005406\n",
      "2500it [08:15,  4.84it/s]Train epoch: 1 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.004865\n",
      "2525it [08:20,  4.83it/s]Train epoch: 1 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.004863\n",
      "2550it [08:25,  4.84it/s]Train epoch: 1 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.006289\n",
      "2575it [08:30,  4.86it/s]Train epoch: 1 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.004571\n",
      "2600it [08:35,  4.91it/s]Train epoch: 1 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.005113\n",
      "2625it [08:40,  4.86it/s]Train epoch: 1 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.004971\n",
      "2650it [08:46,  4.85it/s]Train epoch: 1 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.005583\n",
      "2675it [08:51,  4.76it/s]Train epoch: 1 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.005244\n",
      "2700it [08:56,  4.79it/s]Train epoch: 1 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.004753\n",
      "2725it [09:01,  4.81it/s]Train epoch: 1 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.005063\n",
      "2750it [09:06,  4.92it/s]Train epoch: 1 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.005953\n",
      "2775it [09:12,  4.74it/s]Train epoch: 1 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.005269\n",
      "2800it [09:17,  4.71it/s]Train epoch: 1 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.004853\n",
      "2825it [09:22,  4.83it/s]Train epoch: 1 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.005408\n",
      "2850it [09:27,  4.82it/s]Train epoch: 1 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.005091\n",
      "2875it [09:33,  4.88it/s]Train epoch: 1 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.005545\n",
      "2900it [09:38,  4.78it/s]Train epoch: 1 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.005550\n",
      "2925it [09:43,  4.75it/s]Train epoch: 1 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.005407\n",
      "2950it [09:48,  4.76it/s]Train epoch: 1 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.005633\n",
      "2975it [09:53,  4.77it/s]Train epoch: 1 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.005381\n",
      "3000it [09:59,  4.80it/s]Train epoch: 1 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.005888\n",
      "3025it [10:04,  4.79it/s]Train epoch: 1 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.005661\n",
      "3050it [10:09,  4.77it/s]Train epoch: 1 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.005030\n",
      "3075it [10:14,  4.72it/s]Train epoch: 1 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.005659\n",
      "3100it [10:20,  4.74it/s]Train epoch: 1 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.005870\n",
      "3125it [10:25,  4.77it/s]Train epoch: 1 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.005238\n",
      "3150it [10:30,  4.75it/s]Train epoch: 1 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.005140\n",
      "3175it [10:36,  4.75it/s]Train epoch: 1 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.004968\n",
      "3200it [10:41,  4.68it/s]Train epoch: 1 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.005720\n",
      "3225it [10:46,  4.74it/s]Train epoch: 1 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.005490\n",
      "3250it [10:51,  4.81it/s]Train epoch: 1 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.005577\n",
      "3275it [10:57,  4.77it/s]Train epoch: 1 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.005327\n",
      "3300it [11:02,  4.76it/s]Train epoch: 1 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.006284\n",
      "3325it [11:07,  4.74it/s]Train epoch: 1 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.005465\n",
      "3350it [11:12,  4.72it/s]Train epoch: 1 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.005337\n",
      "3375it [11:18,  4.65it/s]Train epoch: 1 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.006049\n",
      "3400it [11:23,  4.76it/s]Train epoch: 1 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.005822\n",
      "3425it [11:28,  4.72it/s]Train epoch: 1 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.005249\n",
      "3450it [11:34,  4.73it/s]Train epoch: 1 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.005987\n",
      "3475it [11:39,  4.70it/s]Train epoch: 1 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.005372\n",
      "3500it [11:44,  4.72it/s]Train epoch: 1 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.005434\n",
      "3525it [11:50,  4.72it/s]Train epoch: 1 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.005687\n",
      "3550it [11:55,  4.75it/s]Train epoch: 1 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.005965\n",
      "3575it [12:00,  4.78it/s]Train epoch: 1 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.004959\n",
      "3600it [12:05,  4.63it/s]Train epoch: 1 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.006079\n",
      "3625it [12:11,  4.71it/s]Train epoch: 1 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.005731\n",
      "3650it [12:16,  4.68it/s]Train epoch: 1 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.005681\n",
      "3675it [12:21,  4.69it/s]Train epoch: 1 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.005935\n",
      "3700it [12:27,  4.65it/s]Train epoch: 1 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.006035\n",
      "3725it [12:32,  4.64it/s]Train epoch: 1 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.005989\n",
      "3750it [12:37,  4.70it/s]Train epoch: 1 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.006051\n",
      "3775it [12:43,  4.65it/s]Train epoch: 1 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.005724\n",
      "3800it [12:48,  4.63it/s]Train epoch: 1 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.006387\n",
      "3825it [12:53,  4.67it/s]Train epoch: 1 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.005482\n",
      "3850it [12:59,  4.68it/s]Train epoch: 1 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.005136\n",
      "3875it [13:04,  4.65it/s]Train epoch: 1 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.005029\n",
      "3900it [13:09,  4.61it/s]Train epoch: 1 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.006303\n",
      "3925it [13:15,  4.64it/s]Train epoch: 1 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.005680\n",
      "3950it [13:20,  4.62it/s]Train epoch: 1 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.006258\n",
      "3975it [13:26,  4.69it/s]Train epoch: 1 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.007148\n",
      "4000it [13:31,  4.70it/s]Train epoch: 1 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.005217\n",
      "4025it [13:36,  4.68it/s]Train epoch: 1 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.006342\n",
      "4050it [13:42,  4.64it/s]Train epoch: 1 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.006036\n",
      "4075it [13:47,  4.58it/s]Train epoch: 1 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.006004\n",
      "4100it [13:53,  4.66it/s]Train epoch: 1 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.006658\n",
      "4125it [13:58,  4.66it/s]Train epoch: 1 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.006344\n",
      "4150it [14:03,  4.68it/s]Train epoch: 1 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.005449\n",
      "4175it [14:09,  4.62it/s]Train epoch: 1 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.005746\n",
      "4200it [14:14,  4.67it/s]Train epoch: 1 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.006349\n",
      "4225it [14:20,  4.61it/s]Train epoch: 1 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.005312\n",
      "4250it [14:25,  4.62it/s]Train epoch: 1 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.006262\n",
      "4275it [14:30,  4.60it/s]Train epoch: 1 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.005798\n",
      "4300it [14:36,  4.62it/s]Train epoch: 1 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.006355\n",
      "4325it [14:41,  4.62it/s]Train epoch: 1 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.005654\n",
      "4350it [14:47,  4.64it/s]Train epoch: 1 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.006207\n",
      "4375it [14:52,  4.57it/s]Train epoch: 1 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.005828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400it [14:57,  4.60it/s]Train epoch: 1 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.005212\n",
      "4425it [15:03,  4.59it/s]Train epoch: 1 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.006089\n",
      "4450it [15:08,  4.57it/s]Train epoch: 1 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.004872\n",
      "4475it [15:14,  4.51it/s]Train epoch: 1 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.006275\n",
      "4500it [15:19,  4.60it/s]Train epoch: 1 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.007067\n",
      "4525it [15:25,  4.50it/s]Train epoch: 1 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.006149\n",
      "4550it [15:30,  4.61it/s]Train epoch: 1 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.005819\n",
      "4575it [15:35,  4.57it/s]Train epoch: 1 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.006558\n",
      "4600it [15:41,  4.59it/s]Train epoch: 1 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.005583\n",
      "4625it [15:46,  4.63it/s]Train epoch: 1 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.005846\n",
      "4650it [15:52,  4.60it/s]Train epoch: 1 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.006425\n",
      "4675it [15:57,  4.64it/s]Train epoch: 1 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.006187\n",
      "4700it [16:03,  4.61it/s]Train epoch: 1 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.005549\n",
      "4725it [16:08,  4.59it/s]Train epoch: 1 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.005868\n",
      "4750it [16:14,  4.57it/s]Train epoch: 1 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.006787\n",
      "4775it [16:19,  4.58it/s]Train epoch: 1 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.005968\n",
      "4800it [16:24,  4.58it/s]Train epoch: 1 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.006236\n",
      "4825it [16:30,  4.51it/s]Train epoch: 1 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.005555\n",
      "4850it [16:36,  4.51it/s]Train epoch: 1 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.006523\n",
      "4875it [16:41,  4.57it/s]Train epoch: 1 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.005464\n",
      "4900it [16:47,  4.57it/s]Train epoch: 1 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.006144\n",
      "4925it [16:52,  4.47it/s]Train epoch: 1 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.005538\n",
      "4950it [16:58,  4.54it/s]Train epoch: 1 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.005911\n",
      "4975it [17:03,  4.55it/s]Train epoch: 1 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.006034\n",
      "5000it [17:09,  4.34it/s]Train epoch: 1 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.006082\n",
      "5025it [17:14,  4.55it/s]Train epoch: 1 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.005699\n",
      "5050it [17:20,  4.45it/s]Train epoch: 1 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.005654\n",
      "5075it [17:25,  4.50it/s]Train epoch: 1 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.005861\n",
      "5100it [17:31,  4.44it/s]Train epoch: 1 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.005949\n",
      "5125it [17:36,  4.54it/s]Train epoch: 1 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.006354\n",
      "5150it [17:42,  4.51it/s]Train epoch: 1 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.006077\n",
      "5175it [17:47,  4.47it/s]Train epoch: 1 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.006253\n",
      "5200it [17:53,  4.61it/s]Train epoch: 1 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.005605\n",
      "5225it [17:59,  4.44it/s]Train epoch: 1 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.006248\n",
      "5250it [18:04,  4.53it/s]Train epoch: 1 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.005937\n",
      "5275it [18:10,  4.37it/s]Train epoch: 1 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.005927\n",
      "5300it [18:15,  4.48it/s]Train epoch: 1 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.005551\n",
      "5325it [18:21,  4.54it/s]Train epoch: 1 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.006587\n",
      "5350it [18:26,  4.49it/s]Train epoch: 1 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.006596\n",
      "5375it [18:32,  4.44it/s]Train epoch: 1 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.005719\n",
      "5400it [18:38,  4.39it/s]Train epoch: 1 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.005846\n",
      "5425it [18:43,  4.46it/s]Train epoch: 1 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.006146\n",
      "5450it [18:49,  4.48it/s]Train epoch: 1 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.006198\n",
      "5475it [18:54,  4.39it/s]Train epoch: 1 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.007096\n",
      "5500it [19:00,  4.52it/s]Train epoch: 1 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.006671\n",
      "5525it [19:05,  4.48it/s]Train epoch: 1 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.005478\n",
      "5550it [19:11,  4.40it/s]Train epoch: 1 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.006112\n",
      "5575it [19:17,  4.39it/s]Train epoch: 1 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.006286\n",
      "5600it [19:22,  4.47it/s]Train epoch: 1 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.006756\n",
      "5625it [19:28,  4.48it/s]Train epoch: 1 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.006267\n",
      "5650it [19:34,  4.49it/s]Train epoch: 1 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.005589\n",
      "5675it [19:39,  4.42it/s]Train epoch: 1 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.006828\n",
      "5700it [19:45,  4.45it/s]Train epoch: 1 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.005744\n",
      "5725it [19:50,  4.48it/s]Train epoch: 1 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.006138\n",
      "5750it [19:56,  4.44it/s]Train epoch: 1 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.007652\n",
      "5775it [20:02,  4.48it/s]Train epoch: 1 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.006553\n",
      "5800it [20:07,  4.44it/s]Train epoch: 1 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.006556\n",
      "5825it [20:13,  4.39it/s]Train epoch: 1 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.005678\n",
      "5850it [20:19,  4.41it/s]Train epoch: 1 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.007098\n",
      "5875it [20:24,  4.50it/s]Train epoch: 1 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.006803\n",
      "5900it [20:30,  4.42it/s]Train epoch: 1 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.007071\n",
      "5925it [20:36,  4.43it/s]Train epoch: 1 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.005854\n",
      "5950it [20:41,  4.42it/s]Train epoch: 1 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.005696\n",
      "5975it [20:47,  4.41it/s]Train epoch: 1 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.007584\n",
      "6000it [20:52,  4.50it/s]Train epoch: 1 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.006432\n",
      "6025it [20:58,  4.39it/s]Train epoch: 1 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.006885\n",
      "6050it [21:04,  4.42it/s]Train epoch: 1 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.006155\n",
      "6075it [21:10,  4.42it/s]Train epoch: 1 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.006011\n",
      "6100it [21:15,  4.38it/s]Train epoch: 1 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.005608\n",
      "6125it [21:21,  4.39it/s]Train epoch: 1 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.006247\n",
      "6150it [21:27,  4.38it/s]Train epoch: 1 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.006133\n",
      "6175it [21:32,  4.40it/s]Train epoch: 1 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.006872\n",
      "6200it [21:38,  4.37it/s]Train epoch: 1 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.006268\n",
      "6225it [21:44,  4.45it/s]Train epoch: 1 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.005554\n",
      "6250it [21:49,  4.36it/s]Train epoch: 1 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.006043\n",
      "6275it [21:55,  4.39it/s]Train epoch: 1 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.005638\n",
      "6300it [22:01,  4.37it/s]Train epoch: 1 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.006583\n",
      "6325it [22:06,  4.36it/s]Train epoch: 1 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.006785\n",
      "6350it [22:12,  4.38it/s]Train epoch: 1 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.006936\n",
      "6375it [22:18,  4.38it/s]Train epoch: 1 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.005902\n",
      "6400it [22:24,  4.36it/s]Train epoch: 1 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.006127\n",
      "6425it [22:29,  4.35it/s]Train epoch: 1 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.006966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6450it [22:35,  4.36it/s]Train epoch: 1 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.006486\n",
      "6475it [22:41,  4.39it/s]Train epoch: 1 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.006072\n",
      "6500it [22:47,  4.29it/s]Train epoch: 1 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.006844\n",
      "6525it [22:52,  4.35it/s]Train epoch: 1 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.005875\n",
      "6550it [22:58,  4.37it/s]Train epoch: 1 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.006130\n",
      "6575it [23:04,  4.34it/s]Train epoch: 1 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.006406\n",
      "6600it [23:10,  4.42it/s]Train epoch: 1 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.007341\n",
      "6625it [23:15,  4.32it/s]Train epoch: 1 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.006129\n",
      "6650it [23:21,  4.42it/s]Train epoch: 1 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.007187\n",
      "6675it [23:27,  4.37it/s]Train epoch: 1 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.006405\n",
      "6700it [23:32,  4.31it/s]Train epoch: 1 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.006722\n",
      "6725it [23:38,  4.32it/s]Train epoch: 1 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.006707\n",
      "6750it [23:44,  4.37it/s]Train epoch: 1 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.006195\n",
      "6775it [23:50,  4.34it/s]Train epoch: 1 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.006989\n",
      "6800it [23:56,  4.39it/s]Train epoch: 1 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.006757\n",
      "6825it [24:01,  4.35it/s]Train epoch: 1 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.007022\n",
      "6850it [24:07,  4.35it/s]Train epoch: 1 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.006444\n",
      "6875it [24:13,  4.26it/s]Train epoch: 1 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.005592\n",
      "6900it [24:19,  4.29it/s]Train epoch: 1 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.006543\n",
      "6925it [24:24,  4.29it/s]Train epoch: 1 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.006411\n",
      "6950it [24:30,  4.29it/s]Train epoch: 1 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.007144\n",
      "6975it [24:36,  4.37it/s]Train epoch: 1 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.006777\n",
      "7000it [24:42,  4.32it/s]Train epoch: 1 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.006421\n",
      "7025it [24:48,  4.39it/s]Train epoch: 1 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.007447\n",
      "7050it [24:54,  4.32it/s]Train epoch: 1 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.005860\n",
      "7075it [24:59,  4.29it/s]Train epoch: 1 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.006718\n",
      "7100it [25:05,  4.28it/s]Train epoch: 1 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.006822\n",
      "7125it [25:11,  4.26it/s]Train epoch: 1 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.005977\n",
      "7150it [25:17,  4.29it/s]Train epoch: 1 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.007198\n",
      "7175it [25:23,  4.30it/s]Train epoch: 1 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.006624\n",
      "7200it [25:28,  4.33it/s]Train epoch: 1 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.007132\n",
      "7225it [25:34,  4.16it/s]Train epoch: 1 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.006341\n",
      "7250it [25:40,  4.32it/s]Train epoch: 1 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.006556\n",
      "7275it [25:46,  4.29it/s]Train epoch: 1 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.007184\n",
      "7300it [25:52,  4.28it/s]Train epoch: 1 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.007443\n",
      "7325it [25:58,  4.26it/s]Train epoch: 1 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.006389\n",
      "7350it [26:04,  4.26it/s]Train epoch: 1 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.007386\n",
      "7375it [26:09,  4.29it/s]Train epoch: 1 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.006781\n",
      "7400it [26:15,  4.27it/s]Train epoch: 1 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.006199\n",
      "7425it [26:21,  4.24it/s]Train epoch: 1 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.006793\n",
      "7450it [26:27,  4.26it/s]Train epoch: 1 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.007523\n",
      "7475it [26:33,  4.26it/s]Train epoch: 1 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.006542\n",
      "7500it [26:39,  4.22it/s]Train epoch: 1 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.007007\n",
      "7525it [26:45,  4.20it/s]Train epoch: 1 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.006517\n",
      "7550it [26:51,  4.21it/s]Train epoch: 1 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.006402\n",
      "7575it [26:56,  4.20it/s]Train epoch: 1 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.007068\n",
      "7600it [27:02,  4.22it/s]Train epoch: 1 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.008288\n",
      "7625it [27:08,  4.27it/s]Train epoch: 1 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.007734\n",
      "7650it [27:14,  4.23it/s]Train epoch: 1 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.006591\n",
      "7675it [27:20,  4.24it/s]Train epoch: 1 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.006752\n",
      "7700it [27:26,  4.24it/s]Train epoch: 1 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.006793\n",
      "7725it [27:32,  4.18it/s]Train epoch: 1 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.006829\n",
      "7750it [27:38,  4.22it/s]Train epoch: 1 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.007040\n",
      "7775it [27:44,  4.22it/s]Train epoch: 1 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.006497\n",
      "7800it [27:50,  4.21it/s]Train epoch: 1 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.006629\n",
      "7825it [27:56,  4.24it/s]Train epoch: 1 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.006905\n",
      "7850it [28:02,  4.20it/s]Train epoch: 1 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.006353\n",
      "7875it [28:08,  4.17it/s]Train epoch: 1 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.006741\n",
      "7900it [28:14,  4.16it/s]Train epoch: 1 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.007015\n",
      "7925it [28:20,  4.22it/s]Train epoch: 1 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.006868\n",
      "7950it [28:26,  4.19it/s]Train epoch: 1 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.007449\n",
      "7975it [28:32,  4.18it/s]Train epoch: 1 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.006926\n",
      "8000it [28:38,  4.17it/s]Train epoch: 1 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.006636\n",
      "8025it [28:44,  4.19it/s]Train epoch: 1 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.007353\n",
      "8050it [28:49,  4.15it/s]Train epoch: 1 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.006236\n",
      "8075it [28:55,  4.17it/s]Train epoch: 1 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.006931\n",
      "8100it [29:01,  4.15it/s]Train epoch: 1 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.007163\n",
      "8125it [29:07,  4.15it/s]Train epoch: 1 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.007423\n",
      "8150it [29:13,  4.13it/s]Train epoch: 1 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.006545\n",
      "8175it [29:19,  4.16it/s]Train epoch: 1 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.007303\n",
      "8200it [29:25,  4.16it/s]Train epoch: 1 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.006690\n",
      "8225it [29:32,  4.13it/s]Train epoch: 1 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.008160\n",
      "8250it [29:38,  4.11it/s]Train epoch: 1 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.006789\n",
      "8275it [29:44,  4.15it/s]Train epoch: 1 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.007613\n",
      "8300it [29:50,  4.15it/s]Train epoch: 1 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.006653\n",
      "8325it [29:56,  4.14it/s]Train epoch: 1 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.007348\n",
      "8350it [30:02,  4.10it/s]Train epoch: 1 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.006575\n",
      "8375it [30:08,  4.16it/s]Train epoch: 1 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.007262\n",
      "8400it [30:14,  4.12it/s]Train epoch: 1 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.006698\n",
      "8425it [30:20,  4.17it/s]Train epoch: 1 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.007035\n",
      "8450it [30:26,  4.13it/s]Train epoch: 1 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.007201\n",
      "8475it [30:32,  4.13it/s]Train epoch: 1 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.006955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500it [30:38,  4.12it/s]Train epoch: 1 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.007864\n",
      "8525it [30:44,  4.12it/s]Train epoch: 1 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.006975\n",
      "8550it [30:50,  4.05it/s]Train epoch: 1 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.007445\n",
      "8575it [30:56,  4.13it/s]Train epoch: 1 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.006891\n",
      "8600it [31:02,  4.16it/s]Train epoch: 1 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.006994\n",
      "8625it [31:08,  4.10it/s]Train epoch: 1 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.007047\n",
      "8650it [31:14,  4.04it/s]Train epoch: 1 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.007340\n",
      "8675it [31:20,  4.12it/s]Train epoch: 1 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.007974\n",
      "8700it [31:27,  4.08it/s]Train epoch: 1 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.008161\n",
      "8725it [31:33,  4.14it/s]Train epoch: 1 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.007742\n",
      "8750it [31:39,  4.09it/s]Train epoch: 1 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.007414\n",
      "8775it [31:45,  4.03it/s]Train epoch: 1 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.006710\n",
      "8800it [31:51,  4.04it/s]Train epoch: 1 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.007059\n",
      "8825it [31:57,  4.05it/s]Train epoch: 1 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.007101\n",
      "8850it [32:03,  4.09it/s]Train epoch: 1 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.007330\n",
      "8875it [32:09,  4.06it/s]Train epoch: 1 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.007105\n",
      "8900it [32:16,  4.01it/s]Train epoch: 1 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.007088\n",
      "8925it [32:22,  4.04it/s]Train epoch: 1 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.007428\n",
      "8950it [32:28,  4.07it/s]Train epoch: 1 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.008237\n",
      "8975it [32:34,  4.12it/s]Train epoch: 1 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.007897\n",
      "9000it [32:40,  4.03it/s]Train epoch: 1 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.007026\n",
      "9025it [32:46,  4.11it/s]Train epoch: 1 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.007357\n",
      "9050it [32:53,  4.04it/s]Train epoch: 1 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.006965\n",
      "9075it [32:59,  4.05it/s]Train epoch: 1 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.006438\n",
      "9100it [33:05,  4.08it/s]Train epoch: 1 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.007295\n",
      "9125it [33:11,  3.90it/s]Train epoch: 1 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.006967\n",
      "9150it [33:17,  4.07it/s]Train epoch: 1 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.006526\n",
      "9175it [33:23,  4.02it/s]Train epoch: 1 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.007065\n",
      "9200it [33:30,  4.04it/s]Train epoch: 1 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.006966\n",
      "9225it [33:36,  4.04it/s]Train epoch: 1 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.008179\n",
      "9250it [33:42,  4.09it/s]Train epoch: 1 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.007037\n",
      "9275it [33:48,  4.00it/s]Train epoch: 1 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.007647\n",
      "9300it [33:54,  4.04it/s]Train epoch: 1 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.008405\n",
      "9325it [34:01,  3.97it/s]Train epoch: 1 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.008232\n",
      "9350it [34:07,  3.98it/s]Train epoch: 1 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.007973\n",
      "9375it [34:13,  3.97it/s]Train epoch: 1 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.007374\n",
      "9400it [34:20,  3.97it/s]Train epoch: 1 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.007465\n",
      "9425it [34:26,  4.03it/s]Train epoch: 1 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.007143\n",
      "9450it [34:32,  3.97it/s]Train epoch: 1 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.007181\n",
      "9475it [34:38,  3.98it/s]Train epoch: 1 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.008121\n",
      "9500it [34:45,  3.95it/s]Train epoch: 1 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.007545\n",
      "9525it [34:51,  4.05it/s]Train epoch: 1 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.007950\n",
      "9550it [34:57,  3.96it/s]Train epoch: 1 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.007804\n",
      "9575it [35:04,  4.03it/s]Train epoch: 1 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.007781\n",
      "9600it [35:10,  4.05it/s]Train epoch: 1 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.007499\n",
      "9625it [35:16,  3.97it/s]Train epoch: 1 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.006974\n",
      "9650it [35:23,  3.96it/s]Train epoch: 1 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.007109\n",
      "9675it [35:29,  3.94it/s]Train epoch: 1 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.007562\n",
      "9700it [35:35,  3.91it/s]Train epoch: 1 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.006936\n",
      "9725it [35:42,  3.96it/s]Train epoch: 1 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.007858\n",
      "9750it [35:48,  3.92it/s]Train epoch: 1 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.007452\n",
      "9775it [35:54,  3.88it/s]Train epoch: 1 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.008410\n",
      "9800it [36:01,  3.91it/s]Train epoch: 1 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.008135\n",
      "9825it [36:07,  3.89it/s]Train epoch: 1 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.008049\n",
      "9850it [36:13,  3.93it/s]Train epoch: 1 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.007688\n",
      "9875it [36:20,  3.96it/s]Train epoch: 1 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.008201\n",
      "9900it [36:26,  3.81it/s]Train epoch: 1 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.008691\n",
      "9925it [36:33,  3.93it/s]Train epoch: 1 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.008148\n",
      "9950it [36:39,  3.86it/s]Train epoch: 1 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.008670\n",
      "9975it [36:46,  3.89it/s]Train epoch: 1 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.008069\n",
      "10000it [36:52,  3.94it/s]Train epoch: 1 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.007663\n",
      "10025it [36:58,  3.95it/s]Train epoch: 1 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.007807\n",
      "10050it [37:05,  3.91it/s]Train epoch: 1 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.008310\n",
      "10075it [37:11,  3.93it/s]Train epoch: 1 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.008837\n",
      "10100it [37:18,  3.88it/s]Train epoch: 1 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.007966\n",
      "10125it [37:24,  3.87it/s]Train epoch: 1 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.007617\n",
      "10150it [37:31,  3.89it/s]Train epoch: 1 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.008039\n",
      "10175it [37:37,  3.84it/s]Train epoch: 1 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.007578\n",
      "10200it [37:44,  3.89it/s]Train epoch: 1 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.008130\n",
      "10225it [37:50,  3.82it/s]Train epoch: 1 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.008127\n",
      "10250it [37:57,  3.76it/s]Train epoch: 1 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.008626\n",
      "10275it [38:03,  3.88it/s]Train epoch: 1 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.007846\n",
      "10300it [38:10,  3.81it/s]Train epoch: 1 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.008387\n",
      "10325it [38:17,  3.82it/s]Train epoch: 1 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.008389\n",
      "10350it [38:23,  3.83it/s]Train epoch: 1 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.008184\n",
      "10375it [38:30,  3.87it/s]Train epoch: 1 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.008341\n",
      "10400it [38:36,  3.71it/s]Train epoch: 1 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.008445\n",
      "10425it [38:43,  3.76it/s]Train epoch: 1 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.007959\n",
      "10450it [38:50,  3.74it/s]Train epoch: 1 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.008357\n",
      "10475it [38:56,  3.74it/s]Train epoch: 1 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.007391\n",
      "10500it [39:03,  3.80it/s]Train epoch: 1 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.008363\n",
      "10525it [39:09,  3.79it/s]Train epoch: 1 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.007891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10550it [39:16,  3.74it/s]Train epoch: 1 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.008291\n",
      "10575it [39:23,  3.73it/s]Train epoch: 1 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.007727\n",
      "10600it [39:30,  3.74it/s]Train epoch: 1 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.007485\n",
      "10625it [39:36,  3.72it/s]Train epoch: 1 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.008416\n",
      "10650it [39:43,  3.69it/s]Train epoch: 1 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.007803\n",
      "10675it [39:50,  3.69it/s]Train epoch: 1 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.008413\n",
      "10700it [39:56,  3.69it/s]Train epoch: 1 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.007865\n",
      "10725it [40:03,  3.69it/s]Train epoch: 1 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.007278\n",
      "10750it [40:10,  3.73it/s]Train epoch: 1 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.008511\n",
      "10775it [40:17,  3.70it/s]Train epoch: 1 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.008595\n",
      "10800it [40:24,  3.68it/s]Train epoch: 1 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.008921\n",
      "10825it [40:30,  3.66it/s]Train epoch: 1 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.008644\n",
      "10850it [40:37,  3.68it/s]Train epoch: 1 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.008612\n",
      "10875it [40:44,  3.64it/s]Train epoch: 1 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.008828\n",
      "10900it [40:51,  3.69it/s]Train epoch: 1 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.008305\n",
      "10925it [40:58,  3.65it/s]Train epoch: 1 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.008091\n",
      "10950it [41:05,  3.63it/s]Train epoch: 1 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.008437\n",
      "10975it [41:12,  3.62it/s]Train epoch: 1 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.008202\n",
      "11000it [41:18,  3.60it/s]Train epoch: 1 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.008058\n",
      "11025it [41:25,  3.61it/s]Train epoch: 1 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.008234\n",
      "11050it [41:32,  3.59it/s]Train epoch: 1 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.009093\n",
      "11075it [41:39,  3.60it/s]Train epoch: 1 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.008660\n",
      "11100it [41:46,  3.57it/s]Train epoch: 1 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.009271\n",
      "11125it [41:53,  3.56it/s]Train epoch: 1 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.008764\n",
      "11150it [42:00,  3.52it/s]Train epoch: 1 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.008446\n",
      "11175it [42:07,  3.55it/s]Train epoch: 1 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.009772\n",
      "11200it [42:14,  3.53it/s]Train epoch: 1 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.008827\n",
      "11225it [42:21,  3.53it/s]Train epoch: 1 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.008664\n",
      "11250it [42:29,  3.50it/s]Train epoch: 1 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.009544\n",
      "11275it [42:36,  3.53it/s]Train epoch: 1 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.009189\n",
      "11300it [42:43,  3.51it/s]Train epoch: 1 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.008318\n",
      "11325it [42:50,  3.48it/s]Train epoch: 1 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.009596\n",
      "11350it [42:57,  3.45it/s]Train epoch: 1 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.009562\n",
      "11375it [43:04,  3.39it/s]Train epoch: 1 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.009924\n",
      "11400it [43:12,  3.37it/s]Train epoch: 1 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.008522\n",
      "11425it [43:19,  3.40it/s]Train epoch: 1 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.009172\n",
      "11450it [43:26,  3.42it/s]Train epoch: 1 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.008533\n",
      "11475it [43:34,  3.41it/s]Train epoch: 1 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.010202\n",
      "11500it [43:41,  3.38it/s]Train epoch: 1 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.009723\n",
      "11525it [43:49,  3.33it/s]Train epoch: 1 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.009073\n",
      "11550it [43:56,  3.34it/s]Train epoch: 1 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.009045\n",
      "11575it [44:04,  3.30it/s]Train epoch: 1 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.010118\n",
      "11600it [44:11,  3.29it/s]Train epoch: 1 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.009386\n",
      "11625it [44:19,  3.28it/s]Train epoch: 1 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.008709\n",
      "11650it [44:27,  3.25it/s]Train epoch: 1 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.009549\n",
      "11675it [44:34,  3.23it/s]Train epoch: 1 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.010036\n",
      "11700it [44:42,  3.15it/s]Train epoch: 1 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.010364\n",
      "11725it [44:50,  3.14it/s]Train epoch: 1 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.010442\n",
      "11750it [44:58,  3.11it/s]Train epoch: 1 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.010205\n",
      "11775it [45:06,  3.09it/s]Train epoch: 1 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.009982\n",
      "11800it [45:14,  3.03it/s]Train epoch: 1 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.009703\n",
      "11825it [45:23,  2.95it/s]Train epoch: 1 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.010130\n",
      "11850it [45:31,  2.89it/s]Train epoch: 1 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.010062\n",
      "11875it [45:40,  2.79it/s]Train epoch: 1 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.011187\n",
      "11900it [45:50,  2.61it/s]Train epoch: 1 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.013306\n",
      "11925it [46:00,  2.33it/s]Train epoch: 1 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.011288\n",
      "11930it [46:02,  4.32it/s]\n",
      "epoch loss: 0.006587504181194713\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.31it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0081, 0.0146, 0.0138, 0.0142, 0.8310\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2132, 0.5117, 0.2676, 0.3514, 0.9715\n",
      "rec_at_8: 0.2596\n",
      "prec_at_8: 0.4988\n",
      "rec_at_15: 0.3569\n",
      "prec_at_15: 0.3793\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:51, 30.28it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0080, 0.0162, 0.0134, 0.0147, 0.8208\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2090, 0.5143, 0.2604, 0.3457, 0.9705\n",
      "rec_at_8: 0.2519\n",
      "prec_at_8: 0.5027\n",
      "rec_at_15: 0.3461\n",
      "prec_at_15: 0.3812\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 1\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0081, 0.0146, 0.0138, 0.0142, 0.8310\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2132, 0.5117, 0.2676, 0.3514, 0.9715\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0082\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 1\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0080, 0.0162, 0.0134, 0.0147, 0.8208\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2090, 0.5143, 0.2604, 0.3457, 0.9705\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0085\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 2\n",
      "0it [00:00, ?it/s]Train epoch: 2 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.009927\n",
      "25it [00:04,  5.61it/s]Train epoch: 2 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.005486\n",
      "50it [00:09,  5.49it/s]Train epoch: 2 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.004953\n",
      "75it [00:13,  5.33it/s]Train epoch: 2 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.004161\n",
      "100it [00:18,  5.50it/s]Train epoch: 2 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.004083\n",
      "125it [00:22,  5.44it/s]Train epoch: 2 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.004059\n",
      "150it [00:27,  5.44it/s]Train epoch: 2 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.003858\n",
      "175it [00:32,  5.35it/s]Train epoch: 2 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.004077\n",
      "200it [00:36,  5.44it/s]Train epoch: 2 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.003857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225it [00:41,  5.28it/s]Train epoch: 2 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.004764\n",
      "250it [00:46,  5.26it/s]Train epoch: 2 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.004043\n",
      "275it [00:50,  5.22it/s]Train epoch: 2 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.003408\n",
      "300it [00:55,  5.36it/s]Train epoch: 2 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.004357\n",
      "325it [01:00,  5.37it/s]Train epoch: 2 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.003694\n",
      "350it [01:05,  5.20it/s]Train epoch: 2 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.004423\n",
      "375it [01:09,  5.15it/s]Train epoch: 2 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.004169\n",
      "400it [01:14,  5.29it/s]Train epoch: 2 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.004244\n",
      "425it [01:19,  5.17it/s]Train epoch: 2 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.004218\n",
      "450it [01:24,  5.26it/s]Train epoch: 2 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.004001\n",
      "475it [01:29,  5.10it/s]Train epoch: 2 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.004475\n",
      "500it [01:33,  5.23it/s]Train epoch: 2 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.003772\n",
      "525it [01:38,  5.22it/s]Train epoch: 2 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.004324\n",
      "550it [01:43,  5.12it/s]Train epoch: 2 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.004165\n",
      "575it [01:48,  5.22it/s]Train epoch: 2 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.004249\n",
      "600it [01:53,  5.17it/s]Train epoch: 2 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.004375\n",
      "625it [01:58,  5.09it/s]Train epoch: 2 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.004154\n",
      "650it [02:02,  5.23it/s]Train epoch: 2 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.003810\n",
      "675it [02:07,  5.14it/s]Train epoch: 2 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.003385\n",
      "700it [02:12,  5.16it/s]Train epoch: 2 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.004018\n",
      "725it [02:17,  5.27it/s]Train epoch: 2 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.004281\n",
      "750it [02:22,  5.08it/s]Train epoch: 2 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.003983\n",
      "775it [02:27,  5.26it/s]Train epoch: 2 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.004499\n",
      "800it [02:32,  5.04it/s]Train epoch: 2 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.004365\n",
      "825it [02:36,  5.22it/s]Train epoch: 2 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.004116\n",
      "850it [02:41,  5.15it/s]Train epoch: 2 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.004601\n",
      "875it [02:46,  4.91it/s]Train epoch: 2 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.003954\n",
      "900it [02:51,  5.15it/s]Train epoch: 2 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.004291\n",
      "925it [02:56,  5.10it/s]Train epoch: 2 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.004010\n",
      "950it [03:01,  5.21it/s]Train epoch: 2 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.004086\n",
      "975it [03:06,  5.06it/s]Train epoch: 2 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.003310\n",
      "1000it [03:11,  5.14it/s]Train epoch: 2 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.004253\n",
      "1025it [03:16,  5.02it/s]Train epoch: 2 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.005364\n",
      "1050it [03:21,  5.04it/s]Train epoch: 2 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.003918\n",
      "1075it [03:26,  4.91it/s]Train epoch: 2 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.004327\n",
      "1100it [03:31,  5.02it/s]Train epoch: 2 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.004417\n",
      "1125it [03:35,  5.04it/s]Train epoch: 2 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.004470\n",
      "1150it [03:40,  5.03it/s]Train epoch: 2 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.004583\n",
      "1175it [03:46,  5.00it/s]Train epoch: 2 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.004434\n",
      "1200it [03:51,  5.04it/s]Train epoch: 2 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.004401\n",
      "1225it [03:56,  5.02it/s]Train epoch: 2 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.004693\n",
      "1250it [04:01,  5.02it/s]Train epoch: 2 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.004465\n",
      "1275it [04:06,  5.02it/s]Train epoch: 2 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.003936\n",
      "1300it [04:11,  5.06it/s]Train epoch: 2 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.003882\n",
      "1325it [04:16,  4.98it/s]Train epoch: 2 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.003833\n",
      "1350it [04:21,  4.96it/s]Train epoch: 2 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.005220\n",
      "1375it [04:26,  4.89it/s]Train epoch: 2 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.004247\n",
      "1400it [04:31,  4.98it/s]Train epoch: 2 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.004110\n",
      "1425it [04:36,  5.01it/s]Train epoch: 2 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.003855\n",
      "1450it [04:41,  4.81it/s]Train epoch: 2 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.004094\n",
      "1475it [04:46,  4.95it/s]Train epoch: 2 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.004294\n",
      "1500it [04:51,  4.91it/s]Train epoch: 2 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.005577\n",
      "1525it [04:56,  4.95it/s]Train epoch: 2 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.005139\n",
      "1550it [05:01,  4.96it/s]Train epoch: 2 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.004099\n",
      "1575it [05:06,  4.92it/s]Train epoch: 2 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.004478\n",
      "1600it [05:11,  5.02it/s]Train epoch: 2 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.003947\n",
      "1625it [05:16,  4.88it/s]Train epoch: 2 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.004624\n",
      "1650it [05:21,  4.87it/s]Train epoch: 2 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.004782\n",
      "1675it [05:26,  4.86it/s]Train epoch: 2 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.004505\n",
      "1700it [05:31,  5.01it/s]Train epoch: 2 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.004073\n",
      "1725it [05:36,  4.98it/s]Train epoch: 2 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.003564\n",
      "1750it [05:41,  4.85it/s]Train epoch: 2 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.005244\n",
      "1775it [05:46,  4.90it/s]Train epoch: 2 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.004383\n",
      "1800it [05:52,  4.90it/s]Train epoch: 2 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.004237\n",
      "1825it [05:57,  4.95it/s]Train epoch: 2 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.003725\n",
      "1850it [06:02,  4.94it/s]Train epoch: 2 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.004436\n",
      "1875it [06:07,  4.94it/s]Train epoch: 2 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.004752\n",
      "1900it [06:12,  4.92it/s]Train epoch: 2 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.003669\n",
      "1925it [06:17,  4.92it/s]Train epoch: 2 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.003855\n",
      "1950it [06:22,  5.02it/s]Train epoch: 2 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.003907\n",
      "1975it [06:27,  4.87it/s]Train epoch: 2 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.004650\n",
      "2000it [06:32,  4.82it/s]Train epoch: 2 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.003689\n",
      "2025it [06:37,  4.88it/s]Train epoch: 2 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.004628\n",
      "2050it [06:42,  4.95it/s]Train epoch: 2 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.004063\n",
      "2075it [06:47,  4.98it/s]Train epoch: 2 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.004297\n",
      "2100it [06:53,  4.90it/s]Train epoch: 2 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.004602\n",
      "2125it [06:58,  4.77it/s]Train epoch: 2 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.004816\n",
      "2150it [07:03,  4.87it/s]Train epoch: 2 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.004093\n",
      "2175it [07:08,  4.85it/s]Train epoch: 2 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.004724\n",
      "2200it [07:13,  4.90it/s]Train epoch: 2 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.004515\n",
      "2225it [07:18,  4.89it/s]Train epoch: 2 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.004340\n",
      "2250it [07:23,  4.89it/s]Train epoch: 2 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.003920\n",
      "2275it [07:28,  4.86it/s]Train epoch: 2 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.004489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300it [07:34,  4.97it/s]Train epoch: 2 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.003462\n",
      "2325it [07:39,  4.82it/s]Train epoch: 2 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.004297\n",
      "2350it [07:44,  4.85it/s]Train epoch: 2 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.003955\n",
      "2375it [07:49,  4.80it/s]Train epoch: 2 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.005665\n",
      "2400it [07:54,  4.84it/s]Train epoch: 2 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.005296\n",
      "2425it [07:59,  4.84it/s]Train epoch: 2 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.003789\n",
      "2450it [08:05,  4.87it/s]Train epoch: 2 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.004391\n",
      "2475it [08:10,  4.77it/s]Train epoch: 2 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.004744\n",
      "2500it [08:15,  4.81it/s]Train epoch: 2 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.004168\n",
      "2525it [08:20,  4.81it/s]Train epoch: 2 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.004102\n",
      "2550it [08:25,  4.84it/s]Train epoch: 2 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.005455\n",
      "2575it [08:31,  4.90it/s]Train epoch: 2 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.003951\n",
      "2600it [08:36,  4.83it/s]Train epoch: 2 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.004419\n",
      "2625it [08:41,  4.77it/s]Train epoch: 2 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.004358\n",
      "2650it [08:46,  4.84it/s]Train epoch: 2 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.004847\n",
      "2675it [08:51,  4.85it/s]Train epoch: 2 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.004534\n",
      "2700it [08:57,  4.80it/s]Train epoch: 2 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.003957\n",
      "2725it [09:02,  4.80it/s]Train epoch: 2 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.004260\n",
      "2750it [09:07,  4.82it/s]Train epoch: 2 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.005099\n",
      "2775it [09:12,  4.82it/s]Train epoch: 2 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.004485\n",
      "2800it [09:17,  4.82it/s]Train epoch: 2 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.004233\n",
      "2825it [09:23,  4.77it/s]Train epoch: 2 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.004653\n",
      "2850it [09:28,  4.70it/s]Train epoch: 2 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.004415\n",
      "2875it [09:33,  4.78it/s]Train epoch: 2 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.004719\n",
      "2900it [09:38,  4.84it/s]Train epoch: 2 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.004795\n",
      "2925it [09:43,  4.82it/s]Train epoch: 2 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.004673\n",
      "2950it [09:49,  4.77it/s]Train epoch: 2 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.004914\n",
      "2975it [09:54,  4.76it/s]Train epoch: 2 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.004689\n",
      "3000it [09:59,  4.80it/s]Train epoch: 2 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.005127\n",
      "3025it [10:04,  4.86it/s]Train epoch: 2 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.004790\n",
      "3050it [10:10,  4.73it/s]Train epoch: 2 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.004302\n",
      "3075it [10:15,  4.75it/s]Train epoch: 2 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.004906\n",
      "3100it [10:20,  4.74it/s]Train epoch: 2 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.004992\n",
      "3125it [10:25,  4.80it/s]Train epoch: 2 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.004503\n",
      "3150it [10:30,  4.82it/s]Train epoch: 2 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.004400\n",
      "3175it [10:36,  4.73it/s]Train epoch: 2 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.004312\n",
      "3200it [10:41,  4.74it/s]Train epoch: 2 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.004962\n",
      "3225it [10:46,  4.73it/s]Train epoch: 2 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.004805\n",
      "3250it [10:52,  4.72it/s]Train epoch: 2 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.004765\n",
      "3275it [10:57,  4.76it/s]Train epoch: 2 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.004678\n",
      "3300it [11:02,  4.72it/s]Train epoch: 2 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.005423\n",
      "3325it [11:07,  4.77it/s]Train epoch: 2 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.004745\n",
      "3350it [11:13,  4.75it/s]Train epoch: 2 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.004676\n",
      "3375it [11:18,  4.72it/s]Train epoch: 2 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.005122\n",
      "3400it [11:23,  4.72it/s]Train epoch: 2 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.005113\n",
      "3425it [11:28,  4.68it/s]Train epoch: 2 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.004549\n",
      "3450it [11:34,  4.70it/s]Train epoch: 2 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.005154\n",
      "3475it [11:39,  4.66it/s]Train epoch: 2 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.004570\n",
      "3500it [11:44,  4.74it/s]Train epoch: 2 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.004705\n",
      "3525it [11:50,  4.68it/s]Train epoch: 2 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.004939\n",
      "3550it [11:55,  4.68it/s]Train epoch: 2 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.005258\n",
      "3575it [12:00,  4.60it/s]Train epoch: 2 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.004238\n",
      "3600it [12:06,  4.68it/s]Train epoch: 2 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.005368\n",
      "3625it [12:11,  4.66it/s]Train epoch: 2 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.004972\n",
      "3650it [12:16,  4.78it/s]Train epoch: 2 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.004938\n",
      "3675it [12:22,  4.67it/s]Train epoch: 2 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.005203\n",
      "3700it [12:27,  4.55it/s]Train epoch: 2 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.005128\n",
      "3725it [12:32,  4.70it/s]Train epoch: 2 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.005086\n",
      "3750it [12:38,  4.69it/s]Train epoch: 2 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.005237\n",
      "3775it [12:43,  4.83it/s]Train epoch: 2 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.005022\n",
      "3800it [12:48,  4.76it/s]Train epoch: 2 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.005552\n",
      "3825it [12:54,  4.64it/s]Train epoch: 2 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.004713\n",
      "3850it [12:59,  4.71it/s]Train epoch: 2 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.004446\n",
      "3875it [13:04,  4.67it/s]Train epoch: 2 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.004350\n",
      "3900it [13:10,  4.68it/s]Train epoch: 2 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.005547\n",
      "3925it [13:15,  4.65it/s]Train epoch: 2 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.005005\n",
      "3950it [13:20,  4.64it/s]Train epoch: 2 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.005406\n",
      "3975it [13:26,  4.67it/s]Train epoch: 2 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.006205\n",
      "4000it [13:31,  4.64it/s]Train epoch: 2 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.004530\n",
      "4025it [13:37,  4.63it/s]Train epoch: 2 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.005599\n",
      "4050it [13:42,  4.71it/s]Train epoch: 2 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.005228\n",
      "4075it [13:47,  4.71it/s]Train epoch: 2 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.005217\n",
      "4100it [13:53,  4.71it/s]Train epoch: 2 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.005708\n",
      "4125it [13:58,  4.64it/s]Train epoch: 2 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.005547\n",
      "4150it [14:03,  4.64it/s]Train epoch: 2 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.004717\n",
      "4175it [14:09,  4.66it/s]Train epoch: 2 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.004936\n",
      "4200it [14:14,  4.58it/s]Train epoch: 2 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.005445\n",
      "4225it [14:20,  4.63it/s]Train epoch: 2 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.004663\n",
      "4250it [14:25,  4.62it/s]Train epoch: 2 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.005347\n",
      "4275it [14:30,  4.64it/s]Train epoch: 2 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.005006\n",
      "4300it [14:36,  4.64it/s]Train epoch: 2 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.005749\n",
      "4325it [14:41,  4.59it/s]Train epoch: 2 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.005067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4350it [14:47,  4.66it/s]Train epoch: 2 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.005425\n",
      "4375it [14:52,  4.67it/s]Train epoch: 2 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.004997\n",
      "4400it [14:57,  4.67it/s]Train epoch: 2 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.004447\n",
      "4425it [15:03,  4.57it/s]Train epoch: 2 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.005267\n",
      "4450it [15:08,  4.59it/s]Train epoch: 2 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.004269\n",
      "4475it [15:14,  4.64it/s]Train epoch: 2 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.005322\n",
      "4500it [15:19,  4.62it/s]Train epoch: 2 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.006164\n",
      "4525it [15:25,  4.60it/s]Train epoch: 2 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.005314\n",
      "4550it [15:30,  4.66it/s]Train epoch: 2 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.005146\n",
      "4575it [15:35,  4.69it/s]Train epoch: 2 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.005783\n",
      "4600it [15:41,  4.52it/s]Train epoch: 2 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.004785\n",
      "4625it [15:46,  4.67it/s]Train epoch: 2 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.005040\n",
      "4650it [15:52,  4.62it/s]Train epoch: 2 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.005637\n",
      "4675it [15:57,  4.57it/s]Train epoch: 2 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.005341\n",
      "4700it [16:02,  4.60it/s]Train epoch: 2 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.004831\n",
      "4725it [16:08,  4.58it/s]Train epoch: 2 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.005102\n",
      "4750it [16:13,  4.52it/s]Train epoch: 2 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.005867\n",
      "4775it [16:19,  4.54it/s]Train epoch: 2 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.005255\n",
      "4800it [16:24,  4.51it/s]Train epoch: 2 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.005415\n",
      "4825it [16:30,  4.50it/s]Train epoch: 2 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.004902\n",
      "4850it [16:35,  4.65it/s]Train epoch: 2 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.005696\n",
      "4875it [16:41,  4.54it/s]Train epoch: 2 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.004749\n",
      "4900it [16:46,  4.55it/s]Train epoch: 2 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.005285\n",
      "4925it [16:52,  4.55it/s]Train epoch: 2 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.004832\n",
      "4950it [16:57,  4.52it/s]Train epoch: 2 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.005208\n",
      "4975it [17:03,  4.54it/s]Train epoch: 2 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.005161\n",
      "5000it [17:08,  4.55it/s]Train epoch: 2 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.005243\n",
      "5025it [17:14,  4.55it/s]Train epoch: 2 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.004844\n",
      "5050it [17:19,  4.58it/s]Train epoch: 2 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.004814\n",
      "5075it [17:25,  4.50it/s]Train epoch: 2 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.005176\n",
      "5100it [17:30,  4.61it/s]Train epoch: 2 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.005214\n",
      "5125it [17:36,  4.51it/s]Train epoch: 2 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.005644\n",
      "5150it [17:41,  4.59it/s]Train epoch: 2 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.005389\n",
      "5175it [17:47,  4.52it/s]Train epoch: 2 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.005424\n",
      "5200it [17:52,  4.59it/s]Train epoch: 2 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.004865\n",
      "5225it [17:58,  4.42it/s]Train epoch: 2 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.005379\n",
      "5250it [18:04,  4.54it/s]Train epoch: 2 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.005075\n",
      "5275it [18:09,  4.54it/s]Train epoch: 2 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.005119\n",
      "5300it [18:15,  4.54it/s]Train epoch: 2 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.004881\n",
      "5325it [18:20,  4.49it/s]Train epoch: 2 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.005749\n",
      "5350it [18:26,  4.55it/s]Train epoch: 2 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.005803\n",
      "5375it [18:31,  4.52it/s]Train epoch: 2 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.005000\n",
      "5400it [18:37,  4.55it/s]Train epoch: 2 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.005099\n",
      "5425it [18:42,  4.53it/s]Train epoch: 2 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.005452\n",
      "5450it [18:48,  4.46it/s]Train epoch: 2 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.005416\n",
      "5475it [18:53,  4.51it/s]Train epoch: 2 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.006144\n",
      "5500it [18:59,  4.46it/s]Train epoch: 2 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.005778\n",
      "5525it [19:04,  4.56it/s]Train epoch: 2 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.004788\n",
      "5550it [19:10,  4.49it/s]Train epoch: 2 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.005290\n",
      "5575it [19:16,  4.43it/s]Train epoch: 2 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.005477\n",
      "5600it [19:21,  4.51it/s]Train epoch: 2 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.005876\n",
      "5625it [19:27,  4.43it/s]Train epoch: 2 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.005324\n",
      "5650it [19:32,  4.51it/s]Train epoch: 2 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.004873\n",
      "5675it [19:38,  4.45it/s]Train epoch: 2 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.005980\n",
      "5700it [19:44,  4.49it/s]Train epoch: 2 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.005100\n",
      "5725it [19:49,  4.40it/s]Train epoch: 2 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.005368\n",
      "5750it [19:55,  4.51it/s]Train epoch: 2 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.006730\n",
      "5775it [20:00,  4.48it/s]Train epoch: 2 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.005630\n",
      "5800it [20:06,  4.43it/s]Train epoch: 2 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.005692\n",
      "5825it [20:12,  4.37it/s]Train epoch: 2 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.004917\n",
      "5850it [20:17,  4.44it/s]Train epoch: 2 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.006270\n",
      "5875it [20:23,  4.48it/s]Train epoch: 2 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.005970\n",
      "5900it [20:29,  4.42it/s]Train epoch: 2 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.006145\n",
      "5925it [20:34,  4.49it/s]Train epoch: 2 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.005120\n",
      "5950it [20:40,  4.44it/s]Train epoch: 2 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.005020\n",
      "5975it [20:45,  4.40it/s]Train epoch: 2 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.006659\n",
      "6000it [20:51,  4.41it/s]Train epoch: 2 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.005757\n",
      "6025it [20:57,  4.38it/s]Train epoch: 2 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.005950\n",
      "6050it [21:02,  4.46it/s]Train epoch: 2 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.005328\n",
      "6075it [21:08,  4.40it/s]Train epoch: 2 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.005201\n",
      "6100it [21:14,  4.43it/s]Train epoch: 2 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.004832\n",
      "6125it [21:19,  4.44it/s]Train epoch: 2 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.005498\n",
      "6150it [21:25,  4.42it/s]Train epoch: 2 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.005286\n",
      "6175it [21:30,  4.39it/s]Train epoch: 2 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.006044\n",
      "6200it [21:36,  4.39it/s]Train epoch: 2 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.005435\n",
      "6225it [21:42,  4.50it/s]Train epoch: 2 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.004776\n",
      "6250it [21:47,  4.41it/s]Train epoch: 2 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.005199\n",
      "6275it [21:53,  4.44it/s]Train epoch: 2 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.004826\n",
      "6300it [21:59,  4.35it/s]Train epoch: 2 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.005582\n",
      "6325it [22:04,  4.38it/s]Train epoch: 2 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.005881\n",
      "6350it [22:10,  4.41it/s]Train epoch: 2 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.006085\n",
      "6375it [22:16,  4.43it/s]Train epoch: 2 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.005080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400it [22:21,  4.46it/s]Train epoch: 2 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.005318\n",
      "6425it [22:27,  4.38it/s]Train epoch: 2 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.006004\n",
      "6450it [22:33,  4.39it/s]Train epoch: 2 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.005779\n",
      "6475it [22:39,  4.28it/s]Train epoch: 2 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.005333\n",
      "6500it [22:44,  4.48it/s]Train epoch: 2 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.006032\n",
      "6525it [22:50,  4.44it/s]Train epoch: 2 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.005045\n",
      "6550it [22:56,  4.33it/s]Train epoch: 2 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.005313\n",
      "6575it [23:01,  4.35it/s]Train epoch: 2 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.005552\n",
      "6600it [23:07,  4.39it/s]Train epoch: 2 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.006547\n",
      "6625it [23:13,  4.43it/s]Train epoch: 2 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.005396\n",
      "6650it [23:18,  4.30it/s]Train epoch: 2 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.006253\n",
      "6675it [23:24,  4.36it/s]Train epoch: 2 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.005634\n",
      "6700it [23:30,  4.35it/s]Train epoch: 2 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.005717\n",
      "6725it [23:36,  4.36it/s]Train epoch: 2 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.005913\n",
      "6750it [23:41,  4.37it/s]Train epoch: 2 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.005263\n",
      "6775it [23:47,  4.48it/s]Train epoch: 2 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.006021\n",
      "6800it [23:53,  4.32it/s]Train epoch: 2 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.005865\n",
      "6825it [23:59,  4.41it/s]Train epoch: 2 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.006232\n",
      "6850it [24:04,  4.35it/s]Train epoch: 2 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.005765\n",
      "6875it [24:10,  4.34it/s]Train epoch: 2 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.004811\n",
      "6900it [24:16,  4.31it/s]Train epoch: 2 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.005723\n",
      "6925it [24:22,  4.35it/s]Train epoch: 2 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.005563\n",
      "6950it [24:27,  4.41it/s]Train epoch: 2 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.006303\n",
      "6975it [24:33,  4.34it/s]Train epoch: 2 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.005949\n",
      "7000it [24:39,  4.27it/s]Train epoch: 2 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.005558\n",
      "7025it [24:45,  4.31it/s]Train epoch: 2 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.006452\n",
      "7050it [24:50,  4.30it/s]Train epoch: 2 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.005022\n",
      "7075it [24:56,  4.25it/s]Train epoch: 2 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.005790\n",
      "7100it [25:02,  4.29it/s]Train epoch: 2 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.006017\n",
      "7125it [25:08,  4.28it/s]Train epoch: 2 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.005217\n",
      "7150it [25:14,  4.32it/s]Train epoch: 2 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.006411\n",
      "7175it [25:20,  4.32it/s]Train epoch: 2 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.005832\n",
      "7200it [25:26,  4.23it/s]Train epoch: 2 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.006209\n",
      "7225it [25:31,  4.29it/s]Train epoch: 2 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.005655\n",
      "7250it [25:37,  4.22it/s]Train epoch: 2 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.005627\n",
      "7275it [25:43,  4.33it/s]Train epoch: 2 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.006371\n",
      "7300it [25:49,  4.29it/s]Train epoch: 2 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.006565\n",
      "7325it [25:55,  4.22it/s]Train epoch: 2 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.005552\n",
      "7350it [26:01,  4.28it/s]Train epoch: 2 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.006677\n",
      "7375it [26:06,  4.28it/s]Train epoch: 2 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.006063\n",
      "7400it [26:12,  4.20it/s]Train epoch: 2 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.005487\n",
      "7425it [26:18,  4.27it/s]Train epoch: 2 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.006067\n",
      "7450it [26:24,  4.26it/s]Train epoch: 2 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.006741\n",
      "7475it [26:30,  4.20it/s]Train epoch: 2 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.005804\n",
      "7500it [26:36,  4.26it/s]Train epoch: 2 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.006132\n",
      "7525it [26:42,  4.28it/s]Train epoch: 2 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.005790\n",
      "7550it [26:47,  4.25it/s]Train epoch: 2 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.005591\n",
      "7575it [26:53,  4.20it/s]Train epoch: 2 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.006310\n",
      "7600it [26:59,  4.24it/s]Train epoch: 2 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.007291\n",
      "7625it [27:05,  4.26it/s]Train epoch: 2 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.006866\n",
      "7650it [27:11,  4.24it/s]Train epoch: 2 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.005794\n",
      "7675it [27:17,  4.31it/s]Train epoch: 2 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.005975\n",
      "7700it [27:23,  4.15it/s]Train epoch: 2 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.005933\n",
      "7725it [27:29,  4.18it/s]Train epoch: 2 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.005927\n",
      "7750it [27:35,  4.25it/s]Train epoch: 2 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.006227\n",
      "7775it [27:41,  4.23it/s]Train epoch: 2 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.005599\n",
      "7800it [27:46,  4.23it/s]Train epoch: 2 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.005860\n",
      "7825it [27:52,  4.23it/s]Train epoch: 2 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.006054\n",
      "7850it [27:58,  4.20it/s]Train epoch: 2 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.005522\n",
      "7875it [28:04,  4.21it/s]Train epoch: 2 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.005832\n",
      "7900it [28:10,  4.22it/s]Train epoch: 2 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.006100\n",
      "7925it [28:16,  4.20it/s]Train epoch: 2 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.005954\n",
      "7950it [28:22,  4.21it/s]Train epoch: 2 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.006686\n",
      "7975it [28:28,  4.19it/s]Train epoch: 2 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.006039\n",
      "8000it [28:34,  4.19it/s]Train epoch: 2 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.005768\n",
      "8025it [28:40,  4.18it/s]Train epoch: 2 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.006302\n",
      "8050it [28:46,  4.18it/s]Train epoch: 2 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.005465\n",
      "8075it [28:52,  4.17it/s]Train epoch: 2 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.006045\n",
      "8100it [28:58,  4.18it/s]Train epoch: 2 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.006311\n",
      "8125it [29:04,  4.16it/s]Train epoch: 2 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.006375\n",
      "8150it [29:10,  4.16it/s]Train epoch: 2 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.005702\n",
      "8175it [29:16,  4.16it/s]Train epoch: 2 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.006425\n",
      "8200it [29:22,  4.17it/s]Train epoch: 2 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.005623\n",
      "8225it [29:28,  4.15it/s]Train epoch: 2 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.007248\n",
      "8250it [29:34,  4.15it/s]Train epoch: 2 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.005824\n",
      "8275it [29:40,  4.17it/s]Train epoch: 2 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.006665\n",
      "8300it [29:46,  4.15it/s]Train epoch: 2 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.005772\n",
      "8325it [29:52,  4.14it/s]Train epoch: 2 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.006492\n",
      "8350it [29:58,  4.13it/s]Train epoch: 2 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.005800\n",
      "8375it [30:04,  4.14it/s]Train epoch: 2 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.006324\n",
      "8400it [30:10,  4.15it/s]Train epoch: 2 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.005938\n",
      "8425it [30:16,  4.12it/s]Train epoch: 2 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.006080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8450it [30:22,  4.10it/s]Train epoch: 2 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.006403\n",
      "8475it [30:28,  4.12it/s]Train epoch: 2 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.006088\n",
      "8500it [30:34,  4.03it/s]Train epoch: 2 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.006961\n",
      "8525it [30:40,  4.11it/s]Train epoch: 2 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.006061\n",
      "8550it [30:46,  4.13it/s]Train epoch: 2 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.006575\n",
      "8575it [30:53,  4.09it/s]Train epoch: 2 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.006022\n",
      "8600it [30:59,  4.09it/s]Train epoch: 2 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.006118\n",
      "8625it [31:05,  4.12it/s]Train epoch: 2 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.006199\n",
      "8650it [31:11,  4.14it/s]Train epoch: 2 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.006484\n",
      "8675it [31:17,  4.17it/s]Train epoch: 2 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.007099\n",
      "8700it [31:23,  4.08it/s]Train epoch: 2 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.007030\n",
      "8725it [31:29,  4.08it/s]Train epoch: 2 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.006755\n",
      "8750it [31:35,  4.07it/s]Train epoch: 2 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.006627\n",
      "8775it [31:41,  4.09it/s]Train epoch: 2 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.005929\n",
      "8800it [31:47,  4.04it/s]Train epoch: 2 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.006186\n",
      "8825it [31:54,  4.03it/s]Train epoch: 2 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.006196\n",
      "8850it [32:00,  4.10it/s]Train epoch: 2 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.006559\n",
      "8875it [32:06,  4.06it/s]Train epoch: 2 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.006241\n",
      "8900it [32:12,  4.07it/s]Train epoch: 2 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.006240\n",
      "8925it [32:18,  3.99it/s]Train epoch: 2 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.006581\n",
      "8950it [32:24,  4.05it/s]Train epoch: 2 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.007278\n",
      "8975it [32:31,  4.02it/s]Train epoch: 2 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.006909\n",
      "9000it [32:37,  3.97it/s]Train epoch: 2 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.006293\n",
      "9025it [32:43,  4.07it/s]Train epoch: 2 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.006399\n",
      "9050it [32:49,  3.95it/s]Train epoch: 2 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.006111\n",
      "9075it [32:55,  4.03it/s]Train epoch: 2 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.005706\n",
      "9100it [33:02,  4.07it/s]Train epoch: 2 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.006481\n",
      "9125it [33:08,  3.98it/s]Train epoch: 2 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.006120\n",
      "9150it [33:14,  4.02it/s]Train epoch: 2 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.005721\n",
      "9175it [33:20,  3.99it/s]Train epoch: 2 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.006167\n",
      "9200it [33:26,  4.04it/s]Train epoch: 2 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.006245\n",
      "9225it [33:33,  4.05it/s]Train epoch: 2 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.007149\n",
      "9250it [33:39,  4.05it/s]Train epoch: 2 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.006290\n",
      "9275it [33:45,  4.00it/s]Train epoch: 2 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.006670\n",
      "9300it [33:51,  4.03it/s]Train epoch: 2 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.007537\n",
      "9325it [33:57,  4.04it/s]Train epoch: 2 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.007218\n",
      "9350it [34:04,  3.97it/s]Train epoch: 2 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.007000\n",
      "9375it [34:10,  4.02it/s]Train epoch: 2 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.006342\n",
      "9400it [34:16,  3.99it/s]Train epoch: 2 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.006580\n",
      "9425it [34:23,  3.95it/s]Train epoch: 2 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.006310\n",
      "9450it [34:29,  3.96it/s]Train epoch: 2 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.006316\n",
      "9475it [34:35,  4.01it/s]Train epoch: 2 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.007178\n",
      "9500it [34:41,  3.95it/s]Train epoch: 2 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.006599\n",
      "9525it [34:48,  3.96it/s]Train epoch: 2 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.007043\n",
      "9550it [34:54,  3.99it/s]Train epoch: 2 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.006931\n",
      "9575it [35:00,  3.93it/s]Train epoch: 2 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.006853\n",
      "9600it [35:07,  3.97it/s]Train epoch: 2 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.006694\n",
      "9625it [35:13,  3.96it/s]Train epoch: 2 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.006123\n",
      "9650it [35:19,  3.92it/s]Train epoch: 2 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.006252\n",
      "9675it [35:26,  3.90it/s]Train epoch: 2 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.006713\n",
      "9700it [35:32,  3.94it/s]Train epoch: 2 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.006025\n",
      "9725it [35:38,  3.91it/s]Train epoch: 2 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.006927\n",
      "9750it [35:45,  3.81it/s]Train epoch: 2 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.006563\n",
      "9775it [35:51,  3.92it/s]Train epoch: 2 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.007475\n",
      "9800it [35:58,  3.86it/s]Train epoch: 2 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.007129\n",
      "9825it [36:04,  3.93it/s]Train epoch: 2 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.007171\n",
      "9850it [36:10,  3.95it/s]Train epoch: 2 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.006655\n",
      "9875it [36:17,  3.88it/s]Train epoch: 2 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.007207\n",
      "9900it [36:23,  3.86it/s]Train epoch: 2 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.007705\n",
      "9925it [36:30,  3.90it/s]Train epoch: 2 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.007143\n",
      "9950it [36:36,  3.80it/s]Train epoch: 2 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.007849\n",
      "9975it [36:43,  3.88it/s]Train epoch: 2 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.007192\n",
      "10000it [36:49,  3.91it/s]Train epoch: 2 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.006699\n",
      "10025it [36:55,  3.85it/s]Train epoch: 2 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.006869\n",
      "10050it [37:02,  3.90it/s]Train epoch: 2 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.007287\n",
      "10075it [37:08,  3.81it/s]Train epoch: 2 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.007853\n",
      "10100it [37:15,  3.90it/s]Train epoch: 2 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.007108\n",
      "10125it [37:21,  3.84it/s]Train epoch: 2 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.006714\n",
      "10150it [37:28,  3.79it/s]Train epoch: 2 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.007267\n",
      "10175it [37:34,  3.81it/s]Train epoch: 2 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.006775\n",
      "10200it [37:41,  3.84it/s]Train epoch: 2 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.007295\n",
      "10225it [37:47,  3.86it/s]Train epoch: 2 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.007217\n",
      "10250it [37:54,  3.83it/s]Train epoch: 2 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.007640\n",
      "10275it [38:01,  3.87it/s]Train epoch: 2 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.006949\n",
      "10300it [38:07,  3.84it/s]Train epoch: 2 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.007458\n",
      "10325it [38:14,  3.83it/s]Train epoch: 2 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.007501\n",
      "10350it [38:20,  3.82it/s]Train epoch: 2 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.007273\n",
      "10375it [38:27,  3.80it/s]Train epoch: 2 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.007362\n",
      "10400it [38:33,  3.78it/s]Train epoch: 2 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.007499\n",
      "10425it [38:40,  3.84it/s]Train epoch: 2 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.007112\n",
      "10450it [38:47,  3.77it/s]Train epoch: 2 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.007382\n",
      "10475it [38:53,  3.74it/s]Train epoch: 2 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.006490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500it [39:00,  3.75it/s]Train epoch: 2 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.007369\n",
      "10525it [39:07,  3.81it/s]Train epoch: 2 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.007156\n",
      "10550it [39:13,  3.74it/s]Train epoch: 2 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.007329\n",
      "10575it [39:20,  3.70it/s]Train epoch: 2 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.006661\n",
      "10600it [39:27,  3.75it/s]Train epoch: 2 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.006628\n",
      "10625it [39:33,  3.70it/s]Train epoch: 2 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.007595\n",
      "10650it [39:40,  3.70it/s]Train epoch: 2 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.006999\n",
      "10675it [39:47,  3.66it/s]Train epoch: 2 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.007451\n",
      "10700it [39:54,  3.73it/s]Train epoch: 2 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.007009\n",
      "10725it [40:00,  3.70it/s]Train epoch: 2 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.006501\n",
      "10750it [40:07,  3.75it/s]Train epoch: 2 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.007548\n",
      "10775it [40:14,  3.69it/s]Train epoch: 2 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.007576\n",
      "10800it [40:21,  3.66it/s]Train epoch: 2 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.007888\n",
      "10825it [40:27,  3.67it/s]Train epoch: 2 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.007841\n",
      "10850it [40:34,  3.74it/s]Train epoch: 2 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.007735\n",
      "10875it [40:41,  3.65it/s]Train epoch: 2 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.007825\n",
      "10900it [40:48,  3.64it/s]Train epoch: 2 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.007458\n",
      "10925it [40:55,  3.65it/s]Train epoch: 2 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006979\n",
      "10950it [41:02,  3.63it/s]Train epoch: 2 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.007494\n",
      "10975it [41:08,  3.61it/s]Train epoch: 2 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.007284\n",
      "11000it [41:15,  3.57it/s]Train epoch: 2 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.007258\n",
      "11025it [41:22,  3.59it/s]Train epoch: 2 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.007373\n",
      "11050it [41:29,  3.58it/s]Train epoch: 2 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.008254\n",
      "11075it [41:36,  3.67it/s]Train epoch: 2 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.007723\n",
      "11100it [41:43,  3.57it/s]Train epoch: 2 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.008430\n",
      "11125it [41:50,  3.59it/s]Train epoch: 2 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007818\n",
      "11150it [41:57,  3.58it/s]Train epoch: 2 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.007585\n",
      "11175it [42:04,  3.56it/s]Train epoch: 2 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.008842\n",
      "11200it [42:11,  3.63it/s]Train epoch: 2 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007922\n",
      "11225it [42:18,  3.52it/s]Train epoch: 2 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007773\n",
      "11250it [42:25,  3.54it/s]Train epoch: 2 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.008627\n",
      "11275it [42:32,  3.52it/s]Train epoch: 2 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.008302\n",
      "11300it [42:40,  3.49it/s]Train epoch: 2 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.007532\n",
      "11325it [42:47,  3.52it/s]Train epoch: 2 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.008776\n",
      "11350it [42:54,  3.45it/s]Train epoch: 2 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.008634\n",
      "11375it [43:01,  3.44it/s]Train epoch: 2 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.008976\n",
      "11400it [43:08,  3.44it/s]Train epoch: 2 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007727\n",
      "11425it [43:16,  3.40it/s]Train epoch: 2 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.008366\n",
      "11450it [43:23,  3.42it/s]Train epoch: 2 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.007728\n",
      "11475it [43:30,  3.39it/s]Train epoch: 2 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.009133\n",
      "11500it [43:38,  3.40it/s]Train epoch: 2 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.008832\n",
      "11525it [43:45,  3.33it/s]Train epoch: 2 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.008153\n",
      "11550it [43:53,  3.36it/s]Train epoch: 2 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.008090\n",
      "11575it [44:00,  3.30it/s]Train epoch: 2 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.009267\n",
      "11600it [44:08,  3.31it/s]Train epoch: 2 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.008370\n",
      "11625it [44:15,  3.29it/s]Train epoch: 2 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007958\n",
      "11650it [44:23,  3.26it/s]Train epoch: 2 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.008662\n",
      "11675it [44:31,  3.21it/s]Train epoch: 2 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.009150\n",
      "11700it [44:39,  3.20it/s]Train epoch: 2 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.009581\n",
      "11725it [44:47,  3.15it/s]Train epoch: 2 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.009689\n",
      "11750it [44:55,  3.11it/s]Train epoch: 2 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.009281\n",
      "11775it [45:03,  3.07it/s]Train epoch: 2 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.009250\n",
      "11800it [45:11,  3.03it/s]Train epoch: 2 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008883\n",
      "11825it [45:19,  2.95it/s]Train epoch: 2 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.009344\n",
      "11850it [45:28,  2.92it/s]Train epoch: 2 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.009328\n",
      "11875it [45:37,  2.79it/s]Train epoch: 2 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.010402\n",
      "11900it [45:46,  2.63it/s]Train epoch: 2 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.012547\n",
      "11925it [45:56,  2.33it/s]Train epoch: 2 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010659\n",
      "11930it [45:58,  4.32it/s]\n",
      "epoch loss: 0.00578098054689356\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.44it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0157, 0.0253, 0.0294, 0.0272, 0.8574\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2662, 0.4863, 0.3704, 0.4205, 0.9761\n",
      "rec_at_8: 0.3007\n",
      "prec_at_8: 0.5672\n",
      "rec_at_15: 0.4153\n",
      "prec_at_15: 0.4339\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:51, 30.35it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0153, 0.0256, 0.0291, 0.0273, 0.8504\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2599, 0.4848, 0.3591, 0.4126, 0.9753\n",
      "rec_at_8: 0.2873\n",
      "prec_at_8: 0.5621\n",
      "rec_at_15: 0.4020\n",
      "prec_at_15: 0.4350\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 2\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0157, 0.0253, 0.0294, 0.0272, 0.8574\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2662, 0.4863, 0.3704, 0.4205, 0.9761\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0080\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 2\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0153, 0.0256, 0.0291, 0.0273, 0.8504\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2599, 0.4848, 0.3591, 0.4126, 0.9753\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0083\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 3\n",
      "0it [00:00, ?it/s]Train epoch: 3 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.006888\n",
      "25it [00:04,  5.66it/s]Train epoch: 3 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.004872\n",
      "50it [00:09,  5.33it/s]Train epoch: 3 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.004529\n",
      "75it [00:13,  5.34it/s]Train epoch: 3 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.003678\n",
      "100it [00:18,  5.36it/s]Train epoch: 3 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.003851\n",
      "125it [00:22,  5.35it/s]Train epoch: 3 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.003607\n",
      "150it [00:27,  5.35it/s]Train epoch: 3 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.003453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175it [00:32,  5.35it/s]Train epoch: 3 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.003687\n",
      "200it [00:36,  5.34it/s]Train epoch: 3 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.003532\n",
      "225it [00:41,  5.25it/s]Train epoch: 3 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.004345\n",
      "250it [00:46,  5.23it/s]Train epoch: 3 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.003648\n",
      "275it [00:51,  5.24it/s]Train epoch: 3 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.003140\n",
      "300it [00:55,  5.32it/s]Train epoch: 3 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003990\n",
      "325it [01:00,  5.26it/s]Train epoch: 3 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.003343\n",
      "350it [01:05,  5.27it/s]Train epoch: 3 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.003990\n",
      "375it [01:10,  5.33it/s]Train epoch: 3 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.003789\n",
      "400it [01:14,  5.26it/s]Train epoch: 3 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.003833\n",
      "425it [01:19,  5.13it/s]Train epoch: 3 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.003715\n",
      "450it [01:24,  5.20it/s]Train epoch: 3 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.003631\n",
      "475it [01:29,  5.19it/s]Train epoch: 3 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.004088\n",
      "500it [01:34,  5.17it/s]Train epoch: 3 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.003395\n",
      "525it [01:38,  5.08it/s]Train epoch: 3 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.003871\n",
      "550it [01:43,  5.20it/s]Train epoch: 3 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.003710\n",
      "575it [01:48,  5.19it/s]Train epoch: 3 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.003745\n",
      "600it [01:53,  5.23it/s]Train epoch: 3 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.003923\n",
      "625it [01:58,  5.21it/s]Train epoch: 3 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.003789\n",
      "650it [02:03,  5.20it/s]Train epoch: 3 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.003412\n",
      "675it [02:07,  5.19it/s]Train epoch: 3 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002970\n",
      "700it [02:12,  5.14it/s]Train epoch: 3 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.003637\n",
      "725it [02:17,  5.03it/s]Train epoch: 3 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.003825\n",
      "750it [02:22,  5.14it/s]Train epoch: 3 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.003543\n",
      "775it [02:27,  5.17it/s]Train epoch: 3 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.004060\n",
      "800it [02:32,  5.16it/s]Train epoch: 3 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.003902\n",
      "825it [02:37,  5.09it/s]Train epoch: 3 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.003683\n",
      "850it [02:42,  5.08it/s]Train epoch: 3 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.004193\n",
      "875it [02:47,  5.12it/s]Train epoch: 3 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.003416\n",
      "900it [02:51,  5.14it/s]Train epoch: 3 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.003848\n",
      "925it [02:56,  5.14it/s]Train epoch: 3 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.003599\n",
      "950it [03:01,  5.05it/s]Train epoch: 3 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.003590\n",
      "975it [03:06,  5.10it/s]Train epoch: 3 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002874\n",
      "1000it [03:11,  5.17it/s]Train epoch: 3 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.003818\n",
      "1025it [03:16,  5.04it/s]Train epoch: 3 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.004989\n",
      "1050it [03:21,  5.07it/s]Train epoch: 3 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.003510\n",
      "1075it [03:26,  5.18it/s]Train epoch: 3 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.003927\n",
      "1100it [03:31,  5.10it/s]Train epoch: 3 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.003926\n",
      "1125it [03:36,  5.08it/s]Train epoch: 3 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.004074\n",
      "1150it [03:41,  5.12it/s]Train epoch: 3 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.004099\n",
      "1175it [03:46,  5.05it/s]Train epoch: 3 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.003976\n",
      "1200it [03:51,  5.03it/s]Train epoch: 3 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.004021\n",
      "1225it [03:56,  5.02it/s]Train epoch: 3 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.004283\n",
      "1250it [04:01,  5.02it/s]Train epoch: 3 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003994\n",
      "1275it [04:06,  4.99it/s]Train epoch: 3 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.003533\n",
      "1300it [04:11,  5.07it/s]Train epoch: 3 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.003433\n",
      "1325it [04:16,  4.97it/s]Train epoch: 3 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.003467\n",
      "1350it [04:21,  4.98it/s]Train epoch: 3 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.004704\n",
      "1375it [04:26,  5.01it/s]Train epoch: 3 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.003887\n",
      "1400it [04:31,  4.95it/s]Train epoch: 3 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.003703\n",
      "1425it [04:36,  4.97it/s]Train epoch: 3 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.003434\n",
      "1450it [04:41,  4.99it/s]Train epoch: 3 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.003753\n",
      "1475it [04:46,  4.97it/s]Train epoch: 3 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.003870\n",
      "1500it [04:51,  5.01it/s]Train epoch: 3 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.005092\n",
      "1525it [04:56,  5.00it/s]Train epoch: 3 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.004779\n",
      "1550it [05:01,  5.02it/s]Train epoch: 3 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.003713\n",
      "1575it [05:06,  4.98it/s]Train epoch: 3 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.004075\n",
      "1600it [05:11,  5.07it/s]Train epoch: 3 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.003535\n",
      "1625it [05:16,  4.95it/s]Train epoch: 3 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.004271\n",
      "1650it [05:21,  4.99it/s]Train epoch: 3 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.004258\n",
      "1675it [05:26,  4.95it/s]Train epoch: 3 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.004115\n",
      "1700it [05:31,  4.95it/s]Train epoch: 3 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.003698\n",
      "1725it [05:36,  4.95it/s]Train epoch: 3 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.003198\n",
      "1750it [05:41,  5.02it/s]Train epoch: 3 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.004728\n",
      "1775it [05:46,  4.98it/s]Train epoch: 3 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.003934\n",
      "1800it [05:51,  4.90it/s]Train epoch: 3 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.003898\n",
      "1825it [05:56,  4.96it/s]Train epoch: 3 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.003342\n",
      "1850it [06:01,  4.92it/s]Train epoch: 3 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.004082\n",
      "1875it [06:06,  4.90it/s]Train epoch: 3 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.004274\n",
      "1900it [06:11,  4.93it/s]Train epoch: 3 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.003307\n",
      "1925it [06:16,  4.91it/s]Train epoch: 3 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.003461\n",
      "1950it [06:22,  4.87it/s]Train epoch: 3 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.003512\n",
      "1975it [06:27,  4.96it/s]Train epoch: 3 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.004165\n",
      "2000it [06:32,  4.98it/s]Train epoch: 3 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.003320\n",
      "2025it [06:37,  4.92it/s]Train epoch: 3 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.004120\n",
      "2050it [06:42,  4.94it/s]Train epoch: 3 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.003776\n",
      "2075it [06:47,  4.90it/s]Train epoch: 3 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.003975\n",
      "2100it [06:52,  4.84it/s]Train epoch: 3 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.004147\n",
      "2125it [06:57,  5.01it/s]Train epoch: 3 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.004425\n",
      "2150it [07:02,  4.84it/s]Train epoch: 3 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.003717\n",
      "2175it [07:07,  4.87it/s]Train epoch: 3 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.004277\n",
      "2200it [07:13,  4.93it/s]Train epoch: 3 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.004031\n",
      "2225it [07:18,  4.87it/s]Train epoch: 3 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.003866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250it [07:23,  4.90it/s]Train epoch: 3 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.003546\n",
      "2275it [07:28,  4.87it/s]Train epoch: 3 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.004056\n",
      "2300it [07:33,  4.90it/s]Train epoch: 3 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.003146\n",
      "2325it [07:38,  4.95it/s]Train epoch: 3 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.003860\n",
      "2350it [07:43,  4.87it/s]Train epoch: 3 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.003567\n",
      "2375it [07:48,  4.86it/s]Train epoch: 3 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.005182\n",
      "2400it [07:54,  4.82it/s]Train epoch: 3 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.004822\n",
      "2425it [07:59,  4.83it/s]Train epoch: 3 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.003468\n",
      "2450it [08:04,  4.79it/s]Train epoch: 3 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.003990\n",
      "2475it [08:09,  4.89it/s]Train epoch: 3 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.004373\n",
      "2500it [08:14,  4.91it/s]Train epoch: 3 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.003794\n",
      "2525it [08:19,  4.75it/s]Train epoch: 3 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.003657\n",
      "2550it [08:25,  4.82it/s]Train epoch: 3 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.004940\n",
      "2575it [08:30,  4.82it/s]Train epoch: 3 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.003667\n",
      "2600it [08:35,  4.84it/s]Train epoch: 3 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.003990\n",
      "2625it [08:40,  4.92it/s]Train epoch: 3 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.003957\n",
      "2650it [08:45,  4.73it/s]Train epoch: 3 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.004541\n",
      "2675it [08:50,  4.94it/s]Train epoch: 3 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.004053\n",
      "2700it [08:56,  4.79it/s]Train epoch: 3 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.003607\n",
      "2725it [09:01,  4.82it/s]Train epoch: 3 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.003852\n",
      "2750it [09:06,  4.81it/s]Train epoch: 3 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.004605\n",
      "2775it [09:11,  4.77it/s]Train epoch: 3 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.003987\n",
      "2800it [09:17,  4.80it/s]Train epoch: 3 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.003889\n",
      "2825it [09:22,  4.90it/s]Train epoch: 3 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.004240\n",
      "2850it [09:27,  4.87it/s]Train epoch: 3 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.004021\n",
      "2875it [09:32,  4.81it/s]Train epoch: 3 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.004328\n",
      "2900it [09:37,  4.76it/s]Train epoch: 3 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.004298\n",
      "2925it [09:43,  4.82it/s]Train epoch: 3 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.004257\n",
      "2950it [09:48,  4.75it/s]Train epoch: 3 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.004519\n",
      "2975it [09:53,  4.75it/s]Train epoch: 3 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.004265\n",
      "3000it [09:58,  4.65it/s]Train epoch: 3 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.004749\n",
      "3025it [10:04,  4.73it/s]Train epoch: 3 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.004415\n",
      "3050it [10:09,  4.71it/s]Train epoch: 3 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.003835\n",
      "3075it [10:14,  4.90it/s]Train epoch: 3 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.004447\n",
      "3100it [10:19,  4.83it/s]Train epoch: 3 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.004591\n",
      "3125it [10:25,  4.75it/s]Train epoch: 3 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.003986\n",
      "3150it [10:30,  4.69it/s]Train epoch: 3 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.003932\n",
      "3175it [10:35,  4.79it/s]Train epoch: 3 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.003952\n",
      "3200it [10:40,  4.72it/s]Train epoch: 3 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.004586\n",
      "3225it [10:46,  4.82it/s]Train epoch: 3 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.004390\n",
      "3250it [10:51,  4.69it/s]Train epoch: 3 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.004344\n",
      "3275it [10:56,  4.71it/s]Train epoch: 3 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.004142\n",
      "3300it [11:01,  4.65it/s]Train epoch: 3 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.004956\n",
      "3325it [11:07,  4.77it/s]Train epoch: 3 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.004293\n",
      "3350it [11:12,  4.75it/s]Train epoch: 3 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.004298\n",
      "3375it [11:17,  4.76it/s]Train epoch: 3 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.004626\n",
      "3400it [11:22,  4.71it/s]Train epoch: 3 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.004631\n",
      "3425it [11:28,  4.79it/s]Train epoch: 3 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.004051\n",
      "3450it [11:33,  4.77it/s]Train epoch: 3 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.004671\n",
      "3475it [11:38,  4.78it/s]Train epoch: 3 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.004115\n",
      "3500it [11:43,  4.73it/s]Train epoch: 3 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.004297\n",
      "3525it [11:49,  4.68it/s]Train epoch: 3 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.004437\n",
      "3550it [11:54,  4.65it/s]Train epoch: 3 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.004813\n",
      "3575it [11:59,  4.83it/s]Train epoch: 3 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.003830\n",
      "3600it [12:05,  4.71it/s]Train epoch: 3 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.004964\n",
      "3625it [12:10,  4.75it/s]Train epoch: 3 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.004389\n",
      "3650it [12:15,  4.68it/s]Train epoch: 3 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.004501\n",
      "3675it [12:21,  4.70it/s]Train epoch: 3 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.004717\n",
      "3700it [12:26,  4.70it/s]Train epoch: 3 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.004552\n",
      "3725it [12:31,  4.77it/s]Train epoch: 3 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.004636\n",
      "3750it [12:37,  4.65it/s]Train epoch: 3 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.004736\n",
      "3775it [12:42,  4.56it/s]Train epoch: 3 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.004606\n",
      "3800it [12:47,  4.53it/s]Train epoch: 3 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.005004\n",
      "3825it [12:53,  4.69it/s]Train epoch: 3 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.004250\n",
      "3850it [12:58,  4.69it/s]Train epoch: 3 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.003968\n",
      "3875it [13:04,  4.66it/s]Train epoch: 3 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.003864\n",
      "3900it [13:09,  4.75it/s]Train epoch: 3 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.004976\n",
      "3925it [13:14,  4.66it/s]Train epoch: 3 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.004607\n",
      "3950it [13:20,  4.61it/s]Train epoch: 3 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.004892\n",
      "3975it [13:25,  4.68it/s]Train epoch: 3 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.005662\n",
      "4000it [13:30,  4.69it/s]Train epoch: 3 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.004072\n",
      "4025it [13:36,  4.71it/s]Train epoch: 3 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.005092\n",
      "4050it [13:41,  4.70it/s]Train epoch: 3 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.004733\n",
      "4075it [13:47,  4.66it/s]Train epoch: 3 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.004799\n",
      "4100it [13:52,  4.64it/s]Train epoch: 3 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.005159\n",
      "4125it [13:57,  4.61it/s]Train epoch: 3 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.004995\n",
      "4150it [14:03,  4.65it/s]Train epoch: 3 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.004281\n",
      "4175it [14:08,  4.57it/s]Train epoch: 3 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.004459\n",
      "4200it [14:14,  4.59it/s]Train epoch: 3 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.004905\n",
      "4225it [14:19,  4.63it/s]Train epoch: 3 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.004211\n",
      "4250it [14:24,  4.62it/s]Train epoch: 3 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.004862\n",
      "4275it [14:30,  4.59it/s]Train epoch: 3 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.004533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300it [14:35,  4.63it/s]Train epoch: 3 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.005281\n",
      "4325it [14:41,  4.57it/s]Train epoch: 3 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.004653\n",
      "4350it [14:46,  4.66it/s]Train epoch: 3 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.005011\n",
      "4375it [14:52,  4.58it/s]Train epoch: 3 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.004477\n",
      "4400it [14:57,  4.71it/s]Train epoch: 3 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.003960\n",
      "4425it [15:02,  4.61it/s]Train epoch: 3 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.004744\n",
      "4450it [15:08,  4.56it/s]Train epoch: 3 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.003850\n",
      "4475it [15:13,  4.61it/s]Train epoch: 3 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.004750\n",
      "4500it [15:19,  4.55it/s]Train epoch: 3 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.005676\n",
      "4525it [15:24,  4.57it/s]Train epoch: 3 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.004751\n",
      "4550it [15:30,  4.63it/s]Train epoch: 3 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.004654\n",
      "4575it [15:35,  4.66it/s]Train epoch: 3 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.005206\n",
      "4600it [15:40,  4.57it/s]Train epoch: 3 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.004334\n",
      "4625it [15:46,  4.44it/s]Train epoch: 3 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.004553\n",
      "4650it [15:51,  4.61it/s]Train epoch: 3 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.005158\n",
      "4675it [15:57,  4.52it/s]Train epoch: 3 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.004861\n",
      "4700it [16:02,  4.61it/s]Train epoch: 3 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.004435\n",
      "4725it [16:08,  4.52it/s]Train epoch: 3 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.004660\n",
      "4750it [16:13,  4.52it/s]Train epoch: 3 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.005347\n",
      "4775it [16:19,  4.56it/s]Train epoch: 3 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.004770\n",
      "4800it [16:24,  4.58it/s]Train epoch: 3 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.004856\n",
      "4825it [16:30,  4.56it/s]Train epoch: 3 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.004459\n",
      "4850it [16:35,  4.54it/s]Train epoch: 3 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.005146\n",
      "4875it [16:41,  4.49it/s]Train epoch: 3 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.004329\n",
      "4900it [16:46,  4.57it/s]Train epoch: 3 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.004768\n",
      "4925it [16:52,  4.52it/s]Train epoch: 3 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.004387\n",
      "4950it [16:57,  4.54it/s]Train epoch: 3 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.004652\n",
      "4975it [17:03,  4.53it/s]Train epoch: 3 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.004630\n",
      "5000it [17:08,  4.54it/s]Train epoch: 3 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.004760\n",
      "5025it [17:14,  4.54it/s]Train epoch: 3 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.004330\n",
      "5050it [17:19,  4.53it/s]Train epoch: 3 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.004336\n",
      "5075it [17:25,  4.50it/s]Train epoch: 3 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.004733\n",
      "5100it [17:30,  4.53it/s]Train epoch: 3 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.004735\n",
      "5125it [17:36,  4.51it/s]Train epoch: 3 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.005080\n",
      "5150it [17:41,  4.51it/s]Train epoch: 3 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.004973\n",
      "5175it [17:47,  4.51it/s]Train epoch: 3 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.004905\n",
      "5200it [17:52,  4.50it/s]Train epoch: 3 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.004390\n",
      "5225it [17:58,  4.49it/s]Train epoch: 3 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.004793\n",
      "5250it [18:04,  4.51it/s]Train epoch: 3 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.004710\n",
      "5275it [18:09,  4.52it/s]Train epoch: 3 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.004584\n",
      "5300it [18:15,  4.48it/s]Train epoch: 3 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.004441\n",
      "5325it [18:20,  4.50it/s]Train epoch: 3 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.005118\n",
      "5350it [18:26,  4.53it/s]Train epoch: 3 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.005200\n",
      "5375it [18:31,  4.52it/s]Train epoch: 3 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.004573\n",
      "5400it [18:37,  4.49it/s]Train epoch: 3 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.004657\n",
      "5425it [18:42,  4.52it/s]Train epoch: 3 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.005014\n",
      "5450it [18:48,  4.49it/s]Train epoch: 3 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.004929\n",
      "5475it [18:54,  4.45it/s]Train epoch: 3 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.005670\n",
      "5500it [18:59,  4.41it/s]Train epoch: 3 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.005236\n",
      "5525it [19:05,  4.48it/s]Train epoch: 3 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.004320\n",
      "5550it [19:10,  4.46it/s]Train epoch: 3 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.004940\n",
      "5575it [19:16,  4.52it/s]Train epoch: 3 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.005046\n",
      "5600it [19:22,  4.47it/s]Train epoch: 3 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.005304\n",
      "5625it [19:27,  4.48it/s]Train epoch: 3 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.004818\n",
      "5650it [19:33,  4.49it/s]Train epoch: 3 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.004410\n",
      "5675it [19:38,  4.49it/s]Train epoch: 3 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.005479\n",
      "5700it [19:44,  4.50it/s]Train epoch: 3 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.004651\n",
      "5725it [19:50,  4.44it/s]Train epoch: 3 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.004905\n",
      "5750it [19:55,  4.44it/s]Train epoch: 3 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.006166\n",
      "5775it [20:01,  4.48it/s]Train epoch: 3 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.005105\n",
      "5800it [20:07,  4.48it/s]Train epoch: 3 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.005232\n",
      "5825it [20:12,  4.37it/s]Train epoch: 3 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.004513\n",
      "5850it [20:18,  4.41it/s]Train epoch: 3 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.005764\n",
      "5875it [20:23,  4.37it/s]Train epoch: 3 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.005450\n",
      "5900it [20:29,  4.47it/s]Train epoch: 3 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.005541\n",
      "5925it [20:35,  4.47it/s]Train epoch: 3 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.004650\n",
      "5950it [20:40,  4.43it/s]Train epoch: 3 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.004542\n",
      "5975it [20:46,  4.44it/s]Train epoch: 3 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.006128\n",
      "6000it [20:52,  4.52it/s]Train epoch: 3 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.005212\n",
      "6025it [20:57,  4.43it/s]Train epoch: 3 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.005443\n",
      "6050it [21:03,  4.43it/s]Train epoch: 3 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.004936\n",
      "6075it [21:09,  4.41it/s]Train epoch: 3 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.004637\n",
      "6100it [21:14,  4.45it/s]Train epoch: 3 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.004347\n",
      "6125it [21:20,  4.35it/s]Train epoch: 3 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.005091\n",
      "6150it [21:26,  4.39it/s]Train epoch: 3 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.004905\n",
      "6175it [21:31,  4.45it/s]Train epoch: 3 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.005508\n",
      "6200it [21:37,  4.41it/s]Train epoch: 3 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.004954\n",
      "6225it [21:43,  4.41it/s]Train epoch: 3 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.004304\n",
      "6250it [21:48,  4.41it/s]Train epoch: 3 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.004696\n",
      "6275it [21:54,  4.33it/s]Train epoch: 3 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.004298\n",
      "6300it [22:00,  4.38it/s]Train epoch: 3 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.005002\n",
      "6325it [22:05,  4.36it/s]Train epoch: 3 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.005392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6350it [22:11,  4.37it/s]Train epoch: 3 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.005546\n",
      "6375it [22:17,  4.39it/s]Train epoch: 3 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.004566\n",
      "6400it [22:22,  4.43it/s]Train epoch: 3 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.004841\n",
      "6425it [22:28,  4.35it/s]Train epoch: 3 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.005421\n",
      "6450it [22:34,  4.41it/s]Train epoch: 3 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.005318\n",
      "6475it [22:40,  4.42it/s]Train epoch: 3 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.004826\n",
      "6500it [22:45,  4.40it/s]Train epoch: 3 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.005601\n",
      "6525it [22:51,  4.38it/s]Train epoch: 3 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.004638\n",
      "6550it [22:57,  4.39it/s]Train epoch: 3 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.004868\n",
      "6575it [23:02,  4.41it/s]Train epoch: 3 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.005043\n",
      "6600it [23:08,  4.30it/s]Train epoch: 3 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.005894\n",
      "6625it [23:14,  4.31it/s]Train epoch: 3 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.004923\n",
      "6650it [23:20,  4.38it/s]Train epoch: 3 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.005686\n",
      "6675it [23:25,  4.36it/s]Train epoch: 3 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.005166\n",
      "6700it [23:31,  4.34it/s]Train epoch: 3 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.005184\n",
      "6725it [23:37,  4.31it/s]Train epoch: 3 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.005409\n",
      "6750it [23:43,  4.34it/s]Train epoch: 3 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.004760\n",
      "6775it [23:48,  4.28it/s]Train epoch: 3 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.005564\n",
      "6800it [23:54,  4.34it/s]Train epoch: 3 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.005391\n",
      "6825it [24:00,  4.35it/s]Train epoch: 3 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.005688\n",
      "6850it [24:06,  4.33it/s]Train epoch: 3 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.005352\n",
      "6875it [24:11,  4.30it/s]Train epoch: 3 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.004430\n",
      "6900it [24:17,  4.29it/s]Train epoch: 3 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.005131\n",
      "6925it [24:23,  4.31it/s]Train epoch: 3 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.005131\n",
      "6950it [24:29,  4.36it/s]Train epoch: 3 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.005755\n",
      "6975it [24:35,  4.33it/s]Train epoch: 3 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.005322\n",
      "7000it [24:40,  4.31it/s]Train epoch: 3 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.005052\n",
      "7025it [24:46,  4.30it/s]Train epoch: 3 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.005852\n",
      "7050it [24:52,  4.29it/s]Train epoch: 3 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.004580\n",
      "7075it [24:58,  4.33it/s]Train epoch: 3 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.005253\n",
      "7100it [25:04,  4.29it/s]Train epoch: 3 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.005470\n",
      "7125it [25:10,  4.23it/s]Train epoch: 3 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.004798\n",
      "7150it [25:15,  4.28it/s]Train epoch: 3 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.005913\n",
      "7175it [25:21,  4.31it/s]Train epoch: 3 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.005299\n",
      "7200it [25:27,  4.35it/s]Train epoch: 3 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.005757\n",
      "7225it [25:33,  4.34it/s]Train epoch: 3 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.005164\n",
      "7250it [25:39,  4.28it/s]Train epoch: 3 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.005077\n",
      "7275it [25:44,  4.31it/s]Train epoch: 3 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.005847\n",
      "7300it [25:50,  4.26it/s]Train epoch: 3 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.006113\n",
      "7325it [25:56,  4.21it/s]Train epoch: 3 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.004992\n",
      "7350it [26:02,  4.28it/s]Train epoch: 3 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.006177\n",
      "7375it [26:08,  4.29it/s]Train epoch: 3 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.005579\n",
      "7400it [26:14,  4.25it/s]Train epoch: 3 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.005001\n",
      "7425it [26:19,  4.27it/s]Train epoch: 3 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.005552\n",
      "7450it [26:25,  4.23it/s]Train epoch: 3 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.006119\n",
      "7475it [26:31,  4.25it/s]Train epoch: 3 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.005339\n",
      "7500it [26:37,  4.23it/s]Train epoch: 3 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.005633\n",
      "7525it [26:43,  4.25it/s]Train epoch: 3 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.005326\n",
      "7550it [26:49,  4.25it/s]Train epoch: 3 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.005162\n",
      "7575it [26:55,  4.25it/s]Train epoch: 3 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.005725\n",
      "7600it [27:01,  4.21it/s]Train epoch: 3 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.006664\n",
      "7625it [27:06,  4.25it/s]Train epoch: 3 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.006247\n",
      "7650it [27:12,  4.21it/s]Train epoch: 3 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.005262\n",
      "7675it [27:18,  4.18it/s]Train epoch: 3 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.005326\n",
      "7700it [27:24,  4.25it/s]Train epoch: 3 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.005402\n",
      "7725it [27:30,  4.19it/s]Train epoch: 3 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.005418\n",
      "7750it [27:36,  4.24it/s]Train epoch: 3 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.005713\n",
      "7775it [27:42,  4.30it/s]Train epoch: 3 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.005154\n",
      "7800it [27:48,  4.17it/s]Train epoch: 3 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.005388\n",
      "7825it [27:54,  4.28it/s]Train epoch: 3 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.005592\n",
      "7850it [28:00,  4.30it/s]Train epoch: 3 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.005077\n",
      "7875it [28:06,  4.16it/s]Train epoch: 3 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.005326\n",
      "7900it [28:12,  4.20it/s]Train epoch: 3 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.005625\n",
      "7925it [28:18,  4.24it/s]Train epoch: 3 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.005517\n",
      "7950it [28:23,  4.19it/s]Train epoch: 3 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.006181\n",
      "7975it [28:29,  4.23it/s]Train epoch: 3 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.005414\n",
      "8000it [28:35,  4.19it/s]Train epoch: 3 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.005216\n",
      "8025it [28:41,  4.15it/s]Train epoch: 3 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.005757\n",
      "8050it [28:47,  4.18it/s]Train epoch: 3 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.004843\n",
      "8075it [28:53,  4.23it/s]Train epoch: 3 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.005498\n",
      "8100it [28:59,  4.23it/s]Train epoch: 3 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.005815\n",
      "8125it [29:05,  4.18it/s]Train epoch: 3 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.005908\n",
      "8150it [29:11,  4.15it/s]Train epoch: 3 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.005292\n",
      "8175it [29:17,  4.15it/s]Train epoch: 3 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.005992\n",
      "8200it [29:23,  4.12it/s]Train epoch: 3 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.005064\n",
      "8225it [29:29,  4.12it/s]Train epoch: 3 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.006760\n",
      "8250it [29:35,  4.15it/s]Train epoch: 3 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.005260\n",
      "8275it [29:41,  4.13it/s]Train epoch: 3 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.006052\n",
      "8300it [29:47,  4.15it/s]Train epoch: 3 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.005166\n",
      "8325it [29:53,  4.13it/s]Train epoch: 3 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.005887\n",
      "8350it [29:59,  4.14it/s]Train epoch: 3 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.005283\n",
      "8375it [30:05,  4.13it/s]Train epoch: 3 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.005821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400it [30:11,  4.13it/s]Train epoch: 3 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.005423\n",
      "8425it [30:17,  4.12it/s]Train epoch: 3 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.005537\n",
      "8450it [30:23,  4.15it/s]Train epoch: 3 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.005847\n",
      "8475it [30:29,  4.17it/s]Train epoch: 3 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.005536\n",
      "8500it [30:36,  4.13it/s]Train epoch: 3 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.006424\n",
      "8525it [30:42,  4.10it/s]Train epoch: 3 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.005556\n",
      "8550it [30:48,  4.10it/s]Train epoch: 3 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.005971\n",
      "8575it [30:54,  4.17it/s]Train epoch: 3 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.005411\n",
      "8600it [31:00,  4.12it/s]Train epoch: 3 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.005597\n",
      "8625it [31:06,  4.12it/s]Train epoch: 3 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.005766\n",
      "8650it [31:12,  4.10it/s]Train epoch: 3 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.005872\n",
      "8675it [31:18,  4.08it/s]Train epoch: 3 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.006599\n",
      "8700it [31:24,  4.08it/s]Train epoch: 3 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.006447\n",
      "8725it [31:30,  4.06it/s]Train epoch: 3 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.006296\n",
      "8750it [31:36,  4.14it/s]Train epoch: 3 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.006102\n",
      "8775it [31:42,  4.05it/s]Train epoch: 3 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.005429\n",
      "8800it [31:49,  4.08it/s]Train epoch: 3 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.005735\n",
      "8825it [31:55,  4.04it/s]Train epoch: 3 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.005728\n",
      "8850it [32:01,  4.06it/s]Train epoch: 3 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.005971\n",
      "8875it [32:07,  4.06it/s]Train epoch: 3 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.005710\n",
      "8900it [32:13,  4.11it/s]Train epoch: 3 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.005741\n",
      "8925it [32:19,  4.02it/s]Train epoch: 3 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.006016\n",
      "8950it [32:25,  4.14it/s]Train epoch: 3 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.006736\n",
      "8975it [32:31,  4.14it/s]Train epoch: 3 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.006243\n",
      "9000it [32:38,  4.06it/s]Train epoch: 3 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.005867\n",
      "9025it [32:44,  4.05it/s]Train epoch: 3 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.005941\n",
      "9050it [32:50,  4.01it/s]Train epoch: 3 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.005562\n",
      "9075it [32:56,  4.05it/s]Train epoch: 3 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.005216\n",
      "9100it [33:02,  4.07it/s]Train epoch: 3 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.005959\n",
      "9125it [33:09,  4.05it/s]Train epoch: 3 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.005586\n",
      "9150it [33:15,  3.96it/s]Train epoch: 3 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.005264\n",
      "9175it [33:21,  4.07it/s]Train epoch: 3 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.005678\n",
      "9200it [33:27,  4.01it/s]Train epoch: 3 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.005659\n",
      "9225it [33:34,  4.01it/s]Train epoch: 3 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.006578\n",
      "9250it [33:40,  4.05it/s]Train epoch: 3 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.005830\n",
      "9275it [33:46,  4.02it/s]Train epoch: 3 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.006150\n",
      "9300it [33:52,  4.03it/s]Train epoch: 3 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.007017\n",
      "9325it [33:59,  4.08it/s]Train epoch: 3 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.006575\n",
      "9350it [34:05,  3.97it/s]Train epoch: 3 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.006492\n",
      "9375it [34:11,  3.99it/s]Train epoch: 3 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.005691\n",
      "9400it [34:17,  3.90it/s]Train epoch: 3 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.006106\n",
      "9425it [34:24,  4.01it/s]Train epoch: 3 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.005813\n",
      "9450it [34:30,  3.99it/s]Train epoch: 3 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.005875\n",
      "9475it [34:36,  3.95it/s]Train epoch: 3 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.006553\n",
      "9500it [34:42,  3.95it/s]Train epoch: 3 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.006097\n",
      "9525it [34:49,  3.94it/s]Train epoch: 3 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.006607\n",
      "9550it [34:55,  3.92it/s]Train epoch: 3 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.006351\n",
      "9575it [35:02,  3.91it/s]Train epoch: 3 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.006366\n",
      "9600it [35:08,  3.94it/s]Train epoch: 3 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.006235\n",
      "9625it [35:14,  3.85it/s]Train epoch: 3 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.005757\n",
      "9650it [35:21,  3.94it/s]Train epoch: 3 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.005795\n",
      "9675it [35:27,  3.96it/s]Train epoch: 3 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.006245\n",
      "9700it [35:33,  3.92it/s]Train epoch: 3 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.005501\n",
      "9725it [35:40,  3.94it/s]Train epoch: 3 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.006262\n",
      "9750it [35:46,  3.91it/s]Train epoch: 3 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.006095\n",
      "9775it [35:52,  3.95it/s]Train epoch: 3 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.006917\n",
      "9800it [35:59,  3.90it/s]Train epoch: 3 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.006651\n",
      "9825it [36:05,  3.89it/s]Train epoch: 3 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.006641\n",
      "9850it [36:12,  3.89it/s]Train epoch: 3 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.006143\n",
      "9875it [36:18,  3.89it/s]Train epoch: 3 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.006639\n",
      "9900it [36:25,  3.88it/s]Train epoch: 3 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.007216\n",
      "9925it [36:31,  3.86it/s]Train epoch: 3 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.006648\n",
      "9950it [36:37,  3.91it/s]Train epoch: 3 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.007247\n",
      "9975it [36:44,  3.85it/s]Train epoch: 3 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.006564\n",
      "10000it [36:50,  3.86it/s]Train epoch: 3 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.006214\n",
      "10025it [36:57,  3.86it/s]Train epoch: 3 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.006298\n",
      "10050it [37:03,  3.85it/s]Train epoch: 3 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.006547\n",
      "10075it [37:10,  3.85it/s]Train epoch: 3 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.007296\n",
      "10100it [37:16,  3.82it/s]Train epoch: 3 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.006603\n",
      "10125it [37:23,  3.84it/s]Train epoch: 3 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.006130\n",
      "10150it [37:29,  3.80it/s]Train epoch: 3 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.006726\n",
      "10175it [37:36,  3.82it/s]Train epoch: 3 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.006314\n",
      "10200it [37:42,  3.81it/s]Train epoch: 3 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.006826\n",
      "10225it [37:49,  3.81it/s]Train epoch: 3 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.006554\n",
      "10250it [37:55,  3.83it/s]Train epoch: 3 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.007187\n",
      "10275it [38:02,  3.84it/s]Train epoch: 3 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.006389\n",
      "10300it [38:08,  3.76it/s]Train epoch: 3 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.007022\n",
      "10325it [38:15,  3.79it/s]Train epoch: 3 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.007017\n",
      "10350it [38:22,  3.76it/s]Train epoch: 3 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.006652\n",
      "10375it [38:28,  3.75it/s]Train epoch: 3 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.006823\n",
      "10400it [38:35,  3.79it/s]Train epoch: 3 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.006942\n",
      "10425it [38:41,  3.75it/s]Train epoch: 3 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.006452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10450it [38:48,  3.74it/s]Train epoch: 3 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.006807\n",
      "10475it [38:55,  3.77it/s]Train epoch: 3 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.005947\n",
      "10500it [39:01,  3.75it/s]Train epoch: 3 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.006856\n",
      "10525it [39:08,  3.72it/s]Train epoch: 3 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.006602\n",
      "10550it [39:15,  3.76it/s]Train epoch: 3 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.006755\n",
      "10575it [39:21,  3.74it/s]Train epoch: 3 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.006136\n",
      "10600it [39:28,  3.70it/s]Train epoch: 3 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.006134\n",
      "10625it [39:35,  3.70it/s]Train epoch: 3 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.007072\n",
      "10650it [39:42,  3.72it/s]Train epoch: 3 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.006506\n",
      "10675it [39:48,  3.64it/s]Train epoch: 3 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.006946\n",
      "10700it [39:55,  3.72it/s]Train epoch: 3 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.006510\n",
      "10725it [40:02,  3.68it/s]Train epoch: 3 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.006016\n",
      "10750it [40:09,  3.67it/s]Train epoch: 3 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.007068\n",
      "10775it [40:15,  3.75it/s]Train epoch: 3 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.006965\n",
      "10800it [40:22,  3.65it/s]Train epoch: 3 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.007310\n",
      "10825it [40:29,  3.66it/s]Train epoch: 3 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.007298\n",
      "10850it [40:36,  3.67it/s]Train epoch: 3 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.007193\n",
      "10875it [40:43,  3.64it/s]Train epoch: 3 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.007217\n",
      "10900it [40:50,  3.64it/s]Train epoch: 3 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006988\n",
      "10925it [40:57,  3.61it/s]Train epoch: 3 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006448\n",
      "10950it [41:03,  3.60it/s]Train epoch: 3 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.007032\n",
      "10975it [41:10,  3.59it/s]Train epoch: 3 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006650\n",
      "11000it [41:17,  3.57it/s]Train epoch: 3 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006763\n",
      "11025it [41:24,  3.62it/s]Train epoch: 3 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006830\n",
      "11050it [41:31,  3.58it/s]Train epoch: 3 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007749\n",
      "11075it [41:38,  3.55it/s]Train epoch: 3 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.007066\n",
      "11100it [41:45,  3.60it/s]Train epoch: 3 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007864\n",
      "11125it [41:52,  3.60it/s]Train epoch: 3 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007316\n",
      "11150it [41:59,  3.56it/s]Train epoch: 3 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.007051\n",
      "11175it [42:06,  3.54it/s]Train epoch: 3 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.008204\n",
      "11200it [42:13,  3.56it/s]Train epoch: 3 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007380\n",
      "11225it [42:20,  3.50it/s]Train epoch: 3 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007186\n",
      "11250it [42:27,  3.54it/s]Train epoch: 3 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.008029\n",
      "11275it [42:34,  3.51it/s]Train epoch: 3 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007730\n",
      "11300it [42:42,  3.45it/s]Train epoch: 3 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.007040\n",
      "11325it [42:49,  3.47it/s]Train epoch: 3 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.008205\n",
      "11350it [42:56,  3.42it/s]Train epoch: 3 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.008179\n",
      "11375it [43:03,  3.43it/s]Train epoch: 3 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.008404\n",
      "11400it [43:10,  3.40it/s]Train epoch: 3 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007282\n",
      "11425it [43:18,  3.39it/s]Train epoch: 3 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007799\n",
      "11450it [43:25,  3.39it/s]Train epoch: 3 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.007266\n",
      "11475it [43:33,  3.36it/s]Train epoch: 3 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008549\n",
      "11500it [43:40,  3.36it/s]Train epoch: 3 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.008235\n",
      "11525it [43:47,  3.35it/s]Train epoch: 3 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007621\n",
      "11550it [43:55,  3.33it/s]Train epoch: 3 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007531\n",
      "11575it [44:02,  3.28it/s]Train epoch: 3 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008728\n",
      "11600it [44:10,  3.30it/s]Train epoch: 3 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007734\n",
      "11625it [44:18,  3.26it/s]Train epoch: 3 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007510\n",
      "11650it [44:25,  3.25it/s]Train epoch: 3 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.008177\n",
      "11675it [44:33,  3.24it/s]Train epoch: 3 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008572\n",
      "11700it [44:41,  3.18it/s]Train epoch: 3 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.009017\n",
      "11725it [44:49,  3.16it/s]Train epoch: 3 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.009180\n",
      "11750it [44:57,  3.11it/s]Train epoch: 3 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008800\n",
      "11775it [45:05,  3.09it/s]Train epoch: 3 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008659\n",
      "11800it [45:13,  3.02it/s]Train epoch: 3 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008503\n",
      "11825it [45:21,  2.98it/s]Train epoch: 3 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008802\n",
      "11850it [45:30,  2.95it/s]Train epoch: 3 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008817\n",
      "11875it [45:39,  2.77it/s]Train epoch: 3 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009878\n",
      "11900it [45:48,  2.61it/s]Train epoch: 3 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011954\n",
      "11925it [45:58,  2.32it/s]Train epoch: 3 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010033\n",
      "11930it [46:00,  4.32it/s]\n",
      "epoch loss: 0.005295532455811104\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.36it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0222, 0.0324, 0.0427, 0.0369, 0.8715\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2873, 0.4715, 0.4237, 0.4463, 0.9785\n",
      "rec_at_8: 0.3160\n",
      "prec_at_8: 0.5907\n",
      "rec_at_15: 0.4429\n",
      "prec_at_15: 0.4595\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:51, 30.34it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0217, 0.0341, 0.0429, 0.0380, 0.8642\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2798, 0.4645, 0.4131, 0.4373, 0.9778\n",
      "rec_at_8: 0.3025\n",
      "prec_at_8: 0.5865\n",
      "rec_at_15: 0.4233\n",
      "prec_at_15: 0.4563\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 3\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0222, 0.0324, 0.0427, 0.0369, 0.8715\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2873, 0.4715, 0.4237, 0.4463, 0.9785\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 3\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0217, 0.0341, 0.0429, 0.0380, 0.8642\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2798, 0.4645, 0.4131, 0.4373, 0.9778\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0082\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 4\n",
      "0it [00:00, ?it/s]Train epoch: 4 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.006591\n",
      "25it [00:04,  5.34it/s]Train epoch: 4 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.004519\n",
      "50it [00:09,  5.49it/s]Train epoch: 4 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.004197\n",
      "75it [00:13,  5.45it/s]Train epoch: 4 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.003398\n",
      "100it [00:18,  5.47it/s]Train epoch: 4 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.003587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125it [00:22,  5.32it/s]Train epoch: 4 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.003379\n",
      "150it [00:27,  5.33it/s]Train epoch: 4 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.003292\n",
      "175it [00:32,  5.40it/s]Train epoch: 4 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.003496\n",
      "200it [00:37,  5.32it/s]Train epoch: 4 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.003349\n",
      "225it [00:41,  5.31it/s]Train epoch: 4 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.004056\n",
      "250it [00:46,  5.33it/s]Train epoch: 4 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.003374\n",
      "275it [00:51,  5.28it/s]Train epoch: 4 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.002882\n",
      "300it [00:55,  5.25it/s]Train epoch: 4 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003757\n",
      "325it [01:00,  5.25it/s]Train epoch: 4 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.003099\n",
      "350it [01:05,  5.09it/s]Train epoch: 4 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.003740\n",
      "375it [01:10,  5.18it/s]Train epoch: 4 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.003562\n",
      "400it [01:15,  5.19it/s]Train epoch: 4 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.003540\n",
      "425it [01:19,  5.20it/s]Train epoch: 4 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.003449\n",
      "450it [01:24,  5.09it/s]Train epoch: 4 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.003349\n",
      "475it [01:29,  5.32it/s]Train epoch: 4 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.003807\n",
      "500it [01:34,  5.23it/s]Train epoch: 4 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.003221\n",
      "525it [01:39,  5.05it/s]Train epoch: 4 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.003545\n",
      "550it [01:44,  5.17it/s]Train epoch: 4 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.003547\n",
      "575it [01:48,  5.20it/s]Train epoch: 4 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.003482\n",
      "600it [01:53,  5.13it/s]Train epoch: 4 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.003765\n",
      "625it [01:58,  5.16it/s]Train epoch: 4 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.003595\n",
      "650it [02:03,  5.15it/s]Train epoch: 4 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.003172\n",
      "675it [02:08,  5.13it/s]Train epoch: 4 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002798\n",
      "700it [02:13,  5.13it/s]Train epoch: 4 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.003395\n",
      "725it [02:18,  5.09it/s]Train epoch: 4 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.003612\n",
      "750it [02:22,  5.08it/s]Train epoch: 4 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.003295\n",
      "775it [02:27,  5.04it/s]Train epoch: 4 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.003762\n",
      "800it [02:32,  5.08it/s]Train epoch: 4 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.003637\n",
      "825it [02:37,  5.09it/s]Train epoch: 4 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.003424\n",
      "850it [02:42,  4.97it/s]Train epoch: 4 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.003972\n",
      "875it [02:47,  5.05it/s]Train epoch: 4 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.003186\n",
      "900it [02:52,  5.05it/s]Train epoch: 4 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.003612\n",
      "925it [02:57,  5.11it/s]Train epoch: 4 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.003294\n",
      "950it [03:02,  5.05it/s]Train epoch: 4 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.003349\n",
      "975it [03:07,  5.05it/s]Train epoch: 4 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002638\n",
      "1000it [03:12,  5.09it/s]Train epoch: 4 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.003545\n",
      "1025it [03:17,  5.04it/s]Train epoch: 4 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.004687\n",
      "1050it [03:22,  5.04it/s]Train epoch: 4 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.003341\n",
      "1075it [03:27,  4.98it/s]Train epoch: 4 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.003649\n",
      "1100it [03:32,  5.01it/s]Train epoch: 4 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.003731\n",
      "1125it [03:37,  4.91it/s]Train epoch: 4 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.003818\n",
      "1150it [03:42,  5.08it/s]Train epoch: 4 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.003857\n",
      "1175it [03:47,  5.02it/s]Train epoch: 4 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.003745\n",
      "1200it [03:51,  5.02it/s]Train epoch: 4 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.003752\n",
      "1225it [03:56,  4.96it/s]Train epoch: 4 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.004011\n",
      "1250it [04:02,  4.90it/s]Train epoch: 4 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003680\n",
      "1275it [04:07,  4.94it/s]Train epoch: 4 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.003270\n",
      "1300it [04:12,  5.05it/s]Train epoch: 4 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.003162\n",
      "1325it [04:17,  4.97it/s]Train epoch: 4 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.003215\n",
      "1350it [04:22,  4.87it/s]Train epoch: 4 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.004362\n",
      "1375it [04:27,  4.92it/s]Train epoch: 4 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.003599\n",
      "1400it [04:32,  4.99it/s]Train epoch: 4 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.003516\n",
      "1425it [04:37,  4.99it/s]Train epoch: 4 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.003198\n",
      "1450it [04:42,  5.00it/s]Train epoch: 4 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.003561\n",
      "1475it [04:47,  4.97it/s]Train epoch: 4 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.003636\n",
      "1500it [04:52,  4.97it/s]Train epoch: 4 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.004808\n",
      "1525it [04:57,  4.95it/s]Train epoch: 4 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.004511\n",
      "1550it [05:02,  4.94it/s]Train epoch: 4 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.003442\n",
      "1575it [05:07,  4.94it/s]Train epoch: 4 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.003793\n",
      "1600it [05:12,  4.90it/s]Train epoch: 4 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.003279\n",
      "1625it [05:17,  4.93it/s]Train epoch: 4 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.003950\n",
      "1650it [05:22,  4.95it/s]Train epoch: 4 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.003958\n",
      "1675it [05:27,  4.94it/s]Train epoch: 4 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.003906\n",
      "1700it [05:32,  4.93it/s]Train epoch: 4 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.003477\n",
      "1725it [05:37,  4.93it/s]Train epoch: 4 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.002988\n",
      "1750it [05:42,  4.93it/s]Train epoch: 4 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.004419\n",
      "1775it [05:47,  4.92it/s]Train epoch: 4 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.003658\n",
      "1800it [05:52,  4.91it/s]Train epoch: 4 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.003608\n",
      "1825it [05:57,  4.91it/s]Train epoch: 4 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.003085\n",
      "1850it [06:02,  4.99it/s]Train epoch: 4 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.003800\n",
      "1875it [06:08,  4.94it/s]Train epoch: 4 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.003987\n",
      "1900it [06:13,  4.91it/s]Train epoch: 4 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.003067\n",
      "1925it [06:18,  4.89it/s]Train epoch: 4 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.003169\n",
      "1950it [06:23,  4.91it/s]Train epoch: 4 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.003229\n",
      "1975it [06:28,  4.88it/s]Train epoch: 4 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.003909\n",
      "2000it [06:33,  4.93it/s]Train epoch: 4 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.003117\n",
      "2025it [06:38,  4.95it/s]Train epoch: 4 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.003818\n",
      "2050it [06:43,  4.95it/s]Train epoch: 4 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.003550\n",
      "2075it [06:48,  4.88it/s]Train epoch: 4 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.003718\n",
      "2100it [06:53,  4.92it/s]Train epoch: 4 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.003885\n",
      "2125it [06:58,  4.91it/s]Train epoch: 4 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.004103\n",
      "2150it [07:04,  4.85it/s]Train epoch: 4 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.003490\n",
      "2175it [07:09,  4.83it/s]Train epoch: 4 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.003939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200it [07:14,  4.85it/s]Train epoch: 4 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.003712\n",
      "2225it [07:19,  4.87it/s]Train epoch: 4 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.003574\n",
      "2250it [07:24,  4.83it/s]Train epoch: 4 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.003333\n",
      "2275it [07:29,  4.93it/s]Train epoch: 4 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.003801\n",
      "2300it [07:34,  4.81it/s]Train epoch: 4 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.002903\n",
      "2325it [07:40,  4.85it/s]Train epoch: 4 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.003551\n",
      "2350it [07:45,  4.87it/s]Train epoch: 4 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.003390\n",
      "2375it [07:50,  4.80it/s]Train epoch: 4 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.004854\n",
      "2400it [07:55,  4.89it/s]Train epoch: 4 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.004520\n",
      "2425it [08:00,  4.91it/s]Train epoch: 4 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.003208\n",
      "2450it [08:05,  4.84it/s]Train epoch: 4 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.003696\n",
      "2475it [08:10,  4.78it/s]Train epoch: 4 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.004121\n",
      "2500it [08:15,  4.88it/s]Train epoch: 4 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.003496\n",
      "2525it [08:21,  4.91it/s]Train epoch: 4 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.003458\n",
      "2550it [08:26,  4.78it/s]Train epoch: 4 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.004671\n",
      "2575it [08:31,  4.85it/s]Train epoch: 4 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.003450\n",
      "2600it [08:36,  4.84it/s]Train epoch: 4 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.003714\n",
      "2625it [08:41,  4.73it/s]Train epoch: 4 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.003698\n",
      "2650it [08:46,  4.81it/s]Train epoch: 4 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.004332\n",
      "2675it [08:52,  4.80it/s]Train epoch: 4 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.003799\n",
      "2700it [08:57,  4.82it/s]Train epoch: 4 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.003335\n",
      "2725it [09:02,  4.93it/s]Train epoch: 4 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.003626\n",
      "2750it [09:07,  4.81it/s]Train epoch: 4 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.004246\n",
      "2775it [09:12,  4.77it/s]Train epoch: 4 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.003772\n",
      "2800it [09:18,  4.82it/s]Train epoch: 4 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.003555\n",
      "2825it [09:23,  4.80it/s]Train epoch: 4 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.003950\n",
      "2850it [09:28,  4.78it/s]Train epoch: 4 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.003697\n",
      "2875it [09:33,  4.84it/s]Train epoch: 4 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.004069\n",
      "2900it [09:38,  4.83it/s]Train epoch: 4 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.003995\n",
      "2925it [09:44,  4.78it/s]Train epoch: 4 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.003982\n",
      "2950it [09:49,  4.76it/s]Train epoch: 4 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.004272\n",
      "2975it [09:54,  4.81it/s]Train epoch: 4 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.003972\n",
      "3000it [09:59,  4.82it/s]Train epoch: 4 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.004507\n",
      "3025it [10:05,  4.77it/s]Train epoch: 4 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.004030\n",
      "3050it [10:10,  4.74it/s]Train epoch: 4 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.003552\n",
      "3075it [10:15,  4.80it/s]Train epoch: 4 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.004190\n",
      "3100it [10:20,  4.77it/s]Train epoch: 4 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.004252\n",
      "3125it [10:26,  4.75it/s]Train epoch: 4 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.003719\n",
      "3150it [10:31,  4.77it/s]Train epoch: 4 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.003648\n",
      "3175it [10:36,  4.83it/s]Train epoch: 4 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.003651\n",
      "3200it [10:41,  4.70it/s]Train epoch: 4 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.004372\n",
      "3225it [10:47,  4.85it/s]Train epoch: 4 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.004132\n",
      "3250it [10:52,  4.67it/s]Train epoch: 4 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.004089\n",
      "3275it [10:57,  4.71it/s]Train epoch: 4 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.003849\n",
      "3300it [11:02,  4.83it/s]Train epoch: 4 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.004667\n",
      "3325it [11:08,  4.81it/s]Train epoch: 4 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.004026\n",
      "3350it [11:13,  4.69it/s]Train epoch: 4 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.004095\n",
      "3375it [11:18,  4.69it/s]Train epoch: 4 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.004306\n",
      "3400it [11:24,  4.72it/s]Train epoch: 4 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.004279\n",
      "3425it [11:29,  4.66it/s]Train epoch: 4 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.003760\n",
      "3450it [11:34,  4.75it/s]Train epoch: 4 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.004346\n",
      "3475it [11:39,  4.67it/s]Train epoch: 4 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.003842\n",
      "3500it [11:45,  4.78it/s]Train epoch: 4 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.004050\n",
      "3525it [11:50,  4.74it/s]Train epoch: 4 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.004178\n",
      "3550it [11:55,  4.66it/s]Train epoch: 4 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.004451\n",
      "3575it [12:01,  4.69it/s]Train epoch: 4 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.003522\n",
      "3600it [12:06,  4.71it/s]Train epoch: 4 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.004544\n",
      "3625it [12:11,  4.73it/s]Train epoch: 4 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.004112\n",
      "3650it [12:17,  4.61it/s]Train epoch: 4 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.004243\n",
      "3675it [12:22,  4.69it/s]Train epoch: 4 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.004442\n",
      "3700it [12:27,  4.69it/s]Train epoch: 4 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.004272\n",
      "3725it [12:33,  4.70it/s]Train epoch: 4 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.004357\n",
      "3750it [12:38,  4.65it/s]Train epoch: 4 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.004447\n",
      "3775it [12:43,  4.66it/s]Train epoch: 4 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.004281\n",
      "3800it [12:49,  4.70it/s]Train epoch: 4 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.004713\n",
      "3825it [12:54,  4.66it/s]Train epoch: 4 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.003917\n",
      "3850it [12:59,  4.63it/s]Train epoch: 4 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.003640\n",
      "3875it [13:05,  4.70it/s]Train epoch: 4 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.003661\n",
      "3900it [13:10,  4.64it/s]Train epoch: 4 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.004694\n",
      "3925it [13:15,  4.68it/s]Train epoch: 4 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.004310\n",
      "3950it [13:21,  4.66it/s]Train epoch: 4 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.004625\n",
      "3975it [13:26,  4.67it/s]Train epoch: 4 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.005335\n",
      "4000it [13:31,  4.76it/s]Train epoch: 4 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.003818\n",
      "4025it [13:37,  4.69it/s]Train epoch: 4 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.004804\n",
      "4050it [13:42,  4.58it/s]Train epoch: 4 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.004366\n",
      "4075it [13:47,  4.70it/s]Train epoch: 4 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.004500\n",
      "4100it [13:53,  4.62it/s]Train epoch: 4 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.004837\n",
      "4125it [13:58,  4.62it/s]Train epoch: 4 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.004711\n",
      "4150it [14:04,  4.75it/s]Train epoch: 4 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.004031\n",
      "4175it [14:09,  4.62it/s]Train epoch: 4 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.004212\n",
      "4200it [14:14,  4.64it/s]Train epoch: 4 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.004590\n",
      "4225it [14:20,  4.70it/s]Train epoch: 4 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.003917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250it [14:25,  4.72it/s]Train epoch: 4 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.004469\n",
      "4275it [14:31,  4.58it/s]Train epoch: 4 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.004216\n",
      "4300it [14:36,  4.54it/s]Train epoch: 4 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.004950\n",
      "4325it [14:41,  4.61it/s]Train epoch: 4 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.004428\n",
      "4350it [14:47,  4.60it/s]Train epoch: 4 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.004685\n",
      "4375it [14:52,  4.67it/s]Train epoch: 4 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.004179\n",
      "4400it [14:58,  4.69it/s]Train epoch: 4 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.003683\n",
      "4425it [15:03,  4.58it/s]Train epoch: 4 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.004408\n",
      "4450it [15:09,  4.61it/s]Train epoch: 4 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.003654\n",
      "4475it [15:14,  4.62it/s]Train epoch: 4 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.004444\n",
      "4500it [15:19,  4.58it/s]Train epoch: 4 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.005288\n",
      "4525it [15:25,  4.59it/s]Train epoch: 4 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.004385\n",
      "4550it [15:30,  4.63it/s]Train epoch: 4 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.004367\n",
      "4575it [15:36,  4.63it/s]Train epoch: 4 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.004863\n",
      "4600it [15:41,  4.62it/s]Train epoch: 4 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.004020\n",
      "4625it [15:47,  4.58it/s]Train epoch: 4 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.004246\n",
      "4650it [15:52,  4.53it/s]Train epoch: 4 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.004858\n",
      "4675it [15:57,  4.56it/s]Train epoch: 4 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.004614\n",
      "4700it [16:03,  4.56it/s]Train epoch: 4 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.004145\n",
      "4725it [16:08,  4.59it/s]Train epoch: 4 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.004329\n",
      "4750it [16:14,  4.63it/s]Train epoch: 4 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.005020\n",
      "4775it [16:19,  4.62it/s]Train epoch: 4 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.004427\n",
      "4800it [16:25,  4.52it/s]Train epoch: 4 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.004560\n",
      "4825it [16:30,  4.59it/s]Train epoch: 4 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.004132\n",
      "4850it [16:36,  4.54it/s]Train epoch: 4 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.004795\n",
      "4875it [16:41,  4.48it/s]Train epoch: 4 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.004121\n",
      "4900it [16:47,  4.52it/s]Train epoch: 4 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.004418\n",
      "4925it [16:52,  4.57it/s]Train epoch: 4 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.004056\n",
      "4950it [16:58,  4.55it/s]Train epoch: 4 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.004332\n",
      "4975it [17:03,  4.56it/s]Train epoch: 4 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.004346\n",
      "5000it [17:09,  4.51it/s]Train epoch: 4 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.004483\n",
      "5025it [17:14,  4.51it/s]Train epoch: 4 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.004031\n",
      "5050it [17:20,  4.55it/s]Train epoch: 4 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.004084\n",
      "5075it [17:25,  4.61it/s]Train epoch: 4 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.004391\n",
      "5100it [17:31,  4.56it/s]Train epoch: 4 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.004434\n",
      "5125it [17:36,  4.50it/s]Train epoch: 4 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.004723\n",
      "5150it [17:42,  4.53it/s]Train epoch: 4 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.004669\n",
      "5175it [17:47,  4.43it/s]Train epoch: 4 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.004544\n",
      "5200it [17:53,  4.53it/s]Train epoch: 4 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.004098\n",
      "5225it [17:58,  4.47it/s]Train epoch: 4 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.004433\n",
      "5250it [18:04,  4.51it/s]Train epoch: 4 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.004383\n",
      "5275it [18:09,  4.51it/s]Train epoch: 4 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.004250\n",
      "5300it [18:15,  4.52it/s]Train epoch: 4 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.004136\n",
      "5325it [18:20,  4.51it/s]Train epoch: 4 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.004755\n",
      "5350it [18:26,  4.51it/s]Train epoch: 4 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.004845\n",
      "5375it [18:31,  4.48it/s]Train epoch: 4 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.004227\n",
      "5400it [18:37,  4.53it/s]Train epoch: 4 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.004366\n",
      "5425it [18:43,  4.52it/s]Train epoch: 4 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.004668\n",
      "5450it [18:48,  4.42it/s]Train epoch: 4 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.004655\n",
      "5475it [18:54,  4.53it/s]Train epoch: 4 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.005293\n",
      "5500it [18:59,  4.57it/s]Train epoch: 4 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.004940\n",
      "5525it [19:05,  4.48it/s]Train epoch: 4 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.004058\n",
      "5550it [19:10,  4.52it/s]Train epoch: 4 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.004620\n",
      "5575it [19:16,  4.53it/s]Train epoch: 4 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.004703\n",
      "5600it [19:22,  4.34it/s]Train epoch: 4 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.004949\n",
      "5625it [19:27,  4.55it/s]Train epoch: 4 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.004520\n",
      "5650it [19:33,  4.49it/s]Train epoch: 4 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.004200\n",
      "5675it [19:38,  4.49it/s]Train epoch: 4 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.005125\n",
      "5700it [19:44,  4.46it/s]Train epoch: 4 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.004371\n",
      "5725it [19:50,  4.47it/s]Train epoch: 4 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.004522\n",
      "5750it [19:55,  4.45it/s]Train epoch: 4 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.005809\n",
      "5775it [20:01,  4.43it/s]Train epoch: 4 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.004759\n",
      "5800it [20:06,  4.39it/s]Train epoch: 4 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.004928\n",
      "5825it [20:12,  4.37it/s]Train epoch: 4 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.004215\n",
      "5850it [20:18,  4.50it/s]Train epoch: 4 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.005457\n",
      "5875it [20:23,  4.42it/s]Train epoch: 4 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.005127\n",
      "5900it [20:29,  4.42it/s]Train epoch: 4 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.005127\n",
      "5925it [20:35,  4.41it/s]Train epoch: 4 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.004352\n",
      "5950it [20:40,  4.36it/s]Train epoch: 4 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.004198\n",
      "5975it [20:46,  4.43it/s]Train epoch: 4 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.005775\n",
      "6000it [20:52,  4.45it/s]Train epoch: 4 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.004874\n",
      "6025it [20:57,  4.39it/s]Train epoch: 4 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.005119\n",
      "6050it [21:03,  4.47it/s]Train epoch: 4 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.004628\n",
      "6075it [21:09,  4.40it/s]Train epoch: 4 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.004285\n",
      "6100it [21:14,  4.41it/s]Train epoch: 4 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.004067\n",
      "6125it [21:20,  4.38it/s]Train epoch: 4 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.004711\n",
      "6150it [21:26,  4.48it/s]Train epoch: 4 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.004655\n",
      "6175it [21:31,  4.43it/s]Train epoch: 4 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.005156\n",
      "6200it [21:37,  4.32it/s]Train epoch: 4 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.004691\n",
      "6225it [21:43,  4.43it/s]Train epoch: 4 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.004026\n",
      "6250it [21:48,  4.42it/s]Train epoch: 4 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.004445\n",
      "6275it [21:54,  4.46it/s]Train epoch: 4 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.003972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300it [22:00,  4.45it/s]Train epoch: 4 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.004645\n",
      "6325it [22:06,  4.37it/s]Train epoch: 4 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.005106\n",
      "6350it [22:11,  4.40it/s]Train epoch: 4 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.005310\n",
      "6375it [22:17,  4.36it/s]Train epoch: 4 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.004266\n",
      "6400it [22:23,  4.40it/s]Train epoch: 4 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.004552\n",
      "6425it [22:28,  4.36it/s]Train epoch: 4 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.005030\n",
      "6450it [22:34,  4.36it/s]Train epoch: 4 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.005012\n",
      "6475it [22:40,  4.47it/s]Train epoch: 4 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.004549\n",
      "6500it [22:46,  4.37it/s]Train epoch: 4 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.005282\n",
      "6525it [22:51,  4.39it/s]Train epoch: 4 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.004379\n",
      "6550it [22:57,  4.37it/s]Train epoch: 4 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.004550\n",
      "6575it [23:03,  4.35it/s]Train epoch: 4 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.004695\n",
      "6600it [23:08,  4.36it/s]Train epoch: 4 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.005522\n",
      "6625it [23:14,  4.35it/s]Train epoch: 4 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.004663\n",
      "6650it [23:20,  4.31it/s]Train epoch: 4 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.005271\n",
      "6675it [23:26,  4.37it/s]Train epoch: 4 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.004790\n",
      "6700it [23:31,  4.19it/s]Train epoch: 4 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.004887\n",
      "6725it [23:37,  4.35it/s]Train epoch: 4 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.005008\n",
      "6750it [23:43,  4.35it/s]Train epoch: 4 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.004467\n",
      "6775it [23:49,  4.33it/s]Train epoch: 4 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.005150\n",
      "6800it [23:54,  4.33it/s]Train epoch: 4 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.005107\n",
      "6825it [24:00,  4.28it/s]Train epoch: 4 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.005269\n",
      "6850it [24:06,  4.32it/s]Train epoch: 4 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.005108\n",
      "6875it [24:12,  4.33it/s]Train epoch: 4 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.004113\n",
      "6900it [24:18,  4.32it/s]Train epoch: 4 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.004793\n",
      "6925it [24:23,  4.31it/s]Train epoch: 4 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.004862\n",
      "6950it [24:29,  4.32it/s]Train epoch: 4 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.005401\n",
      "6975it [24:35,  4.35it/s]Train epoch: 4 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.005078\n",
      "7000it [24:41,  4.34it/s]Train epoch: 4 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.004729\n",
      "7025it [24:47,  4.29it/s]Train epoch: 4 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.005578\n",
      "7050it [24:52,  4.29it/s]Train epoch: 4 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.004321\n",
      "7075it [24:58,  4.39it/s]Train epoch: 4 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.004986\n",
      "7100it [25:04,  4.27it/s]Train epoch: 4 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.005068\n",
      "7125it [25:10,  4.29it/s]Train epoch: 4 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.004443\n",
      "7150it [25:16,  4.31it/s]Train epoch: 4 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.005558\n",
      "7175it [25:21,  4.34it/s]Train epoch: 4 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.004947\n",
      "7200it [25:27,  4.24it/s]Train epoch: 4 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.005419\n",
      "7225it [25:33,  4.27it/s]Train epoch: 4 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.004868\n",
      "7250it [25:39,  4.30it/s]Train epoch: 4 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.004750\n",
      "7275it [25:45,  4.29it/s]Train epoch: 4 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.005447\n",
      "7300it [25:51,  4.30it/s]Train epoch: 4 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.005744\n",
      "7325it [25:56,  4.26it/s]Train epoch: 4 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.004654\n",
      "7350it [26:02,  4.27it/s]Train epoch: 4 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.005733\n",
      "7375it [26:08,  4.26it/s]Train epoch: 4 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.005230\n",
      "7400it [26:14,  4.25it/s]Train epoch: 4 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.004771\n",
      "7425it [26:20,  4.20it/s]Train epoch: 4 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.005162\n",
      "7450it [26:26,  4.24it/s]Train epoch: 4 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.005731\n",
      "7475it [26:32,  4.23it/s]Train epoch: 4 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.005007\n",
      "7500it [26:38,  4.27it/s]Train epoch: 4 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.005274\n",
      "7525it [26:44,  4.27it/s]Train epoch: 4 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.005022\n",
      "7550it [26:49,  4.29it/s]Train epoch: 4 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.004780\n",
      "7575it [26:55,  4.22it/s]Train epoch: 4 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.005279\n",
      "7600it [27:01,  4.23it/s]Train epoch: 4 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.006260\n",
      "7625it [27:07,  4.23it/s]Train epoch: 4 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.005867\n",
      "7650it [27:13,  4.25it/s]Train epoch: 4 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.004972\n",
      "7675it [27:19,  4.19it/s]Train epoch: 4 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.004881\n",
      "7700it [27:25,  4.21it/s]Train epoch: 4 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.005092\n",
      "7725it [27:31,  4.19it/s]Train epoch: 4 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.005116\n",
      "7750it [27:37,  4.21it/s]Train epoch: 4 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.005405\n",
      "7775it [27:43,  4.23it/s]Train epoch: 4 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.004800\n",
      "7800it [27:49,  4.21it/s]Train epoch: 4 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.005043\n",
      "7825it [27:55,  4.17it/s]Train epoch: 4 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.005318\n",
      "7850it [28:01,  4.15it/s]Train epoch: 4 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.004720\n",
      "7875it [28:06,  4.31it/s]Train epoch: 4 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.005053\n",
      "7900it [28:12,  4.25it/s]Train epoch: 4 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.005196\n",
      "7925it [28:18,  4.22it/s]Train epoch: 4 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.005168\n",
      "7950it [28:24,  4.20it/s]Train epoch: 4 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.005804\n",
      "7975it [28:30,  4.21it/s]Train epoch: 4 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.005057\n",
      "8000it [28:36,  4.19it/s]Train epoch: 4 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.004841\n",
      "8025it [28:42,  4.15it/s]Train epoch: 4 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.005399\n",
      "8050it [28:48,  4.17it/s]Train epoch: 4 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.004543\n",
      "8075it [28:54,  4.18it/s]Train epoch: 4 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.005199\n",
      "8100it [29:00,  4.13it/s]Train epoch: 4 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.005549\n",
      "8125it [29:06,  4.12it/s]Train epoch: 4 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.005573\n",
      "8150it [29:12,  4.21it/s]Train epoch: 4 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.004958\n",
      "8175it [29:18,  4.17it/s]Train epoch: 4 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.005617\n",
      "8200it [29:24,  4.25it/s]Train epoch: 4 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.004740\n",
      "8225it [29:30,  4.17it/s]Train epoch: 4 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.006405\n",
      "8250it [29:36,  4.12it/s]Train epoch: 4 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.004899\n",
      "8275it [29:42,  4.15it/s]Train epoch: 4 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.005737\n",
      "8300it [29:48,  4.18it/s]Train epoch: 4 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.004883\n",
      "8325it [29:54,  4.19it/s]Train epoch: 4 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.005478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8350it [30:00,  4.12it/s]Train epoch: 4 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.004930\n",
      "8375it [30:06,  4.11it/s]Train epoch: 4 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.005496\n",
      "8400it [30:12,  4.11it/s]Train epoch: 4 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.005141\n",
      "8425it [30:18,  4.14it/s]Train epoch: 4 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.005176\n",
      "8450it [30:24,  4.08it/s]Train epoch: 4 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.005583\n",
      "8475it [30:30,  4.16it/s]Train epoch: 4 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.005211\n",
      "8500it [30:36,  4.10it/s]Train epoch: 4 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.006164\n",
      "8525it [30:42,  4.11it/s]Train epoch: 4 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.005254\n",
      "8550it [30:48,  4.17it/s]Train epoch: 4 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.005597\n",
      "8575it [30:55,  4.11it/s]Train epoch: 4 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.005102\n",
      "8600it [31:01,  4.13it/s]Train epoch: 4 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.005268\n",
      "8625it [31:07,  4.14it/s]Train epoch: 4 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.005449\n",
      "8650it [31:13,  4.11it/s]Train epoch: 4 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.005560\n",
      "8675it [31:19,  4.06it/s]Train epoch: 4 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.006211\n",
      "8700it [31:25,  4.11it/s]Train epoch: 4 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.006177\n",
      "8725it [31:31,  4.14it/s]Train epoch: 4 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.005954\n",
      "8750it [31:37,  4.07it/s]Train epoch: 4 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.005716\n",
      "8775it [31:43,  4.06it/s]Train epoch: 4 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.005086\n",
      "8800it [31:49,  4.09it/s]Train epoch: 4 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.005341\n",
      "8825it [31:55,  4.15it/s]Train epoch: 4 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.005458\n",
      "8850it [32:02,  4.07it/s]Train epoch: 4 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.005675\n",
      "8875it [32:08,  4.06it/s]Train epoch: 4 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.005352\n",
      "8900it [32:14,  4.08it/s]Train epoch: 4 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.005470\n",
      "8925it [32:20,  4.08it/s]Train epoch: 4 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.005697\n",
      "8950it [32:26,  4.02it/s]Train epoch: 4 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.006437\n",
      "8975it [32:32,  4.05it/s]Train epoch: 4 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.005811\n",
      "9000it [32:39,  4.05it/s]Train epoch: 4 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.005539\n",
      "9025it [32:45,  4.03it/s]Train epoch: 4 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.005592\n",
      "9050it [32:51,  4.03it/s]Train epoch: 4 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.005178\n",
      "9075it [32:57,  4.03it/s]Train epoch: 4 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.004876\n",
      "9100it [33:03,  4.00it/s]Train epoch: 4 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.005609\n",
      "9125it [33:10,  4.00it/s]Train epoch: 4 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.005231\n",
      "9150it [33:16,  4.02it/s]Train epoch: 4 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.004967\n",
      "9175it [33:22,  4.09it/s]Train epoch: 4 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.005334\n",
      "9200it [33:28,  4.02it/s]Train epoch: 4 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.005297\n",
      "9225it [33:34,  4.07it/s]Train epoch: 4 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.006145\n",
      "9250it [33:41,  4.10it/s]Train epoch: 4 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.005465\n",
      "9275it [33:47,  3.98it/s]Train epoch: 4 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.005879\n",
      "9300it [33:53,  3.99it/s]Train epoch: 4 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.006590\n",
      "9325it [33:59,  4.02it/s]Train epoch: 4 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.006277\n",
      "9350it [34:06,  3.97it/s]Train epoch: 4 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.006097\n",
      "9375it [34:12,  3.97it/s]Train epoch: 4 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.005354\n",
      "9400it [34:18,  4.04it/s]Train epoch: 4 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.005768\n",
      "9425it [34:24,  4.02it/s]Train epoch: 4 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.005478\n",
      "9450it [34:31,  3.94it/s]Train epoch: 4 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.005422\n",
      "9475it [34:37,  4.02it/s]Train epoch: 4 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.006197\n",
      "9500it [34:43,  3.98it/s]Train epoch: 4 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.005678\n",
      "9525it [34:50,  3.97it/s]Train epoch: 4 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.006261\n",
      "9550it [34:56,  3.92it/s]Train epoch: 4 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.006009\n",
      "9575it [35:02,  3.99it/s]Train epoch: 4 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.006022\n",
      "9600it [35:09,  3.95it/s]Train epoch: 4 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.005918\n",
      "9625it [35:15,  3.95it/s]Train epoch: 4 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.005489\n",
      "9650it [35:21,  4.01it/s]Train epoch: 4 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.005489\n",
      "9675it [35:28,  3.90it/s]Train epoch: 4 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.005897\n",
      "9700it [35:34,  3.94it/s]Train epoch: 4 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.005232\n",
      "9725it [35:40,  3.94it/s]Train epoch: 4 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.005929\n",
      "9750it [35:47,  3.88it/s]Train epoch: 4 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.005789\n",
      "9775it [35:53,  3.86it/s]Train epoch: 4 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.006413\n",
      "9800it [36:00,  3.92it/s]Train epoch: 4 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.006244\n",
      "9825it [36:06,  3.92it/s]Train epoch: 4 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.006296\n",
      "9850it [36:12,  3.92it/s]Train epoch: 4 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.005845\n",
      "9875it [36:19,  3.89it/s]Train epoch: 4 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.006235\n",
      "9900it [36:25,  3.89it/s]Train epoch: 4 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.006859\n",
      "9925it [36:32,  3.89it/s]Train epoch: 4 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.006313\n",
      "9950it [36:38,  3.86it/s]Train epoch: 4 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.006807\n",
      "9975it [36:44,  3.89it/s]Train epoch: 4 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.006206\n",
      "10000it [36:51,  3.89it/s]Train epoch: 4 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.005947\n",
      "10025it [36:57,  3.84it/s]Train epoch: 4 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.005999\n",
      "10050it [37:04,  3.86it/s]Train epoch: 4 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.006211\n",
      "10075it [37:10,  3.87it/s]Train epoch: 4 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.006816\n",
      "10100it [37:17,  3.91it/s]Train epoch: 4 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.006314\n",
      "10125it [37:23,  3.79it/s]Train epoch: 4 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.005770\n",
      "10150it [37:30,  3.88it/s]Train epoch: 4 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.006323\n",
      "10175it [37:36,  3.77it/s]Train epoch: 4 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.005971\n",
      "10200it [37:43,  3.79it/s]Train epoch: 4 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.006460\n",
      "10225it [37:49,  3.88it/s]Train epoch: 4 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.006268\n",
      "10250it [37:56,  3.85it/s]Train epoch: 4 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.006838\n",
      "10275it [38:02,  3.86it/s]Train epoch: 4 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.005989\n",
      "10300it [38:09,  3.81it/s]Train epoch: 4 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.006691\n",
      "10325it [38:15,  3.80it/s]Train epoch: 4 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.006674\n",
      "10350it [38:22,  3.82it/s]Train epoch: 4 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.006257\n",
      "10375it [38:29,  3.79it/s]Train epoch: 4 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.006501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400it [38:35,  3.81it/s]Train epoch: 4 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.006546\n",
      "10425it [38:42,  3.76it/s]Train epoch: 4 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.006074\n",
      "10450it [38:48,  3.74it/s]Train epoch: 4 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.006384\n",
      "10475it [38:55,  3.76it/s]Train epoch: 4 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.005648\n",
      "10500it [39:02,  3.81it/s]Train epoch: 4 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.006518\n",
      "10525it [39:08,  3.80it/s]Train epoch: 4 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.006241\n",
      "10550it [39:15,  3.78it/s]Train epoch: 4 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.006403\n",
      "10575it [39:22,  3.73it/s]Train epoch: 4 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.005753\n",
      "10600it [39:28,  3.74it/s]Train epoch: 4 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.005879\n",
      "10625it [39:35,  3.65it/s]Train epoch: 4 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.006799\n",
      "10650it [39:42,  3.72it/s]Train epoch: 4 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.006236\n",
      "10675it [39:49,  3.68it/s]Train epoch: 4 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.006567\n",
      "10700it [39:55,  3.72it/s]Train epoch: 4 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.006228\n",
      "10725it [40:02,  3.69it/s]Train epoch: 4 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.005732\n",
      "10750it [40:09,  3.67it/s]Train epoch: 4 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.006631\n",
      "10775it [40:16,  3.74it/s]Train epoch: 4 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.006582\n",
      "10800it [40:22,  3.64it/s]Train epoch: 4 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.006881\n",
      "10825it [40:29,  3.68it/s]Train epoch: 4 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006866\n",
      "10850it [40:36,  3.62it/s]Train epoch: 4 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006812\n",
      "10875it [40:43,  3.59it/s]Train epoch: 4 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006880\n",
      "10900it [40:50,  3.69it/s]Train epoch: 4 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006654\n",
      "10925it [40:56,  3.68it/s]Train epoch: 4 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006064\n",
      "10950it [41:03,  3.64it/s]Train epoch: 4 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006659\n",
      "10975it [41:10,  3.63it/s]Train epoch: 4 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006371\n",
      "11000it [41:17,  3.61it/s]Train epoch: 4 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006438\n",
      "11025it [41:24,  3.59it/s]Train epoch: 4 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006523\n",
      "11050it [41:31,  3.59it/s]Train epoch: 4 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007370\n",
      "11075it [41:38,  3.65it/s]Train epoch: 4 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006796\n",
      "11100it [41:45,  3.60it/s]Train epoch: 4 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007391\n",
      "11125it [41:52,  3.57it/s]Train epoch: 4 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007022\n",
      "11150it [41:59,  3.60it/s]Train epoch: 4 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006639\n",
      "11175it [42:06,  3.52it/s]Train epoch: 4 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007752\n",
      "11200it [42:13,  3.54it/s]Train epoch: 4 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007084\n",
      "11225it [42:20,  3.56it/s]Train epoch: 4 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006900\n",
      "11250it [42:27,  3.53it/s]Train epoch: 4 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007721\n",
      "11275it [42:34,  3.50it/s]Train epoch: 4 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007324\n",
      "11300it [42:41,  3.48it/s]Train epoch: 4 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006696\n",
      "11325it [42:49,  3.44it/s]Train epoch: 4 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007862\n",
      "11350it [42:56,  3.47it/s]Train epoch: 4 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007696\n",
      "11375it [43:03,  3.45it/s]Train epoch: 4 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007998\n",
      "11400it [43:10,  3.38it/s]Train epoch: 4 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006926\n",
      "11425it [43:18,  3.41it/s]Train epoch: 4 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007518\n",
      "11450it [43:25,  3.40it/s]Train epoch: 4 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006956\n",
      "11475it [43:32,  3.38it/s]Train epoch: 4 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008055\n",
      "11500it [43:40,  3.35it/s]Train epoch: 4 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007883\n",
      "11525it [43:47,  3.35it/s]Train epoch: 4 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007289\n",
      "11550it [43:55,  3.33it/s]Train epoch: 4 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007015\n",
      "11575it [44:02,  3.29it/s]Train epoch: 4 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008252\n",
      "11600it [44:10,  3.29it/s]Train epoch: 4 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007490\n",
      "11625it [44:17,  3.29it/s]Train epoch: 4 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007165\n",
      "11650it [44:25,  3.24it/s]Train epoch: 4 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007844\n",
      "11675it [44:33,  3.21it/s]Train epoch: 4 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008284\n",
      "11700it [44:41,  3.18it/s]Train epoch: 4 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008605\n",
      "11725it [44:49,  3.15it/s]Train epoch: 4 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008755\n",
      "11750it [44:57,  3.11it/s]Train epoch: 4 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008390\n",
      "11775it [45:05,  3.05it/s]Train epoch: 4 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008344\n",
      "11800it [45:13,  3.01it/s]Train epoch: 4 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008121\n",
      "11825it [45:21,  2.96it/s]Train epoch: 4 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008541\n",
      "11850it [45:30,  2.89it/s]Train epoch: 4 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008531\n",
      "11875it [45:39,  2.79it/s]Train epoch: 4 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009538\n",
      "11900it [45:48,  2.62it/s]Train epoch: 4 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011427\n",
      "11925it [45:58,  2.32it/s]Train epoch: 4 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009729\n",
      "11930it [46:00,  4.32it/s]\n",
      "epoch loss: 0.004982031387268555\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.26it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0252, 0.0362, 0.0475, 0.0410, 0.8774\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2965, 0.4772, 0.4393, 0.4574, 0.9796\n",
      "rec_at_8: 0.3237\n",
      "prec_at_8: 0.6019\n",
      "rec_at_15: 0.4537\n",
      "prec_at_15: 0.4693\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:51, 30.19it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0258, 0.0394, 0.0492, 0.0437, 0.8715\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2896, 0.4703, 0.4297, 0.4491, 0.9790\n",
      "rec_at_8: 0.3099\n",
      "prec_at_8: 0.5970\n",
      "rec_at_15: 0.4351\n",
      "prec_at_15: 0.4674\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0252, 0.0362, 0.0475, 0.0410, 0.8774\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2965, 0.4772, 0.4393, 0.4574, 0.9796\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0258, 0.0394, 0.0492, 0.0437, 0.8715\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2896, 0.4703, 0.4297, 0.4491, 0.9790\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0078\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 5\n",
      "0it [00:00, ?it/s]Train epoch: 5 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.006418\n",
      "25it [00:04,  5.52it/s]Train epoch: 5 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.004236\n",
      "50it [00:09,  5.54it/s]Train epoch: 5 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.004073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75it [00:13,  5.42it/s]Train epoch: 5 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.003156\n",
      "100it [00:18,  5.40it/s]Train epoch: 5 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.003407\n",
      "125it [00:22,  5.38it/s]Train epoch: 5 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.003261\n",
      "150it [00:27,  5.39it/s]Train epoch: 5 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.003067\n",
      "175it [00:32,  5.38it/s]Train epoch: 5 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.003371\n",
      "200it [00:36,  5.34it/s]Train epoch: 5 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.003149\n",
      "225it [00:41,  5.29it/s]Train epoch: 5 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.003853\n",
      "250it [00:46,  5.34it/s]Train epoch: 5 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.003153\n",
      "275it [00:50,  5.29it/s]Train epoch: 5 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.002734\n",
      "300it [00:55,  5.26it/s]Train epoch: 5 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003459\n",
      "325it [01:00,  5.27it/s]Train epoch: 5 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.002914\n",
      "350it [01:05,  5.20it/s]Train epoch: 5 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.003564\n",
      "375it [01:10,  5.20it/s]Train epoch: 5 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.003326\n",
      "400it [01:14,  5.19it/s]Train epoch: 5 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.003337\n",
      "425it [01:19,  5.14it/s]Train epoch: 5 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.003252\n",
      "450it [01:24,  5.26it/s]Train epoch: 5 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.003174\n",
      "475it [01:29,  5.14it/s]Train epoch: 5 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.003601\n",
      "500it [01:34,  5.12it/s]Train epoch: 5 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.003036\n",
      "525it [01:38,  5.21it/s]Train epoch: 5 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.003390\n",
      "550it [01:43,  5.18it/s]Train epoch: 5 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.003300\n",
      "575it [01:48,  5.22it/s]Train epoch: 5 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.003362\n",
      "600it [01:53,  5.14it/s]Train epoch: 5 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.003517\n",
      "625it [01:58,  5.15it/s]Train epoch: 5 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.003419\n",
      "650it [02:03,  5.22it/s]Train epoch: 5 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.003009\n",
      "675it [02:08,  5.08it/s]Train epoch: 5 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002671\n",
      "700it [02:12,  5.18it/s]Train epoch: 5 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.003208\n",
      "725it [02:17,  5.12it/s]Train epoch: 5 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.003425\n",
      "750it [02:22,  5.11it/s]Train epoch: 5 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.003147\n",
      "775it [02:27,  5.15it/s]Train epoch: 5 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.003545\n",
      "800it [02:32,  5.09it/s]Train epoch: 5 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.003458\n",
      "825it [02:37,  5.08it/s]Train epoch: 5 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.003307\n",
      "850it [02:42,  5.07it/s]Train epoch: 5 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.003802\n",
      "875it [02:47,  5.19it/s]Train epoch: 5 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.003053\n",
      "900it [02:52,  5.12it/s]Train epoch: 5 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.003489\n",
      "925it [02:56,  5.09it/s]Train epoch: 5 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.003119\n",
      "950it [03:01,  5.09it/s]Train epoch: 5 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.003136\n",
      "975it [03:06,  5.00it/s]Train epoch: 5 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002545\n",
      "1000it [03:11,  5.09it/s]Train epoch: 5 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.003394\n",
      "1025it [03:16,  5.05it/s]Train epoch: 5 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.004510\n",
      "1050it [03:21,  5.03it/s]Train epoch: 5 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.003094\n",
      "1075it [03:26,  5.01it/s]Train epoch: 5 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.003494\n",
      "1100it [03:31,  5.04it/s]Train epoch: 5 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.003554\n",
      "1125it [03:36,  5.08it/s]Train epoch: 5 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.003623\n",
      "1150it [03:41,  5.01it/s]Train epoch: 5 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.003636\n",
      "1175it [03:46,  5.07it/s]Train epoch: 5 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.003516\n",
      "1200it [03:51,  5.09it/s]Train epoch: 5 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.003568\n",
      "1225it [03:56,  5.02it/s]Train epoch: 5 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.003796\n",
      "1250it [04:01,  5.01it/s]Train epoch: 5 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003494\n",
      "1275it [04:06,  5.01it/s]Train epoch: 5 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.003055\n",
      "1300it [04:11,  4.94it/s]Train epoch: 5 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.003057\n",
      "1325it [04:16,  5.03it/s]Train epoch: 5 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.003050\n",
      "1350it [04:21,  5.01it/s]Train epoch: 5 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.004140\n",
      "1375it [04:26,  5.00it/s]Train epoch: 5 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.003455\n",
      "1400it [04:31,  5.04it/s]Train epoch: 5 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.003367\n",
      "1425it [04:36,  5.04it/s]Train epoch: 5 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.003020\n",
      "1450it [04:41,  4.98it/s]Train epoch: 5 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.003402\n",
      "1475it [04:46,  4.96it/s]Train epoch: 5 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.003448\n",
      "1500it [04:51,  4.99it/s]Train epoch: 5 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.004609\n",
      "1525it [04:56,  4.97it/s]Train epoch: 5 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.004265\n",
      "1550it [05:01,  4.98it/s]Train epoch: 5 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.003227\n",
      "1575it [05:06,  4.99it/s]Train epoch: 5 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.003630\n",
      "1600it [05:11,  5.04it/s]Train epoch: 5 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.003116\n",
      "1625it [05:16,  4.93it/s]Train epoch: 5 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.003794\n",
      "1650it [05:21,  4.88it/s]Train epoch: 5 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.003806\n",
      "1675it [05:26,  4.94it/s]Train epoch: 5 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.003703\n",
      "1700it [05:31,  4.99it/s]Train epoch: 5 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.003254\n",
      "1725it [05:37,  4.93it/s]Train epoch: 5 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.002840\n",
      "1750it [05:42,  4.92it/s]Train epoch: 5 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.004257\n",
      "1775it [05:47,  4.91it/s]Train epoch: 5 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.003467\n",
      "1800it [05:52,  4.91it/s]Train epoch: 5 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.003439\n",
      "1825it [05:57,  4.96it/s]Train epoch: 5 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.002963\n",
      "1850it [06:02,  4.88it/s]Train epoch: 5 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.003617\n",
      "1875it [06:07,  4.95it/s]Train epoch: 5 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.003820\n",
      "1900it [06:12,  4.93it/s]Train epoch: 5 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.002832\n",
      "1925it [06:17,  4.91it/s]Train epoch: 5 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.003052\n",
      "1950it [06:22,  4.95it/s]Train epoch: 5 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.003032\n",
      "1975it [06:27,  4.97it/s]Train epoch: 5 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.003697\n",
      "2000it [06:32,  4.94it/s]Train epoch: 5 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.002927\n",
      "2025it [06:37,  4.91it/s]Train epoch: 5 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.003594\n",
      "2050it [06:42,  4.90it/s]Train epoch: 5 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.003367\n",
      "2075it [06:48,  4.91it/s]Train epoch: 5 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.003552\n",
      "2100it [06:53,  5.00it/s]Train epoch: 5 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.003615\n",
      "2125it [06:58,  4.99it/s]Train epoch: 5 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.003979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2150it [07:03,  4.83it/s]Train epoch: 5 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.003376\n",
      "2175it [07:08,  4.83it/s]Train epoch: 5 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.003742\n",
      "2200it [07:13,  4.85it/s]Train epoch: 5 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.003524\n",
      "2225it [07:18,  4.86it/s]Train epoch: 5 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.003410\n",
      "2250it [07:23,  4.93it/s]Train epoch: 5 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.003123\n",
      "2275it [07:29,  4.91it/s]Train epoch: 5 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.003580\n",
      "2300it [07:34,  4.90it/s]Train epoch: 5 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.002724\n",
      "2325it [07:39,  4.63it/s]Train epoch: 5 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.003398\n",
      "2350it [07:44,  4.89it/s]Train epoch: 5 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.003252\n",
      "2375it [07:49,  4.87it/s]Train epoch: 5 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.004619\n",
      "2400it [07:55,  4.82it/s]Train epoch: 5 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.004309\n",
      "2425it [08:00,  4.78it/s]Train epoch: 5 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.003035\n",
      "2450it [08:05,  4.83it/s]Train epoch: 5 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.003504\n",
      "2475it [08:10,  4.67it/s]Train epoch: 5 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.003910\n",
      "2500it [08:15,  4.88it/s]Train epoch: 5 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.003331\n",
      "2525it [08:20,  4.82it/s]Train epoch: 5 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.003320\n",
      "2550it [08:26,  4.90it/s]Train epoch: 5 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.004496\n",
      "2575it [08:31,  4.76it/s]Train epoch: 5 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.003272\n",
      "2600it [08:36,  4.93it/s]Train epoch: 5 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.003546\n",
      "2625it [08:41,  4.81it/s]Train epoch: 5 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.003532\n",
      "2650it [08:46,  4.82it/s]Train epoch: 5 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.004091\n",
      "2675it [08:52,  4.84it/s]Train epoch: 5 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.003637\n",
      "2700it [08:57,  4.71it/s]Train epoch: 5 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.003156\n",
      "2725it [09:02,  4.83it/s]Train epoch: 5 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.003397\n",
      "2750it [09:07,  4.82it/s]Train epoch: 5 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.004052\n",
      "2775it [09:12,  4.88it/s]Train epoch: 5 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.003553\n",
      "2800it [09:18,  4.81it/s]Train epoch: 5 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.003419\n",
      "2825it [09:23,  4.73it/s]Train epoch: 5 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.003785\n",
      "2850it [09:28,  4.72it/s]Train epoch: 5 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.003525\n",
      "2875it [09:33,  4.81it/s]Train epoch: 5 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.003856\n",
      "2900it [09:39,  4.66it/s]Train epoch: 5 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.003799\n",
      "2925it [09:44,  4.77it/s]Train epoch: 5 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.003821\n",
      "2950it [09:49,  4.73it/s]Train epoch: 5 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.004107\n",
      "2975it [09:54,  4.81it/s]Train epoch: 5 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.003717\n",
      "3000it [09:59,  4.83it/s]Train epoch: 5 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.004326\n",
      "3025it [10:05,  4.75it/s]Train epoch: 5 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.003876\n",
      "3050it [10:10,  4.79it/s]Train epoch: 5 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.003418\n",
      "3075it [10:15,  4.79it/s]Train epoch: 5 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.003977\n",
      "3100it [10:20,  4.75it/s]Train epoch: 5 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.004024\n",
      "3125it [10:26,  4.74it/s]Train epoch: 5 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.003541\n",
      "3150it [10:31,  4.77it/s]Train epoch: 5 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.003467\n",
      "3175it [10:36,  4.73it/s]Train epoch: 5 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.003504\n",
      "3200it [10:42,  4.71it/s]Train epoch: 5 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.004142\n",
      "3225it [10:47,  4.82it/s]Train epoch: 5 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.003922\n",
      "3250it [10:52,  4.76it/s]Train epoch: 5 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.003933\n",
      "3275it [10:57,  4.79it/s]Train epoch: 5 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.003600\n",
      "3300it [11:03,  4.73it/s]Train epoch: 5 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.004422\n",
      "3325it [11:08,  4.68it/s]Train epoch: 5 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.003795\n",
      "3350it [11:13,  4.76it/s]Train epoch: 5 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.003922\n",
      "3375it [11:19,  4.72it/s]Train epoch: 5 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.004131\n",
      "3400it [11:24,  4.73it/s]Train epoch: 5 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.004067\n",
      "3425it [11:29,  4.69it/s]Train epoch: 5 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.003559\n",
      "3450it [11:34,  4.74it/s]Train epoch: 5 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.004165\n",
      "3475it [11:40,  4.73it/s]Train epoch: 5 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.003577\n",
      "3500it [11:45,  4.66it/s]Train epoch: 5 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.003816\n",
      "3525it [11:50,  4.63it/s]Train epoch: 5 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.003918\n",
      "3550it [11:56,  4.66it/s]Train epoch: 5 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.004167\n",
      "3575it [12:01,  4.70it/s]Train epoch: 5 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.003348\n",
      "3600it [12:06,  4.68it/s]Train epoch: 5 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.004367\n",
      "3625it [12:12,  4.72it/s]Train epoch: 5 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.003899\n",
      "3650it [12:17,  4.68it/s]Train epoch: 5 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.004019\n",
      "3675it [12:22,  4.68it/s]Train epoch: 5 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.004223\n",
      "3700it [12:28,  4.70it/s]Train epoch: 5 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.003997\n",
      "3725it [12:33,  4.69it/s]Train epoch: 5 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.004132\n",
      "3750it [12:38,  4.65it/s]Train epoch: 5 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.004225\n",
      "3775it [12:44,  4.72it/s]Train epoch: 5 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.003999\n",
      "3800it [12:49,  4.77it/s]Train epoch: 5 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.004428\n",
      "3825it [12:54,  4.68it/s]Train epoch: 5 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.003775\n",
      "3850it [13:00,  4.67it/s]Train epoch: 5 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.003447\n",
      "3875it [13:05,  4.65it/s]Train epoch: 5 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.003476\n",
      "3900it [13:11,  4.64it/s]Train epoch: 5 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.004442\n",
      "3925it [13:16,  4.66it/s]Train epoch: 5 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.004115\n",
      "3950it [13:21,  4.64it/s]Train epoch: 5 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.004427\n",
      "3975it [13:27,  4.61it/s]Train epoch: 5 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.005048\n",
      "4000it [13:32,  4.64it/s]Train epoch: 5 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.003597\n",
      "4025it [13:37,  4.65it/s]Train epoch: 5 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.004591\n",
      "4050it [13:43,  4.69it/s]Train epoch: 5 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.004170\n",
      "4075it [13:48,  4.64it/s]Train epoch: 5 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.004192\n",
      "4100it [13:54,  4.67it/s]Train epoch: 5 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.004581\n",
      "4125it [13:59,  4.63it/s]Train epoch: 5 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.004451\n",
      "4150it [14:04,  4.62it/s]Train epoch: 5 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.003848\n",
      "4175it [14:10,  4.62it/s]Train epoch: 5 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.003963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200it [14:15,  4.60it/s]Train epoch: 5 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.004355\n",
      "4225it [14:21,  4.67it/s]Train epoch: 5 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.003808\n",
      "4250it [14:26,  4.64it/s]Train epoch: 5 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.004281\n",
      "4275it [14:31,  4.63it/s]Train epoch: 5 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.003943\n",
      "4300it [14:37,  4.62it/s]Train epoch: 5 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.004659\n",
      "4325it [14:42,  4.50it/s]Train epoch: 5 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.004193\n",
      "4350it [14:48,  4.53it/s]Train epoch: 5 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.004452\n",
      "4375it [14:53,  4.58it/s]Train epoch: 5 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.003964\n",
      "4400it [14:59,  4.62it/s]Train epoch: 5 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.003480\n",
      "4425it [15:04,  4.54it/s]Train epoch: 5 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.004275\n",
      "4450it [15:09,  4.63it/s]Train epoch: 5 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.003476\n",
      "4475it [15:15,  4.59it/s]Train epoch: 5 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.004168\n",
      "4500it [15:20,  4.60it/s]Train epoch: 5 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.005043\n",
      "4525it [15:26,  4.58it/s]Train epoch: 5 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.004110\n",
      "4550it [15:31,  4.56it/s]Train epoch: 5 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.004109\n",
      "4575it [15:37,  4.55it/s]Train epoch: 5 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.004595\n",
      "4600it [15:42,  4.59it/s]Train epoch: 5 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.003756\n",
      "4625it [15:48,  4.55it/s]Train epoch: 5 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.003986\n",
      "4650it [15:53,  4.67it/s]Train epoch: 5 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.004614\n",
      "4675it [15:59,  4.62it/s]Train epoch: 5 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.004402\n",
      "4700it [16:04,  4.63it/s]Train epoch: 5 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.003884\n",
      "4725it [16:10,  4.55it/s]Train epoch: 5 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.004135\n",
      "4750it [16:15,  4.56it/s]Train epoch: 5 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.004838\n",
      "4775it [16:20,  4.49it/s]Train epoch: 5 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.004206\n",
      "4800it [16:26,  4.61it/s]Train epoch: 5 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.004260\n",
      "4825it [16:31,  4.53it/s]Train epoch: 5 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.003907\n",
      "4850it [16:37,  4.52it/s]Train epoch: 5 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.004578\n",
      "4875it [16:42,  4.54it/s]Train epoch: 5 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.003966\n",
      "4900it [16:48,  4.61it/s]Train epoch: 5 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.004229\n",
      "4925it [16:53,  4.54it/s]Train epoch: 5 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.003864\n",
      "4950it [16:59,  4.54it/s]Train epoch: 5 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.004093\n",
      "4975it [17:05,  4.49it/s]Train epoch: 5 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.004141\n",
      "5000it [17:10,  4.53it/s]Train epoch: 5 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.004270\n",
      "5025it [17:16,  4.54it/s]Train epoch: 5 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.003869\n",
      "5050it [17:21,  4.57it/s]Train epoch: 5 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.003838\n",
      "5075it [17:26,  4.53it/s]Train epoch: 5 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.004234\n",
      "5100it [17:32,  4.57it/s]Train epoch: 5 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.004229\n",
      "5125it [17:38,  4.63it/s]Train epoch: 5 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.004493\n",
      "5150it [17:43,  4.51it/s]Train epoch: 5 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.004397\n",
      "5175it [17:49,  4.52it/s]Train epoch: 5 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.004344\n",
      "5200it [17:54,  4.53it/s]Train epoch: 5 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.003964\n",
      "5225it [18:00,  4.58it/s]Train epoch: 5 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.004265\n",
      "5250it [18:05,  4.60it/s]Train epoch: 5 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.004171\n",
      "5275it [18:11,  4.51it/s]Train epoch: 5 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.004030\n",
      "5300it [18:16,  4.46it/s]Train epoch: 5 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.003928\n",
      "5325it [18:22,  4.57it/s]Train epoch: 5 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.004534\n",
      "5350it [18:27,  4.51it/s]Train epoch: 5 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.004581\n",
      "5375it [18:33,  4.52it/s]Train epoch: 5 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.004048\n",
      "5400it [18:38,  4.49it/s]Train epoch: 5 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.004136\n",
      "5425it [18:44,  4.45it/s]Train epoch: 5 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.004493\n",
      "5450it [18:50,  4.48it/s]Train epoch: 5 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.004328\n",
      "5475it [18:55,  4.48it/s]Train epoch: 5 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.004976\n",
      "5500it [19:01,  4.51it/s]Train epoch: 5 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.004684\n",
      "5525it [19:06,  4.56it/s]Train epoch: 5 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.003835\n",
      "5550it [19:12,  4.50it/s]Train epoch: 5 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.004355\n",
      "5575it [19:17,  4.42it/s]Train epoch: 5 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.004436\n",
      "5600it [19:23,  4.49it/s]Train epoch: 5 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.004716\n",
      "5625it [19:29,  4.45it/s]Train epoch: 5 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.004336\n",
      "5650it [19:34,  4.47it/s]Train epoch: 5 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.003999\n",
      "5675it [19:40,  4.49it/s]Train epoch: 5 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.004874\n",
      "5700it [19:45,  4.46it/s]Train epoch: 5 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.004188\n",
      "5725it [19:51,  4.48it/s]Train epoch: 5 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.004306\n",
      "5750it [19:57,  4.44it/s]Train epoch: 5 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.005573\n",
      "5775it [20:02,  4.43it/s]Train epoch: 5 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.004496\n",
      "5800it [20:08,  4.45it/s]Train epoch: 5 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.004642\n",
      "5825it [20:14,  4.46it/s]Train epoch: 5 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.003999\n",
      "5850it [20:19,  4.46it/s]Train epoch: 5 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.005219\n",
      "5875it [20:25,  4.48it/s]Train epoch: 5 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.004876\n",
      "5900it [20:30,  4.48it/s]Train epoch: 5 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.004807\n",
      "5925it [20:36,  4.44it/s]Train epoch: 5 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.004166\n",
      "5950it [20:42,  4.41it/s]Train epoch: 5 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.003990\n",
      "5975it [20:47,  4.46it/s]Train epoch: 5 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.005537\n",
      "6000it [20:53,  4.40it/s]Train epoch: 5 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.004606\n",
      "6025it [20:59,  4.44it/s]Train epoch: 5 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.004883\n",
      "6050it [21:04,  4.42it/s]Train epoch: 5 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.004388\n",
      "6075it [21:10,  4.49it/s]Train epoch: 5 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.004062\n",
      "6100it [21:16,  4.48it/s]Train epoch: 5 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.003840\n",
      "6125it [21:21,  4.40it/s]Train epoch: 5 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.004444\n",
      "6150it [21:27,  4.40it/s]Train epoch: 5 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.004442\n",
      "6175it [21:32,  4.39it/s]Train epoch: 5 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.004975\n",
      "6200it [21:38,  4.41it/s]Train epoch: 5 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.004448\n",
      "6225it [21:44,  4.43it/s]Train epoch: 5 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.003810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250it [21:49,  4.40it/s]Train epoch: 5 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.004165\n",
      "6275it [21:55,  4.40it/s]Train epoch: 5 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.003766\n",
      "6300it [22:01,  4.41it/s]Train epoch: 5 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.004422\n",
      "6325it [22:06,  4.45it/s]Train epoch: 5 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.004903\n",
      "6350it [22:12,  4.38it/s]Train epoch: 5 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.005099\n",
      "6375it [22:18,  4.35it/s]Train epoch: 5 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.003977\n",
      "6400it [22:24,  4.46it/s]Train epoch: 5 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.004321\n",
      "6425it [22:29,  4.37it/s]Train epoch: 5 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.004815\n",
      "6450it [22:35,  4.40it/s]Train epoch: 5 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.004776\n",
      "6475it [22:41,  4.28it/s]Train epoch: 5 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.004329\n",
      "6500it [22:46,  4.43it/s]Train epoch: 5 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.005003\n",
      "6525it [22:52,  4.42it/s]Train epoch: 5 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.004202\n",
      "6550it [22:58,  4.38it/s]Train epoch: 5 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.004339\n",
      "6575it [23:03,  4.41it/s]Train epoch: 5 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.004455\n",
      "6600it [23:09,  4.34it/s]Train epoch: 5 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.005279\n",
      "6625it [23:15,  4.33it/s]Train epoch: 5 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.004486\n",
      "6650it [23:21,  4.32it/s]Train epoch: 5 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.005114\n",
      "6675it [23:26,  4.33it/s]Train epoch: 5 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.004556\n",
      "6700it [23:32,  4.36it/s]Train epoch: 5 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.004715\n",
      "6725it [23:38,  4.35it/s]Train epoch: 5 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.004792\n",
      "6750it [23:44,  4.38it/s]Train epoch: 5 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.004279\n",
      "6775it [23:49,  4.31it/s]Train epoch: 5 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.005028\n",
      "6800it [23:55,  4.33it/s]Train epoch: 5 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.004888\n",
      "6825it [24:01,  4.32it/s]Train epoch: 5 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.005006\n",
      "6850it [24:07,  4.33it/s]Train epoch: 5 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.004819\n",
      "6875it [24:13,  4.35it/s]Train epoch: 5 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.003878\n",
      "6900it [24:18,  4.29it/s]Train epoch: 5 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.004594\n",
      "6925it [24:24,  4.32it/s]Train epoch: 5 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.004637\n",
      "6950it [24:30,  4.34it/s]Train epoch: 5 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.005156\n",
      "6975it [24:36,  4.31it/s]Train epoch: 5 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.004830\n",
      "7000it [24:41,  4.31it/s]Train epoch: 5 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.004498\n",
      "7025it [24:47,  4.38it/s]Train epoch: 5 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.005355\n",
      "7050it [24:53,  4.32it/s]Train epoch: 5 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.004058\n",
      "7075it [24:59,  4.28it/s]Train epoch: 5 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.004715\n",
      "7100it [25:05,  4.28it/s]Train epoch: 5 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.004779\n",
      "7125it [25:10,  4.29it/s]Train epoch: 5 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.004307\n",
      "7150it [25:16,  4.32it/s]Train epoch: 5 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.005279\n",
      "7175it [25:22,  4.29it/s]Train epoch: 5 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.004751\n",
      "7200it [25:28,  4.31it/s]Train epoch: 5 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.005194\n",
      "7225it [25:34,  4.29it/s]Train epoch: 5 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.004618\n",
      "7250it [25:39,  4.26it/s]Train epoch: 5 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.004528\n",
      "7275it [25:45,  4.33it/s]Train epoch: 5 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.005195\n",
      "7300it [25:51,  4.28it/s]Train epoch: 5 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.005502\n",
      "7325it [25:57,  4.27it/s]Train epoch: 5 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.004472\n",
      "7350it [26:03,  4.26it/s]Train epoch: 5 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.005552\n",
      "7375it [26:09,  4.30it/s]Train epoch: 5 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.005009\n",
      "7400it [26:14,  4.19it/s]Train epoch: 5 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.004452\n",
      "7425it [26:20,  4.27it/s]Train epoch: 5 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.004902\n",
      "7450it [26:26,  4.31it/s]Train epoch: 5 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.005451\n",
      "7475it [26:32,  4.22it/s]Train epoch: 5 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.004729\n",
      "7500it [26:38,  4.23it/s]Train epoch: 5 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.005050\n",
      "7525it [26:44,  4.20it/s]Train epoch: 5 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.004766\n",
      "7550it [26:50,  4.27it/s]Train epoch: 5 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.004607\n",
      "7575it [26:55,  4.27it/s]Train epoch: 5 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.005068\n",
      "7600it [27:01,  4.19it/s]Train epoch: 5 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.005994\n",
      "7625it [27:07,  4.31it/s]Train epoch: 5 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.005635\n",
      "7650it [27:13,  4.24it/s]Train epoch: 5 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.004728\n",
      "7675it [27:19,  4.20it/s]Train epoch: 5 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.004616\n",
      "7700it [27:25,  4.29it/s]Train epoch: 5 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.004835\n",
      "7725it [27:31,  4.29it/s]Train epoch: 5 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.004890\n",
      "7750it [27:37,  4.29it/s]Train epoch: 5 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.005163\n",
      "7775it [27:43,  4.20it/s]Train epoch: 5 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.004574\n",
      "7800it [27:49,  4.21it/s]Train epoch: 5 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.004776\n",
      "7825it [27:55,  4.27it/s]Train epoch: 5 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.005102\n",
      "7850it [28:00,  4.21it/s]Train epoch: 5 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.004498\n",
      "7875it [28:06,  4.18it/s]Train epoch: 5 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.004730\n",
      "7900it [28:12,  4.25it/s]Train epoch: 5 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.004953\n",
      "7925it [28:18,  4.11it/s]Train epoch: 5 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.004935\n",
      "7950it [28:24,  4.14it/s]Train epoch: 5 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.005563\n",
      "7975it [28:30,  4.20it/s]Train epoch: 5 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.004824\n",
      "8000it [28:36,  4.20it/s]Train epoch: 5 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.004628\n",
      "8025it [28:42,  4.05it/s]Train epoch: 5 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.005103\n",
      "8050it [28:48,  4.17it/s]Train epoch: 5 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.004352\n",
      "8075it [28:54,  4.17it/s]Train epoch: 5 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.004941\n",
      "8100it [29:00,  4.18it/s]Train epoch: 5 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.005340\n",
      "8125it [29:06,  4.12it/s]Train epoch: 5 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.005281\n",
      "8150it [29:12,  4.17it/s]Train epoch: 5 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.004676\n",
      "8175it [29:18,  4.10it/s]Train epoch: 5 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.005352\n",
      "8200it [29:24,  4.17it/s]Train epoch: 5 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.004542\n",
      "8225it [29:30,  4.08it/s]Train epoch: 5 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.006112\n",
      "8250it [29:36,  4.17it/s]Train epoch: 5 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.004643\n",
      "8275it [29:42,  4.13it/s]Train epoch: 5 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.005447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300it [29:48,  4.19it/s]Train epoch: 5 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.004658\n",
      "8325it [29:54,  4.13it/s]Train epoch: 5 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.005232\n",
      "8350it [30:00,  4.17it/s]Train epoch: 5 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.004667\n",
      "8375it [30:06,  4.14it/s]Train epoch: 5 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.005242\n",
      "8400it [30:13,  4.21it/s]Train epoch: 5 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.004891\n",
      "8425it [30:19,  4.13it/s]Train epoch: 5 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.004908\n",
      "8450it [30:25,  4.07it/s]Train epoch: 5 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.005328\n",
      "8475it [30:31,  4.13it/s]Train epoch: 5 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.004963\n",
      "8500it [30:37,  4.11it/s]Train epoch: 5 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.005894\n",
      "8525it [30:43,  4.12it/s]Train epoch: 5 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.004955\n",
      "8550it [30:49,  4.09it/s]Train epoch: 5 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.005369\n",
      "8575it [30:55,  4.10it/s]Train epoch: 5 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.004848\n",
      "8600it [31:01,  4.06it/s]Train epoch: 5 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.005014\n",
      "8625it [31:07,  4.14it/s]Train epoch: 5 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.005212\n",
      "8650it [31:13,  4.12it/s]Train epoch: 5 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.005342\n",
      "8675it [31:19,  4.16it/s]Train epoch: 5 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.005909\n",
      "8700it [31:25,  4.07it/s]Train epoch: 5 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.005951\n",
      "8725it [31:32,  4.11it/s]Train epoch: 5 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.005707\n",
      "8750it [31:38,  4.06it/s]Train epoch: 5 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.005412\n",
      "8775it [31:44,  4.11it/s]Train epoch: 5 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.004895\n",
      "8800it [31:50,  4.05it/s]Train epoch: 5 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.005156\n",
      "8825it [31:56,  4.08it/s]Train epoch: 5 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.005242\n",
      "8850it [32:02,  4.09it/s]Train epoch: 5 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.005406\n",
      "8875it [32:08,  4.05it/s]Train epoch: 5 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.005082\n",
      "8900it [32:15,  4.04it/s]Train epoch: 5 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.005178\n",
      "8925it [32:21,  4.05it/s]Train epoch: 5 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.005468\n",
      "8950it [32:27,  4.04it/s]Train epoch: 5 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.006146\n",
      "8975it [32:33,  4.06it/s]Train epoch: 5 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.005616\n",
      "9000it [32:39,  4.03it/s]Train epoch: 5 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.005283\n",
      "9025it [32:46,  4.03it/s]Train epoch: 5 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.005346\n",
      "9050it [32:52,  4.05it/s]Train epoch: 5 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.004894\n",
      "9075it [32:58,  4.03it/s]Train epoch: 5 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.004614\n",
      "9100it [33:04,  4.05it/s]Train epoch: 5 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.005453\n",
      "9125it [33:10,  4.02it/s]Train epoch: 5 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.004986\n",
      "9150it [33:17,  4.05it/s]Train epoch: 5 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.004742\n",
      "9175it [33:23,  4.06it/s]Train epoch: 5 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.005105\n",
      "9200it [33:29,  3.97it/s]Train epoch: 5 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.005088\n",
      "9225it [33:35,  3.99it/s]Train epoch: 5 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.005884\n",
      "9250it [33:41,  4.08it/s]Train epoch: 5 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.005264\n",
      "9275it [33:48,  4.08it/s]Train epoch: 5 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.005554\n",
      "9300it [33:54,  4.03it/s]Train epoch: 5 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.006350\n",
      "9325it [34:00,  3.99it/s]Train epoch: 5 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.005967\n",
      "9350it [34:06,  4.00it/s]Train epoch: 5 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.005861\n",
      "9375it [34:13,  3.90it/s]Train epoch: 5 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.005125\n",
      "9400it [34:19,  3.95it/s]Train epoch: 5 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.005566\n",
      "9425it [34:25,  3.99it/s]Train epoch: 5 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.005238\n",
      "9450it [34:32,  4.03it/s]Train epoch: 5 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.005169\n",
      "9475it [34:38,  4.02it/s]Train epoch: 5 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.005928\n",
      "9500it [34:44,  4.01it/s]Train epoch: 5 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.005478\n",
      "9525it [34:51,  3.95it/s]Train epoch: 5 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.005998\n",
      "9550it [34:57,  3.93it/s]Train epoch: 5 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.005746\n",
      "9575it [35:03,  3.97it/s]Train epoch: 5 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.005796\n",
      "9600it [35:10,  3.96it/s]Train epoch: 5 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.005622\n",
      "9625it [35:16,  4.00it/s]Train epoch: 5 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.005219\n",
      "9650it [35:22,  3.93it/s]Train epoch: 5 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.005236\n",
      "9675it [35:29,  3.83it/s]Train epoch: 5 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.005679\n",
      "9700it [35:35,  3.92it/s]Train epoch: 5 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.005002\n",
      "9725it [35:41,  3.91it/s]Train epoch: 5 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.005658\n",
      "9750it [35:48,  3.90it/s]Train epoch: 5 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.005591\n",
      "9775it [35:54,  3.93it/s]Train epoch: 5 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.006190\n",
      "9800it [36:01,  3.88it/s]Train epoch: 5 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.005989\n",
      "9825it [36:07,  3.91it/s]Train epoch: 5 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.006089\n",
      "9850it [36:13,  3.91it/s]Train epoch: 5 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.005628\n",
      "9875it [36:20,  3.87it/s]Train epoch: 5 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.005944\n",
      "9900it [36:26,  3.88it/s]Train epoch: 5 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.006536\n",
      "9925it [36:33,  3.86it/s]Train epoch: 5 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.006041\n",
      "9950it [36:39,  3.92it/s]Train epoch: 5 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.006511\n",
      "9975it [36:46,  3.87it/s]Train epoch: 5 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.005955\n",
      "10000it [36:52,  3.88it/s]Train epoch: 5 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.005682\n",
      "10025it [36:58,  3.83it/s]Train epoch: 5 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.005722\n",
      "10050it [37:05,  3.87it/s]Train epoch: 5 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.005973\n",
      "10075it [37:11,  3.87it/s]Train epoch: 5 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.006519\n",
      "10100it [37:18,  3.85it/s]Train epoch: 5 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.006059\n",
      "10125it [37:25,  3.81it/s]Train epoch: 5 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.005474\n",
      "10150it [37:31,  3.84it/s]Train epoch: 5 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.006073\n",
      "10175it [37:38,  3.79it/s]Train epoch: 5 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.005793\n",
      "10200it [37:44,  3.81it/s]Train epoch: 5 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.006222\n",
      "10225it [37:51,  3.82it/s]Train epoch: 5 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.005990\n",
      "10250it [37:57,  3.83it/s]Train epoch: 5 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.006583\n",
      "10275it [38:04,  3.79it/s]Train epoch: 5 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.005825\n",
      "10300it [38:10,  3.85it/s]Train epoch: 5 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.006350\n",
      "10325it [38:17,  3.81it/s]Train epoch: 5 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.006382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10350it [38:24,  3.80it/s]Train epoch: 5 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.005946\n",
      "10375it [38:30,  3.80it/s]Train epoch: 5 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.006254\n",
      "10400it [38:37,  3.78it/s]Train epoch: 5 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.006173\n",
      "10425it [38:43,  3.77it/s]Train epoch: 5 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.005900\n",
      "10450it [38:50,  3.81it/s]Train epoch: 5 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.006107\n",
      "10475it [38:57,  3.80it/s]Train epoch: 5 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.005383\n",
      "10500it [39:03,  3.74it/s]Train epoch: 5 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.006257\n",
      "10525it [39:10,  3.79it/s]Train epoch: 5 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.006026\n",
      "10550it [39:17,  3.78it/s]Train epoch: 5 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.006217\n",
      "10575it [39:23,  3.78it/s]Train epoch: 5 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.005485\n",
      "10600it [39:30,  3.69it/s]Train epoch: 5 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.005647\n",
      "10625it [39:37,  3.71it/s]Train epoch: 5 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.006531\n",
      "10650it [39:44,  3.72it/s]Train epoch: 5 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.006029\n",
      "10675it [39:50,  3.70it/s]Train epoch: 5 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.006349\n",
      "10700it [39:57,  3.68it/s]Train epoch: 5 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.005959\n",
      "10725it [40:04,  3.70it/s]Train epoch: 5 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.005475\n",
      "10750it [40:11,  3.69it/s]Train epoch: 5 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.006369\n",
      "10775it [40:17,  3.69it/s]Train epoch: 5 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.006355\n",
      "10800it [40:24,  3.68it/s]Train epoch: 5 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.006617\n",
      "10825it [40:31,  3.71it/s]Train epoch: 5 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006580\n",
      "10850it [40:38,  3.62it/s]Train epoch: 5 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006555\n",
      "10875it [40:45,  3.63it/s]Train epoch: 5 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006635\n",
      "10900it [40:52,  3.62it/s]Train epoch: 5 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006409\n",
      "10925it [40:58,  3.68it/s]Train epoch: 5 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005780\n",
      "10950it [41:05,  3.67it/s]Train epoch: 5 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006352\n",
      "10975it [41:12,  3.64it/s]Train epoch: 5 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006097\n",
      "11000it [41:19,  3.63it/s]Train epoch: 5 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006178\n",
      "11025it [41:26,  3.60it/s]Train epoch: 5 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006287\n",
      "11050it [41:33,  3.56it/s]Train epoch: 5 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007112\n",
      "11075it [41:40,  3.56it/s]Train epoch: 5 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006516\n",
      "11100it [41:47,  3.58it/s]Train epoch: 5 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007099\n",
      "11125it [41:54,  3.60it/s]Train epoch: 5 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006696\n",
      "11150it [42:01,  3.55it/s]Train epoch: 5 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006418\n",
      "11175it [42:08,  3.54it/s]Train epoch: 5 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007517\n",
      "11200it [42:15,  3.51it/s]Train epoch: 5 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006819\n",
      "11225it [42:22,  3.52it/s]Train epoch: 5 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006670\n",
      "11250it [42:29,  3.50it/s]Train epoch: 5 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007449\n",
      "11275it [42:36,  3.50it/s]Train epoch: 5 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007051\n",
      "11300it [42:43,  3.48it/s]Train epoch: 5 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006448\n",
      "11325it [42:51,  3.45it/s]Train epoch: 5 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007571\n",
      "11350it [42:58,  3.44it/s]Train epoch: 5 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007423\n",
      "11375it [43:05,  3.49it/s]Train epoch: 5 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007719\n",
      "11400it [43:12,  3.41it/s]Train epoch: 5 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006674\n",
      "11425it [43:20,  3.47it/s]Train epoch: 5 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007403\n",
      "11450it [43:27,  3.39it/s]Train epoch: 5 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006688\n",
      "11475it [43:34,  3.38it/s]Train epoch: 5 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007817\n",
      "11500it [43:42,  3.36it/s]Train epoch: 5 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007506\n",
      "11525it [43:49,  3.37it/s]Train epoch: 5 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006919\n",
      "11550it [43:56,  3.35it/s]Train epoch: 5 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.006736\n",
      "11575it [44:04,  3.30it/s]Train epoch: 5 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007962\n",
      "11600it [44:12,  3.30it/s]Train epoch: 5 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007247\n",
      "11625it [44:19,  3.28it/s]Train epoch: 5 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006833\n",
      "11650it [44:27,  3.31it/s]Train epoch: 5 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007535\n",
      "11675it [44:35,  3.22it/s]Train epoch: 5 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007979\n",
      "11700it [44:42,  3.19it/s]Train epoch: 5 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008390\n",
      "11725it [44:50,  3.15it/s]Train epoch: 5 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008404\n",
      "11750it [44:58,  3.11it/s]Train epoch: 5 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008099\n",
      "11775it [45:06,  3.06it/s]Train epoch: 5 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008022\n",
      "11800it [45:15,  3.04it/s]Train epoch: 5 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007897\n",
      "11825it [45:23,  2.96it/s]Train epoch: 5 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008107\n",
      "11850it [45:32,  2.89it/s]Train epoch: 5 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008311\n",
      "11875it [45:40,  2.79it/s]Train epoch: 5 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009210\n",
      "11900it [45:50,  2.61it/s]Train epoch: 5 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011136\n",
      "11925it [46:00,  2.33it/s]Train epoch: 5 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009387\n",
      "11930it [46:02,  4.32it/s]\n",
      "epoch loss: 0.004757087564263501\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.40it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0274, 0.0402, 0.0480, 0.0438, 0.8795\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3027, 0.4982, 0.4356, 0.4648, 0.9801\n",
      "rec_at_8: 0.3287\n",
      "prec_at_8: 0.6097\n",
      "rec_at_15: 0.4613\n",
      "prec_at_15: 0.4780\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:51, 30.30it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0281, 0.0443, 0.0498, 0.0469, 0.8745\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2958, 0.4922, 0.4257, 0.4565, 0.9797\n",
      "rec_at_8: 0.3145\n",
      "prec_at_8: 0.6056\n",
      "rec_at_15: 0.4431\n",
      "prec_at_15: 0.4757\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 5\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0274, 0.0402, 0.0480, 0.0438, 0.8795\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3027, 0.4982, 0.4356, 0.4648, 0.9801\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0072\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 5\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0281, 0.0443, 0.0498, 0.0469, 0.8745\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2958, 0.4922, 0.4257, 0.4565, 0.9797\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0074\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 6\n",
      "0it [00:00, ?it/s]Train epoch: 6 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.006025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25it [00:04,  5.53it/s]Train epoch: 6 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.004179\n",
      "50it [00:08,  5.49it/s]Train epoch: 6 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.003778\n",
      "75it [00:13,  5.48it/s]Train epoch: 6 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.003253\n",
      "100it [00:18,  5.51it/s]Train epoch: 6 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.003219\n",
      "125it [00:22,  5.37it/s]Train epoch: 6 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.003144\n",
      "150it [00:27,  5.37it/s]Train epoch: 6 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.003031\n",
      "175it [00:32,  5.32it/s]Train epoch: 6 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.003253\n",
      "200it [00:36,  5.36it/s]Train epoch: 6 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.003022\n",
      "225it [00:41,  5.23it/s]Train epoch: 6 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.003665\n",
      "250it [00:46,  5.36it/s]Train epoch: 6 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.003038\n",
      "275it [00:51,  5.26it/s]Train epoch: 6 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.002603\n",
      "300it [00:55,  5.22it/s]Train epoch: 6 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003438\n",
      "325it [01:00,  5.27it/s]Train epoch: 6 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.002795\n",
      "350it [01:05,  5.21it/s]Train epoch: 6 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.003435\n",
      "375it [01:10,  5.20it/s]Train epoch: 6 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.003191\n",
      "400it [01:14,  5.29it/s]Train epoch: 6 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.003146\n",
      "425it [01:19,  5.24it/s]Train epoch: 6 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.003107\n",
      "450it [01:24,  5.22it/s]Train epoch: 6 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.003036\n",
      "475it [01:29,  5.21it/s]Train epoch: 6 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.003485\n",
      "500it [01:34,  5.26it/s]Train epoch: 6 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.002907\n",
      "525it [01:38,  5.16it/s]Train epoch: 6 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.003293\n",
      "550it [01:43,  5.15it/s]Train epoch: 6 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.003156\n",
      "575it [01:48,  5.17it/s]Train epoch: 6 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.003127\n",
      "600it [01:53,  5.14it/s]Train epoch: 6 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.003393\n",
      "625it [01:58,  5.14it/s]Train epoch: 6 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.003266\n",
      "650it [02:03,  5.15it/s]Train epoch: 6 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.002877\n",
      "675it [02:07,  5.14it/s]Train epoch: 6 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002540\n",
      "700it [02:12,  5.11it/s]Train epoch: 6 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.003054\n",
      "725it [02:17,  5.12it/s]Train epoch: 6 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.003271\n",
      "750it [02:22,  5.13it/s]Train epoch: 6 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.003024\n",
      "775it [02:27,  5.18it/s]Train epoch: 6 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.003452\n",
      "800it [02:32,  5.11it/s]Train epoch: 6 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.003300\n",
      "825it [02:37,  5.15it/s]Train epoch: 6 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.003169\n",
      "850it [02:42,  5.15it/s]Train epoch: 6 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.003619\n",
      "875it [02:47,  5.10it/s]Train epoch: 6 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.002913\n",
      "900it [02:51,  5.00it/s]Train epoch: 6 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.003386\n",
      "925it [02:56,  5.07it/s]Train epoch: 6 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.002977\n",
      "950it [03:01,  5.04it/s]Train epoch: 6 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.002988\n",
      "975it [03:06,  5.21it/s]Train epoch: 6 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002460\n",
      "1000it [03:11,  4.98it/s]Train epoch: 6 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.003237\n",
      "1025it [03:16,  5.05it/s]Train epoch: 6 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.004362\n",
      "1050it [03:21,  5.12it/s]Train epoch: 6 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.002993\n",
      "1075it [03:26,  5.13it/s]Train epoch: 6 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.003346\n",
      "1100it [03:31,  5.00it/s]Train epoch: 6 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.003402\n",
      "1125it [03:36,  5.10it/s]Train epoch: 6 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.003539\n",
      "1150it [03:41,  4.97it/s]Train epoch: 6 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.003475\n",
      "1175it [03:46,  5.03it/s]Train epoch: 6 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.003390\n",
      "1200it [03:51,  5.01it/s]Train epoch: 6 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.003494\n",
      "1225it [03:56,  4.96it/s]Train epoch: 6 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.003639\n",
      "1250it [04:01,  4.98it/s]Train epoch: 6 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003396\n",
      "1275it [04:06,  5.00it/s]Train epoch: 6 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.002917\n",
      "1300it [04:11,  5.08it/s]Train epoch: 6 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.002929\n",
      "1325it [04:16,  5.13it/s]Train epoch: 6 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.002948\n",
      "1350it [04:21,  4.96it/s]Train epoch: 6 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.003973\n",
      "1375it [04:26,  4.98it/s]Train epoch: 6 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.003273\n",
      "1400it [04:31,  4.99it/s]Train epoch: 6 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.003275\n",
      "1425it [04:36,  4.96it/s]Train epoch: 6 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.002883\n",
      "1450it [04:41,  4.94it/s]Train epoch: 6 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.003229\n",
      "1475it [04:46,  4.99it/s]Train epoch: 6 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.003289\n",
      "1500it [04:51,  5.08it/s]Train epoch: 6 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.004463\n",
      "1525it [04:56,  4.98it/s]Train epoch: 6 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.004115\n",
      "1550it [05:01,  5.02it/s]Train epoch: 6 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.003052\n",
      "1575it [05:06,  4.95it/s]Train epoch: 6 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.003480\n",
      "1600it [05:11,  5.00it/s]Train epoch: 6 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.002953\n",
      "1625it [05:16,  4.94it/s]Train epoch: 6 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.003672\n",
      "1650it [05:21,  4.91it/s]Train epoch: 6 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.003601\n",
      "1675it [05:26,  4.96it/s]Train epoch: 6 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.003542\n",
      "1700it [05:31,  4.94it/s]Train epoch: 6 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.003113\n",
      "1725it [05:36,  4.97it/s]Train epoch: 6 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.002684\n",
      "1750it [05:41,  4.96it/s]Train epoch: 6 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.004098\n",
      "1775it [05:46,  4.97it/s]Train epoch: 6 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.003354\n",
      "1800it [05:51,  4.93it/s]Train epoch: 6 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.003240\n",
      "1825it [05:57,  4.94it/s]Train epoch: 6 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.002790\n",
      "1850it [06:02,  4.97it/s]Train epoch: 6 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.003521\n",
      "1875it [06:07,  4.92it/s]Train epoch: 6 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.003716\n",
      "1900it [06:12,  4.98it/s]Train epoch: 6 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.002711\n",
      "1925it [06:17,  4.93it/s]Train epoch: 6 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.002950\n",
      "1950it [06:22,  4.96it/s]Train epoch: 6 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.002914\n",
      "1975it [06:27,  4.89it/s]Train epoch: 6 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.003615\n",
      "2000it [06:32,  4.91it/s]Train epoch: 6 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.002787\n",
      "2025it [06:37,  4.87it/s]Train epoch: 6 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.003411\n",
      "2050it [06:42,  4.85it/s]Train epoch: 6 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.003246\n",
      "2075it [06:47,  4.81it/s]Train epoch: 6 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.003422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100it [06:53,  4.88it/s]Train epoch: 6 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.003463\n",
      "2125it [06:58,  4.90it/s]Train epoch: 6 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.003848\n",
      "2150it [07:03,  4.89it/s]Train epoch: 6 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.003226\n",
      "2175it [07:08,  4.87it/s]Train epoch: 6 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.003626\n",
      "2200it [07:13,  4.87it/s]Train epoch: 6 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.003355\n",
      "2225it [07:18,  4.91it/s]Train epoch: 6 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.003311\n",
      "2250it [07:23,  4.91it/s]Train epoch: 6 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.002941\n",
      "2275it [07:28,  4.88it/s]Train epoch: 6 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.003402\n",
      "2300it [07:34,  4.91it/s]Train epoch: 6 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.002621\n",
      "2325it [07:39,  4.96it/s]Train epoch: 6 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.003258\n",
      "2350it [07:44,  4.84it/s]Train epoch: 6 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.003102\n",
      "2375it [07:49,  4.84it/s]Train epoch: 6 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.004408\n",
      "2400it [07:54,  4.82it/s]Train epoch: 6 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.004038\n",
      "2425it [07:59,  4.85it/s]Train epoch: 6 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.002919\n",
      "2450it [08:05,  4.84it/s]Train epoch: 6 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.003319\n",
      "2475it [08:10,  4.86it/s]Train epoch: 6 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.003734\n",
      "2500it [08:15,  4.87it/s]Train epoch: 6 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.003185\n",
      "2525it [08:20,  4.87it/s]Train epoch: 6 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.003178\n",
      "2550it [08:25,  4.93it/s]Train epoch: 6 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.004281\n",
      "2575it [08:30,  4.86it/s]Train epoch: 6 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.003148\n",
      "2600it [08:35,  4.84it/s]Train epoch: 6 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.003476\n",
      "2625it [08:41,  4.86it/s]Train epoch: 6 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.003404\n",
      "2650it [08:46,  4.88it/s]Train epoch: 6 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.003989\n",
      "2675it [08:51,  4.78it/s]Train epoch: 6 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.003501\n",
      "2700it [08:56,  4.93it/s]Train epoch: 6 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.003094\n",
      "2725it [09:01,  4.85it/s]Train epoch: 6 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.003288\n",
      "2750it [09:07,  4.76it/s]Train epoch: 6 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.003927\n",
      "2775it [09:12,  4.80it/s]Train epoch: 6 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.003371\n",
      "2800it [09:17,  4.79it/s]Train epoch: 6 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.003220\n",
      "2825it [09:22,  4.81it/s]Train epoch: 6 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.003577\n",
      "2850it [09:27,  4.76it/s]Train epoch: 6 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.003381\n",
      "2875it [09:33,  4.75it/s]Train epoch: 6 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.003753\n",
      "2900it [09:38,  4.81it/s]Train epoch: 6 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.003642\n",
      "2925it [09:43,  4.84it/s]Train epoch: 6 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.003665\n",
      "2950it [09:48,  4.70it/s]Train epoch: 6 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.003900\n",
      "2975it [09:54,  4.89it/s]Train epoch: 6 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.003587\n",
      "3000it [09:59,  4.72it/s]Train epoch: 6 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.004153\n",
      "3025it [10:04,  4.75it/s]Train epoch: 6 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.003695\n",
      "3050it [10:09,  4.80it/s]Train epoch: 6 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.003304\n",
      "3075it [10:15,  4.77it/s]Train epoch: 6 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.003786\n",
      "3100it [10:20,  4.65it/s]Train epoch: 6 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.003855\n",
      "3125it [10:25,  4.73it/s]Train epoch: 6 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.003429\n",
      "3150it [10:30,  4.75it/s]Train epoch: 6 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.003336\n",
      "3175it [10:36,  4.75it/s]Train epoch: 6 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.003388\n",
      "3200it [10:41,  4.75it/s]Train epoch: 6 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.004007\n",
      "3225it [10:46,  4.68it/s]Train epoch: 6 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.003786\n",
      "3250it [10:51,  4.77it/s]Train epoch: 6 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.003746\n",
      "3275it [10:57,  4.80it/s]Train epoch: 6 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.003416\n",
      "3300it [11:02,  4.78it/s]Train epoch: 6 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.004227\n",
      "3325it [11:07,  4.66it/s]Train epoch: 6 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.003701\n",
      "3350it [11:12,  4.75it/s]Train epoch: 6 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.003780\n",
      "3375it [11:18,  4.81it/s]Train epoch: 6 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.004029\n",
      "3400it [11:23,  4.77it/s]Train epoch: 6 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.003948\n",
      "3425it [11:28,  4.70it/s]Train epoch: 6 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.003414\n",
      "3450it [11:34,  4.77it/s]Train epoch: 6 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.004003\n",
      "3475it [11:39,  4.68it/s]Train epoch: 6 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.003436\n",
      "3500it [11:44,  4.73it/s]Train epoch: 6 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.003612\n",
      "3525it [11:49,  4.73it/s]Train epoch: 6 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.003745\n",
      "3550it [11:55,  4.73it/s]Train epoch: 6 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.004010\n",
      "3575it [12:00,  4.74it/s]Train epoch: 6 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.003238\n",
      "3600it [12:05,  4.72it/s]Train epoch: 6 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.004168\n",
      "3625it [12:11,  4.73it/s]Train epoch: 6 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.003725\n",
      "3650it [12:16,  4.72it/s]Train epoch: 6 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.003846\n",
      "3675it [12:21,  4.62it/s]Train epoch: 6 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.004039\n",
      "3700it [12:27,  4.70it/s]Train epoch: 6 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.003760\n",
      "3725it [12:32,  4.63it/s]Train epoch: 6 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.003990\n",
      "3750it [12:37,  4.63it/s]Train epoch: 6 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.004044\n",
      "3775it [12:43,  4.59it/s]Train epoch: 6 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.003773\n",
      "3800it [12:48,  4.58it/s]Train epoch: 6 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.004260\n",
      "3825it [12:53,  4.70it/s]Train epoch: 6 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.003584\n",
      "3850it [12:59,  4.67it/s]Train epoch: 6 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.003301\n",
      "3875it [13:04,  4.61it/s]Train epoch: 6 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.003315\n",
      "3900it [13:09,  4.68it/s]Train epoch: 6 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.004328\n",
      "3925it [13:15,  4.67it/s]Train epoch: 6 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.003967\n",
      "3950it [13:20,  4.69it/s]Train epoch: 6 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.004263\n",
      "3975it [13:26,  4.66it/s]Train epoch: 6 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.004848\n",
      "4000it [13:31,  4.67it/s]Train epoch: 6 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.003446\n",
      "4025it [13:36,  4.59it/s]Train epoch: 6 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.004387\n",
      "4050it [13:42,  4.69it/s]Train epoch: 6 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.004029\n",
      "4075it [13:47,  4.72it/s]Train epoch: 6 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.004005\n",
      "4100it [13:52,  4.67it/s]Train epoch: 6 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.004442\n",
      "4125it [13:58,  4.63it/s]Train epoch: 6 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.004263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4150it [14:03,  4.64it/s]Train epoch: 6 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.003681\n",
      "4175it [14:08,  4.66it/s]Train epoch: 6 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.003788\n",
      "4200it [14:14,  4.68it/s]Train epoch: 6 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.004241\n",
      "4225it [14:19,  4.68it/s]Train epoch: 6 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.003633\n",
      "4250it [14:25,  4.65it/s]Train epoch: 6 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.003986\n",
      "4275it [14:30,  4.60it/s]Train epoch: 6 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.003811\n",
      "4300it [14:35,  4.66it/s]Train epoch: 6 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.004528\n",
      "4325it [14:41,  4.62it/s]Train epoch: 6 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.004044\n",
      "4350it [14:46,  4.58it/s]Train epoch: 6 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.004257\n",
      "4375it [14:52,  4.58it/s]Train epoch: 6 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.003829\n",
      "4400it [14:57,  4.66it/s]Train epoch: 6 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.003349\n",
      "4425it [15:03,  4.59it/s]Train epoch: 6 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.004075\n",
      "4450it [15:08,  4.64it/s]Train epoch: 6 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.003269\n",
      "4475it [15:13,  4.61it/s]Train epoch: 6 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.004040\n",
      "4500it [15:19,  4.59it/s]Train epoch: 6 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.004788\n",
      "4525it [15:24,  4.61it/s]Train epoch: 6 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.004009\n",
      "4550it [15:30,  4.58it/s]Train epoch: 6 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.003948\n",
      "4575it [15:35,  4.41it/s]Train epoch: 6 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.004419\n",
      "4600it [15:41,  4.59it/s]Train epoch: 6 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.003582\n",
      "4625it [15:46,  4.56it/s]Train epoch: 6 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.003795\n",
      "4650it [15:52,  4.58it/s]Train epoch: 6 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.004376\n",
      "4675it [15:57,  4.49it/s]Train epoch: 6 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.004195\n",
      "4700it [16:03,  4.56it/s]Train epoch: 6 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.003734\n",
      "4725it [16:08,  4.59it/s]Train epoch: 6 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.003901\n",
      "4750it [16:14,  4.63it/s]Train epoch: 6 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.004646\n",
      "4775it [16:19,  4.53it/s]Train epoch: 6 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.004053\n",
      "4800it [16:25,  4.41it/s]Train epoch: 6 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.004093\n",
      "4825it [16:30,  4.52it/s]Train epoch: 6 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.003705\n",
      "4850it [16:36,  4.60it/s]Train epoch: 6 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.004409\n",
      "4875it [16:41,  4.59it/s]Train epoch: 6 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.003814\n",
      "4900it [16:47,  4.55it/s]Train epoch: 6 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.003991\n",
      "4925it [16:52,  4.51it/s]Train epoch: 6 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.003681\n",
      "4950it [16:58,  4.50it/s]Train epoch: 6 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.003943\n",
      "4975it [17:03,  4.57it/s]Train epoch: 6 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.003948\n",
      "5000it [17:09,  4.52it/s]Train epoch: 6 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.004067\n",
      "5025it [17:14,  4.49it/s]Train epoch: 6 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.003745\n",
      "5050it [17:20,  4.52it/s]Train epoch: 6 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.003743\n",
      "5075it [17:25,  4.45it/s]Train epoch: 6 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.004041\n",
      "5100it [17:31,  4.43it/s]Train epoch: 6 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.004108\n",
      "5125it [17:36,  4.53it/s]Train epoch: 6 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.004359\n",
      "5150it [17:42,  4.49it/s]Train epoch: 6 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.004213\n",
      "5175it [17:48,  4.59it/s]Train epoch: 6 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.004071\n",
      "5200it [17:53,  4.53it/s]Train epoch: 6 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.003775\n",
      "5225it [17:59,  4.53it/s]Train epoch: 6 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.004017\n",
      "5250it [18:04,  4.51it/s]Train epoch: 6 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.004103\n",
      "5275it [18:10,  4.49it/s]Train epoch: 6 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.003898\n",
      "5300it [18:15,  4.47it/s]Train epoch: 6 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.003686\n",
      "5325it [18:21,  4.49it/s]Train epoch: 6 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.004367\n",
      "5350it [18:26,  4.45it/s]Train epoch: 6 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.004364\n",
      "5375it [18:32,  4.49it/s]Train epoch: 6 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.003871\n",
      "5400it [18:38,  4.49it/s]Train epoch: 6 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.003862\n",
      "5425it [18:43,  4.47it/s]Train epoch: 6 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.004280\n",
      "5450it [18:49,  4.47it/s]Train epoch: 6 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.004173\n",
      "5475it [18:54,  4.50it/s]Train epoch: 6 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.004879\n",
      "5500it [19:00,  4.51it/s]Train epoch: 6 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.004487\n",
      "5525it [19:06,  4.52it/s]Train epoch: 6 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.003679\n",
      "5550it [19:11,  4.47it/s]Train epoch: 6 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.004195\n",
      "5575it [19:17,  4.43it/s]Train epoch: 6 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.004193\n",
      "5600it [19:22,  4.48it/s]Train epoch: 6 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.004615\n",
      "5625it [19:28,  4.44it/s]Train epoch: 6 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.004155\n",
      "5650it [19:33,  4.47it/s]Train epoch: 6 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.003810\n",
      "5675it [19:39,  4.51it/s]Train epoch: 6 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.004753\n",
      "5700it [19:45,  4.42it/s]Train epoch: 6 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.004040\n",
      "5725it [19:50,  4.43it/s]Train epoch: 6 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.004131\n",
      "5750it [19:56,  4.44it/s]Train epoch: 6 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.005388\n",
      "5775it [20:02,  4.45it/s]Train epoch: 6 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.004373\n",
      "5800it [20:07,  4.43it/s]Train epoch: 6 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.004517\n",
      "5825it [20:13,  4.44it/s]Train epoch: 6 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.003865\n",
      "5850it [20:18,  4.44it/s]Train epoch: 6 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.005059\n",
      "5875it [20:24,  4.43it/s]Train epoch: 6 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.004702\n",
      "5900it [20:30,  4.45it/s]Train epoch: 6 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.004660\n",
      "5925it [20:35,  4.43it/s]Train epoch: 6 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.003992\n",
      "5950it [20:41,  4.42it/s]Train epoch: 6 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.003826\n",
      "5975it [20:47,  4.41it/s]Train epoch: 6 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.005351\n",
      "6000it [20:52,  4.40it/s]Train epoch: 6 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.004506\n",
      "6025it [20:58,  4.39it/s]Train epoch: 6 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.004838\n",
      "6050it [21:04,  4.42it/s]Train epoch: 6 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.004233\n",
      "6075it [21:09,  4.39it/s]Train epoch: 6 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.003914\n",
      "6100it [21:15,  4.40it/s]Train epoch: 6 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.003786\n",
      "6125it [21:21,  4.42it/s]Train epoch: 6 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.004321\n",
      "6150it [21:26,  4.40it/s]Train epoch: 6 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.004287\n",
      "6175it [21:32,  4.40it/s]Train epoch: 6 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.004753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6200it [21:38,  4.38it/s]Train epoch: 6 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.004256\n",
      "6225it [21:43,  4.41it/s]Train epoch: 6 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.003755\n",
      "6250it [21:49,  4.37it/s]Train epoch: 6 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.004032\n",
      "6275it [21:55,  4.35it/s]Train epoch: 6 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.003608\n",
      "6300it [22:00,  4.46it/s]Train epoch: 6 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.004233\n",
      "6325it [22:06,  4.40it/s]Train epoch: 6 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.004681\n",
      "6350it [22:12,  4.27it/s]Train epoch: 6 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.004935\n",
      "6375it [22:18,  4.41it/s]Train epoch: 6 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.003794\n",
      "6400it [22:23,  4.33it/s]Train epoch: 6 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.004177\n",
      "6425it [22:29,  4.32it/s]Train epoch: 6 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.004660\n",
      "6450it [22:35,  4.38it/s]Train epoch: 6 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.004640\n",
      "6475it [22:40,  4.35it/s]Train epoch: 6 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.004179\n",
      "6500it [22:46,  4.37it/s]Train epoch: 6 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.004817\n",
      "6525it [22:52,  4.35it/s]Train epoch: 6 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.004026\n",
      "6550it [22:58,  4.36it/s]Train epoch: 6 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.004163\n",
      "6575it [23:03,  4.30it/s]Train epoch: 6 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.004310\n",
      "6600it [23:09,  4.41it/s]Train epoch: 6 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.005150\n",
      "6625it [23:15,  4.37it/s]Train epoch: 6 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.004258\n",
      "6650it [23:21,  4.38it/s]Train epoch: 6 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.004887\n",
      "6675it [23:26,  4.34it/s]Train epoch: 6 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.004419\n",
      "6700it [23:32,  4.34it/s]Train epoch: 6 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.004504\n",
      "6725it [23:38,  4.36it/s]Train epoch: 6 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.004512\n",
      "6750it [23:44,  4.32it/s]Train epoch: 6 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.004102\n",
      "6775it [23:49,  4.40it/s]Train epoch: 6 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.004814\n",
      "6800it [23:55,  4.36it/s]Train epoch: 6 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.004736\n",
      "6825it [24:01,  4.31it/s]Train epoch: 6 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.004794\n",
      "6850it [24:07,  4.31it/s]Train epoch: 6 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.004652\n",
      "6875it [24:13,  4.31it/s]Train epoch: 6 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.003784\n",
      "6900it [24:18,  4.41it/s]Train epoch: 6 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.004374\n",
      "6925it [24:24,  4.28it/s]Train epoch: 6 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.004532\n",
      "6950it [24:30,  4.38it/s]Train epoch: 6 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.004971\n",
      "6975it [24:36,  4.30it/s]Train epoch: 6 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.004664\n",
      "7000it [24:41,  4.39it/s]Train epoch: 6 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.004306\n",
      "7025it [24:47,  4.24it/s]Train epoch: 6 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.005107\n",
      "7050it [24:53,  4.33it/s]Train epoch: 6 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.003947\n",
      "7075it [24:59,  4.29it/s]Train epoch: 6 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.004534\n",
      "7100it [25:05,  4.28it/s]Train epoch: 6 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.004580\n",
      "7125it [25:11,  4.29it/s]Train epoch: 6 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.004102\n",
      "7150it [25:16,  4.29it/s]Train epoch: 6 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.005056\n",
      "7175it [25:22,  4.27it/s]Train epoch: 6 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.004582\n",
      "7200it [25:28,  4.28it/s]Train epoch: 6 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.004981\n",
      "7225it [25:34,  4.30it/s]Train epoch: 6 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.004453\n",
      "7250it [25:40,  4.25it/s]Train epoch: 6 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.004315\n",
      "7275it [25:46,  4.30it/s]Train epoch: 6 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.005059\n",
      "7300it [25:51,  4.32it/s]Train epoch: 6 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.005281\n",
      "7325it [25:57,  4.30it/s]Train epoch: 6 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.004189\n",
      "7350it [26:03,  4.26it/s]Train epoch: 6 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.005220\n",
      "7375it [26:09,  4.23it/s]Train epoch: 6 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.004784\n",
      "7400it [26:15,  4.20it/s]Train epoch: 6 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.004368\n",
      "7425it [26:21,  4.27it/s]Train epoch: 6 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.004764\n",
      "7450it [26:27,  4.22it/s]Train epoch: 6 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.005256\n",
      "7475it [26:32,  4.19it/s]Train epoch: 6 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.004557\n",
      "7500it [26:38,  4.28it/s]Train epoch: 6 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.004877\n",
      "7525it [26:44,  4.26it/s]Train epoch: 6 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.004569\n",
      "7550it [26:50,  4.18it/s]Train epoch: 6 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.004399\n",
      "7575it [26:56,  4.22it/s]Train epoch: 6 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.004915\n",
      "7600it [27:02,  4.28it/s]Train epoch: 6 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.005720\n",
      "7625it [27:08,  4.23it/s]Train epoch: 6 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.005417\n",
      "7650it [27:14,  4.21it/s]Train epoch: 6 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.004630\n",
      "7675it [27:20,  4.20it/s]Train epoch: 6 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.004415\n",
      "7700it [27:26,  4.22it/s]Train epoch: 6 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.004701\n",
      "7725it [27:31,  4.17it/s]Train epoch: 6 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.004729\n",
      "7750it [27:37,  4.20it/s]Train epoch: 6 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.005050\n",
      "7775it [27:43,  4.23it/s]Train epoch: 6 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.004410\n",
      "7800it [27:49,  4.19it/s]Train epoch: 6 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.004638\n",
      "7825it [27:55,  4.18it/s]Train epoch: 6 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.004874\n",
      "7850it [28:01,  4.18it/s]Train epoch: 6 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.004374\n",
      "7875it [28:07,  4.15it/s]Train epoch: 6 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.004546\n",
      "7900it [28:13,  4.26it/s]Train epoch: 6 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.004797\n",
      "7925it [28:19,  4.19it/s]Train epoch: 6 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.004754\n",
      "7950it [28:25,  4.27it/s]Train epoch: 6 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.005331\n",
      "7975it [28:31,  4.19it/s]Train epoch: 6 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.004585\n",
      "8000it [28:37,  4.19it/s]Train epoch: 6 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.004436\n",
      "8025it [28:43,  4.17it/s]Train epoch: 6 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.004905\n",
      "8050it [28:49,  4.22it/s]Train epoch: 6 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.004191\n",
      "8075it [28:55,  4.16it/s]Train epoch: 6 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.004769\n",
      "8100it [29:01,  4.14it/s]Train epoch: 6 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.005071\n",
      "8125it [29:07,  4.19it/s]Train epoch: 6 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.005147\n",
      "8150it [29:13,  4.17it/s]Train epoch: 6 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.004527\n",
      "8175it [29:19,  4.11it/s]Train epoch: 6 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.005220\n",
      "8200it [29:25,  4.09it/s]Train epoch: 6 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.004373\n",
      "8225it [29:31,  4.15it/s]Train epoch: 6 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.005942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8250it [29:37,  4.22it/s]Train epoch: 6 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.004492\n",
      "8275it [29:43,  4.13it/s]Train epoch: 6 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.005228\n",
      "8300it [29:49,  4.21it/s]Train epoch: 6 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.004478\n",
      "8325it [29:55,  4.11it/s]Train epoch: 6 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.005067\n",
      "8350it [30:01,  4.14it/s]Train epoch: 6 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.004466\n",
      "8375it [30:07,  4.18it/s]Train epoch: 6 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.005029\n",
      "8400it [30:13,  4.13it/s]Train epoch: 6 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.004750\n",
      "8425it [30:19,  4.06it/s]Train epoch: 6 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.004732\n",
      "8450it [30:25,  4.19it/s]Train epoch: 6 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.005177\n",
      "8475it [30:31,  4.07it/s]Train epoch: 6 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.004813\n",
      "8500it [30:37,  4.13it/s]Train epoch: 6 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.005628\n",
      "8525it [30:44,  4.05it/s]Train epoch: 6 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.004792\n",
      "8550it [30:50,  4.13it/s]Train epoch: 6 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.005117\n",
      "8575it [30:56,  4.08it/s]Train epoch: 6 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.004657\n",
      "8600it [31:02,  4.12it/s]Train epoch: 6 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.004792\n",
      "8625it [31:08,  4.07it/s]Train epoch: 6 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.005009\n",
      "8650it [31:14,  4.11it/s]Train epoch: 6 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.005169\n",
      "8675it [31:20,  4.08it/s]Train epoch: 6 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.005698\n",
      "8700it [31:26,  4.08it/s]Train epoch: 6 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.005794\n",
      "8725it [31:32,  4.13it/s]Train epoch: 6 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.005459\n",
      "8750it [31:38,  4.12it/s]Train epoch: 6 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.005186\n",
      "8775it [31:45,  4.06it/s]Train epoch: 6 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.004748\n",
      "8800it [31:51,  4.12it/s]Train epoch: 6 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.004956\n",
      "8825it [31:57,  4.12it/s]Train epoch: 6 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.005052\n",
      "8850it [32:03,  4.12it/s]Train epoch: 6 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.005225\n",
      "8875it [32:09,  4.06it/s]Train epoch: 6 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.004970\n",
      "8900it [32:15,  4.06it/s]Train epoch: 6 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.005013\n",
      "8925it [32:21,  4.12it/s]Train epoch: 6 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.005230\n",
      "8950it [32:28,  4.09it/s]Train epoch: 6 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.005868\n",
      "8975it [32:34,  4.08it/s]Train epoch: 6 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.005358\n",
      "9000it [32:40,  4.09it/s]Train epoch: 6 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.005085\n",
      "9025it [32:46,  4.04it/s]Train epoch: 6 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.005164\n",
      "9050it [32:52,  4.04it/s]Train epoch: 6 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.004758\n",
      "9075it [32:58,  4.04it/s]Train epoch: 6 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.004376\n",
      "9100it [33:05,  4.03it/s]Train epoch: 6 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.005263\n",
      "9125it [33:11,  4.01it/s]Train epoch: 6 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.004797\n",
      "9150it [33:17,  3.97it/s]Train epoch: 6 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.004571\n",
      "9175it [33:23,  4.00it/s]Train epoch: 6 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.004876\n",
      "9200it [33:29,  4.10it/s]Train epoch: 6 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.004869\n",
      "9225it [33:36,  4.06it/s]Train epoch: 6 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.005671\n",
      "9250it [33:42,  4.04it/s]Train epoch: 6 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.005080\n",
      "9275it [33:48,  3.97it/s]Train epoch: 6 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.005434\n",
      "9300it [33:54,  3.97it/s]Train epoch: 6 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.006170\n",
      "9325it [34:01,  3.99it/s]Train epoch: 6 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.005783\n",
      "9350it [34:07,  3.99it/s]Train epoch: 6 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.005618\n",
      "9375it [34:13,  3.96it/s]Train epoch: 6 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.004906\n",
      "9400it [34:19,  4.00it/s]Train epoch: 6 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.005332\n",
      "9425it [34:26,  3.96it/s]Train epoch: 6 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.005111\n",
      "9450it [34:32,  4.00it/s]Train epoch: 6 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.004998\n",
      "9475it [34:38,  3.94it/s]Train epoch: 6 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.005719\n",
      "9500it [34:45,  4.00it/s]Train epoch: 6 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.005264\n",
      "9525it [34:51,  3.99it/s]Train epoch: 6 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.005775\n",
      "9550it [34:57,  3.99it/s]Train epoch: 6 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.005582\n",
      "9575it [35:03,  3.96it/s]Train epoch: 6 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.005575\n",
      "9600it [35:10,  3.92it/s]Train epoch: 6 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.005485\n",
      "9625it [35:16,  3.97it/s]Train epoch: 6 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.005031\n",
      "9650it [35:22,  3.93it/s]Train epoch: 6 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.004998\n",
      "9675it [35:29,  3.91it/s]Train epoch: 6 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.005475\n",
      "9700it [35:35,  3.94it/s]Train epoch: 6 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.004832\n",
      "9725it [35:42,  3.89it/s]Train epoch: 6 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.005390\n",
      "9750it [35:48,  3.95it/s]Train epoch: 6 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.005390\n",
      "9775it [35:54,  3.95it/s]Train epoch: 6 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.005989\n",
      "9800it [36:00,  3.93it/s]Train epoch: 6 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.005816\n",
      "9825it [36:07,  3.92it/s]Train epoch: 6 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.005857\n",
      "9850it [36:13,  3.94it/s]Train epoch: 6 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.005382\n",
      "9875it [36:20,  3.90it/s]Train epoch: 6 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.005735\n",
      "9900it [36:26,  3.93it/s]Train epoch: 6 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.006239\n",
      "9925it [36:32,  3.87it/s]Train epoch: 6 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.005873\n",
      "9950it [36:39,  3.88it/s]Train epoch: 6 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.006412\n",
      "9975it [36:45,  3.94it/s]Train epoch: 6 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.005760\n",
      "10000it [36:52,  3.85it/s]Train epoch: 6 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.005481\n",
      "10025it [36:58,  3.87it/s]Train epoch: 6 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.005470\n",
      "10050it [37:05,  3.88it/s]Train epoch: 6 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.005759\n",
      "10075it [37:11,  3.85it/s]Train epoch: 6 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.006258\n",
      "10100it [37:18,  3.87it/s]Train epoch: 6 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.005901\n",
      "10125it [37:24,  3.78it/s]Train epoch: 6 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.005300\n",
      "10150it [37:31,  3.90it/s]Train epoch: 6 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.005856\n",
      "10175it [37:37,  3.82it/s]Train epoch: 6 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.005527\n",
      "10200it [37:44,  3.85it/s]Train epoch: 6 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.005974\n",
      "10225it [37:50,  3.87it/s]Train epoch: 6 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.005806\n",
      "10250it [37:57,  3.82it/s]Train epoch: 6 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.006352\n",
      "10275it [38:03,  3.80it/s]Train epoch: 6 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.005652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10300it [38:10,  3.74it/s]Train epoch: 6 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.006242\n",
      "10325it [38:17,  3.82it/s]Train epoch: 6 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.006252\n",
      "10350it [38:23,  3.79it/s]Train epoch: 6 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.005636\n",
      "10375it [38:30,  3.78it/s]Train epoch: 6 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.006068\n",
      "10400it [38:36,  3.78it/s]Train epoch: 6 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.006018\n",
      "10425it [38:43,  3.77it/s]Train epoch: 6 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.005673\n",
      "10450it [38:50,  3.83it/s]Train epoch: 6 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.005936\n",
      "10475it [38:56,  3.76it/s]Train epoch: 6 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.005230\n",
      "10500it [39:03,  3.75it/s]Train epoch: 6 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.005965\n",
      "10525it [39:10,  3.73it/s]Train epoch: 6 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.005797\n",
      "10550it [39:16,  3.72it/s]Train epoch: 6 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.006046\n",
      "10575it [39:23,  3.73it/s]Train epoch: 6 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.005306\n",
      "10600it [39:30,  3.76it/s]Train epoch: 6 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.005522\n",
      "10625it [39:36,  3.71it/s]Train epoch: 6 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.006259\n",
      "10650it [39:43,  3.71it/s]Train epoch: 6 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.005806\n",
      "10675it [39:50,  3.71it/s]Train epoch: 6 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.006202\n",
      "10700it [39:57,  3.70it/s]Train epoch: 6 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.005722\n",
      "10725it [40:03,  3.71it/s]Train epoch: 6 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.005307\n",
      "10750it [40:10,  3.72it/s]Train epoch: 6 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.006124\n",
      "10775it [40:17,  3.68it/s]Train epoch: 6 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.006191\n",
      "10800it [40:24,  3.67it/s]Train epoch: 6 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.006462\n",
      "10825it [40:31,  3.67it/s]Train epoch: 6 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006392\n",
      "10850it [40:37,  3.64it/s]Train epoch: 6 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006386\n",
      "10875it [40:44,  3.61it/s]Train epoch: 6 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006496\n",
      "10900it [40:51,  3.65it/s]Train epoch: 6 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006174\n",
      "10925it [40:58,  3.65it/s]Train epoch: 6 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005570\n",
      "10950it [41:05,  3.66it/s]Train epoch: 6 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006092\n",
      "10975it [41:12,  3.62it/s]Train epoch: 6 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.005883\n",
      "11000it [41:19,  3.62it/s]Train epoch: 6 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.005969\n",
      "11025it [41:26,  3.60it/s]Train epoch: 6 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006055\n",
      "11050it [41:33,  3.59it/s]Train epoch: 6 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.006842\n",
      "11075it [41:40,  3.57it/s]Train epoch: 6 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006287\n",
      "11100it [41:47,  3.54it/s]Train epoch: 6 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.006903\n",
      "11125it [41:54,  3.60it/s]Train epoch: 6 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006500\n",
      "11150it [42:01,  3.54it/s]Train epoch: 6 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006201\n",
      "11175it [42:08,  3.57it/s]Train epoch: 6 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007269\n",
      "11200it [42:15,  3.49it/s]Train epoch: 6 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006594\n",
      "11225it [42:22,  3.52it/s]Train epoch: 6 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006489\n",
      "11250it [42:29,  3.45it/s]Train epoch: 6 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007259\n",
      "11275it [42:36,  3.49it/s]Train epoch: 6 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.006846\n",
      "11300it [42:43,  3.52it/s]Train epoch: 6 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006198\n",
      "11325it [42:51,  3.47it/s]Train epoch: 6 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007378\n",
      "11350it [42:58,  3.44it/s]Train epoch: 6 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007208\n",
      "11375it [43:05,  3.43it/s]Train epoch: 6 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007460\n",
      "11400it [43:12,  3.41it/s]Train epoch: 6 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006535\n",
      "11425it [43:20,  3.43it/s]Train epoch: 6 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007108\n",
      "11450it [43:27,  3.38it/s]Train epoch: 6 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006466\n",
      "11475it [43:34,  3.40it/s]Train epoch: 6 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007593\n",
      "11500it [43:42,  3.38it/s]Train epoch: 6 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007342\n",
      "11525it [43:49,  3.34it/s]Train epoch: 6 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006650\n",
      "11550it [43:57,  3.34it/s]Train epoch: 6 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.006617\n",
      "11575it [44:04,  3.32it/s]Train epoch: 6 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007730\n",
      "11600it [44:12,  3.32it/s]Train epoch: 6 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007022\n",
      "11625it [44:20,  3.30it/s]Train epoch: 6 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006680\n",
      "11650it [44:27,  3.20it/s]Train epoch: 6 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007217\n",
      "11675it [44:35,  3.18it/s]Train epoch: 6 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007748\n",
      "11700it [44:43,  3.14it/s]Train epoch: 6 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008155\n",
      "11725it [44:51,  3.18it/s]Train epoch: 6 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008199\n",
      "11750it [44:59,  3.11it/s]Train epoch: 6 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.007914\n",
      "11775it [45:07,  3.06it/s]Train epoch: 6 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.007833\n",
      "11800it [45:15,  3.01it/s]Train epoch: 6 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007658\n",
      "11825it [45:24,  2.96it/s]Train epoch: 6 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.007872\n",
      "11850it [45:32,  2.89it/s]Train epoch: 6 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008197\n",
      "11875it [45:41,  2.80it/s]Train epoch: 6 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009003\n",
      "11900it [45:50,  2.62it/s]Train epoch: 6 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.010863\n",
      "11925it [46:00,  2.32it/s]Train epoch: 6 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009074\n",
      "11930it [46:03,  4.32it/s]\n",
      "epoch loss: 0.004581303617606496\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.30it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0293, 0.0428, 0.0520, 0.0470, 0.8810\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3032, 0.4862, 0.4461, 0.4653, 0.9802\n",
      "rec_at_8: 0.3297\n",
      "prec_at_8: 0.6129\n",
      "rec_at_15: 0.4623\n",
      "prec_at_15: 0.4787\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:51, 30.27it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0304, 0.0467, 0.0554, 0.0507, 0.8747\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2969, 0.4806, 0.4371, 0.4578, 0.9797\n",
      "rec_at_8: 0.3142\n",
      "prec_at_8: 0.6059\n",
      "rec_at_15: 0.4441\n",
      "prec_at_15: 0.4768\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 6\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0293, 0.0428, 0.0520, 0.0470, 0.8810\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3032, 0.4862, 0.4461, 0.4653, 0.9802\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0072\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 6\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0304, 0.0467, 0.0554, 0.0507, 0.8747\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2969, 0.4806, 0.4371, 0.4578, 0.9797\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0075\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 7\n",
      "0it [00:00, ?it/s]Train epoch: 7 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.005634\n",
      "25it [00:04,  5.45it/s]Train epoch: 7 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.004087\n",
      "50it [00:09,  5.53it/s]Train epoch: 7 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.003674\n",
      "75it [00:13,  5.48it/s]Train epoch: 7 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.002972\n",
      "100it [00:18,  5.47it/s]Train epoch: 7 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.003137\n",
      "125it [00:22,  5.38it/s]Train epoch: 7 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.003053\n",
      "150it [00:27,  5.33it/s]Train epoch: 7 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.002876\n",
      "175it [00:32,  5.35it/s]Train epoch: 7 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.003104\n",
      "200it [00:36,  5.22it/s]Train epoch: 7 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.002836\n",
      "225it [00:41,  5.42it/s]Train epoch: 7 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.003598\n",
      "250it [00:46,  5.24it/s]Train epoch: 7 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.002866\n",
      "275it [00:50,  5.28it/s]Train epoch: 7 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.002531\n",
      "300it [00:55,  5.27it/s]Train epoch: 7 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003302\n",
      "325it [01:00,  5.12it/s]Train epoch: 7 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.002702\n",
      "350it [01:05,  5.29it/s]Train epoch: 7 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.003275\n",
      "375it [01:09,  5.23it/s]Train epoch: 7 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.003065\n",
      "400it [01:14,  5.26it/s]Train epoch: 7 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.003089\n",
      "425it [01:19,  5.22it/s]Train epoch: 7 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.002992\n",
      "450it [01:24,  5.23it/s]Train epoch: 7 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.002872\n",
      "475it [01:29,  5.31it/s]Train epoch: 7 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.003444\n",
      "500it [01:33,  5.13it/s]Train epoch: 7 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.002801\n",
      "525it [01:38,  5.20it/s]Train epoch: 7 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.003168\n",
      "550it [01:43,  5.27it/s]Train epoch: 7 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.003094\n",
      "575it [01:48,  5.16it/s]Train epoch: 7 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.003036\n",
      "600it [01:53,  5.08it/s]Train epoch: 7 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.003249\n",
      "625it [01:58,  5.17it/s]Train epoch: 7 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.003161\n",
      "650it [02:02,  5.11it/s]Train epoch: 7 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.002808\n",
      "675it [02:07,  5.15it/s]Train epoch: 7 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002512\n",
      "700it [02:12,  5.09it/s]Train epoch: 7 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.002943\n",
      "725it [02:17,  5.08it/s]Train epoch: 7 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.003161\n",
      "750it [02:22,  5.08it/s]Train epoch: 7 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.002920\n",
      "775it [02:27,  5.06it/s]Train epoch: 7 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.003310\n",
      "800it [02:32,  5.07it/s]Train epoch: 7 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.003183\n",
      "825it [02:37,  4.97it/s]Train epoch: 7 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.003060\n",
      "850it [02:42,  5.11it/s]Train epoch: 7 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.003541\n",
      "875it [02:47,  5.09it/s]Train epoch: 7 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.002840\n",
      "900it [02:52,  5.16it/s]Train epoch: 7 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.003289\n",
      "925it [02:57,  4.82it/s]Train epoch: 7 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.002873\n",
      "950it [03:02,  5.03it/s]Train epoch: 7 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.002853\n",
      "975it [03:07,  4.73it/s]Train epoch: 7 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002395\n",
      "1000it [03:12,  5.03it/s]Train epoch: 7 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.003181\n",
      "1025it [03:17,  5.00it/s]Train epoch: 7 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.004283\n",
      "1050it [03:22,  4.79it/s]Train epoch: 7 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.002860\n",
      "1075it [03:27,  5.09it/s]Train epoch: 7 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.003217\n",
      "1100it [03:32,  5.00it/s]Train epoch: 7 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.003282\n",
      "1125it [03:37,  4.99it/s]Train epoch: 7 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.003337\n",
      "1150it [03:42,  5.12it/s]Train epoch: 7 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.003379\n",
      "1175it [03:47,  4.82it/s]Train epoch: 7 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.003202\n",
      "1200it [03:52,  5.05it/s]Train epoch: 7 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.003345\n",
      "1225it [03:57,  5.08it/s]Train epoch: 7 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.003497\n",
      "1250it [04:02,  4.98it/s]Train epoch: 7 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003312\n",
      "1275it [04:07,  5.03it/s]Train epoch: 7 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.002865\n",
      "1300it [04:12,  4.97it/s]Train epoch: 7 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.002804\n",
      "1325it [04:17,  5.01it/s]Train epoch: 7 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.002868\n",
      "1350it [04:22,  5.05it/s]Train epoch: 7 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.003761\n",
      "1375it [04:27,  5.02it/s]Train epoch: 7 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.003128\n",
      "1400it [04:32,  4.97it/s]Train epoch: 7 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.003114\n",
      "1425it [04:37,  5.09it/s]Train epoch: 7 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.002782\n",
      "1450it [04:42,  4.93it/s]Train epoch: 7 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.003124\n",
      "1475it [04:47,  5.01it/s]Train epoch: 7 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.003139\n",
      "1500it [04:52,  4.95it/s]Train epoch: 7 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.004377\n",
      "1525it [04:57,  4.95it/s]Train epoch: 7 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.004060\n",
      "1550it [05:02,  4.92it/s]Train epoch: 7 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.002948\n",
      "1575it [05:07,  4.88it/s]Train epoch: 7 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.003350\n",
      "1600it [05:12,  4.96it/s]Train epoch: 7 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.002802\n",
      "1625it [05:17,  4.96it/s]Train epoch: 7 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.003501\n",
      "1650it [05:22,  5.00it/s]Train epoch: 7 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.003510\n",
      "1675it [05:27,  4.95it/s]Train epoch: 7 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.003406\n",
      "1700it [05:32,  5.03it/s]Train epoch: 7 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.003010\n",
      "1725it [05:37,  4.94it/s]Train epoch: 7 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.002607\n",
      "1750it [05:42,  4.98it/s]Train epoch: 7 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.003955\n",
      "1775it [05:47,  4.94it/s]Train epoch: 7 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.003275\n",
      "1800it [05:53,  4.86it/s]Train epoch: 7 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.003156\n",
      "1825it [05:58,  4.90it/s]Train epoch: 7 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.002704\n",
      "1850it [06:03,  4.90it/s]Train epoch: 7 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.003383\n",
      "1875it [06:08,  4.92it/s]Train epoch: 7 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.003519\n",
      "1900it [06:13,  4.92it/s]Train epoch: 7 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.002664\n",
      "1925it [06:18,  4.84it/s]Train epoch: 7 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.002868\n",
      "1950it [06:23,  4.90it/s]Train epoch: 7 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.002769\n",
      "1975it [06:28,  4.88it/s]Train epoch: 7 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.003450\n",
      "2000it [06:33,  4.81it/s]Train epoch: 7 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.002685\n",
      "2025it [06:39,  4.90it/s]Train epoch: 7 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.003347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050it [06:44,  4.88it/s]Train epoch: 7 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.003162\n",
      "2075it [06:49,  4.86it/s]Train epoch: 7 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.003239\n",
      "2100it [06:54,  4.86it/s]Train epoch: 7 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.003346\n",
      "2125it [06:59,  4.86it/s]Train epoch: 7 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.003690\n",
      "2150it [07:04,  4.81it/s]Train epoch: 7 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.003138\n",
      "2175it [07:09,  4.93it/s]Train epoch: 7 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.003533\n",
      "2200it [07:14,  4.85it/s]Train epoch: 7 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.003260\n",
      "2225it [07:20,  4.86it/s]Train epoch: 7 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.003172\n",
      "2250it [07:25,  4.91it/s]Train epoch: 7 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.002876\n",
      "2275it [07:30,  4.84it/s]Train epoch: 7 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.003323\n",
      "2300it [07:35,  4.93it/s]Train epoch: 7 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.002558\n",
      "2325it [07:40,  4.88it/s]Train epoch: 7 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.003159\n",
      "2350it [07:45,  4.88it/s]Train epoch: 7 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.002978\n",
      "2375it [07:50,  4.87it/s]Train epoch: 7 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.004332\n",
      "2400it [07:56,  4.83it/s]Train epoch: 7 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.003865\n",
      "2425it [08:01,  4.85it/s]Train epoch: 7 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.002838\n",
      "2450it [08:06,  4.84it/s]Train epoch: 7 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.003183\n",
      "2475it [08:11,  4.82it/s]Train epoch: 7 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.003669\n",
      "2500it [08:16,  4.75it/s]Train epoch: 7 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.003034\n",
      "2525it [08:21,  4.80it/s]Train epoch: 7 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.003039\n",
      "2550it [08:27,  4.84it/s]Train epoch: 7 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.004160\n",
      "2575it [08:32,  4.80it/s]Train epoch: 7 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.003029\n",
      "2600it [08:37,  4.85it/s]Train epoch: 7 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.003357\n",
      "2625it [08:42,  4.87it/s]Train epoch: 7 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.003287\n",
      "2650it [08:47,  4.84it/s]Train epoch: 7 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.003816\n",
      "2675it [08:52,  4.79it/s]Train epoch: 7 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.003341\n",
      "2700it [08:58,  4.83it/s]Train epoch: 7 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.002988\n",
      "2725it [09:03,  4.81it/s]Train epoch: 7 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.003176\n",
      "2750it [09:08,  4.84it/s]Train epoch: 7 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.003783\n",
      "2775it [09:13,  4.85it/s]Train epoch: 7 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.003306\n",
      "2800it [09:18,  4.78it/s]Train epoch: 7 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.003124\n",
      "2825it [09:24,  4.81it/s]Train epoch: 7 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.003486\n",
      "2850it [09:29,  4.77it/s]Train epoch: 7 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.003220\n",
      "2875it [09:34,  4.82it/s]Train epoch: 7 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.003600\n",
      "2900it [09:39,  4.75it/s]Train epoch: 7 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.003602\n",
      "2925it [09:45,  4.76it/s]Train epoch: 7 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.003551\n",
      "2950it [09:50,  4.77it/s]Train epoch: 7 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.003779\n",
      "2975it [09:55,  4.76it/s]Train epoch: 7 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.003438\n",
      "3000it [10:00,  4.88it/s]Train epoch: 7 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.004021\n",
      "3025it [10:05,  4.74it/s]Train epoch: 7 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.003541\n",
      "3050it [10:11,  4.77it/s]Train epoch: 7 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.003184\n",
      "3075it [10:16,  4.78it/s]Train epoch: 7 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.003694\n",
      "3100it [10:21,  4.74it/s]Train epoch: 7 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.003677\n",
      "3125it [10:26,  4.76it/s]Train epoch: 7 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.003289\n",
      "3150it [10:32,  4.78it/s]Train epoch: 7 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.003213\n",
      "3175it [10:37,  4.78it/s]Train epoch: 7 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.003212\n",
      "3200it [10:42,  4.73it/s]Train epoch: 7 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.003926\n",
      "3225it [10:48,  4.73it/s]Train epoch: 7 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.003689\n",
      "3250it [10:53,  4.72it/s]Train epoch: 7 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.003602\n",
      "3275it [10:58,  4.75it/s]Train epoch: 7 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.003274\n",
      "3300it [11:03,  4.73it/s]Train epoch: 7 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.004107\n",
      "3325it [11:09,  4.70it/s]Train epoch: 7 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.003554\n",
      "3350it [11:14,  4.74it/s]Train epoch: 7 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.003591\n",
      "3375it [11:19,  4.70it/s]Train epoch: 7 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.003892\n",
      "3400it [11:25,  4.71it/s]Train epoch: 7 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.003802\n",
      "3425it [11:30,  4.70it/s]Train epoch: 7 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.003302\n",
      "3450it [11:35,  4.72it/s]Train epoch: 7 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.003817\n",
      "3475it [11:40,  4.69it/s]Train epoch: 7 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.003333\n",
      "3500it [11:46,  4.69it/s]Train epoch: 7 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.003543\n",
      "3525it [11:51,  4.77it/s]Train epoch: 7 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.003572\n",
      "3550it [11:56,  4.72it/s]Train epoch: 7 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.003809\n",
      "3575it [12:02,  4.72it/s]Train epoch: 7 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.003116\n",
      "3600it [12:07,  4.68it/s]Train epoch: 7 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.003974\n",
      "3625it [12:12,  4.70it/s]Train epoch: 7 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.003626\n",
      "3650it [12:18,  4.66it/s]Train epoch: 7 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.003831\n",
      "3675it [12:23,  4.68it/s]Train epoch: 7 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.003794\n",
      "3700it [12:28,  4.71it/s]Train epoch: 7 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.003651\n",
      "3725it [12:34,  4.71it/s]Train epoch: 7 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.003885\n",
      "3750it [12:39,  4.84it/s]Train epoch: 7 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.003885\n",
      "3775it [12:44,  4.73it/s]Train epoch: 7 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.003625\n",
      "3800it [12:50,  4.66it/s]Train epoch: 7 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.004124\n",
      "3825it [12:55,  4.67it/s]Train epoch: 7 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.003454\n",
      "3850it [13:00,  4.68it/s]Train epoch: 7 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.003158\n",
      "3875it [13:06,  4.68it/s]Train epoch: 7 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.003180\n",
      "3900it [13:11,  4.71it/s]Train epoch: 7 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.004116\n",
      "3925it [13:16,  4.73it/s]Train epoch: 7 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.003813\n",
      "3950it [13:22,  4.61it/s]Train epoch: 7 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.004159\n",
      "3975it [13:27,  4.68it/s]Train epoch: 7 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.004660\n",
      "4000it [13:32,  4.68it/s]Train epoch: 7 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.003325\n",
      "4025it [13:38,  4.65it/s]Train epoch: 7 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.004223\n",
      "4050it [13:43,  4.73it/s]Train epoch: 7 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.003872\n",
      "4075it [13:48,  4.66it/s]Train epoch: 7 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.003850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100it [13:54,  4.70it/s]Train epoch: 7 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.004331\n",
      "4125it [13:59,  4.62it/s]Train epoch: 7 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.004066\n",
      "4150it [14:05,  4.55it/s]Train epoch: 7 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.003571\n",
      "4175it [14:10,  4.65it/s]Train epoch: 7 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.003668\n",
      "4200it [14:15,  4.63it/s]Train epoch: 7 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.004075\n",
      "4225it [14:21,  4.66it/s]Train epoch: 7 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.003473\n",
      "4250it [14:26,  4.65it/s]Train epoch: 7 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.003872\n",
      "4275it [14:31,  4.68it/s]Train epoch: 7 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.003709\n",
      "4300it [14:37,  4.66it/s]Train epoch: 7 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.004298\n",
      "4325it [14:42,  4.63it/s]Train epoch: 7 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.003871\n",
      "4350it [14:48,  4.66it/s]Train epoch: 7 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.004145\n",
      "4375it [14:53,  4.60it/s]Train epoch: 7 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.003669\n",
      "4400it [14:58,  4.59it/s]Train epoch: 7 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.003174\n",
      "4425it [15:04,  4.62it/s]Train epoch: 7 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.003949\n",
      "4450it [15:09,  4.60it/s]Train epoch: 7 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.003160\n",
      "4475it [15:15,  4.61it/s]Train epoch: 7 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.003895\n",
      "4500it [15:20,  4.64it/s]Train epoch: 7 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.004687\n",
      "4525it [15:26,  4.60it/s]Train epoch: 7 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.003855\n",
      "4550it [15:31,  4.61it/s]Train epoch: 7 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.003773\n",
      "4575it [15:36,  4.59it/s]Train epoch: 7 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.004237\n",
      "4600it [15:42,  4.66it/s]Train epoch: 7 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.003479\n",
      "4625it [15:47,  4.59it/s]Train epoch: 7 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.003664\n",
      "4650it [15:53,  4.57it/s]Train epoch: 7 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.004280\n",
      "4675it [15:58,  4.57it/s]Train epoch: 7 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.004053\n",
      "4700it [16:04,  4.50it/s]Train epoch: 7 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.003635\n",
      "4725it [16:09,  4.55it/s]Train epoch: 7 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.003801\n",
      "4750it [16:15,  4.62it/s]Train epoch: 7 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.004505\n",
      "4775it [16:20,  4.56it/s]Train epoch: 7 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.003894\n",
      "4800it [16:26,  4.55it/s]Train epoch: 7 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.003960\n",
      "4825it [16:31,  4.54it/s]Train epoch: 7 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.003614\n",
      "4850it [16:37,  4.58it/s]Train epoch: 7 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.004276\n",
      "4875it [16:42,  4.53it/s]Train epoch: 7 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.003699\n",
      "4900it [16:48,  4.50it/s]Train epoch: 7 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.003873\n",
      "4925it [16:53,  4.55it/s]Train epoch: 7 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.003550\n",
      "4950it [16:59,  4.56it/s]Train epoch: 7 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.003745\n",
      "4975it [17:04,  4.54it/s]Train epoch: 7 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.003762\n",
      "5000it [17:10,  4.56it/s]Train epoch: 7 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.003919\n",
      "5025it [17:15,  4.51it/s]Train epoch: 7 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.003646\n",
      "5050it [17:21,  4.55it/s]Train epoch: 7 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.003571\n",
      "5075it [17:26,  4.55it/s]Train epoch: 7 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.003920\n",
      "5100it [17:31,  4.55it/s]Train epoch: 7 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.003951\n",
      "5125it [17:37,  4.52it/s]Train epoch: 7 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.004079\n",
      "5150it [17:43,  4.56it/s]Train epoch: 7 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.004140\n",
      "5175it [17:48,  4.53it/s]Train epoch: 7 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.003928\n",
      "5200it [17:54,  4.47it/s]Train epoch: 7 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.003620\n",
      "5225it [17:59,  4.52it/s]Train epoch: 7 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.003884\n",
      "5250it [18:05,  4.47it/s]Train epoch: 7 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.004014\n",
      "5275it [18:10,  4.53it/s]Train epoch: 7 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.003769\n",
      "5300it [18:16,  4.52it/s]Train epoch: 7 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.003573\n",
      "5325it [18:21,  4.50it/s]Train epoch: 7 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.004164\n",
      "5350it [18:27,  4.47it/s]Train epoch: 7 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.004150\n",
      "5375it [18:32,  4.55it/s]Train epoch: 7 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.003709\n",
      "5400it [18:38,  4.56it/s]Train epoch: 7 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.003778\n",
      "5425it [18:44,  4.53it/s]Train epoch: 7 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.004139\n",
      "5450it [18:49,  4.48it/s]Train epoch: 7 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.004009\n",
      "5475it [18:55,  4.47it/s]Train epoch: 7 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.004688\n",
      "5500it [19:00,  4.46it/s]Train epoch: 7 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.004280\n",
      "5525it [19:06,  4.47it/s]Train epoch: 7 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.003590\n",
      "5550it [19:11,  4.48it/s]Train epoch: 7 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.004053\n",
      "5575it [19:17,  4.46it/s]Train epoch: 7 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.004156\n",
      "5600it [19:23,  4.47it/s]Train epoch: 7 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.004386\n",
      "5625it [19:28,  4.51it/s]Train epoch: 7 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.004026\n",
      "5650it [19:34,  4.52it/s]Train epoch: 7 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.003592\n",
      "5675it [19:39,  4.51it/s]Train epoch: 7 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.004522\n",
      "5700it [19:45,  4.46it/s]Train epoch: 7 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.003868\n",
      "5725it [19:50,  4.47it/s]Train epoch: 7 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.004015\n",
      "5750it [19:56,  4.45it/s]Train epoch: 7 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.005253\n",
      "5775it [20:02,  4.51it/s]Train epoch: 7 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.004184\n",
      "5800it [20:07,  4.38it/s]Train epoch: 7 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.004329\n",
      "5825it [20:13,  4.43it/s]Train epoch: 7 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.003706\n",
      "5850it [20:19,  4.44it/s]Train epoch: 7 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.004877\n",
      "5875it [20:24,  4.46it/s]Train epoch: 7 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.004532\n",
      "5900it [20:30,  4.41it/s]Train epoch: 7 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.004484\n",
      "5925it [20:35,  4.44it/s]Train epoch: 7 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.003880\n",
      "5950it [20:41,  4.44it/s]Train epoch: 7 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.003671\n",
      "5975it [20:47,  4.42it/s]Train epoch: 7 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.005202\n",
      "6000it [20:52,  4.41it/s]Train epoch: 7 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.004323\n",
      "6025it [20:58,  4.39it/s]Train epoch: 7 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.004594\n",
      "6050it [21:04,  4.45it/s]Train epoch: 7 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.004043\n",
      "6075it [21:09,  4.37it/s]Train epoch: 7 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.003783\n",
      "6100it [21:15,  4.40it/s]Train epoch: 7 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.003577\n",
      "6125it [21:21,  4.38it/s]Train epoch: 7 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.004141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6150it [21:26,  4.42it/s]Train epoch: 7 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.004120\n",
      "6175it [21:32,  4.41it/s]Train epoch: 7 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.004620\n",
      "6200it [21:38,  4.39it/s]Train epoch: 7 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.004186\n",
      "6225it [21:43,  4.40it/s]Train epoch: 7 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.003610\n",
      "6250it [21:49,  4.44it/s]Train epoch: 7 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.003861\n",
      "6275it [21:55,  4.39it/s]Train epoch: 7 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.003516\n",
      "6300it [22:00,  4.39it/s]Train epoch: 7 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.004059\n",
      "6325it [22:06,  4.40it/s]Train epoch: 7 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.004506\n",
      "6350it [22:12,  4.39it/s]Train epoch: 7 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.004758\n",
      "6375it [22:17,  4.37it/s]Train epoch: 7 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.003673\n",
      "6400it [22:23,  4.47it/s]Train epoch: 7 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.004097\n",
      "6425it [22:29,  4.42it/s]Train epoch: 7 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.004482\n",
      "6450it [22:34,  4.40it/s]Train epoch: 7 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.004438\n",
      "6475it [22:40,  4.43it/s]Train epoch: 7 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.004011\n",
      "6500it [22:46,  4.36it/s]Train epoch: 7 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.004645\n",
      "6525it [22:52,  4.43it/s]Train epoch: 7 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.003882\n",
      "6550it [22:57,  4.33it/s]Train epoch: 7 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.004009\n",
      "6575it [23:03,  4.38it/s]Train epoch: 7 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.004059\n",
      "6600it [23:09,  4.40it/s]Train epoch: 7 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.004956\n",
      "6625it [23:14,  4.40it/s]Train epoch: 7 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.004109\n",
      "6650it [23:20,  4.33it/s]Train epoch: 7 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.004767\n",
      "6675it [23:26,  4.35it/s]Train epoch: 7 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.004239\n",
      "6700it [23:32,  4.36it/s]Train epoch: 7 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.004400\n",
      "6725it [23:37,  4.31it/s]Train epoch: 7 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.004400\n",
      "6750it [23:43,  4.40it/s]Train epoch: 7 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.003947\n",
      "6775it [23:49,  4.33it/s]Train epoch: 7 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.004645\n",
      "6800it [23:55,  4.34it/s]Train epoch: 7 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.004600\n",
      "6825it [24:00,  4.35it/s]Train epoch: 7 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.004556\n",
      "6850it [24:06,  4.35it/s]Train epoch: 7 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.004434\n",
      "6875it [24:12,  4.33it/s]Train epoch: 7 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.003646\n",
      "6900it [24:18,  4.27it/s]Train epoch: 7 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.004258\n",
      "6925it [24:24,  4.31it/s]Train epoch: 7 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.004321\n",
      "6950it [24:29,  4.33it/s]Train epoch: 7 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.004788\n",
      "6975it [24:35,  4.28it/s]Train epoch: 7 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.004451\n",
      "7000it [24:41,  4.30it/s]Train epoch: 7 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.004158\n",
      "7025it [24:47,  4.32it/s]Train epoch: 7 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.004945\n",
      "7050it [24:53,  4.31it/s]Train epoch: 7 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.003856\n",
      "7075it [24:58,  4.30it/s]Train epoch: 7 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.004435\n",
      "7100it [25:04,  4.31it/s]Train epoch: 7 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.004458\n",
      "7125it [25:10,  4.29it/s]Train epoch: 7 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.003903\n",
      "7150it [25:16,  4.24it/s]Train epoch: 7 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.004813\n",
      "7175it [25:22,  4.29it/s]Train epoch: 7 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.004393\n",
      "7200it [25:28,  4.26it/s]Train epoch: 7 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.004816\n",
      "7225it [25:33,  4.30it/s]Train epoch: 7 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.004269\n",
      "7250it [25:39,  4.31it/s]Train epoch: 7 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.004201\n",
      "7275it [25:45,  4.32it/s]Train epoch: 7 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.004896\n",
      "7300it [25:51,  4.24it/s]Train epoch: 7 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.005169\n",
      "7325it [25:57,  4.31it/s]Train epoch: 7 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.004094\n",
      "7350it [26:03,  4.34it/s]Train epoch: 7 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.005083\n",
      "7375it [26:08,  4.25it/s]Train epoch: 7 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.004626\n",
      "7400it [26:14,  4.24it/s]Train epoch: 7 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.004253\n",
      "7425it [26:20,  4.30it/s]Train epoch: 7 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.004596\n",
      "7450it [26:26,  4.30it/s]Train epoch: 7 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.005067\n",
      "7475it [26:32,  4.31it/s]Train epoch: 7 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.004355\n",
      "7500it [26:38,  4.24it/s]Train epoch: 7 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.004752\n",
      "7525it [26:44,  4.27it/s]Train epoch: 7 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.004467\n",
      "7550it [26:49,  4.22it/s]Train epoch: 7 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.004277\n",
      "7575it [26:55,  4.21it/s]Train epoch: 7 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.004691\n",
      "7600it [27:01,  4.25it/s]Train epoch: 7 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.005676\n",
      "7625it [27:07,  4.28it/s]Train epoch: 7 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.005292\n",
      "7650it [27:13,  4.22it/s]Train epoch: 7 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.004429\n",
      "7675it [27:19,  4.27it/s]Train epoch: 7 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.004242\n",
      "7700it [27:25,  4.21it/s]Train epoch: 7 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.004516\n",
      "7725it [27:31,  4.20it/s]Train epoch: 7 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.004551\n",
      "7750it [27:37,  4.19it/s]Train epoch: 7 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.004849\n",
      "7775it [27:43,  4.28it/s]Train epoch: 7 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.004254\n",
      "7800it [27:48,  4.19it/s]Train epoch: 7 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.004453\n",
      "7825it [27:54,  4.22it/s]Train epoch: 7 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.004741\n",
      "7850it [28:00,  4.26it/s]Train epoch: 7 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.004239\n",
      "7875it [28:06,  4.24it/s]Train epoch: 7 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.004481\n",
      "7900it [28:12,  4.19it/s]Train epoch: 7 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.004676\n",
      "7925it [28:18,  4.17it/s]Train epoch: 7 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.004574\n",
      "7950it [28:24,  4.21it/s]Train epoch: 7 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.005150\n",
      "7975it [28:30,  4.25it/s]Train epoch: 7 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.004360\n",
      "8000it [28:36,  4.19it/s]Train epoch: 7 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.004303\n",
      "8025it [28:42,  4.19it/s]Train epoch: 7 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.004780\n",
      "8050it [28:48,  4.18it/s]Train epoch: 7 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.003956\n",
      "8075it [28:54,  4.18it/s]Train epoch: 7 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.004592\n",
      "8100it [29:00,  4.15it/s]Train epoch: 7 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.004932\n",
      "8125it [29:06,  4.17it/s]Train epoch: 7 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.004963\n",
      "8150it [29:12,  4.15it/s]Train epoch: 7 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.004312\n",
      "8175it [29:18,  4.16it/s]Train epoch: 7 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.004974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200it [29:24,  4.18it/s]Train epoch: 7 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.004242\n",
      "8225it [29:30,  4.17it/s]Train epoch: 7 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.005793\n",
      "8250it [29:36,  4.10it/s]Train epoch: 7 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.004356\n",
      "8275it [29:42,  4.09it/s]Train epoch: 7 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.005097\n",
      "8300it [29:48,  4.16it/s]Train epoch: 7 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.004348\n",
      "8325it [29:54,  4.15it/s]Train epoch: 7 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.004949\n",
      "8350it [30:00,  4.12it/s]Train epoch: 7 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.004381\n",
      "8375it [30:06,  4.10it/s]Train epoch: 7 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.004918\n",
      "8400it [30:12,  4.13it/s]Train epoch: 7 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.004589\n",
      "8425it [30:18,  4.11it/s]Train epoch: 7 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.004616\n",
      "8450it [30:24,  4.14it/s]Train epoch: 7 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.004973\n",
      "8475it [30:30,  4.17it/s]Train epoch: 7 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.004662\n",
      "8500it [30:36,  4.10it/s]Train epoch: 7 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.005517\n",
      "8525it [30:42,  4.09it/s]Train epoch: 7 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.004571\n",
      "8550it [30:48,  4.12it/s]Train epoch: 7 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.004899\n",
      "8575it [30:55,  4.13it/s]Train epoch: 7 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.004490\n",
      "8600it [31:01,  4.05it/s]Train epoch: 7 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.004658\n",
      "8625it [31:07,  4.06it/s]Train epoch: 7 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.004928\n",
      "8650it [31:13,  4.08it/s]Train epoch: 7 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.005008\n",
      "8675it [31:19,  4.07it/s]Train epoch: 7 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.005557\n",
      "8700it [31:25,  4.14it/s]Train epoch: 7 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.005632\n",
      "8725it [31:31,  4.08it/s]Train epoch: 7 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.005307\n",
      "8750it [31:37,  4.09it/s]Train epoch: 7 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.005133\n",
      "8775it [31:43,  4.08it/s]Train epoch: 7 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.004543\n",
      "8800it [31:50,  4.01it/s]Train epoch: 7 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.004856\n",
      "8825it [31:56,  4.07it/s]Train epoch: 7 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.004892\n",
      "8850it [32:02,  4.06it/s]Train epoch: 7 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.005037\n",
      "8875it [32:08,  3.99it/s]Train epoch: 7 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.004796\n",
      "8900it [32:14,  4.09it/s]Train epoch: 7 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.004839\n",
      "8925it [32:20,  4.06it/s]Train epoch: 7 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.005119\n",
      "8950it [32:26,  4.06it/s]Train epoch: 7 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.005754\n",
      "8975it [32:33,  4.06it/s]Train epoch: 7 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.005154\n",
      "9000it [32:39,  4.04it/s]Train epoch: 7 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.004947\n",
      "9025it [32:45,  4.06it/s]Train epoch: 7 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.005032\n",
      "9050it [32:51,  4.10it/s]Train epoch: 7 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.004612\n",
      "9075it [32:57,  4.06it/s]Train epoch: 7 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.004292\n",
      "9100it [33:04,  4.06it/s]Train epoch: 7 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.005142\n",
      "9125it [33:10,  4.02it/s]Train epoch: 7 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.004588\n",
      "9150it [33:16,  4.05it/s]Train epoch: 7 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.004382\n",
      "9175it [33:22,  4.02it/s]Train epoch: 7 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.004721\n",
      "9200it [33:28,  4.01it/s]Train epoch: 7 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.004689\n",
      "9225it [33:35,  4.02it/s]Train epoch: 7 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.005535\n",
      "9250it [33:41,  4.00it/s]Train epoch: 7 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.004968\n",
      "9275it [33:47,  3.99it/s]Train epoch: 7 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.005184\n",
      "9300it [33:53,  3.98it/s]Train epoch: 7 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.005931\n",
      "9325it [34:00,  4.01it/s]Train epoch: 7 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.005572\n",
      "9350it [34:06,  3.93it/s]Train epoch: 7 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.005464\n",
      "9375it [34:12,  3.97it/s]Train epoch: 7 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.004726\n",
      "9400it [34:18,  4.00it/s]Train epoch: 7 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.005147\n",
      "9425it [34:25,  3.96it/s]Train epoch: 7 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.004864\n",
      "9450it [34:31,  3.93it/s]Train epoch: 7 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.004802\n",
      "9475it [34:37,  3.95it/s]Train epoch: 7 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.005537\n",
      "9500it [34:44,  3.99it/s]Train epoch: 7 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.005125\n",
      "9525it [34:50,  3.97it/s]Train epoch: 7 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.005705\n",
      "9550it [34:56,  3.96it/s]Train epoch: 7 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.005431\n",
      "9575it [35:03,  3.95it/s]Train epoch: 7 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.005462\n",
      "9600it [35:09,  3.93it/s]Train epoch: 7 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.005321\n",
      "9625it [35:15,  3.99it/s]Train epoch: 7 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.004872\n",
      "9650it [35:22,  3.97it/s]Train epoch: 7 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.004856\n",
      "9675it [35:28,  3.94it/s]Train epoch: 7 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.005345\n",
      "9700it [35:34,  3.91it/s]Train epoch: 7 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.004715\n",
      "9725it [35:41,  3.97it/s]Train epoch: 7 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.005182\n",
      "9750it [35:47,  3.93it/s]Train epoch: 7 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.005309\n",
      "9775it [35:53,  3.87it/s]Train epoch: 7 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.005753\n",
      "9800it [36:00,  3.91it/s]Train epoch: 7 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.005594\n",
      "9825it [36:06,  3.92it/s]Train epoch: 7 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.005686\n",
      "9850it [36:13,  3.94it/s]Train epoch: 7 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.005249\n",
      "9875it [36:19,  3.94it/s]Train epoch: 7 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.005561\n",
      "9900it [36:25,  3.90it/s]Train epoch: 7 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.006047\n",
      "9925it [36:32,  3.89it/s]Train epoch: 7 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.005674\n",
      "9950it [36:38,  3.86it/s]Train epoch: 7 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.006184\n",
      "9975it [36:45,  3.89it/s]Train epoch: 7 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.005561\n",
      "10000it [36:51,  3.92it/s]Train epoch: 7 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.005389\n",
      "10025it [36:58,  3.86it/s]Train epoch: 7 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.005402\n",
      "10050it [37:04,  3.88it/s]Train epoch: 7 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.005609\n",
      "10075it [37:11,  3.84it/s]Train epoch: 7 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.006058\n",
      "10100it [37:17,  3.84it/s]Train epoch: 7 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.005801\n",
      "10125it [37:24,  3.87it/s]Train epoch: 7 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.005140\n",
      "10150it [37:30,  3.84it/s]Train epoch: 7 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.005652\n",
      "10175it [37:37,  3.82it/s]Train epoch: 7 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.005380\n",
      "10200it [37:43,  3.80it/s]Train epoch: 7 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.005848\n",
      "10225it [37:50,  3.82it/s]Train epoch: 7 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.005652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10250it [37:56,  3.82it/s]Train epoch: 7 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.006202\n",
      "10275it [38:03,  3.82it/s]Train epoch: 7 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.005439\n",
      "10300it [38:09,  3.78it/s]Train epoch: 7 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.006008\n",
      "10325it [38:16,  3.80it/s]Train epoch: 7 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.006074\n",
      "10350it [38:23,  3.79it/s]Train epoch: 7 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.005503\n",
      "10375it [38:29,  3.80it/s]Train epoch: 7 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.005935\n",
      "10400it [38:36,  3.81it/s]Train epoch: 7 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.005803\n",
      "10425it [38:42,  3.78it/s]Train epoch: 7 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.005502\n",
      "10450it [38:49,  3.76it/s]Train epoch: 7 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.005734\n",
      "10475it [38:56,  3.76it/s]Train epoch: 7 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.005022\n",
      "10500it [39:02,  3.74it/s]Train epoch: 7 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.005830\n",
      "10525it [39:09,  3.76it/s]Train epoch: 7 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.005646\n",
      "10550it [39:16,  3.74it/s]Train epoch: 7 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.005796\n",
      "10575it [39:22,  3.77it/s]Train epoch: 7 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.005095\n",
      "10600it [39:29,  3.77it/s]Train epoch: 7 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.005355\n",
      "10625it [39:36,  3.70it/s]Train epoch: 7 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.006095\n",
      "10650it [39:42,  3.74it/s]Train epoch: 7 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.005705\n",
      "10675it [39:49,  3.72it/s]Train epoch: 7 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.005956\n",
      "10700it [39:56,  3.69it/s]Train epoch: 7 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.005703\n",
      "10725it [40:03,  3.68it/s]Train epoch: 7 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.005184\n",
      "10750it [40:09,  3.64it/s]Train epoch: 7 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.005911\n",
      "10775it [40:16,  3.68it/s]Train epoch: 7 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.006028\n",
      "10800it [40:23,  3.69it/s]Train epoch: 7 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.006229\n",
      "10825it [40:30,  3.64it/s]Train epoch: 7 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006190\n",
      "10850it [40:37,  3.69it/s]Train epoch: 7 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006188\n",
      "10875it [40:43,  3.63it/s]Train epoch: 7 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006278\n",
      "10900it [40:50,  3.64it/s]Train epoch: 7 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.005936\n",
      "10925it [40:57,  3.65it/s]Train epoch: 7 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005395\n",
      "10950it [41:04,  3.62it/s]Train epoch: 7 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.005946\n",
      "10975it [41:11,  3.61it/s]Train epoch: 7 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.005681\n",
      "11000it [41:18,  3.68it/s]Train epoch: 7 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.005807\n",
      "11025it [41:25,  3.64it/s]Train epoch: 7 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.005892\n",
      "11050it [41:32,  3.59it/s]Train epoch: 7 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.006635\n",
      "11075it [41:39,  3.57it/s]Train epoch: 7 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006133\n",
      "11100it [41:46,  3.57it/s]Train epoch: 7 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.006637\n",
      "11125it [41:53,  3.57it/s]Train epoch: 7 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006285\n",
      "11150it [42:00,  3.57it/s]Train epoch: 7 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.005995\n",
      "11175it [42:07,  3.51it/s]Train epoch: 7 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007004\n",
      "11200it [42:14,  3.56it/s]Train epoch: 7 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006366\n",
      "11225it [42:21,  3.52it/s]Train epoch: 7 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006265\n",
      "11250it [42:28,  3.52it/s]Train epoch: 7 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007036\n",
      "11275it [42:35,  3.49it/s]Train epoch: 7 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.006627\n",
      "11300it [42:42,  3.50it/s]Train epoch: 7 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006116\n",
      "11325it [42:49,  3.49it/s]Train epoch: 7 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007243\n",
      "11350it [42:56,  3.50it/s]Train epoch: 7 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007017\n",
      "11375it [43:04,  3.48it/s]Train epoch: 7 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007240\n",
      "11400it [43:11,  3.41it/s]Train epoch: 7 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006372\n",
      "11425it [43:18,  3.45it/s]Train epoch: 7 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.006975\n",
      "11450it [43:26,  3.44it/s]Train epoch: 7 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006240\n",
      "11475it [43:33,  3.40it/s]Train epoch: 7 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007360\n",
      "11500it [43:40,  3.37it/s]Train epoch: 7 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007173\n",
      "11525it [43:48,  3.33it/s]Train epoch: 7 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006530\n",
      "11550it [43:55,  3.32it/s]Train epoch: 7 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.006369\n",
      "11575it [44:03,  3.33it/s]Train epoch: 7 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007629\n",
      "11600it [44:10,  3.29it/s]Train epoch: 7 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.006851\n",
      "11625it [44:18,  3.28it/s]Train epoch: 7 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006458\n",
      "11650it [44:26,  3.25it/s]Train epoch: 7 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007021\n",
      "11675it [44:33,  3.25it/s]Train epoch: 7 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007522\n",
      "11700it [44:41,  3.19it/s]Train epoch: 7 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.007961\n",
      "11725it [44:49,  3.15it/s]Train epoch: 7 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008018\n",
      "11750it [44:57,  3.11it/s]Train epoch: 7 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.007718\n",
      "11775it [45:05,  3.07it/s]Train epoch: 7 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.007582\n",
      "11800it [45:13,  3.02it/s]Train epoch: 7 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007533\n",
      "11825it [45:22,  2.96it/s]Train epoch: 7 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.007705\n",
      "11850it [45:30,  2.89it/s]Train epoch: 7 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.007965\n",
      "11875it [45:39,  2.80it/s]Train epoch: 7 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.008917\n",
      "11900it [45:48,  2.61it/s]Train epoch: 7 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.010630\n",
      "11925it [45:59,  2.33it/s]Train epoch: 7 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.008954\n",
      "11930it [46:01,  4.32it/s]\n",
      "epoch loss: 0.004434831321042551\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.43it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0315, 0.0469, 0.0521, 0.0493, 0.8825\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3135, 0.5164, 0.4438, 0.4774, 0.9806\n",
      "rec_at_8: 0.3379\n",
      "prec_at_8: 0.6279\n",
      "rec_at_15: 0.4712\n",
      "prec_at_15: 0.4880\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:51, 30.35it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0331, 0.0517, 0.0560, 0.0538, 0.8750\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3057, 0.5091, 0.4335, 0.4682, 0.9801\n",
      "rec_at_8: 0.3230\n",
      "prec_at_8: 0.6216\n",
      "rec_at_15: 0.4566\n",
      "prec_at_15: 0.4897\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0315, 0.0469, 0.0521, 0.0493, 0.8825\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3135, 0.5164, 0.4438, 0.4774, 0.9806\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0331, 0.0517, 0.0560, 0.0538, 0.8750\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3057, 0.5091, 0.4335, 0.4682, 0.9801\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 8\n",
      "0it [00:00, ?it/s]Train epoch: 8 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.005675\n",
      "25it [00:04,  5.67it/s]Train epoch: 8 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.003972\n",
      "50it [00:08,  5.46it/s]Train epoch: 8 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.003614\n",
      "75it [00:13,  5.44it/s]Train epoch: 8 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.002944\n",
      "100it [00:18,  5.31it/s]Train epoch: 8 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.003036\n",
      "125it [00:22,  5.31it/s]Train epoch: 8 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.002952\n",
      "150it [00:27,  5.39it/s]Train epoch: 8 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.002828\n",
      "175it [00:32,  5.33it/s]Train epoch: 8 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.003047\n",
      "200it [00:36,  5.32it/s]Train epoch: 8 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.002823\n",
      "225it [00:41,  5.28it/s]Train epoch: 8 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.003495\n",
      "250it [00:46,  5.28it/s]Train epoch: 8 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.002744\n",
      "275it [00:51,  5.33it/s]Train epoch: 8 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.002404\n",
      "300it [00:55,  5.22it/s]Train epoch: 8 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003197\n",
      "325it [01:00,  5.24it/s]Train epoch: 8 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.002649\n",
      "350it [01:05,  5.24it/s]Train epoch: 8 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.003184\n",
      "375it [01:10,  5.23it/s]Train epoch: 8 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.003026\n",
      "400it [01:14,  5.26it/s]Train epoch: 8 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.003001\n",
      "425it [01:19,  5.20it/s]Train epoch: 8 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.002938\n",
      "450it [01:24,  5.22it/s]Train epoch: 8 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.002794\n",
      "475it [01:29,  5.15it/s]Train epoch: 8 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.003284\n",
      "500it [01:34,  5.15it/s]Train epoch: 8 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.002713\n",
      "525it [01:38,  5.19it/s]Train epoch: 8 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.003002\n",
      "550it [01:43,  5.19it/s]Train epoch: 8 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.002927\n",
      "575it [01:48,  5.18it/s]Train epoch: 8 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.002989\n",
      "600it [01:53,  5.19it/s]Train epoch: 8 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.003172\n",
      "625it [01:58,  5.12it/s]Train epoch: 8 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.003090\n",
      "650it [02:03,  5.19it/s]Train epoch: 8 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.002699\n",
      "675it [02:07,  5.12it/s]Train epoch: 8 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002449\n",
      "700it [02:12,  5.12it/s]Train epoch: 8 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.002812\n",
      "725it [02:17,  5.16it/s]Train epoch: 8 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.003065\n",
      "750it [02:22,  5.15it/s]Train epoch: 8 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.002797\n",
      "775it [02:27,  5.12it/s]Train epoch: 8 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.003185\n",
      "800it [02:32,  5.01it/s]Train epoch: 8 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.003068\n",
      "825it [02:37,  5.13it/s]Train epoch: 8 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.002925\n",
      "850it [02:42,  5.08it/s]Train epoch: 8 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.003391\n",
      "875it [02:46,  5.06it/s]Train epoch: 8 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.002701\n",
      "900it [02:51,  4.96it/s]Train epoch: 8 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.003195\n",
      "925it [02:56,  5.10it/s]Train epoch: 8 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.002804\n",
      "950it [03:01,  5.08it/s]Train epoch: 8 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.002758\n",
      "975it [03:06,  5.10it/s]Train epoch: 8 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002318\n",
      "1000it [03:11,  5.04it/s]Train epoch: 8 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.003067\n",
      "1025it [03:16,  5.10it/s]Train epoch: 8 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.004108\n",
      "1050it [03:21,  5.06it/s]Train epoch: 8 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.002852\n",
      "1075it [03:26,  5.05it/s]Train epoch: 8 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.003107\n",
      "1100it [03:31,  5.01it/s]Train epoch: 8 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.003204\n",
      "1125it [03:36,  5.02it/s]Train epoch: 8 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.003273\n",
      "1150it [03:41,  5.08it/s]Train epoch: 8 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.003303\n",
      "1175it [03:46,  4.96it/s]Train epoch: 8 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.003145\n",
      "1200it [03:51,  5.04it/s]Train epoch: 8 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.003201\n",
      "1225it [03:56,  5.00it/s]Train epoch: 8 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.003415\n",
      "1250it [04:01,  4.98it/s]Train epoch: 8 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003191\n",
      "1275it [04:06,  5.01it/s]Train epoch: 8 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.002751\n",
      "1300it [04:11,  4.98it/s]Train epoch: 8 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.002716\n",
      "1325it [04:16,  5.00it/s]Train epoch: 8 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.002770\n",
      "1350it [04:21,  4.97it/s]Train epoch: 8 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.003732\n",
      "1375it [04:26,  5.01it/s]Train epoch: 8 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.003072\n",
      "1400it [04:31,  5.00it/s]Train epoch: 8 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.003023\n",
      "1425it [04:36,  4.98it/s]Train epoch: 8 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.002752\n",
      "1450it [04:41,  5.03it/s]Train epoch: 8 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.003046\n",
      "1475it [04:46,  5.10it/s]Train epoch: 8 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.003007\n",
      "1500it [04:51,  4.98it/s]Train epoch: 8 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.004209\n",
      "1525it [04:56,  4.96it/s]Train epoch: 8 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.003883\n",
      "1550it [05:01,  4.98it/s]Train epoch: 8 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.002877\n",
      "1575it [05:06,  4.96it/s]Train epoch: 8 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.003283\n",
      "1600it [05:11,  4.95it/s]Train epoch: 8 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.002694\n",
      "1625it [05:16,  4.98it/s]Train epoch: 8 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.003427\n",
      "1650it [05:21,  4.96it/s]Train epoch: 8 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.003400\n",
      "1675it [05:26,  4.95it/s]Train epoch: 8 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.003324\n",
      "1700it [05:31,  4.94it/s]Train epoch: 8 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.002968\n",
      "1725it [05:36,  4.92it/s]Train epoch: 8 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.002553\n",
      "1750it [05:41,  4.93it/s]Train epoch: 8 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.003842\n",
      "1775it [05:46,  4.94it/s]Train epoch: 8 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.003143\n",
      "1800it [05:51,  4.92it/s]Train epoch: 8 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.003049\n",
      "1825it [05:56,  4.93it/s]Train epoch: 8 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.002639\n",
      "1850it [06:01,  4.94it/s]Train epoch: 8 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.003332\n",
      "1875it [06:06,  4.95it/s]Train epoch: 8 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.003457\n",
      "1900it [06:12,  4.94it/s]Train epoch: 8 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.002439\n",
      "1925it [06:17,  4.85it/s]Train epoch: 8 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.002753\n",
      "1950it [06:22,  4.95it/s]Train epoch: 8 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.002666\n",
      "1975it [06:27,  4.89it/s]Train epoch: 8 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.003408\n",
      "2000it [06:32,  4.91it/s]Train epoch: 8 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.002678\n",
      "2025it [06:37,  4.95it/s]Train epoch: 8 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.003286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050it [06:42,  4.88it/s]Train epoch: 8 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.003034\n",
      "2075it [06:47,  4.89it/s]Train epoch: 8 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.003164\n",
      "2100it [06:52,  4.91it/s]Train epoch: 8 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.003261\n",
      "2125it [06:57,  4.87it/s]Train epoch: 8 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.003617\n",
      "2150it [07:02,  4.89it/s]Train epoch: 8 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.003060\n",
      "2175it [07:08,  4.88it/s]Train epoch: 8 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.003447\n",
      "2200it [07:13,  4.87it/s]Train epoch: 8 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.003203\n",
      "2225it [07:18,  4.92it/s]Train epoch: 8 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.003102\n",
      "2250it [07:23,  4.87it/s]Train epoch: 8 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.002760\n",
      "2275it [07:28,  4.81it/s]Train epoch: 8 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.003213\n",
      "2300it [07:33,  4.93it/s]Train epoch: 8 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.002483\n",
      "2325it [07:38,  4.85it/s]Train epoch: 8 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.003060\n",
      "2350it [07:43,  4.82it/s]Train epoch: 8 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.002909\n",
      "2375it [07:49,  4.82it/s]Train epoch: 8 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.004197\n",
      "2400it [07:54,  4.86it/s]Train epoch: 8 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.003773\n",
      "2425it [07:59,  4.88it/s]Train epoch: 8 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.002773\n",
      "2450it [08:04,  4.84it/s]Train epoch: 8 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.003099\n",
      "2475it [08:09,  4.86it/s]Train epoch: 8 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.003528\n",
      "2500it [08:14,  4.79it/s]Train epoch: 8 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.002999\n",
      "2525it [08:20,  4.82it/s]Train epoch: 8 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.002973\n",
      "2550it [08:25,  4.82it/s]Train epoch: 8 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.004073\n",
      "2575it [08:30,  4.80it/s]Train epoch: 8 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.002943\n",
      "2600it [08:35,  4.83it/s]Train epoch: 8 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.003257\n",
      "2625it [08:40,  4.81it/s]Train epoch: 8 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.003202\n",
      "2650it [08:46,  4.80it/s]Train epoch: 8 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.003748\n",
      "2675it [08:51,  4.79it/s]Train epoch: 8 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.003275\n",
      "2700it [08:56,  4.80it/s]Train epoch: 8 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.002940\n",
      "2725it [09:01,  5.06it/s]Train epoch: 8 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.003094\n",
      "2750it [09:06,  5.05it/s]Train epoch: 8 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.003674\n",
      "2775it [09:11,  4.99it/s]Train epoch: 8 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.003223\n",
      "2800it [09:16,  5.01it/s]Train epoch: 8 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.002969\n",
      "2825it [09:21,  5.02it/s]Train epoch: 8 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.003381\n",
      "2850it [09:26,  5.02it/s]Train epoch: 8 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.003179\n",
      "2875it [09:31,  4.95it/s]Train epoch: 8 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.003452\n",
      "2900it [09:36,  5.01it/s]Train epoch: 8 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.003411\n",
      "2925it [09:41,  5.02it/s]Train epoch: 8 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.003455\n",
      "2950it [09:46,  5.03it/s]Train epoch: 8 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.003687\n",
      "2975it [09:51,  5.01it/s]Train epoch: 8 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.003353\n",
      "3000it [09:56,  5.00it/s]Train epoch: 8 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.003879\n",
      "3025it [10:01,  5.00it/s]Train epoch: 8 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.003428\n",
      "3050it [10:06,  5.00it/s]Train epoch: 8 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.003087\n",
      "3075it [10:11,  4.99it/s]Train epoch: 8 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.003599\n",
      "3100it [10:16,  4.99it/s]Train epoch: 8 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.003551\n",
      "3125it [10:21,  4.99it/s]Train epoch: 8 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.003187\n",
      "3150it [10:26,  4.98it/s]Train epoch: 8 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.003164\n",
      "3175it [10:31,  4.99it/s]Train epoch: 8 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.003161\n",
      "3200it [10:36,  4.99it/s]Train epoch: 8 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.003771\n",
      "3225it [10:41,  4.96it/s]Train epoch: 8 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.003582\n",
      "3250it [10:46,  4.98it/s]Train epoch: 8 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.003519\n",
      "3275it [10:51,  4.99it/s]Train epoch: 8 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.003184\n",
      "3300it [10:56,  4.98it/s]Train epoch: 8 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.003998\n",
      "3325it [11:01,  4.93it/s]Train epoch: 8 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.003490\n",
      "3350it [11:06,  4.91it/s]Train epoch: 8 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.003523\n",
      "3375it [11:11,  4.95it/s]Train epoch: 8 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.003725\n",
      "3400it [11:16,  4.95it/s]Train epoch: 8 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.003697\n",
      "3425it [11:21,  4.94it/s]Train epoch: 8 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.003220\n",
      "3450it [11:27,  4.96it/s]Train epoch: 8 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.003679\n",
      "3475it [11:32,  4.95it/s]Train epoch: 8 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.003180\n",
      "3500it [11:37,  4.96it/s]Train epoch: 8 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.003481\n",
      "3525it [11:42,  4.94it/s]Train epoch: 8 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.003546\n",
      "3550it [11:47,  4.93it/s]Train epoch: 8 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.003690\n",
      "3575it [11:52,  4.94it/s]Train epoch: 8 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.003051\n",
      "3600it [11:57,  4.93it/s]Train epoch: 8 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.003880\n",
      "3625it [12:02,  4.93it/s]Train epoch: 8 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.003509\n",
      "3650it [12:07,  4.92it/s]Train epoch: 8 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.003714\n",
      "3675it [12:12,  4.92it/s]Train epoch: 8 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.003766\n",
      "3700it [12:17,  4.93it/s]Train epoch: 8 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.003566\n",
      "3725it [12:22,  4.92it/s]Train epoch: 8 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.003662\n",
      "3750it [12:27,  4.89it/s]Train epoch: 8 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.003769\n",
      "3775it [12:33,  4.92it/s]Train epoch: 8 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.003442\n",
      "3800it [12:38,  4.90it/s]Train epoch: 8 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.004006\n",
      "3825it [12:43,  4.87it/s]Train epoch: 8 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.003328\n",
      "3850it [12:48,  4.89it/s]Train epoch: 8 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.003034\n",
      "3875it [12:53,  4.87it/s]Train epoch: 8 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.003098\n",
      "3900it [12:58,  4.91it/s]Train epoch: 8 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.004031\n",
      "3925it [13:03,  4.90it/s]Train epoch: 8 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.003658\n",
      "3950it [13:08,  4.87it/s]Train epoch: 8 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.004031\n",
      "3975it [13:14,  4.86it/s]Train epoch: 8 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.004476\n",
      "4000it [13:19,  4.87it/s]Train epoch: 8 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.003183\n",
      "4025it [13:24,  4.86it/s]Train epoch: 8 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.004141\n",
      "4050it [13:29,  4.82it/s]Train epoch: 8 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.003768\n",
      "4075it [13:34,  4.87it/s]Train epoch: 8 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.003724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100it [13:39,  4.87it/s]Train epoch: 8 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.004097\n",
      "4125it [13:44,  4.86it/s]Train epoch: 8 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.003924\n",
      "4150it [13:50,  4.87it/s]Train epoch: 8 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.003448\n",
      "4175it [13:55,  4.86it/s]Train epoch: 8 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.003538\n",
      "4200it [14:00,  4.84it/s]Train epoch: 8 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.003945\n",
      "4225it [14:05,  4.85it/s]Train epoch: 8 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.003380\n",
      "4250it [14:10,  4.76it/s]Train epoch: 8 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.003769\n",
      "4275it [14:15,  4.79it/s]Train epoch: 8 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.003549\n",
      "4300it [14:21,  4.83it/s]Train epoch: 8 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.004189\n",
      "4325it [14:26,  4.76it/s]Train epoch: 8 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.003696\n",
      "4350it [14:31,  4.85it/s]Train epoch: 8 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.004037\n",
      "4375it [14:36,  4.75it/s]Train epoch: 8 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.003571\n",
      "4400it [14:41,  4.84it/s]Train epoch: 8 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.003103\n",
      "4425it [14:46,  4.84it/s]Train epoch: 8 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.003828\n",
      "4450it [14:52,  4.74it/s]Train epoch: 8 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.003114\n",
      "4475it [14:57,  4.82it/s]Train epoch: 8 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.003769\n",
      "4500it [15:02,  4.83it/s]Train epoch: 8 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.004501\n",
      "4525it [15:07,  4.77it/s]Train epoch: 8 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.003697\n",
      "4550it [15:12,  4.82it/s]Train epoch: 8 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.003697\n",
      "4575it [15:18,  4.81it/s]Train epoch: 8 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.004028\n",
      "4600it [15:23,  4.77it/s]Train epoch: 8 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.003336\n",
      "4625it [15:28,  4.80it/s]Train epoch: 8 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.003556\n",
      "4650it [15:33,  4.80it/s]Train epoch: 8 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.004086\n",
      "4675it [15:39,  4.81it/s]Train epoch: 8 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.003950\n",
      "4700it [15:44,  4.79it/s]Train epoch: 8 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.003429\n",
      "4725it [15:49,  4.80it/s]Train epoch: 8 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.003621\n",
      "4750it [15:54,  4.79it/s]Train epoch: 8 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.004386\n",
      "4775it [15:59,  4.77it/s]Train epoch: 8 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.003793\n",
      "4800it [16:05,  4.76it/s]Train epoch: 8 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.003877\n",
      "4825it [16:10,  4.69it/s]Train epoch: 8 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.003514\n",
      "4850it [16:15,  4.77it/s]Train epoch: 8 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.004089\n",
      "4875it [16:20,  4.79it/s]Train epoch: 8 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.003580\n",
      "4900it [16:26,  4.72it/s]Train epoch: 8 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.003684\n",
      "4925it [16:31,  4.76it/s]Train epoch: 8 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.003467\n",
      "4950it [16:36,  4.76it/s]Train epoch: 8 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.003685\n",
      "4975it [16:42,  4.76it/s]Train epoch: 8 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.003695\n",
      "5000it [16:47,  4.66it/s]Train epoch: 8 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.003784\n",
      "5025it [16:52,  4.73it/s]Train epoch: 8 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.003522\n",
      "5050it [16:57,  4.78it/s]Train epoch: 8 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.003519\n",
      "5075it [17:03,  4.74it/s]Train epoch: 8 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.003823\n",
      "5100it [17:08,  4.76it/s]Train epoch: 8 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.003846\n",
      "5125it [17:13,  4.73it/s]Train epoch: 8 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.004028\n",
      "5150it [17:18,  4.73it/s]Train epoch: 8 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.003925\n",
      "5175it [17:24,  4.73it/s]Train epoch: 8 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.003773\n",
      "5200it [17:29,  4.72it/s]Train epoch: 8 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.003582\n",
      "5225it [17:34,  4.74it/s]Train epoch: 8 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.003777\n",
      "5250it [17:40,  4.72it/s]Train epoch: 8 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.003827\n",
      "5275it [17:45,  4.72it/s]Train epoch: 8 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.003639\n",
      "5300it [17:50,  4.71it/s]Train epoch: 8 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.003425\n",
      "5325it [17:56,  4.69it/s]Train epoch: 8 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.004088\n",
      "5350it [18:01,  4.71it/s]Train epoch: 8 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.004103\n",
      "5375it [18:06,  4.72it/s]Train epoch: 8 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.003598\n",
      "5400it [18:11,  4.72it/s]Train epoch: 8 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.003666\n",
      "5425it [18:17,  4.71it/s]Train epoch: 8 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.003985\n",
      "5450it [18:22,  4.70it/s]Train epoch: 8 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.003881\n",
      "5475it [18:27,  4.69it/s]Train epoch: 8 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.004519\n",
      "5500it [18:33,  4.69it/s]Train epoch: 8 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.004118\n",
      "5525it [18:38,  4.61it/s]Train epoch: 8 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.003483\n",
      "5550it [18:44,  4.69it/s]Train epoch: 8 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.003947\n",
      "5575it [18:49,  4.68it/s]Train epoch: 8 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.003958\n",
      "5600it [18:54,  4.69it/s]Train epoch: 8 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.004245\n",
      "5625it [19:00,  4.68it/s]Train epoch: 8 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.003907\n",
      "5650it [19:05,  4.67it/s]Train epoch: 8 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.003488\n",
      "5675it [19:10,  4.61it/s]Train epoch: 8 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.004387\n",
      "5700it [19:16,  4.68it/s]Train epoch: 8 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.003798\n",
      "5725it [19:21,  4.63it/s]Train epoch: 8 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.003916\n",
      "5750it [19:26,  4.63it/s]Train epoch: 8 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.005102\n",
      "5775it [19:32,  4.66it/s]Train epoch: 8 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.004064\n",
      "5800it [19:37,  4.65it/s]Train epoch: 8 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.004215\n",
      "5825it [19:42,  4.66it/s]Train epoch: 8 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.003673\n",
      "5850it [19:48,  4.59it/s]Train epoch: 8 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.004758\n",
      "5875it [19:53,  4.64it/s]Train epoch: 8 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.004420\n",
      "5900it [19:59,  4.66it/s]Train epoch: 8 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.004317\n",
      "5925it [20:04,  4.60it/s]Train epoch: 8 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.003797\n",
      "5950it [20:09,  4.65it/s]Train epoch: 8 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.003619\n",
      "5975it [20:15,  4.64it/s]Train epoch: 8 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.005026\n",
      "6000it [20:20,  4.64it/s]Train epoch: 8 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.004285\n",
      "6025it [20:26,  4.61it/s]Train epoch: 8 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.004488\n",
      "6050it [20:31,  4.63it/s]Train epoch: 8 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.003949\n",
      "6075it [20:36,  4.63it/s]Train epoch: 8 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.003690\n",
      "6100it [20:42,  4.61it/s]Train epoch: 8 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.003556\n",
      "6125it [20:47,  4.61it/s]Train epoch: 8 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.004060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6150it [20:53,  4.57it/s]Train epoch: 8 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.004081\n",
      "6175it [20:58,  4.62it/s]Train epoch: 8 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.004526\n",
      "6200it [21:04,  4.60it/s]Train epoch: 8 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.004080\n",
      "6225it [21:09,  4.61it/s]Train epoch: 8 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.003438\n",
      "6250it [21:14,  4.61it/s]Train epoch: 8 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.003688\n",
      "6275it [21:20,  4.54it/s]Train epoch: 8 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.003396\n",
      "6300it [21:25,  4.61it/s]Train epoch: 8 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.003960\n",
      "6325it [21:31,  4.59it/s]Train epoch: 8 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.004448\n",
      "6350it [21:36,  4.59it/s]Train epoch: 8 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.004579\n",
      "6375it [21:42,  4.60it/s]Train epoch: 8 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.003474\n",
      "6400it [21:47,  4.59it/s]Train epoch: 8 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.003954\n",
      "6425it [21:53,  4.58it/s]Train epoch: 8 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.004335\n",
      "6450it [21:58,  4.59it/s]Train epoch: 8 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.004359\n",
      "6475it [22:04,  4.57it/s]Train epoch: 8 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.003858\n",
      "6500it [22:09,  4.57it/s]Train epoch: 8 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.004486\n",
      "6525it [22:14,  4.57it/s]Train epoch: 8 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.003749\n",
      "6550it [22:20,  4.57it/s]Train epoch: 8 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.003877\n",
      "6575it [22:25,  4.57it/s]Train epoch: 8 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.004026\n",
      "6600it [22:31,  4.57it/s]Train epoch: 8 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.004815\n",
      "6625it [22:36,  4.56it/s]Train epoch: 8 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.003909\n",
      "6650it [22:42,  4.55it/s]Train epoch: 8 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.004566\n",
      "6675it [22:47,  4.55it/s]Train epoch: 8 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.004078\n",
      "6700it [22:53,  4.54it/s]Train epoch: 8 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.004265\n",
      "6725it [22:58,  4.54it/s]Train epoch: 8 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.004239\n",
      "6750it [23:04,  4.51it/s]Train epoch: 8 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.003825\n",
      "6775it [23:09,  4.51it/s]Train epoch: 8 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.004566\n",
      "6800it [23:15,  4.53it/s]Train epoch: 8 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.004534\n",
      "6825it [23:20,  4.55it/s]Train epoch: 8 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.004463\n",
      "6850it [23:26,  4.53it/s]Train epoch: 8 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.004323\n",
      "6875it [23:32,  4.52it/s]Train epoch: 8 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.003458\n",
      "6900it [23:37,  4.52it/s]Train epoch: 8 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.004128\n",
      "6925it [23:43,  4.52it/s]Train epoch: 8 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.004212\n",
      "6950it [23:48,  4.52it/s]Train epoch: 8 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.004673\n",
      "6975it [23:54,  4.51it/s]Train epoch: 8 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.004350\n",
      "7000it [23:59,  4.51it/s]Train epoch: 8 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.004060\n",
      "7025it [24:05,  4.51it/s]Train epoch: 8 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.004797\n",
      "7050it [24:10,  4.51it/s]Train epoch: 8 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.003698\n",
      "7075it [24:16,  4.50it/s]Train epoch: 8 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.004251\n",
      "7100it [24:21,  4.48it/s]Train epoch: 8 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.004278\n",
      "7125it [24:27,  4.50it/s]Train epoch: 8 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.003815\n",
      "7150it [24:33,  4.49it/s]Train epoch: 8 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.004751\n",
      "7175it [24:38,  4.48it/s]Train epoch: 8 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.004328\n",
      "7200it [24:44,  4.46it/s]Train epoch: 8 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.004691\n",
      "7225it [24:49,  4.48it/s]Train epoch: 8 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.004148\n",
      "7250it [24:55,  4.47it/s]Train epoch: 8 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.004056\n",
      "7275it [25:01,  4.48it/s]Train epoch: 8 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.004747\n",
      "7300it [25:06,  4.47it/s]Train epoch: 8 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.005014\n",
      "7325it [25:12,  4.46it/s]Train epoch: 8 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.003946\n",
      "7350it [25:17,  4.46it/s]Train epoch: 8 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.004908\n",
      "7375it [25:23,  4.46it/s]Train epoch: 8 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.004475\n",
      "7400it [25:29,  4.45it/s]Train epoch: 8 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.004122\n",
      "7425it [25:34,  4.45it/s]Train epoch: 8 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.004498\n",
      "7450it [25:40,  4.46it/s]Train epoch: 8 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.004937\n",
      "7475it [25:45,  4.44it/s]Train epoch: 8 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.004279\n",
      "7500it [25:51,  4.42it/s]Train epoch: 8 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.004497\n",
      "7525it [25:57,  4.44it/s]Train epoch: 8 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.004341\n",
      "7550it [26:02,  4.42it/s]Train epoch: 8 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.004202\n",
      "7575it [26:08,  4.44it/s]Train epoch: 8 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.004532\n",
      "7600it [26:14,  4.40it/s]Train epoch: 8 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.005478\n",
      "7625it [26:19,  4.43it/s]Train epoch: 8 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.005196\n",
      "7650it [26:25,  4.37it/s]Train epoch: 8 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.004289\n",
      "7675it [26:31,  4.42it/s]Train epoch: 8 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.004127\n",
      "7700it [26:36,  4.41it/s]Train epoch: 8 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.004374\n",
      "7725it [26:42,  4.35it/s]Train epoch: 8 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.004461\n",
      "7750it [26:48,  4.38it/s]Train epoch: 8 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.004737\n",
      "7775it [26:53,  4.41it/s]Train epoch: 8 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.004147\n",
      "7800it [26:59,  4.39it/s]Train epoch: 8 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.004336\n",
      "7825it [27:05,  4.40it/s]Train epoch: 8 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.004652\n",
      "7850it [27:10,  4.41it/s]Train epoch: 8 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.004107\n",
      "7875it [27:16,  4.40it/s]Train epoch: 8 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.004283\n",
      "7900it [27:22,  4.40it/s]Train epoch: 8 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.004555\n",
      "7925it [27:27,  4.35it/s]Train epoch: 8 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.004525\n",
      "7950it [27:33,  4.39it/s]Train epoch: 8 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.005002\n",
      "7975it [27:39,  4.37it/s]Train epoch: 8 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.004227\n",
      "8000it [27:45,  4.38it/s]Train epoch: 8 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.004195\n",
      "8025it [27:50,  4.38it/s]Train epoch: 8 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.004575\n",
      "8050it [27:56,  4.38it/s]Train epoch: 8 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.003878\n",
      "8075it [28:02,  4.37it/s]Train epoch: 8 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.004492\n",
      "8100it [28:08,  4.38it/s]Train epoch: 8 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.004761\n",
      "8125it [28:13,  4.36it/s]Train epoch: 8 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.004850\n",
      "8150it [28:19,  4.36it/s]Train epoch: 8 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.004193\n",
      "8175it [28:25,  4.35it/s]Train epoch: 8 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.004825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200it [28:30,  4.36it/s]Train epoch: 8 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.004072\n",
      "8225it [28:36,  4.35it/s]Train epoch: 8 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.005537\n",
      "8250it [28:42,  4.27it/s]Train epoch: 8 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.004269\n",
      "8275it [28:48,  4.33it/s]Train epoch: 8 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.004978\n",
      "8300it [28:54,  4.34it/s]Train epoch: 8 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.004146\n",
      "8325it [28:59,  4.33it/s]Train epoch: 8 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.004727\n",
      "8350it [29:05,  4.32it/s]Train epoch: 8 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.004242\n",
      "8375it [29:11,  4.29it/s]Train epoch: 8 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.004738\n",
      "8400it [29:17,  4.31it/s]Train epoch: 8 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.004497\n",
      "8425it [29:23,  4.31it/s]Train epoch: 8 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.004459\n",
      "8450it [29:28,  4.31it/s]Train epoch: 8 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.004823\n",
      "8475it [29:34,  4.31it/s]Train epoch: 8 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.004516\n",
      "8500it [29:40,  4.31it/s]Train epoch: 8 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.005323\n",
      "8525it [29:46,  4.30it/s]Train epoch: 8 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.004428\n",
      "8550it [29:52,  4.32it/s]Train epoch: 8 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.004808\n",
      "8575it [29:57,  4.31it/s]Train epoch: 8 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.004436\n",
      "8600it [30:03,  4.31it/s]Train epoch: 8 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.004540\n",
      "8625it [30:09,  4.27it/s]Train epoch: 8 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.004665\n",
      "8650it [30:15,  4.28it/s]Train epoch: 8 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.004830\n",
      "8675it [30:21,  4.28it/s]Train epoch: 8 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.005367\n",
      "8700it [30:27,  4.25it/s]Train epoch: 8 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.005448\n",
      "8725it [30:33,  4.27it/s]Train epoch: 8 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.005227\n",
      "8750it [30:38,  4.23it/s]Train epoch: 8 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.004917\n",
      "8775it [30:44,  4.26it/s]Train epoch: 8 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.004467\n",
      "8800it [30:50,  4.26it/s]Train epoch: 8 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.004645\n",
      "8825it [30:56,  4.25it/s]Train epoch: 8 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.004711\n",
      "8850it [31:02,  4.26it/s]Train epoch: 8 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.004976\n",
      "8875it [31:08,  4.23it/s]Train epoch: 8 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.004777\n",
      "8900it [31:14,  4.24it/s]Train epoch: 8 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.004731\n",
      "8925it [31:20,  4.24it/s]Train epoch: 8 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.005001\n",
      "8950it [31:26,  4.23it/s]Train epoch: 8 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.005517\n",
      "8975it [31:31,  4.24it/s]Train epoch: 8 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.005052\n",
      "9000it [31:37,  4.21it/s]Train epoch: 8 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.004810\n",
      "9025it [31:43,  4.19it/s]Train epoch: 8 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.004887\n",
      "9050it [31:49,  4.21it/s]Train epoch: 8 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.004426\n",
      "9075it [31:55,  4.21it/s]Train epoch: 8 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.004220\n",
      "9100it [32:01,  4.22it/s]Train epoch: 8 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.005010\n",
      "9125it [32:07,  4.20it/s]Train epoch: 8 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.004460\n",
      "9150it [32:13,  4.21it/s]Train epoch: 8 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.004255\n",
      "9175it [32:19,  4.20it/s]Train epoch: 8 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.004620\n",
      "9200it [32:25,  4.21it/s]Train epoch: 8 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.004568\n",
      "9225it [32:31,  4.19it/s]Train epoch: 8 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.005327\n",
      "9250it [32:37,  4.20it/s]Train epoch: 8 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.004747\n",
      "9275it [32:43,  4.16it/s]Train epoch: 8 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.005064\n",
      "9300it [32:49,  4.17it/s]Train epoch: 8 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.005803\n",
      "9325it [32:55,  4.18it/s]Train epoch: 8 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.005449\n",
      "9350it [33:01,  4.16it/s]Train epoch: 8 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.005277\n",
      "9375it [33:07,  4.15it/s]Train epoch: 8 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.004619\n",
      "9400it [33:13,  4.16it/s]Train epoch: 8 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.005033\n",
      "9425it [33:19,  4.11it/s]Train epoch: 8 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.004830\n",
      "9450it [33:25,  4.14it/s]Train epoch: 8 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.004658\n",
      "9475it [33:31,  4.12it/s]Train epoch: 8 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.005390\n",
      "9500it [33:37,  4.12it/s]Train epoch: 8 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.005016\n",
      "9525it [33:43,  4.14it/s]Train epoch: 8 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.005594\n",
      "9550it [33:49,  4.12it/s]Train epoch: 8 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.005228\n",
      "9575it [33:55,  4.13it/s]Train epoch: 8 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.005298\n",
      "9600it [34:01,  4.11it/s]Train epoch: 8 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.005209\n",
      "9625it [34:07,  4.12it/s]Train epoch: 8 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.004784\n",
      "9650it [34:14,  4.11it/s]Train epoch: 8 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.004675\n",
      "9675it [34:20,  4.09it/s]Train epoch: 8 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.005268\n",
      "9700it [34:26,  4.04it/s]Train epoch: 8 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.004560\n",
      "9725it [34:32,  4.09it/s]Train epoch: 8 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.005034\n",
      "9750it [34:38,  4.09it/s]Train epoch: 8 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.005171\n",
      "9775it [34:44,  4.08it/s]Train epoch: 8 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.005712\n",
      "9800it [34:50,  4.07it/s]Train epoch: 8 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.005438\n",
      "9825it [34:56,  4.04it/s]Train epoch: 8 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.005420\n",
      "9850it [35:03,  4.07it/s]Train epoch: 8 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.005104\n",
      "9875it [35:09,  4.07it/s]Train epoch: 8 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.005435\n",
      "9900it [35:15,  4.06it/s]Train epoch: 8 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.005922\n",
      "9925it [35:21,  4.04it/s]Train epoch: 8 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.005527\n",
      "9950it [35:27,  4.04it/s]Train epoch: 8 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.006052\n",
      "9975it [35:33,  4.03it/s]Train epoch: 8 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.005405\n",
      "10000it [35:40,  4.04it/s]Train epoch: 8 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.005196\n",
      "10025it [35:46,  4.02it/s]Train epoch: 8 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.005142\n",
      "10050it [35:52,  4.02it/s]Train epoch: 8 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.005459\n",
      "10075it [35:58,  4.02it/s]Train epoch: 8 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.005956\n",
      "10100it [36:05,  4.01it/s]Train epoch: 8 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.005654\n",
      "10125it [36:11,  4.00it/s]Train epoch: 8 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.004993\n",
      "10150it [36:17,  3.99it/s]Train epoch: 8 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.005569\n",
      "10175it [36:23,  3.98it/s]Train epoch: 8 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.005224\n",
      "10200it [36:30,  3.98it/s]Train epoch: 8 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.005710\n",
      "10225it [36:36,  3.99it/s]Train epoch: 8 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.005551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10250it [36:42,  3.97it/s]Train epoch: 8 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.006052\n",
      "10275it [36:48,  3.97it/s]Train epoch: 8 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.005315\n",
      "10300it [36:55,  3.97it/s]Train epoch: 8 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.005869\n",
      "10325it [37:01,  3.96it/s]Train epoch: 8 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.005891\n",
      "10350it [37:07,  3.96it/s]Train epoch: 8 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.005370\n",
      "10375it [37:14,  3.91it/s]Train epoch: 8 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.005763\n",
      "10400it [37:20,  3.95it/s]Train epoch: 8 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.005656\n",
      "10425it [37:27,  3.90it/s]Train epoch: 8 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.005353\n",
      "10450it [37:33,  3.94it/s]Train epoch: 8 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.005637\n",
      "10475it [37:39,  3.91it/s]Train epoch: 8 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.004870\n",
      "10500it [37:46,  3.90it/s]Train epoch: 8 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.005722\n",
      "10525it [37:52,  3.91it/s]Train epoch: 8 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.005472\n",
      "10550it [37:59,  3.90it/s]Train epoch: 8 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.005663\n",
      "10575it [38:05,  3.89it/s]Train epoch: 8 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.004959\n",
      "10600it [38:11,  3.90it/s]Train epoch: 8 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.005182\n",
      "10625it [38:18,  3.85it/s]Train epoch: 8 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.005943\n",
      "10650it [38:24,  3.89it/s]Train epoch: 8 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.005447\n",
      "10675it [38:31,  3.85it/s]Train epoch: 8 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.005883\n",
      "10700it [38:37,  3.86it/s]Train epoch: 8 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.005524\n",
      "10725it [38:44,  3.84it/s]Train epoch: 8 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.005083\n",
      "10750it [38:50,  3.80it/s]Train epoch: 8 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.005830\n",
      "10775it [38:57,  3.83it/s]Train epoch: 8 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.005827\n",
      "10800it [39:03,  3.83it/s]Train epoch: 8 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.006126\n",
      "10825it [39:10,  3.82it/s]Train epoch: 8 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.005976\n",
      "10850it [39:16,  3.81it/s]Train epoch: 8 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006096\n",
      "10875it [39:23,  3.78it/s]Train epoch: 8 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006068\n",
      "10900it [39:30,  3.80it/s]Train epoch: 8 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.005889\n",
      "10925it [39:36,  3.80it/s]Train epoch: 8 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005288\n",
      "10950it [39:43,  3.78it/s]Train epoch: 8 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.005763\n",
      "10975it [39:49,  3.77it/s]Train epoch: 8 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.005541\n",
      "11000it [39:56,  3.75it/s]Train epoch: 8 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.005633\n",
      "11025it [40:03,  3.76it/s]Train epoch: 8 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.005736\n",
      "11050it [40:09,  3.73it/s]Train epoch: 8 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.006474\n",
      "11075it [40:16,  3.75it/s]Train epoch: 8 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.005934\n",
      "11100it [40:23,  3.72it/s]Train epoch: 8 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.006482\n",
      "11125it [40:30,  3.72it/s]Train epoch: 8 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006131\n",
      "11150it [40:36,  3.68it/s]Train epoch: 8 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.005855\n",
      "11175it [40:43,  3.67it/s]Train epoch: 8 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.006836\n",
      "11200it [40:50,  3.67it/s]Train epoch: 8 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006267\n",
      "11225it [40:57,  3.66it/s]Train epoch: 8 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006094\n",
      "11250it [41:04,  3.62it/s]Train epoch: 8 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.006820\n",
      "11275it [41:10,  3.64it/s]Train epoch: 8 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.006445\n",
      "11300it [41:17,  3.63it/s]Train epoch: 8 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.005922\n",
      "11325it [41:24,  3.61it/s]Train epoch: 8 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007103\n",
      "11350it [41:31,  3.58it/s]Train epoch: 8 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.006809\n",
      "11375it [41:38,  3.58it/s]Train epoch: 8 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007045\n",
      "11400it [41:45,  3.55it/s]Train epoch: 8 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006280\n",
      "11425it [41:52,  3.55it/s]Train epoch: 8 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.006799\n",
      "11450it [41:59,  3.54it/s]Train epoch: 8 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006136\n",
      "11475it [42:06,  3.52it/s]Train epoch: 8 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007269\n",
      "11500it [42:14,  3.50it/s]Train epoch: 8 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007002\n",
      "11525it [42:21,  3.47it/s]Train epoch: 8 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006361\n",
      "11550it [42:28,  3.46it/s]Train epoch: 8 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.006206\n",
      "11575it [42:35,  3.43it/s]Train epoch: 8 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007480\n",
      "11600it [42:43,  3.41it/s]Train epoch: 8 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.006815\n",
      "11625it [42:50,  3.37it/s]Train epoch: 8 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006368\n",
      "11650it [42:57,  3.38it/s]Train epoch: 8 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.006900\n",
      "11675it [43:05,  3.33it/s]Train epoch: 8 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007241\n",
      "11700it [43:12,  3.31it/s]Train epoch: 8 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.007781\n",
      "11725it [43:20,  3.25it/s]Train epoch: 8 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.007890\n",
      "11750it [43:28,  3.19it/s]Train epoch: 8 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.007522\n",
      "11775it [43:36,  3.19it/s]Train epoch: 8 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.007418\n",
      "11800it [43:43,  3.13it/s]Train epoch: 8 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007381\n",
      "11825it [43:52,  3.07it/s]Train epoch: 8 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.007556\n",
      "11850it [44:00,  3.00it/s]Train epoch: 8 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.007752\n",
      "11875it [44:08,  2.89it/s]Train epoch: 8 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.008733\n",
      "11900it [44:17,  2.71it/s]Train epoch: 8 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.010410\n",
      "11925it [44:27,  2.38it/s]Train epoch: 8 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.008899\n",
      "11930it [44:29,  4.47it/s]\n",
      "epoch loss: 0.004309762754299571\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.66it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0325, 0.0480, 0.0549, 0.0512, 0.8813\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3129, 0.5072, 0.4496, 0.4767, 0.9805\n",
      "rec_at_8: 0.3365\n",
      "prec_at_8: 0.6237\n",
      "rec_at_15: 0.4706\n",
      "prec_at_15: 0.4870\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:50, 30.63it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0348, 0.0530, 0.0590, 0.0559, 0.8735\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3061, 0.5018, 0.4399, 0.4688, 0.9800\n",
      "rec_at_8: 0.3221\n",
      "prec_at_8: 0.6197\n",
      "rec_at_15: 0.4555\n",
      "prec_at_15: 0.4874\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0315, 0.0469, 0.0521, 0.0493, 0.8825\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3135, 0.5164, 0.4438, 0.4774, 0.9806\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0331, 0.0517, 0.0560, 0.0538, 0.8750\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3057, 0.5091, 0.4335, 0.4682, 0.9801\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Train epoch: 9 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.005355\n",
      "25it [00:04,  5.73it/s]Train epoch: 9 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.003865\n",
      "50it [00:08,  5.67it/s]Train epoch: 9 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.003494\n",
      "75it [00:12,  5.71it/s]Train epoch: 9 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.002905\n",
      "100it [00:17,  5.55it/s]Train epoch: 9 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.002989\n",
      "125it [00:21,  5.64it/s]Train epoch: 9 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.002937\n",
      "150it [00:26,  5.61it/s]Train epoch: 9 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.002788\n",
      "175it [00:30,  5.64it/s]Train epoch: 9 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.003029\n",
      "200it [00:35,  5.58it/s]Train epoch: 9 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.002711\n",
      "225it [00:39,  5.61it/s]Train epoch: 9 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.003449\n",
      "250it [00:44,  5.56it/s]Train epoch: 9 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.002642\n",
      "275it [00:48,  5.55it/s]Train epoch: 9 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.002395\n",
      "300it [00:52,  5.55it/s]Train epoch: 9 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003131\n",
      "325it [00:57,  5.49it/s]Train epoch: 9 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.002592\n",
      "350it [01:02,  5.53it/s]Train epoch: 9 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.003076\n",
      "375it [01:06,  5.52it/s]Train epoch: 9 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.002939\n",
      "400it [01:11,  5.41it/s]Train epoch: 9 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.002927\n",
      "425it [01:15,  5.50it/s]Train epoch: 9 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.002850\n",
      "450it [01:20,  5.50it/s]Train epoch: 9 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.002752\n",
      "475it [01:24,  5.49it/s]Train epoch: 9 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.003247\n",
      "500it [01:29,  5.42it/s]Train epoch: 9 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.002654\n",
      "525it [01:33,  5.46it/s]Train epoch: 9 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.002951\n",
      "550it [01:38,  5.45it/s]Train epoch: 9 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.002863\n",
      "575it [01:43,  5.45it/s]Train epoch: 9 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.002917\n",
      "600it [01:47,  5.37it/s]Train epoch: 9 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.003108\n",
      "625it [01:52,  5.43it/s]Train epoch: 9 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.003008\n",
      "650it [01:57,  5.42it/s]Train epoch: 9 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.002656\n",
      "675it [02:01,  5.36it/s]Train epoch: 9 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002352\n",
      "700it [02:06,  5.40it/s]Train epoch: 9 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.002757\n",
      "725it [02:10,  5.36it/s]Train epoch: 9 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.002982\n",
      "750it [02:15,  5.34it/s]Train epoch: 9 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.002754\n",
      "775it [02:20,  5.39it/s]Train epoch: 9 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.003095\n",
      "800it [02:24,  5.38it/s]Train epoch: 9 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.003016\n",
      "825it [02:29,  5.38it/s]Train epoch: 9 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.002927\n",
      "850it [02:34,  5.37it/s]Train epoch: 9 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.003344\n",
      "875it [02:38,  5.35it/s]Train epoch: 9 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.002651\n",
      "900it [02:43,  5.36it/s]Train epoch: 9 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.003086\n",
      "925it [02:48,  5.35it/s]Train epoch: 9 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.002725\n",
      "950it [02:52,  5.34it/s]Train epoch: 9 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.002689\n",
      "975it [02:57,  5.35it/s]Train epoch: 9 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002188\n",
      "1000it [03:02,  5.34it/s]Train epoch: 9 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.003041\n",
      "1025it [03:07,  5.31it/s]Train epoch: 9 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.004085\n",
      "1050it [03:11,  5.31it/s]Train epoch: 9 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.002702\n",
      "1075it [03:16,  5.27it/s]Train epoch: 9 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.003086\n",
      "1100it [03:21,  5.31it/s]Train epoch: 9 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.003104\n",
      "1125it [03:25,  5.30it/s]Train epoch: 9 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.003184\n",
      "1150it [03:30,  5.24it/s]Train epoch: 9 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.003195\n",
      "1175it [03:35,  5.30it/s]Train epoch: 9 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.003022\n",
      "1200it [03:40,  5.29it/s]Train epoch: 9 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.003148\n",
      "1225it [03:44,  5.25it/s]Train epoch: 9 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.003245\n",
      "1250it [03:49,  5.27it/s]Train epoch: 9 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003141\n",
      "1275it [03:54,  5.27it/s]Train epoch: 9 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.002655\n",
      "1300it [03:59,  5.29it/s]Train epoch: 9 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.002707\n",
      "1325it [04:03,  5.27it/s]Train epoch: 9 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.002711\n",
      "1350it [04:08,  5.26it/s]Train epoch: 9 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.003585\n",
      "1375it [04:13,  5.24it/s]Train epoch: 9 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.002969\n",
      "1400it [04:18,  5.04it/s]Train epoch: 9 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.002980\n",
      "1425it [04:23,  5.25it/s]Train epoch: 9 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.002695\n",
      "1450it [04:27,  5.24it/s]Train epoch: 9 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.002969\n",
      "1475it [04:32,  5.22it/s]Train epoch: 9 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.002993\n",
      "1500it [04:37,  5.25it/s]Train epoch: 9 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.004113\n",
      "1525it [04:42,  5.20it/s]Train epoch: 9 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.003809\n",
      "1550it [04:47,  5.22it/s]Train epoch: 9 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.002807\n",
      "1575it [04:51,  5.22it/s]Train epoch: 9 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.003172\n",
      "1600it [04:56,  5.16it/s]Train epoch: 9 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.002665\n",
      "1625it [05:01,  5.17it/s]Train epoch: 9 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.003310\n",
      "1650it [05:06,  5.12it/s]Train epoch: 9 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.003304\n",
      "1675it [05:11,  5.21it/s]Train epoch: 9 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.003260\n",
      "1700it [05:16,  5.19it/s]Train epoch: 9 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.002787\n",
      "1725it [05:20,  5.04it/s]Train epoch: 9 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.002485\n",
      "1750it [05:25,  5.16it/s]Train epoch: 9 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.003708\n",
      "1775it [05:30,  5.08it/s]Train epoch: 9 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.003133\n",
      "1800it [05:35,  5.18it/s]Train epoch: 9 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.002946\n",
      "1825it [05:40,  5.18it/s]Train epoch: 9 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.002519\n",
      "1850it [05:45,  5.17it/s]Train epoch: 9 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.003195\n",
      "1875it [05:49,  5.13it/s]Train epoch: 9 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.003404\n",
      "1900it [05:54,  5.17it/s]Train epoch: 9 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.002432\n",
      "1925it [05:59,  5.17it/s]Train epoch: 9 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.002677\n",
      "1950it [06:04,  5.14it/s]Train epoch: 9 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.002566\n",
      "1975it [06:09,  5.15it/s]Train epoch: 9 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.003281\n",
      "2000it [06:14,  5.14it/s]Train epoch: 9 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.002511\n",
      "2025it [06:19,  5.12it/s]Train epoch: 9 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.003147\n",
      "2050it [06:24,  5.16it/s]Train epoch: 9 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.002989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2075it [06:28,  5.07it/s]Train epoch: 9 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.003103\n",
      "2100it [06:33,  5.15it/s]Train epoch: 9 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.003137\n",
      "2125it [06:38,  5.13it/s]Train epoch: 9 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.003493\n",
      "2150it [06:43,  5.03it/s]Train epoch: 9 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.002916\n",
      "2175it [06:48,  5.11it/s]Train epoch: 9 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.003366\n",
      "2200it [06:53,  5.11it/s]Train epoch: 9 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.003049\n",
      "2225it [06:58,  5.10it/s]Train epoch: 9 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.003022\n",
      "2250it [07:03,  5.01it/s]Train epoch: 9 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.002659\n",
      "2275it [07:08,  5.05it/s]Train epoch: 9 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.003130\n",
      "2300it [07:13,  5.02it/s]Train epoch: 9 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.002398\n",
      "2325it [07:18,  5.10it/s]Train epoch: 9 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.003002\n",
      "2350it [07:22,  5.07it/s]Train epoch: 9 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.002854\n",
      "2375it [07:27,  5.09it/s]Train epoch: 9 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.004091\n",
      "2400it [07:32,  4.97it/s]Train epoch: 9 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.003671\n",
      "2425it [07:37,  5.08it/s]Train epoch: 9 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.002709\n",
      "2450it [07:42,  5.08it/s]Train epoch: 9 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.003014\n",
      "2475it [07:47,  5.07it/s]Train epoch: 9 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.003409\n",
      "2500it [07:52,  5.08it/s]Train epoch: 9 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.002913\n",
      "2525it [07:57,  5.08it/s]Train epoch: 9 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.002900\n",
      "2550it [08:02,  5.08it/s]Train epoch: 9 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.004022\n",
      "2575it [08:07,  5.06it/s]Train epoch: 9 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.002878\n",
      "2600it [08:12,  5.07it/s]Train epoch: 9 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.003175\n",
      "2625it [08:17,  5.06it/s]Train epoch: 9 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.003136\n",
      "2650it [08:22,  4.99it/s]Train epoch: 9 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.003612\n",
      "2675it [08:27,  5.06it/s]Train epoch: 9 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.003150\n",
      "2700it [08:32,  4.98it/s]Train epoch: 9 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.002875\n",
      "2725it [08:37,  5.06it/s]Train epoch: 9 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.002998\n",
      "2750it [08:42,  5.01it/s]Train epoch: 9 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.003613\n",
      "2775it [08:47,  4.97it/s]Train epoch: 9 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.003081\n",
      "2800it [08:52,  5.00it/s]Train epoch: 9 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.002986\n",
      "2825it [08:57,  5.02it/s]Train epoch: 9 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.003360\n",
      "2850it [09:02,  5.01it/s]Train epoch: 9 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.003012\n",
      "2875it [09:07,  5.03it/s]Train epoch: 9 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.003395\n",
      "2900it [09:12,  5.01it/s]Train epoch: 9 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.003359\n",
      "2925it [09:17,  5.01it/s]Train epoch: 9 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.003346\n",
      "2950it [09:22,  5.00it/s]Train epoch: 9 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.003541\n",
      "2975it [09:27,  4.99it/s]Train epoch: 9 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.003271\n",
      "3000it [09:32,  4.99it/s]Train epoch: 9 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.003803\n",
      "3025it [09:37,  4.99it/s]Train epoch: 9 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.003401\n",
      "3050it [09:42,  5.00it/s]Train epoch: 9 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.002985\n",
      "3075it [09:47,  4.99it/s]Train epoch: 9 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.003461\n",
      "3100it [09:52,  4.96it/s]Train epoch: 9 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.003470\n",
      "3125it [09:57,  4.96it/s]Train epoch: 9 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.003103\n",
      "3150it [10:02,  4.92it/s]Train epoch: 9 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.003059\n",
      "3175it [10:07,  4.95it/s]Train epoch: 9 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.003059\n",
      "3200it [10:12,  4.99it/s]Train epoch: 9 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.003713\n",
      "3225it [10:17,  4.99it/s]Train epoch: 9 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.003488\n",
      "3250it [10:22,  4.95it/s]Train epoch: 9 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.003412\n",
      "3275it [10:27,  4.94it/s]Train epoch: 9 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.003088\n",
      "3300it [10:32,  4.96it/s]Train epoch: 9 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.003945\n",
      "3325it [10:37,  4.96it/s]Train epoch: 9 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.003373\n",
      "3350it [10:42,  4.95it/s]Train epoch: 9 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.003394\n",
      "3375it [10:47,  4.93it/s]Train epoch: 9 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.003615\n",
      "3400it [10:52,  4.96it/s]Train epoch: 9 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.003567\n",
      "3425it [10:57,  4.95it/s]Train epoch: 9 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.003123\n",
      "3450it [11:02,  4.96it/s]Train epoch: 9 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.003570\n",
      "3475it [11:08,  4.94it/s]Train epoch: 9 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.003101\n",
      "3500it [11:13,  4.94it/s]Train epoch: 9 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.003336\n",
      "3525it [11:18,  4.93it/s]Train epoch: 9 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.003379\n",
      "3550it [11:23,  4.94it/s]Train epoch: 9 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.003556\n",
      "3575it [11:28,  4.93it/s]Train epoch: 9 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.002945\n",
      "3600it [11:33,  4.93it/s]Train epoch: 9 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.003770\n",
      "3625it [11:38,  4.94it/s]Train epoch: 9 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.003329\n",
      "3650it [11:43,  4.91it/s]Train epoch: 9 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.003537\n",
      "3675it [11:48,  4.92it/s]Train epoch: 9 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.003622\n",
      "3700it [11:53,  4.93it/s]Train epoch: 9 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.003426\n",
      "3725it [11:58,  4.92it/s]Train epoch: 9 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.003652\n",
      "3750it [12:03,  4.90it/s]Train epoch: 9 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.003702\n",
      "3775it [12:09,  4.90it/s]Train epoch: 9 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.003380\n",
      "3800it [12:14,  4.90it/s]Train epoch: 9 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.003890\n",
      "3825it [12:19,  4.91it/s]Train epoch: 9 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.003238\n",
      "3850it [12:24,  4.89it/s]Train epoch: 9 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.002945\n",
      "3875it [12:29,  4.84it/s]Train epoch: 9 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.002996\n",
      "3900it [12:34,  4.90it/s]Train epoch: 9 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.003916\n",
      "3925it [12:39,  4.90it/s]Train epoch: 9 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.003504\n",
      "3950it [12:44,  4.89it/s]Train epoch: 9 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.003889\n",
      "3975it [12:49,  4.88it/s]Train epoch: 9 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.004368\n",
      "4000it [12:55,  4.80it/s]Train epoch: 9 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.003139\n",
      "4025it [13:00,  4.88it/s]Train epoch: 9 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.003999\n",
      "4050it [13:05,  4.88it/s]Train epoch: 9 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.003708\n",
      "4075it [13:10,  4.80it/s]Train epoch: 9 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.003656\n",
      "4100it [13:15,  4.85it/s]Train epoch: 9 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.004063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4125it [13:20,  4.86it/s]Train epoch: 9 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.003844\n",
      "4150it [13:25,  4.86it/s]Train epoch: 9 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.003377\n",
      "4175it [13:31,  4.87it/s]Train epoch: 9 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.003466\n",
      "4200it [13:36,  4.81it/s]Train epoch: 9 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.003779\n",
      "4225it [13:41,  4.85it/s]Train epoch: 9 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.003260\n",
      "4250it [13:46,  4.87it/s]Train epoch: 9 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.003590\n",
      "4275it [13:51,  4.84it/s]Train epoch: 9 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.003420\n",
      "4300it [13:56,  4.85it/s]Train epoch: 9 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.004142\n",
      "4325it [14:01,  4.84it/s]Train epoch: 9 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.003611\n",
      "4350it [14:07,  4.83it/s]Train epoch: 9 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.003921\n",
      "4375it [14:12,  4.82it/s]Train epoch: 9 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.003506\n",
      "4400it [14:17,  4.74it/s]Train epoch: 9 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.002966\n",
      "4425it [14:22,  4.84it/s]Train epoch: 9 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.003773\n",
      "4450it [14:27,  4.82it/s]Train epoch: 9 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.003013\n",
      "4475it [14:33,  4.83it/s]Train epoch: 9 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.003720\n",
      "4500it [14:38,  4.82it/s]Train epoch: 9 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.004409\n",
      "4525it [14:43,  4.82it/s]Train epoch: 9 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.003678\n",
      "4550it [14:48,  4.79it/s]Train epoch: 9 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.003524\n",
      "4575it [14:53,  4.79it/s]Train epoch: 9 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.003970\n",
      "4600it [14:59,  4.76it/s]Train epoch: 9 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.003229\n",
      "4625it [15:04,  4.74it/s]Train epoch: 9 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.003464\n",
      "4650it [15:09,  4.80it/s]Train epoch: 9 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.003953\n",
      "4675it [15:14,  4.76it/s]Train epoch: 9 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.003840\n",
      "4700it [15:19,  4.81it/s]Train epoch: 9 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.003356\n",
      "4725it [15:25,  4.74it/s]Train epoch: 9 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.003581\n",
      "4750it [15:30,  4.78it/s]Train epoch: 9 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.004281\n",
      "4775it [15:35,  4.78it/s]Train epoch: 9 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.003688\n",
      "4800it [15:40,  4.79it/s]Train epoch: 9 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.003766\n",
      "4825it [15:46,  4.76it/s]Train epoch: 9 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.003424\n",
      "4850it [15:51,  4.76it/s]Train epoch: 9 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.003993\n",
      "4875it [15:56,  4.76it/s]Train epoch: 9 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.003548\n",
      "4900it [16:01,  4.73it/s]Train epoch: 9 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.003581\n",
      "4925it [16:07,  4.74it/s]Train epoch: 9 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.003366\n",
      "4950it [16:12,  4.77it/s]Train epoch: 9 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.003538\n",
      "4975it [16:17,  4.75it/s]Train epoch: 9 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.003629\n",
      "5000it [16:23,  4.76it/s]Train epoch: 9 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.003608\n",
      "5025it [16:28,  4.72it/s]Train epoch: 9 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.003466\n",
      "5050it [16:33,  4.70it/s]Train epoch: 9 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.003363\n",
      "5075it [16:38,  4.75it/s]Train epoch: 9 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.003659\n",
      "5100it [16:44,  4.74it/s]Train epoch: 9 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.003726\n",
      "5125it [16:49,  4.75it/s]Train epoch: 9 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.003941\n",
      "5150it [16:54,  4.72it/s]Train epoch: 9 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.003915\n",
      "5175it [17:00,  4.73it/s]Train epoch: 9 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.003688\n",
      "5200it [17:05,  4.71it/s]Train epoch: 9 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.003508\n",
      "5225it [17:10,  4.71it/s]Train epoch: 9 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.003631\n",
      "5250it [17:15,  4.70it/s]Train epoch: 9 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.003708\n",
      "5275it [17:21,  4.64it/s]Train epoch: 9 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.003585\n",
      "5300it [17:26,  4.69it/s]Train epoch: 9 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.003321\n",
      "5325it [17:31,  4.71it/s]Train epoch: 9 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.003974\n",
      "5350it [17:37,  4.70it/s]Train epoch: 9 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.003954\n",
      "5375it [17:42,  4.72it/s]Train epoch: 9 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.003529\n",
      "5400it [17:47,  4.72it/s]Train epoch: 9 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.003560\n",
      "5425it [17:53,  4.70it/s]Train epoch: 9 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.003913\n",
      "5450it [17:58,  4.69it/s]Train epoch: 9 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.003792\n",
      "5475it [18:03,  4.69it/s]Train epoch: 9 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.004407\n",
      "5500it [18:09,  4.70it/s]Train epoch: 9 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.004039\n",
      "5525it [18:14,  4.71it/s]Train epoch: 9 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.003375\n",
      "5550it [18:19,  4.70it/s]Train epoch: 9 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.003832\n",
      "5575it [18:25,  4.68it/s]Train epoch: 9 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.003874\n",
      "5600it [18:30,  4.67it/s]Train epoch: 9 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.004231\n",
      "5625it [18:35,  4.62it/s]Train epoch: 9 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.003788\n",
      "5650it [18:41,  4.68it/s]Train epoch: 9 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.003407\n",
      "5675it [18:46,  4.66it/s]Train epoch: 9 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.004318\n",
      "5700it [18:51,  4.67it/s]Train epoch: 9 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.003656\n",
      "5725it [18:57,  4.67it/s]Train epoch: 9 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.003790\n",
      "5750it [19:02,  4.65it/s]Train epoch: 9 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.004922\n",
      "5775it [19:07,  4.66it/s]Train epoch: 9 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.003952\n",
      "5800it [19:13,  4.65it/s]Train epoch: 9 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.004096\n",
      "5825it [19:18,  4.64it/s]Train epoch: 9 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.003551\n",
      "5850it [19:24,  4.66it/s]Train epoch: 9 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.004646\n",
      "5875it [19:29,  4.65it/s]Train epoch: 9 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.004272\n",
      "5900it [19:34,  4.65it/s]Train epoch: 9 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.004242\n",
      "5925it [19:40,  4.65it/s]Train epoch: 9 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.003666\n",
      "5950it [19:45,  4.64it/s]Train epoch: 9 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.003480\n",
      "5975it [19:51,  4.64it/s]Train epoch: 9 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.004945\n",
      "6000it [19:56,  4.64it/s]Train epoch: 9 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.004195\n",
      "6025it [20:01,  4.62it/s]Train epoch: 9 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.004422\n",
      "6050it [20:07,  4.63it/s]Train epoch: 9 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.003821\n",
      "6075it [20:12,  4.63it/s]Train epoch: 9 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.003520\n",
      "6100it [20:18,  4.62it/s]Train epoch: 9 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.003417\n",
      "6125it [20:23,  4.59it/s]Train epoch: 9 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.003887\n",
      "6150it [20:28,  4.62it/s]Train epoch: 9 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.003941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6175it [20:34,  4.62it/s]Train epoch: 9 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.004371\n",
      "6200it [20:39,  4.61it/s]Train epoch: 9 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.003935\n",
      "6225it [20:45,  4.61it/s]Train epoch: 9 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.003330\n",
      "6250it [20:50,  4.60it/s]Train epoch: 9 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.003596\n",
      "6275it [20:56,  4.61it/s]Train epoch: 9 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.003342\n",
      "6300it [21:01,  4.57it/s]Train epoch: 9 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.003847\n",
      "6325it [21:06,  4.58it/s]Train epoch: 9 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.004276\n",
      "6350it [21:12,  4.58it/s]Train epoch: 9 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.004487\n",
      "6375it [21:17,  4.57it/s]Train epoch: 9 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.003423\n",
      "6400it [21:23,  4.60it/s]Train epoch: 9 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.003824\n",
      "6425it [21:28,  4.59it/s]Train epoch: 9 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.004265\n",
      "6450it [21:34,  4.58it/s]Train epoch: 9 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.004222\n",
      "6475it [21:39,  4.59it/s]Train epoch: 9 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.003747\n",
      "6500it [21:45,  4.58it/s]Train epoch: 9 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.004360\n",
      "6525it [21:50,  4.57it/s]Train epoch: 9 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.003601\n",
      "6550it [21:56,  4.56it/s]Train epoch: 9 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.003839\n",
      "6575it [22:01,  4.57it/s]Train epoch: 9 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.003917\n",
      "6600it [22:07,  4.57it/s]Train epoch: 9 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.004702\n",
      "6625it [22:12,  4.56it/s]Train epoch: 9 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.003837\n",
      "6650it [22:18,  4.55it/s]Train epoch: 9 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.004459\n",
      "6675it [22:23,  4.54it/s]Train epoch: 9 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.004046\n",
      "6700it [22:29,  4.54it/s]Train epoch: 9 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.004143\n",
      "6725it [22:34,  4.55it/s]Train epoch: 9 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.004109\n",
      "6750it [22:40,  4.55it/s]Train epoch: 9 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.003736\n",
      "6775it [22:45,  4.55it/s]Train epoch: 9 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.004345\n",
      "6800it [22:51,  4.49it/s]Train epoch: 9 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.004380\n",
      "6825it [22:56,  4.55it/s]Train epoch: 9 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.004354\n",
      "6850it [23:02,  4.54it/s]Train epoch: 9 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.004202\n",
      "6875it [23:07,  4.49it/s]Train epoch: 9 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.003433\n",
      "6900it [23:13,  4.50it/s]Train epoch: 9 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.003989\n",
      "6925it [23:18,  4.53it/s]Train epoch: 9 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.004081\n",
      "6950it [23:24,  4.52it/s]Train epoch: 9 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.004516\n",
      "6975it [23:29,  4.51it/s]Train epoch: 9 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.004224\n",
      "7000it [23:35,  4.51it/s]Train epoch: 9 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.003965\n",
      "7025it [23:40,  4.50it/s]Train epoch: 9 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.004760\n",
      "7050it [23:46,  4.49it/s]Train epoch: 9 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.003647\n",
      "7075it [23:51,  4.49it/s]Train epoch: 9 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.004166\n",
      "7100it [23:57,  4.50it/s]Train epoch: 9 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.004213\n",
      "7125it [24:03,  4.49it/s]Train epoch: 9 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.003733\n",
      "7150it [24:08,  4.49it/s]Train epoch: 9 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.004656\n",
      "7175it [24:14,  4.49it/s]Train epoch: 9 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.004187\n",
      "7200it [24:19,  4.49it/s]Train epoch: 9 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.004523\n",
      "7225it [24:25,  4.48it/s]Train epoch: 9 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.004020\n",
      "7250it [24:31,  4.49it/s]Train epoch: 9 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.003985\n",
      "7275it [24:36,  4.46it/s]Train epoch: 9 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.004575\n",
      "7300it [24:42,  4.42it/s]Train epoch: 9 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.004885\n",
      "7325it [24:47,  4.47it/s]Train epoch: 9 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.003938\n",
      "7350it [24:53,  4.46it/s]Train epoch: 9 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.004851\n",
      "7375it [24:59,  4.46it/s]Train epoch: 9 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.004378\n",
      "7400it [25:04,  4.44it/s]Train epoch: 9 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.004031\n",
      "7425it [25:10,  4.45it/s]Train epoch: 9 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.004404\n",
      "7450it [25:15,  4.45it/s]Train epoch: 9 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.004788\n",
      "7475it [25:21,  4.45it/s]Train epoch: 9 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.004136\n",
      "7500it [25:27,  4.42it/s]Train epoch: 9 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.004445\n",
      "7525it [25:32,  4.40it/s]Train epoch: 9 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.004181\n",
      "7550it [25:38,  4.39it/s]Train epoch: 9 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.004022\n",
      "7575it [25:44,  4.44it/s]Train epoch: 9 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.004411\n",
      "7600it [25:49,  4.43it/s]Train epoch: 9 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.005285\n",
      "7625it [25:55,  4.43it/s]Train epoch: 9 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.005061\n",
      "7650it [26:01,  4.43it/s]Train epoch: 9 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.004128\n",
      "7675it [26:06,  4.41it/s]Train epoch: 9 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.003985\n",
      "7700it [26:12,  4.42it/s]Train epoch: 9 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.004237\n",
      "7725it [26:18,  4.39it/s]Train epoch: 9 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.004359\n",
      "7750it [26:23,  4.41it/s]Train epoch: 9 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.004586\n",
      "7775it [26:29,  4.36it/s]Train epoch: 9 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.004018\n",
      "7800it [26:35,  4.41it/s]Train epoch: 9 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.004246\n",
      "7825it [26:40,  4.42it/s]Train epoch: 9 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.004511\n",
      "7850it [26:46,  4.41it/s]Train epoch: 9 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.003976\n",
      "7875it [26:52,  4.39it/s]Train epoch: 9 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.004185\n",
      "7900it [26:57,  4.41it/s]Train epoch: 9 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.004388\n",
      "7925it [27:03,  4.33it/s]Train epoch: 9 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.004372\n",
      "7950it [27:09,  4.39it/s]Train epoch: 9 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.004913\n",
      "7975it [27:14,  4.39it/s]Train epoch: 9 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.004138\n",
      "8000it [27:20,  4.37it/s]Train epoch: 9 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.004092\n",
      "8025it [27:26,  4.37it/s]Train epoch: 9 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.004490\n",
      "8050it [27:32,  4.38it/s]Train epoch: 9 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.003794\n",
      "8075it [27:37,  4.37it/s]Train epoch: 9 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.004337\n",
      "8100it [27:43,  4.38it/s]Train epoch: 9 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.004647\n",
      "8125it [27:49,  4.31it/s]Train epoch: 9 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.004652\n",
      "8150it [27:55,  4.33it/s]Train epoch: 9 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.004090\n",
      "8175it [28:00,  4.36it/s]Train epoch: 9 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.004678\n",
      "8200it [28:06,  4.34it/s]Train epoch: 9 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.004037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8225it [28:12,  4.34it/s]Train epoch: 9 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.005510\n",
      "8250it [28:18,  4.35it/s]Train epoch: 9 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.004070\n",
      "8275it [28:23,  4.33it/s]Train epoch: 9 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.004783\n",
      "8300it [28:29,  4.35it/s]Train epoch: 9 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.004100\n",
      "8325it [28:35,  4.27it/s]Train epoch: 9 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.004669\n",
      "8350it [28:41,  4.31it/s]Train epoch: 9 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.004146\n",
      "8375it [28:46,  4.33it/s]Train epoch: 9 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.004680\n",
      "8400it [28:52,  4.30it/s]Train epoch: 9 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.004342\n",
      "8425it [28:58,  4.31it/s]Train epoch: 9 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.004361\n",
      "8450it [29:04,  4.28it/s]Train epoch: 9 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.004778\n",
      "8475it [29:10,  4.31it/s]Train epoch: 9 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.004400\n",
      "8500it [29:16,  4.31it/s]Train epoch: 9 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.005204\n",
      "8525it [29:21,  4.25it/s]Train epoch: 9 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.004319\n",
      "8550it [29:27,  4.31it/s]Train epoch: 9 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.004643\n",
      "8575it [29:33,  4.30it/s]Train epoch: 9 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.004305\n",
      "8600it [29:39,  4.31it/s]Train epoch: 9 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.004397\n",
      "8625it [29:45,  4.28it/s]Train epoch: 9 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.004637\n",
      "8650it [29:51,  4.27it/s]Train epoch: 9 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.004767\n",
      "8675it [29:56,  4.28it/s]Train epoch: 9 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.005211\n",
      "8700it [30:02,  4.26it/s]Train epoch: 9 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.005342\n",
      "8725it [30:08,  4.25it/s]Train epoch: 9 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.005052\n",
      "8750it [30:14,  4.27it/s]Train epoch: 9 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.004781\n",
      "8775it [30:20,  4.25it/s]Train epoch: 9 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.004306\n",
      "8800it [30:26,  4.24it/s]Train epoch: 9 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.004497\n",
      "8825it [30:32,  4.26it/s]Train epoch: 9 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.004593\n",
      "8850it [30:37,  4.26it/s]Train epoch: 9 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.004799\n",
      "8875it [30:43,  4.25it/s]Train epoch: 9 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.004589\n",
      "8900it [30:49,  4.24it/s]Train epoch: 9 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.004606\n",
      "8925it [30:55,  4.19it/s]Train epoch: 9 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.004904\n",
      "8950it [31:01,  4.24it/s]Train epoch: 9 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.005351\n",
      "8975it [31:07,  4.24it/s]Train epoch: 9 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.004921\n",
      "9000it [31:13,  4.21it/s]Train epoch: 9 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.004679\n",
      "9025it [31:19,  4.21it/s]Train epoch: 9 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.004766\n",
      "9050it [31:25,  4.22it/s]Train epoch: 9 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.004371\n",
      "9075it [31:31,  4.20it/s]Train epoch: 9 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.004107\n",
      "9100it [31:37,  4.22it/s]Train epoch: 9 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.004900\n",
      "9125it [31:43,  4.21it/s]Train epoch: 9 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.004327\n",
      "9150it [31:49,  4.21it/s]Train epoch: 9 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.004156\n",
      "9175it [31:55,  4.20it/s]Train epoch: 9 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.004450\n",
      "9200it [32:01,  4.21it/s]Train epoch: 9 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.004402\n",
      "9225it [32:07,  4.20it/s]Train epoch: 9 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.005300\n",
      "9250it [32:13,  4.20it/s]Train epoch: 9 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.004650\n",
      "9275it [32:18,  4.19it/s]Train epoch: 9 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.004917\n",
      "9300it [32:24,  4.18it/s]Train epoch: 9 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.005636\n",
      "9325it [32:30,  4.18it/s]Train epoch: 9 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.005313\n",
      "9350it [32:36,  4.16it/s]Train epoch: 9 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.005143\n",
      "9375it [32:43,  4.16it/s]Train epoch: 9 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.004509\n",
      "9400it [32:49,  4.16it/s]Train epoch: 9 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.004861\n",
      "9425it [32:55,  4.14it/s]Train epoch: 9 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.004615\n",
      "9450it [33:01,  4.14it/s]Train epoch: 9 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.004466\n",
      "9475it [33:07,  4.14it/s]Train epoch: 9 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.005342\n",
      "9500it [33:13,  4.13it/s]Train epoch: 9 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.004812\n",
      "9525it [33:19,  4.13it/s]Train epoch: 9 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.005373\n",
      "9550it [33:25,  4.11it/s]Train epoch: 9 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.005047\n",
      "9575it [33:31,  4.13it/s]Train epoch: 9 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.005166\n",
      "9600it [33:37,  4.12it/s]Train epoch: 9 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.005069\n",
      "9625it [33:43,  4.12it/s]Train epoch: 9 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.004713\n",
      "9650it [33:49,  4.11it/s]Train epoch: 9 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.004563\n",
      "9675it [33:55,  4.09it/s]Train epoch: 9 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.005143\n",
      "9700it [34:01,  4.10it/s]Train epoch: 9 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.004470\n",
      "9725it [34:07,  4.10it/s]Train epoch: 9 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.004843\n",
      "9750it [34:14,  4.08it/s]Train epoch: 9 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.005039\n",
      "9775it [34:20,  4.07it/s]Train epoch: 9 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.005563\n",
      "9800it [34:26,  4.08it/s]Train epoch: 9 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.005296\n",
      "9825it [34:32,  4.05it/s]Train epoch: 9 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.005380\n",
      "9850it [34:38,  4.06it/s]Train epoch: 9 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.004970\n",
      "9875it [34:44,  4.05it/s]Train epoch: 9 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.005268\n",
      "9900it [34:51,  4.01it/s]Train epoch: 9 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.005767\n",
      "9925it [34:57,  4.04it/s]Train epoch: 9 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.005379\n",
      "9950it [35:03,  4.04it/s]Train epoch: 9 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.005837\n",
      "9975it [35:09,  4.03it/s]Train epoch: 9 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.005261\n",
      "10000it [35:15,  4.05it/s]Train epoch: 9 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.005075\n",
      "10025it [35:21,  4.03it/s]Train epoch: 9 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.005075\n",
      "10050it [35:28,  4.02it/s]Train epoch: 9 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.005326\n",
      "10075it [35:34,  4.01it/s]Train epoch: 9 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.005756\n",
      "10100it [35:40,  4.00it/s]Train epoch: 9 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.005503\n",
      "10125it [35:46,  3.99it/s]Train epoch: 9 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.004961\n",
      "10150it [35:53,  3.96it/s]Train epoch: 9 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.005374\n",
      "10175it [35:59,  3.98it/s]Train epoch: 9 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.005123\n",
      "10200it [36:05,  3.99it/s]Train epoch: 9 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.005547\n",
      "10225it [36:11,  3.99it/s]Train epoch: 9 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.005466\n",
      "10250it [36:18,  3.98it/s]Train epoch: 9 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.005917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10275it [36:24,  3.98it/s]Train epoch: 9 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.005146\n",
      "10300it [36:30,  3.97it/s]Train epoch: 9 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.005748\n",
      "10325it [36:37,  3.96it/s]Train epoch: 9 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.005860\n",
      "10350it [36:43,  3.96it/s]Train epoch: 9 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.005237\n",
      "10375it [36:49,  3.90it/s]Train epoch: 9 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.005729\n",
      "10400it [36:56,  3.94it/s]Train epoch: 9 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.005526\n",
      "10425it [37:02,  3.92it/s]Train epoch: 9 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.005253\n",
      "10450it [37:08,  3.94it/s]Train epoch: 9 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.005494\n",
      "10475it [37:15,  3.91it/s]Train epoch: 9 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.004768\n",
      "10500it [37:21,  3.90it/s]Train epoch: 9 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.005589\n",
      "10525it [37:28,  3.91it/s]Train epoch: 9 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.005284\n",
      "10550it [37:34,  3.90it/s]Train epoch: 9 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.005445\n",
      "10575it [37:40,  3.89it/s]Train epoch: 9 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.004882\n",
      "10600it [37:47,  3.89it/s]Train epoch: 9 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.005100\n",
      "10625it [37:53,  3.88it/s]Train epoch: 9 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.005880\n",
      "10650it [38:00,  3.89it/s]Train epoch: 9 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.005384\n",
      "10675it [38:06,  3.85it/s]Train epoch: 9 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.005713\n",
      "10700it [38:13,  3.86it/s]Train epoch: 9 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.005386\n",
      "10725it [38:19,  3.86it/s]Train epoch: 9 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.004956\n",
      "10750it [38:26,  3.84it/s]Train epoch: 9 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.005705\n",
      "10775it [38:32,  3.84it/s]Train epoch: 9 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.005683\n",
      "10800it [38:39,  3.83it/s]Train epoch: 9 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.005999\n",
      "10825it [38:45,  3.80it/s]Train epoch: 9 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.005854\n",
      "10850it [38:52,  3.83it/s]Train epoch: 9 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.005936\n",
      "10875it [38:58,  3.80it/s]Train epoch: 9 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.005914\n",
      "10900it [39:05,  3.76it/s]Train epoch: 9 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.005762\n",
      "10925it [39:12,  3.77it/s]Train epoch: 9 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005166\n",
      "10950it [39:18,  3.77it/s]Train epoch: 9 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.005616\n",
      "10975it [39:25,  3.77it/s]Train epoch: 9 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.005475\n",
      "11000it [39:32,  3.75it/s]Train epoch: 9 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.005534\n",
      "11025it [39:38,  3.76it/s]Train epoch: 9 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.005599\n",
      "11050it [39:45,  3.70it/s]Train epoch: 9 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.006328\n",
      "11075it [39:52,  3.75it/s]Train epoch: 9 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.005781\n",
      "11100it [39:58,  3.71it/s]Train epoch: 9 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.006356\n",
      "11125it [40:05,  3.71it/s]Train epoch: 9 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006016\n",
      "11150it [40:12,  3.71it/s]Train epoch: 9 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.005769\n",
      "11175it [40:19,  3.67it/s]Train epoch: 9 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.006715\n",
      "11200it [40:25,  3.70it/s]Train epoch: 9 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006139\n",
      "11225it [40:32,  3.66it/s]Train epoch: 9 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.005990\n",
      "11250it [40:39,  3.64it/s]Train epoch: 9 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.006669\n",
      "11275it [40:46,  3.63it/s]Train epoch: 9 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.006293\n",
      "11300it [40:53,  3.62it/s]Train epoch: 9 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.005722\n",
      "11325it [41:00,  3.61it/s]Train epoch: 9 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.006921\n",
      "11350it [41:07,  3.58it/s]Train epoch: 9 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.006735\n",
      "11375it [41:14,  3.59it/s]Train epoch: 9 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.006859\n",
      "11400it [41:21,  3.55it/s]Train epoch: 9 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006122\n",
      "11425it [41:28,  3.55it/s]Train epoch: 9 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.006728\n",
      "11450it [41:35,  3.54it/s]Train epoch: 9 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.005992\n",
      "11475it [41:42,  3.51it/s]Train epoch: 9 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007092\n",
      "11500it [41:49,  3.51it/s]Train epoch: 9 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.006807\n",
      "11525it [41:56,  3.47it/s]Train epoch: 9 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006212\n",
      "11550it [42:03,  3.46it/s]Train epoch: 9 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.006089\n",
      "11575it [42:11,  3.42it/s]Train epoch: 9 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007261\n",
      "11600it [42:18,  3.42it/s]Train epoch: 9 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.006669\n",
      "11625it [42:25,  3.39it/s]Train epoch: 9 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006219\n",
      "11650it [42:33,  3.38it/s]Train epoch: 9 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.006797\n",
      "11675it [42:40,  3.34it/s]Train epoch: 9 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007204\n",
      "11700it [42:48,  3.31it/s]Train epoch: 9 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.007661\n",
      "11725it [42:55,  3.27it/s]Train epoch: 9 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.007588\n",
      "11750it [43:03,  3.23it/s]Train epoch: 9 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.007438\n",
      "11775it [43:11,  3.18it/s]Train epoch: 9 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.007356\n",
      "11800it [43:19,  3.14it/s]Train epoch: 9 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007237\n",
      "11825it [43:27,  3.07it/s]Train epoch: 9 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.007388\n",
      "11850it [43:35,  3.01it/s]Train epoch: 9 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.007698\n",
      "11875it [43:44,  2.89it/s]Train epoch: 9 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.008541\n",
      "11900it [43:53,  2.70it/s]Train epoch: 9 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.010285\n",
      "11925it [44:03,  2.39it/s]Train epoch: 9 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.008580\n",
      "11930it [44:05,  4.51it/s]\n",
      "epoch loss: 0.004202940286992372\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.66it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0345, 0.0491, 0.0600, 0.0540, 0.8811\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3145, 0.4860, 0.4712, 0.4785, 0.9804\n",
      "rec_at_8: 0.3385\n",
      "prec_at_8: 0.6267\n",
      "rec_at_15: 0.4731\n",
      "prec_at_15: 0.4899\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:50, 30.64it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0370, 0.0547, 0.0655, 0.0596, 0.8730\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3078, 0.4802, 0.4616, 0.4707, 0.9799\n",
      "rec_at_8: 0.3227\n",
      "prec_at_8: 0.6198\n",
      "rec_at_15: 0.4576\n",
      "prec_at_15: 0.4895\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0315, 0.0469, 0.0521, 0.0493, 0.8825\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3135, 0.5164, 0.4438, 0.4774, 0.9806\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0331, 0.0517, 0.0560, 0.0538, 0.8750\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3057, 0.5091, 0.4335, 0.4682, 0.9801\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Train epoch: 10 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.005372\n",
      "25it [00:04,  5.85it/s]Train epoch: 10 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.003872\n",
      "50it [00:08,  5.80it/s]Train epoch: 10 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.003416\n",
      "75it [00:12,  5.70it/s]Train epoch: 10 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.002787\n",
      "100it [00:17,  5.72it/s]Train epoch: 10 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.002941\n",
      "125it [00:21,  5.68it/s]Train epoch: 10 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.002872\n",
      "150it [00:26,  5.65it/s]Train epoch: 10 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.002733\n",
      "175it [00:30,  5.62it/s]Train epoch: 10 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.002889\n",
      "200it [00:35,  5.58it/s]Train epoch: 10 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.002742\n",
      "225it [00:39,  5.60it/s]Train epoch: 10 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.003373\n",
      "250it [00:44,  5.51it/s]Train epoch: 10 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.002557\n",
      "275it [00:48,  5.59it/s]Train epoch: 10 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.002309\n",
      "300it [00:52,  5.54it/s]Train epoch: 10 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003071\n",
      "325it [00:57,  5.52it/s]Train epoch: 10 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.002501\n",
      "350it [01:02,  5.53it/s]Train epoch: 10 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.003000\n",
      "375it [01:06,  5.53it/s]Train epoch: 10 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.002888\n",
      "400it [01:11,  5.51it/s]Train epoch: 10 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.002862\n",
      "425it [01:15,  5.47it/s]Train epoch: 10 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.002799\n",
      "450it [01:20,  5.50it/s]Train epoch: 10 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.002623\n",
      "475it [01:24,  5.48it/s]Train epoch: 10 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.003140\n",
      "500it [01:29,  5.38it/s]Train epoch: 10 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.002678\n",
      "525it [01:33,  5.43it/s]Train epoch: 10 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.002906\n",
      "550it [01:38,  5.38it/s]Train epoch: 10 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.002754\n",
      "575it [01:43,  5.38it/s]Train epoch: 10 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.002865\n",
      "600it [01:47,  5.42it/s]Train epoch: 10 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.003041\n",
      "625it [01:52,  5.36it/s]Train epoch: 10 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.002946\n",
      "650it [01:57,  5.41it/s]Train epoch: 10 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.002548\n",
      "675it [02:01,  5.32it/s]Train epoch: 10 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002322\n",
      "700it [02:06,  5.40it/s]Train epoch: 10 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.002681\n",
      "725it [02:11,  5.39it/s]Train epoch: 10 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.002874\n",
      "750it [02:15,  5.38it/s]Train epoch: 10 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.002704\n",
      "775it [02:20,  5.33it/s]Train epoch: 10 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.003123\n",
      "800it [02:25,  5.36it/s]Train epoch: 10 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.002978\n",
      "825it [02:29,  5.37it/s]Train epoch: 10 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.002802\n",
      "850it [02:34,  5.36it/s]Train epoch: 10 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.003260\n",
      "875it [02:39,  5.32it/s]Train epoch: 10 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.002534\n",
      "900it [02:43,  5.36it/s]Train epoch: 10 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.002996\n",
      "925it [02:48,  5.32it/s]Train epoch: 10 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.002688\n",
      "950it [02:53,  5.32it/s]Train epoch: 10 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.002622\n",
      "975it [02:57,  5.30it/s]Train epoch: 10 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002232\n",
      "1000it [03:02,  5.24it/s]Train epoch: 10 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.002942\n",
      "1025it [03:07,  5.33it/s]Train epoch: 10 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.004063\n",
      "1050it [03:12,  5.30it/s]Train epoch: 10 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.002685\n",
      "1075it [03:16,  5.29it/s]Train epoch: 10 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.002977\n",
      "1100it [03:21,  5.30it/s]Train epoch: 10 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.003088\n",
      "1125it [03:26,  5.30it/s]Train epoch: 10 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.003138\n",
      "1150it [03:30,  5.30it/s]Train epoch: 10 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.003109\n",
      "1175it [03:35,  5.26it/s]Train epoch: 10 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.002995\n",
      "1200it [03:40,  5.29it/s]Train epoch: 10 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.003101\n",
      "1225it [03:45,  5.15it/s]Train epoch: 10 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.003150\n",
      "1250it [03:49,  5.19it/s]Train epoch: 10 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003093\n",
      "1275it [03:54,  5.29it/s]Train epoch: 10 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.002609\n",
      "1300it [03:59,  5.27it/s]Train epoch: 10 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.002609\n",
      "1325it [04:04,  5.26it/s]Train epoch: 10 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.002659\n",
      "1350it [04:08,  5.26it/s]Train epoch: 10 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.003448\n",
      "1375it [04:13,  5.21it/s]Train epoch: 10 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.002926\n",
      "1400it [04:18,  5.24it/s]Train epoch: 10 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.002848\n",
      "1425it [04:23,  5.24it/s]Train epoch: 10 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.002675\n",
      "1450it [04:28,  5.21it/s]Train epoch: 10 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.002955\n",
      "1475it [04:32,  5.23it/s]Train epoch: 10 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.002917\n",
      "1500it [04:37,  5.24it/s]Train epoch: 10 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.004066\n",
      "1525it [04:42,  5.20it/s]Train epoch: 10 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.003732\n",
      "1550it [04:47,  5.23it/s]Train epoch: 10 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.002763\n",
      "1575it [04:52,  5.21it/s]Train epoch: 10 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.003077\n",
      "1600it [04:56,  5.08it/s]Train epoch: 10 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.002640\n",
      "1625it [05:01,  5.22it/s]Train epoch: 10 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.003227\n",
      "1650it [05:06,  5.20it/s]Train epoch: 10 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.003217\n",
      "1675it [05:11,  5.19it/s]Train epoch: 10 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.003161\n",
      "1700it [05:16,  5.19it/s]Train epoch: 10 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.002734\n",
      "1725it [05:20,  5.20it/s]Train epoch: 10 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.002408\n",
      "1750it [05:25,  5.19it/s]Train epoch: 10 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.003679\n",
      "1775it [05:30,  5.17it/s]Train epoch: 10 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.002999\n",
      "1800it [05:35,  5.18it/s]Train epoch: 10 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.002857\n",
      "1825it [05:40,  5.17it/s]Train epoch: 10 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.002464\n",
      "1850it [05:45,  5.17it/s]Train epoch: 10 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.003068\n",
      "1875it [05:50,  5.17it/s]Train epoch: 10 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.003303\n",
      "1900it [05:54,  5.18it/s]Train epoch: 10 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.002364\n",
      "1925it [05:59,  5.16it/s]Train epoch: 10 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.002669\n",
      "1950it [06:04,  5.14it/s]Train epoch: 10 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.002524\n",
      "1975it [06:09,  5.13it/s]Train epoch: 10 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.003218\n",
      "2000it [06:14,  5.06it/s]Train epoch: 10 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.002496\n",
      "2025it [06:19,  5.15it/s]Train epoch: 10 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.003047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050it [06:24,  5.13it/s]Train epoch: 10 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.002925\n",
      "2075it [06:29,  5.15it/s]Train epoch: 10 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.003044\n",
      "2100it [06:33,  5.13it/s]Train epoch: 10 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.003120\n",
      "2125it [06:38,  5.10it/s]Train epoch: 10 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.003426\n",
      "2150it [06:43,  5.12it/s]Train epoch: 10 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.002910\n",
      "2175it [06:48,  5.08it/s]Train epoch: 10 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.003241\n",
      "2200it [06:53,  5.10it/s]Train epoch: 10 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.003009\n",
      "2225it [06:58,  5.12it/s]Train epoch: 10 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.002942\n",
      "2250it [07:03,  5.01it/s]Train epoch: 10 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.002588\n",
      "2275it [07:08,  5.08it/s]Train epoch: 10 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.003034\n",
      "2300it [07:13,  5.11it/s]Train epoch: 10 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.002321\n",
      "2325it [07:18,  5.11it/s]Train epoch: 10 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.002911\n",
      "2350it [07:23,  5.08it/s]Train epoch: 10 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.002752\n",
      "2375it [07:27,  4.98it/s]Train epoch: 10 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.003986\n",
      "2400it [07:32,  5.09it/s]Train epoch: 10 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.003585\n",
      "2425it [07:37,  5.09it/s]Train epoch: 10 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.002658\n",
      "2450it [07:42,  5.08it/s]Train epoch: 10 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.003010\n",
      "2475it [07:47,  5.09it/s]Train epoch: 10 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.003352\n",
      "2500it [07:52,  5.07it/s]Train epoch: 10 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.002858\n",
      "2525it [07:57,  5.08it/s]Train epoch: 10 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.002825\n",
      "2550it [08:02,  5.08it/s]Train epoch: 10 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.003932\n",
      "2575it [08:07,  4.94it/s]Train epoch: 10 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.002820\n",
      "2600it [08:12,  5.08it/s]Train epoch: 10 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.003096\n",
      "2625it [08:17,  5.07it/s]Train epoch: 10 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.003062\n",
      "2650it [08:22,  5.06it/s]Train epoch: 10 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.003579\n",
      "2675it [08:27,  5.02it/s]Train epoch: 10 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.003110\n",
      "2700it [08:32,  5.05it/s]Train epoch: 10 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.002821\n",
      "2725it [08:37,  5.02it/s]Train epoch: 10 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.002988\n",
      "2750it [08:42,  5.03it/s]Train epoch: 10 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.003535\n",
      "2775it [08:47,  4.99it/s]Train epoch: 10 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.003004\n",
      "2800it [08:52,  5.04it/s]Train epoch: 10 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.002863\n",
      "2825it [08:57,  5.01it/s]Train epoch: 10 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.003302\n",
      "2850it [09:02,  5.01it/s]Train epoch: 10 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.002995\n",
      "2875it [09:07,  4.95it/s]Train epoch: 10 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.003321\n",
      "2900it [09:12,  5.02it/s]Train epoch: 10 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.003281\n",
      "2925it [09:17,  4.97it/s]Train epoch: 10 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.003349\n",
      "2950it [09:22,  5.01it/s]Train epoch: 10 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.003508\n",
      "2975it [09:27,  4.92it/s]Train epoch: 10 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.003212\n",
      "3000it [09:32,  4.99it/s]Train epoch: 10 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.003771\n",
      "3025it [09:37,  4.96it/s]Train epoch: 10 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.003238\n",
      "3050it [09:42,  4.98it/s]Train epoch: 10 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.002902\n",
      "3075it [09:47,  5.00it/s]Train epoch: 10 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.003378\n",
      "3100it [09:52,  4.93it/s]Train epoch: 10 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.003369\n",
      "3125it [09:57,  4.99it/s]Train epoch: 10 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.003034\n",
      "3150it [10:02,  4.98it/s]Train epoch: 10 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.002929\n",
      "3175it [10:07,  4.99it/s]Train epoch: 10 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.002947\n",
      "3200it [10:12,  4.99it/s]Train epoch: 10 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.003585\n",
      "3225it [10:17,  4.99it/s]Train epoch: 10 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.003365\n",
      "3250it [10:22,  4.96it/s]Train epoch: 10 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.003363\n",
      "3275it [10:27,  4.99it/s]Train epoch: 10 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.003047\n",
      "3300it [10:32,  4.89it/s]Train epoch: 10 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.003766\n",
      "3325it [10:37,  4.96it/s]Train epoch: 10 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.003318\n",
      "3350it [10:42,  4.92it/s]Train epoch: 10 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.003357\n",
      "3375it [10:47,  4.95it/s]Train epoch: 10 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.003548\n",
      "3400it [10:52,  4.95it/s]Train epoch: 10 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.003503\n",
      "3425it [10:57,  4.93it/s]Train epoch: 10 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.003074\n",
      "3450it [11:02,  4.94it/s]Train epoch: 10 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.003493\n",
      "3475it [11:07,  4.93it/s]Train epoch: 10 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.002999\n",
      "3500it [11:12,  4.95it/s]Train epoch: 10 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.003214\n",
      "3525it [11:17,  4.94it/s]Train epoch: 10 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.003281\n",
      "3550it [11:23,  4.94it/s]Train epoch: 10 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.003446\n",
      "3575it [11:28,  4.94it/s]Train epoch: 10 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.002866\n",
      "3600it [11:33,  4.92it/s]Train epoch: 10 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.003758\n",
      "3625it [11:38,  4.94it/s]Train epoch: 10 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.003328\n",
      "3650it [11:43,  4.91it/s]Train epoch: 10 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.003508\n",
      "3675it [11:48,  4.92it/s]Train epoch: 10 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.003500\n",
      "3700it [11:53,  4.93it/s]Train epoch: 10 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.003345\n",
      "3725it [11:58,  4.91it/s]Train epoch: 10 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.003485\n",
      "3750it [12:03,  4.89it/s]Train epoch: 10 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.003599\n",
      "3775it [12:08,  4.92it/s]Train epoch: 10 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.003279\n",
      "3800it [12:13,  4.90it/s]Train epoch: 10 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.003795\n",
      "3825it [12:18,  4.90it/s]Train epoch: 10 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.003135\n",
      "3850it [12:24,  4.90it/s]Train epoch: 10 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.002851\n",
      "3875it [12:29,  4.88it/s]Train epoch: 10 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.002916\n",
      "3900it [12:34,  4.91it/s]Train epoch: 10 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.003834\n",
      "3925it [12:39,  4.85it/s]Train epoch: 10 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.003428\n",
      "3950it [12:44,  4.88it/s]Train epoch: 10 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.003745\n",
      "3975it [12:49,  4.87it/s]Train epoch: 10 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.004226\n",
      "4000it [12:54,  4.88it/s]Train epoch: 10 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.003015\n",
      "4025it [12:59,  4.85it/s]Train epoch: 10 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.003950\n",
      "4050it [13:05,  4.88it/s]Train epoch: 10 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.003576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4075it [13:10,  4.87it/s]Train epoch: 10 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.003607\n",
      "4100it [13:15,  4.88it/s]Train epoch: 10 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.003862\n",
      "4125it [13:20,  4.85it/s]Train epoch: 10 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.003696\n",
      "4150it [13:25,  4.85it/s]Train epoch: 10 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.003284\n",
      "4175it [13:30,  4.86it/s]Train epoch: 10 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.003349\n",
      "4200it [13:35,  4.86it/s]Train epoch: 10 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.003787\n",
      "4225it [13:41,  4.84it/s]Train epoch: 10 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.003227\n",
      "4250it [13:46,  4.87it/s]Train epoch: 10 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.003498\n",
      "4275it [13:51,  4.81it/s]Train epoch: 10 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.003322\n",
      "4300it [13:56,  4.77it/s]Train epoch: 10 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.003982\n",
      "4325it [14:01,  4.84it/s]Train epoch: 10 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.003545\n",
      "4350it [14:07,  4.84it/s]Train epoch: 10 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.003847\n",
      "4375it [14:12,  4.74it/s]Train epoch: 10 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.003392\n",
      "4400it [14:17,  4.84it/s]Train epoch: 10 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.002856\n",
      "4425it [14:22,  4.83it/s]Train epoch: 10 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.003662\n",
      "4450it [14:27,  4.82it/s]Train epoch: 10 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.002954\n",
      "4475it [14:32,  4.77it/s]Train epoch: 10 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.003600\n",
      "4500it [14:38,  4.82it/s]Train epoch: 10 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.004215\n",
      "4525it [14:43,  4.82it/s]Train epoch: 10 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.003549\n",
      "4550it [14:48,  4.82it/s]Train epoch: 10 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.003436\n",
      "4575it [14:53,  4.81it/s]Train epoch: 10 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.003851\n",
      "4600it [14:58,  4.82it/s]Train epoch: 10 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.003162\n",
      "4625it [15:04,  4.80it/s]Train epoch: 10 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.003378\n",
      "4650it [15:09,  4.75it/s]Train epoch: 10 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.003967\n",
      "4675it [15:14,  4.80it/s]Train epoch: 10 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.003727\n",
      "4700it [15:19,  4.80it/s]Train epoch: 10 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.003250\n",
      "4725it [15:25,  4.81it/s]Train epoch: 10 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.003502\n",
      "4750it [15:30,  4.80it/s]Train epoch: 10 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.004163\n",
      "4775it [15:35,  4.77it/s]Train epoch: 10 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.003614\n",
      "4800it [15:40,  4.79it/s]Train epoch: 10 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.003681\n",
      "4825it [15:46,  4.74it/s]Train epoch: 10 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.003333\n",
      "4850it [15:51,  4.73it/s]Train epoch: 10 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.003875\n",
      "4875it [15:56,  4.78it/s]Train epoch: 10 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.003401\n",
      "4900it [16:01,  4.76it/s]Train epoch: 10 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.003471\n",
      "4925it [16:07,  4.78it/s]Train epoch: 10 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.003357\n",
      "4950it [16:12,  4.75it/s]Train epoch: 10 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.003504\n",
      "4975it [16:17,  4.72it/s]Train epoch: 10 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.003518\n",
      "5000it [16:22,  4.77it/s]Train epoch: 10 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.003602\n",
      "5025it [16:28,  4.75it/s]Train epoch: 10 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.003383\n",
      "5050it [16:33,  4.77it/s]Train epoch: 10 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.003270\n",
      "5075it [16:38,  4.75it/s]Train epoch: 10 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.003565\n",
      "5100it [16:43,  4.76it/s]Train epoch: 10 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.003635\n",
      "5125it [16:49,  4.74it/s]Train epoch: 10 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.003866\n",
      "5150it [16:54,  4.74it/s]Train epoch: 10 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.003805\n",
      "5175it [16:59,  4.73it/s]Train epoch: 10 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.003620\n",
      "5200it [17:05,  4.44it/s]Train epoch: 10 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.003446\n",
      "5225it [17:10,  4.69it/s]Train epoch: 10 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.003630\n",
      "5250it [17:15,  4.71it/s]Train epoch: 10 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.003696\n",
      "5275it [17:21,  4.73it/s]Train epoch: 10 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.003464\n",
      "5300it [17:26,  4.72it/s]Train epoch: 10 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.003203\n",
      "5325it [17:31,  4.70it/s]Train epoch: 10 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.003905\n",
      "5350it [17:37,  4.62it/s]Train epoch: 10 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.003846\n",
      "5375it [17:42,  4.72it/s]Train epoch: 10 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.003470\n",
      "5400it [17:47,  4.73it/s]Train epoch: 10 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.003444\n",
      "5425it [17:52,  4.71it/s]Train epoch: 10 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.003788\n",
      "5450it [17:58,  4.65it/s]Train epoch: 10 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.003735\n",
      "5475it [18:03,  4.69it/s]Train epoch: 10 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.004333\n",
      "5500it [18:09,  4.61it/s]Train epoch: 10 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.003949\n",
      "5525it [18:14,  4.71it/s]Train epoch: 10 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.003336\n",
      "5550it [18:19,  4.71it/s]Train epoch: 10 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.003734\n",
      "5575it [18:24,  4.69it/s]Train epoch: 10 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.003789\n",
      "5600it [18:30,  4.69it/s]Train epoch: 10 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.004128\n",
      "5625it [18:35,  4.69it/s]Train epoch: 10 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.003699\n",
      "5650it [18:41,  4.67it/s]Train epoch: 10 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.003325\n",
      "5675it [18:46,  4.68it/s]Train epoch: 10 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.004179\n",
      "5700it [18:51,  4.66it/s]Train epoch: 10 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.003645\n",
      "5725it [18:57,  4.60it/s]Train epoch: 10 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.003645\n",
      "5750it [19:02,  4.67it/s]Train epoch: 10 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.004866\n",
      "5775it [19:07,  4.67it/s]Train epoch: 10 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.003838\n",
      "5800it [19:13,  4.65it/s]Train epoch: 10 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.003945\n",
      "5825it [19:18,  4.60it/s]Train epoch: 10 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.003473\n",
      "5850it [19:24,  4.66it/s]Train epoch: 10 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.004528\n",
      "5875it [19:29,  4.64it/s]Train epoch: 10 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.004153\n",
      "5900it [19:34,  4.66it/s]Train epoch: 10 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.004129\n",
      "5925it [19:40,  4.65it/s]Train epoch: 10 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.003595\n",
      "5950it [19:45,  4.65it/s]Train epoch: 10 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.003386\n",
      "5975it [19:50,  4.60it/s]Train epoch: 10 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.004788\n",
      "6000it [19:56,  4.63it/s]Train epoch: 10 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.004049\n",
      "6025it [20:01,  4.53it/s]Train epoch: 10 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.004311\n",
      "6050it [20:07,  4.62it/s]Train epoch: 10 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.003678\n",
      "6075it [20:12,  4.62it/s]Train epoch: 10 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.003543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6100it [20:18,  4.60it/s]Train epoch: 10 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.003337\n",
      "6125it [20:23,  4.62it/s]Train epoch: 10 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.003857\n",
      "6150it [20:28,  4.62it/s]Train epoch: 10 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.003840\n",
      "6175it [20:34,  4.56it/s]Train epoch: 10 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.004304\n",
      "6200it [20:39,  4.60it/s]Train epoch: 10 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.003872\n",
      "6225it [20:45,  4.62it/s]Train epoch: 10 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.003316\n",
      "6250it [20:50,  4.61it/s]Train epoch: 10 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.003553\n",
      "6275it [20:55,  4.60it/s]Train epoch: 10 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.003235\n",
      "6300it [21:01,  4.60it/s]Train epoch: 10 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.003727\n",
      "6325it [21:06,  4.58it/s]Train epoch: 10 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.004272\n",
      "6350it [21:12,  4.58it/s]Train epoch: 10 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.004326\n",
      "6375it [21:17,  4.59it/s]Train epoch: 10 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.003344\n",
      "6400it [21:23,  4.59it/s]Train epoch: 10 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.003793\n",
      "6425it [21:28,  4.57it/s]Train epoch: 10 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.004174\n",
      "6450it [21:34,  4.59it/s]Train epoch: 10 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.004155\n",
      "6475it [21:39,  4.59it/s]Train epoch: 10 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.003737\n",
      "6500it [21:45,  4.56it/s]Train epoch: 10 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.004230\n",
      "6525it [21:50,  4.56it/s]Train epoch: 10 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.003564\n",
      "6550it [21:56,  4.57it/s]Train epoch: 10 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.003717\n",
      "6575it [22:01,  4.57it/s]Train epoch: 10 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.003824\n",
      "6600it [22:07,  4.54it/s]Train epoch: 10 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.004658\n",
      "6625it [22:12,  4.56it/s]Train epoch: 10 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.003758\n",
      "6650it [22:18,  4.51it/s]Train epoch: 10 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.004415\n",
      "6675it [22:23,  4.56it/s]Train epoch: 10 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.003865\n",
      "6700it [22:29,  4.55it/s]Train epoch: 10 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.004127\n",
      "6725it [22:34,  4.55it/s]Train epoch: 10 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.004022\n",
      "6750it [22:40,  4.51it/s]Train epoch: 10 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.003681\n",
      "6775it [22:45,  4.55it/s]Train epoch: 10 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.004359\n",
      "6800it [22:51,  4.50it/s]Train epoch: 10 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.004279\n",
      "6825it [22:56,  4.52it/s]Train epoch: 10 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.004226\n",
      "6850it [23:02,  4.53it/s]Train epoch: 10 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.004087\n",
      "6875it [23:07,  4.54it/s]Train epoch: 10 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.003410\n",
      "6900it [23:13,  4.52it/s]Train epoch: 10 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.003955\n",
      "6925it [23:18,  4.53it/s]Train epoch: 10 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.004000\n",
      "6950it [23:24,  4.53it/s]Train epoch: 10 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.004413\n",
      "6975it [23:29,  4.50it/s]Train epoch: 10 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.004135\n",
      "7000it [23:35,  4.51it/s]Train epoch: 10 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.003855\n",
      "7025it [23:40,  4.51it/s]Train epoch: 10 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.004544\n",
      "7050it [23:46,  4.52it/s]Train epoch: 10 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.003520\n",
      "7075it [23:52,  4.49it/s]Train epoch: 10 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.004053\n",
      "7100it [23:57,  4.49it/s]Train epoch: 10 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.004087\n",
      "7125it [24:03,  4.49it/s]Train epoch: 10 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.003619\n",
      "7150it [24:08,  4.49it/s]Train epoch: 10 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.004544\n",
      "7175it [24:14,  4.45it/s]Train epoch: 10 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.004071\n",
      "7200it [24:19,  4.47it/s]Train epoch: 10 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.004408\n",
      "7225it [24:25,  4.48it/s]Train epoch: 10 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.004014\n",
      "7250it [24:31,  4.49it/s]Train epoch: 10 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.003905\n",
      "7275it [24:36,  4.48it/s]Train epoch: 10 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.004495\n",
      "7300it [24:42,  4.46it/s]Train epoch: 10 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.004751\n",
      "7325it [24:47,  4.47it/s]Train epoch: 10 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.003793\n",
      "7350it [24:53,  4.47it/s]Train epoch: 10 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.004741\n",
      "7375it [24:59,  4.45it/s]Train epoch: 10 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.004308\n",
      "7400it [25:04,  4.45it/s]Train epoch: 10 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.003903\n",
      "7425it [25:10,  4.46it/s]Train epoch: 10 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.004290\n",
      "7450it [25:15,  4.42it/s]Train epoch: 10 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.004639\n",
      "7475it [25:21,  4.44it/s]Train epoch: 10 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.004119\n",
      "7500it [25:27,  4.41it/s]Train epoch: 10 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.004375\n",
      "7525it [25:32,  4.45it/s]Train epoch: 10 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.004121\n",
      "7550it [25:38,  4.43it/s]Train epoch: 10 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.003985\n",
      "7575it [25:44,  4.44it/s]Train epoch: 10 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.004396\n",
      "7600it [25:49,  4.43it/s]Train epoch: 10 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.005199\n",
      "7625it [25:55,  4.42it/s]Train epoch: 10 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.004932\n",
      "7650it [26:01,  4.39it/s]Train epoch: 10 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.004106\n",
      "7675it [26:06,  4.39it/s]Train epoch: 10 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.003903\n",
      "7700it [26:12,  4.42it/s]Train epoch: 10 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.004213\n",
      "7725it [26:18,  4.41it/s]Train epoch: 10 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.004242\n",
      "7750it [26:23,  4.42it/s]Train epoch: 10 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.004503\n",
      "7775it [26:29,  4.41it/s]Train epoch: 10 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.003957\n",
      "7800it [26:35,  4.41it/s]Train epoch: 10 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.004121\n",
      "7825it [26:40,  4.42it/s]Train epoch: 10 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.004411\n",
      "7850it [26:46,  4.41it/s]Train epoch: 10 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.003940\n",
      "7875it [26:52,  4.38it/s]Train epoch: 10 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.004051\n",
      "7900it [26:57,  4.41it/s]Train epoch: 10 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.004269\n",
      "7925it [27:03,  4.38it/s]Train epoch: 10 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.004306\n",
      "7950it [27:09,  4.38it/s]Train epoch: 10 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.004761\n",
      "7975it [27:14,  4.37it/s]Train epoch: 10 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.003975\n",
      "8000it [27:20,  4.37it/s]Train epoch: 10 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.004069\n",
      "8025it [27:26,  4.34it/s]Train epoch: 10 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.004477\n",
      "8050it [27:32,  4.39it/s]Train epoch: 10 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.003643\n",
      "8075it [27:37,  4.34it/s]Train epoch: 10 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.004233\n",
      "8100it [27:43,  4.38it/s]Train epoch: 10 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.004589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8125it [27:49,  4.35it/s]Train epoch: 10 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.004600\n",
      "8150it [27:55,  4.37it/s]Train epoch: 10 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.003960\n",
      "8175it [28:00,  4.34it/s]Train epoch: 10 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.004557\n",
      "8200it [28:06,  4.36it/s]Train epoch: 10 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.003941\n",
      "8225it [28:12,  4.34it/s]Train epoch: 10 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.005334\n",
      "8250it [28:18,  4.35it/s]Train epoch: 10 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.004018\n",
      "8275it [28:23,  4.34it/s]Train epoch: 10 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.004723\n",
      "8300it [28:29,  4.35it/s]Train epoch: 10 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.004044\n",
      "8325it [28:35,  4.33it/s]Train epoch: 10 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.004576\n",
      "8350it [28:41,  4.32it/s]Train epoch: 10 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.004009\n",
      "8375it [28:46,  4.33it/s]Train epoch: 10 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.004630\n",
      "8400it [28:52,  4.32it/s]Train epoch: 10 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.004248\n",
      "8425it [28:58,  4.31it/s]Train epoch: 10 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.004252\n",
      "8450it [29:04,  4.31it/s]Train epoch: 10 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.004602\n",
      "8475it [29:10,  4.29it/s]Train epoch: 10 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.004301\n",
      "8500it [29:15,  4.30it/s]Train epoch: 10 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.005091\n",
      "8525it [29:21,  4.30it/s]Train epoch: 10 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.004255\n",
      "8550it [29:27,  4.30it/s]Train epoch: 10 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.004534\n",
      "8575it [29:33,  4.28it/s]Train epoch: 10 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.004187\n",
      "8600it [29:39,  4.28it/s]Train epoch: 10 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.004278\n",
      "8625it [29:45,  4.27it/s]Train epoch: 10 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.004519\n",
      "8650it [29:50,  4.28it/s]Train epoch: 10 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.004681\n",
      "8675it [29:56,  4.28it/s]Train epoch: 10 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.005131\n",
      "8700it [30:02,  4.27it/s]Train epoch: 10 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.005246\n",
      "8725it [30:08,  4.26it/s]Train epoch: 10 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.004922\n",
      "8750it [30:14,  4.27it/s]Train epoch: 10 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.004635\n",
      "8775it [30:20,  4.25it/s]Train epoch: 10 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.004233\n",
      "8800it [30:26,  4.26it/s]Train epoch: 10 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.004463\n",
      "8825it [30:31,  4.26it/s]Train epoch: 10 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.004498\n",
      "8850it [30:37,  4.26it/s]Train epoch: 10 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.004658\n",
      "8875it [30:43,  4.25it/s]Train epoch: 10 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.004527\n",
      "8900it [30:49,  4.25it/s]Train epoch: 10 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.004555\n",
      "8925it [30:55,  4.23it/s]Train epoch: 10 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.004741\n",
      "8950it [31:01,  4.22it/s]Train epoch: 10 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.005289\n",
      "8975it [31:07,  4.24it/s]Train epoch: 10 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.004746\n",
      "9000it [31:13,  4.22it/s]Train epoch: 10 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.004573\n",
      "9025it [31:19,  4.23it/s]Train epoch: 10 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.004646\n",
      "9050it [31:25,  4.21it/s]Train epoch: 10 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.004273\n",
      "9075it [31:30,  4.21it/s]Train epoch: 10 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.003982\n",
      "9100it [31:36,  4.21it/s]Train epoch: 10 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.004809\n",
      "9125it [31:42,  4.21it/s]Train epoch: 10 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.004320\n",
      "9150it [31:48,  4.21it/s]Train epoch: 10 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.004014\n",
      "9175it [31:54,  4.20it/s]Train epoch: 10 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.004359\n",
      "9200it [32:00,  4.21it/s]Train epoch: 10 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.004390\n",
      "9225it [32:06,  4.19it/s]Train epoch: 10 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.005174\n",
      "9250it [32:12,  4.18it/s]Train epoch: 10 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.004556\n",
      "9275it [32:18,  4.18it/s]Train epoch: 10 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.004800\n",
      "9300it [32:24,  4.18it/s]Train epoch: 10 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.005592\n",
      "9325it [32:30,  4.18it/s]Train epoch: 10 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.005128\n",
      "9350it [32:36,  4.16it/s]Train epoch: 10 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.005017\n",
      "9375it [32:42,  4.16it/s]Train epoch: 10 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.004411\n",
      "9400it [32:48,  4.14it/s]Train epoch: 10 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.004810\n",
      "9425it [32:54,  4.14it/s]Train epoch: 10 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.004580\n",
      "9450it [33:00,  4.14it/s]Train epoch: 10 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.004377\n",
      "9475it [33:06,  4.12it/s]Train epoch: 10 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.005116\n",
      "9500it [33:12,  4.14it/s]Train epoch: 10 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.004776\n",
      "9525it [33:18,  4.13it/s]Train epoch: 10 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.005286\n",
      "9550it [33:24,  4.10it/s]Train epoch: 10 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.004950\n",
      "9575it [33:31,  4.13it/s]Train epoch: 10 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.005053\n",
      "9600it [33:37,  4.12it/s]Train epoch: 10 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.005001\n",
      "9625it [33:43,  4.09it/s]Train epoch: 10 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.004603\n",
      "9650it [33:49,  4.12it/s]Train epoch: 10 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.004504\n",
      "9675it [33:55,  4.06it/s]Train epoch: 10 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.005030\n",
      "9700it [34:01,  4.09it/s]Train epoch: 10 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.004362\n",
      "9725it [34:07,  4.09it/s]Train epoch: 10 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.004738\n",
      "9750it [34:13,  4.09it/s]Train epoch: 10 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.005018\n",
      "9775it [34:19,  4.05it/s]Train epoch: 10 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.005435\n",
      "9800it [34:26,  4.07it/s]Train epoch: 10 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.005182\n",
      "9825it [34:32,  4.05it/s]Train epoch: 10 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.005272\n",
      "9850it [34:38,  4.07it/s]Train epoch: 10 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.004934\n",
      "9875it [34:44,  4.06it/s]Train epoch: 10 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.005178\n",
      "9900it [34:50,  4.05it/s]Train epoch: 10 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.005638\n",
      "9925it [34:56,  4.02it/s]Train epoch: 10 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.005351\n",
      "9950it [35:03,  4.04it/s]Train epoch: 10 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.005758\n",
      "9975it [35:09,  4.03it/s]Train epoch: 10 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.005108\n",
      "10000it [35:15,  4.04it/s]Train epoch: 10 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.004930\n",
      "10025it [35:21,  4.03it/s]Train epoch: 10 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.004937\n",
      "10050it [35:27,  4.03it/s]Train epoch: 10 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.005223\n",
      "10075it [35:34,  3.93it/s]Train epoch: 10 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.005623\n",
      "10100it [35:40,  3.97it/s]Train epoch: 10 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.005353\n",
      "10125it [35:46,  4.00it/s]Train epoch: 10 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.004802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10150it [35:52,  3.99it/s]Train epoch: 10 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.005298\n",
      "10175it [35:59,  3.98it/s]Train epoch: 10 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.005028\n",
      "10200it [36:05,  3.98it/s]Train epoch: 10 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.005442\n",
      "10225it [36:11,  3.99it/s]Train epoch: 10 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.005333\n",
      "10250it [36:18,  3.99it/s]Train epoch: 10 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.005888\n",
      "10275it [36:24,  3.98it/s]Train epoch: 10 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.005056\n",
      "10300it [36:30,  3.97it/s]Train epoch: 10 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.005633\n",
      "10325it [36:36,  3.96it/s]Train epoch: 10 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.005723\n",
      "10350it [36:43,  3.96it/s]Train epoch: 10 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.005074\n",
      "10375it [36:49,  3.95it/s]Train epoch: 10 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.005549\n",
      "10400it [36:55,  3.95it/s]Train epoch: 10 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.005424\n",
      "10425it [37:02,  3.80it/s]Train epoch: 10 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.005186\n",
      "10450it [37:08,  3.92it/s]Train epoch: 10 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.005403\n",
      "10475it [37:15,  3.91it/s]Train epoch: 10 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.004611\n",
      "10500it [37:21,  3.91it/s]Train epoch: 10 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.005501\n",
      "10525it [37:27,  3.92it/s]Train epoch: 10 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.005171\n",
      "10550it [37:34,  3.89it/s]Train epoch: 10 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.005407\n",
      "10575it [37:40,  3.90it/s]Train epoch: 10 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.004730\n",
      "10600it [37:47,  3.88it/s]Train epoch: 10 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.004995\n",
      "10625it [37:53,  3.88it/s]Train epoch: 10 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.005716\n",
      "10650it [38:00,  3.83it/s]Train epoch: 10 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.005248\n",
      "10675it [38:06,  3.85it/s]Train epoch: 10 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.005515\n",
      "10700it [38:13,  3.87it/s]Train epoch: 10 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.005198\n",
      "10725it [38:19,  3.86it/s]Train epoch: 10 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.004908\n",
      "10750it [38:26,  3.85it/s]Train epoch: 10 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.005547\n",
      "10775it [38:32,  3.83it/s]Train epoch: 10 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.005574\n",
      "10800it [38:39,  3.83it/s]Train epoch: 10 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.005846\n",
      "10825it [38:45,  3.82it/s]Train epoch: 10 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.005698\n",
      "10850it [38:52,  3.81it/s]Train epoch: 10 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.005860\n",
      "10875it [38:58,  3.80it/s]Train epoch: 10 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.005832\n",
      "10900it [39:05,  3.80it/s]Train epoch: 10 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.005558\n",
      "10925it [39:12,  3.80it/s]Train epoch: 10 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005117\n",
      "10950it [39:18,  3.79it/s]Train epoch: 10 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.005614\n",
      "10975it [39:25,  3.76it/s]Train epoch: 10 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.005316\n",
      "11000it [39:31,  3.74it/s]Train epoch: 10 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.005421\n",
      "11025it [39:38,  3.76it/s]Train epoch: 10 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.005585\n",
      "11050it [39:45,  3.72it/s]Train epoch: 10 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.006163\n",
      "11075it [39:51,  3.73it/s]Train epoch: 10 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.005664\n",
      "11100it [39:58,  3.71it/s]Train epoch: 10 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.006267\n",
      "11125it [40:05,  3.72it/s]Train epoch: 10 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.005873\n",
      "11150it [40:12,  3.71it/s]Train epoch: 10 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.005631\n",
      "11175it [40:18,  3.68it/s]Train epoch: 10 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.006556\n",
      "11200it [40:25,  3.69it/s]Train epoch: 10 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.005992\n",
      "11225it [40:32,  3.67it/s]Train epoch: 10 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.005800\n",
      "11250it [40:39,  3.65it/s]Train epoch: 10 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.006557\n",
      "11275it [40:46,  3.64it/s]Train epoch: 10 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.006202\n",
      "11300it [40:53,  3.60it/s]Train epoch: 10 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.005642\n",
      "11325it [41:00,  3.61it/s]Train epoch: 10 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.006815\n",
      "11350it [41:07,  3.59it/s]Train epoch: 10 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.006665\n",
      "11375it [41:14,  3.59it/s]Train epoch: 10 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.006832\n",
      "11400it [41:21,  3.55it/s]Train epoch: 10 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.005993\n",
      "11425it [41:28,  3.55it/s]Train epoch: 10 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.006662\n",
      "11450it [41:35,  3.51it/s]Train epoch: 10 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.005878\n",
      "11475it [41:42,  3.52it/s]Train epoch: 10 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.006950\n",
      "11500it [41:49,  3.49it/s]Train epoch: 10 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.006624\n",
      "11525it [41:56,  3.47it/s]Train epoch: 10 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006155\n",
      "11550it [42:03,  3.45it/s]Train epoch: 10 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.005976\n",
      "11575it [42:11,  3.42it/s]Train epoch: 10 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007091\n",
      "11600it [42:18,  3.42it/s]Train epoch: 10 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.006489\n",
      "11625it [42:25,  3.41it/s]Train epoch: 10 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006069\n",
      "11650it [42:33,  3.38it/s]Train epoch: 10 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.006646\n",
      "11675it [42:40,  3.33it/s]Train epoch: 10 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007049\n",
      "11700it [42:48,  3.30it/s]Train epoch: 10 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.007552\n",
      "11725it [42:55,  3.27it/s]Train epoch: 10 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.007548\n",
      "11750it [43:03,  3.22it/s]Train epoch: 10 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.007325\n",
      "11775it [43:11,  3.18it/s]Train epoch: 10 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.007188\n",
      "11800it [43:19,  3.11it/s]Train epoch: 10 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007101\n",
      "11825it [43:27,  3.06it/s]Train epoch: 10 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.007241\n",
      "11850it [43:35,  2.99it/s]Train epoch: 10 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.007612\n",
      "11875it [43:44,  2.89it/s]Train epoch: 10 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.008339\n",
      "11900it [43:53,  2.70it/s]Train epoch: 10 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.010188\n",
      "11925it [44:03,  2.39it/s]Train epoch: 10 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.008569\n",
      "11930it [44:05,  4.51it/s]\n",
      "epoch loss: 0.004114365596975077\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:53, 30.72it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0355, 0.0493, 0.0624, 0.0550, 0.8792\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3158, 0.4843, 0.4757, 0.4800, 0.9802\n",
      "rec_at_8: 0.3401\n",
      "prec_at_8: 0.6303\n",
      "rec_at_15: 0.4774\n",
      "prec_at_15: 0.4933\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:50, 30.63it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0378, 0.0545, 0.0681, 0.0606, 0.8706\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3102, 0.4781, 0.4689, 0.4735, 0.9797\n",
      "rec_at_8: 0.3259\n",
      "prec_at_8: 0.6256\n",
      "rec_at_15: 0.4597\n",
      "prec_at_15: 0.4914\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0315, 0.0469, 0.0521, 0.0493, 0.8825\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3135, 0.5164, 0.4438, 0.4774, 0.9806\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0331, 0.0517, 0.0560, 0.0538, 0.8750\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3057, 0.5091, 0.4335, 0.4682, 0.9801\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 11\n",
      "0it [00:00, ?it/s]Train epoch: 11 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.005643\n",
      "25it [00:04,  5.86it/s]Train epoch: 11 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.003868\n",
      "50it [00:08,  5.79it/s]Train epoch: 11 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.003343\n",
      "75it [00:12,  5.71it/s]Train epoch: 11 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.002777\n",
      "100it [00:17,  5.72it/s]Train epoch: 11 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.002855\n",
      "125it [00:21,  5.68it/s]Train epoch: 11 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.002818\n",
      "150it [00:26,  5.66it/s]Train epoch: 11 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.002687\n",
      "175it [00:30,  5.59it/s]Train epoch: 11 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.002832\n",
      "200it [00:34,  5.63it/s]Train epoch: 11 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.002718\n",
      "225it [00:39,  5.62it/s]Train epoch: 11 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.003411\n",
      "250it [00:43,  5.53it/s]Train epoch: 11 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.002585\n",
      "275it [00:48,  5.53it/s]Train epoch: 11 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.002302\n",
      "300it [00:52,  5.56it/s]Train epoch: 11 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003049\n",
      "325it [00:57,  5.53it/s]Train epoch: 11 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.002499\n",
      "350it [01:01,  5.53it/s]Train epoch: 11 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.002995\n",
      "375it [01:06,  5.52it/s]Train epoch: 11 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.002815\n",
      "400it [01:11,  5.52it/s]Train epoch: 11 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.002798\n",
      "425it [01:15,  5.51it/s]Train epoch: 11 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.002744\n",
      "450it [01:20,  5.50it/s]Train epoch: 11 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.002577\n",
      "475it [01:24,  5.44it/s]Train epoch: 11 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.003083\n",
      "500it [01:29,  5.47it/s]Train epoch: 11 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.002625\n",
      "525it [01:33,  5.46it/s]Train epoch: 11 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.002943\n",
      "550it [01:38,  5.46it/s]Train epoch: 11 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.002715\n",
      "575it [01:43,  5.45it/s]Train epoch: 11 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.002802\n",
      "600it [01:47,  5.40it/s]Train epoch: 11 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.002954\n",
      "625it [01:52,  5.43it/s]Train epoch: 11 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.002853\n",
      "650it [01:56,  5.40it/s]Train epoch: 11 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.002582\n",
      "675it [02:01,  5.42it/s]Train epoch: 11 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002310\n",
      "700it [02:06,  5.38it/s]Train epoch: 11 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.002634\n",
      "725it [02:10,  5.35it/s]Train epoch: 11 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.002859\n",
      "750it [02:15,  5.36it/s]Train epoch: 11 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.002724\n",
      "775it [02:20,  5.39it/s]Train epoch: 11 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.003042\n",
      "800it [02:24,  5.28it/s]Train epoch: 11 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.002920\n",
      "825it [02:29,  5.31it/s]Train epoch: 11 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.002779\n",
      "850it [02:34,  5.37it/s]Train epoch: 11 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.003175\n",
      "875it [02:38,  5.32it/s]Train epoch: 11 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.002505\n",
      "900it [02:43,  5.35it/s]Train epoch: 11 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.003029\n",
      "925it [02:48,  5.34it/s]Train epoch: 11 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.002704\n",
      "950it [02:52,  5.33it/s]Train epoch: 11 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.002595\n",
      "975it [02:57,  5.35it/s]Train epoch: 11 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002132\n",
      "1000it [03:02,  5.30it/s]Train epoch: 11 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.002909\n",
      "1025it [03:07,  5.33it/s]Train epoch: 11 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.003987\n",
      "1050it [03:11,  5.32it/s]Train epoch: 11 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.002600\n",
      "1075it [03:16,  5.22it/s]Train epoch: 11 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.002933\n",
      "1100it [03:21,  5.26it/s]Train epoch: 11 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.003012\n",
      "1125it [03:25,  5.31it/s]Train epoch: 11 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.003048\n",
      "1150it [03:30,  5.29it/s]Train epoch: 11 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.003051\n",
      "1175it [03:35,  5.30it/s]Train epoch: 11 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.002884\n",
      "1200it [03:40,  5.26it/s]Train epoch: 11 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.003062\n",
      "1225it [03:44,  5.29it/s]Train epoch: 11 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.003154\n",
      "1250it [03:49,  5.27it/s]Train epoch: 11 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003039\n",
      "1275it [03:54,  5.29it/s]Train epoch: 11 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.002573\n",
      "1300it [03:59,  5.18it/s]Train epoch: 11 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.002568\n",
      "1325it [04:03,  5.26it/s]Train epoch: 11 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.002626\n",
      "1350it [04:08,  5.22it/s]Train epoch: 11 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.003500\n",
      "1375it [04:13,  5.26it/s]Train epoch: 11 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.002856\n",
      "1400it [04:18,  5.25it/s]Train epoch: 11 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.002884\n",
      "1425it [04:22,  5.21it/s]Train epoch: 11 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.002598\n",
      "1450it [04:27,  5.24it/s]Train epoch: 11 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.002822\n",
      "1475it [04:32,  5.22it/s]Train epoch: 11 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.002810\n",
      "1500it [04:37,  5.16it/s]Train epoch: 11 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.003957\n",
      "1525it [04:42,  5.23it/s]Train epoch: 11 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.003691\n",
      "1550it [04:46,  5.22it/s]Train epoch: 11 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.002685\n",
      "1575it [04:51,  5.22it/s]Train epoch: 11 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.003071\n",
      "1600it [04:56,  5.17it/s]Train epoch: 11 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.002552\n",
      "1625it [05:01,  5.21it/s]Train epoch: 11 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.003161\n",
      "1650it [05:06,  5.19it/s]Train epoch: 11 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.003152\n",
      "1675it [05:11,  5.20it/s]Train epoch: 11 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.003147\n",
      "1700it [05:15,  5.20it/s]Train epoch: 11 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.002683\n",
      "1725it [05:20,  5.19it/s]Train epoch: 11 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.002402\n",
      "1750it [05:25,  5.20it/s]Train epoch: 11 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.003656\n",
      "1775it [05:30,  5.18it/s]Train epoch: 11 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.002930\n",
      "1800it [05:35,  5.18it/s]Train epoch: 11 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.002780\n",
      "1825it [05:40,  5.09it/s]Train epoch: 11 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.002397\n",
      "1850it [05:44,  5.07it/s]Train epoch: 11 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.003046\n",
      "1875it [05:49,  5.17it/s]Train epoch: 11 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.003236\n",
      "1900it [05:54,  5.17it/s]Train epoch: 11 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.002338\n",
      "1925it [05:59,  5.16it/s]Train epoch: 11 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.002604\n",
      "1950it [06:04,  5.15it/s]Train epoch: 11 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.002448\n",
      "1975it [06:09,  5.15it/s]Train epoch: 11 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.003223\n",
      "2000it [06:13,  5.15it/s]Train epoch: 11 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.002450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025it [06:18,  5.10it/s]Train epoch: 11 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.002976\n",
      "2050it [06:23,  5.16it/s]Train epoch: 11 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.002846\n",
      "2075it [06:28,  5.10it/s]Train epoch: 11 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.002977\n",
      "2100it [06:33,  5.13it/s]Train epoch: 11 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.003074\n",
      "2125it [06:38,  5.06it/s]Train epoch: 11 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.003376\n",
      "2150it [06:43,  5.04it/s]Train epoch: 11 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.002843\n",
      "2175it [06:48,  5.12it/s]Train epoch: 11 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.003170\n",
      "2200it [06:53,  5.12it/s]Train epoch: 11 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.002965\n",
      "2225it [06:57,  5.13it/s]Train epoch: 11 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.002885\n",
      "2250it [07:02,  5.12it/s]Train epoch: 11 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.002547\n",
      "2275it [07:07,  5.11it/s]Train epoch: 11 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.002989\n",
      "2300it [07:12,  5.09it/s]Train epoch: 11 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.002272\n",
      "2325it [07:17,  5.10it/s]Train epoch: 11 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.002823\n",
      "2350it [07:22,  5.00it/s]Train epoch: 11 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.002731\n",
      "2375it [07:27,  5.06it/s]Train epoch: 11 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.003848\n",
      "2400it [07:32,  5.08it/s]Train epoch: 11 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.003522\n",
      "2425it [07:37,  5.09it/s]Train epoch: 11 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.002551\n",
      "2450it [07:42,  5.02it/s]Train epoch: 11 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.002865\n",
      "2475it [07:47,  5.07it/s]Train epoch: 11 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.003312\n",
      "2500it [07:52,  5.04it/s]Train epoch: 11 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.002778\n",
      "2525it [07:57,  5.09it/s]Train epoch: 11 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.002706\n",
      "2550it [08:02,  5.07it/s]Train epoch: 11 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.003857\n",
      "2575it [08:07,  5.03it/s]Train epoch: 11 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.002719\n",
      "2600it [08:11,  5.08it/s]Train epoch: 11 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.002992\n",
      "2625it [08:16,  5.07it/s]Train epoch: 11 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.003016\n",
      "2650it [08:21,  5.00it/s]Train epoch: 11 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.003524\n",
      "2675it [08:26,  5.06it/s]Train epoch: 11 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.003035\n",
      "2700it [08:31,  5.04it/s]Train epoch: 11 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.002785\n",
      "2725it [08:36,  5.06it/s]Train epoch: 11 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.002880\n",
      "2750it [08:41,  5.03it/s]Train epoch: 11 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.003450\n",
      "2775it [08:46,  4.98it/s]Train epoch: 11 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.002961\n",
      "2800it [08:51,  4.94it/s]Train epoch: 11 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.002833\n",
      "2825it [08:56,  4.92it/s]Train epoch: 11 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.003219\n",
      "2850it [09:01,  5.02it/s]Train epoch: 11 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.002835\n",
      "2875it [09:06,  5.04it/s]Train epoch: 11 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.003239\n",
      "2900it [09:11,  4.98it/s]Train epoch: 11 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.003197\n",
      "2925it [09:16,  4.98it/s]Train epoch: 11 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.003265\n",
      "2950it [09:21,  5.03it/s]Train epoch: 11 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.003474\n",
      "2975it [09:26,  4.98it/s]Train epoch: 11 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.003093\n",
      "3000it [09:31,  4.99it/s]Train epoch: 11 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.003636\n",
      "3025it [09:36,  5.01it/s]Train epoch: 11 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.003181\n",
      "3050it [09:41,  5.01it/s]Train epoch: 11 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.002841\n",
      "3075it [09:46,  4.99it/s]Train epoch: 11 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.003383\n",
      "3100it [09:51,  4.97it/s]Train epoch: 11 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.003333\n",
      "3125it [09:56,  5.00it/s]Train epoch: 11 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.002915\n",
      "3150it [10:01,  4.99it/s]Train epoch: 11 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.002935\n",
      "3175it [10:07,  4.98it/s]Train epoch: 11 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.002948\n",
      "3200it [10:12,  4.97it/s]Train epoch: 11 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.003477\n",
      "3225it [10:17,  4.91it/s]Train epoch: 11 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.003328\n",
      "3250it [10:22,  4.95it/s]Train epoch: 11 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.003337\n",
      "3275it [10:27,  4.92it/s]Train epoch: 11 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.002957\n",
      "3300it [10:32,  4.93it/s]Train epoch: 11 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.003719\n",
      "3325it [10:37,  4.89it/s]Train epoch: 11 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.003215\n",
      "3350it [10:42,  4.95it/s]Train epoch: 11 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.003264\n",
      "3375it [10:47,  4.88it/s]Train epoch: 11 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.003491\n",
      "3400it [10:52,  4.96it/s]Train epoch: 11 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.003460\n",
      "3425it [10:57,  4.95it/s]Train epoch: 11 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.002984\n",
      "3450it [11:02,  4.96it/s]Train epoch: 11 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.003360\n",
      "3475it [11:07,  4.94it/s]Train epoch: 11 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.002909\n",
      "3500it [11:12,  4.96it/s]Train epoch: 11 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.003127\n",
      "3525it [11:17,  4.91it/s]Train epoch: 11 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.003245\n",
      "3550it [11:22,  4.89it/s]Train epoch: 11 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.003353\n",
      "3575it [11:28,  4.84it/s]Train epoch: 11 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.002815\n",
      "3600it [11:33,  4.79it/s]Train epoch: 11 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.003605\n",
      "3625it [11:38,  4.83it/s]Train epoch: 11 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.003215\n",
      "3650it [11:43,  4.90it/s]Train epoch: 11 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.003477\n",
      "3675it [11:48,  4.84it/s]Train epoch: 11 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.003394\n",
      "3700it [11:53,  4.78it/s]Train epoch: 11 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.003277\n",
      "3725it [11:59,  4.91it/s]Train epoch: 11 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.003407\n",
      "3750it [12:04,  4.85it/s]Train epoch: 11 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.003537\n",
      "3775it [12:09,  4.83it/s]Train epoch: 11 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.003218\n",
      "3800it [12:14,  4.88it/s]Train epoch: 11 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.003655\n",
      "3825it [12:19,  4.86it/s]Train epoch: 11 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.003103\n",
      "3850it [12:24,  4.86it/s]Train epoch: 11 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.002799\n",
      "3875it [12:29,  4.84it/s]Train epoch: 11 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.002855\n",
      "3900it [12:35,  4.81it/s]Train epoch: 11 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.003765\n",
      "3925it [12:40,  4.76it/s]Train epoch: 11 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.003361\n",
      "3950it [12:45,  4.76it/s]Train epoch: 11 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.003715\n",
      "3975it [12:50,  4.76it/s]Train epoch: 11 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.004123\n",
      "4000it [12:56,  4.81it/s]Train epoch: 11 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.002944\n",
      "4025it [13:01,  4.88it/s]Train epoch: 11 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.003878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4050it [13:06,  4.85it/s]Train epoch: 11 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.003491\n",
      "4075it [13:11,  4.86it/s]Train epoch: 11 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.003472\n",
      "4100it [13:16,  4.76it/s]Train epoch: 11 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.003840\n",
      "4125it [13:22,  4.84it/s]Train epoch: 11 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.003558\n",
      "4150it [13:27,  4.77it/s]Train epoch: 11 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.003312\n",
      "4175it [13:32,  4.71it/s]Train epoch: 11 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.003268\n",
      "4200it [13:37,  4.79it/s]Train epoch: 11 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.003645\n",
      "4225it [13:42,  4.84it/s]Train epoch: 11 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.003147\n",
      "4250it [13:48,  4.82it/s]Train epoch: 11 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.003416\n",
      "4275it [13:53,  4.70it/s]Train epoch: 11 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.003224\n",
      "4300it [13:58,  4.79it/s]Train epoch: 11 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.003888\n",
      "4325it [14:03,  4.56it/s]Train epoch: 11 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.003443\n",
      "4350it [14:09,  4.63it/s]Train epoch: 11 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.003789\n",
      "4375it [14:14,  4.53it/s]Train epoch: 11 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.003331\n",
      "4400it [14:20,  4.61it/s]Train epoch: 11 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.002813\n",
      "4425it [14:25,  4.57it/s]Train epoch: 11 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.003578\n",
      "4450it [14:31,  4.59it/s]Train epoch: 11 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.002954\n",
      "4475it [14:36,  4.62it/s]Train epoch: 11 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.003560\n",
      "4500it [14:42,  4.57it/s]Train epoch: 11 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.004165\n",
      "4525it [14:47,  4.62it/s]Train epoch: 11 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.003491\n",
      "4550it [14:52,  4.56it/s]Train epoch: 11 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.003386\n",
      "4575it [14:58,  4.49it/s]Train epoch: 11 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.003766\n",
      "4600it [15:03,  4.56it/s]Train epoch: 11 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.003033\n",
      "4625it [15:09,  4.62it/s]Train epoch: 11 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.003249\n",
      "4650it [15:14,  4.49it/s]Train epoch: 11 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.003753\n",
      "4675it [15:20,  4.56it/s]Train epoch: 11 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.003645\n",
      "4700it [15:25,  4.50it/s]Train epoch: 11 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.003223\n",
      "4725it [15:31,  4.54it/s]Train epoch: 11 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.003394\n",
      "4750it [15:36,  4.58it/s]Train epoch: 11 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.004070\n",
      "4775it [15:42,  4.55it/s]Train epoch: 11 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.003531\n",
      "4800it [15:47,  4.59it/s]Train epoch: 11 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.003579\n",
      "4825it [15:53,  4.44it/s]Train epoch: 11 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.003221\n",
      "4850it [15:58,  4.54it/s]Train epoch: 11 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.003806\n",
      "4875it [16:04,  4.50it/s]Train epoch: 11 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.003341\n",
      "4900it [16:09,  4.51it/s]Train epoch: 11 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.003385\n",
      "4925it [16:15,  4.53it/s]Train epoch: 11 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.003208\n",
      "4950it [16:20,  4.55it/s]Train epoch: 11 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.003382\n",
      "4975it [16:26,  4.53it/s]Train epoch: 11 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.003397\n",
      "5000it [16:31,  4.49it/s]Train epoch: 11 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.003477\n",
      "5025it [16:37,  4.56it/s]Train epoch: 11 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.003317\n",
      "5050it [16:42,  4.56it/s]Train epoch: 11 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.003225\n",
      "5075it [16:48,  4.48it/s]Train epoch: 11 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.003514\n",
      "5100it [16:54,  4.58it/s]Train epoch: 11 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.003596\n",
      "5125it [16:59,  4.50it/s]Train epoch: 11 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.003749\n",
      "5150it [17:05,  4.52it/s]Train epoch: 11 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.003691\n",
      "5175it [17:10,  4.52it/s]Train epoch: 11 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.003487\n",
      "5200it [17:16,  4.51it/s]Train epoch: 11 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.003297\n",
      "5225it [17:21,  4.53it/s]Train epoch: 11 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.003521\n",
      "5250it [17:27,  4.51it/s]Train epoch: 11 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.003603\n",
      "5275it [17:32,  4.55it/s]Train epoch: 11 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.003349\n",
      "5300it [17:38,  4.53it/s]Train epoch: 11 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.003174\n",
      "5325it [17:43,  4.44it/s]Train epoch: 11 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.003807\n",
      "5350it [17:49,  4.49it/s]Train epoch: 11 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.003799\n",
      "5375it [17:54,  4.50it/s]Train epoch: 11 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.003375\n",
      "5400it [18:00,  4.56it/s]Train epoch: 11 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.003351\n",
      "5425it [18:06,  4.47it/s]Train epoch: 11 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.003689\n",
      "5450it [18:11,  4.44it/s]Train epoch: 11 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.003586\n",
      "5475it [18:17,  4.47it/s]Train epoch: 11 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.004290\n",
      "5500it [18:22,  4.49it/s]Train epoch: 11 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.003835\n",
      "5525it [18:28,  4.57it/s]Train epoch: 11 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.003280\n",
      "5550it [18:34,  4.49it/s]Train epoch: 11 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.003630\n",
      "5575it [18:39,  4.46it/s]Train epoch: 11 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.003759\n",
      "5600it [18:45,  4.47it/s]Train epoch: 11 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.003961\n",
      "5625it [18:50,  4.48it/s]Train epoch: 11 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.003649\n",
      "5650it [18:56,  4.54it/s]Train epoch: 11 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.003320\n",
      "5675it [19:01,  4.47it/s]Train epoch: 11 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.004103\n",
      "5700it [19:07,  4.49it/s]Train epoch: 11 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.003537\n",
      "5725it [19:12,  4.48it/s]Train epoch: 11 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.003622\n",
      "5750it [19:18,  4.56it/s]Train epoch: 11 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.004839\n",
      "5775it [19:24,  4.50it/s]Train epoch: 11 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.003796\n",
      "5800it [19:29,  4.48it/s]Train epoch: 11 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.003865\n",
      "5825it [19:35,  4.51it/s]Train epoch: 11 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.003408\n",
      "5850it [19:40,  4.43it/s]Train epoch: 11 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.004475\n",
      "5875it [19:46,  4.53it/s]Train epoch: 11 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.004079\n",
      "5900it [19:52,  4.52it/s]Train epoch: 11 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.004047\n",
      "5925it [19:57,  4.40it/s]Train epoch: 11 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.003589\n",
      "5950it [20:03,  4.44it/s]Train epoch: 11 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.003330\n",
      "5975it [20:08,  4.41it/s]Train epoch: 11 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.004837\n",
      "6000it [20:14,  4.48it/s]Train epoch: 11 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.004000\n",
      "6025it [20:20,  4.40it/s]Train epoch: 11 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.004227\n",
      "6050it [20:25,  4.39it/s]Train epoch: 11 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.003591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6075it [20:31,  4.36it/s]Train epoch: 11 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.003497\n",
      "6100it [20:37,  4.45it/s]Train epoch: 11 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.003253\n",
      "6125it [20:42,  4.42it/s]Train epoch: 11 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.003704\n",
      "6150it [20:48,  4.45it/s]Train epoch: 11 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.003782\n",
      "6175it [20:54,  4.41it/s]Train epoch: 11 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.004226\n",
      "6200it [20:59,  4.38it/s]Train epoch: 11 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.003828\n",
      "6225it [21:05,  4.40it/s]Train epoch: 11 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.003194\n",
      "6250it [21:11,  4.40it/s]Train epoch: 11 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.003422\n",
      "6275it [21:16,  4.39it/s]Train epoch: 11 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.003145\n",
      "6300it [21:22,  4.43it/s]Train epoch: 11 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.003652\n",
      "6325it [21:28,  4.52it/s]Train epoch: 11 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.004103\n",
      "6350it [21:33,  4.41it/s]Train epoch: 11 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.004280\n",
      "6375it [21:39,  4.37it/s]Train epoch: 11 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.003230\n",
      "6400it [21:45,  4.43it/s]Train epoch: 11 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.003724\n",
      "6425it [21:51,  4.32it/s]Train epoch: 11 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.004048\n",
      "6450it [21:56,  4.43it/s]Train epoch: 11 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.004084\n",
      "6475it [22:02,  4.38it/s]Train epoch: 11 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.003580\n",
      "6500it [22:08,  4.34it/s]Train epoch: 11 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.004170\n",
      "6525it [22:13,  4.35it/s]Train epoch: 11 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.003484\n",
      "6550it [22:19,  4.35it/s]Train epoch: 11 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.003699\n",
      "6575it [22:25,  4.29it/s]Train epoch: 11 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.003784\n",
      "6600it [22:31,  4.26it/s]Train epoch: 11 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.004558\n",
      "6625it [22:36,  4.35it/s]Train epoch: 11 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.003698\n",
      "6650it [22:42,  4.28it/s]Train epoch: 11 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.004246\n",
      "6675it [22:48,  4.39it/s]Train epoch: 11 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.003804\n",
      "6700it [22:54,  4.31it/s]Train epoch: 11 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.004005\n",
      "6725it [22:59,  4.42it/s]Train epoch: 11 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.003980\n",
      "6750it [23:05,  4.33it/s]Train epoch: 11 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.003618\n",
      "6775it [23:11,  4.37it/s]Train epoch: 11 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.004283\n",
      "6800it [23:17,  4.35it/s]Train epoch: 11 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.004241\n",
      "6825it [23:23,  4.32it/s]Train epoch: 11 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.004126\n",
      "6850it [23:28,  4.30it/s]Train epoch: 11 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.004011\n",
      "6875it [23:34,  4.29it/s]Train epoch: 11 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.003272\n",
      "6900it [23:40,  4.28it/s]Train epoch: 11 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.003863\n",
      "6925it [23:46,  4.24it/s]Train epoch: 11 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.003934\n",
      "6950it [23:52,  4.33it/s]Train epoch: 11 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.004368\n",
      "6975it [23:57,  4.34it/s]Train epoch: 11 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.004018\n",
      "7000it [24:03,  4.31it/s]Train epoch: 11 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.003683\n",
      "7025it [24:09,  4.22it/s]Train epoch: 11 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.004516\n",
      "7050it [24:15,  4.31it/s]Train epoch: 11 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.003452\n",
      "7075it [24:20,  4.37it/s]Train epoch: 11 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.003983\n",
      "7100it [24:26,  4.30it/s]Train epoch: 11 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.004043\n",
      "7125it [24:32,  4.23it/s]Train epoch: 11 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.003552\n",
      "7150it [24:38,  4.29it/s]Train epoch: 11 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.004430\n",
      "7175it [24:44,  4.27it/s]Train epoch: 11 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.004060\n",
      "7200it [24:50,  4.27it/s]Train epoch: 11 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.004359\n",
      "7225it [24:55,  4.30it/s]Train epoch: 11 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.003880\n",
      "7250it [25:01,  4.29it/s]Train epoch: 11 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.003836\n",
      "7275it [25:07,  4.27it/s]Train epoch: 11 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.004396\n",
      "7300it [25:13,  4.26it/s]Train epoch: 11 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.004683\n",
      "7325it [25:19,  4.29it/s]Train epoch: 11 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.003739\n",
      "7350it [25:25,  4.27it/s]Train epoch: 11 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.004595\n",
      "7375it [25:30,  4.26it/s]Train epoch: 11 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.004252\n",
      "7400it [25:36,  4.28it/s]Train epoch: 11 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.003869\n",
      "7425it [25:42,  4.27it/s]Train epoch: 11 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.004239\n",
      "7450it [25:48,  4.28it/s]Train epoch: 11 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.004569\n",
      "7475it [25:54,  4.23it/s]Train epoch: 11 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.003951\n",
      "7500it [26:00,  4.25it/s]Train epoch: 11 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.004269\n",
      "7525it [26:06,  4.32it/s]Train epoch: 11 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.004065\n",
      "7550it [26:12,  4.21it/s]Train epoch: 11 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.003905\n",
      "7575it [26:17,  4.29it/s]Train epoch: 11 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.004293\n",
      "7600it [26:23,  4.25it/s]Train epoch: 11 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.005151\n",
      "7625it [26:29,  4.21it/s]Train epoch: 11 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.004884\n",
      "7650it [26:35,  4.16it/s]Train epoch: 11 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.004044\n",
      "7675it [26:41,  4.20it/s]Train epoch: 11 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.003873\n",
      "7700it [26:47,  4.23it/s]Train epoch: 11 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.004104\n",
      "7725it [26:53,  4.21it/s]Train epoch: 11 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.004211\n",
      "7750it [26:59,  4.21it/s]Train epoch: 11 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.004475\n",
      "7775it [27:05,  4.20it/s]Train epoch: 11 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.003855\n",
      "7800it [27:11,  4.22it/s]Train epoch: 11 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.004026\n",
      "7825it [27:16,  4.22it/s]Train epoch: 11 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.004286\n",
      "7850it [27:22,  4.20it/s]Train epoch: 11 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.003829\n",
      "7875it [27:28,  4.23it/s]Train epoch: 11 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.004090\n",
      "7900it [27:34,  4.18it/s]Train epoch: 11 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.004135\n",
      "7925it [27:40,  4.24it/s]Train epoch: 11 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.004240\n",
      "7950it [27:46,  4.25it/s]Train epoch: 11 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.004699\n",
      "7975it [27:52,  4.29it/s]Train epoch: 11 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.003881\n",
      "8000it [27:58,  4.16it/s]Train epoch: 11 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.003936\n",
      "8025it [28:04,  4.15it/s]Train epoch: 11 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.004345\n",
      "8050it [28:10,  4.17it/s]Train epoch: 11 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.003646\n",
      "8075it [28:16,  4.14it/s]Train epoch: 11 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.004174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100it [28:22,  4.17it/s]Train epoch: 11 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.004446\n",
      "8125it [28:28,  4.18it/s]Train epoch: 11 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.004571\n",
      "8150it [28:34,  4.19it/s]Train epoch: 11 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.003959\n",
      "8175it [28:40,  4.20it/s]Train epoch: 11 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.004496\n",
      "8200it [28:46,  4.16it/s]Train epoch: 11 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.003846\n",
      "8225it [28:52,  4.13it/s]Train epoch: 11 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.005228\n",
      "8250it [28:58,  4.17it/s]Train epoch: 11 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.003905\n",
      "8275it [29:04,  4.17it/s]Train epoch: 11 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.004649\n",
      "8300it [29:10,  4.18it/s]Train epoch: 11 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.003920\n",
      "8325it [29:16,  4.15it/s]Train epoch: 11 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.004530\n",
      "8350it [29:22,  4.12it/s]Train epoch: 11 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.003993\n",
      "8375it [29:28,  4.13it/s]Train epoch: 11 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.004548\n",
      "8400it [29:34,  4.08it/s]Train epoch: 11 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.004165\n",
      "8425it [29:41,  4.09it/s]Train epoch: 11 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.004187\n",
      "8450it [29:47,  4.14it/s]Train epoch: 11 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.004565\n",
      "8475it [29:53,  4.05it/s]Train epoch: 11 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.004236\n",
      "8500it [29:59,  4.07it/s]Train epoch: 11 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.005012\n",
      "8525it [30:05,  4.04it/s]Train epoch: 11 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.004089\n",
      "8550it [30:11,  4.13it/s]Train epoch: 11 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.004455\n",
      "8575it [30:17,  4.13it/s]Train epoch: 11 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.004100\n",
      "8600it [30:23,  4.15it/s]Train epoch: 11 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.004275\n",
      "8625it [30:29,  4.12it/s]Train epoch: 11 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.004391\n",
      "8650it [30:35,  4.10it/s]Train epoch: 11 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.004612\n",
      "8675it [30:41,  4.06it/s]Train epoch: 11 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.005038\n",
      "8700it [30:48,  3.99it/s]Train epoch: 11 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.005137\n",
      "8725it [30:54,  4.09it/s]Train epoch: 11 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.004873\n",
      "8750it [31:00,  4.02it/s]Train epoch: 11 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.004546\n",
      "8775it [31:06,  4.02it/s]Train epoch: 11 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.004192\n",
      "8800it [31:12,  4.01it/s]Train epoch: 11 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.004391\n",
      "8825it [31:19,  4.05it/s]Train epoch: 11 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.004378\n",
      "8850it [31:25,  4.03it/s]Train epoch: 11 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.004603\n",
      "8875it [31:31,  3.98it/s]Train epoch: 11 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.004393\n",
      "8900it [31:37,  3.99it/s]Train epoch: 11 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.004411\n",
      "8925it [31:43,  3.94it/s]Train epoch: 11 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.004657\n",
      "8950it [31:50,  4.01it/s]Train epoch: 11 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.005189\n",
      "8975it [31:56,  4.10it/s]Train epoch: 11 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.004695\n",
      "9000it [32:02,  4.05it/s]Train epoch: 11 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.004462\n",
      "9025it [32:08,  4.03it/s]Train epoch: 11 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.004630\n",
      "9050it [32:14,  4.03it/s]Train epoch: 11 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.004142\n",
      "9075it [32:21,  4.04it/s]Train epoch: 11 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.003928\n",
      "9100it [32:27,  4.03it/s]Train epoch: 11 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.004730\n",
      "9125it [32:33,  4.00it/s]Train epoch: 11 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.004156\n",
      "9150it [32:39,  4.01it/s]Train epoch: 11 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.004026\n",
      "9175it [32:46,  3.98it/s]Train epoch: 11 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.004301\n",
      "9200it [32:52,  3.96it/s]Train epoch: 11 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.004277\n",
      "9225it [32:58,  4.03it/s]Train epoch: 11 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.005048\n",
      "9250it [33:04,  4.01it/s]Train epoch: 11 [batch #9250, batch_size 4, seq length 2500]\tLoss: 0.004484\n",
      "9275it [33:11,  3.95it/s]Train epoch: 11 [batch #9275, batch_size 4, seq length 2500]\tLoss: 0.004739\n",
      "9300it [33:17,  4.00it/s]Train epoch: 11 [batch #9300, batch_size 4, seq length 2500]\tLoss: 0.005410\n",
      "9325it [33:23,  3.94it/s]Train epoch: 11 [batch #9325, batch_size 4, seq length 2500]\tLoss: 0.005108\n",
      "9350it [33:30,  3.97it/s]Train epoch: 11 [batch #9350, batch_size 4, seq length 2500]\tLoss: 0.004880\n",
      "9375it [33:36,  3.97it/s]Train epoch: 11 [batch #9375, batch_size 4, seq length 2500]\tLoss: 0.004286\n",
      "9400it [33:42,  3.94it/s]Train epoch: 11 [batch #9400, batch_size 4, seq length 2500]\tLoss: 0.004713\n",
      "9425it [33:49,  3.99it/s]Train epoch: 11 [batch #9425, batch_size 4, seq length 2500]\tLoss: 0.004484\n",
      "9450it [33:55,  3.97it/s]Train epoch: 11 [batch #9450, batch_size 4, seq length 2500]\tLoss: 0.004326\n",
      "9475it [34:01,  3.95it/s]Train epoch: 11 [batch #9475, batch_size 4, seq length 2500]\tLoss: 0.005083\n",
      "9500it [34:08,  3.93it/s]Train epoch: 11 [batch #9500, batch_size 4, seq length 2500]\tLoss: 0.004638\n",
      "9525it [34:14,  3.95it/s]Train epoch: 11 [batch #9525, batch_size 4, seq length 2500]\tLoss: 0.005236\n",
      "9550it [34:20,  3.91it/s]Train epoch: 11 [batch #9550, batch_size 4, seq length 2500]\tLoss: 0.004867\n",
      "9575it [34:27,  3.96it/s]Train epoch: 11 [batch #9575, batch_size 4, seq length 2500]\tLoss: 0.004975\n",
      "9600it [34:33,  3.92it/s]Train epoch: 11 [batch #9600, batch_size 4, seq length 2500]\tLoss: 0.004841\n",
      "9625it [34:39,  3.92it/s]Train epoch: 11 [batch #9625, batch_size 4, seq length 2500]\tLoss: 0.004558\n",
      "9650it [34:46,  3.91it/s]Train epoch: 11 [batch #9650, batch_size 4, seq length 2500]\tLoss: 0.004368\n",
      "9675it [34:52,  3.90it/s]Train epoch: 11 [batch #9675, batch_size 4, seq length 2500]\tLoss: 0.004887\n",
      "9700it [34:59,  3.88it/s]Train epoch: 11 [batch #9700, batch_size 4, seq length 2500]\tLoss: 0.004317\n",
      "9725it [35:05,  3.90it/s]Train epoch: 11 [batch #9725, batch_size 4, seq length 2500]\tLoss: 0.004696\n",
      "9750it [35:11,  3.91it/s]Train epoch: 11 [batch #9750, batch_size 4, seq length 2500]\tLoss: 0.004854\n",
      "9775it [35:18,  3.86it/s]Train epoch: 11 [batch #9775, batch_size 4, seq length 2500]\tLoss: 0.005373\n",
      "9800it [35:24,  3.90it/s]Train epoch: 11 [batch #9800, batch_size 4, seq length 2500]\tLoss: 0.005089\n",
      "9825it [35:31,  3.92it/s]Train epoch: 11 [batch #9825, batch_size 4, seq length 2500]\tLoss: 0.005167\n",
      "9850it [35:37,  3.88it/s]Train epoch: 11 [batch #9850, batch_size 4, seq length 2500]\tLoss: 0.004756\n",
      "9875it [35:44,  3.88it/s]Train epoch: 11 [batch #9875, batch_size 4, seq length 2500]\tLoss: 0.005056\n",
      "9900it [35:50,  3.89it/s]Train epoch: 11 [batch #9900, batch_size 4, seq length 2500]\tLoss: 0.005492\n",
      "9925it [35:57,  3.85it/s]Train epoch: 11 [batch #9925, batch_size 4, seq length 2500]\tLoss: 0.005219\n",
      "9950it [36:03,  3.84it/s]Train epoch: 11 [batch #9950, batch_size 4, seq length 2500]\tLoss: 0.005653\n",
      "9975it [36:09,  3.83it/s]Train epoch: 11 [batch #9975, batch_size 4, seq length 2500]\tLoss: 0.005112\n",
      "10000it [36:16,  3.85it/s]Train epoch: 11 [batch #10000, batch_size 4, seq length 2500]\tLoss: 0.004883\n",
      "10025it [36:23,  3.84it/s]Train epoch: 11 [batch #10025, batch_size 4, seq length 2500]\tLoss: 0.004841\n",
      "10050it [36:29,  3.82it/s]Train epoch: 11 [batch #10050, batch_size 4, seq length 2500]\tLoss: 0.005105\n",
      "10075it [36:36,  3.78it/s]Train epoch: 11 [batch #10075, batch_size 4, seq length 2500]\tLoss: 0.005590\n",
      "10100it [36:42,  3.79it/s]Train epoch: 11 [batch #10100, batch_size 4, seq length 2500]\tLoss: 0.005271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10125it [36:49,  3.85it/s]Train epoch: 11 [batch #10125, batch_size 4, seq length 2500]\tLoss: 0.004710\n",
      "10150it [36:55,  3.80it/s]Train epoch: 11 [batch #10150, batch_size 4, seq length 2500]\tLoss: 0.005225\n",
      "10175it [37:02,  3.75it/s]Train epoch: 11 [batch #10175, batch_size 4, seq length 2500]\tLoss: 0.004900\n",
      "10200it [37:09,  3.69it/s]Train epoch: 11 [batch #10200, batch_size 4, seq length 2500]\tLoss: 0.005363\n",
      "10225it [37:15,  3.78it/s]Train epoch: 11 [batch #10225, batch_size 4, seq length 2500]\tLoss: 0.005253\n",
      "10250it [37:22,  3.77it/s]Train epoch: 11 [batch #10250, batch_size 4, seq length 2500]\tLoss: 0.005697\n",
      "10275it [37:28,  3.73it/s]Train epoch: 11 [batch #10275, batch_size 4, seq length 2500]\tLoss: 0.004983\n",
      "10300it [37:35,  3.75it/s]Train epoch: 11 [batch #10300, batch_size 4, seq length 2500]\tLoss: 0.005481\n",
      "10325it [37:42,  3.72it/s]Train epoch: 11 [batch #10325, batch_size 4, seq length 2500]\tLoss: 0.005600\n",
      "10350it [37:48,  3.74it/s]Train epoch: 11 [batch #10350, batch_size 4, seq length 2500]\tLoss: 0.005054\n",
      "10375it [37:55,  3.74it/s]Train epoch: 11 [batch #10375, batch_size 4, seq length 2500]\tLoss: 0.005498\n",
      "10400it [38:02,  3.83it/s]Train epoch: 11 [batch #10400, batch_size 4, seq length 2500]\tLoss: 0.005215\n",
      "10425it [38:08,  3.72it/s]Train epoch: 11 [batch #10425, batch_size 4, seq length 2500]\tLoss: 0.004996\n",
      "10450it [38:15,  3.72it/s]Train epoch: 11 [batch #10450, batch_size 4, seq length 2500]\tLoss: 0.005310\n",
      "10475it [38:22,  3.76it/s]Train epoch: 11 [batch #10475, batch_size 4, seq length 2500]\tLoss: 0.004588\n",
      "10500it [38:28,  3.74it/s]Train epoch: 11 [batch #10500, batch_size 4, seq length 2500]\tLoss: 0.005399\n",
      "10525it [38:35,  3.72it/s]Train epoch: 11 [batch #10525, batch_size 4, seq length 2500]\tLoss: 0.005141\n",
      "10550it [38:42,  3.72it/s]Train epoch: 11 [batch #10550, batch_size 4, seq length 2500]\tLoss: 0.005301\n",
      "10575it [38:49,  3.70it/s]Train epoch: 11 [batch #10575, batch_size 4, seq length 2500]\tLoss: 0.004668\n",
      "10600it [38:55,  3.77it/s]Train epoch: 11 [batch #10600, batch_size 4, seq length 2500]\tLoss: 0.004971\n",
      "10625it [39:02,  3.67it/s]Train epoch: 11 [batch #10625, batch_size 4, seq length 2500]\tLoss: 0.005567\n",
      "10650it [39:09,  3.70it/s]Train epoch: 11 [batch #10650, batch_size 4, seq length 2500]\tLoss: 0.005164\n",
      "10675it [39:15,  3.67it/s]Train epoch: 11 [batch #10675, batch_size 4, seq length 2500]\tLoss: 0.005444\n",
      "10700it [39:22,  3.72it/s]Train epoch: 11 [batch #10700, batch_size 4, seq length 2500]\tLoss: 0.005170\n",
      "10725it [39:29,  3.68it/s]Train epoch: 11 [batch #10725, batch_size 4, seq length 2500]\tLoss: 0.004778\n",
      "10750it [39:36,  3.69it/s]Train epoch: 11 [batch #10750, batch_size 4, seq length 2500]\tLoss: 0.005481\n",
      "10775it [39:43,  3.66it/s]Train epoch: 11 [batch #10775, batch_size 4, seq length 2500]\tLoss: 0.005524\n",
      "10800it [39:49,  3.65it/s]Train epoch: 11 [batch #10800, batch_size 4, seq length 2500]\tLoss: 0.005835\n",
      "10825it [39:56,  3.62it/s]Train epoch: 11 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.005663\n",
      "10850it [40:03,  3.65it/s]Train epoch: 11 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.005700\n",
      "10875it [40:10,  3.66it/s]Train epoch: 11 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.005711\n",
      "10900it [40:17,  3.62it/s]Train epoch: 11 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.005547\n",
      "10925it [40:24,  3.62it/s]Train epoch: 11 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.004966\n",
      "10950it [40:31,  3.59it/s]Train epoch: 11 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.005431\n",
      "10975it [40:38,  3.58it/s]Train epoch: 11 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.005254\n",
      "11000it [40:45,  3.57it/s]Train epoch: 11 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.005319\n",
      "11025it [40:52,  3.60it/s]Train epoch: 11 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.005401\n",
      "11050it [40:59,  3.55it/s]Train epoch: 11 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.006066\n",
      "11075it [41:06,  3.61it/s]Train epoch: 11 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.005657\n",
      "11100it [41:13,  3.58it/s]Train epoch: 11 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.006132\n",
      "11125it [41:20,  3.55it/s]Train epoch: 11 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.005800\n",
      "11150it [41:27,  3.55it/s]Train epoch: 11 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.005575\n",
      "11175it [41:34,  3.50it/s]Train epoch: 11 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.006503\n",
      "11200it [41:41,  3.55it/s]Train epoch: 11 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.005920\n",
      "11225it [41:48,  3.50it/s]Train epoch: 11 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.005786\n",
      "11250it [41:55,  3.44it/s]Train epoch: 11 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.006488\n",
      "11275it [42:02,  3.47it/s]Train epoch: 11 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.006106\n",
      "11300it [42:10,  3.50it/s]Train epoch: 11 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.005552\n",
      "11325it [42:17,  3.44it/s]Train epoch: 11 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.006746\n",
      "11350it [42:24,  3.41it/s]Train epoch: 11 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.006565\n",
      "11375it [42:31,  3.45it/s]Train epoch: 11 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.006636\n",
      "11400it [42:39,  3.41it/s]Train epoch: 11 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.005892\n",
      "11425it [42:46,  3.44it/s]Train epoch: 11 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.006484\n",
      "11450it [42:53,  3.41it/s]Train epoch: 11 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.005782\n",
      "11475it [43:01,  3.37it/s]Train epoch: 11 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.006880\n",
      "11500it [43:08,  3.36it/s]Train epoch: 11 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.006595\n",
      "11525it [43:16,  3.32it/s]Train epoch: 11 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006028\n",
      "11550it [43:23,  3.32it/s]Train epoch: 11 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.005952\n",
      "11575it [43:31,  3.30it/s]Train epoch: 11 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007104\n",
      "11600it [43:38,  3.27it/s]Train epoch: 11 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.006423\n",
      "11625it [43:46,  3.28it/s]Train epoch: 11 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.005997\n",
      "11650it [43:54,  3.21it/s]Train epoch: 11 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.006489\n",
      "11675it [44:02,  3.17it/s]Train epoch: 11 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007035\n",
      "11700it [44:10,  3.13it/s]Train epoch: 11 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.007373\n",
      "11725it [44:18,  3.08it/s]Train epoch: 11 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.007433\n",
      "11750it [44:26,  3.13it/s]Train epoch: 11 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.007142\n",
      "11775it [44:34,  3.05it/s]Train epoch: 11 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.007099\n",
      "11800it [44:42,  3.02it/s]Train epoch: 11 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.006961\n",
      "11825it [44:50,  2.94it/s]Train epoch: 11 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.007133\n",
      "11850it [44:59,  2.90it/s]Train epoch: 11 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.007470\n",
      "11875it [45:08,  2.79it/s]Train epoch: 11 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.008193\n",
      "11900it [45:17,  2.58it/s]Train epoch: 11 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.010047\n",
      "11925it [45:27,  2.32it/s]Train epoch: 11 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.008453\n",
      "11930it [45:30,  4.37it/s]\n",
      "epoch loss: 0.00403831850043818\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:54, 30.07it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0363, 0.0504, 0.0636, 0.0562, 0.8784\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3167, 0.4874, 0.4748, 0.4810, 0.9800\n",
      "rec_at_8: 0.3424\n",
      "prec_at_8: 0.6342\n",
      "rec_at_15: 0.4793\n",
      "prec_at_15: 0.4960\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:52, 29.99it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0383, 0.0544, 0.0690, 0.0608, 0.8697\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3108, 0.4803, 0.4682, 0.4742, 0.9795\n",
      "rec_at_8: 0.3284\n",
      "prec_at_8: 0.6310\n",
      "rec_at_15: 0.4627\n",
      "prec_at_15: 0.4951\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0315, 0.0469, 0.0521, 0.0493, 0.8825\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3135, 0.5164, 0.4438, 0.4774, 0.9806\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0331, 0.0517, 0.0560, 0.0538, 0.8750\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3057, 0.5091, 0.4335, 0.4682, 0.9801\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:44:30\n",
      "\n",
      "EPOCH 12\n",
      "0it [00:00, ?it/s]Train epoch: 12 [batch #0, batch_size 4, seq length 2500]\tLoss: 0.005351\n",
      "25it [00:04,  5.67it/s]Train epoch: 12 [batch #25, batch_size 4, seq length 2500]\tLoss: 0.003698\n",
      "50it [00:08,  5.51it/s]Train epoch: 12 [batch #50, batch_size 4, seq length 2500]\tLoss: 0.003356\n",
      "75it [00:13,  5.42it/s]Train epoch: 12 [batch #75, batch_size 4, seq length 2500]\tLoss: 0.002688\n",
      "100it [00:18,  5.46it/s]Train epoch: 12 [batch #100, batch_size 4, seq length 2500]\tLoss: 0.002902\n",
      "125it [00:22,  5.44it/s]Train epoch: 12 [batch #125, batch_size 4, seq length 2500]\tLoss: 0.002767\n",
      "150it [00:27,  5.33it/s]Train epoch: 12 [batch #150, batch_size 4, seq length 2500]\tLoss: 0.002632\n",
      "175it [00:32,  5.41it/s]Train epoch: 12 [batch #175, batch_size 4, seq length 2500]\tLoss: 0.002834\n",
      "200it [00:36,  5.38it/s]Train epoch: 12 [batch #200, batch_size 4, seq length 2500]\tLoss: 0.002628\n",
      "225it [00:41,  5.34it/s]Train epoch: 12 [batch #225, batch_size 4, seq length 2500]\tLoss: 0.003351\n",
      "250it [00:46,  5.27it/s]Train epoch: 12 [batch #250, batch_size 4, seq length 2500]\tLoss: 0.002508\n",
      "275it [00:50,  5.31it/s]Train epoch: 12 [batch #275, batch_size 4, seq length 2500]\tLoss: 0.002293\n",
      "300it [00:55,  5.32it/s]Train epoch: 12 [batch #300, batch_size 4, seq length 2500]\tLoss: 0.003071\n",
      "325it [01:00,  5.23it/s]Train epoch: 12 [batch #325, batch_size 4, seq length 2500]\tLoss: 0.002450\n",
      "350it [01:05,  5.30it/s]Train epoch: 12 [batch #350, batch_size 4, seq length 2500]\tLoss: 0.002893\n",
      "375it [01:09,  5.26it/s]Train epoch: 12 [batch #375, batch_size 4, seq length 2500]\tLoss: 0.002752\n",
      "400it [01:14,  5.20it/s]Train epoch: 12 [batch #400, batch_size 4, seq length 2500]\tLoss: 0.002731\n",
      "425it [01:19,  5.15it/s]Train epoch: 12 [batch #425, batch_size 4, seq length 2500]\tLoss: 0.002718\n",
      "450it [01:24,  5.23it/s]Train epoch: 12 [batch #450, batch_size 4, seq length 2500]\tLoss: 0.002602\n",
      "475it [01:29,  5.22it/s]Train epoch: 12 [batch #475, batch_size 4, seq length 2500]\tLoss: 0.003066\n",
      "500it [01:33,  5.20it/s]Train epoch: 12 [batch #500, batch_size 4, seq length 2500]\tLoss: 0.002618\n",
      "525it [01:38,  5.14it/s]Train epoch: 12 [batch #525, batch_size 4, seq length 2500]\tLoss: 0.002843\n",
      "550it [01:43,  5.16it/s]Train epoch: 12 [batch #550, batch_size 4, seq length 2500]\tLoss: 0.002690\n",
      "575it [01:48,  5.18it/s]Train epoch: 12 [batch #575, batch_size 4, seq length 2500]\tLoss: 0.002810\n",
      "600it [01:53,  5.14it/s]Train epoch: 12 [batch #600, batch_size 4, seq length 2500]\tLoss: 0.002996\n",
      "625it [01:58,  5.13it/s]Train epoch: 12 [batch #625, batch_size 4, seq length 2500]\tLoss: 0.002883\n",
      "650it [02:02,  5.17it/s]Train epoch: 12 [batch #650, batch_size 4, seq length 2500]\tLoss: 0.002479\n",
      "675it [02:07,  5.17it/s]Train epoch: 12 [batch #675, batch_size 4, seq length 2500]\tLoss: 0.002270\n",
      "700it [02:12,  5.05it/s]Train epoch: 12 [batch #700, batch_size 4, seq length 2500]\tLoss: 0.002611\n",
      "725it [02:17,  5.10it/s]Train epoch: 12 [batch #725, batch_size 4, seq length 2500]\tLoss: 0.002791\n",
      "750it [02:22,  5.16it/s]Train epoch: 12 [batch #750, batch_size 4, seq length 2500]\tLoss: 0.002601\n",
      "775it [02:27,  5.10it/s]Train epoch: 12 [batch #775, batch_size 4, seq length 2500]\tLoss: 0.003040\n",
      "800it [02:32,  5.09it/s]Train epoch: 12 [batch #800, batch_size 4, seq length 2500]\tLoss: 0.002886\n",
      "825it [02:37,  5.15it/s]Train epoch: 12 [batch #825, batch_size 4, seq length 2500]\tLoss: 0.002756\n",
      "850it [02:41,  5.14it/s]Train epoch: 12 [batch #850, batch_size 4, seq length 2500]\tLoss: 0.003137\n",
      "875it [02:46,  5.12it/s]Train epoch: 12 [batch #875, batch_size 4, seq length 2500]\tLoss: 0.002539\n",
      "900it [02:51,  5.05it/s]Train epoch: 12 [batch #900, batch_size 4, seq length 2500]\tLoss: 0.002896\n",
      "925it [02:56,  5.03it/s]Train epoch: 12 [batch #925, batch_size 4, seq length 2500]\tLoss: 0.002627\n",
      "950it [03:01,  5.01it/s]Train epoch: 12 [batch #950, batch_size 4, seq length 2500]\tLoss: 0.002530\n",
      "975it [03:06,  4.96it/s]Train epoch: 12 [batch #975, batch_size 4, seq length 2500]\tLoss: 0.002096\n",
      "1000it [03:11,  5.04it/s]Train epoch: 12 [batch #1000, batch_size 4, seq length 2500]\tLoss: 0.002813\n",
      "1025it [03:16,  5.05it/s]Train epoch: 12 [batch #1025, batch_size 4, seq length 2500]\tLoss: 0.003977\n",
      "1050it [03:21,  5.05it/s]Train epoch: 12 [batch #1050, batch_size 4, seq length 2500]\tLoss: 0.002584\n",
      "1075it [03:26,  5.04it/s]Train epoch: 12 [batch #1075, batch_size 4, seq length 2500]\tLoss: 0.002889\n",
      "1100it [03:31,  4.97it/s]Train epoch: 12 [batch #1100, batch_size 4, seq length 2500]\tLoss: 0.002971\n",
      "1125it [03:36,  5.02it/s]Train epoch: 12 [batch #1125, batch_size 4, seq length 2500]\tLoss: 0.002993\n",
      "1150it [03:41,  5.00it/s]Train epoch: 12 [batch #1150, batch_size 4, seq length 2500]\tLoss: 0.003009\n",
      "1175it [03:46,  5.03it/s]Train epoch: 12 [batch #1175, batch_size 4, seq length 2500]\tLoss: 0.002849\n",
      "1200it [03:51,  5.02it/s]Train epoch: 12 [batch #1200, batch_size 4, seq length 2500]\tLoss: 0.002965\n",
      "1225it [03:56,  5.03it/s]Train epoch: 12 [batch #1225, batch_size 4, seq length 2500]\tLoss: 0.003097\n",
      "1250it [04:01,  4.99it/s]Train epoch: 12 [batch #1250, batch_size 4, seq length 2500]\tLoss: 0.003025\n",
      "1275it [04:06,  4.98it/s]Train epoch: 12 [batch #1275, batch_size 4, seq length 2500]\tLoss: 0.002495\n",
      "1300it [04:11,  4.98it/s]Train epoch: 12 [batch #1300, batch_size 4, seq length 2500]\tLoss: 0.002535\n",
      "1325it [04:16,  4.96it/s]Train epoch: 12 [batch #1325, batch_size 4, seq length 2500]\tLoss: 0.002587\n",
      "1350it [04:21,  5.00it/s]Train epoch: 12 [batch #1350, batch_size 4, seq length 2500]\tLoss: 0.003329\n",
      "1375it [04:26,  5.00it/s]Train epoch: 12 [batch #1375, batch_size 4, seq length 2500]\tLoss: 0.002802\n",
      "1400it [04:31,  4.99it/s]Train epoch: 12 [batch #1400, batch_size 4, seq length 2500]\tLoss: 0.002755\n",
      "1425it [04:36,  5.00it/s]Train epoch: 12 [batch #1425, batch_size 4, seq length 2500]\tLoss: 0.002545\n",
      "1450it [04:41,  4.99it/s]Train epoch: 12 [batch #1450, batch_size 4, seq length 2500]\tLoss: 0.002782\n",
      "1475it [04:46,  4.93it/s]Train epoch: 12 [batch #1475, batch_size 4, seq length 2500]\tLoss: 0.002801\n",
      "1500it [04:51,  4.95it/s]Train epoch: 12 [batch #1500, batch_size 4, seq length 2500]\tLoss: 0.003880\n",
      "1525it [04:56,  4.96it/s]Train epoch: 12 [batch #1525, batch_size 4, seq length 2500]\tLoss: 0.003590\n",
      "1550it [05:01,  4.96it/s]Train epoch: 12 [batch #1550, batch_size 4, seq length 2500]\tLoss: 0.002605\n",
      "1575it [05:06,  4.96it/s]Train epoch: 12 [batch #1575, batch_size 4, seq length 2500]\tLoss: 0.002974\n",
      "1600it [05:11,  4.97it/s]Train epoch: 12 [batch #1600, batch_size 4, seq length 2500]\tLoss: 0.002524\n",
      "1625it [05:16,  4.91it/s]Train epoch: 12 [batch #1625, batch_size 4, seq length 2500]\tLoss: 0.003048\n",
      "1650it [05:21,  4.86it/s]Train epoch: 12 [batch #1650, batch_size 4, seq length 2500]\tLoss: 0.003074\n",
      "1675it [05:26,  4.99it/s]Train epoch: 12 [batch #1675, batch_size 4, seq length 2500]\tLoss: 0.003043\n",
      "1700it [05:31,  4.98it/s]Train epoch: 12 [batch #1700, batch_size 4, seq length 2500]\tLoss: 0.002644\n",
      "1725it [05:36,  4.94it/s]Train epoch: 12 [batch #1725, batch_size 4, seq length 2500]\tLoss: 0.002388\n",
      "1750it [05:41,  4.87it/s]Train epoch: 12 [batch #1750, batch_size 4, seq length 2500]\tLoss: 0.003570\n",
      "1775it [05:46,  4.93it/s]Train epoch: 12 [batch #1775, batch_size 4, seq length 2500]\tLoss: 0.002886\n",
      "1800it [05:52,  4.94it/s]Train epoch: 12 [batch #1800, batch_size 4, seq length 2500]\tLoss: 0.002782\n",
      "1825it [05:57,  4.94it/s]Train epoch: 12 [batch #1825, batch_size 4, seq length 2500]\tLoss: 0.002333\n",
      "1850it [06:02,  5.02it/s]Train epoch: 12 [batch #1850, batch_size 4, seq length 2500]\tLoss: 0.003010\n",
      "1875it [06:07,  4.98it/s]Train epoch: 12 [batch #1875, batch_size 4, seq length 2500]\tLoss: 0.003237\n",
      "1900it [06:12,  4.90it/s]Train epoch: 12 [batch #1900, batch_size 4, seq length 2500]\tLoss: 0.002278\n",
      "1925it [06:17,  4.98it/s]Train epoch: 12 [batch #1925, batch_size 4, seq length 2500]\tLoss: 0.002555\n",
      "1950it [06:22,  4.90it/s]Train epoch: 12 [batch #1950, batch_size 4, seq length 2500]\tLoss: 0.002434\n",
      "1975it [06:27,  4.86it/s]Train epoch: 12 [batch #1975, batch_size 4, seq length 2500]\tLoss: 0.003090\n",
      "2000it [06:32,  4.96it/s]Train epoch: 12 [batch #2000, batch_size 4, seq length 2500]\tLoss: 0.002427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025it [06:37,  4.88it/s]Train epoch: 12 [batch #2025, batch_size 4, seq length 2500]\tLoss: 0.003002\n",
      "2050it [06:43,  4.90it/s]Train epoch: 12 [batch #2050, batch_size 4, seq length 2500]\tLoss: 0.002786\n",
      "2075it [06:48,  4.81it/s]Train epoch: 12 [batch #2075, batch_size 4, seq length 2500]\tLoss: 0.002909\n",
      "2100it [06:53,  4.91it/s]Train epoch: 12 [batch #2100, batch_size 4, seq length 2500]\tLoss: 0.003029\n",
      "2125it [06:58,  4.82it/s]Train epoch: 12 [batch #2125, batch_size 4, seq length 2500]\tLoss: 0.003294\n",
      "2150it [07:03,  4.82it/s]Train epoch: 12 [batch #2150, batch_size 4, seq length 2500]\tLoss: 0.002766\n",
      "2175it [07:08,  4.98it/s]Train epoch: 12 [batch #2175, batch_size 4, seq length 2500]\tLoss: 0.003141\n",
      "2200it [07:13,  4.84it/s]Train epoch: 12 [batch #2200, batch_size 4, seq length 2500]\tLoss: 0.002915\n",
      "2225it [07:18,  4.88it/s]Train epoch: 12 [batch #2225, batch_size 4, seq length 2500]\tLoss: 0.002812\n",
      "2250it [07:24,  4.81it/s]Train epoch: 12 [batch #2250, batch_size 4, seq length 2500]\tLoss: 0.002495\n",
      "2275it [07:29,  4.91it/s]Train epoch: 12 [batch #2275, batch_size 4, seq length 2500]\tLoss: 0.002923\n",
      "2300it [07:34,  4.79it/s]Train epoch: 12 [batch #2300, batch_size 4, seq length 2500]\tLoss: 0.002258\n",
      "2325it [07:39,  4.79it/s]Train epoch: 12 [batch #2325, batch_size 4, seq length 2500]\tLoss: 0.002762\n",
      "2350it [07:44,  4.87it/s]Train epoch: 12 [batch #2350, batch_size 4, seq length 2500]\tLoss: 0.002745\n",
      "2375it [07:49,  4.84it/s]Train epoch: 12 [batch #2375, batch_size 4, seq length 2500]\tLoss: 0.003832\n",
      "2400it [07:54,  4.86it/s]Train epoch: 12 [batch #2400, batch_size 4, seq length 2500]\tLoss: 0.003445\n",
      "2425it [08:00,  4.78it/s]Train epoch: 12 [batch #2425, batch_size 4, seq length 2500]\tLoss: 0.002515\n",
      "2450it [08:05,  4.82it/s]Train epoch: 12 [batch #2450, batch_size 4, seq length 2500]\tLoss: 0.002885\n",
      "2475it [08:10,  4.92it/s]Train epoch: 12 [batch #2475, batch_size 4, seq length 2500]\tLoss: 0.003216\n",
      "2500it [08:15,  4.85it/s]Train epoch: 12 [batch #2500, batch_size 4, seq length 2500]\tLoss: 0.002768\n",
      "2525it [08:20,  4.83it/s]Train epoch: 12 [batch #2525, batch_size 4, seq length 2500]\tLoss: 0.002687\n",
      "2550it [08:25,  4.83it/s]Train epoch: 12 [batch #2550, batch_size 4, seq length 2500]\tLoss: 0.003765\n",
      "2575it [08:31,  4.80it/s]Train epoch: 12 [batch #2575, batch_size 4, seq length 2500]\tLoss: 0.002687\n",
      "2600it [08:36,  4.90it/s]Train epoch: 12 [batch #2600, batch_size 4, seq length 2500]\tLoss: 0.002989\n",
      "2625it [08:41,  4.82it/s]Train epoch: 12 [batch #2625, batch_size 4, seq length 2500]\tLoss: 0.002983\n",
      "2650it [08:46,  4.78it/s]Train epoch: 12 [batch #2650, batch_size 4, seq length 2500]\tLoss: 0.003408\n",
      "2675it [08:51,  4.85it/s]Train epoch: 12 [batch #2675, batch_size 4, seq length 2500]\tLoss: 0.002987\n",
      "2700it [08:57,  4.86it/s]Train epoch: 12 [batch #2700, batch_size 4, seq length 2500]\tLoss: 0.002752\n",
      "2725it [09:02,  4.81it/s]Train epoch: 12 [batch #2725, batch_size 4, seq length 2500]\tLoss: 0.002824\n",
      "2750it [09:07,  4.85it/s]Train epoch: 12 [batch #2750, batch_size 4, seq length 2500]\tLoss: 0.003425\n",
      "2775it [09:12,  4.76it/s]Train epoch: 12 [batch #2775, batch_size 4, seq length 2500]\tLoss: 0.002879\n",
      "2800it [09:17,  4.78it/s]Train epoch: 12 [batch #2800, batch_size 4, seq length 2500]\tLoss: 0.002768\n",
      "2825it [09:23,  4.80it/s]Train epoch: 12 [batch #2825, batch_size 4, seq length 2500]\tLoss: 0.003196\n",
      "2850it [09:28,  4.79it/s]Train epoch: 12 [batch #2850, batch_size 4, seq length 2500]\tLoss: 0.002835\n",
      "2875it [09:33,  4.85it/s]Train epoch: 12 [batch #2875, batch_size 4, seq length 2500]\tLoss: 0.003174\n",
      "2900it [09:38,  4.77it/s]Train epoch: 12 [batch #2900, batch_size 4, seq length 2500]\tLoss: 0.003155\n",
      "2925it [09:44,  4.82it/s]Train epoch: 12 [batch #2925, batch_size 4, seq length 2500]\tLoss: 0.003206\n",
      "2950it [09:49,  4.72it/s]Train epoch: 12 [batch #2950, batch_size 4, seq length 2500]\tLoss: 0.003386\n",
      "2975it [09:54,  4.70it/s]Train epoch: 12 [batch #2975, batch_size 4, seq length 2500]\tLoss: 0.003079\n",
      "3000it [09:59,  4.72it/s]Train epoch: 12 [batch #3000, batch_size 4, seq length 2500]\tLoss: 0.003543\n",
      "3025it [10:05,  4.73it/s]Train epoch: 12 [batch #3025, batch_size 4, seq length 2500]\tLoss: 0.003164\n",
      "3050it [10:10,  4.76it/s]Train epoch: 12 [batch #3050, batch_size 4, seq length 2500]\tLoss: 0.002796\n",
      "3075it [10:15,  4.77it/s]Train epoch: 12 [batch #3075, batch_size 4, seq length 2500]\tLoss: 0.003266\n",
      "3100it [10:20,  4.80it/s]Train epoch: 12 [batch #3100, batch_size 4, seq length 2500]\tLoss: 0.003306\n",
      "3125it [10:26,  4.77it/s]Train epoch: 12 [batch #3125, batch_size 4, seq length 2500]\tLoss: 0.002902\n",
      "3150it [10:31,  4.73it/s]Train epoch: 12 [batch #3150, batch_size 4, seq length 2500]\tLoss: 0.002902\n",
      "3175it [10:36,  4.78it/s]Train epoch: 12 [batch #3175, batch_size 4, seq length 2500]\tLoss: 0.002841\n",
      "3200it [10:41,  4.71it/s]Train epoch: 12 [batch #3200, batch_size 4, seq length 2500]\tLoss: 0.003490\n",
      "3225it [10:47,  4.68it/s]Train epoch: 12 [batch #3225, batch_size 4, seq length 2500]\tLoss: 0.003289\n",
      "3250it [10:52,  4.77it/s]Train epoch: 12 [batch #3250, batch_size 4, seq length 2500]\tLoss: 0.003247\n",
      "3275it [10:57,  4.76it/s]Train epoch: 12 [batch #3275, batch_size 4, seq length 2500]\tLoss: 0.002920\n",
      "3300it [11:03,  4.72it/s]Train epoch: 12 [batch #3300, batch_size 4, seq length 2500]\tLoss: 0.003735\n",
      "3325it [11:08,  4.71it/s]Train epoch: 12 [batch #3325, batch_size 4, seq length 2500]\tLoss: 0.003165\n",
      "3350it [11:13,  4.73it/s]Train epoch: 12 [batch #3350, batch_size 4, seq length 2500]\tLoss: 0.003205\n",
      "3375it [11:18,  4.69it/s]Train epoch: 12 [batch #3375, batch_size 4, seq length 2500]\tLoss: 0.003395\n",
      "3400it [11:24,  4.81it/s]Train epoch: 12 [batch #3400, batch_size 4, seq length 2500]\tLoss: 0.003401\n",
      "3425it [11:29,  4.68it/s]Train epoch: 12 [batch #3425, batch_size 4, seq length 2500]\tLoss: 0.002945\n",
      "3450it [11:34,  4.68it/s]Train epoch: 12 [batch #3450, batch_size 4, seq length 2500]\tLoss: 0.003311\n",
      "3475it [11:40,  4.73it/s]Train epoch: 12 [batch #3475, batch_size 4, seq length 2500]\tLoss: 0.002941\n",
      "3500it [11:45,  4.69it/s]Train epoch: 12 [batch #3500, batch_size 4, seq length 2500]\tLoss: 0.003151\n",
      "3525it [11:50,  4.66it/s]Train epoch: 12 [batch #3525, batch_size 4, seq length 2500]\tLoss: 0.003179\n",
      "3550it [11:56,  4.69it/s]Train epoch: 12 [batch #3550, batch_size 4, seq length 2500]\tLoss: 0.003292\n",
      "3575it [12:01,  4.71it/s]Train epoch: 12 [batch #3575, batch_size 4, seq length 2500]\tLoss: 0.002778\n",
      "3600it [12:06,  4.75it/s]Train epoch: 12 [batch #3600, batch_size 4, seq length 2500]\tLoss: 0.003514\n",
      "3625it [12:12,  4.64it/s]Train epoch: 12 [batch #3625, batch_size 4, seq length 2500]\tLoss: 0.003190\n",
      "3650it [12:17,  4.67it/s]Train epoch: 12 [batch #3650, batch_size 4, seq length 2500]\tLoss: 0.003377\n",
      "3675it [12:22,  4.68it/s]Train epoch: 12 [batch #3675, batch_size 4, seq length 2500]\tLoss: 0.003369\n",
      "3700it [12:28,  4.69it/s]Train epoch: 12 [batch #3700, batch_size 4, seq length 2500]\tLoss: 0.003170\n",
      "3725it [12:33,  4.71it/s]Train epoch: 12 [batch #3725, batch_size 4, seq length 2500]\tLoss: 0.003315\n",
      "3750it [12:38,  4.64it/s]Train epoch: 12 [batch #3750, batch_size 4, seq length 2500]\tLoss: 0.003492\n",
      "3775it [12:44,  4.67it/s]Train epoch: 12 [batch #3775, batch_size 4, seq length 2500]\tLoss: 0.003135\n",
      "3800it [12:49,  4.65it/s]Train epoch: 12 [batch #3800, batch_size 4, seq length 2500]\tLoss: 0.003622\n",
      "3825it [12:54,  4.66it/s]Train epoch: 12 [batch #3825, batch_size 4, seq length 2500]\tLoss: 0.003008\n",
      "3850it [13:00,  4.64it/s]Train epoch: 12 [batch #3850, batch_size 4, seq length 2500]\tLoss: 0.002750\n",
      "3875it [13:05,  4.64it/s]Train epoch: 12 [batch #3875, batch_size 4, seq length 2500]\tLoss: 0.002801\n",
      "3900it [13:11,  4.67it/s]Train epoch: 12 [batch #3900, batch_size 4, seq length 2500]\tLoss: 0.003686\n",
      "3925it [13:16,  4.67it/s]Train epoch: 12 [batch #3925, batch_size 4, seq length 2500]\tLoss: 0.003306\n",
      "3950it [13:21,  4.67it/s]Train epoch: 12 [batch #3950, batch_size 4, seq length 2500]\tLoss: 0.003642\n",
      "3975it [13:27,  4.64it/s]Train epoch: 12 [batch #3975, batch_size 4, seq length 2500]\tLoss: 0.004086\n",
      "4000it [13:32,  4.62it/s]Train epoch: 12 [batch #4000, batch_size 4, seq length 2500]\tLoss: 0.002920\n",
      "4025it [13:37,  4.65it/s]Train epoch: 12 [batch #4025, batch_size 4, seq length 2500]\tLoss: 0.003822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4050it [13:43,  4.63it/s]Train epoch: 12 [batch #4050, batch_size 4, seq length 2500]\tLoss: 0.003498\n",
      "4075it [13:48,  4.61it/s]Train epoch: 12 [batch #4075, batch_size 4, seq length 2500]\tLoss: 0.003401\n",
      "4100it [13:54,  4.63it/s]Train epoch: 12 [batch #4100, batch_size 4, seq length 2500]\tLoss: 0.003786\n",
      "4125it [13:59,  4.63it/s]Train epoch: 12 [batch #4125, batch_size 4, seq length 2500]\tLoss: 0.003560\n",
      "4150it [14:04,  4.63it/s]Train epoch: 12 [batch #4150, batch_size 4, seq length 2500]\tLoss: 0.003122\n",
      "4175it [14:10,  4.60it/s]Train epoch: 12 [batch #4175, batch_size 4, seq length 2500]\tLoss: 0.003207\n",
      "4200it [14:15,  4.66it/s]Train epoch: 12 [batch #4200, batch_size 4, seq length 2500]\tLoss: 0.003615\n",
      "4225it [14:21,  4.64it/s]Train epoch: 12 [batch #4225, batch_size 4, seq length 2500]\tLoss: 0.003122\n",
      "4250it [14:26,  4.62it/s]Train epoch: 12 [batch #4250, batch_size 4, seq length 2500]\tLoss: 0.003413\n",
      "4275it [14:31,  4.61it/s]Train epoch: 12 [batch #4275, batch_size 4, seq length 2500]\tLoss: 0.003188\n",
      "4300it [14:37,  4.60it/s]Train epoch: 12 [batch #4300, batch_size 4, seq length 2500]\tLoss: 0.003853\n",
      "4325it [14:42,  4.66it/s]Train epoch: 12 [batch #4325, batch_size 4, seq length 2500]\tLoss: 0.003404\n",
      "4350it [14:48,  4.65it/s]Train epoch: 12 [batch #4350, batch_size 4, seq length 2500]\tLoss: 0.003709\n",
      "4375it [14:53,  4.60it/s]Train epoch: 12 [batch #4375, batch_size 4, seq length 2500]\tLoss: 0.003305\n",
      "4400it [14:59,  4.59it/s]Train epoch: 12 [batch #4400, batch_size 4, seq length 2500]\tLoss: 0.002790\n",
      "4425it [15:04,  4.57it/s]Train epoch: 12 [batch #4425, batch_size 4, seq length 2500]\tLoss: 0.003532\n",
      "4450it [15:09,  4.61it/s]Train epoch: 12 [batch #4450, batch_size 4, seq length 2500]\tLoss: 0.002818\n",
      "4475it [15:15,  4.57it/s]Train epoch: 12 [batch #4475, batch_size 4, seq length 2500]\tLoss: 0.003468\n",
      "4500it [15:20,  4.59it/s]Train epoch: 12 [batch #4500, batch_size 4, seq length 2500]\tLoss: 0.004072\n",
      "4525it [15:26,  4.59it/s]Train epoch: 12 [batch #4525, batch_size 4, seq length 2500]\tLoss: 0.003418\n",
      "4550it [15:31,  4.64it/s]Train epoch: 12 [batch #4550, batch_size 4, seq length 2500]\tLoss: 0.003305\n",
      "4575it [15:37,  4.62it/s]Train epoch: 12 [batch #4575, batch_size 4, seq length 2500]\tLoss: 0.003747\n",
      "4600it [15:42,  4.59it/s]Train epoch: 12 [batch #4600, batch_size 4, seq length 2500]\tLoss: 0.002975\n",
      "4625it [15:48,  4.51it/s]Train epoch: 12 [batch #4625, batch_size 4, seq length 2500]\tLoss: 0.003226\n",
      "4650it [15:53,  4.60it/s]Train epoch: 12 [batch #4650, batch_size 4, seq length 2500]\tLoss: 0.003732\n",
      "4675it [15:59,  4.60it/s]Train epoch: 12 [batch #4675, batch_size 4, seq length 2500]\tLoss: 0.003605\n",
      "4700it [16:04,  4.63it/s]Train epoch: 12 [batch #4700, batch_size 4, seq length 2500]\tLoss: 0.003141\n",
      "4725it [16:09,  4.57it/s]Train epoch: 12 [batch #4725, batch_size 4, seq length 2500]\tLoss: 0.003309\n",
      "4750it [16:15,  4.57it/s]Train epoch: 12 [batch #4750, batch_size 4, seq length 2500]\tLoss: 0.004057\n",
      "4775it [16:20,  4.55it/s]Train epoch: 12 [batch #4775, batch_size 4, seq length 2500]\tLoss: 0.003467\n",
      "4800it [16:26,  4.58it/s]Train epoch: 12 [batch #4800, batch_size 4, seq length 2500]\tLoss: 0.003485\n",
      "4825it [16:31,  4.52it/s]Train epoch: 12 [batch #4825, batch_size 4, seq length 2500]\tLoss: 0.003196\n",
      "4850it [16:37,  4.53it/s]Train epoch: 12 [batch #4850, batch_size 4, seq length 2500]\tLoss: 0.003767\n",
      "4875it [16:42,  4.54it/s]Train epoch: 12 [batch #4875, batch_size 4, seq length 2500]\tLoss: 0.003288\n",
      "4900it [16:48,  4.55it/s]Train epoch: 12 [batch #4900, batch_size 4, seq length 2500]\tLoss: 0.003331\n",
      "4925it [16:53,  4.52it/s]Train epoch: 12 [batch #4925, batch_size 4, seq length 2500]\tLoss: 0.003215\n",
      "4950it [16:59,  4.57it/s]Train epoch: 12 [batch #4950, batch_size 4, seq length 2500]\tLoss: 0.003382\n",
      "4975it [17:04,  4.50it/s]Train epoch: 12 [batch #4975, batch_size 4, seq length 2500]\tLoss: 0.003358\n",
      "5000it [17:10,  4.52it/s]Train epoch: 12 [batch #5000, batch_size 4, seq length 2500]\tLoss: 0.003447\n",
      "5025it [17:15,  4.53it/s]Train epoch: 12 [batch #5025, batch_size 4, seq length 2500]\tLoss: 0.003266\n",
      "5050it [17:21,  4.60it/s]Train epoch: 12 [batch #5050, batch_size 4, seq length 2500]\tLoss: 0.003161\n",
      "5075it [17:26,  4.54it/s]Train epoch: 12 [batch #5075, batch_size 4, seq length 2500]\tLoss: 0.003463\n",
      "5100it [17:32,  4.53it/s]Train epoch: 12 [batch #5100, batch_size 4, seq length 2500]\tLoss: 0.003560\n",
      "5125it [17:38,  4.61it/s]Train epoch: 12 [batch #5125, batch_size 4, seq length 2500]\tLoss: 0.003632\n",
      "5150it [17:43,  4.51it/s]Train epoch: 12 [batch #5150, batch_size 4, seq length 2500]\tLoss: 0.003697\n",
      "5175it [17:49,  4.50it/s]Train epoch: 12 [batch #5175, batch_size 4, seq length 2500]\tLoss: 0.003475\n",
      "5200it [17:54,  4.57it/s]Train epoch: 12 [batch #5200, batch_size 4, seq length 2500]\tLoss: 0.003276\n",
      "5225it [18:00,  4.51it/s]Train epoch: 12 [batch #5225, batch_size 4, seq length 2500]\tLoss: 0.003493\n",
      "5250it [18:05,  4.49it/s]Train epoch: 12 [batch #5250, batch_size 4, seq length 2500]\tLoss: 0.003540\n",
      "5275it [18:11,  4.50it/s]Train epoch: 12 [batch #5275, batch_size 4, seq length 2500]\tLoss: 0.003380\n",
      "5300it [18:16,  4.48it/s]Train epoch: 12 [batch #5300, batch_size 4, seq length 2500]\tLoss: 0.003156\n",
      "5325it [18:22,  4.50it/s]Train epoch: 12 [batch #5325, batch_size 4, seq length 2500]\tLoss: 0.003766\n",
      "5350it [18:27,  4.49it/s]Train epoch: 12 [batch #5350, batch_size 4, seq length 2500]\tLoss: 0.003715\n",
      "5375it [18:33,  4.46it/s]Train epoch: 12 [batch #5375, batch_size 4, seq length 2500]\tLoss: 0.003297\n",
      "5400it [18:39,  4.48it/s]Train epoch: 12 [batch #5400, batch_size 4, seq length 2500]\tLoss: 0.003300\n",
      "5425it [18:44,  4.45it/s]Train epoch: 12 [batch #5425, batch_size 4, seq length 2500]\tLoss: 0.003615\n",
      "5450it [18:50,  4.47it/s]Train epoch: 12 [batch #5450, batch_size 4, seq length 2500]\tLoss: 0.003530\n",
      "5475it [18:55,  4.51it/s]Train epoch: 12 [batch #5475, batch_size 4, seq length 2500]\tLoss: 0.004202\n",
      "5500it [19:01,  4.45it/s]Train epoch: 12 [batch #5500, batch_size 4, seq length 2500]\tLoss: 0.003771\n",
      "5525it [19:07,  4.46it/s]Train epoch: 12 [batch #5525, batch_size 4, seq length 2500]\tLoss: 0.003208\n",
      "5550it [19:12,  4.46it/s]Train epoch: 12 [batch #5550, batch_size 4, seq length 2500]\tLoss: 0.003567\n",
      "5575it [19:18,  4.43it/s]Train epoch: 12 [batch #5575, batch_size 4, seq length 2500]\tLoss: 0.003652\n",
      "5600it [19:23,  4.44it/s]Train epoch: 12 [batch #5600, batch_size 4, seq length 2500]\tLoss: 0.003944\n",
      "5625it [19:29,  4.47it/s]Train epoch: 12 [batch #5625, batch_size 4, seq length 2500]\tLoss: 0.003630\n",
      "5650it [19:35,  4.49it/s]Train epoch: 12 [batch #5650, batch_size 4, seq length 2500]\tLoss: 0.003273\n",
      "5675it [19:40,  4.44it/s]Train epoch: 12 [batch #5675, batch_size 4, seq length 2500]\tLoss: 0.004089\n",
      "5700it [19:46,  4.47it/s]Train epoch: 12 [batch #5700, batch_size 4, seq length 2500]\tLoss: 0.003481\n",
      "5725it [19:51,  4.42it/s]Train epoch: 12 [batch #5725, batch_size 4, seq length 2500]\tLoss: 0.003564\n",
      "5750it [19:57,  4.45it/s]Train epoch: 12 [batch #5750, batch_size 4, seq length 2500]\tLoss: 0.004711\n",
      "5775it [20:03,  4.52it/s]Train epoch: 12 [batch #5775, batch_size 4, seq length 2500]\tLoss: 0.003709\n",
      "5800it [20:08,  4.38it/s]Train epoch: 12 [batch #5800, batch_size 4, seq length 2500]\tLoss: 0.003832\n",
      "5825it [20:14,  4.42it/s]Train epoch: 12 [batch #5825, batch_size 4, seq length 2500]\tLoss: 0.003328\n",
      "5850it [20:20,  4.42it/s]Train epoch: 12 [batch #5850, batch_size 4, seq length 2500]\tLoss: 0.004374\n",
      "5875it [20:25,  4.38it/s]Train epoch: 12 [batch #5875, batch_size 4, seq length 2500]\tLoss: 0.003938\n",
      "5900it [20:31,  4.40it/s]Train epoch: 12 [batch #5900, batch_size 4, seq length 2500]\tLoss: 0.004019\n",
      "5925it [20:37,  4.43it/s]Train epoch: 12 [batch #5925, batch_size 4, seq length 2500]\tLoss: 0.003480\n",
      "5950it [20:42,  4.42it/s]Train epoch: 12 [batch #5950, batch_size 4, seq length 2500]\tLoss: 0.003250\n",
      "5975it [20:48,  4.39it/s]Train epoch: 12 [batch #5975, batch_size 4, seq length 2500]\tLoss: 0.004690\n",
      "6000it [20:54,  4.43it/s]Train epoch: 12 [batch #6000, batch_size 4, seq length 2500]\tLoss: 0.003939\n",
      "6025it [20:59,  4.36it/s]Train epoch: 12 [batch #6025, batch_size 4, seq length 2500]\tLoss: 0.004189\n",
      "6050it [21:05,  4.41it/s]Train epoch: 12 [batch #6050, batch_size 4, seq length 2500]\tLoss: 0.003581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6075it [21:11,  4.40it/s]Train epoch: 12 [batch #6075, batch_size 4, seq length 2500]\tLoss: 0.003362\n",
      "6100it [21:16,  4.40it/s]Train epoch: 12 [batch #6100, batch_size 4, seq length 2500]\tLoss: 0.003196\n",
      "6125it [21:22,  4.39it/s]Train epoch: 12 [batch #6125, batch_size 4, seq length 2500]\tLoss: 0.003684\n",
      "6150it [21:27,  4.40it/s]Train epoch: 12 [batch #6150, batch_size 4, seq length 2500]\tLoss: 0.003702\n",
      "6175it [21:33,  4.40it/s]Train epoch: 12 [batch #6175, batch_size 4, seq length 2500]\tLoss: 0.004129\n",
      "6200it [21:39,  4.41it/s]Train epoch: 12 [batch #6200, batch_size 4, seq length 2500]\tLoss: 0.003704\n",
      "6225it [21:45,  4.40it/s]Train epoch: 12 [batch #6225, batch_size 4, seq length 2500]\tLoss: 0.003152\n",
      "6250it [21:50,  4.37it/s]Train epoch: 12 [batch #6250, batch_size 4, seq length 2500]\tLoss: 0.003393\n",
      "6275it [21:56,  4.38it/s]Train epoch: 12 [batch #6275, batch_size 4, seq length 2500]\tLoss: 0.003079\n",
      "6300it [22:02,  4.42it/s]Train epoch: 12 [batch #6300, batch_size 4, seq length 2500]\tLoss: 0.003563\n",
      "6325it [22:07,  4.36it/s]Train epoch: 12 [batch #6325, batch_size 4, seq length 2500]\tLoss: 0.004043\n",
      "6350it [22:13,  4.41it/s]Train epoch: 12 [batch #6350, batch_size 4, seq length 2500]\tLoss: 0.004243\n",
      "6375it [22:19,  4.41it/s]Train epoch: 12 [batch #6375, batch_size 4, seq length 2500]\tLoss: 0.003176\n",
      "6400it [22:24,  4.37it/s]Train epoch: 12 [batch #6400, batch_size 4, seq length 2500]\tLoss: 0.003627\n",
      "6425it [22:30,  4.40it/s]Train epoch: 12 [batch #6425, batch_size 4, seq length 2500]\tLoss: 0.003997\n",
      "6450it [22:36,  4.34it/s]Train epoch: 12 [batch #6450, batch_size 4, seq length 2500]\tLoss: 0.004033\n",
      "6475it [22:42,  4.36it/s]Train epoch: 12 [batch #6475, batch_size 4, seq length 2500]\tLoss: 0.003535\n",
      "6500it [22:47,  4.36it/s]Train epoch: 12 [batch #6500, batch_size 4, seq length 2500]\tLoss: 0.004089\n",
      "6525it [22:53,  4.35it/s]Train epoch: 12 [batch #6525, batch_size 4, seq length 2500]\tLoss: 0.003402\n",
      "6550it [22:59,  4.32it/s]Train epoch: 12 [batch #6550, batch_size 4, seq length 2500]\tLoss: 0.003624\n",
      "6575it [23:05,  4.28it/s]Train epoch: 12 [batch #6575, batch_size 4, seq length 2500]\tLoss: 0.003632\n",
      "6600it [23:10,  4.31it/s]Train epoch: 12 [batch #6600, batch_size 4, seq length 2500]\tLoss: 0.004439\n",
      "6625it [23:16,  4.35it/s]Train epoch: 12 [batch #6625, batch_size 4, seq length 2500]\tLoss: 0.003619\n",
      "6650it [23:22,  4.33it/s]Train epoch: 12 [batch #6650, batch_size 4, seq length 2500]\tLoss: 0.004198\n",
      "6675it [23:28,  4.32it/s]Train epoch: 12 [batch #6675, batch_size 4, seq length 2500]\tLoss: 0.003755\n",
      "6700it [23:33,  4.30it/s]Train epoch: 12 [batch #6700, batch_size 4, seq length 2500]\tLoss: 0.003913\n",
      "6725it [23:39,  4.36it/s]Train epoch: 12 [batch #6725, batch_size 4, seq length 2500]\tLoss: 0.003892\n",
      "6750it [23:45,  4.33it/s]Train epoch: 12 [batch #6750, batch_size 4, seq length 2500]\tLoss: 0.003530\n",
      "6775it [23:51,  4.33it/s]Train epoch: 12 [batch #6775, batch_size 4, seq length 2500]\tLoss: 0.004183\n",
      "6800it [23:57,  4.31it/s]Train epoch: 12 [batch #6800, batch_size 4, seq length 2500]\tLoss: 0.004196\n",
      "6825it [24:02,  4.29it/s]Train epoch: 12 [batch #6825, batch_size 4, seq length 2500]\tLoss: 0.004123\n",
      "6850it [24:08,  4.35it/s]Train epoch: 12 [batch #6850, batch_size 4, seq length 2500]\tLoss: 0.004001\n",
      "6875it [24:14,  4.29it/s]Train epoch: 12 [batch #6875, batch_size 4, seq length 2500]\tLoss: 0.003200\n",
      "6900it [24:20,  4.31it/s]Train epoch: 12 [batch #6900, batch_size 4, seq length 2500]\tLoss: 0.003747\n",
      "6925it [24:26,  4.29it/s]Train epoch: 12 [batch #6925, batch_size 4, seq length 2500]\tLoss: 0.003880\n",
      "6950it [24:31,  4.29it/s]Train epoch: 12 [batch #6950, batch_size 4, seq length 2500]\tLoss: 0.004282\n",
      "6975it [24:37,  4.30it/s]Train epoch: 12 [batch #6975, batch_size 4, seq length 2500]\tLoss: 0.003991\n",
      "7000it [24:43,  4.27it/s]Train epoch: 12 [batch #7000, batch_size 4, seq length 2500]\tLoss: 0.003718\n",
      "7025it [24:49,  4.35it/s]Train epoch: 12 [batch #7025, batch_size 4, seq length 2500]\tLoss: 0.004434\n",
      "7050it [24:55,  4.29it/s]Train epoch: 12 [batch #7050, batch_size 4, seq length 2500]\tLoss: 0.003369\n",
      "7075it [25:00,  4.33it/s]Train epoch: 12 [batch #7075, batch_size 4, seq length 2500]\tLoss: 0.003914\n",
      "7100it [25:06,  4.30it/s]Train epoch: 12 [batch #7100, batch_size 4, seq length 2500]\tLoss: 0.003940\n",
      "7125it [25:12,  4.24it/s]Train epoch: 12 [batch #7125, batch_size 4, seq length 2500]\tLoss: 0.003522\n",
      "7150it [25:18,  4.24it/s]Train epoch: 12 [batch #7150, batch_size 4, seq length 2500]\tLoss: 0.004313\n",
      "7175it [25:24,  4.26it/s]Train epoch: 12 [batch #7175, batch_size 4, seq length 2500]\tLoss: 0.003946\n",
      "7200it [25:30,  4.32it/s]Train epoch: 12 [batch #7200, batch_size 4, seq length 2500]\tLoss: 0.004300\n",
      "7225it [25:36,  4.27it/s]Train epoch: 12 [batch #7225, batch_size 4, seq length 2500]\tLoss: 0.003780\n",
      "7250it [25:41,  4.26it/s]Train epoch: 12 [batch #7250, batch_size 4, seq length 2500]\tLoss: 0.003804\n",
      "7275it [25:47,  4.33it/s]Train epoch: 12 [batch #7275, batch_size 4, seq length 2500]\tLoss: 0.004363\n",
      "7300it [25:53,  4.33it/s]Train epoch: 12 [batch #7300, batch_size 4, seq length 2500]\tLoss: 0.004650\n",
      "7325it [25:59,  4.27it/s]Train epoch: 12 [batch #7325, batch_size 4, seq length 2500]\tLoss: 0.003675\n",
      "7350it [26:05,  4.27it/s]Train epoch: 12 [batch #7350, batch_size 4, seq length 2500]\tLoss: 0.004536\n",
      "7375it [26:11,  4.29it/s]Train epoch: 12 [batch #7375, batch_size 4, seq length 2500]\tLoss: 0.004227\n",
      "7400it [26:17,  4.30it/s]Train epoch: 12 [batch #7400, batch_size 4, seq length 2500]\tLoss: 0.003805\n",
      "7425it [26:22,  4.23it/s]Train epoch: 12 [batch #7425, batch_size 4, seq length 2500]\tLoss: 0.004167\n",
      "7450it [26:28,  4.25it/s]Train epoch: 12 [batch #7450, batch_size 4, seq length 2500]\tLoss: 0.004570\n",
      "7475it [26:34,  4.33it/s]Train epoch: 12 [batch #7475, batch_size 4, seq length 2500]\tLoss: 0.003874\n",
      "7500it [26:40,  4.26it/s]Train epoch: 12 [batch #7500, batch_size 4, seq length 2500]\tLoss: 0.004213\n",
      "7525it [26:46,  4.24it/s]Train epoch: 12 [batch #7525, batch_size 4, seq length 2500]\tLoss: 0.003918\n",
      "7550it [26:52,  4.27it/s]Train epoch: 12 [batch #7550, batch_size 4, seq length 2500]\tLoss: 0.003855\n",
      "7575it [26:58,  4.26it/s]Train epoch: 12 [batch #7575, batch_size 4, seq length 2500]\tLoss: 0.004217\n",
      "7600it [27:03,  4.22it/s]Train epoch: 12 [batch #7600, batch_size 4, seq length 2500]\tLoss: 0.004987\n",
      "7625it [27:09,  4.27it/s]Train epoch: 12 [batch #7625, batch_size 4, seq length 2500]\tLoss: 0.004824\n",
      "7650it [27:15,  4.23it/s]Train epoch: 12 [batch #7650, batch_size 4, seq length 2500]\tLoss: 0.003979\n",
      "7675it [27:21,  4.29it/s]Train epoch: 12 [batch #7675, batch_size 4, seq length 2500]\tLoss: 0.003801\n",
      "7700it [27:27,  4.24it/s]Train epoch: 12 [batch #7700, batch_size 4, seq length 2500]\tLoss: 0.003986\n",
      "7725it [27:33,  4.20it/s]Train epoch: 12 [batch #7725, batch_size 4, seq length 2500]\tLoss: 0.004137\n",
      "7750it [27:39,  4.26it/s]Train epoch: 12 [batch #7750, batch_size 4, seq length 2500]\tLoss: 0.004370\n",
      "7775it [27:45,  4.18it/s]Train epoch: 12 [batch #7775, batch_size 4, seq length 2500]\tLoss: 0.003779\n",
      "7800it [27:51,  4.23it/s]Train epoch: 12 [batch #7800, batch_size 4, seq length 2500]\tLoss: 0.004016\n",
      "7825it [27:57,  4.24it/s]Train epoch: 12 [batch #7825, batch_size 4, seq length 2500]\tLoss: 0.004246\n",
      "7850it [28:03,  4.20it/s]Train epoch: 12 [batch #7850, batch_size 4, seq length 2500]\tLoss: 0.003727\n",
      "7875it [28:08,  4.24it/s]Train epoch: 12 [batch #7875, batch_size 4, seq length 2500]\tLoss: 0.003991\n",
      "7900it [28:14,  4.21it/s]Train epoch: 12 [batch #7900, batch_size 4, seq length 2500]\tLoss: 0.004128\n",
      "7925it [28:20,  4.25it/s]Train epoch: 12 [batch #7925, batch_size 4, seq length 2500]\tLoss: 0.004139\n",
      "7950it [28:26,  4.23it/s]Train epoch: 12 [batch #7950, batch_size 4, seq length 2500]\tLoss: 0.004648\n",
      "7975it [28:32,  4.21it/s]Train epoch: 12 [batch #7975, batch_size 4, seq length 2500]\tLoss: 0.003847\n",
      "8000it [28:38,  4.10it/s]Train epoch: 12 [batch #8000, batch_size 4, seq length 2500]\tLoss: 0.003878\n",
      "8025it [28:44,  4.18it/s]Train epoch: 12 [batch #8025, batch_size 4, seq length 2500]\tLoss: 0.004319\n",
      "8050it [28:50,  4.20it/s]Train epoch: 12 [batch #8050, batch_size 4, seq length 2500]\tLoss: 0.003590\n",
      "8075it [28:56,  4.20it/s]Train epoch: 12 [batch #8075, batch_size 4, seq length 2500]\tLoss: 0.004093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100it [29:02,  4.19it/s]Train epoch: 12 [batch #8100, batch_size 4, seq length 2500]\tLoss: 0.004407\n",
      "8125it [29:08,  4.17it/s]Train epoch: 12 [batch #8125, batch_size 4, seq length 2500]\tLoss: 0.004463\n",
      "8150it [29:14,  4.21it/s]Train epoch: 12 [batch #8150, batch_size 4, seq length 2500]\tLoss: 0.003897\n",
      "8175it [29:20,  4.24it/s]Train epoch: 12 [batch #8175, batch_size 4, seq length 2500]\tLoss: 0.004448\n",
      "8200it [29:26,  4.17it/s]Train epoch: 12 [batch #8200, batch_size 4, seq length 2500]\tLoss: 0.003822\n",
      "8225it [29:32,  4.14it/s]Train epoch: 12 [batch #8225, batch_size 4, seq length 2500]\tLoss: 0.005112\n",
      "8250it [29:38,  4.17it/s]Train epoch: 12 [batch #8250, batch_size 4, seq length 2500]\tLoss: 0.003878\n",
      "8275it [29:44,  4.04it/s]Train epoch: 12 [batch #8275, batch_size 4, seq length 2500]\tLoss: 0.004521\n",
      "8300it [29:50,  4.09it/s]Train epoch: 12 [batch #8300, batch_size 4, seq length 2500]\tLoss: 0.003866\n",
      "8325it [29:56,  4.14it/s]Train epoch: 12 [batch #8325, batch_size 4, seq length 2500]\tLoss: 0.004427\n",
      "8350it [30:02,  4.08it/s]Train epoch: 12 [batch #8350, batch_size 4, seq length 2500]\tLoss: 0.003918\n",
      "8375it [30:09,  4.04it/s]Train epoch: 12 [batch #8375, batch_size 4, seq length 2500]\tLoss: 0.004422\n",
      "8400it [30:15,  4.10it/s]Train epoch: 12 [batch #8400, batch_size 4, seq length 2500]\tLoss: 0.004163\n",
      "8425it [30:21,  4.06it/s]Train epoch: 12 [batch #8425, batch_size 4, seq length 2500]\tLoss: 0.004096\n",
      "8450it [30:27,  4.05it/s]Train epoch: 12 [batch #8450, batch_size 4, seq length 2500]\tLoss: 0.004587\n",
      "8475it [30:33,  4.06it/s]Train epoch: 12 [batch #8475, batch_size 4, seq length 2500]\tLoss: 0.004145\n",
      "8500it [30:39,  4.00it/s]Train epoch: 12 [batch #8500, batch_size 4, seq length 2500]\tLoss: 0.004969\n",
      "8525it [30:45,  4.16it/s]Train epoch: 12 [batch #8525, batch_size 4, seq length 2500]\tLoss: 0.004033\n",
      "8550it [30:51,  4.14it/s]Train epoch: 12 [batch #8550, batch_size 4, seq length 2500]\tLoss: 0.004359\n",
      "8575it [30:58,  4.07it/s]Train epoch: 12 [batch #8575, batch_size 4, seq length 2500]\tLoss: 0.004041\n",
      "8600it [31:04,  4.11it/s]Train epoch: 12 [batch #8600, batch_size 4, seq length 2500]\tLoss: 0.004149\n",
      "8625it [31:10,  4.06it/s]Train epoch: 12 [batch #8625, batch_size 4, seq length 2500]\tLoss: 0.004336\n",
      "8650it [31:16,  3.99it/s]Train epoch: 12 [batch #8650, batch_size 4, seq length 2500]\tLoss: 0.004483\n",
      "8675it [31:22,  4.10it/s]Train epoch: 12 [batch #8675, batch_size 4, seq length 2500]\tLoss: 0.004935\n",
      "8700it [31:28,  4.12it/s]Train epoch: 12 [batch #8700, batch_size 4, seq length 2500]\tLoss: 0.005136\n",
      "8725it [31:35,  4.05it/s]Train epoch: 12 [batch #8725, batch_size 4, seq length 2500]\tLoss: 0.004788\n",
      "8750it [31:41,  4.06it/s]Train epoch: 12 [batch #8750, batch_size 4, seq length 2500]\tLoss: 0.004513\n",
      "8775it [31:47,  4.10it/s]Train epoch: 12 [batch #8775, batch_size 4, seq length 2500]\tLoss: 0.004083\n",
      "8800it [31:53,  4.05it/s]Train epoch: 12 [batch #8800, batch_size 4, seq length 2500]\tLoss: 0.004250\n",
      "8825it [31:59,  3.98it/s]Train epoch: 12 [batch #8825, batch_size 4, seq length 2500]\tLoss: 0.004393\n",
      "8850it [32:05,  4.02it/s]Train epoch: 12 [batch #8850, batch_size 4, seq length 2500]\tLoss: 0.004504\n",
      "8875it [32:12,  4.01it/s]Train epoch: 12 [batch #8875, batch_size 4, seq length 2500]\tLoss: 0.004448\n",
      "8900it [32:18,  3.99it/s]Train epoch: 12 [batch #8900, batch_size 4, seq length 2500]\tLoss: 0.004406\n",
      "8925it [32:24,  4.03it/s]Train epoch: 12 [batch #8925, batch_size 4, seq length 2500]\tLoss: 0.004645\n",
      "8950it [32:30,  4.03it/s]Train epoch: 12 [batch #8950, batch_size 4, seq length 2500]\tLoss: 0.005153\n",
      "8975it [32:37,  4.04it/s]Train epoch: 12 [batch #8975, batch_size 4, seq length 2500]\tLoss: 0.004664\n",
      "9000it [32:43,  4.00it/s]Train epoch: 12 [batch #9000, batch_size 4, seq length 2500]\tLoss: 0.004437\n",
      "9025it [32:49,  4.02it/s]Train epoch: 12 [batch #9025, batch_size 4, seq length 2500]\tLoss: 0.004495\n",
      "9050it [32:55,  3.90it/s]Train epoch: 12 [batch #9050, batch_size 4, seq length 2500]\tLoss: 0.004090\n",
      "9075it [33:01,  4.00it/s]Train epoch: 12 [batch #9075, batch_size 4, seq length 2500]\tLoss: 0.003836\n",
      "9100it [33:08,  3.99it/s]Train epoch: 12 [batch #9100, batch_size 4, seq length 2500]\tLoss: 0.004712\n",
      "9125it [33:14,  4.00it/s]Train epoch: 12 [batch #9125, batch_size 4, seq length 2500]\tLoss: 0.004130\n",
      "9150it [33:20,  4.00it/s]Train epoch: 12 [batch #9150, batch_size 4, seq length 2500]\tLoss: 0.003889\n",
      "9175it [33:27,  3.95it/s]Train epoch: 12 [batch #9175, batch_size 4, seq length 2500]\tLoss: 0.004248\n",
      "9200it [33:33,  3.97it/s]Train epoch: 12 [batch #9200, batch_size 4, seq length 2500]\tLoss: 0.004170\n",
      "9225it [33:39,  3.94it/s]Train epoch: 12 [batch #9225, batch_size 4, seq length 2500]\tLoss: 0.005010\n",
      "9250it [33:45,  3.95it/s]"
     ]
    }
   ],
   "source": [
    "# bert-tiny pretrain BPE 2500\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny \\\n",
    "    15 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience 10 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 4 \\\n",
    "    --last_module caml_attn \\\n",
    "    --redefined_tokenizer \\\n",
    "    --pretrain_lr 1e-4 \\\n",
    "    --pretrain-batch-size 1 \\\n",
    "    --pretrain \\\n",
    "    --max_sequence_length 2500 \\\n",
    "    --cuda_device_no 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert-tiny 2500 BPE\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny \\\n",
    "    50 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience 3 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 4 \\\n",
    "    --last_module caml_attn \\\n",
    "    --redefined_tokenizer \\\n",
    "    --max_sequence_length 2500 \\\n",
    "    --cuda_device_no 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert-tiny-parallel-caml 2 3500 W2V\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny-parallel-caml \\\n",
    "    50 \\\n",
    "    --batch-size 4 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.3 \\\n",
    "    --patience 3 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-size 100 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --max_sequence_length 3500 \\\n",
    "    --last_module caml_attn \\\n",
    "    --bert_parallel_count 2 \\\n",
    "    --bert_parallel_final_layer sum \\\n",
    "    --cuda_device_no 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('mlhc': conda)",
   "language": "python",
   "name": "python37764bitmlhcconda1212f3f7d082463bae9a49ba6e3c1c5e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
