{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:00] Reading files                            ░░░░░░░░                   0\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            ░░░░░░░░                   1\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            ░░░░░░░░                   3\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            ░░░░░░░░                   4\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            ░░░░░░░░                   5\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            ░░░░░░░░                   7\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            ░░░░░░░░                   8\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            ░░░░░░░░                  10\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            ░░░░░░░░                  11\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            █░░░░░░░                  13\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            █░░░░░░░                  14\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            █░░░░░░░                  16\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Reading files                            █░░░░░░░                  17\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            █░░░░░░░                  18\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            █░░░░░░░                  20\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            █░░░░░░░                  21\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            █░░░░░░░                  22\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            █░░░░░░░                  24\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            ██░░░░░░                  25\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            ██░░░░░░                  27\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            ██░░░░░░                  28\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            ██░░░░░░                  30\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            ██░░░░░░                  31\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Reading files                            ██░░░░░░                  33\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ██░░░░░░                  34\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ██░░░░░░                  35\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ██░░░░░░                  37\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ███░░░░░                  38\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ███░░░░░                  40\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ███░░░░░                  41\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ███░░░░░                  42\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ███░░░░░                  44\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ███░░░░░                  45\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ███░░░░░                  47\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ███░░░░░                  48\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ████░░░░                  50\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Reading files                            ████░░░░                  51\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Reading files                            ████░░░░                  52\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Reading files                            ████░░░░                  52\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Reading files                            ████░░░░                  53\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Reading files                            ████░░░░                  54\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Reading files                            ████░░░░                  54\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Reading files                            ████░░░░                  55\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Reading files                            ████░░░░                  55\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Reading files                            ████░░░░                  56\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Reading files                            ████░░░░                  56\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Reading files                            ████░░░░                  57\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Reading files                            ████░░░░                  58\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Reading files                            ████░░░░                  58\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Reading files                            ████░░░░                  59\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Reading files                            ████░░░░                  60\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Reading files                            ████░░░░                  61\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Reading files                            ████░░░░                  61\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Reading files                            ████░░░░                  62\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:05] Reading files                            █████░░░                  63\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:05] Reading files                            █████░░░                  64\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:05] Reading files                            █████░░░                  64\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:05] Reading files                            █████░░░                  65\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:05] Reading files                            █████░░░                  66\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:05] Reading files                            █████░░░                  66\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:05] Reading files                            █████░░░                  67\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:05] Reading files                            █████░░░                  68\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:05] Reading files                            █████░░░                  68\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:06] Reading files                            █████░░░                  69\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:06] Reading files                            █████░░░                  69\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:06] Reading files                            █████░░░                  70\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:07] Reading files                            █████░░░                  70\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:07] Reading files                            █████░░░                  70\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:08] Reading files                            █████░░░                  71\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:09] Reading files                            █████░░░                  71\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:09] Reading files                            █████░░░                  71\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:10] Reading files                            █████░░░                  72\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:11] Reading files                            █████░░░                  72\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:11] Reading files                            █████░░░                  72\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:12] Reading files                            █████░░░                  73\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:13] Reading files                            █████░░░                  73\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:14] Reading files                            █████░░░                  73\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:14] Reading files                            █████░░░                  74\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:15] Reading files                            █████░░░                  74\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:16] Reading files                            █████░░░                  74\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:16] Reading files                            █████░░░                  75\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:17] Reading files                            ██████░░                  75\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:18] Reading files                            ██████░░                  75\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:18] Reading files                            ██████░░                  76\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:19] Reading files                            ██████░░                  76\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:20] Reading files                            ██████░░                  76\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:20] Reading files                            ██████░░                  77\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:21] Reading files                            ██████░░                  77\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:22] Reading files                            ██████░░                  77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[1B\u001b[1A[00:00:22] Reading files                            ██████░░                  78\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:23] Reading files                            ██████░░                  78\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:24] Reading files                            ██████░░                  78\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:24] Reading files                            ██████░░                  79\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:25] Reading files                            ██████░░                  79\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:26] Reading files                            ██████░░                  79\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:26] Reading files                            ██████░░                  80\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:27] Reading files                            ██████░░                  80\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:28] Reading files                            ██████░░                  80\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:29] Reading files                            ██████░░                  81\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:29] Reading files                            ██████░░                  81\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:30] Reading files                            ██████░░                  81\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:31] Reading files                            ██████░░                  82\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:31] Reading files                            ██████░░                  82\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:32] Reading files                            ██████░░                  82\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:33] Reading files                            ██████░░                  83\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:33] Reading files                            ██████░░                  83\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:34] Reading files                            ██████░░                  83\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:35] Reading files                            ██████░░                  84\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:36] Reading files                            ██████░░                  84\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:36] Reading files                            ██████░░                  84\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:37] Reading files                            ██████░░                  85\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:38] Reading files                            ██████░░                  85\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:38] Reading files                            ██████░░                  85\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:39] Reading files                            ██████░░                  86\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:40] Reading files                            ██████░░                  86\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:40] Reading files                            ██████░░                  86\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:41] Reading files                            ██████░░                  87\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:42] Reading files                            ██████░░                  87\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:42] Reading files                            ██████░░                  87\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:43] Reading files                            ███████░                  88\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:44] Reading files                            ███████░                  88\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:44] Reading files                            ███████░                  88\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:45] Reading files                            ███████░                  89\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:46] Reading files                            ███████░                  89\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:46] Reading files                            ███████░                  89\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:47] Reading files                            ███████░                  90\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:48] Reading files                            ███████░                  90\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:49] Reading files                            ███████░                  90\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:49] Reading files                            ███████░                  91\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:50] Reading files                            ███████░                  91\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:51] Reading files                            ███████░                  91\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:51] Reading files                            ███████░                  92\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:52] Reading files                            ███████░                  92\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:53] Reading files                            ███████░                  92\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:53] Reading files                            ███████░                  93\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:54] Reading files                            ███████░                  93\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:55] Reading files                            ███████░                  93\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:55] Reading files                            ███████░                  94\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:56] Reading files                            ███████░                  94\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:57] Reading files                            ███████░                  94\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:57] Reading files                            ███████░                  95\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:58] Reading files                            ███████░                  95\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:59] Reading files                            ███████░                  95\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:59] Reading files                            ███████░                  96\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:00] Reading files                            ███████░                  96\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:01] Reading files                            ███████░                  96\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:02] Reading files                            ███████░                  97\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:02] Reading files                            ███████░                  97\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:03] Reading files                            ███████░                  97\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:04] Reading files                            ███████░                  98\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:04] Reading files                            ███████░                  98\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:05] Reading files                            ███████░                  98\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:06] Reading files                            ███████░                  99\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:06] Reading files                            ███████░                  99\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:07] Reading files                            ███████░                  99\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:08] Reading files                            ███████░                 100\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:08] Reading files                            ████████                 100\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:01:08] Reading files                            ████████                 100\n",
      "[00:00:00] Tokenize words                           ████████ 0        /        0\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ░░░░░░░░ 9388     /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ░░░░░░░░ 18909    /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ░░░░░░░░ 28544    /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           █░░░░░░░ 38090    /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           █░░░░░░░ 47614    /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           █░░░░░░░ 57210    /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ██░░░░░░ 66691    /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ██░░░░░░ 76184    /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ██░░░░░░ 85412    /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ███░░░░░ 94748    /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ███░░░░░ 103850   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ███░░░░░ 112892   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ███░░░░░ 121773   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ████░░░░ 131177   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ████░░░░ 140535   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           ████░░░░ 149505   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           █████░░░ 158787   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           █████░░░ 168085   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           █████░░░ 177083   /   245472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           ██████░░ 186423   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           ██████░░ 195693   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           ██████░░ 205094   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           ██████░░ 214391   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           ███████░ 223705   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           ███████░ 233158   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           ███████░ 242521   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Tokenize words                           ████████ 245472   /   245472\n",
      "\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Count pairs                              ████████ 245472   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Count pairs                              ████████ 245472   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Count pairs                              ████████ 245472   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Count pairs                              ████████ 245472   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Count pairs                              ████████ 245472   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Count pairs                              ████████ 245472   /   245472\n",
      "\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ████████ 245472   /   245472\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ████████ 245472   /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ████████ 245472   /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ████████ 245472   /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 8        /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 31       /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 88       /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 201      /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 465      /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 941      /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 1435     /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 2017     /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 2828     /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 3828     /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 4918     /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 5877     /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 6935     /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 8248     /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           ░░░░░░░░ 9498     /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           ░░░░░░░░ 10891    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           █░░░░░░░ 12602    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           █░░░░░░░ 13952    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           █░░░░░░░ 15365    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           █░░░░░░░ 16961    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           █░░░░░░░ 18625    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           █░░░░░░░ 20185    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           █░░░░░░░ 21714    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           █░░░░░░░ 23032    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           █░░░░░░░ 24391    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           ██░░░░░░ 25895    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           ██░░░░░░ 27505    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           ██░░░░░░ 29172    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           ██░░░░░░ 30916    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Compute merges                           ██░░░░░░ 32079    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ██░░░░░░ 33877    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ██░░░░░░ 35667    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ██░░░░░░ 37484    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ███░░░░░ 39351    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ███░░░░░ 41238    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ███░░░░░ 43085    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ███░░░░░ 44926    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ███░░░░░ 46794    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ███░░░░░ 48682    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ████░░░░ 50522    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ████░░░░ 52421    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ████░░░░ 54289    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ████░░░░ 56234    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ████░░░░ 57801    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:02] Compute merges                           ████░░░░ 59645    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           ████░░░░ 61532    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           ████░░░░ 62466    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           █████░░░ 63904    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           █████░░░ 65846    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           █████░░░ 67762    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           █████░░░ 69711    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           █████░░░ 71430    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           █████░░░ 73378    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           ██████░░ 75447    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           ██████░░ 77519    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           ██████░░ 78901    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           ██████░░ 80620    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           ██████░░ 82496    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           ██████░░ 84429    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:03] Compute merges                           ██████░░ 86488    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Compute merges                           ███████░ 88531    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Compute merges                           ███████░ 90650    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Compute merges                           ███████░ 92596    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Compute merges                           ███████░ 94096    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Compute merges                           ███████░ 95737    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Compute merges                           ███████░ 97685    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Compute merges                           ███████░ 99467    /   100000\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:04] Compute merges                           ████████ 99919    /    99919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir tokenizers\n",
    "!python create_tokenizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir pretrained_weights\n",
      "8994\n",
      "processing notes file\n",
      "writing to ./mimicdata/mimic3/disch_full.csv\n",
      "2083180it [00:55, 37470.63it/s] \n",
      "52726\n",
      "Num types 150853\n",
      "Num tokens 79801402\n",
      "sys:1: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "52726 58976\n",
      "sys:1: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "52726\n",
      "CONCATENATING\n",
      "0 done\n",
      "10000 done\n",
      "20000 done\n",
      "30000 done\n",
      "40000 done\n",
      "50000 done\n",
      "./mimicdata/mimic3/notes_labeled.csv\n",
      "num types 150853 num tokens 79801402\n",
      "52726\n",
      "SPLITTING\n",
      "0 read\n",
      "10000 read\n",
      "20000 read\n",
      "30000 read\n",
      "40000 read\n",
      "50000 read\n",
      "reading in data...\n",
      "removing rare terms\n",
      "51917 terms qualify out of 140794 total\n",
      "writing output\n",
      "building word2vec vocab on ./mimicdata/mimic3/disch_full.csv...\n",
      "training...\n",
      "writing embeddings to ./mimicdata/mimic3/processed_full.w2v\n",
      "100%|█████████████████████████████████| 51917/51917 [00:00<00:00, 547397.15it/s]\n",
      "100%|█████████████████████████████████| 22267/22267 [00:00<00:00, 172436.87it/s]\n",
      "['401.9', '38.93', '428.0', '427.31', '414.01', '96.04', '96.6', '584.9', '250.00', '96.71', '272.4', '518.81', '99.04', '39.61', '599.0', '530.81', '96.72', '272.0', '285.9', '88.56', '244.9', '486', '38.91', '285.1', '36.15', '276.2', '496', '99.15', '995.92', 'V58.61', '507.0', '038.9', '88.72', '585.9', '403.90', '311', '305.1', '37.22', '412', '33.24', '39.95', '287.5', '410.71', '276.1', 'V45.81', '424.0', '45.13', 'V15.82', '511.9', '37.23']\n",
      "train\n",
      "dev\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "!python dataproc_mimic_III.py ../mimic3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(Y='full', batch_size=4, bert_parallel_count=None, bert_parallel_final_layer='sum', bidirectional=None, cell_type='gru', code_emb=None, criterion='prec_at_8', cuda_device_no=None, data_path='./mimicdata/mimic3/train_full.csv', dropout=0.2, embed_file='./mimicdata/mimic3/processed_full.embed', embed_size=100, filter_size='10', from_scratch=False, gpu=True, last_module='caml_attn', lmbda=0, lr=5e-05, max_sequence_length=2500, model='bert-tiny-caml', n_epochs=15, num_filter_maps=50, patience=10, pool=None, pos=False, pretrain=False, pretrain_batch_size=2, pretrain_datafile='./mimicdata/mimic3/pretrain_bert_tiny_2500', pretrain_epochs=3, pretrain_lr=0.0001, public_model=None, quiet=None, redefined_tokenizer=False, rnn_dim=128, rnn_layers=1, samples=None, seed=1598, stack_filters=None, test_model=None, tokenizer_path='./tokenizers/bert-tiny-mimic3-full-100-limit-100000-vocab.txt', version='mimic3', vocab='./mimicdata/mimic3/vocab.csv', warmup_steps=0, weight_decay=0)\n",
      "loading lookups...\n",
      "loading pretrained embeddings...\n",
      "adding unk embedding\n",
      "BertWithCAMLForMedical(\n",
      "  (bert): BertModel(\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (embed): Embedding(51919, 100, padding_idx=0)\n",
      "  (expand_linear): Linear(in_features=100, out_features=128, bias=False)\n",
      "  (bert_pool): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (bert_attention): Linear(in_features=128, out_features=8921, bias=False)\n",
      "  (bert_classifier): Linear(in_features=128, out_features=8921, bias=True)\n",
      ")\n",
      "EPOCH 0\n",
      "0it [00:00, ?it/s]Train epoch: 0 [batch #0, batch_size 4, seq length 68]\tLoss: 0.698001\n",
      "18it [00:00, 31.18it/s]Train epoch: 0 [batch #25, batch_size 4, seq length 221]\tLoss: 0.634066\n",
      "50it [00:00, 54.67it/s]Train epoch: 0 [batch #50, batch_size 4, seq length 270]\tLoss: 0.518515\n",
      "71it [00:01, 60.98it/s]Train epoch: 0 [batch #75, batch_size 4, seq length 307]\tLoss: 0.395133\n",
      "99it [00:01, 62.65it/s]Train epoch: 0 [batch #100, batch_size 4, seq length 333]\tLoss: 0.284596\n",
      "120it [00:01, 61.42it/s]Train epoch: 0 [batch #125, batch_size 4, seq length 354]\tLoss: 0.198534\n",
      "148it [00:02, 59.49it/s]Train epoch: 0 [batch #150, batch_size 4, seq length 370]\tLoss: 0.137646\n",
      "174it [00:02, 58.65it/s]Train epoch: 0 [batch #175, batch_size 4, seq length 386]\tLoss: 0.098052\n",
      "198it [00:03, 57.63it/s]Train epoch: 0 [batch #200, batch_size 4, seq length 400]\tLoss: 0.071470\n",
      "222it [00:03, 55.61it/s]Train epoch: 0 [batch #225, batch_size 4, seq length 414]\tLoss: 0.054990\n",
      "246it [00:04, 55.32it/s]Train epoch: 0 [batch #250, batch_size 4, seq length 428]\tLoss: 0.042621\n",
      "270it [00:04, 53.69it/s]Train epoch: 0 [batch #275, batch_size 4, seq length 439]\tLoss: 0.034089\n",
      "300it [00:05, 54.01it/s]Train epoch: 0 [batch #300, batch_size 4, seq length 450]\tLoss: 0.028931\n",
      "324it [00:05, 50.86it/s]Train epoch: 0 [batch #325, batch_size 4, seq length 463]\tLoss: 0.024167\n",
      "348it [00:06, 50.55it/s]Train epoch: 0 [batch #350, batch_size 4, seq length 472]\tLoss: 0.021764\n",
      "372it [00:06, 50.42it/s]Train epoch: 0 [batch #375, batch_size 4, seq length 480]\tLoss: 0.019076\n",
      "396it [00:06, 50.87it/s]Train epoch: 0 [batch #400, batch_size 4, seq length 489]\tLoss: 0.016811\n",
      "420it [00:07, 51.29it/s]Train epoch: 0 [batch #425, batch_size 4, seq length 497]\tLoss: 0.015386\n",
      "450it [00:08, 51.42it/s]Train epoch: 0 [batch #450, batch_size 4, seq length 504]\tLoss: 0.013797\n",
      "474it [00:08, 50.61it/s]Train epoch: 0 [batch #475, batch_size 4, seq length 512]\tLoss: 0.013721\n",
      "496it [00:08, 48.13it/s]Train epoch: 0 [batch #500, batch_size 4, seq length 519]\tLoss: 0.011826\n",
      "521it [00:09, 44.97it/s]Train epoch: 0 [batch #525, batch_size 4, seq length 527]\tLoss: 0.011803\n",
      "546it [00:10, 46.82it/s]Train epoch: 0 [batch #550, batch_size 4, seq length 534]\tLoss: 0.010801\n",
      "571it [00:10, 44.69it/s]Train epoch: 0 [batch #575, batch_size 4, seq length 541]\tLoss: 0.010342\n",
      "596it [00:11, 44.72it/s]Train epoch: 0 [batch #600, batch_size 4, seq length 547]\tLoss: 0.010526\n",
      "621it [00:11, 44.61it/s]Train epoch: 0 [batch #625, batch_size 4, seq length 553]\tLoss: 0.009653\n",
      "646it [00:12, 40.22it/s]Train epoch: 0 [batch #650, batch_size 4, seq length 559]\tLoss: 0.009035\n",
      "671it [00:12, 40.09it/s]Train epoch: 0 [batch #675, batch_size 4, seq length 566]\tLoss: 0.008216\n",
      "696it [00:13, 44.51it/s]Train epoch: 0 [batch #700, batch_size 4, seq length 573]\tLoss: 0.008669\n",
      "721it [00:14, 44.20it/s]Train epoch: 0 [batch #725, batch_size 4, seq length 578]\tLoss: 0.008562\n",
      "746it [00:14, 40.17it/s]Train epoch: 0 [batch #750, batch_size 4, seq length 584]\tLoss: 0.008066\n",
      "775it [00:15, 39.35it/s]Train epoch: 0 [batch #775, batch_size 4, seq length 589]\tLoss: 0.008587\n",
      "800it [00:15, 42.92it/s]Train epoch: 0 [batch #800, batch_size 4, seq length 596]\tLoss: 0.008172\n",
      "825it [00:16, 43.28it/s]Train epoch: 0 [batch #825, batch_size 4, seq length 601]\tLoss: 0.008277\n",
      "850it [00:17, 43.20it/s]Train epoch: 0 [batch #850, batch_size 4, seq length 606]\tLoss: 0.008341\n",
      "875it [00:17, 39.50it/s]Train epoch: 0 [batch #875, batch_size 4, seq length 612]\tLoss: 0.007676\n",
      "900it [00:18, 38.98it/s]Train epoch: 0 [batch #900, batch_size 4, seq length 617]\tLoss: 0.007674\n",
      "922it [00:18, 39.32it/s]Train epoch: 0 [batch #925, batch_size 4, seq length 622]\tLoss: 0.007391\n",
      "947it [00:19, 41.93it/s]Train epoch: 0 [batch #950, batch_size 4, seq length 627]\tLoss: 0.007216\n",
      "972it [00:20, 42.40it/s]Train epoch: 0 [batch #975, batch_size 4, seq length 632]\tLoss: 0.006384\n",
      "997it [00:20, 39.63it/s]Train epoch: 0 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.007523\n",
      "1022it [00:21, 40.76it/s]Train epoch: 0 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.008718\n",
      "1050it [00:22, 40.16it/s]Train epoch: 0 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.007068\n",
      "1072it [00:22, 38.24it/s]Train epoch: 0 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.007151\n",
      "1098it [00:23, 39.59it/s]Train epoch: 0 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.007309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1123it [00:23, 41.43it/s]Train epoch: 0 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.007377\n",
      "1148it [00:24, 41.62it/s]Train epoch: 0 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.007425\n",
      "1173it [00:25, 40.93it/s]Train epoch: 0 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.007463\n",
      "1197it [00:25, 37.26it/s]Train epoch: 0 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.007373\n",
      "1225it [00:26, 31.67it/s]Train epoch: 0 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.007558\n",
      "1250it [00:27, 37.03it/s]Train epoch: 0 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.007391\n",
      "1274it [00:28, 37.35it/s]Train epoch: 0 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.006399\n",
      "1299it [00:28, 39.09it/s]Train epoch: 0 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.006307\n",
      "1324it [00:29, 39.92it/s]Train epoch: 0 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.006686\n",
      "1347it [00:29, 40.20it/s]Train epoch: 0 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.008148\n",
      "1372it [00:30, 39.91it/s]Train epoch: 0 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.006778\n",
      "1397it [00:31, 39.62it/s]Train epoch: 0 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.006664\n",
      "1423it [00:31, 39.73it/s]Train epoch: 0 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.006465\n",
      "1447it [00:32, 39.86it/s]Train epoch: 0 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.006652\n",
      "1473it [00:33, 37.99it/s]Train epoch: 0 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.007309\n",
      "1498it [00:33, 38.55it/s]Train epoch: 0 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.008250\n",
      "1522it [00:34, 37.47it/s]Train epoch: 0 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.007562\n",
      "1550it [00:35, 36.30it/s]Train epoch: 0 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.006507\n",
      "1574it [00:35, 36.89it/s]Train epoch: 0 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.007281\n",
      "1598it [00:36, 37.93it/s]Train epoch: 0 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.006559\n",
      "1622it [00:37, 35.74it/s]Train epoch: 0 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.007151\n",
      "1650it [00:37, 32.43it/s]Train epoch: 0 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.007517\n",
      "1674it [00:38, 33.02it/s]Train epoch: 0 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.007033\n",
      "1698it [00:39, 33.38it/s]Train epoch: 0 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.006370\n",
      "1722it [00:40, 35.04it/s]Train epoch: 0 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.005971\n",
      "1750it [00:40, 36.54it/s]Train epoch: 0 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.007795\n",
      "1774it [00:41, 36.16it/s]Train epoch: 0 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.006697\n",
      "1798it [00:42, 35.57it/s]Train epoch: 0 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.006576\n",
      "1822it [00:42, 36.13it/s]Train epoch: 0 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.006143\n",
      "1850it [00:43, 33.32it/s]Train epoch: 0 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.006998\n",
      "1874it [00:44, 32.50it/s]Train epoch: 0 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.007345\n",
      "1898it [00:45, 32.96it/s]Train epoch: 0 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.005997\n",
      "1922it [00:45, 34.96it/s]Train epoch: 0 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.006283\n",
      "1950it [00:46, 32.74it/s]Train epoch: 0 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.006313\n",
      "1974it [00:47, 34.87it/s]Train epoch: 0 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.007212\n",
      "1998it [00:48, 35.18it/s]Train epoch: 0 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.005985\n",
      "2022it [00:48, 29.73it/s]Train epoch: 0 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.007096\n",
      "2049it [00:49, 31.08it/s]Train epoch: 0 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.006470\n",
      "2073it [00:50, 31.36it/s]Train epoch: 0 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.006487\n",
      "2097it [00:51, 34.50it/s]Train epoch: 0 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.007001\n",
      "2125it [00:51, 34.17it/s]Train epoch: 0 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.007440\n",
      "2149it [00:52, 33.27it/s]Train epoch: 0 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.006562\n",
      "2173it [00:53, 34.80it/s]Train epoch: 0 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.007353\n",
      "2197it [00:54, 34.11it/s]Train epoch: 0 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.006910\n",
      "2225it [00:54, 33.76it/s]Train epoch: 0 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.006933\n",
      "2249it [00:55, 33.80it/s]Train epoch: 0 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.006292\n",
      "2273it [00:56, 34.14it/s]Train epoch: 0 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.006922\n",
      "2297it [00:57, 34.11it/s]Train epoch: 0 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.005678\n",
      "2325it [00:57, 33.71it/s]Train epoch: 0 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.006781\n",
      "2349it [00:58, 32.54it/s]Train epoch: 0 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.006708\n",
      "2373it [00:59, 33.49it/s]Train epoch: 0 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.008282\n",
      "2397it [01:00, 33.54it/s]Train epoch: 0 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.007904\n",
      "2425it [01:00, 32.90it/s]Train epoch: 0 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.005955\n",
      "2449it [01:01, 32.50it/s]Train epoch: 0 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.006726\n",
      "2473it [01:02, 31.69it/s]Train epoch: 0 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.007371\n",
      "2497it [01:03, 31.48it/s]Train epoch: 0 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.006535\n",
      "2525it [01:04, 31.40it/s]Train epoch: 0 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.006569\n",
      "2549it [01:04, 31.41it/s]Train epoch: 0 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.008191\n",
      "2574it [01:05, 28.64it/s]Train epoch: 0 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.006662\n",
      "2598it [01:06, 30.50it/s]Train epoch: 0 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.006904\n",
      "2622it [01:07, 30.47it/s]Train epoch: 0 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.007001\n",
      "2650it [01:08, 31.09it/s]Train epoch: 0 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.007268\n",
      "2674it [01:08, 31.06it/s]Train epoch: 0 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.006890\n",
      "2698it [01:09, 31.70it/s]Train epoch: 0 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.006509\n",
      "2722it [01:10, 29.42it/s]Train epoch: 0 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.006887\n",
      "2750it [01:11, 31.23it/s]Train epoch: 0 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.007841\n",
      "2774it [01:12, 30.52it/s]Train epoch: 0 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.007146\n",
      "2798it [01:12, 31.23it/s]Train epoch: 0 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.006809\n",
      "2822it [01:13, 31.31it/s]Train epoch: 0 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.006996\n",
      "2850it [01:14, 31.14it/s]Train epoch: 0 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.006914\n",
      "2874it [01:15, 29.87it/s]Train epoch: 0 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.007542\n",
      "2898it [01:16, 30.00it/s]Train epoch: 0 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.007134\n",
      "2922it [01:16, 30.42it/s]Train epoch: 0 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.007409\n",
      "2950it [01:17, 29.97it/s]Train epoch: 0 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.007287\n",
      "2974it [01:18, 30.64it/s]Train epoch: 0 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.007327\n",
      "2998it [01:19, 30.11it/s]Train epoch: 0 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.007861\n",
      "3022it [01:20, 30.54it/s]Train epoch: 0 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.007694\n",
      "3049it [01:21, 30.17it/s]Train epoch: 0 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.006891\n",
      "3073it [01:21, 29.86it/s]Train epoch: 0 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.007657\n",
      "3100it [01:22, 30.11it/s]Train epoch: 0 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.007560\n",
      "3124it [01:23, 30.14it/s]Train epoch: 0 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.007152\n",
      "3148it [01:24, 29.43it/s]Train epoch: 0 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.006789\n",
      "3175it [01:25, 28.35it/s]Train epoch: 0 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.006696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200it [01:26, 29.69it/s]Train epoch: 0 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.007428\n",
      "3224it [01:27, 29.80it/s]Train epoch: 0 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.007073\n",
      "3248it [01:27, 29.80it/s]Train epoch: 0 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.007343\n",
      "3275it [01:28, 29.72it/s]Train epoch: 0 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.006873\n",
      "3299it [01:29, 29.12it/s]Train epoch: 0 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.008267\n",
      "3323it [01:30, 28.71it/s]Train epoch: 0 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.007423\n",
      "3350it [01:31, 29.39it/s]Train epoch: 0 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.007036\n",
      "3374it [01:32, 29.24it/s]Train epoch: 0 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.008066\n",
      "3398it [01:32, 28.68it/s]Train epoch: 0 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.007651\n",
      "3425it [01:33, 29.13it/s]Train epoch: 0 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.006939\n",
      "3449it [01:34, 25.04it/s]Train epoch: 0 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.007756\n",
      "3473it [01:35, 27.68it/s]Train epoch: 0 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.007090\n",
      "3500it [01:36, 28.25it/s]Train epoch: 0 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.007221\n",
      "3524it [01:37, 26.54it/s]Train epoch: 0 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.007583\n",
      "3548it [01:38, 27.05it/s]Train epoch: 0 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.007803\n",
      "3575it [01:39, 21.06it/s]Train epoch: 0 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.006541\n",
      "3599it [01:40, 24.57it/s]Train epoch: 0 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.008241\n",
      "3623it [01:41, 28.75it/s]Train epoch: 0 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.007461\n",
      "3650it [01:42, 26.11it/s]Train epoch: 0 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.007733\n",
      "3674it [01:43, 24.12it/s]Train epoch: 0 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.007672\n",
      "3698it [01:44, 23.43it/s]Train epoch: 0 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.007571\n",
      "3725it [01:45, 24.02it/s]Train epoch: 0 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.007664\n",
      "3749it [01:46, 22.88it/s]Train epoch: 0 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.008321\n",
      "3773it [01:47, 23.42it/s]Train epoch: 0 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.007447\n",
      "3800it [01:48, 23.05it/s]Train epoch: 0 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.008286\n",
      "3824it [01:50, 22.51it/s]Train epoch: 0 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.007281\n",
      "3848it [01:51, 22.86it/s]Train epoch: 0 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.006823\n",
      "3875it [01:52, 21.94it/s]Train epoch: 0 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.006896\n",
      "3899it [01:53, 22.82it/s]Train epoch: 0 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.008013\n",
      "3923it [01:54, 22.01it/s]Train epoch: 0 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.007341\n",
      "3950it [01:55, 21.58it/s]Train epoch: 0 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.008222\n",
      "3974it [01:56, 22.87it/s]Train epoch: 0 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.008982\n",
      "3998it [01:57, 22.27it/s]Train epoch: 0 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.007172\n",
      "4025it [01:59, 22.26it/s]Train epoch: 0 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.008454\n",
      "4049it [02:00, 21.83it/s]Train epoch: 0 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.007933\n",
      "4073it [02:01, 21.71it/s]Train epoch: 0 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.007972\n",
      "4100it [02:02, 21.54it/s]Train epoch: 0 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.008309\n",
      "4124it [02:03, 22.47it/s]Train epoch: 0 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.008483\n",
      "4148it [02:04, 21.89it/s]Train epoch: 0 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.007277\n",
      "4175it [02:05, 21.21it/s]Train epoch: 0 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.007802\n",
      "4199it [02:06, 21.69it/s]Train epoch: 0 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.008236\n",
      "4223it [02:08, 21.99it/s]Train epoch: 0 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.007312\n",
      "4250it [02:09, 21.74it/s]Train epoch: 0 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.008615\n",
      "4274it [02:10, 22.05it/s]Train epoch: 0 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.007624\n",
      "4298it [02:11, 21.86it/s]Train epoch: 0 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.008428\n",
      "4325it [02:12, 21.55it/s]Train epoch: 0 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.007678\n",
      "4349it [02:13, 20.06it/s]Train epoch: 0 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.008431\n",
      "4375it [02:15, 18.92it/s]Train epoch: 0 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.007995\n",
      "4399it [02:16, 21.13it/s]Train epoch: 0 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.007272\n",
      "4423it [02:17, 21.46it/s]Train epoch: 0 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.008133\n",
      "4450it [02:18, 21.38it/s]Train epoch: 0 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.006620\n",
      "4474it [02:19, 20.96it/s]Train epoch: 0 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.008148\n",
      "4498it [02:21, 21.33it/s]Train epoch: 0 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.009146\n",
      "4525it [02:22, 21.21it/s]Train epoch: 0 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.008011\n",
      "4549it [02:23, 21.40it/s]Train epoch: 0 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.007665\n",
      "4573it [02:24, 20.82it/s]Train epoch: 0 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.008368\n",
      "4600it [02:25, 19.29it/s]Train epoch: 0 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.007199\n",
      "4625it [02:27, 18.66it/s]Train epoch: 0 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.007601\n",
      "4650it [02:28, 19.30it/s]Train epoch: 0 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.008564\n",
      "4674it [02:29, 19.54it/s]Train epoch: 0 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.007963\n",
      "4699it [02:31, 20.17it/s]Train epoch: 0 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.007395\n",
      "4725it [02:32, 19.34it/s]Train epoch: 0 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.007854\n",
      "4750it [02:33, 19.31it/s]Train epoch: 0 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.008819\n",
      "4774it [02:34, 19.62it/s]Train epoch: 0 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.008013\n",
      "4799it [02:36, 19.12it/s]Train epoch: 0 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.008458\n",
      "4825it [02:37, 19.16it/s]Train epoch: 0 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.007199\n",
      "4849it [02:38, 19.53it/s]Train epoch: 0 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.008244\n",
      "4875it [02:40, 19.57it/s]Train epoch: 0 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.007579\n",
      "4899it [02:41, 18.37it/s]Train epoch: 0 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.007914\n",
      "4925it [02:42, 18.60it/s]Train epoch: 0 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.007646\n",
      "4949it [02:44, 18.53it/s]Train epoch: 0 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.007575\n",
      "4975it [02:45, 18.43it/s]Train epoch: 0 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.007859\n",
      "4999it [02:46, 18.72it/s]Train epoch: 0 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.008204\n",
      "5025it [02:48, 18.46it/s]Train epoch: 0 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.007410\n",
      "5049it [02:49, 18.98it/s]Train epoch: 0 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.007389\n",
      "5075it [02:51, 18.86it/s]Train epoch: 0 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.007801\n",
      "5099it [02:52, 18.30it/s]Train epoch: 0 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.007581\n",
      "5125it [02:53, 18.80it/s]Train epoch: 0 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.008011\n",
      "5149it [02:54, 19.10it/s]Train epoch: 0 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.007884\n",
      "5175it [02:56, 19.13it/s]Train epoch: 0 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.007978\n",
      "5199it [02:57, 18.67it/s]Train epoch: 0 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.007218\n",
      "5225it [02:59, 18.61it/s]Train epoch: 0 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.008065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5249it [03:00, 17.88it/s]Train epoch: 0 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.007792\n",
      "5275it [03:01, 18.59it/s]Train epoch: 0 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.007706\n",
      "5299it [03:03, 18.54it/s]Train epoch: 0 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.007525\n",
      "5325it [03:04, 18.47it/s]Train epoch: 0 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.008681\n",
      "5349it [03:05, 17.87it/s]Train epoch: 0 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.008299\n",
      "5375it [03:07, 18.22it/s]Train epoch: 0 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.007560\n",
      "5399it [03:08, 18.24it/s]Train epoch: 0 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.007881\n",
      "5425it [03:09, 18.71it/s]Train epoch: 0 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.008031\n",
      "5449it [03:11, 18.34it/s]Train epoch: 0 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.007946\n",
      "5475it [03:12, 18.38it/s]Train epoch: 0 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.008942\n",
      "5499it [03:13, 18.36it/s]Train epoch: 0 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.008445\n",
      "5525it [03:15, 17.77it/s]Train epoch: 0 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.007478\n",
      "5549it [03:16, 18.20it/s]Train epoch: 0 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.007691\n",
      "5575it [03:18, 18.12it/s]Train epoch: 0 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.008389\n",
      "5599it [03:19, 18.10it/s]Train epoch: 0 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.008793\n",
      "5625it [03:20, 16.66it/s]Train epoch: 0 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.008155\n",
      "5649it [03:22, 18.03it/s]Train epoch: 0 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.007456\n",
      "5675it [03:23, 17.94it/s]Train epoch: 0 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.008640\n",
      "5699it [03:25, 18.09it/s]Train epoch: 0 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.007575\n",
      "5725it [03:26, 18.03it/s]Train epoch: 0 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.007630\n",
      "5749it [03:27, 17.45it/s]Train epoch: 0 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.009400\n",
      "5775it [03:29, 16.69it/s]Train epoch: 0 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.008113\n",
      "5799it [03:30, 16.78it/s]Train epoch: 0 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.008457\n",
      "5825it [03:32, 17.42it/s]Train epoch: 0 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.007115\n",
      "5849it [03:33, 17.34it/s]Train epoch: 0 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.009279\n",
      "5875it [03:35, 16.49it/s]Train epoch: 0 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.008671\n",
      "5899it [03:36, 17.34it/s]Train epoch: 0 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.009127\n",
      "5925it [03:38, 16.58it/s]Train epoch: 0 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.007514\n",
      "5949it [03:39, 17.11it/s]Train epoch: 0 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.007395\n",
      "5975it [03:41, 16.16it/s]Train epoch: 0 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.009400\n",
      "5999it [03:42, 16.30it/s]Train epoch: 0 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.008379\n",
      "6025it [03:44, 17.01it/s]Train epoch: 0 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.008829\n",
      "6049it [03:46, 14.22it/s]Train epoch: 0 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.008012\n",
      "6075it [03:47, 16.99it/s]Train epoch: 0 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.007752\n",
      "6099it [03:49, 16.27it/s]Train epoch: 0 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.007617\n",
      "6125it [03:50, 16.97it/s]Train epoch: 0 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.007821\n",
      "6149it [03:52, 16.71it/s]Train epoch: 0 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.008103\n",
      "6175it [03:53, 16.82it/s]Train epoch: 0 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.008534\n",
      "6199it [03:55, 16.57it/s]Train epoch: 0 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.008508\n",
      "6225it [03:56, 16.79it/s]Train epoch: 0 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.007443\n",
      "6249it [03:58, 16.86it/s]Train epoch: 0 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.007696\n",
      "6275it [03:59, 15.60it/s]Train epoch: 0 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.007211\n",
      "6299it [04:01, 16.85it/s]Train epoch: 0 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.008401\n",
      "6325it [04:02, 16.69it/s]Train epoch: 0 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.008432\n",
      "6349it [04:04, 16.77it/s]Train epoch: 0 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.008816\n",
      "6375it [04:05, 16.49it/s]Train epoch: 0 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.007735\n",
      "6399it [04:07, 16.36it/s]Train epoch: 0 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.008090\n",
      "6425it [04:08, 16.46it/s]Train epoch: 0 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.008964\n",
      "6449it [04:10, 14.96it/s]Train epoch: 0 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.008431\n",
      "6475it [04:12, 15.25it/s]Train epoch: 0 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.007887\n",
      "6499it [04:13, 16.02it/s]Train epoch: 0 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.008536\n",
      "6525it [04:15, 15.86it/s]Train epoch: 0 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.007671\n",
      "6549it [04:16, 15.84it/s]Train epoch: 0 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.007664\n",
      "6575it [04:18, 15.45it/s]Train epoch: 0 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.008022\n",
      "6599it [04:19, 16.04it/s]Train epoch: 0 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.009112\n",
      "6625it [04:21, 15.97it/s]Train epoch: 0 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.007759\n",
      "6649it [04:23, 15.96it/s]Train epoch: 0 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.008978\n",
      "6675it [04:24, 14.32it/s]Train epoch: 0 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.008166\n",
      "6699it [04:26, 15.09it/s]Train epoch: 0 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.008541\n",
      "6725it [04:28, 15.00it/s]Train epoch: 0 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.008365\n",
      "6749it [04:29, 16.16it/s]Train epoch: 0 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.007735\n",
      "6775it [04:31, 16.06it/s]Train epoch: 0 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.008659\n",
      "6799it [04:32, 15.85it/s]Train epoch: 0 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.008524\n",
      "6825it [04:34, 15.90it/s]Train epoch: 0 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.008636\n",
      "6849it [04:35, 15.81it/s]Train epoch: 0 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.008344\n",
      "6875it [04:37, 15.77it/s]Train epoch: 0 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.007289\n",
      "6899it [04:39, 15.52it/s]Train epoch: 0 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.008143\n",
      "6925it [04:40, 15.77it/s]Train epoch: 0 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.008202\n",
      "6949it [04:42, 15.72it/s]Train epoch: 0 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.008549\n",
      "6975it [04:43, 15.48it/s]Train epoch: 0 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.008554\n",
      "6999it [04:45, 15.66it/s]Train epoch: 0 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.008281\n",
      "7025it [04:47, 14.99it/s]Train epoch: 0 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.009569\n",
      "7049it [04:48, 15.08it/s]Train epoch: 0 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.007385\n",
      "7075it [04:50, 15.46it/s]Train epoch: 0 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.008174\n",
      "7099it [04:51, 15.60it/s]Train epoch: 0 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.008604\n",
      "7125it [04:53, 15.37it/s]Train epoch: 0 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.007652\n",
      "7149it [04:55, 15.38it/s]Train epoch: 0 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.008727\n",
      "7175it [04:56, 14.73it/s]Train epoch: 0 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.008433\n",
      "7199it [04:58, 15.53it/s]Train epoch: 0 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.009011\n",
      "7225it [05:00, 15.41it/s]Train epoch: 0 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.007997\n",
      "7249it [05:01, 15.33it/s]Train epoch: 0 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.008210\n",
      "7275it [05:03, 15.38it/s]Train epoch: 0 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.008926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7299it [05:04, 15.21it/s]Train epoch: 0 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.009295\n",
      "7325it [05:06, 15.14it/s]Train epoch: 0 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.008089\n",
      "7349it [05:08, 14.78it/s]Train epoch: 0 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.009005\n",
      "7375it [05:09, 14.95it/s]Train epoch: 0 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.008665\n",
      "7399it [05:11, 14.11it/s]Train epoch: 0 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.007920\n",
      "7425it [05:13, 14.49it/s]Train epoch: 0 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.008537\n",
      "7449it [05:15, 14.51it/s]Train epoch: 0 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.009222\n",
      "7475it [05:16, 15.00it/s]Train epoch: 0 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.008090\n",
      "7499it [05:18, 14.92it/s]Train epoch: 0 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.008587\n",
      "7525it [05:20, 14.83it/s]Train epoch: 0 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.008125\n",
      "7549it [05:21, 14.83it/s]Train epoch: 0 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.008065\n",
      "7575it [05:23, 14.42it/s]Train epoch: 0 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.008716\n",
      "7599it [05:25, 14.78it/s]Train epoch: 0 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.010202\n",
      "7625it [05:27, 14.24it/s]Train epoch: 0 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.009795\n",
      "7649it [05:28, 14.78it/s]Train epoch: 0 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.008260\n",
      "7675it [05:30, 14.88it/s]Train epoch: 0 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.008275\n",
      "7699it [05:32, 14.75it/s]Train epoch: 0 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.008539\n",
      "7725it [05:33, 14.87it/s]Train epoch: 0 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.008596\n",
      "7749it [05:35, 14.06it/s]Train epoch: 0 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.008675\n",
      "7775it [05:37, 14.27it/s]Train epoch: 0 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.008347\n",
      "7799it [05:39, 13.24it/s]Train epoch: 0 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.008364\n",
      "7825it [05:41, 14.40it/s]Train epoch: 0 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.008439\n",
      "7849it [05:42, 13.97it/s]Train epoch: 0 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.008210\n",
      "7875it [05:44, 14.17it/s]Train epoch: 0 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.008404\n",
      "7899it [05:46, 14.14it/s]Train epoch: 0 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.008665\n",
      "7925it [05:48, 13.25it/s]Train epoch: 0 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.008612\n",
      "7949it [05:50, 13.49it/s]Train epoch: 0 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.009238\n",
      "7975it [05:51, 13.93it/s]Train epoch: 0 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.008398\n",
      "7999it [05:53, 13.63it/s]Train epoch: 0 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.008232\n",
      "8025it [05:55, 13.55it/s]Train epoch: 0 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.009109\n",
      "8049it [05:57, 14.04it/s]Train epoch: 0 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.007889\n",
      "8075it [05:59, 13.91it/s]Train epoch: 0 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.008638\n",
      "8099it [06:01, 13.95it/s]Train epoch: 0 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.008715\n",
      "8125it [06:02, 13.67it/s]Train epoch: 0 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.009172\n",
      "8149it [06:04, 13.72it/s]Train epoch: 0 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.008214\n",
      "8175it [06:06, 13.81it/s]Train epoch: 0 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.009007\n",
      "8199it [06:08, 13.75it/s]Train epoch: 0 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.008442\n",
      "8225it [06:10, 13.76it/s]Train epoch: 0 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.009990\n",
      "8249it [06:11, 13.44it/s]Train epoch: 0 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.008510\n",
      "8275it [06:13, 13.15it/s]Train epoch: 0 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.009484\n",
      "8299it [06:15, 13.53it/s]Train epoch: 0 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.008388\n",
      "8325it [06:17, 13.22it/s]Train epoch: 0 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.009009\n",
      "8349it [06:19, 12.95it/s]Train epoch: 0 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.008189\n",
      "8375it [06:21, 13.32it/s]Train epoch: 0 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.009000\n",
      "8399it [06:23, 13.26it/s]Train epoch: 0 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.008241\n",
      "8425it [06:25, 13.02it/s]Train epoch: 0 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.008711\n",
      "8449it [06:27, 12.88it/s]Train epoch: 0 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.008939\n",
      "8475it [06:29, 13.20it/s]Train epoch: 0 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.008570\n",
      "8499it [06:31, 12.38it/s]Train epoch: 0 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.009549\n",
      "8525it [06:33, 12.56it/s]Train epoch: 0 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.008827\n",
      "8549it [06:35, 12.62it/s]Train epoch: 0 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.009121\n",
      "8575it [06:37, 13.04it/s]Train epoch: 0 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.008574\n",
      "8599it [06:38, 13.20it/s]Train epoch: 0 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.008704\n",
      "8625it [06:40, 12.50it/s]Train epoch: 0 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.008949\n",
      "8649it [06:42, 12.57it/s]Train epoch: 0 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.009121\n",
      "8675it [06:44, 12.88it/s]Train epoch: 0 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.009903\n",
      "8699it [06:46, 10.65it/s]Train epoch: 0 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.009711\n",
      "8725it [06:49, 12.09it/s]Train epoch: 0 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.009649\n",
      "8749it [06:51, 11.50it/s]Train epoch: 0 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.008943\n",
      "8775it [06:53, 12.19it/s]Train epoch: 0 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.008475\n",
      "8799it [06:55, 12.13it/s]Train epoch: 0 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.008904\n",
      "8825it [06:57, 12.59it/s]Train epoch: 0 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.008814\n",
      "8849it [06:59, 12.30it/s]Train epoch: 0 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.009286\n",
      "8875it [07:01, 11.51it/s]Train epoch: 0 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.008751\n",
      "8899it [07:03, 12.00it/s]Train epoch: 0 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.008854\n",
      "8925it [07:06, 12.06it/s]Train epoch: 0 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.009083\n",
      "8949it [07:07, 12.72it/s]Train epoch: 0 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.009999\n",
      "8975it [07:09, 12.25it/s]Train epoch: 0 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.009694\n",
      "8999it [07:11, 12.42it/s]Train epoch: 0 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.008730\n",
      "9025it [07:14, 11.04it/s]Train epoch: 0 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.009096\n",
      "9049it [07:16, 12.35it/s]Train epoch: 0 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.008843\n",
      "9075it [07:18, 11.82it/s]Train epoch: 0 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.007869\n",
      "9099it [07:20, 12.35it/s]Train epoch: 0 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.008878\n",
      "9125it [07:22, 11.47it/s]Train epoch: 0 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.008548\n",
      "9149it [07:24, 12.32it/s]Train epoch: 0 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.008237\n",
      "9175it [07:26, 12.06it/s]Train epoch: 0 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.008831\n",
      "9199it [07:28, 11.29it/s]Train epoch: 0 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.008601\n",
      "9225it [07:31, 12.02it/s]Train epoch: 0 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.010068\n",
      "9249it [07:33, 11.51it/s]Train epoch: 0 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.008375\n",
      "9275it [07:35, 10.25it/s]Train epoch: 0 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.009387\n",
      "9299it [07:37, 11.51it/s]Train epoch: 0 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.010067\n",
      "9325it [07:40, 10.67it/s]Train epoch: 0 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.010006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9349it [07:42, 11.85it/s]Train epoch: 0 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.009683\n",
      "9375it [07:44, 11.68it/s]Train epoch: 0 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.009208\n",
      "9399it [07:46, 10.89it/s]Train epoch: 0 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.009206\n",
      "9425it [07:48, 11.70it/s]Train epoch: 0 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.008724\n",
      "9449it [07:50, 11.77it/s]Train epoch: 0 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.008696\n",
      "9475it [07:53, 11.72it/s]Train epoch: 0 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.009870\n",
      "9499it [07:55, 11.78it/s]Train epoch: 0 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.009145\n",
      "9525it [07:57, 11.76it/s]Train epoch: 0 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.009678\n",
      "9549it [07:59, 11.52it/s]Train epoch: 0 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.009380\n",
      "9575it [08:01, 11.61it/s]Train epoch: 0 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.009635\n",
      "9599it [08:04, 10.70it/s]Train epoch: 0 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.009255\n",
      "9625it [08:06,  9.88it/s]Train epoch: 0 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.008777\n",
      "9649it [08:08, 10.40it/s]Train epoch: 0 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.008608\n",
      "9675it [08:11, 11.20it/s]Train epoch: 0 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.009327\n",
      "9699it [08:13, 10.60it/s]Train epoch: 0 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.008369\n",
      "9725it [08:15, 11.18it/s]Train epoch: 0 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.009437\n",
      "9750it [08:18,  9.67it/s]Train epoch: 0 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.009101\n",
      "9775it [08:20,  9.91it/s]Train epoch: 0 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.010063\n",
      "9800it [08:23,  9.96it/s]Train epoch: 0 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.009737\n",
      "9824it [08:25,  9.82it/s]Train epoch: 0 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.009608\n",
      "9849it [08:28,  9.99it/s]Train epoch: 0 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.009328\n",
      "9874it [08:30, 10.26it/s]Train epoch: 0 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.010116\n",
      "9900it [08:33, 10.11it/s]Train epoch: 0 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.010824\n",
      "9925it [08:35,  9.90it/s]Train epoch: 0 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.010116\n",
      "9950it [08:38,  9.88it/s]Train epoch: 0 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.010360\n",
      "9975it [08:40,  9.68it/s]Train epoch: 0 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.009796\n",
      "10000it [08:43,  9.89it/s]Train epoch: 0 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.009356\n",
      "10024it [08:45,  9.87it/s]Train epoch: 0 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.009364\n",
      "10050it [08:48,  9.88it/s]Train epoch: 0 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.010283\n",
      "10075it [08:51,  9.77it/s]Train epoch: 0 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.010602\n",
      "10100it [08:53,  9.05it/s]Train epoch: 0 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.009544\n",
      "10124it [08:56,  9.79it/s]Train epoch: 0 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.009359\n",
      "10150it [08:58,  9.49it/s]Train epoch: 0 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.009643\n",
      "10175it [09:01,  9.37it/s]Train epoch: 0 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.009232\n",
      "10200it [09:04,  9.55it/s]Train epoch: 0 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.009922\n",
      "10225it [09:06,  9.28it/s]Train epoch: 0 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.009977\n",
      "10250it [09:09,  9.61it/s]Train epoch: 0 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.010594\n",
      "10275it [09:12,  9.35it/s]Train epoch: 0 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.009313\n",
      "10300it [09:14,  9.16it/s]Train epoch: 0 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.010086\n",
      "10325it [09:17,  9.03it/s]Train epoch: 0 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.010152\n",
      "10350it [09:20,  9.34it/s]Train epoch: 0 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.009743\n",
      "10375it [09:22,  9.10it/s]Train epoch: 0 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.010092\n",
      "10400it [09:25,  9.19it/s]Train epoch: 0 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.010337\n",
      "10425it [09:28,  8.95it/s]Train epoch: 0 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.009766\n",
      "10450it [09:31,  8.84it/s]Train epoch: 0 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.010045\n",
      "10475it [09:33,  8.76it/s]Train epoch: 0 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.009070\n",
      "10500it [09:36,  8.58it/s]Train epoch: 0 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.010283\n",
      "10525it [09:39,  8.79it/s]Train epoch: 0 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.009663\n",
      "10550it [09:42,  8.93it/s]Train epoch: 0 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.010037\n",
      "10575it [09:45,  8.14it/s]Train epoch: 0 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.009332\n",
      "10600it [09:48,  8.48it/s]Train epoch: 0 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.009211\n",
      "10625it [09:51,  8.23it/s]Train epoch: 0 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.010003\n",
      "10650it [09:55,  7.00it/s]Train epoch: 0 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.009816\n",
      "10675it [09:58,  8.41it/s]Train epoch: 0 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.009991\n",
      "10700it [10:01,  7.70it/s]Train epoch: 0 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.009528\n",
      "10725it [10:04,  7.75it/s]Train epoch: 0 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.008769\n",
      "10750it [10:07,  8.23it/s]Train epoch: 0 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.010057\n",
      "10775it [10:11,  7.76it/s]Train epoch: 0 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.010400\n",
      "10800it [10:14,  8.17it/s]Train epoch: 0 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.010825\n",
      "10825it [10:17,  7.95it/s]Train epoch: 0 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.010399\n",
      "10850it [10:20,  8.25it/s]Train epoch: 0 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.010128\n",
      "10875it [10:23,  8.02it/s]Train epoch: 0 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.010561\n",
      "10900it [10:26,  7.14it/s]Train epoch: 0 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.010054\n",
      "10925it [10:30,  8.00it/s]Train epoch: 0 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.009700\n",
      "10950it [10:33,  7.92it/s]Train epoch: 0 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.009859\n",
      "10975it [10:36,  7.72it/s]Train epoch: 0 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.009738\n",
      "11000it [10:39,  8.16it/s]Train epoch: 0 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.009805\n",
      "11025it [10:42,  7.90it/s]Train epoch: 0 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.009948\n",
      "11050it [10:46,  7.48it/s]Train epoch: 0 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.010773\n",
      "11075it [10:49,  8.07it/s]Train epoch: 0 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.010445\n",
      "11100it [10:52,  7.94it/s]Train epoch: 0 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.011056\n",
      "11125it [10:55,  7.77it/s]Train epoch: 0 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.010742\n",
      "11150it [10:58,  7.79it/s]Train epoch: 0 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.010198\n",
      "11175it [11:02,  7.95it/s]Train epoch: 0 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.011368\n",
      "11200it [11:05,  7.91it/s]Train epoch: 0 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.010435\n",
      "11225it [11:08,  7.68it/s]Train epoch: 0 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.010355\n",
      "11250it [11:11,  7.82it/s]Train epoch: 0 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.011343\n",
      "11275it [11:14,  7.77it/s]Train epoch: 0 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.010923\n",
      "11300it [11:17,  7.95it/s]Train epoch: 0 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.010064\n",
      "11325it [11:20,  8.01it/s]Train epoch: 0 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.011143\n",
      "11350it [11:24,  7.81it/s]Train epoch: 0 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.011421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11375it [11:27,  7.95it/s]Train epoch: 0 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.011793\n",
      "11400it [11:30,  7.94it/s]Train epoch: 0 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.010276\n",
      "11425it [11:33,  7.59it/s]Train epoch: 0 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.010938\n",
      "11450it [11:36,  7.93it/s]Train epoch: 0 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.010257\n",
      "11475it [11:40,  7.92it/s]Train epoch: 0 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.012024\n",
      "11500it [11:43,  7.70it/s]Train epoch: 0 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.011506\n",
      "11525it [11:46,  7.83it/s]Train epoch: 0 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.010821\n",
      "11550it [11:49,  8.06it/s]Train epoch: 0 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.010839\n",
      "11575it [11:53,  7.61it/s]Train epoch: 0 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.011756\n",
      "11600it [11:56,  7.33it/s]Train epoch: 0 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.010964\n",
      "11625it [11:59,  7.38it/s]Train epoch: 0 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.010259\n",
      "11650it [12:03,  7.32it/s]Train epoch: 0 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.011173\n",
      "11675it [12:06,  7.79it/s]Train epoch: 0 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.011643\n",
      "11700it [12:09,  7.83it/s]Train epoch: 0 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.011986\n",
      "11725it [12:13,  7.45it/s]Train epoch: 0 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.012099\n",
      "11750it [12:16,  7.64it/s]Train epoch: 0 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.012082\n",
      "11775it [12:19,  7.96it/s]Train epoch: 0 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.011556\n",
      "11800it [12:22,  8.01it/s]Train epoch: 0 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.011471\n",
      "11825it [12:26,  7.37it/s]Train epoch: 0 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.011673\n",
      "11850it [12:29,  7.79it/s]Train epoch: 0 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.011714\n",
      "11875it [12:32,  7.79it/s]Train epoch: 0 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.012633\n",
      "11900it [12:35,  7.57it/s]Train epoch: 0 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.014975\n",
      "11925it [12:39,  7.75it/s]Train epoch: 0 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.013027\n",
      "11930it [12:39, 15.70it/s]\n",
      "epoch loss: 0.014185863886866172\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 127.97it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0009, 0.0017, 0.0013, 0.0015, 0.7175\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0707, 0.4993, 0.0761, 0.1320, 0.9555\n",
      "rec_at_8: 0.1536\n",
      "prec_at_8: 0.3200\n",
      "rec_at_15: 0.2303\n",
      "prec_at_15: 0.2574\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 131.67it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0008, 0.0016, 0.0013, 0.0014, 0.7105\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0714, 0.5155, 0.0766, 0.1334, 0.9539\n",
      "rec_at_8: 0.1502\n",
      "prec_at_8: 0.3261\n",
      "rec_at_15: 0.2232\n",
      "prec_at_15: 0.2597\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 0\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0009, 0.0017, 0.0013, 0.0015, 0.7175\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0707, 0.4993, 0.0761, 0.1320, 0.9555\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0091\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 0\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0008, 0.0016, 0.0013, 0.0014, 0.7105\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0714, 0.5155, 0.0766, 0.1334, 0.9539\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0094\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 1\n",
      "0it [00:00, ?it/s]Train epoch: 1 [batch #0, batch_size 4, seq length 68]\tLoss: 0.007304\n",
      "22it [00:00, 47.37it/s]Train epoch: 1 [batch #25, batch_size 4, seq length 221]\tLoss: 0.005821\n",
      "47it [00:00, 47.28it/s]Train epoch: 1 [batch #50, batch_size 4, seq length 270]\tLoss: 0.005695\n",
      "72it [00:01, 40.87it/s]Train epoch: 1 [batch #75, batch_size 4, seq length 307]\tLoss: 0.005003\n",
      "99it [00:02, 37.11it/s]Train epoch: 1 [batch #100, batch_size 4, seq length 333]\tLoss: 0.004856\n",
      "124it [00:03, 34.53it/s]Train epoch: 1 [batch #125, batch_size 4, seq length 354]\tLoss: 0.005274\n",
      "149it [00:03, 38.12it/s]Train epoch: 1 [batch #150, batch_size 4, seq length 370]\tLoss: 0.004610\n",
      "173it [00:04, 36.21it/s]Train epoch: 1 [batch #175, batch_size 4, seq length 386]\tLoss: 0.005157\n",
      "197it [00:05, 34.62it/s]Train epoch: 1 [batch #200, batch_size 4, seq length 400]\tLoss: 0.004618\n",
      "225it [00:05, 33.98it/s]Train epoch: 1 [batch #225, batch_size 4, seq length 414]\tLoss: 0.005808\n",
      "250it [00:06, 35.39it/s]Train epoch: 1 [batch #250, batch_size 4, seq length 428]\tLoss: 0.004927\n",
      "274it [00:07, 34.40it/s]Train epoch: 1 [batch #275, batch_size 4, seq length 439]\tLoss: 0.004217\n",
      "298it [00:08, 31.04it/s]Train epoch: 1 [batch #300, batch_size 4, seq length 450]\tLoss: 0.005461\n",
      "322it [00:08, 31.40it/s]Train epoch: 1 [batch #325, batch_size 4, seq length 463]\tLoss: 0.004541\n",
      "350it [00:09, 33.04it/s]Train epoch: 1 [batch #350, batch_size 4, seq length 472]\tLoss: 0.005518\n",
      "374it [00:10, 31.36it/s]Train epoch: 1 [batch #375, batch_size 4, seq length 480]\tLoss: 0.004950\n",
      "398it [00:11, 32.36it/s]Train epoch: 1 [batch #400, batch_size 4, seq length 489]\tLoss: 0.004930\n",
      "422it [00:12, 30.01it/s]Train epoch: 1 [batch #425, batch_size 4, seq length 497]\tLoss: 0.005159\n",
      "449it [00:12, 30.03it/s]Train epoch: 1 [batch #450, batch_size 4, seq length 504]\tLoss: 0.004929\n",
      "473it [00:13, 31.00it/s]Train epoch: 1 [batch #475, batch_size 4, seq length 512]\tLoss: 0.005346\n",
      "497it [00:14, 31.09it/s]Train epoch: 1 [batch #500, batch_size 4, seq length 519]\tLoss: 0.004568\n",
      "522it [00:15, 27.27it/s]Train epoch: 1 [batch #525, batch_size 4, seq length 527]\tLoss: 0.005437\n",
      "550it [00:16, 29.79it/s]Train epoch: 1 [batch #550, batch_size 4, seq length 534]\tLoss: 0.005042\n",
      "574it [00:17, 30.10it/s]Train epoch: 1 [batch #575, batch_size 4, seq length 541]\tLoss: 0.005173\n",
      "598it [00:17, 30.40it/s]Train epoch: 1 [batch #600, batch_size 4, seq length 547]\tLoss: 0.005479\n",
      "625it [00:18, 29.79it/s]Train epoch: 1 [batch #625, batch_size 4, seq length 553]\tLoss: 0.005205\n",
      "650it [00:19, 28.92it/s]Train epoch: 1 [batch #650, batch_size 4, seq length 559]\tLoss: 0.004619\n",
      "672it [00:20, 30.66it/s]Train epoch: 1 [batch #675, batch_size 4, seq length 566]\tLoss: 0.004063\n",
      "699it [00:21, 28.84it/s]Train epoch: 1 [batch #700, batch_size 4, seq length 573]\tLoss: 0.005008\n",
      "724it [00:22, 27.38it/s]Train epoch: 1 [batch #725, batch_size 4, seq length 578]\tLoss: 0.005164\n",
      "750it [00:23, 27.71it/s]Train epoch: 1 [batch #750, batch_size 4, seq length 584]\tLoss: 0.004869\n",
      "773it [00:23, 28.79it/s]Train epoch: 1 [batch #775, batch_size 4, seq length 589]\tLoss: 0.005471\n",
      "798it [00:24, 29.17it/s]Train epoch: 1 [batch #800, batch_size 4, seq length 596]\tLoss: 0.005345\n",
      "824it [00:25, 28.02it/s]Train epoch: 1 [batch #825, batch_size 4, seq length 601]\tLoss: 0.005001\n",
      "850it [00:26, 27.04it/s]Train epoch: 1 [batch #850, batch_size 4, seq length 606]\tLoss: 0.005426\n",
      "875it [00:27, 27.08it/s]Train epoch: 1 [batch #875, batch_size 4, seq length 612]\tLoss: 0.004978\n",
      "898it [00:28, 27.23it/s]Train epoch: 1 [batch #900, batch_size 4, seq length 617]\tLoss: 0.005164\n",
      "924it [00:29, 28.10it/s]Train epoch: 1 [batch #925, batch_size 4, seq length 622]\tLoss: 0.005129\n",
      "949it [00:30, 28.08it/s]Train epoch: 1 [batch #950, batch_size 4, seq length 627]\tLoss: 0.004953\n",
      "975it [00:30, 29.05it/s]Train epoch: 1 [batch #975, batch_size 4, seq length 632]\tLoss: 0.004082\n",
      "999it [00:31, 28.13it/s]Train epoch: 1 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.005180\n",
      "1023it [00:32, 28.01it/s]Train epoch: 1 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.006391\n",
      "1050it [00:33, 26.93it/s]Train epoch: 1 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.004734\n",
      "1074it [00:34, 27.75it/s]Train epoch: 1 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.005323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098it [00:35, 25.87it/s]Train epoch: 1 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.005325\n",
      "1125it [00:36, 27.54it/s]Train epoch: 1 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.005560\n",
      "1150it [00:37, 28.38it/s]Train epoch: 1 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.005619\n",
      "1175it [00:38, 27.40it/s]Train epoch: 1 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.005453\n",
      "1200it [00:39, 28.11it/s]Train epoch: 1 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.005418\n",
      "1224it [00:40, 27.96it/s]Train epoch: 1 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.005835\n",
      "1248it [00:41, 27.02it/s]Train epoch: 1 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.005386\n",
      "1274it [00:42, 26.86it/s]Train epoch: 1 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.004805\n",
      "1298it [00:42, 25.66it/s]Train epoch: 1 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.004892\n",
      "1325it [00:43, 27.03it/s]Train epoch: 1 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.004864\n",
      "1349it [00:44, 28.55it/s]Train epoch: 1 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.006230\n",
      "1373it [00:45, 25.87it/s]Train epoch: 1 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.005210\n",
      "1400it [00:46, 25.76it/s]Train epoch: 1 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.005021\n",
      "1424it [00:47, 25.98it/s]Train epoch: 1 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.004814\n",
      "1448it [00:48, 27.23it/s]Train epoch: 1 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.004951\n",
      "1473it [00:49, 27.35it/s]Train epoch: 1 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.005479\n",
      "1500it [00:50, 25.70it/s]Train epoch: 1 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.006588\n",
      "1524it [00:51, 25.38it/s]Train epoch: 1 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.005979\n",
      "1548it [00:52, 26.43it/s]Train epoch: 1 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.004987\n",
      "1575it [00:53, 26.58it/s]Train epoch: 1 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.005700\n",
      "1599it [00:54, 26.39it/s]Train epoch: 1 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.004950\n",
      "1624it [00:55, 26.68it/s]Train epoch: 1 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.005680\n",
      "1648it [00:56, 26.59it/s]Train epoch: 1 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.005817\n",
      "1675it [00:57, 24.71it/s]Train epoch: 1 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.005493\n",
      "1699it [00:58, 24.79it/s]Train epoch: 1 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.005084\n",
      "1723it [00:59, 24.51it/s]Train epoch: 1 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.004539\n",
      "1750it [01:00, 25.30it/s]Train epoch: 1 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.006353\n",
      "1774it [01:01, 25.77it/s]Train epoch: 1 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.005361\n",
      "1798it [01:02, 24.93it/s]Train epoch: 1 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.005085\n",
      "1825it [01:03, 25.06it/s]Train epoch: 1 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.004588\n",
      "1849it [01:04, 24.78it/s]Train epoch: 1 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.005511\n",
      "1873it [01:05, 24.55it/s]Train epoch: 1 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.005651\n",
      "1900it [01:06, 26.11it/s]Train epoch: 1 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.004635\n",
      "1924it [01:07, 25.29it/s]Train epoch: 1 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.004883\n",
      "1948it [01:08, 24.03it/s]Train epoch: 1 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.004909\n",
      "1975it [01:09, 24.96it/s]Train epoch: 1 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.005649\n",
      "2000it [01:10, 27.55it/s]Train epoch: 1 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.004570\n",
      "2024it [01:10, 33.09it/s]Train epoch: 1 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.005697\n",
      "2048it [01:11, 32.41it/s]Train epoch: 1 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.005081\n",
      "2072it [01:12, 33.36it/s]Train epoch: 1 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.005188\n",
      "2100it [01:13, 32.12it/s]Train epoch: 1 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.005571\n",
      "2124it [01:14, 32.98it/s]Train epoch: 1 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.005910\n",
      "2148it [01:14, 32.86it/s]Train epoch: 1 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.005056\n",
      "2172it [01:15, 30.54it/s]Train epoch: 1 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.005907\n",
      "2199it [01:16, 31.89it/s]Train epoch: 1 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.005526\n",
      "2223it [01:17, 32.03it/s]Train epoch: 1 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.005332\n",
      "2247it [01:17, 31.87it/s]Train epoch: 1 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.004950\n",
      "2275it [01:18, 32.78it/s]Train epoch: 1 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.005626\n",
      "2299it [01:19, 32.63it/s]Train epoch: 1 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.004284\n",
      "2323it [01:20, 32.61it/s]Train epoch: 1 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.005387\n",
      "2348it [01:21, 28.41it/s]Train epoch: 1 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.005081\n",
      "2374it [01:21, 30.89it/s]Train epoch: 1 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.006706\n",
      "2398it [01:22, 31.82it/s]Train epoch: 1 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.006512\n",
      "2422it [01:23, 30.52it/s]Train epoch: 1 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.004678\n",
      "2450it [01:24, 31.18it/s]Train epoch: 1 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.005315\n",
      "2474it [01:25, 28.44it/s]Train epoch: 1 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.005803\n",
      "2497it [01:26, 30.43it/s]Train epoch: 1 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.005247\n",
      "2525it [01:26, 30.21it/s]Train epoch: 1 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.005290\n",
      "2549it [01:27, 29.20it/s]Train epoch: 1 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.006727\n",
      "2573it [01:28, 30.59it/s]Train epoch: 1 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.004960\n",
      "2599it [01:29, 28.23it/s]Train epoch: 1 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.005385\n",
      "2624it [01:30, 30.02it/s]Train epoch: 1 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.005408\n",
      "2647it [01:31, 28.90it/s]Train epoch: 1 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.006067\n",
      "2673it [01:32, 26.24it/s]Train epoch: 1 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.005556\n",
      "2700it [01:33, 23.71it/s]Train epoch: 1 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.005111\n",
      "2724it [01:34, 21.73it/s]Train epoch: 1 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.005418\n",
      "2748it [01:35, 20.86it/s]Train epoch: 1 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.006414\n",
      "2775it [01:36, 23.01it/s]Train epoch: 1 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.005631\n",
      "2799it [01:37, 22.41it/s]Train epoch: 1 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.005236\n",
      "2823it [01:38, 22.36it/s]Train epoch: 1 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.005691\n",
      "2850it [01:39, 21.25it/s]Train epoch: 1 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.005592\n",
      "2874it [01:41, 22.18it/s]Train epoch: 1 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.005961\n",
      "2898it [01:42, 22.14it/s]Train epoch: 1 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.005952\n",
      "2925it [01:43, 22.10it/s]Train epoch: 1 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.005926\n",
      "2949it [01:44, 21.74it/s]Train epoch: 1 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.005932\n",
      "2973it [01:45, 21.37it/s]Train epoch: 1 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.005715\n",
      "3000it [01:46, 20.66it/s]Train epoch: 1 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.006260\n",
      "3024it [01:47, 21.21it/s]Train epoch: 1 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.006102\n",
      "3048it [01:49, 21.64it/s]Train epoch: 1 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.005396\n",
      "3075it [01:50, 20.33it/s]Train epoch: 1 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.006096\n",
      "3099it [01:51, 20.19it/s]Train epoch: 1 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.006165\n",
      "3123it [01:52, 20.98it/s]Train epoch: 1 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.005542\n",
      "3150it [01:53, 22.12it/s]Train epoch: 1 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.005594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3174it [01:54, 22.14it/s]Train epoch: 1 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.005375\n",
      "3198it [01:56, 20.71it/s]Train epoch: 1 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.006176\n",
      "3225it [01:57, 21.84it/s]Train epoch: 1 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.005870\n",
      "3249it [01:58, 21.32it/s]Train epoch: 1 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.005914\n",
      "3273it [01:59, 21.09it/s]Train epoch: 1 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.005742\n",
      "3300it [02:00, 21.08it/s]Train epoch: 1 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.006820\n",
      "3324it [02:02, 21.50it/s]Train epoch: 1 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.005912\n",
      "3348it [02:03, 21.98it/s]Train epoch: 1 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.005562\n",
      "3375it [02:04, 21.04it/s]Train epoch: 1 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.006399\n",
      "3399it [02:05, 21.33it/s]Train epoch: 1 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.006158\n",
      "3423it [02:06, 22.01it/s]Train epoch: 1 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.005586\n",
      "3450it [02:07, 21.22it/s]Train epoch: 1 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.006410\n",
      "3474it [02:09, 21.76it/s]Train epoch: 1 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.005839\n",
      "3498it [02:10, 22.10it/s]Train epoch: 1 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.005713\n",
      "3525it [02:11, 20.71it/s]Train epoch: 1 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.006180\n",
      "3549it [02:12, 22.45it/s]Train epoch: 1 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.006303\n",
      "3573it [02:13, 21.03it/s]Train epoch: 1 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.005331\n",
      "3599it [02:14, 21.00it/s]Train epoch: 1 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.006467\n",
      "3623it [02:16, 20.42it/s]Train epoch: 1 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.006164\n",
      "3650it [02:17, 17.47it/s]Train epoch: 1 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.005962\n",
      "3675it [02:18, 18.52it/s]Train epoch: 1 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.006337\n",
      "3700it [02:20, 19.37it/s]Train epoch: 1 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.006370\n",
      "3724it [02:21, 18.23it/s]Train epoch: 1 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.006322\n",
      "3749it [02:22, 17.81it/s]Train epoch: 1 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.006517\n",
      "3774it [02:24, 18.55it/s]Train epoch: 1 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.006143\n",
      "3800it [02:25, 17.76it/s]Train epoch: 1 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.006809\n",
      "3825it [02:27, 18.47it/s]Train epoch: 1 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.005912\n",
      "3850it [02:28, 17.90it/s]Train epoch: 1 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.005584\n",
      "3875it [02:29, 18.44it/s]Train epoch: 1 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.005222\n",
      "3899it [02:31, 16.90it/s]Train epoch: 1 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.006800\n",
      "3924it [02:32, 17.86it/s]Train epoch: 1 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.006091\n",
      "3950it [02:33, 18.31it/s]Train epoch: 1 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.006689\n",
      "3974it [02:35, 17.08it/s]Train epoch: 1 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.007517\n",
      "3998it [02:36, 16.63it/s]Train epoch: 1 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.005686\n",
      "4025it [02:38, 15.95it/s]Train epoch: 1 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.006769\n",
      "4049it [02:39, 17.61it/s]Train epoch: 1 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.006466\n",
      "4075it [02:41, 17.42it/s]Train epoch: 1 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.006366\n",
      "4099it [02:42, 16.55it/s]Train epoch: 1 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.007010\n",
      "4125it [02:44, 17.43it/s]Train epoch: 1 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.006903\n",
      "4149it [02:45, 17.44it/s]Train epoch: 1 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.005875\n",
      "4175it [02:46, 17.83it/s]Train epoch: 1 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.006087\n",
      "4199it [02:48, 18.07it/s]Train epoch: 1 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.006795\n",
      "4225it [02:49, 17.12it/s]Train epoch: 1 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.005902\n",
      "4249it [02:51, 16.87it/s]Train epoch: 1 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.006825\n",
      "4275it [02:52, 17.21it/s]Train epoch: 1 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.006192\n",
      "4299it [02:54, 16.85it/s]Train epoch: 1 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.006766\n",
      "4324it [02:55, 17.96it/s]Train epoch: 1 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.005999\n",
      "4350it [02:57, 17.36it/s]Train epoch: 1 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.006733\n",
      "4374it [02:58, 17.54it/s]Train epoch: 1 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.006327\n",
      "4400it [03:00, 17.34it/s]Train epoch: 1 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.005637\n",
      "4424it [03:01, 16.65it/s]Train epoch: 1 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.006472\n",
      "4450it [03:03, 17.25it/s]Train epoch: 1 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.005255\n",
      "4474it [03:04, 17.52it/s]Train epoch: 1 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.006678\n",
      "4500it [03:05, 17.33it/s]Train epoch: 1 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.007649\n",
      "4525it [03:07, 17.95it/s]Train epoch: 1 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.006582\n",
      "4549it [03:08, 16.73it/s]Train epoch: 1 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.006295\n",
      "4575it [03:10, 17.23it/s]Train epoch: 1 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.006900\n",
      "4599it [03:11, 15.95it/s]Train epoch: 1 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.006048\n",
      "4625it [03:13, 16.04it/s]Train epoch: 1 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.006281\n",
      "4649it [03:14, 16.75it/s]Train epoch: 1 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.006962\n",
      "4675it [03:16, 16.73it/s]Train epoch: 1 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.006573\n",
      "4699it [03:17, 16.74it/s]Train epoch: 1 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.005949\n",
      "4725it [03:19, 16.54it/s]Train epoch: 1 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.006288\n",
      "4749it [03:21, 15.38it/s]Train epoch: 1 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.007231\n",
      "4775it [03:22, 15.99it/s]Train epoch: 1 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.006421\n",
      "4799it [03:24, 15.78it/s]Train epoch: 1 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.006791\n",
      "4825it [03:25, 16.44it/s]Train epoch: 1 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.005945\n",
      "4849it [03:27, 15.39it/s]Train epoch: 1 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.006934\n",
      "4875it [03:28, 15.49it/s]Train epoch: 1 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.005819\n",
      "4899it [03:30, 16.01it/s]Train epoch: 1 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.006592\n",
      "4925it [03:32, 15.58it/s]Train epoch: 1 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.006011\n",
      "4949it [03:33, 15.65it/s]Train epoch: 1 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.006348\n",
      "4975it [03:35, 14.79it/s]Train epoch: 1 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.006450\n",
      "4999it [03:36, 15.87it/s]Train epoch: 1 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.006602\n",
      "5025it [03:38, 14.97it/s]Train epoch: 1 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.006152\n",
      "5049it [03:40, 15.61it/s]Train epoch: 1 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.006148\n",
      "5075it [03:41, 15.49it/s]Train epoch: 1 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.006245\n",
      "5099it [03:43, 15.58it/s]Train epoch: 1 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.006326\n",
      "5125it [03:45, 15.87it/s]Train epoch: 1 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.006670\n",
      "5149it [03:46, 15.56it/s]Train epoch: 1 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.006463\n",
      "5175it [03:48, 16.04it/s]Train epoch: 1 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.006680\n",
      "5199it [03:49, 15.86it/s]Train epoch: 1 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.005997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5225it [03:51, 15.56it/s]Train epoch: 1 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.006711\n",
      "5249it [03:53, 14.33it/s]Train epoch: 1 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.006379\n",
      "5275it [03:54, 14.46it/s]Train epoch: 1 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.006390\n",
      "5299it [03:56, 15.13it/s]Train epoch: 1 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.005891\n",
      "5325it [03:58, 15.10it/s]Train epoch: 1 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.007023\n",
      "5349it [03:59, 14.70it/s]Train epoch: 1 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.007033\n",
      "5375it [04:01, 14.95it/s]Train epoch: 1 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.006137\n",
      "5399it [04:03, 14.12it/s]Train epoch: 1 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.006266\n",
      "5425it [04:05, 14.46it/s]Train epoch: 1 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.006561\n",
      "5449it [04:06, 14.84it/s]Train epoch: 1 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.006644\n",
      "5475it [04:08, 14.17it/s]Train epoch: 1 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.007559\n",
      "5499it [04:10, 15.20it/s]Train epoch: 1 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.007166\n",
      "5525it [04:11, 15.13it/s]Train epoch: 1 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.005858\n",
      "5549it [04:13, 14.31it/s]Train epoch: 1 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.006449\n",
      "5575it [04:15, 15.40it/s]Train epoch: 1 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.006718\n",
      "5599it [04:16, 15.54it/s]Train epoch: 1 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.007331\n",
      "5625it [04:18, 14.27it/s]Train epoch: 1 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.006691\n",
      "5649it [04:20, 15.22it/s]Train epoch: 1 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.006006\n",
      "5675it [04:21, 15.16it/s]Train epoch: 1 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.007368\n",
      "5699it [04:23, 14.60it/s]Train epoch: 1 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.006197\n",
      "5725it [04:25, 14.91it/s]Train epoch: 1 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.006526\n",
      "5749it [04:26, 15.67it/s]Train epoch: 1 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.008003\n",
      "5775it [04:28, 15.98it/s]Train epoch: 1 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.006992\n",
      "5799it [04:30, 14.23it/s]Train epoch: 1 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.006980\n",
      "5825it [04:31, 14.39it/s]Train epoch: 1 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.006008\n",
      "5849it [04:33, 14.45it/s]Train epoch: 1 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.007640\n",
      "5875it [04:35, 14.69it/s]Train epoch: 1 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.007178\n",
      "5899it [04:36, 15.01it/s]Train epoch: 1 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.007681\n",
      "5925it [04:38, 14.21it/s]Train epoch: 1 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.006271\n",
      "5949it [04:40, 14.18it/s]Train epoch: 1 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.006194\n",
      "5975it [04:42, 14.54it/s]Train epoch: 1 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.008019\n",
      "5999it [04:43, 15.03it/s]Train epoch: 1 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.006945\n",
      "6025it [04:45, 14.49it/s]Train epoch: 1 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.007489\n",
      "6049it [04:47, 14.73it/s]Train epoch: 1 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.006531\n",
      "6075it [04:48, 14.98it/s]Train epoch: 1 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.006430\n",
      "6099it [04:50, 14.34it/s]Train epoch: 1 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.006091\n",
      "6125it [04:52, 14.37it/s]Train epoch: 1 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.006605\n",
      "6149it [04:54, 14.39it/s]Train epoch: 1 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.006510\n",
      "6175it [04:55, 14.59it/s]Train epoch: 1 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.007258\n",
      "6199it [04:57, 14.00it/s]Train epoch: 1 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.006810\n",
      "6225it [04:59, 14.31it/s]Train epoch: 1 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.005951\n",
      "6249it [05:01, 14.45it/s]Train epoch: 1 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.006490\n",
      "6275it [05:02, 14.47it/s]Train epoch: 1 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.006160\n",
      "6299it [05:04, 14.31it/s]Train epoch: 1 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.007013\n",
      "6325it [05:06, 14.16it/s]Train epoch: 1 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.007239\n",
      "6349it [05:08, 13.76it/s]Train epoch: 1 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.007358\n",
      "6375it [05:09, 14.85it/s]Train epoch: 1 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.006247\n",
      "6399it [05:11, 14.00it/s]Train epoch: 1 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.006713\n",
      "6425it [05:13, 13.47it/s]Train epoch: 1 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.007548\n",
      "6449it [05:15, 14.41it/s]Train epoch: 1 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.007047\n",
      "6475it [05:17, 14.15it/s]Train epoch: 1 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.006454\n",
      "6499it [05:18, 13.92it/s]Train epoch: 1 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.007228\n",
      "6525it [05:20, 13.68it/s]Train epoch: 1 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.006366\n",
      "6549it [05:22, 14.20it/s]Train epoch: 1 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.006580\n",
      "6575it [05:24, 13.61it/s]Train epoch: 1 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.006788\n",
      "6599it [05:25, 13.56it/s]Train epoch: 1 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.007753\n",
      "6625it [05:27, 13.38it/s]Train epoch: 1 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.006555\n",
      "6649it [05:29, 12.30it/s]Train epoch: 1 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.007630\n",
      "6675it [05:31, 13.16it/s]Train epoch: 1 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.007056\n",
      "6699it [05:33, 13.45it/s]Train epoch: 1 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.007169\n",
      "6725it [05:35, 14.24it/s]Train epoch: 1 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.007085\n",
      "6749it [05:37, 12.70it/s]Train epoch: 1 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.006541\n",
      "6775it [05:39, 14.40it/s]Train epoch: 1 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.007558\n",
      "6799it [05:40, 13.31it/s]Train epoch: 1 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.007324\n",
      "6825it [05:42, 14.03it/s]Train epoch: 1 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.007552\n",
      "6849it [05:44, 13.26it/s]Train epoch: 1 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.006932\n",
      "6875it [05:46, 12.79it/s]Train epoch: 1 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.006131\n",
      "6899it [05:48, 13.09it/s]Train epoch: 1 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.006936\n",
      "6925it [05:50, 13.53it/s]Train epoch: 1 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.007035\n",
      "6949it [05:52, 13.52it/s]Train epoch: 1 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.007486\n",
      "6975it [05:54, 13.33it/s]Train epoch: 1 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.007164\n",
      "6999it [05:55, 13.53it/s]Train epoch: 1 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.006982\n",
      "7025it [05:57, 13.47it/s]Train epoch: 1 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.008050\n",
      "7049it [05:59, 13.22it/s]Train epoch: 1 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.006267\n",
      "7075it [06:01, 13.75it/s]Train epoch: 1 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.007118\n",
      "7099it [06:03, 13.54it/s]Train epoch: 1 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.007313\n",
      "7125it [06:05, 12.72it/s]Train epoch: 1 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.006392\n",
      "7149it [06:07, 13.52it/s]Train epoch: 1 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.007657\n",
      "7175it [06:09, 13.09it/s]Train epoch: 1 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.007087\n",
      "7199it [06:10, 12.91it/s]Train epoch: 1 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.007579\n",
      "7225it [06:12, 13.23it/s]Train epoch: 1 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.006730\n",
      "7249it [06:14, 12.55it/s]Train epoch: 1 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.007128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7275it [06:16, 13.26it/s]Train epoch: 1 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.007691\n",
      "7299it [06:18, 12.58it/s]Train epoch: 1 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.007987\n",
      "7325it [06:20, 13.53it/s]Train epoch: 1 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.006784\n",
      "7349it [06:22, 13.49it/s]Train epoch: 1 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.007828\n",
      "7375it [06:24, 13.89it/s]Train epoch: 1 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.007314\n",
      "7399it [06:26, 13.19it/s]Train epoch: 1 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.006732\n",
      "7425it [06:28, 13.24it/s]Train epoch: 1 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.007290\n",
      "7449it [06:30, 12.98it/s]Train epoch: 1 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.008016\n",
      "7475it [06:31, 13.50it/s]Train epoch: 1 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.007035\n",
      "7499it [06:33, 13.15it/s]Train epoch: 1 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.007408\n",
      "7525it [06:35, 13.19it/s]Train epoch: 1 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.007078\n",
      "7549it [06:37, 13.44it/s]Train epoch: 1 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.006916\n",
      "7575it [06:39, 12.93it/s]Train epoch: 1 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.007472\n",
      "7599it [06:41, 13.30it/s]Train epoch: 1 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.008922\n",
      "7625it [06:43, 12.76it/s]Train epoch: 1 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.008206\n",
      "7649it [06:45, 12.40it/s]Train epoch: 1 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.007059\n",
      "7675it [06:47, 12.63it/s]Train epoch: 1 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.007140\n",
      "7699it [06:49, 12.74it/s]Train epoch: 1 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.007359\n",
      "7725it [06:51, 12.69it/s]Train epoch: 1 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.007327\n",
      "7749it [06:53, 12.74it/s]Train epoch: 1 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.007454\n",
      "7775it [06:55, 12.57it/s]Train epoch: 1 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.007036\n",
      "7799it [06:56, 12.52it/s]Train epoch: 1 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.007177\n",
      "7825it [06:59, 12.52it/s]Train epoch: 1 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.007266\n",
      "7849it [07:01, 11.95it/s]Train epoch: 1 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.006956\n",
      "7875it [07:03, 12.60it/s]Train epoch: 1 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.007294\n",
      "7899it [07:05, 12.47it/s]Train epoch: 1 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.007561\n",
      "7925it [07:07, 12.88it/s]Train epoch: 1 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.007330\n",
      "7949it [07:08, 12.24it/s]Train epoch: 1 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.008047\n",
      "7975it [07:11, 12.16it/s]Train epoch: 1 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.007349\n",
      "7999it [07:13, 12.29it/s]Train epoch: 1 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.007126\n",
      "8025it [07:15, 12.22it/s]Train epoch: 1 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.007895\n",
      "8049it [07:17, 12.70it/s]Train epoch: 1 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.006682\n",
      "8075it [07:19, 11.94it/s]Train epoch: 1 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.007401\n",
      "8099it [07:21, 11.65it/s]Train epoch: 1 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.007572\n",
      "8125it [07:23, 12.52it/s]Train epoch: 1 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.007946\n",
      "8149it [07:25, 12.01it/s]Train epoch: 1 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.007140\n",
      "8175it [07:27, 12.28it/s]Train epoch: 1 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.007871\n",
      "8199it [07:29, 12.08it/s]Train epoch: 1 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.007203\n",
      "8225it [07:31, 11.81it/s]Train epoch: 1 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.008634\n",
      "8249it [07:33, 11.83it/s]Train epoch: 1 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.007415\n",
      "8275it [07:35, 11.58it/s]Train epoch: 1 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.008190\n",
      "8299it [07:37, 11.80it/s]Train epoch: 1 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.007147\n",
      "8325it [07:40, 11.76it/s]Train epoch: 1 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.007842\n",
      "8349it [07:42, 11.46it/s]Train epoch: 1 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.007068\n",
      "8375it [07:44, 11.96it/s]Train epoch: 1 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.007867\n",
      "8399it [07:46, 12.04it/s]Train epoch: 1 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.007089\n",
      "8425it [07:48, 11.36it/s]Train epoch: 1 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.007628\n",
      "8449it [07:50, 11.92it/s]Train epoch: 1 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.007768\n",
      "8475it [07:52, 11.65it/s]Train epoch: 1 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.007407\n",
      "8499it [07:54, 12.00it/s]Train epoch: 1 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.008426\n",
      "8525it [07:56, 13.19it/s]Train epoch: 1 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.007532\n",
      "8549it [07:58, 13.06it/s]Train epoch: 1 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.007975\n",
      "8575it [08:00, 13.12it/s]Train epoch: 1 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.007430\n",
      "8599it [08:02, 13.54it/s]Train epoch: 1 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.007555\n",
      "8625it [08:04, 13.00it/s]Train epoch: 1 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.007594\n",
      "8649it [08:06, 13.18it/s]Train epoch: 1 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.007984\n",
      "8675it [08:08, 11.80it/s]Train epoch: 1 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.008566\n",
      "8699it [08:10, 12.16it/s]Train epoch: 1 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.008657\n",
      "8725it [08:12, 13.14it/s]Train epoch: 1 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.008422\n",
      "8749it [08:14, 13.06it/s]Train epoch: 1 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.008046\n",
      "8775it [08:16, 11.82it/s]Train epoch: 1 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.007247\n",
      "8799it [08:18, 12.60it/s]Train epoch: 1 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.007679\n",
      "8825it [08:20, 12.20it/s]Train epoch: 1 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.007766\n",
      "8849it [08:22, 12.35it/s]Train epoch: 1 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.008008\n",
      "8875it [08:24, 11.86it/s]Train epoch: 1 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.007660\n",
      "8899it [08:26, 11.77it/s]Train epoch: 1 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.007615\n",
      "8925it [08:28, 11.95it/s]Train epoch: 1 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.007966\n",
      "8949it [08:31, 11.30it/s]Train epoch: 1 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.008776\n",
      "8975it [08:33, 10.83it/s]Train epoch: 1 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.008464\n",
      "8999it [08:35, 11.06it/s]Train epoch: 1 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.007495\n",
      "9025it [08:37, 11.33it/s]Train epoch: 1 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.007839\n",
      "9049it [08:40, 11.10it/s]Train epoch: 1 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.007655\n",
      "9075it [08:42, 11.15it/s]Train epoch: 1 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.006945\n",
      "9099it [08:44, 11.34it/s]Train epoch: 1 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.007838\n",
      "9125it [08:46, 11.05it/s]Train epoch: 1 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.007577\n",
      "9149it [08:49, 11.15it/s]Train epoch: 1 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.007169\n",
      "9175it [08:51, 11.02it/s]Train epoch: 1 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.007623\n",
      "9199it [08:53, 11.10it/s]Train epoch: 1 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.007479\n",
      "9225it [08:56, 11.14it/s]Train epoch: 1 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.008930\n",
      "9249it [08:58, 10.87it/s]Train epoch: 1 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.007501\n",
      "9275it [09:00, 10.81it/s]Train epoch: 1 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.008212\n",
      "9299it [09:02, 10.74it/s]Train epoch: 1 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.008932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9325it [09:05, 11.05it/s]Train epoch: 1 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.008875\n",
      "9349it [09:07, 10.81it/s]Train epoch: 1 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.008687\n",
      "9375it [09:09, 11.02it/s]Train epoch: 1 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.007843\n",
      "9399it [09:12, 10.57it/s]Train epoch: 1 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.008058\n",
      "9425it [09:14, 10.77it/s]Train epoch: 1 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.007626\n",
      "9449it [09:16, 10.93it/s]Train epoch: 1 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.007721\n",
      "9475it [09:19, 10.71it/s]Train epoch: 1 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.008700\n",
      "9499it [09:21, 10.89it/s]Train epoch: 1 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.008096\n",
      "9525it [09:23, 10.68it/s]Train epoch: 1 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.008461\n",
      "9549it [09:26, 10.47it/s]Train epoch: 1 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.008420\n",
      "9575it [09:28, 10.48it/s]Train epoch: 1 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.008340\n",
      "9599it [09:30, 10.57it/s]Train epoch: 1 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.008091\n",
      "9625it [09:33, 10.60it/s]Train epoch: 1 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.007625\n",
      "9649it [09:35, 10.22it/s]Train epoch: 1 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.007640\n",
      "9675it [09:38,  9.60it/s]Train epoch: 1 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.008089\n",
      "9699it [09:40, 10.56it/s]Train epoch: 1 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.007465\n",
      "9725it [09:43, 10.16it/s]Train epoch: 1 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.008443\n",
      "9749it [09:45, 10.13it/s]Train epoch: 1 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.008020\n",
      "9774it [09:47, 10.23it/s]Train epoch: 1 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.008893\n",
      "9800it [09:50, 10.10it/s]Train epoch: 1 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.008779\n",
      "9825it [09:52, 10.25it/s]Train epoch: 1 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.008622\n",
      "9849it [09:55, 10.17it/s]Train epoch: 1 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.008163\n",
      "9875it [09:57,  9.84it/s]Train epoch: 1 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.008820\n",
      "9899it [10:00, 10.00it/s]Train epoch: 1 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.009470\n",
      "9924it [10:02, 10.04it/s]Train epoch: 1 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.008856\n",
      "9950it [10:05,  9.81it/s]Train epoch: 1 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.009340\n",
      "9975it [10:07,  9.78it/s]Train epoch: 1 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.008760\n",
      "10000it [10:10,  9.84it/s]Train epoch: 1 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.008261\n",
      "10025it [10:13,  9.75it/s]Train epoch: 1 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.008266\n",
      "10050it [10:15,  9.58it/s]Train epoch: 1 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.009137\n",
      "10075it [10:18,  9.58it/s]Train epoch: 1 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.009407\n",
      "10100it [10:20,  9.71it/s]Train epoch: 1 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.008516\n",
      "10125it [10:23,  9.57it/s]Train epoch: 1 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.008212\n",
      "10150it [10:25,  9.57it/s]Train epoch: 1 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.008479\n",
      "10175it [10:28,  9.30it/s]Train epoch: 1 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.008081\n",
      "10200it [10:31,  9.33it/s]Train epoch: 1 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.008700\n",
      "10225it [10:33,  9.44it/s]Train epoch: 1 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.008935\n",
      "10250it [10:36,  9.47it/s]Train epoch: 1 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.009230\n",
      "10275it [10:39,  9.36it/s]Train epoch: 1 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.008270\n",
      "10300it [10:41,  9.46it/s]Train epoch: 1 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.008984\n",
      "10325it [10:44,  9.82it/s]Train epoch: 1 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.008878\n",
      "10350it [10:46,  9.90it/s]Train epoch: 1 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.008820\n",
      "10375it [10:49,  9.35it/s]Train epoch: 1 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.008920\n",
      "10400it [10:52,  8.88it/s]Train epoch: 1 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.009159\n",
      "10425it [10:55,  9.12it/s]Train epoch: 1 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.008685\n",
      "10450it [10:57,  8.63it/s]Train epoch: 1 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.008993\n",
      "10475it [11:00,  8.69it/s]Train epoch: 1 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.007955\n",
      "10500it [11:03,  8.78it/s]Train epoch: 1 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.009117\n",
      "10525it [11:06,  8.84it/s]Train epoch: 1 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.008538\n",
      "10550it [11:09,  8.65it/s]Train epoch: 1 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.009016\n",
      "10575it [11:12,  8.07it/s]Train epoch: 1 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.008332\n",
      "10600it [11:15,  8.44it/s]Train epoch: 1 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.008117\n",
      "10625it [11:18,  8.32it/s]Train epoch: 1 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.008960\n",
      "10650it [11:21,  8.64it/s]Train epoch: 1 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.008434\n",
      "10675it [11:24,  7.86it/s]Train epoch: 1 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.008949\n",
      "10700it [11:27,  8.62it/s]Train epoch: 1 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.008576\n",
      "10725it [11:30,  8.58it/s]Train epoch: 1 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.007848\n",
      "10750it [11:33,  8.38it/s]Train epoch: 1 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.009186\n",
      "10775it [11:36,  8.15it/s]Train epoch: 1 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.009348\n",
      "10800it [11:39,  8.39it/s]Train epoch: 1 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.009613\n",
      "10825it [11:42,  8.60it/s]Train epoch: 1 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.009396\n",
      "10850it [11:45,  8.47it/s]Train epoch: 1 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.009113\n",
      "10875it [11:48,  8.56it/s]Train epoch: 1 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.009436\n",
      "10900it [11:51,  8.40it/s]Train epoch: 1 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.009015\n",
      "10925it [11:54,  8.32it/s]Train epoch: 1 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.008590\n",
      "10950it [11:57,  8.45it/s]Train epoch: 1 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.008977\n",
      "10975it [12:00,  8.47it/s]Train epoch: 1 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.008743\n",
      "11000it [12:03,  8.27it/s]Train epoch: 1 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.008768\n",
      "11025it [12:06,  8.51it/s]Train epoch: 1 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.008919\n",
      "11050it [12:09,  8.42it/s]Train epoch: 1 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.009746\n",
      "11075it [12:11,  8.45it/s]Train epoch: 1 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.009341\n",
      "11100it [12:15,  8.34it/s]Train epoch: 1 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.009951\n",
      "11125it [12:18,  8.39it/s]Train epoch: 1 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.009478\n",
      "11150it [12:20,  8.17it/s]Train epoch: 1 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.009177\n",
      "11175it [12:24,  8.34it/s]Train epoch: 1 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.010413\n",
      "11200it [12:26,  8.47it/s]Train epoch: 1 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.009381\n",
      "11225it [12:29,  8.40it/s]Train epoch: 1 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.009328\n",
      "11250it [12:32,  8.38it/s]Train epoch: 1 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.010175\n",
      "11275it [12:35,  8.27it/s]Train epoch: 1 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.009891\n",
      "11300it [12:38,  8.38it/s]Train epoch: 1 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.008920\n",
      "11325it [12:41,  8.54it/s]Train epoch: 1 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.010201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11350it [12:44,  8.28it/s]Train epoch: 1 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.010470\n",
      "11375it [12:47,  8.31it/s]Train epoch: 1 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.010563\n",
      "11400it [12:50,  8.66it/s]Train epoch: 1 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.009259\n",
      "11425it [12:53,  8.53it/s]Train epoch: 1 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.009937\n",
      "11450it [12:56,  8.51it/s]Train epoch: 1 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.009154\n",
      "11475it [12:59,  8.27it/s]Train epoch: 1 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.010993\n",
      "11500it [13:02,  8.38it/s]Train epoch: 1 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.010453\n",
      "11525it [13:05,  7.56it/s]Train epoch: 1 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.009718\n",
      "11550it [13:09,  7.96it/s]Train epoch: 1 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.009702\n",
      "11575it [13:12,  8.23it/s]Train epoch: 1 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.010721\n",
      "11600it [13:15,  8.46it/s]Train epoch: 1 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.009977\n",
      "11625it [13:18,  8.16it/s]Train epoch: 1 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.009283\n",
      "11650it [13:21,  8.18it/s]Train epoch: 1 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.010038\n",
      "11675it [13:24,  8.39it/s]Train epoch: 1 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.010540\n",
      "11700it [13:27,  8.20it/s]Train epoch: 1 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.011133\n",
      "11725it [13:30,  8.11it/s]Train epoch: 1 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.011024\n",
      "11750it [13:33,  8.07it/s]Train epoch: 1 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.010993\n",
      "11775it [13:36,  8.27it/s]Train epoch: 1 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.010580\n",
      "11800it [13:39,  8.40it/s]Train epoch: 1 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.010453\n",
      "11825it [13:42,  8.00it/s]Train epoch: 1 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.010810\n",
      "11850it [13:45,  8.18it/s]Train epoch: 1 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.010753\n",
      "11875it [13:48,  8.30it/s]Train epoch: 1 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.011777\n",
      "11900it [13:51,  8.09it/s]Train epoch: 1 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.013931\n",
      "11925it [13:54,  8.09it/s]Train epoch: 1 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.011898\n",
      "11930it [13:55, 14.28it/s]\n",
      "epoch loss: 0.007042197616983983\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 131.61it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0033, 0.0075, 0.0047, 0.0057, 0.8071\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1548, 0.5813, 0.1742, 0.2680, 0.9685\n",
      "rec_at_8: 0.2305\n",
      "prec_at_8: 0.4549\n",
      "rec_at_15: 0.3179\n",
      "prec_at_15: 0.3431\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 133.67it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0033, 0.0077, 0.0046, 0.0058, 0.7984\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1522, 0.5832, 0.1708, 0.2642, 0.9676\n",
      "rec_at_8: 0.2216\n",
      "prec_at_8: 0.4570\n",
      "rec_at_15: 0.3054\n",
      "prec_at_15: 0.3429\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 1\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0033, 0.0075, 0.0047, 0.0057, 0.8071\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1548, 0.5813, 0.1742, 0.2680, 0.9685\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0083\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 1\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0033, 0.0077, 0.0046, 0.0058, 0.7984\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1522, 0.5832, 0.1708, 0.2642, 0.9676\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0086\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 2\n",
      "0it [00:00, ?it/s]Train epoch: 2 [batch #0, batch_size 4, seq length 68]\tLoss: 0.007185\n",
      "22it [00:00, 48.52it/s]Train epoch: 2 [batch #25, batch_size 4, seq length 221]\tLoss: 0.005066\n",
      "47it [00:01, 44.41it/s]Train epoch: 2 [batch #50, batch_size 4, seq length 270]\tLoss: 0.005065\n",
      "74it [00:01, 37.42it/s]Train epoch: 2 [batch #75, batch_size 4, seq length 307]\tLoss: 0.004345\n",
      "96it [00:02, 38.80it/s]Train epoch: 2 [batch #100, batch_size 4, seq length 333]\tLoss: 0.004341\n",
      "123it [00:03, 35.62it/s]Train epoch: 2 [batch #125, batch_size 4, seq length 354]\tLoss: 0.004291\n",
      "149it [00:03, 36.66it/s]Train epoch: 2 [batch #150, batch_size 4, seq length 370]\tLoss: 0.004080\n",
      "174it [00:04, 36.27it/s]Train epoch: 2 [batch #175, batch_size 4, seq length 386]\tLoss: 0.004415\n",
      "199it [00:05, 35.91it/s]Train epoch: 2 [batch #200, batch_size 4, seq length 400]\tLoss: 0.004080\n",
      "223it [00:05, 33.28it/s]Train epoch: 2 [batch #225, batch_size 4, seq length 414]\tLoss: 0.005065\n",
      "247it [00:06, 34.41it/s]Train epoch: 2 [batch #250, batch_size 4, seq length 428]\tLoss: 0.004328\n",
      "275it [00:07, 35.08it/s]Train epoch: 2 [batch #275, batch_size 4, seq length 439]\tLoss: 0.003653\n",
      "299it [00:08, 33.94it/s]Train epoch: 2 [batch #300, batch_size 4, seq length 450]\tLoss: 0.004861\n",
      "323it [00:08, 31.24it/s]Train epoch: 2 [batch #325, batch_size 4, seq length 463]\tLoss: 0.003968\n",
      "347it [00:09, 31.09it/s]Train epoch: 2 [batch #350, batch_size 4, seq length 472]\tLoss: 0.004683\n",
      "374it [00:10, 31.85it/s]Train epoch: 2 [batch #375, batch_size 4, seq length 480]\tLoss: 0.004380\n",
      "398it [00:11, 30.16it/s]Train epoch: 2 [batch #400, batch_size 4, seq length 489]\tLoss: 0.004424\n",
      "422it [00:12, 31.02it/s]Train epoch: 2 [batch #425, batch_size 4, seq length 497]\tLoss: 0.004468\n",
      "450it [00:12, 30.96it/s]Train epoch: 2 [batch #450, batch_size 4, seq length 504]\tLoss: 0.004353\n",
      "474it [00:13, 30.68it/s]Train epoch: 2 [batch #475, batch_size 4, seq length 512]\tLoss: 0.004802\n",
      "498it [00:14, 32.68it/s]Train epoch: 2 [batch #500, batch_size 4, seq length 519]\tLoss: 0.004112\n",
      "522it [00:15, 30.06it/s]Train epoch: 2 [batch #525, batch_size 4, seq length 527]\tLoss: 0.004737\n",
      "550it [00:16, 30.34it/s]Train epoch: 2 [batch #550, batch_size 4, seq length 534]\tLoss: 0.004452\n",
      "573it [00:16, 30.24it/s]Train epoch: 2 [batch #575, batch_size 4, seq length 541]\tLoss: 0.004614\n",
      "597it [00:17, 29.99it/s]Train epoch: 2 [batch #600, batch_size 4, seq length 547]\tLoss: 0.004776\n",
      "623it [00:18, 29.64it/s]Train epoch: 2 [batch #625, batch_size 4, seq length 553]\tLoss: 0.004562\n",
      "648it [00:19, 28.20it/s]Train epoch: 2 [batch #650, batch_size 4, seq length 559]\tLoss: 0.004081\n",
      "674it [00:20, 27.45it/s]Train epoch: 2 [batch #675, batch_size 4, seq length 566]\tLoss: 0.003595\n",
      "698it [00:21, 29.60it/s]Train epoch: 2 [batch #700, batch_size 4, seq length 573]\tLoss: 0.004382\n",
      "724it [00:22, 30.33it/s]Train epoch: 2 [batch #725, batch_size 4, seq length 578]\tLoss: 0.004510\n",
      "748it [00:22, 29.91it/s]Train epoch: 2 [batch #750, batch_size 4, seq length 584]\tLoss: 0.004374\n",
      "773it [00:23, 27.68it/s]Train epoch: 2 [batch #775, batch_size 4, seq length 589]\tLoss: 0.004892\n",
      "800it [00:24, 29.07it/s]Train epoch: 2 [batch #800, batch_size 4, seq length 596]\tLoss: 0.004760\n",
      "822it [00:25, 28.68it/s]Train epoch: 2 [batch #825, batch_size 4, seq length 601]\tLoss: 0.004351\n",
      "850it [00:26, 28.51it/s]Train epoch: 2 [batch #850, batch_size 4, seq length 606]\tLoss: 0.004901\n",
      "873it [00:27, 30.05it/s]Train epoch: 2 [batch #875, batch_size 4, seq length 612]\tLoss: 0.004292\n",
      "898it [00:28, 25.79it/s]Train epoch: 2 [batch #900, batch_size 4, seq length 617]\tLoss: 0.004564\n",
      "925it [00:29, 27.45it/s]Train epoch: 2 [batch #925, batch_size 4, seq length 622]\tLoss: 0.004430\n",
      "948it [00:29, 29.13it/s]Train epoch: 2 [batch #950, batch_size 4, seq length 627]\tLoss: 0.004349\n",
      "972it [00:30, 28.29it/s]Train epoch: 2 [batch #975, batch_size 4, seq length 632]\tLoss: 0.003610\n",
      "999it [00:31, 26.76it/s]Train epoch: 2 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.004553\n",
      "1023it [00:32, 26.69it/s]Train epoch: 2 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.005827\n",
      "1050it [00:33, 28.26it/s]Train epoch: 2 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.004209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1074it [00:34, 27.94it/s]Train epoch: 2 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.004699\n",
      "1099it [00:35, 28.96it/s]Train epoch: 2 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.004685\n",
      "1124it [00:36, 26.84it/s]Train epoch: 2 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.004778\n",
      "1148it [00:37, 27.87it/s]Train epoch: 2 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.004959\n",
      "1175it [00:38, 25.37it/s]Train epoch: 2 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.004842\n",
      "1199it [00:39, 25.85it/s]Train epoch: 2 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.004726\n",
      "1224it [00:39, 28.41it/s]Train epoch: 2 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.005050\n",
      "1248it [00:40, 27.02it/s]Train epoch: 2 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.004755\n",
      "1273it [00:41, 27.00it/s]Train epoch: 2 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.004195\n",
      "1300it [00:42, 27.17it/s]Train epoch: 2 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.004248\n",
      "1323it [00:43, 28.21it/s]Train epoch: 2 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.004251\n",
      "1350it [00:44, 25.40it/s]Train epoch: 2 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.005632\n",
      "1374it [00:45, 27.33it/s]Train epoch: 2 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.004547\n",
      "1398it [00:46, 25.24it/s]Train epoch: 2 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.004489\n",
      "1425it [00:47, 26.63it/s]Train epoch: 2 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.004174\n",
      "1449it [00:48, 27.00it/s]Train epoch: 2 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.004360\n",
      "1473it [00:49, 25.79it/s]Train epoch: 2 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.004744\n",
      "1498it [00:50, 26.64it/s]Train epoch: 2 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.005809\n",
      "1523it [00:51, 27.34it/s]Train epoch: 2 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.005424\n",
      "1550it [00:52, 26.02it/s]Train epoch: 2 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.004411\n",
      "1574it [00:53, 25.79it/s]Train epoch: 2 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.004852\n",
      "1598it [00:54, 25.85it/s]Train epoch: 2 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.004305\n",
      "1625it [00:55, 23.98it/s]Train epoch: 2 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.004973\n",
      "1649it [00:56, 24.93it/s]Train epoch: 2 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.005151\n",
      "1673it [00:57, 25.95it/s]Train epoch: 2 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.004875\n",
      "1700it [00:58, 26.36it/s]Train epoch: 2 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.004458\n",
      "1724it [00:59, 24.76it/s]Train epoch: 2 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.003925\n",
      "1749it [01:00, 25.33it/s]Train epoch: 2 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.005674\n",
      "1773it [01:01, 25.93it/s]Train epoch: 2 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.004602\n",
      "1800it [01:02, 25.69it/s]Train epoch: 2 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.004655\n",
      "1824it [01:03, 24.56it/s]Train epoch: 2 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.004053\n",
      "1848it [01:04, 23.36it/s]Train epoch: 2 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.004779\n",
      "1875it [01:05, 23.41it/s]Train epoch: 2 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.005003\n",
      "1899it [01:06, 24.81it/s]Train epoch: 2 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.004084\n",
      "1923it [01:07, 24.15it/s]Train epoch: 2 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.004255\n",
      "1950it [01:08, 25.38it/s]Train epoch: 2 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.004254\n",
      "1974it [01:09, 23.40it/s]Train epoch: 2 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.005020\n",
      "1998it [01:10, 24.01it/s]Train epoch: 2 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.004008\n",
      "2025it [01:11, 23.50it/s]Train epoch: 2 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.004953\n",
      "2049it [01:12, 24.45it/s]Train epoch: 2 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.004509\n",
      "2073it [01:13, 23.24it/s]Train epoch: 2 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.004577\n",
      "2100it [01:14, 21.71it/s]Train epoch: 2 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.005004\n",
      "2124it [01:15, 24.17it/s]Train epoch: 2 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.005220\n",
      "2148it [01:16, 24.77it/s]Train epoch: 2 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.004401\n",
      "2175it [01:17, 25.03it/s]Train epoch: 2 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.005255\n",
      "2199it [01:18, 23.80it/s]Train epoch: 2 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.004887\n",
      "2223it [01:19, 23.66it/s]Train epoch: 2 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.004644\n",
      "2250it [01:20, 23.68it/s]Train epoch: 2 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.004342\n",
      "2274it [01:21, 23.25it/s]Train epoch: 2 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.004912\n",
      "2298it [01:22, 23.39it/s]Train epoch: 2 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.003730\n",
      "2325it [01:24, 22.28it/s]Train epoch: 2 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.004750\n",
      "2349it [01:25, 22.88it/s]Train epoch: 2 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.004337\n",
      "2373it [01:26, 23.63it/s]Train epoch: 2 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.006058\n",
      "2400it [01:27, 23.39it/s]Train epoch: 2 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.005759\n",
      "2424it [01:28, 22.83it/s]Train epoch: 2 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.004152\n",
      "2448it [01:29, 22.25it/s]Train epoch: 2 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.004721\n",
      "2475it [01:30, 22.08it/s]Train epoch: 2 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.005152\n",
      "2499it [01:31, 21.40it/s]Train epoch: 2 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.004633\n",
      "2523it [01:32, 22.98it/s]Train epoch: 2 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.004508\n",
      "2550it [01:33, 23.59it/s]Train epoch: 2 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.006009\n",
      "2574it [01:34, 23.76it/s]Train epoch: 2 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.004363\n",
      "2598it [01:36, 21.99it/s]Train epoch: 2 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.004758\n",
      "2625it [01:37, 22.44it/s]Train epoch: 2 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.004628\n",
      "2649it [01:38, 23.55it/s]Train epoch: 2 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.005397\n",
      "2673it [01:39, 22.88it/s]Train epoch: 2 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.004989\n",
      "2700it [01:40, 21.70it/s]Train epoch: 2 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.004398\n",
      "2724it [01:41, 23.14it/s]Train epoch: 2 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.004740\n",
      "2748it [01:42, 23.42it/s]Train epoch: 2 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.005600\n",
      "2775it [01:43, 23.94it/s]Train epoch: 2 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.004913\n",
      "2799it [01:44, 22.80it/s]Train epoch: 2 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.004681\n",
      "2823it [01:45, 22.55it/s]Train epoch: 2 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.004977\n",
      "2850it [01:47, 22.93it/s]Train epoch: 2 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.004787\n",
      "2874it [01:48, 22.41it/s]Train epoch: 2 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.005210\n",
      "2898it [01:49, 21.26it/s]Train epoch: 2 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.005236\n",
      "2925it [01:50, 22.71it/s]Train epoch: 2 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.005164\n",
      "2949it [01:51, 21.53it/s]Train epoch: 2 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.005282\n",
      "2973it [01:52, 22.28it/s]Train epoch: 2 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.005099\n",
      "3000it [01:53, 23.13it/s]Train epoch: 2 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.005587\n",
      "3024it [01:54, 22.62it/s]Train epoch: 2 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.005312\n",
      "3048it [01:56, 23.41it/s]Train epoch: 2 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.004674\n",
      "3075it [01:57, 22.20it/s]Train epoch: 2 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.005275\n",
      "3099it [01:58, 21.33it/s]Train epoch: 2 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.005449\n",
      "3123it [01:59, 22.11it/s]Train epoch: 2 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.004871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3150it [02:00, 21.96it/s]Train epoch: 2 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.004879\n",
      "3174it [02:01, 22.05it/s]Train epoch: 2 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.004738\n",
      "3198it [02:02, 21.41it/s]Train epoch: 2 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.005439\n",
      "3225it [02:04, 21.65it/s]Train epoch: 2 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.005235\n",
      "3249it [02:05, 21.97it/s]Train epoch: 2 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.005287\n",
      "3273it [02:06, 22.00it/s]Train epoch: 2 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.005070\n",
      "3300it [02:07, 21.15it/s]Train epoch: 2 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.006001\n",
      "3324it [02:08, 22.11it/s]Train epoch: 2 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.005168\n",
      "3348it [02:09, 20.88it/s]Train epoch: 2 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.005013\n",
      "3375it [02:11, 21.50it/s]Train epoch: 2 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.005542\n",
      "3399it [02:12, 21.97it/s]Train epoch: 2 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.005610\n",
      "3423it [02:13, 21.81it/s]Train epoch: 2 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.004940\n",
      "3450it [02:14, 21.81it/s]Train epoch: 2 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.005692\n",
      "3474it [02:15, 21.03it/s]Train epoch: 2 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.005065\n",
      "3498it [02:16, 22.03it/s]Train epoch: 2 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.005029\n",
      "3525it [02:18, 21.64it/s]Train epoch: 2 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.005372\n",
      "3549it [02:19, 21.10it/s]Train epoch: 2 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.005656\n",
      "3573it [02:20, 20.98it/s]Train epoch: 2 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.004734\n",
      "3600it [02:21, 22.03it/s]Train epoch: 2 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.005794\n",
      "3624it [02:22, 20.91it/s]Train epoch: 2 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.005491\n",
      "3648it [02:23, 20.49it/s]Train epoch: 2 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.005392\n",
      "3674it [02:25, 18.87it/s]Train epoch: 2 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.005626\n",
      "3700it [02:26, 18.56it/s]Train epoch: 2 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.005642\n",
      "3724it [02:27, 18.85it/s]Train epoch: 2 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.005631\n",
      "3750it [02:29, 18.37it/s]Train epoch: 2 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.005672\n",
      "3774it [02:30, 18.32it/s]Train epoch: 2 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.005401\n",
      "3799it [02:31, 18.40it/s]Train epoch: 2 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.006100\n",
      "3825it [02:33, 18.35it/s]Train epoch: 2 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.005248\n",
      "3850it [02:34, 17.94it/s]Train epoch: 2 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.005003\n",
      "3875it [02:36, 18.24it/s]Train epoch: 2 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.004676\n",
      "3899it [02:37, 17.58it/s]Train epoch: 2 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.006147\n",
      "3924it [02:38, 18.24it/s]Train epoch: 2 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.005530\n",
      "3949it [02:40, 18.01it/s]Train epoch: 2 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.005930\n",
      "3974it [02:41, 18.09it/s]Train epoch: 2 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.006687\n",
      "4000it [02:43, 17.80it/s]Train epoch: 2 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.005091\n",
      "4024it [02:44, 18.06it/s]Train epoch: 2 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.006037\n",
      "4050it [02:45, 16.97it/s]Train epoch: 2 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.005757\n",
      "4074it [02:47, 17.24it/s]Train epoch: 2 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.005680\n",
      "4100it [02:48, 17.47it/s]Train epoch: 2 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.006232\n",
      "4124it [02:50, 17.58it/s]Train epoch: 2 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.006114\n",
      "4150it [02:51, 18.04it/s]Train epoch: 2 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.005202\n",
      "4174it [02:52, 18.11it/s]Train epoch: 2 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.005451\n",
      "4200it [02:54, 17.22it/s]Train epoch: 2 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.005963\n",
      "4224it [02:55, 17.86it/s]Train epoch: 2 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.005192\n",
      "4250it [02:57, 18.01it/s]Train epoch: 2 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.005917\n",
      "4274it [02:58, 17.53it/s]Train epoch: 2 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.005559\n",
      "4300it [03:00, 17.76it/s]Train epoch: 2 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.006162\n",
      "4324it [03:01, 17.41it/s]Train epoch: 2 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.005405\n",
      "4350it [03:02, 17.12it/s]Train epoch: 2 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.005973\n",
      "4374it [03:04, 16.88it/s]Train epoch: 2 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.005588\n",
      "4400it [03:05, 17.32it/s]Train epoch: 2 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.004877\n",
      "4424it [03:07, 17.17it/s]Train epoch: 2 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.005794\n",
      "4450it [03:08, 17.42it/s]Train epoch: 2 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.004646\n",
      "4474it [03:10, 17.71it/s]Train epoch: 2 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.005920\n",
      "4500it [03:11, 17.64it/s]Train epoch: 2 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.006858\n",
      "4524it [03:12, 17.38it/s]Train epoch: 2 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.005917\n",
      "4549it [03:14, 16.72it/s]Train epoch: 2 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.005593\n",
      "4575it [03:15, 16.95it/s]Train epoch: 2 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.006301\n",
      "4599it [03:17, 15.80it/s]Train epoch: 2 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.005314\n",
      "4625it [03:19, 15.06it/s]Train epoch: 2 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.005545\n",
      "4649it [03:20, 16.11it/s]Train epoch: 2 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.006246\n",
      "4674it [03:22, 16.57it/s]Train epoch: 2 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.005884\n",
      "4700it [03:23, 15.92it/s]Train epoch: 2 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.005355\n",
      "4724it [03:25, 15.54it/s]Train epoch: 2 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.005548\n",
      "4750it [03:26, 15.90it/s]Train epoch: 2 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.006459\n",
      "4774it [03:28, 16.31it/s]Train epoch: 2 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.005738\n",
      "4800it [03:30, 16.42it/s]Train epoch: 2 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.006136\n",
      "4824it [03:31, 16.57it/s]Train epoch: 2 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.005349\n",
      "4850it [03:33, 16.87it/s]Train epoch: 2 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.006183\n",
      "4874it [03:34, 16.64it/s]Train epoch: 2 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.005254\n",
      "4900it [03:36, 16.23it/s]Train epoch: 2 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.006006\n",
      "4924it [03:37, 16.05it/s]Train epoch: 2 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.005338\n",
      "4950it [03:39, 16.04it/s]Train epoch: 2 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.005617\n",
      "4974it [03:40, 16.20it/s]Train epoch: 2 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.005725\n",
      "5000it [03:42, 16.29it/s]Train epoch: 2 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.005947\n",
      "5024it [03:43, 16.48it/s]Train epoch: 2 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.005445\n",
      "5050it [03:45, 15.35it/s]Train epoch: 2 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.005482\n",
      "5074it [03:47, 15.39it/s]Train epoch: 2 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.005624\n",
      "5100it [03:48, 15.68it/s]Train epoch: 2 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.005691\n",
      "5124it [03:50, 16.63it/s]Train epoch: 2 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.006072\n",
      "5150it [03:51, 14.92it/s]Train epoch: 2 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.005872\n",
      "5174it [03:53, 15.59it/s]Train epoch: 2 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.005976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200it [03:55, 15.85it/s]Train epoch: 2 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.005441\n",
      "5224it [03:56, 15.46it/s]Train epoch: 2 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.005978\n",
      "5250it [03:58, 15.84it/s]Train epoch: 2 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.005623\n",
      "5274it [03:59, 15.33it/s]Train epoch: 2 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.005668\n",
      "5300it [04:01, 15.95it/s]Train epoch: 2 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.005301\n",
      "5324it [04:03, 16.12it/s]Train epoch: 2 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.006267\n",
      "5350it [04:04, 15.98it/s]Train epoch: 2 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.006300\n",
      "5374it [04:06, 15.29it/s]Train epoch: 2 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.005544\n",
      "5400it [04:07, 15.62it/s]Train epoch: 2 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.005564\n",
      "5424it [04:09, 15.28it/s]Train epoch: 2 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.005912\n",
      "5450it [04:11, 15.43it/s]Train epoch: 2 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.005958\n",
      "5474it [04:12, 15.50it/s]Train epoch: 2 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.006837\n",
      "5500it [04:14, 15.44it/s]Train epoch: 2 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.006394\n",
      "5524it [04:16, 14.90it/s]Train epoch: 2 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.005213\n",
      "5550it [04:17, 14.81it/s]Train epoch: 2 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.005878\n",
      "5574it [04:19, 15.26it/s]Train epoch: 2 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.006109\n",
      "5600it [04:21, 15.55it/s]Train epoch: 2 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.006532\n",
      "5624it [04:22, 15.17it/s]Train epoch: 2 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.005977\n",
      "5650it [04:24, 15.29it/s]Train epoch: 2 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.005433\n",
      "5674it [04:25, 15.64it/s]Train epoch: 2 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.006691\n",
      "5700it [04:27, 14.96it/s]Train epoch: 2 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.005694\n",
      "5724it [04:29, 15.11it/s]Train epoch: 2 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.005893\n",
      "5750it [04:30, 14.99it/s]Train epoch: 2 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.007254\n",
      "5774it [04:32, 14.53it/s]Train epoch: 2 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.006316\n",
      "5800it [04:34, 15.31it/s]Train epoch: 2 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.006253\n",
      "5824it [04:35, 15.25it/s]Train epoch: 2 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.005484\n",
      "5850it [04:37, 15.16it/s]Train epoch: 2 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.006923\n",
      "5874it [04:39, 14.90it/s]Train epoch: 2 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.006564\n",
      "5900it [04:40, 14.91it/s]Train epoch: 2 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.006859\n",
      "5924it [04:42, 14.88it/s]Train epoch: 2 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.005613\n",
      "5950it [04:44, 15.04it/s]Train epoch: 2 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.005578\n",
      "5974it [04:45, 14.94it/s]Train epoch: 2 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.007437\n",
      "6000it [04:47, 14.48it/s]Train epoch: 2 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.006250\n",
      "6024it [04:49, 14.84it/s]Train epoch: 2 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.006646\n",
      "6050it [04:50, 14.60it/s]Train epoch: 2 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.005843\n",
      "6074it [04:52, 14.91it/s]Train epoch: 2 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.005725\n",
      "6100it [04:54, 15.14it/s]Train epoch: 2 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.005448\n",
      "6124it [04:55, 14.81it/s]Train epoch: 2 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.006023\n",
      "6150it [04:57, 14.35it/s]Train epoch: 2 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.005829\n",
      "6174it [04:59, 14.72it/s]Train epoch: 2 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.006641\n",
      "6200it [05:01, 14.47it/s]Train epoch: 2 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.006072\n",
      "6224it [05:02, 14.45it/s]Train epoch: 2 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.005359\n",
      "6250it [05:04, 14.92it/s]Train epoch: 2 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.005849\n",
      "6274it [05:06, 14.55it/s]Train epoch: 2 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.005449\n",
      "6300it [05:07, 14.61it/s]Train epoch: 2 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.006250\n",
      "6324it [05:09, 14.69it/s]Train epoch: 2 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.006454\n",
      "6350it [05:11, 14.62it/s]Train epoch: 2 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.006728\n",
      "6374it [05:12, 14.85it/s]Train epoch: 2 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.005577\n",
      "6400it [05:14, 14.71it/s]Train epoch: 2 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.005870\n",
      "6424it [05:16, 14.62it/s]Train epoch: 2 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.006790\n",
      "6450it [05:18, 14.11it/s]Train epoch: 2 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.006387\n",
      "6474it [05:19, 14.17it/s]Train epoch: 2 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.005821\n",
      "6500it [05:21, 14.29it/s]Train epoch: 2 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.006641\n",
      "6524it [05:23, 14.06it/s]Train epoch: 2 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.005686\n",
      "6550it [05:25, 14.32it/s]Train epoch: 2 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.005919\n",
      "6574it [05:26, 14.04it/s]Train epoch: 2 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.006116\n",
      "6600it [05:28, 14.27it/s]Train epoch: 2 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.007078\n",
      "6624it [05:30, 14.89it/s]Train epoch: 2 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.005856\n",
      "6650it [05:32, 13.95it/s]Train epoch: 2 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.006854\n",
      "6674it [05:33, 13.58it/s]Train epoch: 2 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.006318\n",
      "6700it [05:35, 14.08it/s]Train epoch: 2 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.006462\n",
      "6724it [05:37, 13.75it/s]Train epoch: 2 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.006480\n",
      "6750it [05:39, 13.59it/s]Train epoch: 2 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.005834\n",
      "6774it [05:41, 14.39it/s]Train epoch: 2 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.006769\n",
      "6800it [05:43, 13.78it/s]Train epoch: 2 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.006572\n",
      "6824it [05:44, 13.50it/s]Train epoch: 2 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.006916\n",
      "6850it [05:46, 13.60it/s]Train epoch: 2 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.006284\n",
      "6874it [05:48, 13.54it/s]Train epoch: 2 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.005411\n",
      "6900it [05:50, 13.78it/s]Train epoch: 2 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.006279\n",
      "6924it [05:52, 14.04it/s]Train epoch: 2 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.006211\n",
      "6950it [05:53, 13.50it/s]Train epoch: 2 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.006955\n",
      "6974it [05:55, 13.95it/s]Train epoch: 2 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.006492\n",
      "7000it [05:57, 14.06it/s]Train epoch: 2 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.006263\n",
      "7024it [05:59, 14.77it/s]Train epoch: 2 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.007237\n",
      "7050it [06:00, 13.68it/s]Train epoch: 2 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.005614\n",
      "7074it [06:02, 14.41it/s]Train epoch: 2 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.006451\n",
      "7100it [06:04, 14.86it/s]Train epoch: 2 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.006627\n",
      "7124it [06:06, 14.87it/s]Train epoch: 2 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.005793\n",
      "7150it [06:07, 15.40it/s]Train epoch: 2 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.007029\n",
      "7174it [06:09, 14.35it/s]Train epoch: 2 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.006437\n",
      "7200it [06:11, 14.19it/s]Train epoch: 2 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.006774\n",
      "7224it [06:12, 14.54it/s]Train epoch: 2 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.006156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7250it [06:14, 12.69it/s]Train epoch: 2 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.006433\n",
      "7274it [06:16, 12.24it/s]Train epoch: 2 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.006939\n",
      "7300it [06:18, 12.49it/s]Train epoch: 2 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.007369\n",
      "7324it [06:20, 12.64it/s]Train epoch: 2 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.006102\n",
      "7350it [06:22, 13.03it/s]Train epoch: 2 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.007145\n",
      "7374it [06:24, 12.99it/s]Train epoch: 2 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.006628\n",
      "7400it [06:26, 12.88it/s]Train epoch: 2 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.006069\n",
      "7424it [06:28, 12.71it/s]Train epoch: 2 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.006642\n",
      "7450it [06:30, 12.72it/s]Train epoch: 2 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.007372\n",
      "7474it [06:32, 13.07it/s]Train epoch: 2 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.006405\n",
      "7500it [06:34, 12.89it/s]Train epoch: 2 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.006737\n",
      "7524it [06:36, 12.70it/s]Train epoch: 2 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.006481\n",
      "7550it [06:38, 12.44it/s]Train epoch: 2 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.006251\n",
      "7574it [06:40, 12.16it/s]Train epoch: 2 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.006802\n",
      "7600it [06:42, 12.71it/s]Train epoch: 2 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.008093\n",
      "7624it [06:44, 12.15it/s]Train epoch: 2 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.007402\n",
      "7650it [06:46, 12.84it/s]Train epoch: 2 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.006382\n",
      "7674it [06:48, 12.55it/s]Train epoch: 2 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.006541\n",
      "7700it [06:50, 12.66it/s]Train epoch: 2 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.006602\n",
      "7724it [06:52, 12.82it/s]Train epoch: 2 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.006643\n",
      "7750it [06:54, 12.95it/s]Train epoch: 2 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.006725\n",
      "7774it [06:55, 13.02it/s]Train epoch: 2 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.006294\n",
      "7800it [06:58, 12.45it/s]Train epoch: 2 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.006515\n",
      "7824it [06:59, 12.15it/s]Train epoch: 2 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.006600\n",
      "7850it [07:02, 12.22it/s]Train epoch: 2 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.006251\n",
      "7874it [07:04, 12.44it/s]Train epoch: 2 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.006600\n",
      "7900it [07:06, 12.25it/s]Train epoch: 2 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.006833\n",
      "7924it [07:08, 11.88it/s]Train epoch: 2 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.006692\n",
      "7950it [07:10, 12.19it/s]Train epoch: 2 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.007319\n",
      "7974it [07:12, 12.52it/s]Train epoch: 2 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.006666\n",
      "8000it [07:14, 12.08it/s]Train epoch: 2 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.006447\n",
      "8024it [07:16, 12.08it/s]Train epoch: 2 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.007031\n",
      "8050it [07:18, 12.14it/s]Train epoch: 2 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.006008\n",
      "8074it [07:20, 12.29it/s]Train epoch: 2 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.006732\n",
      "8100it [07:22, 11.80it/s]Train epoch: 2 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.006982\n",
      "8124it [07:24, 11.88it/s]Train epoch: 2 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.007225\n",
      "8150it [07:26, 11.90it/s]Train epoch: 2 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.006400\n",
      "8174it [07:28, 11.81it/s]Train epoch: 2 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.007157\n",
      "8200it [07:30, 12.16it/s]Train epoch: 2 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.006520\n",
      "8224it [07:32, 11.85it/s]Train epoch: 2 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.007844\n",
      "8250it [07:34, 12.11it/s]Train epoch: 2 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.006566\n",
      "8274it [07:36, 11.96it/s]Train epoch: 2 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.007353\n",
      "8300it [07:39, 11.68it/s]Train epoch: 2 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.006487\n",
      "8324it [07:41, 12.01it/s]Train epoch: 2 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.007114\n",
      "8350it [07:43, 11.60it/s]Train epoch: 2 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.006382\n",
      "8374it [07:45, 11.62it/s]Train epoch: 2 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.007096\n",
      "8400it [07:47, 12.00it/s]Train epoch: 2 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.006529\n",
      "8424it [07:49, 11.53it/s]Train epoch: 2 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.006880\n",
      "8450it [07:51, 11.91it/s]Train epoch: 2 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.007035\n",
      "8474it [07:53, 11.87it/s]Train epoch: 2 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.006730\n",
      "8500it [07:56, 11.53it/s]Train epoch: 2 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.007732\n",
      "8524it [07:58, 12.13it/s]Train epoch: 2 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.006736\n",
      "8550it [08:00, 11.25it/s]Train epoch: 2 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.007197\n",
      "8574it [08:02, 11.42it/s]Train epoch: 2 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.006746\n",
      "8600it [08:04, 11.66it/s]Train epoch: 2 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.006792\n",
      "8624it [08:06, 11.25it/s]Train epoch: 2 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.006914\n",
      "8650it [08:09, 11.28it/s]Train epoch: 2 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.007182\n",
      "8674it [08:11, 11.38it/s]Train epoch: 2 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.007848\n",
      "8700it [08:13, 11.86it/s]Train epoch: 2 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.007930\n",
      "8724it [08:15, 11.20it/s]Train epoch: 2 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.007592\n",
      "8750it [08:17, 11.49it/s]Train epoch: 2 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.007278\n",
      "8774it [08:20, 11.40it/s]Train epoch: 2 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.006545\n",
      "8800it [08:22, 11.40it/s]Train epoch: 2 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.006939\n",
      "8824it [08:24, 11.13it/s]Train epoch: 2 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.007029\n",
      "8850it [08:26, 11.19it/s]Train epoch: 2 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.007174\n",
      "8874it [08:28, 11.18it/s]Train epoch: 2 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.007006\n",
      "8900it [08:31, 11.29it/s]Train epoch: 2 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.006992\n",
      "8924it [08:33, 10.94it/s]Train epoch: 2 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.007263\n",
      "8950it [08:35, 10.91it/s]Train epoch: 2 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.007965\n",
      "8974it [08:37, 11.09it/s]Train epoch: 2 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.007654\n",
      "9000it [08:40, 10.86it/s]Train epoch: 2 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.006843\n",
      "9024it [08:42, 11.20it/s]Train epoch: 2 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.007134\n",
      "9050it [08:44, 10.95it/s]Train epoch: 2 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.006795\n",
      "9074it [08:47, 10.78it/s]Train epoch: 2 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.006231\n",
      "9100it [08:49, 10.68it/s]Train epoch: 2 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.007242\n",
      "9124it [08:51, 11.17it/s]Train epoch: 2 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.006899\n",
      "9150it [08:54, 10.58it/s]Train epoch: 2 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.006465\n",
      "9174it [08:56, 10.39it/s]Train epoch: 2 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.006850\n",
      "9200it [08:58, 10.60it/s]Train epoch: 2 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.006859\n",
      "9224it [09:01, 10.55it/s]Train epoch: 2 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.008130\n",
      "9250it [09:03, 10.33it/s]Train epoch: 2 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.006838\n",
      "9274it [09:05, 10.70it/s]Train epoch: 2 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.007471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9300it [09:08, 10.15it/s]Train epoch: 2 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.008186\n",
      "9324it [09:10, 10.48it/s]Train epoch: 2 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.008078\n",
      "9350it [09:13, 10.29it/s]Train epoch: 2 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.007884\n",
      "9374it [09:15, 10.44it/s]Train epoch: 2 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.007094\n",
      "9399it [09:17,  9.84it/s]Train epoch: 2 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.007321\n",
      "9425it [09:20, 10.50it/s]Train epoch: 2 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.006995\n",
      "9449it [09:22, 10.56it/s]Train epoch: 2 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.006939\n",
      "9475it [09:25, 10.11it/s]Train epoch: 2 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.007987\n",
      "9500it [09:27, 10.09it/s]Train epoch: 2 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.007445\n",
      "9524it [09:30, 10.20it/s]Train epoch: 2 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.007734\n",
      "9550it [09:32,  9.92it/s]Train epoch: 2 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.007787\n",
      "9575it [09:35,  9.91it/s]Train epoch: 2 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.007599\n",
      "9600it [09:37,  9.63it/s]Train epoch: 2 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.007365\n",
      "9624it [09:40, 10.00it/s]Train epoch: 2 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.006950\n",
      "9650it [09:42,  9.84it/s]Train epoch: 2 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.006970\n",
      "9674it [09:45,  9.97it/s]Train epoch: 2 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.007356\n",
      "9700it [09:47,  9.87it/s]Train epoch: 2 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.006807\n",
      "9725it [09:50,  9.83it/s]Train epoch: 2 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.007725\n",
      "9750it [09:52,  9.74it/s]Train epoch: 2 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.007306\n",
      "9774it [09:55,  9.80it/s]Train epoch: 2 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.008203\n",
      "9800it [09:57,  9.49it/s]Train epoch: 2 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.008007\n",
      "9825it [10:00,  9.40it/s]Train epoch: 2 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.007973\n",
      "9850it [10:03,  9.51it/s]Train epoch: 2 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.007423\n",
      "9875it [10:05,  9.20it/s]Train epoch: 2 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.008079\n",
      "9900it [10:08,  9.37it/s]Train epoch: 2 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.008560\n",
      "9925it [10:11,  9.54it/s]Train epoch: 2 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.007967\n",
      "9950it [10:13,  9.06it/s]Train epoch: 2 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.008657\n",
      "9975it [10:16,  9.02it/s]Train epoch: 2 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.008041\n",
      "10000it [10:19,  9.39it/s]Train epoch: 2 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.007518\n",
      "10025it [10:21,  9.25it/s]Train epoch: 2 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.007571\n",
      "10050it [10:24,  9.11it/s]Train epoch: 2 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.008338\n",
      "10075it [10:27,  8.91it/s]Train epoch: 2 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.008595\n",
      "10100it [10:30,  9.07it/s]Train epoch: 2 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.007909\n",
      "10125it [10:32,  8.89it/s]Train epoch: 2 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.007445\n",
      "10150it [10:35,  8.71it/s]Train epoch: 2 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.007936\n",
      "10175it [10:38,  9.15it/s]Train epoch: 2 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.007441\n",
      "10200it [10:41,  9.11it/s]Train epoch: 2 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.008024\n",
      "10225it [10:44,  8.59it/s]Train epoch: 2 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.008178\n",
      "10250it [10:46,  9.07it/s]Train epoch: 2 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.008490\n",
      "10275it [10:49,  8.77it/s]Train epoch: 2 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.007662\n",
      "10300it [10:52,  8.72it/s]Train epoch: 2 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.008292\n",
      "10325it [10:55,  9.03it/s]Train epoch: 2 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.008200\n",
      "10350it [10:58,  8.75it/s]Train epoch: 2 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.008096\n",
      "10375it [11:01,  8.67it/s]Train epoch: 2 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.008243\n",
      "10400it [11:03,  8.73it/s]Train epoch: 2 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.008318\n",
      "10425it [11:06,  8.26it/s]Train epoch: 2 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.007933\n",
      "10450it [11:09,  8.35it/s]Train epoch: 2 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.008269\n",
      "10475it [11:12,  8.41it/s]Train epoch: 2 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.007313\n",
      "10500it [11:15,  8.18it/s]Train epoch: 2 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.008259\n",
      "10525it [11:19,  8.36it/s]Train epoch: 2 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.007819\n",
      "10550it [11:22,  8.14it/s]Train epoch: 2 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.008268\n",
      "10575it [11:25,  7.84it/s]Train epoch: 2 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.007477\n",
      "10600it [11:28,  8.00it/s]Train epoch: 2 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.007541\n",
      "10625it [11:31,  8.33it/s]Train epoch: 2 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.008164\n",
      "10650it [11:34,  8.01it/s]Train epoch: 2 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.007743\n",
      "10675it [11:37,  8.04it/s]Train epoch: 2 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.008249\n",
      "10700it [11:40,  7.80it/s]Train epoch: 2 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.007836\n",
      "10725it [11:43,  7.91it/s]Train epoch: 2 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.007168\n",
      "10750it [11:47,  7.66it/s]Train epoch: 2 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.008464\n",
      "10775it [11:50,  7.66it/s]Train epoch: 2 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.008655\n",
      "10800it [11:53,  7.72it/s]Train epoch: 2 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.008778\n",
      "10825it [11:56,  7.81it/s]Train epoch: 2 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.008640\n",
      "10850it [11:59,  7.85it/s]Train epoch: 2 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.008447\n",
      "10875it [12:03,  7.69it/s]Train epoch: 2 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.008739\n",
      "10900it [12:06,  7.56it/s]Train epoch: 2 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.008281\n",
      "10925it [12:09,  7.79it/s]Train epoch: 2 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.007857\n",
      "10950it [12:13,  7.64it/s]Train epoch: 2 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.008285\n",
      "10975it [12:16,  7.45it/s]Train epoch: 2 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.008096\n",
      "11000it [12:19,  7.69it/s]Train epoch: 2 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.008100\n",
      "11025it [12:22,  7.67it/s]Train epoch: 2 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.008215\n",
      "11050it [12:26,  7.95it/s]Train epoch: 2 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.009048\n",
      "11075it [12:29,  7.54it/s]Train epoch: 2 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.008510\n",
      "11100it [12:32,  7.59it/s]Train epoch: 2 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.009331\n",
      "11125it [12:35,  7.57it/s]Train epoch: 2 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.008671\n",
      "11150it [12:39,  7.50it/s]Train epoch: 2 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.008459\n",
      "11175it [12:42,  7.62it/s]Train epoch: 2 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.009716\n",
      "11200it [12:45,  7.71it/s]Train epoch: 2 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.008751\n",
      "11225it [12:49,  7.73it/s]Train epoch: 2 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.008640\n",
      "11250it [12:52,  7.61it/s]Train epoch: 2 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.009412\n",
      "11275it [12:55,  7.66it/s]Train epoch: 2 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.009171\n",
      "11300it [12:58,  7.60it/s]Train epoch: 2 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.008213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11325it [13:02,  7.90it/s]Train epoch: 2 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.009542\n",
      "11350it [13:05,  7.67it/s]Train epoch: 2 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.009618\n",
      "11375it [13:08,  7.53it/s]Train epoch: 2 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.009843\n",
      "11400it [13:11,  7.63it/s]Train epoch: 2 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.008671\n",
      "11425it [13:15,  7.65it/s]Train epoch: 2 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.009340\n",
      "11450it [13:18,  7.64it/s]Train epoch: 2 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.008461\n",
      "11475it [13:21,  7.59it/s]Train epoch: 2 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.010262\n",
      "11500it [13:24,  7.87it/s]Train epoch: 2 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.009647\n",
      "11525it [13:28,  7.80it/s]Train epoch: 2 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.008918\n",
      "11550it [13:31,  7.65it/s]Train epoch: 2 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.008964\n",
      "11575it [13:34,  7.80it/s]Train epoch: 2 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.010082\n",
      "11600it [13:37,  7.56it/s]Train epoch: 2 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.009314\n",
      "11625it [13:41,  7.50it/s]Train epoch: 2 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.008689\n",
      "11650it [13:44,  7.84it/s]Train epoch: 2 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.009436\n",
      "11675it [13:47,  7.54it/s]Train epoch: 2 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.009980\n",
      "11700it [13:50,  7.83it/s]Train epoch: 2 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.010416\n",
      "11725it [13:54,  7.61it/s]Train epoch: 2 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.010440\n",
      "11750it [13:57,  7.81it/s]Train epoch: 2 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.010199\n",
      "11775it [14:00,  7.74it/s]Train epoch: 2 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.009981\n",
      "11800it [14:04,  7.63it/s]Train epoch: 2 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.009848\n",
      "11825it [14:07,  7.64it/s]Train epoch: 2 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.010153\n",
      "11850it [14:10,  7.58it/s]Train epoch: 2 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.010099\n",
      "11875it [14:13,  7.67it/s]Train epoch: 2 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.011224\n",
      "11900it [14:17,  7.63it/s]Train epoch: 2 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.013262\n",
      "11925it [14:20,  7.33it/s]Train epoch: 2 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.011323\n",
      "11930it [14:21, 13.85it/s]\n",
      "epoch loss: 0.0063585218698179\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:13, 124.20it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0078, 0.0139, 0.0121, 0.0129, 0.8374\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2270, 0.5682, 0.2744, 0.3701, 0.9735\n",
      "rec_at_8: 0.2779\n",
      "prec_at_8: 0.5334\n",
      "rec_at_15: 0.3834\n",
      "prec_at_15: 0.4056\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 126.28it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0077, 0.0148, 0.0118, 0.0131, 0.8306\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2231, 0.5668, 0.2690, 0.3649, 0.9730\n",
      "rec_at_8: 0.2675\n",
      "prec_at_8: 0.5335\n",
      "rec_at_15: 0.3686\n",
      "prec_at_15: 0.4051\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 2\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0078, 0.0139, 0.0121, 0.0129, 0.8374\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2270, 0.5682, 0.2744, 0.3701, 0.9735\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0078\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 2\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0077, 0.0148, 0.0118, 0.0131, 0.8306\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2231, 0.5668, 0.2690, 0.3649, 0.9730\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0081\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 3\n",
      "0it [00:00, ?it/s]Train epoch: 3 [batch #0, batch_size 4, seq length 68]\tLoss: 0.007275\n",
      "21it [00:00, 48.41it/s]Train epoch: 3 [batch #25, batch_size 4, seq length 221]\tLoss: 0.004669\n",
      "50it [00:01, 44.32it/s]Train epoch: 3 [batch #50, batch_size 4, seq length 270]\tLoss: 0.004555\n",
      "75it [00:01, 40.12it/s]Train epoch: 3 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003965\n",
      "98it [00:02, 37.36it/s]Train epoch: 3 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003973\n",
      "124it [00:03, 38.02it/s]Train epoch: 3 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003852\n",
      "149it [00:03, 39.87it/s]Train epoch: 3 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003696\n",
      "172it [00:04, 37.26it/s]Train epoch: 3 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003956\n",
      "200it [00:05, 36.18it/s]Train epoch: 3 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003727\n",
      "224it [00:05, 35.04it/s]Train epoch: 3 [batch #225, batch_size 4, seq length 414]\tLoss: 0.004682\n",
      "248it [00:06, 35.27it/s]Train epoch: 3 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003955\n",
      "272it [00:07, 32.34it/s]Train epoch: 3 [batch #275, batch_size 4, seq length 439]\tLoss: 0.003306\n",
      "300it [00:08, 32.71it/s]Train epoch: 3 [batch #300, batch_size 4, seq length 450]\tLoss: 0.004391\n",
      "324it [00:08, 32.54it/s]Train epoch: 3 [batch #325, batch_size 4, seq length 463]\tLoss: 0.003638\n",
      "348it [00:09, 32.97it/s]Train epoch: 3 [batch #350, batch_size 4, seq length 472]\tLoss: 0.004265\n",
      "372it [00:10, 31.17it/s]Train epoch: 3 [batch #375, batch_size 4, seq length 480]\tLoss: 0.004005\n",
      "400it [00:11, 32.49it/s]Train epoch: 3 [batch #400, batch_size 4, seq length 489]\tLoss: 0.004114\n",
      "424it [00:11, 32.12it/s]Train epoch: 3 [batch #425, batch_size 4, seq length 497]\tLoss: 0.004105\n",
      "448it [00:12, 30.54it/s]Train epoch: 3 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003960\n",
      "472it [00:13, 30.34it/s]Train epoch: 3 [batch #475, batch_size 4, seq length 512]\tLoss: 0.004496\n",
      "500it [00:14, 31.28it/s]Train epoch: 3 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003785\n",
      "524it [00:15, 30.12it/s]Train epoch: 3 [batch #525, batch_size 4, seq length 527]\tLoss: 0.004275\n",
      "548it [00:15, 29.29it/s]Train epoch: 3 [batch #550, batch_size 4, seq length 534]\tLoss: 0.004094\n",
      "573it [00:16, 28.78it/s]Train epoch: 3 [batch #575, batch_size 4, seq length 541]\tLoss: 0.004141\n",
      "598it [00:17, 30.03it/s]Train epoch: 3 [batch #600, batch_size 4, seq length 547]\tLoss: 0.004359\n",
      "625it [00:18, 28.13it/s]Train epoch: 3 [batch #625, batch_size 4, seq length 553]\tLoss: 0.004142\n",
      "648it [00:19, 29.91it/s]Train epoch: 3 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003732\n",
      "673it [00:20, 29.68it/s]Train epoch: 3 [batch #675, batch_size 4, seq length 566]\tLoss: 0.003228\n",
      "699it [00:21, 27.37it/s]Train epoch: 3 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003979\n",
      "724it [00:22, 30.05it/s]Train epoch: 3 [batch #725, batch_size 4, seq length 578]\tLoss: 0.004195\n",
      "748it [00:22, 28.59it/s]Train epoch: 3 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003929\n",
      "772it [00:23, 31.24it/s]Train epoch: 3 [batch #775, batch_size 4, seq length 589]\tLoss: 0.004429\n",
      "800it [00:24, 28.10it/s]Train epoch: 3 [batch #800, batch_size 4, seq length 596]\tLoss: 0.004321\n",
      "823it [00:25, 27.93it/s]Train epoch: 3 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003946\n",
      "848it [00:26, 28.16it/s]Train epoch: 3 [batch #850, batch_size 4, seq length 606]\tLoss: 0.004521\n",
      "874it [00:27, 28.68it/s]Train epoch: 3 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003895\n",
      "900it [00:28, 27.59it/s]Train epoch: 3 [batch #900, batch_size 4, seq length 617]\tLoss: 0.004171\n",
      "923it [00:28, 27.21it/s]Train epoch: 3 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003990\n",
      "948it [00:29, 27.46it/s]Train epoch: 3 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003941\n",
      "974it [00:30, 28.30it/s]Train epoch: 3 [batch #975, batch_size 4, seq length 632]\tLoss: 0.003213\n",
      "998it [00:31, 29.43it/s]Train epoch: 3 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.004090\n",
      "1024it [00:32, 26.66it/s]Train epoch: 3 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.005327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049it [00:33, 27.69it/s]Train epoch: 3 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003852\n",
      "1074it [00:34, 27.95it/s]Train epoch: 3 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.004336\n",
      "1099it [00:35, 27.54it/s]Train epoch: 3 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.004363\n",
      "1123it [00:36, 26.37it/s]Train epoch: 3 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.004404\n",
      "1148it [00:37, 26.68it/s]Train epoch: 3 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.004490\n",
      "1175it [00:38, 26.68it/s]Train epoch: 3 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.004383\n",
      "1199it [00:39, 26.49it/s]Train epoch: 3 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.004452\n",
      "1224it [00:39, 27.05it/s]Train epoch: 3 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.004698\n",
      "1249it [00:40, 26.20it/s]Train epoch: 3 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.004386\n",
      "1273it [00:41, 24.17it/s]Train epoch: 3 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003818\n",
      "1300it [00:43, 25.19it/s]Train epoch: 3 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003873\n",
      "1324it [00:43, 26.01it/s]Train epoch: 3 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003873\n",
      "1348it [00:44, 25.34it/s]Train epoch: 3 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.005135\n",
      "1375it [00:45, 26.24it/s]Train epoch: 3 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.004203\n",
      "1399it [00:46, 25.50it/s]Train epoch: 3 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.004099\n",
      "1423it [00:47, 24.90it/s]Train epoch: 3 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003815\n",
      "1450it [00:48, 24.41it/s]Train epoch: 3 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.004012\n",
      "1474it [00:49, 26.00it/s]Train epoch: 3 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.004303\n",
      "1498it [00:50, 24.31it/s]Train epoch: 3 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.005417\n",
      "1525it [00:51, 24.31it/s]Train epoch: 3 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.005072\n",
      "1549it [00:52, 24.48it/s]Train epoch: 3 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.004028\n",
      "1573it [00:53, 24.11it/s]Train epoch: 3 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.004433\n",
      "1597it [00:54, 24.59it/s]Train epoch: 3 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003895\n",
      "1625it [00:55, 25.97it/s]Train epoch: 3 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.004551\n",
      "1650it [00:56, 25.76it/s]Train epoch: 3 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.004782\n",
      "1674it [00:57, 24.23it/s]Train epoch: 3 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.004520\n",
      "1698it [00:58, 24.79it/s]Train epoch: 3 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.004088\n",
      "1725it [00:59, 25.23it/s]Train epoch: 3 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.003568\n",
      "1749it [01:01, 22.42it/s]Train epoch: 3 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.005201\n",
      "1773it [01:01, 24.99it/s]Train epoch: 3 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.004307\n",
      "1800it [01:03, 25.09it/s]Train epoch: 3 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.004250\n",
      "1824it [01:04, 23.22it/s]Train epoch: 3 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.003780\n",
      "1848it [01:05, 23.98it/s]Train epoch: 3 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.004394\n",
      "1875it [01:06, 24.16it/s]Train epoch: 3 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.004723\n",
      "1899it [01:07, 24.34it/s]Train epoch: 3 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.003691\n",
      "1923it [01:08, 24.95it/s]Train epoch: 3 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003928\n",
      "1950it [01:09, 25.49it/s]Train epoch: 3 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003899\n",
      "1974it [01:10, 24.61it/s]Train epoch: 3 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.004605\n",
      "1998it [01:11, 24.58it/s]Train epoch: 3 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.003640\n",
      "2025it [01:12, 24.47it/s]Train epoch: 3 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.004546\n",
      "2049it [01:13, 23.30it/s]Train epoch: 3 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.004200\n",
      "2074it [01:14, 25.13it/s]Train epoch: 3 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.004204\n",
      "2098it [01:15, 23.98it/s]Train epoch: 3 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.004624\n",
      "2125it [01:16, 24.11it/s]Train epoch: 3 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.004795\n",
      "2149it [01:17, 23.36it/s]Train epoch: 3 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.004060\n",
      "2173it [01:18, 23.08it/s]Train epoch: 3 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.004767\n",
      "2200it [01:19, 24.81it/s]Train epoch: 3 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.004503\n",
      "2224it [01:20, 24.49it/s]Train epoch: 3 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.004272\n",
      "2248it [01:21, 24.47it/s]Train epoch: 3 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.004009\n",
      "2275it [01:22, 23.37it/s]Train epoch: 3 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.004441\n",
      "2299it [01:23, 22.50it/s]Train epoch: 3 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.003462\n",
      "2323it [01:24, 21.84it/s]Train epoch: 3 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.004288\n",
      "2350it [01:25, 24.99it/s]Train epoch: 3 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003989\n",
      "2374it [01:27, 22.92it/s]Train epoch: 3 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.005647\n",
      "2398it [01:27, 24.35it/s]Train epoch: 3 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.005254\n",
      "2425it [01:29, 22.75it/s]Train epoch: 3 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.003790\n",
      "2449it [01:30, 22.98it/s]Train epoch: 3 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.004369\n",
      "2473it [01:31, 23.47it/s]Train epoch: 3 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.004748\n",
      "2500it [01:32, 23.54it/s]Train epoch: 3 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.004246\n",
      "2524it [01:33, 22.64it/s]Train epoch: 3 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.004105\n",
      "2548it [01:34, 24.24it/s]Train epoch: 3 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.005530\n",
      "2575it [01:35, 23.75it/s]Train epoch: 3 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003989\n",
      "2599it [01:36, 23.58it/s]Train epoch: 3 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.004353\n",
      "2623it [01:37, 23.08it/s]Train epoch: 3 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.004294\n",
      "2650it [01:38, 23.50it/s]Train epoch: 3 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004897\n",
      "2674it [01:39, 22.97it/s]Train epoch: 3 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.004571\n",
      "2698it [01:41, 21.98it/s]Train epoch: 3 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.004002\n",
      "2725it [01:42, 23.07it/s]Train epoch: 3 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.004338\n",
      "2749it [01:43, 23.00it/s]Train epoch: 3 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.005055\n",
      "2773it [01:44, 23.16it/s]Train epoch: 3 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.004467\n",
      "2800it [01:45, 20.95it/s]Train epoch: 3 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.004305\n",
      "2824it [01:46, 21.38it/s]Train epoch: 3 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.004510\n",
      "2848it [01:47, 22.97it/s]Train epoch: 3 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.004383\n",
      "2875it [01:49, 22.00it/s]Train epoch: 3 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.004767\n",
      "2899it [01:50, 21.24it/s]Train epoch: 3 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.004745\n",
      "2923it [01:51, 21.78it/s]Train epoch: 3 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.004756\n",
      "2950it [01:52, 21.72it/s]Train epoch: 3 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004878\n",
      "2974it [01:53, 22.86it/s]Train epoch: 3 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.004693\n",
      "2998it [01:54, 21.47it/s]Train epoch: 3 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.005157\n",
      "3025it [01:55, 23.15it/s]Train epoch: 3 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.004914\n",
      "3049it [01:56, 21.71it/s]Train epoch: 3 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.004247\n",
      "3073it [01:58, 21.19it/s]Train epoch: 3 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.004854\n",
      "3100it [01:59, 22.90it/s]Train epoch: 3 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.004971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3124it [02:00, 21.41it/s]Train epoch: 3 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.004467\n",
      "3148it [02:01, 21.00it/s]Train epoch: 3 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.004409\n",
      "3175it [02:02, 21.63it/s]Train epoch: 3 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.004399\n",
      "3199it [02:03, 22.63it/s]Train epoch: 3 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.005050\n",
      "3223it [02:05, 21.73it/s]Train epoch: 3 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004820\n",
      "3250it [02:06, 21.47it/s]Train epoch: 3 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004892\n",
      "3274it [02:07, 21.90it/s]Train epoch: 3 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.004627\n",
      "3298it [02:08, 21.56it/s]Train epoch: 3 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.005477\n",
      "3325it [02:09, 21.86it/s]Train epoch: 3 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.004756\n",
      "3349it [02:10, 20.65it/s]Train epoch: 3 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.004752\n",
      "3373it [02:11, 20.78it/s]Train epoch: 3 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.005050\n",
      "3398it [02:13, 20.36it/s]Train epoch: 3 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.005104\n",
      "3425it [02:14, 21.29it/s]Train epoch: 3 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.004547\n",
      "3449it [02:15, 20.73it/s]Train epoch: 3 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.005226\n",
      "3473it [02:16, 20.92it/s]Train epoch: 3 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.004610\n",
      "3500it [02:18, 20.95it/s]Train epoch: 3 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.004653\n",
      "3524it [02:19, 20.97it/s]Train epoch: 3 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.004957\n",
      "3548it [02:20, 21.91it/s]Train epoch: 3 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.005276\n",
      "3575it [02:21, 20.72it/s]Train epoch: 3 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.004283\n",
      "3600it [02:22, 19.68it/s]Train epoch: 3 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.005397\n",
      "3625it [02:24, 21.40it/s]Train epoch: 3 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.005028\n",
      "3650it [02:25, 18.37it/s]Train epoch: 3 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.005024\n",
      "3675it [02:26, 18.15it/s]Train epoch: 3 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.005172\n",
      "3699it [02:28, 17.33it/s]Train epoch: 3 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.005156\n",
      "3724it [02:29, 18.37it/s]Train epoch: 3 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.005205\n",
      "3749it [02:30, 18.09it/s]Train epoch: 3 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.005277\n",
      "3775it [02:32, 17.80it/s]Train epoch: 3 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.005093\n",
      "3799it [02:33, 17.48it/s]Train epoch: 3 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.005639\n",
      "3825it [02:35, 17.96it/s]Train epoch: 3 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.004822\n",
      "3849it [02:36, 17.24it/s]Train epoch: 3 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.004618\n",
      "3875it [02:37, 18.46it/s]Train epoch: 3 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.004357\n",
      "3899it [02:39, 18.02it/s]Train epoch: 3 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.005642\n",
      "3925it [02:40, 16.39it/s]Train epoch: 3 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.005083\n",
      "3950it [02:42, 16.87it/s]Train epoch: 3 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.005510\n",
      "3974it [02:43, 17.12it/s]Train epoch: 3 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.006113\n",
      "3999it [02:45, 17.48it/s]Train epoch: 3 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.004641\n",
      "4025it [02:46, 17.22it/s]Train epoch: 3 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.005659\n",
      "4050it [02:48, 16.75it/s]Train epoch: 3 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.005334\n",
      "4074it [02:49, 17.55it/s]Train epoch: 3 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.005195\n",
      "4100it [02:50, 17.26it/s]Train epoch: 3 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.005764\n",
      "4124it [02:52, 17.17it/s]Train epoch: 3 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.005625\n",
      "4150it [02:53, 17.07it/s]Train epoch: 3 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.004781\n",
      "4174it [02:55, 17.02it/s]Train epoch: 3 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.005077\n",
      "4200it [02:56, 17.71it/s]Train epoch: 3 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.005490\n",
      "4225it [02:58, 17.75it/s]Train epoch: 3 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.004757\n",
      "4249it [02:59, 17.07it/s]Train epoch: 3 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.005398\n",
      "4275it [03:01, 17.07it/s]Train epoch: 3 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.005140\n",
      "4299it [03:02, 17.37it/s]Train epoch: 3 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.005733\n",
      "4325it [03:04, 16.65it/s]Train epoch: 3 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.005054\n",
      "4349it [03:05, 15.86it/s]Train epoch: 3 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.005585\n",
      "4375it [03:07, 16.98it/s]Train epoch: 3 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.005072\n",
      "4399it [03:08, 16.88it/s]Train epoch: 3 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.004426\n",
      "4425it [03:10, 16.25it/s]Train epoch: 3 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.005389\n",
      "4449it [03:11, 17.18it/s]Train epoch: 3 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.004290\n",
      "4475it [03:12, 17.86it/s]Train epoch: 3 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.005322\n",
      "4499it [03:14, 17.58it/s]Train epoch: 3 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.006389\n",
      "4525it [03:15, 16.54it/s]Train epoch: 3 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.005499\n",
      "4549it [03:17, 16.67it/s]Train epoch: 3 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.005159\n",
      "4575it [03:18, 16.27it/s]Train epoch: 3 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.005878\n",
      "4599it [03:20, 16.55it/s]Train epoch: 3 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004888\n",
      "4625it [03:22, 15.55it/s]Train epoch: 3 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.005087\n",
      "4649it [03:23, 15.87it/s]Train epoch: 3 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.005766\n",
      "4675it [03:25, 15.72it/s]Train epoch: 3 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.005417\n",
      "4699it [03:26, 15.97it/s]Train epoch: 3 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.004899\n",
      "4725it [03:28, 15.95it/s]Train epoch: 3 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.005094\n",
      "4749it [03:29, 15.78it/s]Train epoch: 3 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.006026\n",
      "4775it [03:31, 15.82it/s]Train epoch: 3 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.005270\n",
      "4799it [03:33, 15.77it/s]Train epoch: 3 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.005619\n",
      "4825it [03:34, 16.30it/s]Train epoch: 3 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.004896\n",
      "4849it [03:36, 16.16it/s]Train epoch: 3 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.005676\n",
      "4875it [03:37, 16.06it/s]Train epoch: 3 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.004843\n",
      "4899it [03:39, 15.53it/s]Train epoch: 3 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.005514\n",
      "4925it [03:41, 15.76it/s]Train epoch: 3 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.004929\n",
      "4949it [03:42, 15.38it/s]Train epoch: 3 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.005212\n",
      "4975it [03:44, 15.30it/s]Train epoch: 3 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.005318\n",
      "4999it [03:45, 15.89it/s]Train epoch: 3 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.005474\n",
      "5025it [03:47, 14.84it/s]Train epoch: 3 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004986\n",
      "5049it [03:49, 15.41it/s]Train epoch: 3 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004944\n",
      "5075it [03:50, 15.46it/s]Train epoch: 3 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.005195\n",
      "5099it [03:52, 15.12it/s]Train epoch: 3 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.005245\n",
      "5125it [03:54, 15.22it/s]Train epoch: 3 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.005619\n",
      "5149it [03:55, 15.10it/s]Train epoch: 3 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.005509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175it [03:57, 15.46it/s]Train epoch: 3 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.005513\n",
      "5199it [03:58, 15.43it/s]Train epoch: 3 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004963\n",
      "5225it [04:00, 15.73it/s]Train epoch: 3 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.005477\n",
      "5249it [04:02, 15.33it/s]Train epoch: 3 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.005133\n",
      "5275it [04:03, 14.54it/s]Train epoch: 3 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.005167\n",
      "5299it [04:05, 15.85it/s]Train epoch: 3 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004949\n",
      "5325it [04:07, 14.57it/s]Train epoch: 3 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.005770\n",
      "5349it [04:08, 15.05it/s]Train epoch: 3 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.005808\n",
      "5375it [04:10, 15.23it/s]Train epoch: 3 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.005113\n",
      "5399it [04:11, 15.36it/s]Train epoch: 3 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.005166\n",
      "5425it [04:13, 14.51it/s]Train epoch: 3 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.005516\n",
      "5449it [04:15, 15.37it/s]Train epoch: 3 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.005461\n",
      "5475it [04:17, 15.38it/s]Train epoch: 3 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.006381\n",
      "5499it [04:18, 15.08it/s]Train epoch: 3 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.005908\n",
      "5525it [04:20, 15.30it/s]Train epoch: 3 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.004800\n",
      "5549it [04:22, 14.62it/s]Train epoch: 3 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.005406\n",
      "5575it [04:23, 14.83it/s]Train epoch: 3 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.005655\n",
      "5599it [04:25, 14.79it/s]Train epoch: 3 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.006044\n",
      "5625it [04:27, 14.62it/s]Train epoch: 3 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.005465\n",
      "5649it [04:28, 14.84it/s]Train epoch: 3 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.005034\n",
      "5675it [04:30, 15.22it/s]Train epoch: 3 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.006135\n",
      "5699it [04:32, 14.33it/s]Train epoch: 3 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.005341\n",
      "5725it [04:33, 14.84it/s]Train epoch: 3 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.005471\n",
      "5749it [04:35, 14.80it/s]Train epoch: 3 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.006780\n",
      "5775it [04:37, 14.96it/s]Train epoch: 3 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.005850\n",
      "5799it [04:38, 15.39it/s]Train epoch: 3 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.005816\n",
      "5825it [04:40, 14.65it/s]Train epoch: 3 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.005100\n",
      "5849it [04:42, 14.18it/s]Train epoch: 3 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.006497\n",
      "5875it [04:44, 14.60it/s]Train epoch: 3 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.006150\n",
      "5899it [04:45, 14.82it/s]Train epoch: 3 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.006346\n",
      "5925it [04:47, 14.29it/s]Train epoch: 3 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.005154\n",
      "5949it [04:49, 13.63it/s]Train epoch: 3 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.005130\n",
      "5975it [04:51, 14.54it/s]Train epoch: 3 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.006909\n",
      "5999it [04:52, 14.35it/s]Train epoch: 3 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.005861\n",
      "6025it [04:54, 14.94it/s]Train epoch: 3 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.006085\n",
      "6049it [04:56, 14.73it/s]Train epoch: 3 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.005421\n",
      "6075it [04:57, 14.22it/s]Train epoch: 3 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.005260\n",
      "6099it [04:59, 14.42it/s]Train epoch: 3 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004988\n",
      "6125it [05:01, 14.38it/s]Train epoch: 3 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.005554\n",
      "6149it [05:03, 14.64it/s]Train epoch: 3 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.005399\n",
      "6175it [05:04, 14.43it/s]Train epoch: 3 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.006196\n",
      "6199it [05:06, 14.37it/s]Train epoch: 3 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.005557\n",
      "6225it [05:08, 14.41it/s]Train epoch: 3 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.004921\n",
      "6249it [05:10, 14.19it/s]Train epoch: 3 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.005371\n",
      "6275it [05:11, 14.07it/s]Train epoch: 3 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.004987\n",
      "6299it [05:13, 14.35it/s]Train epoch: 3 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.005783\n",
      "6325it [05:15, 14.25it/s]Train epoch: 3 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005942\n",
      "6349it [05:17, 13.73it/s]Train epoch: 3 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.006297\n",
      "6375it [05:18, 13.76it/s]Train epoch: 3 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.005167\n",
      "6399it [05:20, 14.00it/s]Train epoch: 3 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.005327\n",
      "6425it [05:22, 14.42it/s]Train epoch: 3 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.006207\n",
      "6449it [05:24, 13.57it/s]Train epoch: 3 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.005878\n",
      "6475it [05:26, 13.65it/s]Train epoch: 3 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.005409\n",
      "6499it [05:27, 13.69it/s]Train epoch: 3 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.006181\n",
      "6525it [05:29, 13.80it/s]Train epoch: 3 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.005275\n",
      "6549it [05:31, 13.67it/s]Train epoch: 3 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.005454\n",
      "6575it [05:33, 13.87it/s]Train epoch: 3 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.005692\n",
      "6599it [05:35, 13.72it/s]Train epoch: 3 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.006668\n",
      "6625it [05:37, 13.47it/s]Train epoch: 3 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.005494\n",
      "6649it [05:39, 12.77it/s]Train epoch: 3 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.006342\n",
      "6675it [05:40, 13.32it/s]Train epoch: 3 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.005847\n",
      "6699it [05:42, 13.59it/s]Train epoch: 3 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.005895\n",
      "6725it [05:44, 13.04it/s]Train epoch: 3 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.006043\n",
      "6749it [05:46, 13.38it/s]Train epoch: 3 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.005391\n",
      "6775it [05:48, 13.09it/s]Train epoch: 3 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.006209\n",
      "6799it [05:50, 13.34it/s]Train epoch: 3 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.006084\n",
      "6825it [05:52, 13.20it/s]Train epoch: 3 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.006430\n",
      "6849it [05:54, 12.88it/s]Train epoch: 3 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005933\n",
      "6875it [05:56, 12.78it/s]Train epoch: 3 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004952\n",
      "6899it [05:58, 12.85it/s]Train epoch: 3 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.005799\n",
      "6925it [06:00, 12.94it/s]Train epoch: 3 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.005756\n",
      "6949it [06:02, 12.99it/s]Train epoch: 3 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.006466\n",
      "6975it [06:04, 12.85it/s]Train epoch: 3 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.006016\n",
      "6999it [06:05, 12.85it/s]Train epoch: 3 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.005774\n",
      "7025it [06:07, 12.63it/s]Train epoch: 3 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.006646\n",
      "7049it [06:09, 12.97it/s]Train epoch: 3 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.005250\n",
      "7075it [06:11, 13.42it/s]Train epoch: 3 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.005940\n",
      "7099it [06:13, 12.67it/s]Train epoch: 3 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.006220\n",
      "7125it [06:15, 13.07it/s]Train epoch: 3 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.005371\n",
      "7149it [06:17, 13.14it/s]Train epoch: 3 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.006588\n",
      "7175it [06:19, 12.91it/s]Train epoch: 3 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.005974\n",
      "7199it [06:21, 12.40it/s]Train epoch: 3 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.006346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7225it [06:23, 12.52it/s]Train epoch: 3 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.005743\n",
      "7249it [06:25, 12.74it/s]Train epoch: 3 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.005935\n",
      "7275it [06:27, 12.91it/s]Train epoch: 3 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.006466\n",
      "7299it [06:29, 12.39it/s]Train epoch: 3 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.006920\n",
      "7325it [06:31, 12.88it/s]Train epoch: 3 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.005622\n",
      "7349it [06:33, 12.90it/s]Train epoch: 3 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.006725\n",
      "7375it [06:35, 12.83it/s]Train epoch: 3 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.006166\n",
      "7399it [06:37, 12.26it/s]Train epoch: 3 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.005634\n",
      "7425it [06:39, 12.60it/s]Train epoch: 3 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.006165\n",
      "7449it [06:41, 12.48it/s]Train epoch: 3 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.006914\n",
      "7475it [06:43, 12.22it/s]Train epoch: 3 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.005928\n",
      "7499it [06:45, 12.41it/s]Train epoch: 3 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.006250\n",
      "7525it [06:47, 12.65it/s]Train epoch: 3 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.006010\n",
      "7549it [06:49, 12.29it/s]Train epoch: 3 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.005725\n",
      "7575it [06:51, 12.29it/s]Train epoch: 3 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.006378\n",
      "7599it [06:53, 12.36it/s]Train epoch: 3 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.007451\n",
      "7625it [06:55, 12.53it/s]Train epoch: 3 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.006880\n",
      "7649it [06:57, 12.01it/s]Train epoch: 3 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.005893\n",
      "7675it [06:59, 12.47it/s]Train epoch: 3 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.006157\n",
      "7699it [07:01, 12.43it/s]Train epoch: 3 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.006125\n",
      "7725it [07:03, 12.10it/s]Train epoch: 3 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.006116\n",
      "7749it [07:05, 12.21it/s]Train epoch: 3 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.006358\n",
      "7775it [07:07, 12.41it/s]Train epoch: 3 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.005803\n",
      "7799it [07:09, 11.89it/s]Train epoch: 3 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.006109\n",
      "7825it [07:11, 11.83it/s]Train epoch: 3 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.006174\n",
      "7849it [07:13, 11.96it/s]Train epoch: 3 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.005724\n",
      "7875it [07:15, 12.18it/s]Train epoch: 3 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.006092\n",
      "7899it [07:17, 11.87it/s]Train epoch: 3 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.006321\n",
      "7925it [07:20, 11.87it/s]Train epoch: 3 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.006280\n",
      "7949it [07:22, 12.30it/s]Train epoch: 3 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.006933\n",
      "7975it [07:24, 12.34it/s]Train epoch: 3 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.006183\n",
      "7999it [07:26, 12.00it/s]Train epoch: 3 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.005925\n",
      "8025it [07:28, 11.64it/s]Train epoch: 3 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.006514\n",
      "8049it [07:30, 12.08it/s]Train epoch: 3 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.005628\n",
      "8075it [07:32, 11.71it/s]Train epoch: 3 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.006237\n",
      "8099it [07:34, 11.63it/s]Train epoch: 3 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.006542\n",
      "8125it [07:37, 11.79it/s]Train epoch: 3 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.006700\n",
      "8149it [07:39, 11.98it/s]Train epoch: 3 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.005936\n",
      "8175it [07:41, 11.14it/s]Train epoch: 3 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.006724\n",
      "8199it [07:43, 11.61it/s]Train epoch: 3 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.005962\n",
      "8225it [07:45, 11.39it/s]Train epoch: 3 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.007383\n",
      "8249it [07:47, 11.32it/s]Train epoch: 3 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.006050\n",
      "8275it [07:50, 11.48it/s]Train epoch: 3 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.006804\n",
      "8299it [07:52, 11.12it/s]Train epoch: 3 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.006047\n",
      "8325it [07:54, 11.38it/s]Train epoch: 3 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.006695\n",
      "8349it [07:56, 10.91it/s]Train epoch: 3 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.005910\n",
      "8375it [07:59, 10.93it/s]Train epoch: 3 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.006642\n",
      "8399it [08:01, 11.33it/s]Train epoch: 3 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.006153\n",
      "8425it [08:03, 10.77it/s]Train epoch: 3 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.006349\n",
      "8449it [08:05, 11.30it/s]Train epoch: 3 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.006633\n",
      "8475it [08:08, 11.36it/s]Train epoch: 3 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.006286\n",
      "8499it [08:10, 11.21it/s]Train epoch: 3 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.007309\n",
      "8525it [08:12, 11.27it/s]Train epoch: 3 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.006234\n",
      "8549it [08:14, 10.92it/s]Train epoch: 3 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.006717\n",
      "8575it [08:17, 11.10it/s]Train epoch: 3 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.006301\n",
      "8599it [08:19, 10.68it/s]Train epoch: 3 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.006345\n",
      "8625it [08:21, 10.63it/s]Train epoch: 3 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.006426\n",
      "8649it [08:23, 10.56it/s]Train epoch: 3 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.006670\n",
      "8675it [08:26, 10.87it/s]Train epoch: 3 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.007370\n",
      "8699it [08:28, 10.65it/s]Train epoch: 3 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.007381\n",
      "8725it [08:30, 11.03it/s]Train epoch: 3 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.007062\n",
      "8749it [08:33, 10.88it/s]Train epoch: 3 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.006825\n",
      "8775it [08:35, 10.69it/s]Train epoch: 3 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.006149\n",
      "8799it [08:37, 10.56it/s]Train epoch: 3 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.006456\n",
      "8825it [08:40,  9.95it/s]Train epoch: 3 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.006535\n",
      "8849it [08:42, 10.60it/s]Train epoch: 3 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.006799\n",
      "8875it [08:44, 10.69it/s]Train epoch: 3 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.006612\n",
      "8899it [08:47, 10.47it/s]Train epoch: 3 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.006535\n",
      "8925it [08:49, 10.93it/s]Train epoch: 3 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.006808\n",
      "8949it [08:51, 10.76it/s]Train epoch: 3 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.007483\n",
      "8975it [08:54, 10.81it/s]Train epoch: 3 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.007179\n",
      "8999it [08:56, 10.88it/s]Train epoch: 3 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.006427\n",
      "9025it [08:59, 10.64it/s]Train epoch: 3 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.006692\n",
      "9049it [09:01, 10.55it/s]Train epoch: 3 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.006340\n",
      "9075it [09:03, 10.67it/s]Train epoch: 3 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.005814\n",
      "9099it [09:06,  9.93it/s]Train epoch: 3 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.006843\n",
      "9125it [09:08, 10.37it/s]Train epoch: 3 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.006467\n",
      "9150it [09:11,  9.91it/s]Train epoch: 3 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.005985\n",
      "9174it [09:13, 10.62it/s]Train epoch: 3 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.006424\n",
      "9200it [09:15,  9.96it/s]Train epoch: 3 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.006443\n",
      "9224it [09:18,  9.89it/s]Train epoch: 3 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.007583\n",
      "9249it [09:21,  9.74it/s]Train epoch: 3 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.006473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9274it [09:23,  9.42it/s]Train epoch: 3 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.007071\n",
      "9300it [09:26, 10.01it/s]Train epoch: 3 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.007734\n",
      "9325it [09:28,  9.71it/s]Train epoch: 3 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.007620\n",
      "9350it [09:31, 10.08it/s]Train epoch: 3 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.007388\n",
      "9375it [09:33,  9.88it/s]Train epoch: 3 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.006654\n",
      "9399it [09:36,  9.53it/s]Train epoch: 3 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.006893\n",
      "9425it [09:38,  9.17it/s]Train epoch: 3 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.006566\n",
      "9449it [09:41, 10.09it/s]Train epoch: 3 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.006464\n",
      "9475it [09:43,  9.88it/s]Train epoch: 3 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.007431\n",
      "9500it [09:46,  9.35it/s]Train epoch: 3 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.006901\n",
      "9525it [09:49,  9.93it/s]Train epoch: 3 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.007305\n",
      "9550it [09:51,  9.10it/s]Train epoch: 3 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.007299\n",
      "9574it [09:54, 10.07it/s]Train epoch: 3 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.007163\n",
      "9600it [09:56, 10.01it/s]Train epoch: 3 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.006950\n",
      "9625it [09:59,  9.63it/s]Train epoch: 3 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.006470\n",
      "9650it [10:02,  9.30it/s]Train epoch: 3 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.006583\n",
      "9675it [10:04,  8.94it/s]Train epoch: 3 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.006937\n",
      "9700it [10:07,  9.26it/s]Train epoch: 3 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.006335\n",
      "9725it [10:09,  9.73it/s]Train epoch: 3 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.007194\n",
      "9750it [10:12,  9.40it/s]Train epoch: 3 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.006825\n",
      "9775it [10:15,  9.36it/s]Train epoch: 3 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.007779\n",
      "9800it [10:17,  9.18it/s]Train epoch: 3 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.007462\n",
      "9825it [10:20,  9.36it/s]Train epoch: 3 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.007604\n",
      "9850it [10:23,  8.94it/s]Train epoch: 3 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.006941\n",
      "9875it [10:26,  8.70it/s]Train epoch: 3 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.007587\n",
      "9900it [10:28,  8.92it/s]Train epoch: 3 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.008078\n",
      "9924it [10:31,  9.31it/s]Train epoch: 3 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.007431\n",
      "9950it [10:34,  9.34it/s]Train epoch: 3 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.008117\n",
      "9975it [10:37,  8.99it/s]Train epoch: 3 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.007545\n",
      "10000it [10:39,  8.95it/s]Train epoch: 3 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.007107\n",
      "10025it [10:42,  9.29it/s]Train epoch: 3 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.007115\n",
      "10050it [10:45,  8.80it/s]Train epoch: 3 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.007713\n",
      "10075it [10:47,  9.25it/s]Train epoch: 3 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.008081\n",
      "10100it [10:50,  9.08it/s]Train epoch: 3 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.007500\n",
      "10125it [10:53,  8.92it/s]Train epoch: 3 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.006962\n",
      "10150it [10:56,  8.83it/s]Train epoch: 3 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.007564\n",
      "10175it [10:59,  8.80it/s]Train epoch: 3 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.007054\n",
      "10200it [11:01,  8.97it/s]Train epoch: 3 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.007560\n",
      "10225it [11:04,  8.85it/s]Train epoch: 3 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.007656\n",
      "10250it [11:07,  8.84it/s]Train epoch: 3 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.008013\n",
      "10275it [11:10,  8.81it/s]Train epoch: 3 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.007202\n",
      "10300it [11:13,  9.17it/s]Train epoch: 3 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.007849\n",
      "10325it [11:15,  8.69it/s]Train epoch: 3 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.007706\n",
      "10350it [11:18,  8.78it/s]Train epoch: 3 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.007566\n",
      "10375it [11:21,  8.59it/s]Train epoch: 3 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.007849\n",
      "10400it [11:24,  8.82it/s]Train epoch: 3 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.007938\n",
      "10425it [11:27,  8.25it/s]Train epoch: 3 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.007496\n",
      "10450it [11:30,  8.44it/s]Train epoch: 3 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.007788\n",
      "10475it [11:33,  8.23it/s]Train epoch: 3 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.006869\n",
      "10500it [11:36,  8.59it/s]Train epoch: 3 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.007815\n",
      "10525it [11:39,  8.05it/s]Train epoch: 3 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.007413\n",
      "10550it [11:42,  8.08it/s]Train epoch: 3 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.007831\n",
      "10575it [11:45,  8.17it/s]Train epoch: 3 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.006980\n",
      "10600it [11:48,  8.22it/s]Train epoch: 3 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.007121\n",
      "10625it [11:51,  8.10it/s]Train epoch: 3 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.007741\n",
      "10650it [11:55,  7.98it/s]Train epoch: 3 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.007301\n",
      "10675it [11:58,  7.95it/s]Train epoch: 3 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.007747\n",
      "10700it [12:01,  7.77it/s]Train epoch: 3 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.007337\n",
      "10725it [12:04,  8.15it/s]Train epoch: 3 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.006721\n",
      "10750it [12:07,  7.33it/s]Train epoch: 3 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.008039\n",
      "10775it [12:11,  7.65it/s]Train epoch: 3 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.008124\n",
      "10800it [12:14,  7.27it/s]Train epoch: 3 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.008276\n",
      "10825it [12:17,  7.22it/s]Train epoch: 3 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.008196\n",
      "10850it [12:21,  7.63it/s]Train epoch: 3 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.007971\n",
      "10875it [12:24,  7.71it/s]Train epoch: 3 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.008247\n",
      "10900it [12:27,  7.80it/s]Train epoch: 3 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.007829\n",
      "10925it [12:31,  7.48it/s]Train epoch: 3 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.007392\n",
      "10950it [12:34,  7.69it/s]Train epoch: 3 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.007788\n",
      "10975it [12:37,  7.65it/s]Train epoch: 3 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.007662\n",
      "11000it [12:40,  7.57it/s]Train epoch: 3 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.007604\n",
      "11025it [12:44,  7.74it/s]Train epoch: 3 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.007733\n",
      "11050it [12:47,  7.83it/s]Train epoch: 3 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.008594\n",
      "11075it [12:50,  7.77it/s]Train epoch: 3 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.008047\n",
      "11100it [12:53,  7.76it/s]Train epoch: 3 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.008839\n",
      "11125it [12:56,  7.71it/s]Train epoch: 3 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.008197\n",
      "11150it [13:00,  7.68it/s]Train epoch: 3 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.007973\n",
      "11175it [13:03,  7.78it/s]Train epoch: 3 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.009182\n",
      "11200it [13:06,  7.64it/s]Train epoch: 3 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.008334\n",
      "11225it [13:09,  7.87it/s]Train epoch: 3 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.008200\n",
      "11250it [13:13,  7.75it/s]Train epoch: 3 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.008882\n",
      "11275it [13:16,  7.62it/s]Train epoch: 3 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.008694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11300it [13:19,  7.97it/s]Train epoch: 3 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.007852\n",
      "11325it [13:22,  7.67it/s]Train epoch: 3 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.009075\n",
      "11350it [13:25,  7.67it/s]Train epoch: 3 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.009147\n",
      "11375it [13:29,  7.82it/s]Train epoch: 3 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.009397\n",
      "11400it [13:32,  7.76it/s]Train epoch: 3 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.008245\n",
      "11425it [13:35,  7.39it/s]Train epoch: 3 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.008870\n",
      "11450it [13:39,  7.76it/s]Train epoch: 3 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.008037\n",
      "11475it [13:42,  7.87it/s]Train epoch: 3 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.009753\n",
      "11500it [13:45,  7.61it/s]Train epoch: 3 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.009252\n",
      "11525it [13:48,  7.74it/s]Train epoch: 3 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.008485\n",
      "11550it [13:51,  7.59it/s]Train epoch: 3 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.008536\n",
      "11575it [13:55,  7.64it/s]Train epoch: 3 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.009657\n",
      "11600it [13:58,  7.68it/s]Train epoch: 3 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.008824\n",
      "11625it [14:01,  7.59it/s]Train epoch: 3 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.008320\n",
      "11650it [14:04,  7.75it/s]Train epoch: 3 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.009056\n",
      "11675it [14:08,  7.80it/s]Train epoch: 3 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.009541\n",
      "11700it [14:11,  7.47it/s]Train epoch: 3 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.009961\n",
      "11725it [14:15,  7.12it/s]Train epoch: 3 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.010008\n",
      "11750it [14:18,  7.26it/s]Train epoch: 3 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.009712\n",
      "11775it [14:21,  7.13it/s]Train epoch: 3 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.009591\n",
      "11800it [14:25,  7.62it/s]Train epoch: 3 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.009470\n",
      "11825it [14:28,  7.92it/s]Train epoch: 3 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.009748\n",
      "11850it [14:31,  7.84it/s]Train epoch: 3 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.009720\n",
      "11875it [14:34,  7.72it/s]Train epoch: 3 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.010836\n",
      "11900it [14:38,  7.74it/s]Train epoch: 3 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.012904\n",
      "11925it [14:41,  7.67it/s]Train epoch: 3 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010964\n",
      "11930it [14:41, 13.53it/s]\n",
      "epoch loss: 0.005918673525592866\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 126.30it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0109, 0.0188, 0.0169, 0.0178, 0.8510\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2609, 0.5700, 0.3248, 0.4138, 0.9761\n",
      "rec_at_8: 0.3050\n",
      "prec_at_8: 0.5763\n",
      "rec_at_15: 0.4214\n",
      "prec_at_15: 0.4413\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 127.07it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0110, 0.0204, 0.0171, 0.0186, 0.8427\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2566, 0.5684, 0.3187, 0.4084, 0.9757\n",
      "rec_at_8: 0.2916\n",
      "prec_at_8: 0.5740\n",
      "rec_at_15: 0.4029\n",
      "prec_at_15: 0.4386\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 3\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0109, 0.0188, 0.0169, 0.0178, 0.8510\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2609, 0.5700, 0.3248, 0.4138, 0.9761\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0074\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 3\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0110, 0.0204, 0.0171, 0.0186, 0.8427\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2566, 0.5684, 0.3187, 0.4084, 0.9757\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0077\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 4\n",
      "0it [00:00, ?it/s]Train epoch: 4 [batch #0, batch_size 4, seq length 68]\tLoss: 0.007591\n",
      "24it [00:00, 44.52it/s]Train epoch: 4 [batch #25, batch_size 4, seq length 221]\tLoss: 0.004414\n",
      "46it [00:01, 46.03it/s]Train epoch: 4 [batch #50, batch_size 4, seq length 270]\tLoss: 0.004330\n",
      "71it [00:01, 41.10it/s]Train epoch: 4 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003710\n",
      "99it [00:02, 39.27it/s]Train epoch: 4 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003693\n",
      "125it [00:03, 37.31it/s]Train epoch: 4 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003673\n",
      "150it [00:03, 36.30it/s]Train epoch: 4 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003487\n",
      "173it [00:04, 39.71it/s]Train epoch: 4 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003717\n",
      "197it [00:04, 35.78it/s]Train epoch: 4 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003511\n",
      "222it [00:05, 34.17it/s]Train epoch: 4 [batch #225, batch_size 4, seq length 414]\tLoss: 0.004408\n",
      "250it [00:06, 33.91it/s]Train epoch: 4 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003747\n",
      "274it [00:07, 32.54it/s]Train epoch: 4 [batch #275, batch_size 4, seq length 439]\tLoss: 0.003074\n",
      "298it [00:08, 32.35it/s]Train epoch: 4 [batch #300, batch_size 4, seq length 450]\tLoss: 0.004089\n",
      "322it [00:08, 31.95it/s]Train epoch: 4 [batch #325, batch_size 4, seq length 463]\tLoss: 0.003435\n",
      "349it [00:09, 30.36it/s]Train epoch: 4 [batch #350, batch_size 4, seq length 472]\tLoss: 0.004022\n",
      "373it [00:10, 32.29it/s]Train epoch: 4 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003828\n",
      "397it [00:11, 30.22it/s]Train epoch: 4 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003878\n",
      "425it [00:12, 31.11it/s]Train epoch: 4 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003848\n",
      "449it [00:12, 31.38it/s]Train epoch: 4 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003742\n",
      "473it [00:13, 32.65it/s]Train epoch: 4 [batch #475, batch_size 4, seq length 512]\tLoss: 0.004250\n",
      "497it [00:14, 30.69it/s]Train epoch: 4 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003574\n",
      "523it [00:15, 29.89it/s]Train epoch: 4 [batch #525, batch_size 4, seq length 527]\tLoss: 0.004001\n",
      "547it [00:16, 31.18it/s]Train epoch: 4 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003853\n",
      "575it [00:16, 30.37it/s]Train epoch: 4 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003860\n",
      "599it [00:17, 29.07it/s]Train epoch: 4 [batch #600, batch_size 4, seq length 547]\tLoss: 0.004075\n",
      "623it [00:18, 30.32it/s]Train epoch: 4 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003882\n",
      "649it [00:19, 27.58it/s]Train epoch: 4 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003542\n",
      "674it [00:20, 29.73it/s]Train epoch: 4 [batch #675, batch_size 4, seq length 566]\tLoss: 0.003061\n",
      "698it [00:21, 30.13it/s]Train epoch: 4 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003771\n",
      "723it [00:21, 27.67it/s]Train epoch: 4 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003934\n",
      "748it [00:22, 28.47it/s]Train epoch: 4 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003663\n",
      "775it [00:23, 29.01it/s]Train epoch: 4 [batch #775, batch_size 4, seq length 589]\tLoss: 0.004146\n",
      "800it [00:24, 28.21it/s]Train epoch: 4 [batch #800, batch_size 4, seq length 596]\tLoss: 0.004052\n",
      "824it [00:25, 28.18it/s]Train epoch: 4 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003798\n",
      "849it [00:26, 28.67it/s]Train epoch: 4 [batch #850, batch_size 4, seq length 606]\tLoss: 0.004319\n",
      "874it [00:27, 26.50it/s]Train epoch: 4 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003605\n",
      "898it [00:28, 27.20it/s]Train epoch: 4 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003948\n",
      "923it [00:29, 27.39it/s]Train epoch: 4 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003746\n",
      "949it [00:30, 28.02it/s]Train epoch: 4 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003702\n",
      "974it [00:30, 27.25it/s]Train epoch: 4 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002966\n",
      "997it [00:31, 28.42it/s]Train epoch: 4 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023it [00:32, 26.66it/s]Train epoch: 4 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.005081\n",
      "1048it [00:33, 26.75it/s]Train epoch: 4 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003626\n",
      "1074it [00:34, 29.24it/s]Train epoch: 4 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.004106\n",
      "1099it [00:35, 27.25it/s]Train epoch: 4 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.004124\n",
      "1123it [00:36, 25.97it/s]Train epoch: 4 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.004195\n",
      "1150it [00:37, 26.74it/s]Train epoch: 4 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.004239\n",
      "1174it [00:38, 25.97it/s]Train epoch: 4 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.004157\n",
      "1198it [00:39, 27.12it/s]Train epoch: 4 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.004201\n",
      "1222it [00:40, 25.89it/s]Train epoch: 4 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.004417\n",
      "1250it [00:41, 27.97it/s]Train epoch: 4 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.004168\n",
      "1275it [00:41, 26.21it/s]Train epoch: 4 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003612\n",
      "1300it [00:42, 26.92it/s]Train epoch: 4 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003641\n",
      "1324it [00:43, 25.93it/s]Train epoch: 4 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003656\n",
      "1349it [00:44, 25.95it/s]Train epoch: 4 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004801\n",
      "1373it [00:45, 25.58it/s]Train epoch: 4 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003984\n",
      "1398it [00:46, 26.84it/s]Train epoch: 4 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003886\n",
      "1425it [00:47, 25.39it/s]Train epoch: 4 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003556\n",
      "1449it [00:48, 25.48it/s]Train epoch: 4 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003835\n",
      "1474it [00:49, 25.86it/s]Train epoch: 4 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.004041\n",
      "1499it [00:50, 25.70it/s]Train epoch: 4 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.005153\n",
      "1524it [00:51, 27.42it/s]Train epoch: 4 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004881\n",
      "1548it [00:52, 25.57it/s]Train epoch: 4 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003870\n",
      "1575it [00:53, 24.61it/s]Train epoch: 4 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.004207\n",
      "1600it [00:54, 26.91it/s]Train epoch: 4 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003666\n",
      "1624it [00:55, 24.95it/s]Train epoch: 4 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.004363\n",
      "1648it [00:56, 25.39it/s]Train epoch: 4 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.004528\n",
      "1675it [00:57, 24.41it/s]Train epoch: 4 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.004290\n",
      "1699it [00:58, 26.12it/s]Train epoch: 4 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003820\n",
      "1723it [00:59, 23.43it/s]Train epoch: 4 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.003330\n",
      "1748it [01:00, 24.81it/s]Train epoch: 4 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004940\n",
      "1775it [01:01, 24.50it/s]Train epoch: 4 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.004088\n",
      "1799it [01:02, 23.96it/s]Train epoch: 4 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.004054\n",
      "1823it [01:03, 24.77it/s]Train epoch: 4 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.003503\n",
      "1850it [01:04, 25.35it/s]Train epoch: 4 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.004186\n",
      "1874it [01:05, 25.04it/s]Train epoch: 4 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.004461\n",
      "1898it [01:06, 24.82it/s]Train epoch: 4 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.003467\n",
      "1925it [01:07, 24.36it/s]Train epoch: 4 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003663\n",
      "1949it [01:08, 24.54it/s]Train epoch: 4 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003597\n",
      "1973it [01:09, 25.02it/s]Train epoch: 4 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.004365\n",
      "2000it [01:10, 24.55it/s]Train epoch: 4 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.003443\n",
      "2024it [01:11, 24.97it/s]Train epoch: 4 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.004284\n",
      "2048it [01:12, 23.54it/s]Train epoch: 4 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003956\n",
      "2075it [01:13, 25.59it/s]Train epoch: 4 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.004000\n",
      "2099it [01:14, 24.39it/s]Train epoch: 4 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.004313\n",
      "2123it [01:15, 24.01it/s]Train epoch: 4 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.004539\n",
      "2150it [01:16, 23.55it/s]Train epoch: 4 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003836\n",
      "2174it [01:17, 24.25it/s]Train epoch: 4 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.004519\n",
      "2198it [01:18, 24.84it/s]Train epoch: 4 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.004246\n",
      "2225it [01:19, 24.42it/s]Train epoch: 4 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.004036\n",
      "2249it [01:20, 23.34it/s]Train epoch: 4 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003844\n",
      "2273it [01:21, 22.81it/s]Train epoch: 4 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.004219\n",
      "2300it [01:23, 22.41it/s]Train epoch: 4 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.003239\n",
      "2324it [01:24, 23.93it/s]Train epoch: 4 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003991\n",
      "2348it [01:25, 23.03it/s]Train epoch: 4 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003747\n",
      "2375it [01:26, 23.80it/s]Train epoch: 4 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.005349\n",
      "2399it [01:27, 23.44it/s]Train epoch: 4 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004975\n",
      "2423it [01:28, 24.35it/s]Train epoch: 4 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.003550\n",
      "2450it [01:29, 22.84it/s]Train epoch: 4 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.004137\n",
      "2474it [01:30, 23.15it/s]Train epoch: 4 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.004536\n",
      "2498it [01:31, 22.26it/s]Train epoch: 4 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.004009\n",
      "2525it [01:32, 22.79it/s]Train epoch: 4 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003867\n",
      "2549it [01:34, 21.95it/s]Train epoch: 4 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.005265\n",
      "2573it [01:35, 22.84it/s]Train epoch: 4 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003754\n",
      "2600it [01:36, 22.30it/s]Train epoch: 4 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.004096\n",
      "2624it [01:37, 22.39it/s]Train epoch: 4 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.004082\n",
      "2648it [01:38, 21.78it/s]Train epoch: 4 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004681\n",
      "2675it [01:39, 21.14it/s]Train epoch: 4 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.004298\n",
      "2699it [01:40, 21.23it/s]Train epoch: 4 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003776\n",
      "2723it [01:41, 22.71it/s]Train epoch: 4 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.004083\n",
      "2750it [01:43, 22.60it/s]Train epoch: 4 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004760\n",
      "2774it [01:44, 23.47it/s]Train epoch: 4 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.004167\n",
      "2798it [01:45, 22.34it/s]Train epoch: 4 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.004063\n",
      "2825it [01:46, 20.81it/s]Train epoch: 4 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.004344\n",
      "2849it [01:47, 22.11it/s]Train epoch: 4 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.004165\n",
      "2873it [01:48, 22.34it/s]Train epoch: 4 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.004519\n",
      "2900it [01:49, 21.84it/s]Train epoch: 4 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.004510\n",
      "2924it [01:51, 21.50it/s]Train epoch: 4 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.004488\n",
      "2948it [01:52, 20.80it/s]Train epoch: 4 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004704\n",
      "2975it [01:53, 21.24it/s]Train epoch: 4 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.004445\n",
      "2999it [01:54, 21.22it/s]Train epoch: 4 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004912\n",
      "3023it [01:55, 20.42it/s]Train epoch: 4 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.004621\n",
      "3050it [01:56, 21.61it/s]Train epoch: 4 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.004020\n",
      "3074it [01:58, 21.57it/s]Train epoch: 4 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.004562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3098it [01:59, 22.61it/s]Train epoch: 4 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.004710\n",
      "3125it [02:00, 22.40it/s]Train epoch: 4 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.004197\n",
      "3149it [02:01, 21.38it/s]Train epoch: 4 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.004163\n",
      "3173it [02:02, 20.94it/s]Train epoch: 4 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.004119\n",
      "3200it [02:03, 22.16it/s]Train epoch: 4 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004783\n",
      "3224it [02:05, 20.80it/s]Train epoch: 4 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004579\n",
      "3248it [02:06, 20.76it/s]Train epoch: 4 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004646\n",
      "3275it [02:07, 19.99it/s]Train epoch: 4 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.004331\n",
      "3299it [02:08, 21.25it/s]Train epoch: 4 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.005230\n",
      "3323it [02:09, 20.51it/s]Train epoch: 4 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.004513\n",
      "3350it [02:11, 20.78it/s]Train epoch: 4 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.004480\n",
      "3374it [02:12, 20.99it/s]Train epoch: 4 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.004670\n",
      "3398it [02:13, 20.30it/s]Train epoch: 4 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004784\n",
      "3425it [02:14, 21.18it/s]Train epoch: 4 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.004263\n",
      "3449it [02:15, 19.66it/s]Train epoch: 4 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004907\n",
      "3475it [02:17, 20.29it/s]Train epoch: 4 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.004407\n",
      "3499it [02:18, 20.66it/s]Train epoch: 4 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.004435\n",
      "3523it [02:19, 21.15it/s]Train epoch: 4 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.004711\n",
      "3550it [02:20, 20.10it/s]Train epoch: 4 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.005032\n",
      "3574it [02:21, 20.52it/s]Train epoch: 4 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.004032\n",
      "3598it [02:23, 20.69it/s]Train epoch: 4 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.005164\n",
      "3625it [02:24, 20.05it/s]Train epoch: 4 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.004744\n",
      "3649it [02:25, 19.70it/s]Train epoch: 4 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004771\n",
      "3674it [02:26, 18.63it/s]Train epoch: 4 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004930\n",
      "3699it [02:28, 17.52it/s]Train epoch: 4 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004848\n",
      "3724it [02:29, 17.95it/s]Train epoch: 4 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004949\n",
      "3750it [02:31, 17.75it/s]Train epoch: 4 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.005047\n",
      "3774it [02:32, 17.76it/s]Train epoch: 4 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004839\n",
      "3800it [02:34, 17.37it/s]Train epoch: 4 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.005355\n",
      "3825it [02:35, 17.28it/s]Train epoch: 4 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.004526\n",
      "3849it [02:36, 17.68it/s]Train epoch: 4 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.004295\n",
      "3875it [02:38, 16.59it/s]Train epoch: 4 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.004140\n",
      "3899it [02:39, 17.27it/s]Train epoch: 4 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.005332\n",
      "3925it [02:41, 17.17it/s]Train epoch: 4 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004791\n",
      "3949it [02:42, 17.38it/s]Train epoch: 4 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.005230\n",
      "3975it [02:44, 17.69it/s]Train epoch: 4 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.005759\n",
      "3999it [02:45, 17.66it/s]Train epoch: 4 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.004400\n",
      "4025it [02:47, 16.68it/s]Train epoch: 4 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.005387\n",
      "4049it [02:48, 16.41it/s]Train epoch: 4 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.005024\n",
      "4075it [02:49, 17.00it/s]Train epoch: 4 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004935\n",
      "4099it [02:51, 17.32it/s]Train epoch: 4 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.005455\n",
      "4125it [02:52, 17.65it/s]Train epoch: 4 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.005409\n",
      "4149it [02:54, 17.30it/s]Train epoch: 4 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.004517\n",
      "4175it [02:55, 17.32it/s]Train epoch: 4 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004790\n",
      "4199it [02:57, 17.23it/s]Train epoch: 4 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.005253\n",
      "4225it [02:58, 16.89it/s]Train epoch: 4 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.004505\n",
      "4249it [03:00, 16.39it/s]Train epoch: 4 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.005112\n",
      "4275it [03:01, 17.28it/s]Train epoch: 4 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004842\n",
      "4299it [03:03, 17.32it/s]Train epoch: 4 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.005429\n",
      "4325it [03:04, 15.81it/s]Train epoch: 4 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004796\n",
      "4349it [03:06, 17.10it/s]Train epoch: 4 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.005317\n",
      "4375it [03:07, 16.70it/s]Train epoch: 4 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004764\n",
      "4399it [03:09, 16.41it/s]Train epoch: 4 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.004229\n",
      "4425it [03:10, 16.36it/s]Train epoch: 4 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.005108\n",
      "4449it [03:12, 16.28it/s]Train epoch: 4 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.004016\n",
      "4475it [03:13, 16.24it/s]Train epoch: 4 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.005061\n",
      "4499it [03:15, 16.07it/s]Train epoch: 4 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.006055\n",
      "4525it [03:16, 16.29it/s]Train epoch: 4 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.005217\n",
      "4549it [03:18, 16.38it/s]Train epoch: 4 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004893\n",
      "4575it [03:19, 16.76it/s]Train epoch: 4 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.005580\n",
      "4599it [03:21, 15.45it/s]Train epoch: 4 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004650\n",
      "4625it [03:23, 15.45it/s]Train epoch: 4 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004743\n",
      "4649it [03:24, 15.73it/s]Train epoch: 4 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.005432\n",
      "4675it [03:26, 15.73it/s]Train epoch: 4 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.005110\n",
      "4699it [03:27, 15.27it/s]Train epoch: 4 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.004637\n",
      "4725it [03:29, 16.60it/s]Train epoch: 4 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004848\n",
      "4749it [03:30, 15.29it/s]Train epoch: 4 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.005655\n",
      "4775it [03:32, 15.96it/s]Train epoch: 4 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.005003\n",
      "4799it [03:34, 15.46it/s]Train epoch: 4 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.005250\n",
      "4825it [03:35, 15.13it/s]Train epoch: 4 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.004648\n",
      "4849it [03:37, 15.53it/s]Train epoch: 4 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.005352\n",
      "4875it [03:39, 16.21it/s]Train epoch: 4 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.004527\n",
      "4899it [03:40, 14.99it/s]Train epoch: 4 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.005154\n",
      "4925it [03:42, 15.32it/s]Train epoch: 4 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.004670\n",
      "4949it [03:43, 14.98it/s]Train epoch: 4 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004972\n",
      "4975it [03:45, 15.47it/s]Train epoch: 4 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004985\n",
      "4999it [03:47, 15.77it/s]Train epoch: 4 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.005187\n",
      "5025it [03:48, 15.34it/s]Train epoch: 4 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004745\n",
      "5049it [03:50, 14.72it/s]Train epoch: 4 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004678\n",
      "5075it [03:52, 15.19it/s]Train epoch: 4 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004954\n",
      "5099it [03:53, 15.41it/s]Train epoch: 4 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004935\n",
      "5125it [03:55, 15.06it/s]Train epoch: 4 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.005327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5149it [03:57, 15.21it/s]Train epoch: 4 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.005258\n",
      "5175it [03:58, 15.83it/s]Train epoch: 4 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.005261\n",
      "5199it [04:00, 14.92it/s]Train epoch: 4 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004701\n",
      "5225it [04:02, 14.74it/s]Train epoch: 4 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.005168\n",
      "5249it [04:03, 15.43it/s]Train epoch: 4 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004886\n",
      "5275it [04:05, 15.14it/s]Train epoch: 4 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004872\n",
      "5299it [04:06, 15.24it/s]Train epoch: 4 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004699\n",
      "5325it [04:08, 14.39it/s]Train epoch: 4 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.005464\n",
      "5349it [04:10, 15.10it/s]Train epoch: 4 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.005492\n",
      "5375it [04:12, 14.56it/s]Train epoch: 4 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004868\n",
      "5399it [04:13, 14.44it/s]Train epoch: 4 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004915\n",
      "5425it [04:15, 15.12it/s]Train epoch: 4 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.005245\n",
      "5449it [04:16, 15.04it/s]Train epoch: 4 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.005253\n",
      "5475it [04:18, 15.07it/s]Train epoch: 4 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.006054\n",
      "5499it [04:20, 15.40it/s]Train epoch: 4 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.005556\n",
      "5525it [04:22, 14.55it/s]Train epoch: 4 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.004546\n",
      "5549it [04:23, 14.60it/s]Train epoch: 4 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.005199\n",
      "5575it [04:25, 14.85it/s]Train epoch: 4 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.005349\n",
      "5599it [04:27, 14.54it/s]Train epoch: 4 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.005709\n",
      "5625it [04:28, 14.58it/s]Train epoch: 4 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.005185\n",
      "5649it [04:30, 14.97it/s]Train epoch: 4 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004734\n",
      "5675it [04:32, 13.78it/s]Train epoch: 4 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.005864\n",
      "5699it [04:34, 13.22it/s]Train epoch: 4 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.005111\n",
      "5725it [04:36, 12.75it/s]Train epoch: 4 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.005228\n",
      "5749it [04:37, 14.05it/s]Train epoch: 4 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.006442\n",
      "5775it [04:39, 14.65it/s]Train epoch: 4 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.005563\n",
      "5799it [04:41, 14.25it/s]Train epoch: 4 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.005529\n",
      "5825it [04:43, 13.42it/s]Train epoch: 4 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004854\n",
      "5849it [04:44, 14.31it/s]Train epoch: 4 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.006189\n",
      "5875it [04:46, 14.08it/s]Train epoch: 4 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005921\n",
      "5899it [04:48, 14.25it/s]Train epoch: 4 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005984\n",
      "5925it [04:50, 14.27it/s]Train epoch: 4 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004801\n",
      "5949it [04:51, 14.40it/s]Train epoch: 4 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004846\n",
      "5975it [04:53, 14.29it/s]Train epoch: 4 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.006520\n",
      "5999it [04:55, 14.58it/s]Train epoch: 4 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.005613\n",
      "6025it [04:57, 14.32it/s]Train epoch: 4 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.005770\n",
      "6049it [04:58, 14.08it/s]Train epoch: 4 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.005194\n",
      "6075it [05:00, 13.70it/s]Train epoch: 4 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004962\n",
      "6099it [05:02, 14.71it/s]Train epoch: 4 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004731\n",
      "6125it [05:04, 14.09it/s]Train epoch: 4 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.005288\n",
      "6149it [05:05, 14.79it/s]Train epoch: 4 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.005148\n",
      "6175it [05:07, 14.31it/s]Train epoch: 4 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005908\n",
      "6199it [05:09, 14.31it/s]Train epoch: 4 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.005311\n",
      "6225it [05:11, 13.97it/s]Train epoch: 4 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.004634\n",
      "6249it [05:12, 14.06it/s]Train epoch: 4 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.005104\n",
      "6275it [05:14, 14.44it/s]Train epoch: 4 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.004679\n",
      "6299it [05:16, 13.82it/s]Train epoch: 4 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.005441\n",
      "6325it [05:18, 13.89it/s]Train epoch: 4 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005700\n",
      "6349it [05:20, 13.11it/s]Train epoch: 4 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005994\n",
      "6375it [05:22, 14.16it/s]Train epoch: 4 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004929\n",
      "6399it [05:23, 14.18it/s]Train epoch: 4 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.005066\n",
      "6425it [05:25, 12.76it/s]Train epoch: 4 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.005862\n",
      "6449it [05:27, 13.23it/s]Train epoch: 4 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.005642\n",
      "6475it [05:29, 14.18it/s]Train epoch: 4 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.005156\n",
      "6499it [05:31, 13.72it/s]Train epoch: 4 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.005864\n",
      "6525it [05:33, 13.21it/s]Train epoch: 4 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004974\n",
      "6549it [05:34, 13.83it/s]Train epoch: 4 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.005178\n",
      "6575it [05:36, 13.87it/s]Train epoch: 4 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.005412\n",
      "6599it [05:38, 13.43it/s]Train epoch: 4 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.006394\n",
      "6625it [05:40, 13.80it/s]Train epoch: 4 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.005213\n",
      "6649it [05:42, 13.15it/s]Train epoch: 4 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005985\n",
      "6675it [05:44, 13.19it/s]Train epoch: 4 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.005534\n",
      "6699it [05:45, 13.23it/s]Train epoch: 4 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.005555\n",
      "6725it [05:47, 13.01it/s]Train epoch: 4 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.005691\n",
      "6749it [05:49, 13.28it/s]Train epoch: 4 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.005197\n",
      "6775it [05:51, 12.71it/s]Train epoch: 4 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005912\n",
      "6799it [05:53, 13.06it/s]Train epoch: 4 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005787\n",
      "6825it [05:55, 13.84it/s]Train epoch: 4 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.006081\n",
      "6849it [05:57, 13.48it/s]Train epoch: 4 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005666\n",
      "6875it [05:59, 13.36it/s]Train epoch: 4 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004684\n",
      "6899it [06:01, 12.92it/s]Train epoch: 4 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.005568\n",
      "6925it [06:03, 13.47it/s]Train epoch: 4 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.005501\n",
      "6949it [06:04, 13.05it/s]Train epoch: 4 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.006150\n",
      "6975it [06:06, 12.66it/s]Train epoch: 4 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.005691\n",
      "6999it [06:08, 13.30it/s]Train epoch: 4 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.005445\n",
      "7025it [06:10, 12.99it/s]Train epoch: 4 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.006321\n",
      "7049it [06:12, 13.07it/s]Train epoch: 4 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.005016\n",
      "7075it [06:14, 12.77it/s]Train epoch: 4 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.005593\n",
      "7099it [06:16, 13.16it/s]Train epoch: 4 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005945\n",
      "7125it [06:18, 12.95it/s]Train epoch: 4 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.005091\n",
      "7149it [06:20, 13.13it/s]Train epoch: 4 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.006202\n",
      "7175it [06:22, 12.79it/s]Train epoch: 4 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.005714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7199it [06:24, 13.35it/s]Train epoch: 4 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.006010\n",
      "7225it [06:26, 12.89it/s]Train epoch: 4 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.005518\n",
      "7249it [06:28, 12.90it/s]Train epoch: 4 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.005645\n",
      "7275it [06:30, 12.43it/s]Train epoch: 4 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.006127\n",
      "7299it [06:31, 12.40it/s]Train epoch: 4 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.006581\n",
      "7325it [06:34, 13.03it/s]Train epoch: 4 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.005342\n",
      "7349it [06:35, 12.66it/s]Train epoch: 4 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.006399\n",
      "7375it [06:37, 12.80it/s]Train epoch: 4 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005916\n",
      "7399it [06:39, 12.77it/s]Train epoch: 4 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.005426\n",
      "7425it [06:41, 12.44it/s]Train epoch: 4 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005842\n",
      "7449it [06:43, 12.60it/s]Train epoch: 4 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.006581\n",
      "7475it [06:45, 12.38it/s]Train epoch: 4 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.005588\n",
      "7499it [06:47, 11.91it/s]Train epoch: 4 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005941\n",
      "7525it [06:49, 12.58it/s]Train epoch: 4 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.005728\n",
      "7549it [06:51, 12.47it/s]Train epoch: 4 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.005487\n",
      "7575it [06:53, 12.25it/s]Train epoch: 4 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.006106\n",
      "7599it [06:55, 12.40it/s]Train epoch: 4 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.007104\n",
      "7625it [06:58, 11.95it/s]Train epoch: 4 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.006581\n",
      "7649it [07:00, 12.53it/s]Train epoch: 4 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.005580\n",
      "7675it [07:02, 12.37it/s]Train epoch: 4 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.005877\n",
      "7699it [07:04, 12.43it/s]Train epoch: 4 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005831\n",
      "7725it [07:06, 12.49it/s]Train epoch: 4 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005832\n",
      "7749it [07:08, 12.27it/s]Train epoch: 4 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.006106\n",
      "7775it [07:10, 12.12it/s]Train epoch: 4 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.005507\n",
      "7799it [07:12, 12.28it/s]Train epoch: 4 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.005852\n",
      "7825it [07:14, 11.92it/s]Train epoch: 4 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005898\n",
      "7849it [07:16, 12.13it/s]Train epoch: 4 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.005407\n",
      "7875it [07:18, 12.03it/s]Train epoch: 4 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.005788\n",
      "7899it [07:20, 12.58it/s]Train epoch: 4 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.006016\n",
      "7925it [07:22, 11.90it/s]Train epoch: 4 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005963\n",
      "7949it [07:24, 11.94it/s]Train epoch: 4 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.006574\n",
      "7975it [07:26, 11.69it/s]Train epoch: 4 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.005874\n",
      "7999it [07:29, 11.51it/s]Train epoch: 4 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.005608\n",
      "8025it [07:31, 11.62it/s]Train epoch: 4 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.006137\n",
      "8049it [07:33, 11.77it/s]Train epoch: 4 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.005441\n",
      "8075it [07:35, 11.97it/s]Train epoch: 4 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005948\n",
      "8099it [07:37, 11.55it/s]Train epoch: 4 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.006256\n",
      "8125it [07:39, 11.55it/s]Train epoch: 4 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.006356\n",
      "8149it [07:41, 10.92it/s]Train epoch: 4 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.005586\n",
      "8175it [07:44, 11.76it/s]Train epoch: 4 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.006391\n",
      "8199it [07:46, 11.31it/s]Train epoch: 4 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.005637\n",
      "8225it [07:48, 11.48it/s]Train epoch: 4 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.007135\n",
      "8249it [07:50, 11.50it/s]Train epoch: 4 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.005727\n",
      "8275it [07:52, 11.32it/s]Train epoch: 4 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.006497\n",
      "8299it [07:55, 11.71it/s]Train epoch: 4 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.005679\n",
      "8325it [07:57, 11.42it/s]Train epoch: 4 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.006396\n",
      "8349it [07:59, 11.17it/s]Train epoch: 4 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.005597\n",
      "8375it [08:01, 11.12it/s]Train epoch: 4 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.006319\n",
      "8399it [08:03, 11.55it/s]Train epoch: 4 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005832\n",
      "8425it [08:06, 11.36it/s]Train epoch: 4 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.006014\n",
      "8449it [08:08, 11.17it/s]Train epoch: 4 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.006299\n",
      "8475it [08:10, 11.15it/s]Train epoch: 4 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005987\n",
      "8499it [08:12, 11.16it/s]Train epoch: 4 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.007017\n",
      "8525it [08:15, 11.56it/s]Train epoch: 4 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005980\n",
      "8549it [08:17, 11.00it/s]Train epoch: 4 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.006374\n",
      "8575it [08:19, 11.23it/s]Train epoch: 4 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005990\n",
      "8599it [08:21, 11.22it/s]Train epoch: 4 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.006034\n",
      "8625it [08:23, 11.29it/s]Train epoch: 4 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.006156\n",
      "8649it [08:26, 11.11it/s]Train epoch: 4 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.006373\n",
      "8675it [08:28, 11.05it/s]Train epoch: 4 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.007026\n",
      "8699it [08:30, 11.40it/s]Train epoch: 4 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.007041\n",
      "8725it [08:32, 10.92it/s]Train epoch: 4 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.006761\n",
      "8749it [08:35, 11.20it/s]Train epoch: 4 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.006526\n",
      "8775it [08:37, 10.57it/s]Train epoch: 4 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005834\n",
      "8799it [08:39, 11.13it/s]Train epoch: 4 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.006175\n",
      "8825it [08:42, 10.86it/s]Train epoch: 4 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.006218\n",
      "8849it [08:44, 10.86it/s]Train epoch: 4 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.006490\n",
      "8875it [08:46, 10.67it/s]Train epoch: 4 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.006272\n",
      "8899it [08:49, 10.86it/s]Train epoch: 4 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.006278\n",
      "8925it [08:51, 10.70it/s]Train epoch: 4 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.006500\n",
      "8949it [08:53, 10.50it/s]Train epoch: 4 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.007172\n",
      "8975it [08:56, 10.70it/s]Train epoch: 4 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.006803\n",
      "8999it [08:58, 10.79it/s]Train epoch: 4 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.006169\n",
      "9025it [09:00, 10.47it/s]Train epoch: 4 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.006376\n",
      "9049it [09:03, 10.50it/s]Train epoch: 4 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005992\n",
      "9075it [09:05, 10.65it/s]Train epoch: 4 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.005519\n",
      "9099it [09:07, 10.81it/s]Train epoch: 4 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.006509\n",
      "9125it [09:10, 10.48it/s]Train epoch: 4 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.006151\n",
      "9149it [09:12, 10.60it/s]Train epoch: 4 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.005717\n",
      "9175it [09:15, 10.35it/s]Train epoch: 4 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.006128\n",
      "9199it [09:17, 10.44it/s]Train epoch: 4 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.006100\n",
      "9225it [09:19, 10.18it/s]Train epoch: 4 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.007226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9249it [09:22, 10.41it/s]Train epoch: 4 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.006205\n",
      "9275it [09:24, 10.13it/s]Train epoch: 4 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.006752\n",
      "9299it [09:27, 10.04it/s]Train epoch: 4 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.007432\n",
      "9325it [09:29, 10.17it/s]Train epoch: 4 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.007251\n",
      "9349it [09:32, 10.32it/s]Train epoch: 4 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.007065\n",
      "9375it [09:34, 10.26it/s]Train epoch: 4 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.006315\n",
      "9399it [09:36, 10.26it/s]Train epoch: 4 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.006585\n",
      "9425it [09:39, 10.11it/s]Train epoch: 4 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.006226\n",
      "9450it [09:41, 10.05it/s]Train epoch: 4 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.006173\n",
      "9474it [09:44, 10.10it/s]Train epoch: 4 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.007091\n",
      "9499it [09:46, 10.08it/s]Train epoch: 4 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.006554\n",
      "9525it [09:49,  9.62it/s]Train epoch: 4 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.007001\n",
      "9550it [09:51, 10.03it/s]Train epoch: 4 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006951\n",
      "9575it [09:54,  9.88it/s]Train epoch: 4 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006869\n",
      "9599it [09:56,  9.99it/s]Train epoch: 4 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.006639\n",
      "9625it [09:59,  9.95it/s]Train epoch: 4 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.006180\n",
      "9650it [10:02,  9.95it/s]Train epoch: 4 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.006274\n",
      "9675it [10:04,  9.98it/s]Train epoch: 4 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.006688\n",
      "9699it [10:07,  9.83it/s]Train epoch: 4 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.006026\n",
      "9724it [10:09,  9.70it/s]Train epoch: 4 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.006864\n",
      "9750it [10:12,  9.47it/s]Train epoch: 4 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.006522\n",
      "9775it [10:14,  9.54it/s]Train epoch: 4 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.007440\n",
      "9800it [10:17,  9.58it/s]Train epoch: 4 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.007172\n",
      "9825it [10:19,  9.35it/s]Train epoch: 4 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.007238\n",
      "9850it [10:22,  9.41it/s]Train epoch: 4 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.006655\n",
      "9875it [10:25,  9.46it/s]Train epoch: 4 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.007257\n",
      "9900it [10:27,  9.13it/s]Train epoch: 4 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.007722\n",
      "9925it [10:30,  9.41it/s]Train epoch: 4 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.007090\n",
      "9950it [10:33,  9.18it/s]Train epoch: 4 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.007808\n",
      "9975it [10:36,  9.24it/s]Train epoch: 4 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.007203\n",
      "9999it [10:38,  9.27it/s]Train epoch: 4 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.006798\n",
      "10025it [10:41,  9.33it/s]Train epoch: 4 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.006797\n",
      "10050it [10:44,  9.00it/s]Train epoch: 4 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.007391\n",
      "10075it [10:46,  9.08it/s]Train epoch: 4 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.007722\n",
      "10100it [10:49,  9.14it/s]Train epoch: 4 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.007232\n",
      "10125it [10:52,  8.71it/s]Train epoch: 4 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.006666\n",
      "10150it [10:55,  8.99it/s]Train epoch: 4 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.007253\n",
      "10175it [10:57,  9.07it/s]Train epoch: 4 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.006768\n",
      "10200it [11:00,  9.00it/s]Train epoch: 4 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.007287\n",
      "10225it [11:03,  8.93it/s]Train epoch: 4 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.007302\n",
      "10250it [11:06,  8.90it/s]Train epoch: 4 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.007731\n",
      "10275it [11:09,  8.93it/s]Train epoch: 4 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006844\n",
      "10300it [11:11,  8.82it/s]Train epoch: 4 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.007581\n",
      "10325it [11:14,  8.67it/s]Train epoch: 4 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.007379\n",
      "10350it [11:17,  8.91it/s]Train epoch: 4 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.007180\n",
      "10375it [11:20,  8.75it/s]Train epoch: 4 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.007465\n",
      "10400it [11:23,  8.52it/s]Train epoch: 4 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.007565\n",
      "10425it [11:26,  8.63it/s]Train epoch: 4 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.007139\n",
      "10450it [11:29,  8.78it/s]Train epoch: 4 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.007472\n",
      "10475it [11:32,  8.39it/s]Train epoch: 4 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.006549\n",
      "10500it [11:35,  8.34it/s]Train epoch: 4 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.007483\n",
      "10525it [11:38,  8.25it/s]Train epoch: 4 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.007122\n",
      "10550it [11:41,  8.44it/s]Train epoch: 4 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.007477\n",
      "10575it [11:44,  8.24it/s]Train epoch: 4 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.006648\n",
      "10600it [11:47,  8.27it/s]Train epoch: 4 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.006856\n",
      "10625it [11:50,  8.09it/s]Train epoch: 4 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.007454\n",
      "10650it [11:53,  8.03it/s]Train epoch: 4 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.007001\n",
      "10675it [11:56,  8.25it/s]Train epoch: 4 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.007516\n",
      "10700it [11:59,  7.90it/s]Train epoch: 4 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.007002\n",
      "10725it [12:02,  8.09it/s]Train epoch: 4 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.006484\n",
      "10750it [12:05,  7.79it/s]Train epoch: 4 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.007743\n",
      "10775it [12:09,  7.86it/s]Train epoch: 4 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.007784\n",
      "10800it [12:12,  7.77it/s]Train epoch: 4 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.007971\n",
      "10825it [12:15,  7.74it/s]Train epoch: 4 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.007876\n",
      "10850it [12:18,  7.80it/s]Train epoch: 4 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.007662\n",
      "10875it [12:21,  7.82it/s]Train epoch: 4 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.007862\n",
      "10900it [12:25,  7.84it/s]Train epoch: 4 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.007497\n",
      "10925it [12:28,  7.84it/s]Train epoch: 4 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006959\n",
      "10950it [12:31,  7.62it/s]Train epoch: 4 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.007513\n",
      "10975it [12:34,  7.79it/s]Train epoch: 4 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.007366\n",
      "11000it [12:38,  7.62it/s]Train epoch: 4 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.007236\n",
      "11025it [12:41,  7.76it/s]Train epoch: 4 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.007407\n",
      "11050it [12:44,  7.77it/s]Train epoch: 4 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.008248\n",
      "11075it [12:47,  7.87it/s]Train epoch: 4 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.007723\n",
      "11100it [12:50,  7.75it/s]Train epoch: 4 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.008528\n",
      "11125it [12:54,  7.85it/s]Train epoch: 4 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007911\n",
      "11150it [12:57,  7.68it/s]Train epoch: 4 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.007636\n",
      "11175it [13:00,  7.55it/s]Train epoch: 4 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.008846\n",
      "11200it [13:03,  7.76it/s]Train epoch: 4 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.008025\n",
      "11225it [13:07,  7.79it/s]Train epoch: 4 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007872\n",
      "11250it [13:10,  7.84it/s]Train epoch: 4 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.008592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11275it [13:13,  7.67it/s]Train epoch: 4 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.008314\n",
      "11300it [13:16,  7.75it/s]Train epoch: 4 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.007501\n",
      "11325it [13:19,  7.85it/s]Train epoch: 4 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.008759\n",
      "11350it [13:23,  7.77it/s]Train epoch: 4 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.008844\n",
      "11375it [13:26,  7.69it/s]Train epoch: 4 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.009066\n",
      "11400it [13:29,  8.08it/s]Train epoch: 4 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007942\n",
      "11425it [13:32,  7.75it/s]Train epoch: 4 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.008508\n",
      "11450it [13:35,  7.67it/s]Train epoch: 4 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.007765\n",
      "11475it [13:39,  7.70it/s]Train epoch: 4 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.009354\n",
      "11500it [13:42,  7.80it/s]Train epoch: 4 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.008869\n",
      "11525it [13:45,  7.68it/s]Train epoch: 4 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.008166\n",
      "11550it [13:48,  7.70it/s]Train epoch: 4 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.008196\n",
      "11575it [13:52,  7.95it/s]Train epoch: 4 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.009285\n",
      "11600it [13:55,  7.57it/s]Train epoch: 4 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.008600\n",
      "11625it [13:58,  7.88it/s]Train epoch: 4 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.008016\n",
      "11650it [14:01,  7.60it/s]Train epoch: 4 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.008747\n",
      "11675it [14:04,  7.76it/s]Train epoch: 4 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.009296\n",
      "11700it [14:08,  7.78it/s]Train epoch: 4 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.009611\n",
      "11725it [14:11,  7.70it/s]Train epoch: 4 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.009630\n",
      "11750it [14:14,  7.58it/s]Train epoch: 4 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.009390\n",
      "11775it [14:17,  7.65it/s]Train epoch: 4 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.009332\n",
      "11800it [14:21,  7.84it/s]Train epoch: 4 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.009182\n",
      "11825it [14:24,  7.86it/s]Train epoch: 4 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.009501\n",
      "11850it [14:27,  7.70it/s]Train epoch: 4 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.009479\n",
      "11875it [14:30,  7.76it/s]Train epoch: 4 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.010572\n",
      "11900it [14:34,  7.87it/s]Train epoch: 4 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.012662\n",
      "11925it [14:37,  7.49it/s]Train epoch: 4 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010661\n",
      "11930it [14:38, 13.59it/s]\n",
      "epoch loss: 0.0056357876133612435\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 126.12it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0151, 0.0249, 0.0234, 0.0241, 0.8586\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2823, 0.5634, 0.3614, 0.4404, 0.9778\n",
      "rec_at_8: 0.3215\n",
      "prec_at_8: 0.6009\n",
      "rec_at_15: 0.4429\n",
      "prec_at_15: 0.4607\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 128.40it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0150, 0.0269, 0.0233, 0.0250, 0.8503\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2760, 0.5616, 0.3517, 0.4326, 0.9774\n",
      "rec_at_8: 0.3069\n",
      "prec_at_8: 0.5986\n",
      "rec_at_15: 0.4247\n",
      "prec_at_15: 0.4595\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0151, 0.0249, 0.0234, 0.0241, 0.8586\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2823, 0.5634, 0.3614, 0.4404, 0.9778\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0073\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0150, 0.0269, 0.0233, 0.0250, 0.8503\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2760, 0.5616, 0.3517, 0.4326, 0.9774\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 5\n",
      "0it [00:00, ?it/s]Train epoch: 5 [batch #0, batch_size 4, seq length 68]\tLoss: 0.007128\n",
      "24it [00:00, 50.98it/s]Train epoch: 5 [batch #25, batch_size 4, seq length 221]\tLoss: 0.004336\n",
      "49it [00:01, 46.31it/s]Train epoch: 5 [batch #50, batch_size 4, seq length 270]\tLoss: 0.004152\n",
      "75it [00:01, 44.52it/s]Train epoch: 5 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003548\n",
      "100it [00:02, 38.68it/s]Train epoch: 5 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003552\n",
      "125it [00:02, 39.66it/s]Train epoch: 5 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003489\n",
      "146it [00:03, 34.99it/s]Train epoch: 5 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003339\n",
      "172it [00:04, 36.13it/s]Train epoch: 5 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003525\n",
      "197it [00:04, 36.64it/s]Train epoch: 5 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003381\n",
      "225it [00:05, 34.39it/s]Train epoch: 5 [batch #225, batch_size 4, seq length 414]\tLoss: 0.004259\n",
      "249it [00:06, 34.42it/s]Train epoch: 5 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003559\n",
      "274it [00:07, 34.59it/s]Train epoch: 5 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002990\n",
      "298it [00:07, 33.71it/s]Train epoch: 5 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003884\n",
      "322it [00:08, 32.01it/s]Train epoch: 5 [batch #325, batch_size 4, seq length 463]\tLoss: 0.003245\n",
      "350it [00:09, 31.41it/s]Train epoch: 5 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003806\n",
      "374it [00:10, 32.66it/s]Train epoch: 5 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003570\n",
      "398it [00:11, 31.80it/s]Train epoch: 5 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003698\n",
      "422it [00:11, 31.42it/s]Train epoch: 5 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003612\n",
      "449it [00:12, 28.35it/s]Train epoch: 5 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003596\n",
      "475it [00:13, 30.83it/s]Train epoch: 5 [batch #475, batch_size 4, seq length 512]\tLoss: 0.004082\n",
      "498it [00:14, 29.30it/s]Train epoch: 5 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003435\n",
      "524it [00:15, 30.42it/s]Train epoch: 5 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003835\n",
      "547it [00:15, 29.75it/s]Train epoch: 5 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003711\n",
      "575it [00:16, 29.56it/s]Train epoch: 5 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003674\n",
      "598it [00:17, 30.32it/s]Train epoch: 5 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003953\n",
      "623it [00:18, 29.18it/s]Train epoch: 5 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003754\n",
      "650it [00:19, 29.35it/s]Train epoch: 5 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003416\n",
      "672it [00:20, 30.35it/s]Train epoch: 5 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002881\n",
      "700it [00:21, 31.98it/s]Train epoch: 5 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003556\n",
      "723it [00:21, 28.74it/s]Train epoch: 5 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003848\n",
      "750it [00:22, 27.05it/s]Train epoch: 5 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003521\n",
      "775it [00:23, 26.46it/s]Train epoch: 5 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003966\n",
      "799it [00:24, 27.65it/s]Train epoch: 5 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003824\n",
      "823it [00:25, 29.16it/s]Train epoch: 5 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003659\n",
      "850it [00:26, 27.19it/s]Train epoch: 5 [batch #850, batch_size 4, seq length 606]\tLoss: 0.004155\n",
      "873it [00:27, 28.49it/s]Train epoch: 5 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003513\n",
      "898it [00:28, 27.72it/s]Train epoch: 5 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003762\n",
      "925it [00:28, 29.57it/s]Train epoch: 5 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003595\n",
      "949it [00:29, 27.00it/s]Train epoch: 5 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003539\n",
      "974it [00:30, 26.69it/s]Train epoch: 5 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999it [00:31, 28.65it/s]Train epoch: 5 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003627\n",
      "1024it [00:32, 27.53it/s]Train epoch: 5 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004899\n",
      "1048it [00:33, 27.27it/s]Train epoch: 5 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003482\n",
      "1073it [00:34, 27.69it/s]Train epoch: 5 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003917\n",
      "1100it [00:35, 26.96it/s]Train epoch: 5 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003981\n",
      "1125it [00:36, 27.16it/s]Train epoch: 5 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.004021\n",
      "1149it [00:37, 26.15it/s]Train epoch: 5 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.004062\n",
      "1173it [00:38, 26.26it/s]Train epoch: 5 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003962\n",
      "1198it [00:39, 26.80it/s]Train epoch: 5 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.004074\n",
      "1225it [00:40, 26.36it/s]Train epoch: 5 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.004291\n",
      "1247it [00:40, 25.38it/s]Train epoch: 5 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003972\n",
      "1273it [00:41, 26.27it/s]Train epoch: 5 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003451\n",
      "1300it [00:42, 26.56it/s]Train epoch: 5 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003497\n",
      "1324it [00:43, 26.88it/s]Train epoch: 5 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003529\n",
      "1348it [00:44, 26.43it/s]Train epoch: 5 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004611\n",
      "1375it [00:45, 26.52it/s]Train epoch: 5 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003868\n",
      "1399it [00:46, 26.33it/s]Train epoch: 5 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003699\n",
      "1423it [00:47, 26.28it/s]Train epoch: 5 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003431\n",
      "1448it [00:48, 27.40it/s]Train epoch: 5 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003630\n",
      "1475it [00:49, 26.79it/s]Train epoch: 5 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003858\n",
      "1499it [00:50, 26.39it/s]Train epoch: 5 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.005006\n",
      "1523it [00:51, 26.40it/s]Train epoch: 5 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004774\n",
      "1550it [00:52, 25.04it/s]Train epoch: 5 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003703\n",
      "1574it [00:53, 24.87it/s]Train epoch: 5 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.004051\n",
      "1598it [00:54, 25.09it/s]Train epoch: 5 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003579\n",
      "1625it [00:55, 25.09it/s]Train epoch: 5 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.004265\n",
      "1649it [00:56, 26.31it/s]Train epoch: 5 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.004391\n",
      "1673it [00:57, 25.35it/s]Train epoch: 5 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.004097\n",
      "1700it [00:58, 24.15it/s]Train epoch: 5 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003660\n",
      "1724it [00:59, 25.25it/s]Train epoch: 5 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.003218\n",
      "1748it [01:00, 23.36it/s]Train epoch: 5 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004744\n",
      "1775it [01:01, 23.71it/s]Train epoch: 5 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003903\n",
      "1799it [01:02, 24.76it/s]Train epoch: 5 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003940\n",
      "1823it [01:03, 24.84it/s]Train epoch: 5 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.003347\n",
      "1850it [01:04, 24.62it/s]Train epoch: 5 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.004010\n",
      "1874it [01:05, 23.54it/s]Train epoch: 5 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.004371\n",
      "1898it [01:06, 24.64it/s]Train epoch: 5 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.003336\n",
      "1925it [01:07, 23.91it/s]Train epoch: 5 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003495\n",
      "1949it [01:08, 24.47it/s]Train epoch: 5 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003467\n",
      "1973it [01:09, 23.33it/s]Train epoch: 5 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.004135\n",
      "2000it [01:10, 23.97it/s]Train epoch: 5 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.003289\n",
      "2024it [01:11, 24.27it/s]Train epoch: 5 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.004098\n",
      "2048it [01:12, 23.33it/s]Train epoch: 5 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003759\n",
      "2073it [01:13, 25.96it/s]Train epoch: 5 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003884\n",
      "2100it [01:14, 24.85it/s]Train epoch: 5 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.004148\n",
      "2124it [01:15, 23.77it/s]Train epoch: 5 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.004344\n",
      "2148it [01:16, 24.53it/s]Train epoch: 5 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003671\n",
      "2175it [01:17, 23.94it/s]Train epoch: 5 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.004268\n",
      "2199it [01:18, 23.95it/s]Train epoch: 5 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.004060\n",
      "2223it [01:19, 24.06it/s]Train epoch: 5 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003807\n",
      "2250it [01:21, 21.60it/s]Train epoch: 5 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003627\n",
      "2274it [01:22, 25.04it/s]Train epoch: 5 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.004036\n",
      "2298it [01:23, 24.22it/s]Train epoch: 5 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.003100\n",
      "2325it [01:24, 22.59it/s]Train epoch: 5 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003898\n",
      "2349it [01:25, 23.46it/s]Train epoch: 5 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003580\n",
      "2373it [01:26, 22.44it/s]Train epoch: 5 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.005157\n",
      "2400it [01:27, 21.35it/s]Train epoch: 5 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004755\n",
      "2424it [01:28, 24.12it/s]Train epoch: 5 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.003431\n",
      "2448it [01:29, 24.25it/s]Train epoch: 5 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003941\n",
      "2475it [01:30, 22.31it/s]Train epoch: 5 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.004391\n",
      "2499it [01:31, 22.76it/s]Train epoch: 5 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003812\n",
      "2523it [01:32, 22.25it/s]Train epoch: 5 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003721\n",
      "2550it [01:34, 22.39it/s]Train epoch: 5 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.005106\n",
      "2574it [01:35, 22.08it/s]Train epoch: 5 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003638\n",
      "2598it [01:36, 21.75it/s]Train epoch: 5 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003952\n",
      "2625it [01:37, 21.75it/s]Train epoch: 5 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003937\n",
      "2649it [01:38, 22.83it/s]Train epoch: 5 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004572\n",
      "2673it [01:39, 23.13it/s]Train epoch: 5 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.004184\n",
      "2700it [01:40, 22.29it/s]Train epoch: 5 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003593\n",
      "2724it [01:41, 22.11it/s]Train epoch: 5 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003916\n",
      "2748it [01:42, 21.77it/s]Train epoch: 5 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004574\n",
      "2775it [01:44, 22.04it/s]Train epoch: 5 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003984\n",
      "2799it [01:45, 21.11it/s]Train epoch: 5 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003878\n",
      "2823it [01:46, 22.46it/s]Train epoch: 5 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.004215\n",
      "2850it [01:47, 22.53it/s]Train epoch: 5 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.004006\n",
      "2874it [01:48, 23.18it/s]Train epoch: 5 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.004342\n",
      "2898it [01:49, 21.43it/s]Train epoch: 5 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.004326\n",
      "2925it [01:51, 21.09it/s]Train epoch: 5 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.004355\n",
      "2949it [01:52, 21.11it/s]Train epoch: 5 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004533\n",
      "2973it [01:53, 22.57it/s]Train epoch: 5 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.004249\n",
      "3000it [01:54, 22.23it/s]Train epoch: 5 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004805\n",
      "3024it [01:55, 20.08it/s]Train epoch: 5 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.004469\n",
      "3048it [01:56, 21.08it/s]Train epoch: 5 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075it [01:58, 22.88it/s]Train epoch: 5 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.004429\n",
      "3099it [01:59, 21.15it/s]Train epoch: 5 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.004540\n",
      "3123it [02:00, 22.31it/s]Train epoch: 5 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.004031\n",
      "3150it [02:01, 20.93it/s]Train epoch: 5 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003978\n",
      "3174it [02:02, 19.91it/s]Train epoch: 5 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003979\n",
      "3200it [02:04, 20.87it/s]Train epoch: 5 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004603\n",
      "3224it [02:05, 21.84it/s]Train epoch: 5 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004444\n",
      "3248it [02:06, 20.69it/s]Train epoch: 5 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004513\n",
      "3275it [02:07, 21.08it/s]Train epoch: 5 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.004109\n",
      "3299it [02:08, 20.60it/s]Train epoch: 5 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.005005\n",
      "3323it [02:09, 20.93it/s]Train epoch: 5 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.004312\n",
      "3350it [02:11, 20.90it/s]Train epoch: 5 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.004340\n",
      "3374it [02:12, 21.52it/s]Train epoch: 5 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.004508\n",
      "3398it [02:13, 21.15it/s]Train epoch: 5 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004606\n",
      "3425it [02:14, 19.96it/s]Train epoch: 5 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.004032\n",
      "3449it [02:15, 21.36it/s]Train epoch: 5 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004723\n",
      "3473it [02:17, 20.91it/s]Train epoch: 5 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.004272\n",
      "3500it [02:18, 20.56it/s]Train epoch: 5 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.004227\n",
      "3525it [02:19, 20.15it/s]Train epoch: 5 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.004524\n",
      "3548it [02:20, 21.10it/s]Train epoch: 5 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004852\n",
      "3575it [02:22, 20.52it/s]Train epoch: 5 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003835\n",
      "3600it [02:23, 19.38it/s]Train epoch: 5 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004940\n",
      "3624it [02:24, 20.11it/s]Train epoch: 5 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.004544\n",
      "3650it [02:25, 19.61it/s]Train epoch: 5 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004625\n",
      "3674it [02:27, 18.53it/s]Train epoch: 5 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004731\n",
      "3700it [02:28, 17.65it/s]Train epoch: 5 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004680\n",
      "3724it [02:29, 17.82it/s]Train epoch: 5 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004754\n",
      "3750it [02:31, 17.96it/s]Train epoch: 5 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004855\n",
      "3774it [02:32, 16.88it/s]Train epoch: 5 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004643\n",
      "3800it [02:34, 17.52it/s]Train epoch: 5 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.005091\n",
      "3825it [02:35, 17.91it/s]Train epoch: 5 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.004358\n",
      "3849it [02:37, 17.27it/s]Train epoch: 5 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.004167\n",
      "3875it [02:38, 16.91it/s]Train epoch: 5 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003938\n",
      "3899it [02:39, 18.08it/s]Train epoch: 5 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.005123\n",
      "3925it [02:41, 16.68it/s]Train epoch: 5 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004580\n",
      "3949it [02:42, 17.10it/s]Train epoch: 5 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.005002\n",
      "3974it [02:44, 16.41it/s]Train epoch: 5 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.005551\n",
      "4000it [02:45, 16.33it/s]Train epoch: 5 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.004208\n",
      "4024it [02:47, 16.71it/s]Train epoch: 5 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.005209\n",
      "4050it [02:48, 17.70it/s]Train epoch: 5 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004774\n",
      "4075it [02:50, 17.47it/s]Train epoch: 5 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004762\n",
      "4099it [02:51, 17.12it/s]Train epoch: 5 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.005243\n",
      "4125it [02:53, 16.88it/s]Train epoch: 5 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.005077\n",
      "4149it [02:54, 16.85it/s]Train epoch: 5 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.004307\n",
      "4175it [02:56, 17.06it/s]Train epoch: 5 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004653\n",
      "4199it [02:57, 17.02it/s]Train epoch: 5 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.005058\n",
      "4225it [02:59, 16.87it/s]Train epoch: 5 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.004370\n",
      "4249it [03:00, 16.78it/s]Train epoch: 5 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004913\n",
      "4275it [03:02, 16.47it/s]Train epoch: 5 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004658\n",
      "4299it [03:03, 17.08it/s]Train epoch: 5 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.005261\n",
      "4325it [03:05, 16.01it/s]Train epoch: 5 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004653\n",
      "4349it [03:06, 17.14it/s]Train epoch: 5 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.005115\n",
      "4375it [03:07, 17.07it/s]Train epoch: 5 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004586\n",
      "4399it [03:09, 16.81it/s]Train epoch: 5 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.004011\n",
      "4425it [03:11, 15.99it/s]Train epoch: 5 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004894\n",
      "4449it [03:12, 16.51it/s]Train epoch: 5 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003870\n",
      "4475it [03:14, 16.82it/s]Train epoch: 5 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004881\n",
      "4499it [03:15, 16.71it/s]Train epoch: 5 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005812\n",
      "4525it [03:17, 16.09it/s]Train epoch: 5 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004985\n",
      "4549it [03:18, 16.13it/s]Train epoch: 5 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004677\n",
      "4575it [03:20, 16.27it/s]Train epoch: 5 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.005392\n",
      "4599it [03:21, 16.02it/s]Train epoch: 5 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004420\n",
      "4625it [03:23, 15.68it/s]Train epoch: 5 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004528\n",
      "4649it [03:24, 15.47it/s]Train epoch: 5 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.005265\n",
      "4675it [03:26, 15.99it/s]Train epoch: 5 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004865\n",
      "4699it [03:28, 15.61it/s]Train epoch: 5 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.004442\n",
      "4725it [03:29, 15.66it/s]Train epoch: 5 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004656\n",
      "4749it [03:31, 15.14it/s]Train epoch: 5 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.005436\n",
      "4775it [03:32, 14.81it/s]Train epoch: 5 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004790\n",
      "4799it [03:34, 15.75it/s]Train epoch: 5 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.005019\n",
      "4825it [03:36, 16.07it/s]Train epoch: 5 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.004474\n",
      "4849it [03:37, 15.57it/s]Train epoch: 5 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.005140\n",
      "4875it [03:39, 15.67it/s]Train epoch: 5 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.004406\n",
      "4899it [03:40, 15.39it/s]Train epoch: 5 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004943\n",
      "4925it [03:42, 15.16it/s]Train epoch: 5 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.004445\n",
      "4949it [03:44, 15.29it/s]Train epoch: 5 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004793\n",
      "4975it [03:45, 15.09it/s]Train epoch: 5 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004765\n",
      "4999it [03:47, 14.90it/s]Train epoch: 5 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004860\n",
      "5025it [03:49, 16.06it/s]Train epoch: 5 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004526\n",
      "5049it [03:50, 14.94it/s]Train epoch: 5 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004479\n",
      "5075it [03:52, 15.02it/s]Train epoch: 5 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004722\n",
      "5099it [03:54, 15.35it/s]Train epoch: 5 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125it [03:55, 15.13it/s]Train epoch: 5 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.005101\n",
      "5149it [03:57, 14.83it/s]Train epoch: 5 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.005092\n",
      "5175it [03:59, 15.61it/s]Train epoch: 5 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.005041\n",
      "5199it [04:00, 15.32it/s]Train epoch: 5 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004512\n",
      "5225it [04:02, 14.81it/s]Train epoch: 5 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004916\n",
      "5249it [04:04, 15.39it/s]Train epoch: 5 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004745\n",
      "5275it [04:05, 14.83it/s]Train epoch: 5 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004677\n",
      "5299it [04:07, 14.67it/s]Train epoch: 5 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004505\n",
      "5325it [04:09, 14.69it/s]Train epoch: 5 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.005173\n",
      "5349it [04:10, 14.90it/s]Train epoch: 5 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.005234\n",
      "5375it [04:12, 14.38it/s]Train epoch: 5 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004672\n",
      "5399it [04:14, 15.00it/s]Train epoch: 5 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004654\n",
      "5425it [04:15, 14.81it/s]Train epoch: 5 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.005064\n",
      "5449it [04:17, 14.31it/s]Train epoch: 5 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.005050\n",
      "5475it [04:19, 14.31it/s]Train epoch: 5 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005790\n",
      "5499it [04:20, 14.64it/s]Train epoch: 5 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.005370\n",
      "5525it [04:22, 14.82it/s]Train epoch: 5 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.004374\n",
      "5549it [04:24, 15.21it/s]Train epoch: 5 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004998\n",
      "5575it [04:26, 14.99it/s]Train epoch: 5 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.005097\n",
      "5599it [04:27, 14.19it/s]Train epoch: 5 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.005438\n",
      "5625it [04:29, 14.92it/s]Train epoch: 5 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004966\n",
      "5649it [04:31, 15.05it/s]Train epoch: 5 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004585\n",
      "5675it [04:32, 14.66it/s]Train epoch: 5 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.005599\n",
      "5699it [04:34, 14.05it/s]Train epoch: 5 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004907\n",
      "5725it [04:36, 14.77it/s]Train epoch: 5 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.005057\n",
      "5749it [04:37, 14.35it/s]Train epoch: 5 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.006205\n",
      "5775it [04:39, 14.77it/s]Train epoch: 5 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.005304\n",
      "5799it [04:41, 14.69it/s]Train epoch: 5 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.005320\n",
      "5825it [04:43, 14.61it/s]Train epoch: 5 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004683\n",
      "5849it [04:44, 13.60it/s]Train epoch: 5 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005972\n",
      "5875it [04:46, 14.36it/s]Train epoch: 5 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005697\n",
      "5899it [04:48, 14.56it/s]Train epoch: 5 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005807\n",
      "5925it [04:50, 14.02it/s]Train epoch: 5 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004640\n",
      "5949it [04:51, 15.25it/s]Train epoch: 5 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004612\n",
      "5975it [04:53, 14.09it/s]Train epoch: 5 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.006319\n",
      "5999it [04:55, 14.24it/s]Train epoch: 5 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.005396\n",
      "6025it [04:57, 14.21it/s]Train epoch: 5 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.005573\n",
      "6049it [04:58, 14.42it/s]Train epoch: 5 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.005051\n",
      "6075it [05:00, 13.91it/s]Train epoch: 5 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004774\n",
      "6099it [05:02, 14.43it/s]Train epoch: 5 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004510\n",
      "6125it [05:04, 14.13it/s]Train epoch: 5 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.005055\n",
      "6149it [05:05, 13.58it/s]Train epoch: 5 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004985\n",
      "6175it [05:07, 13.70it/s]Train epoch: 5 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005697\n",
      "6199it [05:09, 14.20it/s]Train epoch: 5 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.005123\n",
      "6225it [05:11, 13.56it/s]Train epoch: 5 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.004404\n",
      "6249it [05:13, 14.21it/s]Train epoch: 5 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004875\n",
      "6275it [05:14, 14.39it/s]Train epoch: 5 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.004443\n",
      "6299it [05:16, 13.96it/s]Train epoch: 5 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.005199\n",
      "6325it [05:18, 13.79it/s]Train epoch: 5 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005488\n",
      "6349it [05:20, 13.38it/s]Train epoch: 5 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005825\n",
      "6375it [05:22, 13.43it/s]Train epoch: 5 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004722\n",
      "6399it [05:23, 13.72it/s]Train epoch: 5 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004860\n",
      "6425it [05:25, 13.46it/s]Train epoch: 5 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.005632\n",
      "6449it [05:27, 13.72it/s]Train epoch: 5 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.005399\n",
      "6475it [05:29, 13.61it/s]Train epoch: 5 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004958\n",
      "6499it [05:31, 13.49it/s]Train epoch: 5 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.005643\n",
      "6525it [05:33, 13.40it/s]Train epoch: 5 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004814\n",
      "6549it [05:34, 13.26it/s]Train epoch: 5 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004937\n",
      "6575it [05:36, 12.95it/s]Train epoch: 5 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.005201\n",
      "6599it [05:38, 13.33it/s]Train epoch: 5 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.006180\n",
      "6625it [05:40, 13.35it/s]Train epoch: 5 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.005013\n",
      "6649it [05:42, 13.23it/s]Train epoch: 5 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005755\n",
      "6675it [05:44, 13.06it/s]Train epoch: 5 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.005395\n",
      "6699it [05:46, 13.13it/s]Train epoch: 5 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.005340\n",
      "6725it [05:48, 13.48it/s]Train epoch: 5 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.005499\n",
      "6749it [05:49, 13.15it/s]Train epoch: 5 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004908\n",
      "6775it [05:51, 13.65it/s]Train epoch: 5 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005651\n",
      "6799it [05:53, 12.82it/s]Train epoch: 5 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005589\n",
      "6825it [05:55, 12.73it/s]Train epoch: 5 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005852\n",
      "6849it [05:57, 12.84it/s]Train epoch: 5 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005465\n",
      "6875it [05:59, 13.01it/s]Train epoch: 5 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004476\n",
      "6899it [06:01, 12.89it/s]Train epoch: 5 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.005374\n",
      "6925it [06:03, 13.10it/s]Train epoch: 5 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.005224\n",
      "6949it [06:05, 13.09it/s]Train epoch: 5 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005934\n",
      "6975it [06:07, 12.83it/s]Train epoch: 5 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.005489\n",
      "6999it [06:09, 12.63it/s]Train epoch: 5 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.005215\n",
      "7025it [06:11, 13.17it/s]Train epoch: 5 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.006044\n",
      "7049it [06:12, 12.57it/s]Train epoch: 5 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004809\n",
      "7075it [06:14, 12.93it/s]Train epoch: 5 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.005362\n",
      "7099it [06:16, 13.03it/s]Train epoch: 5 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005714\n",
      "7125it [06:18, 12.84it/s]Train epoch: 5 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004901\n",
      "7149it [06:20, 13.11it/s]Train epoch: 5 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.006016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7175it [06:22, 13.09it/s]Train epoch: 5 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.005439\n",
      "7199it [06:24, 12.89it/s]Train epoch: 5 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005852\n",
      "7225it [06:26, 12.94it/s]Train epoch: 5 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.005302\n",
      "7249it [06:28, 12.95it/s]Train epoch: 5 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.005469\n",
      "7275it [06:30, 12.73it/s]Train epoch: 5 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005890\n",
      "7299it [06:32, 12.82it/s]Train epoch: 5 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.006354\n",
      "7325it [06:34, 12.51it/s]Train epoch: 5 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.005152\n",
      "7349it [06:36, 12.39it/s]Train epoch: 5 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.006153\n",
      "7375it [06:38, 12.65it/s]Train epoch: 5 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005753\n",
      "7399it [06:40, 12.20it/s]Train epoch: 5 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.005240\n",
      "7425it [06:42, 12.58it/s]Train epoch: 5 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005649\n",
      "7449it [06:44, 12.31it/s]Train epoch: 5 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.006349\n",
      "7475it [06:46, 12.18it/s]Train epoch: 5 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.005388\n",
      "7499it [06:48, 12.73it/s]Train epoch: 5 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005771\n",
      "7525it [06:50, 12.36it/s]Train epoch: 5 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.005534\n",
      "7549it [06:52, 12.66it/s]Train epoch: 5 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.005288\n",
      "7575it [06:54, 12.64it/s]Train epoch: 5 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005885\n",
      "7599it [06:56, 12.07it/s]Train epoch: 5 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006874\n",
      "7625it [06:58, 12.22it/s]Train epoch: 5 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.006384\n",
      "7649it [07:00, 12.41it/s]Train epoch: 5 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.005405\n",
      "7675it [07:02, 12.55it/s]Train epoch: 5 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.005659\n",
      "7699it [07:04, 12.48it/s]Train epoch: 5 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005658\n",
      "7725it [07:06, 12.37it/s]Train epoch: 5 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005600\n",
      "7749it [07:08, 12.37it/s]Train epoch: 5 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005897\n",
      "7775it [07:10, 12.28it/s]Train epoch: 5 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.005302\n",
      "7799it [07:12, 12.41it/s]Train epoch: 5 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.005552\n",
      "7825it [07:14, 12.08it/s]Train epoch: 5 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005732\n",
      "7849it [07:16, 11.87it/s]Train epoch: 5 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.005217\n",
      "7875it [07:19, 12.45it/s]Train epoch: 5 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.005544\n",
      "7899it [07:20, 12.28it/s]Train epoch: 5 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005773\n",
      "7925it [07:23, 11.80it/s]Train epoch: 5 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005769\n",
      "7949it [07:25, 12.58it/s]Train epoch: 5 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.006381\n",
      "7975it [07:27, 11.91it/s]Train epoch: 5 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.005611\n",
      "7999it [07:29, 12.11it/s]Train epoch: 5 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.005396\n",
      "8025it [07:31, 11.72it/s]Train epoch: 5 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005871\n",
      "8049it [07:33, 11.51it/s]Train epoch: 5 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.005173\n",
      "8075it [07:35, 11.95it/s]Train epoch: 5 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005729\n",
      "8099it [07:37, 11.80it/s]Train epoch: 5 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.006012\n",
      "8125it [07:39, 12.08it/s]Train epoch: 5 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.006108\n",
      "8149it [07:41, 11.73it/s]Train epoch: 5 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.005363\n",
      "8175it [07:44, 11.64it/s]Train epoch: 5 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.006199\n",
      "8199it [07:46, 12.07it/s]Train epoch: 5 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.005357\n",
      "8225it [07:48, 11.81it/s]Train epoch: 5 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006882\n",
      "8249it [07:50, 11.43it/s]Train epoch: 5 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.005470\n",
      "8275it [07:52, 11.30it/s]Train epoch: 5 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.006251\n",
      "8299it [07:54, 11.48it/s]Train epoch: 5 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.005520\n",
      "8325it [07:57, 11.24it/s]Train epoch: 5 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.006215\n",
      "8349it [07:59, 11.57it/s]Train epoch: 5 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.005410\n",
      "8375it [08:01, 11.53it/s]Train epoch: 5 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.006136\n",
      "8399it [08:03, 11.08it/s]Train epoch: 5 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005644\n",
      "8425it [08:05, 11.14it/s]Train epoch: 5 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005771\n",
      "8449it [08:07, 11.36it/s]Train epoch: 5 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.006122\n",
      "8475it [08:10, 11.51it/s]Train epoch: 5 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005784\n",
      "8499it [08:12, 11.44it/s]Train epoch: 5 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006794\n",
      "8525it [08:14, 11.14it/s]Train epoch: 5 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005784\n",
      "8549it [08:16, 11.42it/s]Train epoch: 5 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.006121\n",
      "8575it [08:19, 11.18it/s]Train epoch: 5 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005788\n",
      "8599it [08:21, 11.06it/s]Train epoch: 5 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005847\n",
      "8625it [08:23, 11.24it/s]Train epoch: 5 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005983\n",
      "8649it [08:25, 11.30it/s]Train epoch: 5 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.006133\n",
      "8675it [08:28, 10.78it/s]Train epoch: 5 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006803\n",
      "8699it [08:30, 10.80it/s]Train epoch: 5 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006732\n",
      "8725it [08:32, 10.73it/s]Train epoch: 5 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.006556\n",
      "8749it [08:34, 10.81it/s]Train epoch: 5 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.006278\n",
      "8775it [08:37, 10.74it/s]Train epoch: 5 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005633\n",
      "8799it [08:39, 10.86it/s]Train epoch: 5 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005948\n",
      "8825it [08:41, 10.83it/s]Train epoch: 5 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.006061\n",
      "8849it [08:43, 10.73it/s]Train epoch: 5 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.006246\n",
      "8875it [08:46, 10.85it/s]Train epoch: 5 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.006058\n",
      "8899it [08:48, 10.67it/s]Train epoch: 5 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.006131\n",
      "8925it [08:51, 10.60it/s]Train epoch: 5 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.006260\n",
      "8949it [08:53, 10.71it/s]Train epoch: 5 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006907\n",
      "8975it [08:55, 10.95it/s]Train epoch: 5 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.006584\n",
      "8999it [08:58, 10.41it/s]Train epoch: 5 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005962\n",
      "9025it [09:00, 10.61it/s]Train epoch: 5 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.006154\n",
      "9049it [09:02, 10.44it/s]Train epoch: 5 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005792\n",
      "9075it [09:05, 10.65it/s]Train epoch: 5 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.005360\n",
      "9099it [09:07, 10.76it/s]Train epoch: 5 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.006340\n",
      "9125it [09:09, 10.68it/s]Train epoch: 5 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005957\n",
      "9149it [09:12, 10.66it/s]Train epoch: 5 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.005478\n",
      "9175it [09:14, 10.37it/s]Train epoch: 5 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005899\n",
      "9199it [09:16, 10.40it/s]Train epoch: 5 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9225it [09:19, 10.41it/s]Train epoch: 5 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006962\n",
      "9249it [09:21, 10.49it/s]Train epoch: 5 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005981\n",
      "9275it [09:24, 10.37it/s]Train epoch: 5 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.006454\n",
      "9299it [09:26, 10.44it/s]Train epoch: 5 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.007152\n",
      "9325it [09:29, 10.37it/s]Train epoch: 5 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006941\n",
      "9349it [09:31, 10.40it/s]Train epoch: 5 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006830\n",
      "9375it [09:34, 10.21it/s]Train epoch: 5 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.006122\n",
      "9399it [09:36, 10.15it/s]Train epoch: 5 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.006367\n",
      "9424it [09:38,  9.87it/s]Train epoch: 5 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.006035\n",
      "9450it [09:41, 10.16it/s]Train epoch: 5 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.006049\n",
      "9474it [09:43, 10.28it/s]Train epoch: 5 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006847\n",
      "9500it [09:46,  9.92it/s]Train epoch: 5 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.006352\n",
      "9525it [09:48,  9.82it/s]Train epoch: 5 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006802\n",
      "9549it [09:51, 10.00it/s]Train epoch: 5 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006710\n",
      "9574it [09:53,  9.87it/s]Train epoch: 5 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006721\n",
      "9599it [09:56,  9.53it/s]Train epoch: 5 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.006477\n",
      "9625it [09:59, 10.02it/s]Train epoch: 5 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005981\n",
      "9649it [10:01,  9.68it/s]Train epoch: 5 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.006013\n",
      "9675it [10:04,  9.90it/s]Train epoch: 5 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.006434\n",
      "9700it [10:06,  9.91it/s]Train epoch: 5 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005834\n",
      "9724it [10:09, 10.00it/s]Train epoch: 5 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.006565\n",
      "9750it [10:11,  9.19it/s]Train epoch: 5 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.006301\n",
      "9775it [10:14,  9.54it/s]Train epoch: 5 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.007222\n",
      "9800it [10:16,  9.38it/s]Train epoch: 5 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006862\n",
      "9825it [10:19,  9.33it/s]Train epoch: 5 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.007013\n",
      "9850it [10:22,  9.33it/s]Train epoch: 5 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.006402\n",
      "9875it [10:24,  9.58it/s]Train epoch: 5 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.007022\n",
      "9900it [10:27,  9.96it/s]Train epoch: 5 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.007469\n",
      "9925it [10:30,  9.56it/s]Train epoch: 5 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006850\n",
      "9950it [10:32,  9.09it/s]Train epoch: 5 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.007539\n",
      "9975it [10:35,  9.16it/s]Train epoch: 5 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006977\n",
      "10000it [10:38,  9.04it/s]Train epoch: 5 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.006486\n",
      "10025it [10:40,  9.48it/s]Train epoch: 5 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.006497\n",
      "10050it [10:43,  8.74it/s]Train epoch: 5 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.007078\n",
      "10075it [10:46,  8.78it/s]Train epoch: 5 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.007427\n",
      "10100it [10:49,  8.76it/s]Train epoch: 5 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.007009\n",
      "10125it [10:52,  8.87it/s]Train epoch: 5 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.006441\n",
      "10150it [10:54,  9.01it/s]Train epoch: 5 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.007014\n",
      "10175it [10:57,  8.88it/s]Train epoch: 5 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.006582\n",
      "10200it [11:00,  9.19it/s]Train epoch: 5 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.007052\n",
      "10225it [11:03,  8.77it/s]Train epoch: 5 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.007010\n",
      "10250it [11:06,  8.74it/s]Train epoch: 5 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.007470\n",
      "10275it [11:08,  9.16it/s]Train epoch: 5 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006645\n",
      "10300it [11:11,  8.69it/s]Train epoch: 5 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.007365\n",
      "10325it [11:14,  8.70it/s]Train epoch: 5 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.007148\n",
      "10350it [11:17,  8.90it/s]Train epoch: 5 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006898\n",
      "10375it [11:20,  8.73it/s]Train epoch: 5 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.007159\n",
      "10400it [11:23,  8.58it/s]Train epoch: 5 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.007295\n",
      "10425it [11:26,  8.38it/s]Train epoch: 5 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006855\n",
      "10450it [11:29,  8.46it/s]Train epoch: 5 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.007259\n",
      "10475it [11:32,  8.13it/s]Train epoch: 5 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.006299\n",
      "10500it [11:35,  8.23it/s]Train epoch: 5 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.007238\n",
      "10525it [11:38,  8.16it/s]Train epoch: 5 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006860\n",
      "10550it [11:41,  8.21it/s]Train epoch: 5 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.007224\n",
      "10575it [11:44,  8.49it/s]Train epoch: 5 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.006359\n",
      "10600it [11:47,  8.40it/s]Train epoch: 5 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.006593\n",
      "10625it [11:50,  8.16it/s]Train epoch: 5 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.007264\n",
      "10650it [11:53,  8.10it/s]Train epoch: 5 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006759\n",
      "10675it [11:56,  8.10it/s]Train epoch: 5 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.007268\n",
      "10700it [11:59,  7.94it/s]Train epoch: 5 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006752\n",
      "10725it [12:02,  7.88it/s]Train epoch: 5 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.006289\n",
      "10750it [12:05,  7.72it/s]Train epoch: 5 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.007502\n",
      "10775it [12:08,  7.85it/s]Train epoch: 5 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.007483\n",
      "10800it [12:12,  7.65it/s]Train epoch: 5 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.007705\n",
      "10825it [12:15,  8.06it/s]Train epoch: 5 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.007634\n",
      "10850it [12:18,  7.85it/s]Train epoch: 5 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.007454\n",
      "10875it [12:21,  7.63it/s]Train epoch: 5 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.007615\n",
      "10900it [12:24,  7.98it/s]Train epoch: 5 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.007303\n",
      "10925it [12:28,  7.92it/s]Train epoch: 5 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006703\n",
      "10950it [12:31,  7.62it/s]Train epoch: 5 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.007253\n",
      "10975it [12:34,  7.85it/s]Train epoch: 5 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.007139\n",
      "11000it [12:37,  7.73it/s]Train epoch: 5 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006990\n",
      "11025it [12:40,  7.86it/s]Train epoch: 5 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.007215\n",
      "11050it [12:44,  7.44it/s]Train epoch: 5 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.008014\n",
      "11075it [12:47,  7.89it/s]Train epoch: 5 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.007485\n",
      "11100it [12:50,  7.63it/s]Train epoch: 5 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.008261\n",
      "11125it [12:53,  7.85it/s]Train epoch: 5 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007640\n",
      "11150it [12:57,  7.81it/s]Train epoch: 5 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.007395\n",
      "11175it [13:00,  7.81it/s]Train epoch: 5 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.008615\n",
      "11200it [13:03,  7.94it/s]Train epoch: 5 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007739\n",
      "11225it [13:06,  7.84it/s]Train epoch: 5 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250it [13:10,  7.71it/s]Train epoch: 5 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.008349\n",
      "11275it [13:13,  7.70it/s]Train epoch: 5 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.008048\n",
      "11300it [13:16,  7.70it/s]Train epoch: 5 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.007234\n",
      "11325it [13:19,  7.73it/s]Train epoch: 5 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.008471\n",
      "11350it [13:22,  7.71it/s]Train epoch: 5 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.008561\n",
      "11375it [13:26,  7.70it/s]Train epoch: 5 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.008779\n",
      "11400it [13:29,  8.02it/s]Train epoch: 5 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007716\n",
      "11425it [13:32,  7.97it/s]Train epoch: 5 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.008322\n",
      "11450it [13:35,  7.79it/s]Train epoch: 5 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.007481\n",
      "11475it [13:39,  7.80it/s]Train epoch: 5 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.009042\n",
      "11500it [13:42,  7.69it/s]Train epoch: 5 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.008598\n",
      "11525it [13:45,  7.54it/s]Train epoch: 5 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007933\n",
      "11550it [13:48,  7.81it/s]Train epoch: 5 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007954\n",
      "11575it [13:52,  7.72it/s]Train epoch: 5 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008997\n",
      "11600it [13:55,  7.74it/s]Train epoch: 5 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.008318\n",
      "11625it [13:58,  7.70it/s]Train epoch: 5 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007772\n",
      "11650it [14:01,  8.05it/s]Train epoch: 5 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.008520\n",
      "11675it [14:04,  7.59it/s]Train epoch: 5 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008993\n",
      "11700it [14:08,  7.92it/s]Train epoch: 5 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.009387\n",
      "11725it [14:11,  7.44it/s]Train epoch: 5 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.009393\n",
      "11750it [14:14,  7.80it/s]Train epoch: 5 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.009129\n",
      "11775it [14:17,  7.73it/s]Train epoch: 5 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.009151\n",
      "11800it [14:21,  7.69it/s]Train epoch: 5 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008974\n",
      "11825it [14:24,  7.76it/s]Train epoch: 5 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.009259\n",
      "11850it [14:27,  7.73it/s]Train epoch: 5 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.009343\n",
      "11875it [14:30,  7.69it/s]Train epoch: 5 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.010378\n",
      "11900it [14:34,  7.80it/s]Train epoch: 5 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.012430\n",
      "11925it [14:37,  7.64it/s]Train epoch: 5 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010439\n",
      "11930it [14:37, 13.59it/s]\n",
      "epoch loss: 0.005430825641318259\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 126.16it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0189, 0.0300, 0.0301, 0.0300, 0.8647\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2966, 0.5512, 0.3910, 0.4575, 0.9789\n",
      "rec_at_8: 0.3315\n",
      "prec_at_8: 0.6171\n",
      "rec_at_15: 0.4574\n",
      "prec_at_15: 0.4744\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 128.47it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0185, 0.0318, 0.0293, 0.0305, 0.8565\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2908, 0.5515, 0.3809, 0.4506, 0.9785\n",
      "rec_at_8: 0.3172\n",
      "prec_at_8: 0.6161\n",
      "rec_at_15: 0.4394\n",
      "prec_at_15: 0.4734\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 5\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0189, 0.0300, 0.0301, 0.0300, 0.8647\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2966, 0.5512, 0.3910, 0.4575, 0.9789\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0072\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 5\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0185, 0.0318, 0.0293, 0.0305, 0.8565\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2908, 0.5515, 0.3809, 0.4506, 0.9785\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0074\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 6\n",
      "0it [00:00, ?it/s]Train epoch: 6 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006795\n",
      "23it [00:00, 41.75it/s]Train epoch: 6 [batch #25, batch_size 4, seq length 221]\tLoss: 0.004222\n",
      "48it [00:01, 39.57it/s]Train epoch: 6 [batch #50, batch_size 4, seq length 270]\tLoss: 0.004053\n",
      "74it [00:01, 41.01it/s]Train epoch: 6 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003405\n",
      "98it [00:02, 38.19it/s]Train epoch: 6 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003513\n",
      "123it [00:03, 37.50it/s]Train epoch: 6 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003366\n",
      "148it [00:03, 39.91it/s]Train epoch: 6 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003256\n",
      "173it [00:04, 34.65it/s]Train epoch: 6 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003411\n",
      "197it [00:05, 35.81it/s]Train epoch: 6 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003270\n",
      "225it [00:05, 32.74it/s]Train epoch: 6 [batch #225, batch_size 4, seq length 414]\tLoss: 0.004137\n",
      "249it [00:06, 32.25it/s]Train epoch: 6 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003409\n",
      "274it [00:07, 34.46it/s]Train epoch: 6 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002872\n",
      "298it [00:08, 33.65it/s]Train epoch: 6 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003752\n",
      "322it [00:08, 31.08it/s]Train epoch: 6 [batch #325, batch_size 4, seq length 463]\tLoss: 0.003187\n",
      "350it [00:09, 31.72it/s]Train epoch: 6 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003668\n",
      "374it [00:10, 31.96it/s]Train epoch: 6 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003457\n",
      "398it [00:11, 30.95it/s]Train epoch: 6 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003583\n",
      "422it [00:12, 30.54it/s]Train epoch: 6 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003505\n",
      "450it [00:12, 31.21it/s]Train epoch: 6 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003475\n",
      "474it [00:13, 30.66it/s]Train epoch: 6 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003938\n",
      "498it [00:14, 31.01it/s]Train epoch: 6 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003298\n",
      "522it [00:15, 30.55it/s]Train epoch: 6 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003689\n",
      "548it [00:16, 28.93it/s]Train epoch: 6 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003548\n",
      "574it [00:17, 27.87it/s]Train epoch: 6 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003528\n",
      "599it [00:17, 28.88it/s]Train epoch: 6 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003786\n",
      "624it [00:18, 28.75it/s]Train epoch: 6 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003661\n",
      "647it [00:19, 28.15it/s]Train epoch: 6 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003293\n",
      "673it [00:20, 27.98it/s]Train epoch: 6 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002785\n",
      "697it [00:21, 29.51it/s]Train epoch: 6 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003457\n",
      "725it [00:22, 29.76it/s]Train epoch: 6 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003661\n",
      "749it [00:23, 27.58it/s]Train epoch: 6 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003403\n",
      "775it [00:24, 26.81it/s]Train epoch: 6 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003807\n",
      "798it [00:24, 29.26it/s]Train epoch: 6 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003748\n",
      "825it [00:25, 28.38it/s]Train epoch: 6 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003498\n",
      "850it [00:26, 28.29it/s]Train epoch: 6 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003999\n",
      "874it [00:27, 26.83it/s]Train epoch: 6 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003349\n",
      "898it [00:28, 29.01it/s]Train epoch: 6 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003650\n",
      "923it [00:29, 26.64it/s]Train epoch: 6 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003465\n",
      "948it [00:30, 28.18it/s]Train epoch: 6 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974it [00:31, 27.52it/s]Train epoch: 6 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002682\n",
      "999it [00:32, 27.98it/s]Train epoch: 6 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003592\n",
      "1023it [00:32, 26.94it/s]Train epoch: 6 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004768\n",
      "1050it [00:33, 26.60it/s]Train epoch: 6 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003380\n",
      "1074it [00:34, 26.00it/s]Train epoch: 6 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003825\n",
      "1098it [00:35, 25.54it/s]Train epoch: 6 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003850\n",
      "1123it [00:36, 26.07it/s]Train epoch: 6 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003918\n",
      "1148it [00:37, 26.99it/s]Train epoch: 6 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003900\n",
      "1175it [00:38, 25.27it/s]Train epoch: 6 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003792\n",
      "1199it [00:39, 25.07it/s]Train epoch: 6 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003947\n",
      "1224it [00:40, 26.41it/s]Train epoch: 6 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.004106\n",
      "1249it [00:41, 28.14it/s]Train epoch: 6 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003833\n",
      "1275it [00:42, 26.49it/s]Train epoch: 6 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003298\n",
      "1300it [00:43, 26.37it/s]Train epoch: 6 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003410\n",
      "1324it [00:44, 26.83it/s]Train epoch: 6 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003420\n",
      "1348it [00:45, 26.13it/s]Train epoch: 6 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004469\n",
      "1375it [00:46, 26.61it/s]Train epoch: 6 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003728\n",
      "1399it [00:47, 27.27it/s]Train epoch: 6 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003595\n",
      "1423it [00:48, 26.29it/s]Train epoch: 6 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003317\n",
      "1448it [00:48, 26.20it/s]Train epoch: 6 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003546\n",
      "1475it [00:50, 24.63it/s]Train epoch: 6 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003702\n",
      "1499it [00:50, 25.59it/s]Train epoch: 6 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004852\n",
      "1523it [00:51, 25.65it/s]Train epoch: 6 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004633\n",
      "1550it [00:52, 25.32it/s]Train epoch: 6 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003587\n",
      "1573it [00:53, 26.51it/s]Train epoch: 6 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003932\n",
      "1598it [00:54, 25.84it/s]Train epoch: 6 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003458\n",
      "1623it [00:55, 26.51it/s]Train epoch: 6 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.004124\n",
      "1650it [00:56, 24.49it/s]Train epoch: 6 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.004235\n",
      "1674it [00:57, 25.71it/s]Train epoch: 6 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.004013\n",
      "1698it [00:58, 24.12it/s]Train epoch: 6 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003521\n",
      "1725it [00:59, 25.88it/s]Train epoch: 6 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.003107\n",
      "1750it [01:00, 25.85it/s]Train epoch: 6 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004656\n",
      "1774it [01:01, 21.89it/s]Train epoch: 6 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003829\n",
      "1798it [01:02, 25.03it/s]Train epoch: 6 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003782\n",
      "1825it [01:03, 23.09it/s]Train epoch: 6 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.003234\n",
      "1849it [01:04, 23.55it/s]Train epoch: 6 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003966\n",
      "1873it [01:05, 23.86it/s]Train epoch: 6 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.004218\n",
      "1900it [01:06, 25.33it/s]Train epoch: 6 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.003146\n",
      "1924it [01:07, 24.93it/s]Train epoch: 6 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003393\n",
      "1948it [01:08, 24.00it/s]Train epoch: 6 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003368\n",
      "1973it [01:09, 26.40it/s]Train epoch: 6 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003983\n",
      "2000it [01:11, 24.15it/s]Train epoch: 6 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.003186\n",
      "2024it [01:12, 24.97it/s]Train epoch: 6 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003990\n",
      "2048it [01:13, 23.38it/s]Train epoch: 6 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003683\n",
      "2075it [01:14, 24.53it/s]Train epoch: 6 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003771\n",
      "2099it [01:15, 24.28it/s]Train epoch: 6 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.004009\n",
      "2123it [01:16, 25.03it/s]Train epoch: 6 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.004229\n",
      "2150it [01:17, 25.17it/s]Train epoch: 6 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003564\n",
      "2174it [01:18, 22.64it/s]Train epoch: 6 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.004137\n",
      "2198it [01:19, 23.95it/s]Train epoch: 6 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003904\n",
      "2225it [01:20, 23.50it/s]Train epoch: 6 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003713\n",
      "2249it [01:21, 22.63it/s]Train epoch: 6 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003528\n",
      "2273it [01:22, 23.79it/s]Train epoch: 6 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003924\n",
      "2300it [01:23, 25.14it/s]Train epoch: 6 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002997\n",
      "2324it [01:24, 23.25it/s]Train epoch: 6 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003770\n",
      "2348it [01:25, 24.19it/s]Train epoch: 6 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003456\n",
      "2375it [01:26, 24.13it/s]Train epoch: 6 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004972\n",
      "2399it [01:27, 22.93it/s]Train epoch: 6 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004609\n",
      "2423it [01:28, 23.25it/s]Train epoch: 6 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.003290\n",
      "2450it [01:29, 23.99it/s]Train epoch: 6 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003802\n",
      "2474it [01:31, 23.14it/s]Train epoch: 6 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.004243\n",
      "2498it [01:32, 22.92it/s]Train epoch: 6 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003698\n",
      "2525it [01:33, 23.53it/s]Train epoch: 6 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003528\n",
      "2549it [01:34, 21.48it/s]Train epoch: 6 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004892\n",
      "2573it [01:35, 22.87it/s]Train epoch: 6 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003511\n",
      "2600it [01:36, 22.31it/s]Train epoch: 6 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003831\n",
      "2624it [01:37, 22.73it/s]Train epoch: 6 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003832\n",
      "2648it [01:38, 21.69it/s]Train epoch: 6 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004422\n",
      "2675it [01:40, 21.39it/s]Train epoch: 6 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003982\n",
      "2699it [01:41, 20.94it/s]Train epoch: 6 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003491\n",
      "2723it [01:42, 21.79it/s]Train epoch: 6 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003793\n",
      "2750it [01:43, 22.76it/s]Train epoch: 6 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004505\n",
      "2774it [01:44, 22.29it/s]Train epoch: 6 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003886\n",
      "2798it [01:45, 19.90it/s]Train epoch: 6 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003739\n",
      "2825it [01:46, 21.22it/s]Train epoch: 6 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.004113\n",
      "2849it [01:48, 21.70it/s]Train epoch: 6 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003885\n",
      "2873it [01:49, 22.74it/s]Train epoch: 6 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.004219\n",
      "2900it [01:50, 21.12it/s]Train epoch: 6 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.004169\n",
      "2924it [01:51, 21.03it/s]Train epoch: 6 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.004258\n",
      "2948it [01:52, 22.10it/s]Train epoch: 6 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004391\n",
      "2975it [01:53, 22.76it/s]Train epoch: 6 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.004138\n",
      "2999it [01:55, 20.83it/s]Train epoch: 6 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004666\n",
      "3023it [01:56, 19.97it/s]Train epoch: 6 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.004330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3050it [01:57, 21.48it/s]Train epoch: 6 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003746\n",
      "3074it [01:58, 22.27it/s]Train epoch: 6 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.004295\n",
      "3098it [01:59, 21.76it/s]Train epoch: 6 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.004375\n",
      "3125it [02:00, 22.53it/s]Train epoch: 6 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003873\n",
      "3149it [02:02, 21.09it/s]Train epoch: 6 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003847\n",
      "3173it [02:03, 21.38it/s]Train epoch: 6 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003864\n",
      "3200it [02:04, 20.93it/s]Train epoch: 6 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004456\n",
      "3224it [02:05, 21.19it/s]Train epoch: 6 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004317\n",
      "3248it [02:06, 21.26it/s]Train epoch: 6 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004371\n",
      "3275it [02:07, 21.68it/s]Train epoch: 6 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003966\n",
      "3299it [02:09, 20.42it/s]Train epoch: 6 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004854\n",
      "3323it [02:10, 21.74it/s]Train epoch: 6 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.004181\n",
      "3350it [02:11, 21.69it/s]Train epoch: 6 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.004180\n",
      "3374it [02:12, 21.18it/s]Train epoch: 6 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.004397\n",
      "3398it [02:13, 20.73it/s]Train epoch: 6 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004474\n",
      "3425it [02:15, 20.63it/s]Train epoch: 6 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003936\n",
      "3449it [02:16, 20.82it/s]Train epoch: 6 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004564\n",
      "3473it [02:17, 21.75it/s]Train epoch: 6 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.004054\n",
      "3500it [02:18, 20.83it/s]Train epoch: 6 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.004129\n",
      "3524it [02:19, 20.48it/s]Train epoch: 6 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.004340\n",
      "3550it [02:21, 20.53it/s]Train epoch: 6 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004646\n",
      "3574it [02:22, 20.74it/s]Train epoch: 6 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003708\n",
      "3600it [02:23, 19.52it/s]Train epoch: 6 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004780\n",
      "3624it [02:24, 21.06it/s]Train epoch: 6 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.004442\n",
      "3650it [02:26, 19.77it/s]Train epoch: 6 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004476\n",
      "3674it [02:27, 17.59it/s]Train epoch: 6 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004552\n",
      "3699it [02:28, 17.47it/s]Train epoch: 6 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004562\n",
      "3724it [02:30, 17.59it/s]Train epoch: 6 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004598\n",
      "3750it [02:31, 17.70it/s]Train epoch: 6 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004630\n",
      "3775it [02:33, 17.31it/s]Train epoch: 6 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004517\n",
      "3799it [02:34, 17.55it/s]Train epoch: 6 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004929\n",
      "3825it [02:35, 17.61it/s]Train epoch: 6 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.004186\n",
      "3849it [02:37, 16.46it/s]Train epoch: 6 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003957\n",
      "3875it [02:38, 17.34it/s]Train epoch: 6 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003808\n",
      "3899it [02:40, 17.24it/s]Train epoch: 6 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004911\n",
      "3924it [02:41, 16.94it/s]Train epoch: 6 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004450\n",
      "3950it [02:43, 17.70it/s]Train epoch: 6 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004906\n",
      "3974it [02:44, 16.46it/s]Train epoch: 6 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.005438\n",
      "4000it [02:46, 16.55it/s]Train epoch: 6 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.004076\n",
      "4024it [02:47, 17.20it/s]Train epoch: 6 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.005056\n",
      "4049it [02:48, 17.52it/s]Train epoch: 6 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004597\n",
      "4075it [02:50, 16.39it/s]Train epoch: 6 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004607\n",
      "4099it [02:51, 16.19it/s]Train epoch: 6 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.005067\n",
      "4125it [02:53, 17.13it/s]Train epoch: 6 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004951\n",
      "4149it [02:54, 17.24it/s]Train epoch: 6 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.004198\n",
      "4175it [02:56, 16.89it/s]Train epoch: 6 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004485\n",
      "4199it [02:57, 16.39it/s]Train epoch: 6 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004890\n",
      "4225it [02:59, 16.13it/s]Train epoch: 6 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.004197\n",
      "4249it [03:00, 15.59it/s]Train epoch: 6 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004707\n",
      "4275it [03:02, 15.53it/s]Train epoch: 6 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004501\n",
      "4299it [03:04, 16.07it/s]Train epoch: 6 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.005126\n",
      "4324it [03:05, 16.98it/s]Train epoch: 6 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004521\n",
      "4350it [03:07, 16.62it/s]Train epoch: 6 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004947\n",
      "4374it [03:08, 17.07it/s]Train epoch: 6 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004397\n",
      "4400it [03:10, 17.13it/s]Train epoch: 6 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003885\n",
      "4424it [03:11, 16.35it/s]Train epoch: 6 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004663\n",
      "4450it [03:13, 16.66it/s]Train epoch: 6 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003792\n",
      "4474it [03:14, 16.86it/s]Train epoch: 6 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004799\n",
      "4500it [03:16, 16.44it/s]Train epoch: 6 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005611\n",
      "4524it [03:17, 17.23it/s]Train epoch: 6 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004818\n",
      "4550it [03:19, 16.39it/s]Train epoch: 6 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004495\n",
      "4574it [03:20, 15.69it/s]Train epoch: 6 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.005194\n",
      "4600it [03:22, 14.80it/s]Train epoch: 6 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004326\n",
      "4624it [03:23, 15.06it/s]Train epoch: 6 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004419\n",
      "4650it [03:25, 15.60it/s]Train epoch: 6 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.005081\n",
      "4674it [03:27, 15.02it/s]Train epoch: 6 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004785\n",
      "4700it [03:28, 14.92it/s]Train epoch: 6 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.004333\n",
      "4724it [03:30, 15.83it/s]Train epoch: 6 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004524\n",
      "4750it [03:32, 16.37it/s]Train epoch: 6 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.005270\n",
      "4774it [03:33, 14.88it/s]Train epoch: 6 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004662\n",
      "4800it [03:35, 14.59it/s]Train epoch: 6 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004865\n",
      "4824it [03:36, 14.92it/s]Train epoch: 6 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.004335\n",
      "4850it [03:38, 16.28it/s]Train epoch: 6 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.005001\n",
      "4874it [03:40, 15.42it/s]Train epoch: 6 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.004248\n",
      "4900it [03:41, 15.30it/s]Train epoch: 6 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004757\n",
      "4924it [03:43, 15.11it/s]Train epoch: 6 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.004303\n",
      "4950it [03:45, 15.55it/s]Train epoch: 6 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004657\n",
      "4974it [03:46, 15.24it/s]Train epoch: 6 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004649\n",
      "5000it [03:48, 14.94it/s]Train epoch: 6 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004640\n",
      "5024it [03:50, 14.60it/s]Train epoch: 6 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004378\n",
      "5050it [03:51, 14.81it/s]Train epoch: 6 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004326\n",
      "5074it [03:53, 14.60it/s]Train epoch: 6 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100it [03:55, 14.31it/s]Train epoch: 6 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004642\n",
      "5124it [03:56, 14.92it/s]Train epoch: 6 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004949\n",
      "5150it [03:58, 14.95it/s]Train epoch: 6 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004971\n",
      "5174it [04:00, 15.54it/s]Train epoch: 6 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004873\n",
      "5200it [04:02, 14.91it/s]Train epoch: 6 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004337\n",
      "5224it [04:03, 15.23it/s]Train epoch: 6 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004737\n",
      "5250it [04:05, 14.79it/s]Train epoch: 6 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004581\n",
      "5274it [04:07, 13.94it/s]Train epoch: 6 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004476\n",
      "5300it [04:08, 15.10it/s]Train epoch: 6 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004389\n",
      "5324it [04:10, 14.90it/s]Train epoch: 6 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.005007\n",
      "5350it [04:12, 14.49it/s]Train epoch: 6 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.005028\n",
      "5374it [04:13, 14.96it/s]Train epoch: 6 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004573\n",
      "5400it [04:15, 14.79it/s]Train epoch: 6 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004551\n",
      "5424it [04:17, 14.89it/s]Train epoch: 6 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004888\n",
      "5450it [04:19, 14.66it/s]Train epoch: 6 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004914\n",
      "5474it [04:20, 14.96it/s]Train epoch: 6 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005655\n",
      "5500it [04:22, 14.91it/s]Train epoch: 6 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.005171\n",
      "5524it [04:24, 14.71it/s]Train epoch: 6 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.004221\n",
      "5550it [04:25, 14.57it/s]Train epoch: 6 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004833\n",
      "5574it [04:27, 14.78it/s]Train epoch: 6 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004932\n",
      "5600it [04:29, 14.26it/s]Train epoch: 6 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.005293\n",
      "5624it [04:30, 14.59it/s]Train epoch: 6 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004869\n",
      "5650it [04:32, 14.44it/s]Train epoch: 6 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004426\n",
      "5674it [04:34, 15.11it/s]Train epoch: 6 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.005416\n",
      "5700it [04:36, 14.51it/s]Train epoch: 6 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004681\n",
      "5724it [04:37, 14.39it/s]Train epoch: 6 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004915\n",
      "5750it [04:39, 14.84it/s]Train epoch: 6 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005998\n",
      "5774it [04:41, 14.32it/s]Train epoch: 6 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.005163\n",
      "5800it [04:43, 14.40it/s]Train epoch: 6 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.005181\n",
      "5824it [04:44, 14.86it/s]Train epoch: 6 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004565\n",
      "5850it [04:46, 14.07it/s]Train epoch: 6 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005754\n",
      "5874it [04:48, 14.19it/s]Train epoch: 6 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005562\n",
      "5900it [04:50, 14.22it/s]Train epoch: 6 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005603\n",
      "5924it [04:51, 14.20it/s]Train epoch: 6 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004471\n",
      "5950it [04:53, 13.97it/s]Train epoch: 6 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004501\n",
      "5974it [04:55, 14.30it/s]Train epoch: 6 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.006158\n",
      "6000it [04:57, 14.03it/s]Train epoch: 6 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.005268\n",
      "6024it [04:58, 14.32it/s]Train epoch: 6 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.005409\n",
      "6050it [05:00, 13.66it/s]Train epoch: 6 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004891\n",
      "6074it [05:02, 14.15it/s]Train epoch: 6 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004598\n",
      "6100it [05:04, 14.19it/s]Train epoch: 6 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004365\n",
      "6124it [05:05, 13.92it/s]Train epoch: 6 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004919\n",
      "6150it [05:07, 14.18it/s]Train epoch: 6 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004878\n",
      "6174it [05:09, 13.76it/s]Train epoch: 6 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005572\n",
      "6200it [05:11, 12.92it/s]Train epoch: 6 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004953\n",
      "6224it [05:13, 13.68it/s]Train epoch: 6 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.004331\n",
      "6250it [05:15, 13.80it/s]Train epoch: 6 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004699\n",
      "6274it [05:16, 13.93it/s]Train epoch: 6 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.004281\n",
      "6300it [05:18, 13.34it/s]Train epoch: 6 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004996\n",
      "6324it [05:20, 13.74it/s]Train epoch: 6 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005369\n",
      "6350it [05:22, 13.53it/s]Train epoch: 6 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005688\n",
      "6374it [05:24, 13.54it/s]Train epoch: 6 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004572\n",
      "6400it [05:26, 14.33it/s]Train epoch: 6 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004724\n",
      "6424it [05:27, 13.43it/s]Train epoch: 6 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.005466\n",
      "6450it [05:29, 14.08it/s]Train epoch: 6 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.005260\n",
      "6474it [05:31, 13.99it/s]Train epoch: 6 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004777\n",
      "6500it [05:33, 14.27it/s]Train epoch: 6 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.005493\n",
      "6524it [05:35, 13.89it/s]Train epoch: 6 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004690\n",
      "6550it [05:36, 13.33it/s]Train epoch: 6 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004798\n",
      "6574it [05:38, 13.54it/s]Train epoch: 6 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.005043\n",
      "6600it [05:40, 14.01it/s]Train epoch: 6 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.006030\n",
      "6624it [05:42, 14.13it/s]Train epoch: 6 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004902\n",
      "6650it [05:44, 13.99it/s]Train epoch: 6 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005543\n",
      "6674it [05:45, 13.95it/s]Train epoch: 6 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.005184\n",
      "6700it [05:47, 13.60it/s]Train epoch: 6 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.005245\n",
      "6724it [05:49, 13.76it/s]Train epoch: 6 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.005322\n",
      "6750it [05:51, 13.68it/s]Train epoch: 6 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004772\n",
      "6774it [05:53, 13.78it/s]Train epoch: 6 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005477\n",
      "6800it [05:55, 13.41it/s]Train epoch: 6 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005431\n",
      "6824it [05:56, 13.35it/s]Train epoch: 6 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005678\n",
      "6850it [05:58, 13.46it/s]Train epoch: 6 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005318\n",
      "6874it [06:00, 13.34it/s]Train epoch: 6 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004377\n",
      "6900it [06:02, 13.27it/s]Train epoch: 6 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.005219\n",
      "6924it [06:04, 13.65it/s]Train epoch: 6 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.005106\n",
      "6950it [06:06, 13.17it/s]Train epoch: 6 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005733\n",
      "6974it [06:08, 13.59it/s]Train epoch: 6 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.005325\n",
      "7000it [06:10, 13.49it/s]Train epoch: 6 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.005053\n",
      "7024it [06:11, 13.31it/s]Train epoch: 6 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005848\n",
      "7050it [06:13, 13.31it/s]Train epoch: 6 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004628\n",
      "7074it [06:15, 13.38it/s]Train epoch: 6 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.005180\n",
      "7100it [06:17, 13.44it/s]Train epoch: 6 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005538\n",
      "7124it [06:19, 13.40it/s]Train epoch: 6 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7150it [06:21, 13.26it/s]Train epoch: 6 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005851\n",
      "7174it [06:23, 13.14it/s]Train epoch: 6 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.005270\n",
      "7200it [06:25, 13.14it/s]Train epoch: 6 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005693\n",
      "7224it [06:27, 12.82it/s]Train epoch: 6 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.005167\n",
      "7250it [06:29, 12.87it/s]Train epoch: 6 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.005312\n",
      "7274it [06:31, 12.72it/s]Train epoch: 6 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005716\n",
      "7300it [06:33, 12.90it/s]Train epoch: 6 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.006186\n",
      "7324it [06:34, 12.50it/s]Train epoch: 6 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004974\n",
      "7350it [06:36, 12.91it/s]Train epoch: 6 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.006035\n",
      "7374it [06:38, 12.39it/s]Train epoch: 6 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005611\n",
      "7400it [06:40, 12.68it/s]Train epoch: 6 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.005059\n",
      "7424it [06:42, 12.63it/s]Train epoch: 6 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005538\n",
      "7450it [06:44, 12.71it/s]Train epoch: 6 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.006141\n",
      "7474it [06:46, 12.72it/s]Train epoch: 6 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.005253\n",
      "7500it [06:48, 12.68it/s]Train epoch: 6 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005569\n",
      "7524it [06:50, 12.44it/s]Train epoch: 6 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.005338\n",
      "7550it [06:52, 13.04it/s]Train epoch: 6 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.005173\n",
      "7574it [06:54, 12.40it/s]Train epoch: 6 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005696\n",
      "7600it [06:56, 13.10it/s]Train epoch: 6 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006719\n",
      "7624it [06:58, 12.38it/s]Train epoch: 6 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.006213\n",
      "7650it [07:00, 12.51it/s]Train epoch: 6 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.005266\n",
      "7674it [07:02, 12.39it/s]Train epoch: 6 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.005490\n",
      "7700it [07:04, 12.48it/s]Train epoch: 6 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005418\n",
      "7724it [07:06, 12.67it/s]Train epoch: 6 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005510\n",
      "7750it [07:08, 12.53it/s]Train epoch: 6 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005764\n",
      "7774it [07:10, 12.44it/s]Train epoch: 6 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.005084\n",
      "7800it [07:12, 12.21it/s]Train epoch: 6 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.005374\n",
      "7824it [07:14, 12.17it/s]Train epoch: 6 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005611\n",
      "7850it [07:16, 12.25it/s]Train epoch: 6 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.005035\n",
      "7874it [07:18, 12.20it/s]Train epoch: 6 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.005412\n",
      "7900it [07:20, 12.37it/s]Train epoch: 6 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005572\n",
      "7924it [07:22, 12.24it/s]Train epoch: 6 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005576\n",
      "7950it [07:24, 12.30it/s]Train epoch: 6 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.006217\n",
      "7974it [07:26, 12.09it/s]Train epoch: 6 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.005440\n",
      "8000it [07:29, 12.21it/s]Train epoch: 6 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.005242\n",
      "8024it [07:31, 11.71it/s]Train epoch: 6 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005670\n",
      "8050it [07:33, 12.03it/s]Train epoch: 6 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.005012\n",
      "8074it [07:35, 11.58it/s]Train epoch: 6 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005518\n",
      "8100it [07:37, 12.08it/s]Train epoch: 6 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005833\n",
      "8124it [07:39, 11.91it/s]Train epoch: 6 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005941\n",
      "8150it [07:41, 11.87it/s]Train epoch: 6 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.005146\n",
      "8174it [07:43, 11.72it/s]Train epoch: 6 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005990\n",
      "8200it [07:45, 12.26it/s]Train epoch: 6 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.005193\n",
      "8224it [07:47, 11.82it/s]Train epoch: 6 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006710\n",
      "8250it [07:49, 12.15it/s]Train epoch: 6 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.005300\n",
      "8274it [07:52, 11.54it/s]Train epoch: 6 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.006023\n",
      "8300it [07:54, 12.11it/s]Train epoch: 6 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.005279\n",
      "8324it [07:56, 11.70it/s]Train epoch: 6 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.006001\n",
      "8350it [07:58, 11.69it/s]Train epoch: 6 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.005229\n",
      "8374it [08:00, 11.71it/s]Train epoch: 6 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005937\n",
      "8400it [08:02, 11.54it/s]Train epoch: 6 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005518\n",
      "8424it [08:04, 11.41it/s]Train epoch: 6 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005646\n",
      "8450it [08:07, 11.50it/s]Train epoch: 6 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005984\n",
      "8474it [08:09, 11.46it/s]Train epoch: 6 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005653\n",
      "8500it [08:11, 11.52it/s]Train epoch: 6 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006579\n",
      "8524it [08:13, 11.41it/s]Train epoch: 6 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005623\n",
      "8550it [08:15, 11.42it/s]Train epoch: 6 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005953\n",
      "8574it [08:17, 11.22it/s]Train epoch: 6 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005593\n",
      "8600it [08:20, 11.70it/s]Train epoch: 6 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005718\n",
      "8624it [08:22, 11.22it/s]Train epoch: 6 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005803\n",
      "8650it [08:24, 11.33it/s]Train epoch: 6 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005909\n",
      "8674it [08:26, 11.17it/s]Train epoch: 6 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006621\n",
      "8700it [08:29, 11.12it/s]Train epoch: 6 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006545\n",
      "8724it [08:31, 11.27it/s]Train epoch: 6 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.006395\n",
      "8750it [08:33, 11.42it/s]Train epoch: 6 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.006101\n",
      "8774it [08:35, 11.09it/s]Train epoch: 6 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005503\n",
      "8800it [08:38, 10.97it/s]Train epoch: 6 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005765\n",
      "8824it [08:40, 11.24it/s]Train epoch: 6 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005879\n",
      "8850it [08:42, 10.79it/s]Train epoch: 6 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.006000\n",
      "8874it [08:44, 11.04it/s]Train epoch: 6 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005892\n",
      "8900it [08:47, 11.19it/s]Train epoch: 6 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005952\n",
      "8924it [08:49, 10.99it/s]Train epoch: 6 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.006118\n",
      "8950it [08:51, 10.89it/s]Train epoch: 6 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006742\n",
      "8974it [08:53, 10.93it/s]Train epoch: 6 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.006352\n",
      "9000it [08:56, 10.86it/s]Train epoch: 6 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005836\n",
      "9024it [08:58, 10.72it/s]Train epoch: 6 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.006032\n",
      "9050it [09:01, 10.41it/s]Train epoch: 6 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005632\n",
      "9074it [09:03, 10.38it/s]Train epoch: 6 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.005196\n",
      "9100it [09:05, 10.66it/s]Train epoch: 6 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.006128\n",
      "9124it [09:07, 10.71it/s]Train epoch: 6 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005774\n",
      "9150it [09:10, 10.72it/s]Train epoch: 6 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.005305\n",
      "9174it [09:12, 10.54it/s]Train epoch: 6 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200it [09:15, 10.54it/s]Train epoch: 6 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005642\n",
      "9224it [09:17, 10.55it/s]Train epoch: 6 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006717\n",
      "9250it [09:19, 10.54it/s]Train epoch: 6 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005862\n",
      "9274it [09:22, 10.24it/s]Train epoch: 6 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.006281\n",
      "9300it [09:24, 10.47it/s]Train epoch: 6 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006993\n",
      "9324it [09:26, 10.41it/s]Train epoch: 6 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006713\n",
      "9350it [09:29, 10.27it/s]Train epoch: 6 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006684\n",
      "9374it [09:31, 10.55it/s]Train epoch: 6 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005989\n",
      "9400it [09:34, 10.52it/s]Train epoch: 6 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.006150\n",
      "9424it [09:36, 10.42it/s]Train epoch: 6 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005919\n",
      "9450it [09:39, 10.38it/s]Train epoch: 6 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005842\n",
      "9474it [09:41, 10.25it/s]Train epoch: 6 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006604\n",
      "9499it [09:43, 10.13it/s]Train epoch: 6 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.006202\n",
      "9525it [09:46, 10.06it/s]Train epoch: 6 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006604\n",
      "9549it [09:48, 10.14it/s]Train epoch: 6 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006512\n",
      "9575it [09:51, 10.04it/s]Train epoch: 6 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006541\n",
      "9600it [09:53,  9.97it/s]Train epoch: 6 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.006303\n",
      "9625it [09:56,  9.94it/s]Train epoch: 6 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005770\n",
      "9649it [09:58, 10.00it/s]Train epoch: 6 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005857\n",
      "9675it [10:01, 10.25it/s]Train epoch: 6 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.006308\n",
      "9700it [10:03,  9.73it/s]Train epoch: 6 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005684\n",
      "9725it [10:06,  9.72it/s]Train epoch: 6 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.006388\n",
      "9750it [10:09,  9.38it/s]Train epoch: 6 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.006166\n",
      "9774it [10:11,  9.58it/s]Train epoch: 6 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.007011\n",
      "9800it [10:14,  9.91it/s]Train epoch: 6 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006698\n",
      "9824it [10:16,  9.80it/s]Train epoch: 6 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006846\n",
      "9850it [10:19,  9.39it/s]Train epoch: 6 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.006210\n",
      "9875it [10:21,  9.52it/s]Train epoch: 6 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006739\n",
      "9900it [10:24,  9.66it/s]Train epoch: 6 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.007258\n",
      "9925it [10:27,  9.28it/s]Train epoch: 6 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006702\n",
      "9950it [10:29,  9.53it/s]Train epoch: 6 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.007333\n",
      "9975it [10:32,  9.37it/s]Train epoch: 6 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006827\n",
      "10000it [10:34,  9.44it/s]Train epoch: 6 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.006349\n",
      "10025it [10:37,  9.72it/s]Train epoch: 6 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.006339\n",
      "10050it [10:40,  9.04it/s]Train epoch: 6 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006905\n",
      "10075it [10:42,  8.92it/s]Train epoch: 6 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.007259\n",
      "10100it [10:45,  9.24it/s]Train epoch: 6 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006822\n",
      "10125it [10:48,  9.29it/s]Train epoch: 6 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.006256\n",
      "10150it [10:51,  9.05it/s]Train epoch: 6 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006839\n",
      "10175it [10:53,  9.27it/s]Train epoch: 6 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.006366\n",
      "10200it [10:56,  9.10it/s]Train epoch: 6 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006844\n",
      "10225it [10:59,  9.14it/s]Train epoch: 6 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006855\n",
      "10250it [11:02,  9.12it/s]Train epoch: 6 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.007333\n",
      "10275it [11:04,  9.01it/s]Train epoch: 6 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006466\n",
      "10300it [11:07,  9.02it/s]Train epoch: 6 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.007177\n",
      "10325it [11:10,  8.85it/s]Train epoch: 6 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006987\n",
      "10350it [11:13,  8.96it/s]Train epoch: 6 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006748\n",
      "10375it [11:15,  8.93it/s]Train epoch: 6 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.007034\n",
      "10400it [11:18,  8.70it/s]Train epoch: 6 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.007048\n",
      "10425it [11:21,  8.55it/s]Train epoch: 6 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006610\n",
      "10450it [11:24,  8.55it/s]Train epoch: 6 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.007031\n",
      "10475it [11:27,  8.64it/s]Train epoch: 6 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.006177\n",
      "10500it [11:30,  8.44it/s]Train epoch: 6 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006996\n",
      "10525it [11:33,  8.37it/s]Train epoch: 6 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006745\n",
      "10550it [11:36,  8.40it/s]Train epoch: 6 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.007044\n",
      "10575it [11:39,  8.19it/s]Train epoch: 6 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.006216\n",
      "10600it [11:42,  8.36it/s]Train epoch: 6 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.006369\n",
      "10625it [11:45,  8.17it/s]Train epoch: 6 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.007124\n",
      "10650it [11:48,  8.55it/s]Train epoch: 6 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006594\n",
      "10675it [11:51,  8.23it/s]Train epoch: 6 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.007055\n",
      "10700it [11:54,  8.31it/s]Train epoch: 6 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006614\n",
      "10725it [11:57,  8.18it/s]Train epoch: 6 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.006163\n",
      "10750it [12:00,  8.00it/s]Train epoch: 6 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.007337\n",
      "10775it [12:03,  8.03it/s]Train epoch: 6 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.007312\n",
      "10800it [12:06,  7.98it/s]Train epoch: 6 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.007474\n",
      "10825it [12:10,  8.24it/s]Train epoch: 6 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.007416\n",
      "10850it [12:13,  7.78it/s]Train epoch: 6 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.007250\n",
      "10875it [12:16,  7.81it/s]Train epoch: 6 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.007420\n",
      "10900it [12:19,  7.74it/s]Train epoch: 6 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.007109\n",
      "10925it [12:22,  7.79it/s]Train epoch: 6 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006498\n",
      "10950it [12:25,  7.83it/s]Train epoch: 6 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.007090\n",
      "10975it [12:29,  7.93it/s]Train epoch: 6 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006898\n",
      "11000it [12:32,  7.89it/s]Train epoch: 6 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006814\n",
      "11025it [12:35,  7.96it/s]Train epoch: 6 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.007080\n",
      "11050it [12:38,  7.68it/s]Train epoch: 6 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007832\n",
      "11075it [12:41,  8.28it/s]Train epoch: 6 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.007307\n",
      "11100it [12:44,  7.85it/s]Train epoch: 6 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007974\n",
      "11125it [12:48,  7.82it/s]Train epoch: 6 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007475\n",
      "11150it [12:51,  7.85it/s]Train epoch: 6 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.007211\n",
      "11175it [12:54,  7.85it/s]Train epoch: 6 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.008401\n",
      "11200it [12:57,  8.04it/s]Train epoch: 6 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11225it [13:00,  7.84it/s]Train epoch: 6 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007529\n",
      "11250it [13:03,  7.79it/s]Train epoch: 6 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.008164\n",
      "11275it [13:06,  7.86it/s]Train epoch: 6 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007834\n",
      "11300it [13:10,  7.56it/s]Train epoch: 6 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.007118\n",
      "11325it [13:13,  7.96it/s]Train epoch: 6 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.008308\n",
      "11350it [13:16,  8.02it/s]Train epoch: 6 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.008384\n",
      "11375it [13:19,  7.90it/s]Train epoch: 6 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.008576\n",
      "11400it [13:22,  8.05it/s]Train epoch: 6 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007501\n",
      "11425it [13:25,  7.94it/s]Train epoch: 6 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.008142\n",
      "11450it [13:29,  7.73it/s]Train epoch: 6 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.007316\n",
      "11475it [13:32,  7.93it/s]Train epoch: 6 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008808\n",
      "11500it [13:35,  7.99it/s]Train epoch: 6 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.008386\n",
      "11525it [13:38,  7.85it/s]Train epoch: 6 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007762\n",
      "11550it [13:41,  7.80it/s]Train epoch: 6 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007740\n",
      "11575it [13:45,  7.85it/s]Train epoch: 6 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008802\n",
      "11600it [13:48,  7.83it/s]Train epoch: 6 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.008188\n",
      "11625it [13:51,  7.83it/s]Train epoch: 6 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007662\n",
      "11650it [13:54,  7.90it/s]Train epoch: 6 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.008336\n",
      "11675it [13:57,  8.04it/s]Train epoch: 6 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008836\n",
      "11700it [14:00,  8.11it/s]Train epoch: 6 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.009206\n",
      "11725it [14:04,  7.87it/s]Train epoch: 6 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.009170\n",
      "11750it [14:07,  7.84it/s]Train epoch: 6 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008917\n",
      "11775it [14:10,  7.88it/s]Train epoch: 6 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.009023\n",
      "11800it [14:13,  7.90it/s]Train epoch: 6 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008791\n",
      "11825it [14:16,  7.88it/s]Train epoch: 6 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.009060\n",
      "11850it [14:19,  7.80it/s]Train epoch: 6 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.009229\n",
      "11875it [14:23,  7.82it/s]Train epoch: 6 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.010182\n",
      "11900it [14:26,  7.68it/s]Train epoch: 6 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.012210\n",
      "11925it [14:29,  7.63it/s]Train epoch: 6 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010283\n",
      "11930it [14:30, 13.71it/s]\n",
      "epoch loss: 0.005275682625112929\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 129.54it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0220, 0.0339, 0.0344, 0.0342, 0.8689\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3046, 0.5538, 0.4037, 0.4669, 0.9798\n",
      "rec_at_8: 0.3352\n",
      "prec_at_8: 0.6232\n",
      "rec_at_15: 0.4662\n",
      "prec_at_15: 0.4822\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 131.71it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0213, 0.0360, 0.0335, 0.0347, 0.8612\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2977, 0.5517, 0.3928, 0.4589, 0.9794\n",
      "rec_at_8: 0.3236\n",
      "prec_at_8: 0.6264\n",
      "rec_at_15: 0.4488\n",
      "prec_at_15: 0.4821\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 6\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0220, 0.0339, 0.0344, 0.0342, 0.8689\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3046, 0.5538, 0.4037, 0.4669, 0.9798\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 6\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0213, 0.0360, 0.0335, 0.0347, 0.8612\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2977, 0.5517, 0.3928, 0.4589, 0.9794\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0073\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 7\n",
      "0it [00:00, ?it/s]Train epoch: 7 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006895\n",
      "25it [00:00, 43.22it/s]Train epoch: 7 [batch #25, batch_size 4, seq length 221]\tLoss: 0.004122\n",
      "50it [00:01, 41.32it/s]Train epoch: 7 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003943\n",
      "75it [00:01, 40.75it/s]Train epoch: 7 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003309\n",
      "100it [00:02, 40.01it/s]Train epoch: 7 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003428\n",
      "123it [00:02, 37.96it/s]Train epoch: 7 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003388\n",
      "149it [00:03, 38.91it/s]Train epoch: 7 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003233\n",
      "174it [00:04, 35.31it/s]Train epoch: 7 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003375\n",
      "199it [00:05, 37.25it/s]Train epoch: 7 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003196\n",
      "223it [00:05, 34.34it/s]Train epoch: 7 [batch #225, batch_size 4, seq length 414]\tLoss: 0.004011\n",
      "247it [00:06, 35.29it/s]Train epoch: 7 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003359\n",
      "275it [00:07, 32.77it/s]Train epoch: 7 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002823\n",
      "299it [00:08, 33.20it/s]Train epoch: 7 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003669\n",
      "323it [00:08, 31.22it/s]Train epoch: 7 [batch #325, batch_size 4, seq length 463]\tLoss: 0.003078\n",
      "347it [00:09, 33.05it/s]Train epoch: 7 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003589\n",
      "375it [00:10, 31.92it/s]Train epoch: 7 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003376\n",
      "399it [00:11, 34.53it/s]Train epoch: 7 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003475\n",
      "423it [00:11, 31.02it/s]Train epoch: 7 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003415\n",
      "447it [00:12, 32.45it/s]Train epoch: 7 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003360\n",
      "475it [00:13, 31.53it/s]Train epoch: 7 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003831\n",
      "498it [00:14, 29.24it/s]Train epoch: 7 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003256\n",
      "524it [00:15, 29.14it/s]Train epoch: 7 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003543\n",
      "550it [00:16, 29.09it/s]Train epoch: 7 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003490\n",
      "574it [00:16, 29.57it/s]Train epoch: 7 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003446\n",
      "599it [00:17, 28.57it/s]Train epoch: 7 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003720\n",
      "625it [00:18, 29.05it/s]Train epoch: 7 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003548\n",
      "647it [00:19, 28.70it/s]Train epoch: 7 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003276\n",
      "673it [00:20, 28.83it/s]Train epoch: 7 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002712\n",
      "698it [00:21, 28.54it/s]Train epoch: 7 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003339\n",
      "724it [00:22, 28.00it/s]Train epoch: 7 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003590\n",
      "749it [00:22, 27.90it/s]Train epoch: 7 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003332\n",
      "774it [00:23, 30.73it/s]Train epoch: 7 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003689\n",
      "798it [00:24, 29.55it/s]Train epoch: 7 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003641\n",
      "823it [00:25, 28.92it/s]Train epoch: 7 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003485\n",
      "848it [00:26, 28.32it/s]Train epoch: 7 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003896\n",
      "872it [00:27, 27.91it/s]Train epoch: 7 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003281\n",
      "898it [00:28, 27.81it/s]Train epoch: 7 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003563\n",
      "924it [00:29, 28.55it/s]Train epoch: 7 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949it [00:29, 28.45it/s]Train epoch: 7 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003278\n",
      "974it [00:30, 27.49it/s]Train epoch: 7 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002633\n",
      "1000it [00:31, 28.11it/s]Train epoch: 7 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003456\n",
      "1024it [00:32, 26.60it/s]Train epoch: 7 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004673\n",
      "1048it [00:33, 28.75it/s]Train epoch: 7 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003304\n",
      "1073it [00:34, 26.90it/s]Train epoch: 7 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003707\n",
      "1098it [00:35, 26.88it/s]Train epoch: 7 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003737\n",
      "1125it [00:36, 28.72it/s]Train epoch: 7 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003842\n",
      "1149it [00:37, 25.48it/s]Train epoch: 7 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003845\n",
      "1175it [00:38, 26.75it/s]Train epoch: 7 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003708\n",
      "1199it [00:39, 27.24it/s]Train epoch: 7 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003894\n",
      "1223it [00:39, 26.33it/s]Train epoch: 7 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003991\n",
      "1250it [00:41, 26.58it/s]Train epoch: 7 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003741\n",
      "1274it [00:41, 24.72it/s]Train epoch: 7 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003253\n",
      "1299it [00:42, 28.15it/s]Train epoch: 7 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003302\n",
      "1323it [00:43, 25.99it/s]Train epoch: 7 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003329\n",
      "1350it [00:44, 25.79it/s]Train epoch: 7 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004387\n",
      "1374it [00:45, 26.52it/s]Train epoch: 7 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003635\n",
      "1398it [00:46, 27.28it/s]Train epoch: 7 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003554\n",
      "1422it [00:47, 27.29it/s]Train epoch: 7 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003200\n",
      "1450it [00:48, 25.75it/s]Train epoch: 7 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003467\n",
      "1475it [00:49, 26.84it/s]Train epoch: 7 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003647\n",
      "1499it [00:50, 27.32it/s]Train epoch: 7 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004749\n",
      "1523it [00:51, 26.37it/s]Train epoch: 7 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004477\n",
      "1550it [00:52, 25.53it/s]Train epoch: 7 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003485\n",
      "1574it [00:53, 25.17it/s]Train epoch: 7 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003851\n",
      "1598it [00:54, 25.55it/s]Train epoch: 7 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003337\n",
      "1625it [00:55, 23.92it/s]Train epoch: 7 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.004012\n",
      "1649it [00:56, 25.97it/s]Train epoch: 7 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.004126\n",
      "1673it [00:57, 25.65it/s]Train epoch: 7 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003940\n",
      "1700it [00:58, 24.76it/s]Train epoch: 7 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003451\n",
      "1724it [00:59, 23.86it/s]Train epoch: 7 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.003025\n",
      "1748it [01:00, 24.57it/s]Train epoch: 7 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004493\n",
      "1775it [01:01, 24.27it/s]Train epoch: 7 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003728\n",
      "1799it [01:02, 26.11it/s]Train epoch: 7 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003665\n",
      "1823it [01:03, 25.61it/s]Train epoch: 7 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.003099\n",
      "1850it [01:04, 24.38it/s]Train epoch: 7 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003842\n",
      "1874it [01:05, 23.08it/s]Train epoch: 7 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.004132\n",
      "1898it [01:06, 24.24it/s]Train epoch: 7 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.003071\n",
      "1925it [01:07, 24.87it/s]Train epoch: 7 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003353\n",
      "1949it [01:08, 24.29it/s]Train epoch: 7 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003319\n",
      "1973it [01:09, 24.42it/s]Train epoch: 7 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003859\n",
      "2000it [01:10, 24.61it/s]Train epoch: 7 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.003086\n",
      "2024it [01:11, 24.54it/s]Train epoch: 7 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003829\n",
      "2048it [01:12, 23.87it/s]Train epoch: 7 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003560\n",
      "2075it [01:13, 24.31it/s]Train epoch: 7 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003703\n",
      "2099it [01:14, 23.94it/s]Train epoch: 7 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003911\n",
      "2123it [01:15, 24.52it/s]Train epoch: 7 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.004099\n",
      "2150it [01:16, 24.31it/s]Train epoch: 7 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003511\n",
      "2174it [01:17, 23.85it/s]Train epoch: 7 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.004047\n",
      "2198it [01:18, 24.58it/s]Train epoch: 7 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003815\n",
      "2225it [01:20, 23.86it/s]Train epoch: 7 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003611\n",
      "2249it [01:21, 22.38it/s]Train epoch: 7 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003427\n",
      "2273it [01:22, 21.45it/s]Train epoch: 7 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003808\n",
      "2300it [01:23, 24.40it/s]Train epoch: 7 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002944\n",
      "2324it [01:24, 23.25it/s]Train epoch: 7 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003673\n",
      "2348it [01:25, 24.05it/s]Train epoch: 7 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003428\n",
      "2375it [01:26, 24.84it/s]Train epoch: 7 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004868\n",
      "2399it [01:27, 23.21it/s]Train epoch: 7 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004516\n",
      "2423it [01:28, 23.86it/s]Train epoch: 7 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.003193\n",
      "2450it [01:29, 23.04it/s]Train epoch: 7 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003681\n",
      "2474it [01:30, 22.15it/s]Train epoch: 7 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.004115\n",
      "2498it [01:31, 22.41it/s]Train epoch: 7 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003563\n",
      "2525it [01:32, 22.31it/s]Train epoch: 7 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003491\n",
      "2549it [01:33, 23.85it/s]Train epoch: 7 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004788\n",
      "2573it [01:34, 23.21it/s]Train epoch: 7 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003409\n",
      "2600it [01:36, 23.30it/s]Train epoch: 7 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003708\n",
      "2624it [01:37, 21.51it/s]Train epoch: 7 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003682\n",
      "2648it [01:38, 24.01it/s]Train epoch: 7 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004301\n",
      "2675it [01:39, 22.95it/s]Train epoch: 7 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003904\n",
      "2699it [01:40, 22.30it/s]Train epoch: 7 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003375\n",
      "2723it [01:41, 21.85it/s]Train epoch: 7 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003660\n",
      "2750it [01:42, 23.52it/s]Train epoch: 7 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004336\n",
      "2774it [01:43, 22.27it/s]Train epoch: 7 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003780\n",
      "2798it [01:44, 21.51it/s]Train epoch: 7 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003616\n",
      "2825it [01:46, 23.22it/s]Train epoch: 7 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.004013\n",
      "2849it [01:47, 21.15it/s]Train epoch: 7 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003797\n",
      "2873it [01:48, 22.36it/s]Train epoch: 7 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.004153\n",
      "2900it [01:49, 21.96it/s]Train epoch: 7 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.004080\n",
      "2924it [01:50, 22.59it/s]Train epoch: 7 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.004157\n",
      "2948it [01:51, 22.58it/s]Train epoch: 7 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004298\n",
      "2975it [01:52, 22.77it/s]Train epoch: 7 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.004021\n",
      "2999it [01:53, 21.65it/s]Train epoch: 7 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3023it [01:55, 22.07it/s]Train epoch: 7 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.004214\n",
      "3050it [01:56, 22.03it/s]Train epoch: 7 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003696\n",
      "3074it [01:57, 22.36it/s]Train epoch: 7 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.004213\n",
      "3098it [01:58, 22.13it/s]Train epoch: 7 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.004312\n",
      "3125it [01:59, 22.16it/s]Train epoch: 7 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003877\n",
      "3149it [02:00, 21.03it/s]Train epoch: 7 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003785\n",
      "3173it [02:01, 22.48it/s]Train epoch: 7 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003747\n",
      "3200it [02:03, 20.93it/s]Train epoch: 7 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004330\n",
      "3224it [02:04, 21.07it/s]Train epoch: 7 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004236\n",
      "3248it [02:05, 21.86it/s]Train epoch: 7 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004253\n",
      "3275it [02:06, 21.43it/s]Train epoch: 7 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003855\n",
      "3299it [02:07, 20.40it/s]Train epoch: 7 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004759\n",
      "3323it [02:08, 20.69it/s]Train epoch: 7 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.004035\n",
      "3350it [02:10, 21.24it/s]Train epoch: 7 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.004066\n",
      "3374it [02:11, 20.16it/s]Train epoch: 7 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.004288\n",
      "3398it [02:12, 20.70it/s]Train epoch: 7 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004382\n",
      "3425it [02:13, 20.47it/s]Train epoch: 7 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003809\n",
      "3449it [02:14, 20.29it/s]Train epoch: 7 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004444\n",
      "3473it [02:16, 20.39it/s]Train epoch: 7 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003942\n",
      "3500it [02:17, 21.39it/s]Train epoch: 7 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003985\n",
      "3524it [02:18, 20.84it/s]Train epoch: 7 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.004233\n",
      "3548it [02:19, 21.03it/s]Train epoch: 7 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004541\n",
      "3575it [02:20, 20.91it/s]Train epoch: 7 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003606\n",
      "3599it [02:22, 20.96it/s]Train epoch: 7 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004630\n",
      "3623it [02:23, 21.75it/s]Train epoch: 7 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.004292\n",
      "3650it [02:24, 18.32it/s]Train epoch: 7 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004375\n",
      "3674it [02:25, 17.68it/s]Train epoch: 7 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004430\n",
      "3700it [02:27, 18.76it/s]Train epoch: 7 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004444\n",
      "3725it [02:28, 18.26it/s]Train epoch: 7 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004485\n",
      "3750it [02:30, 17.94it/s]Train epoch: 7 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004519\n",
      "3774it [02:31, 17.34it/s]Train epoch: 7 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004384\n",
      "3800it [02:32, 18.18it/s]Train epoch: 7 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004768\n",
      "3825it [02:34, 18.45it/s]Train epoch: 7 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.004081\n",
      "3849it [02:35, 17.59it/s]Train epoch: 7 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003798\n",
      "3874it [02:37, 17.78it/s]Train epoch: 7 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003700\n",
      "3900it [02:38, 17.35it/s]Train epoch: 7 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004777\n",
      "3925it [02:39, 17.90it/s]Train epoch: 7 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004378\n",
      "3949it [02:41, 17.12it/s]Train epoch: 7 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004760\n",
      "3975it [02:42, 17.45it/s]Train epoch: 7 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.005277\n",
      "3999it [02:44, 18.00it/s]Train epoch: 7 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003982\n",
      "4025it [02:45, 17.68it/s]Train epoch: 7 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004955\n",
      "4049it [02:47, 17.40it/s]Train epoch: 7 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004528\n",
      "4073it [02:48, 18.52it/s]Train epoch: 7 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004494\n",
      "4099it [02:49, 17.26it/s]Train epoch: 7 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004935\n",
      "4125it [02:51, 16.68it/s]Train epoch: 7 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004828\n",
      "4149it [02:52, 16.93it/s]Train epoch: 7 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.004073\n",
      "4174it [02:54, 17.58it/s]Train epoch: 7 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004403\n",
      "4200it [02:55, 17.10it/s]Train epoch: 7 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004757\n",
      "4224it [02:57, 16.79it/s]Train epoch: 7 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.004081\n",
      "4250it [02:58, 16.70it/s]Train epoch: 7 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004632\n",
      "4274it [03:00, 16.75it/s]Train epoch: 7 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004312\n",
      "4300it [03:01, 16.14it/s]Train epoch: 7 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.005033\n",
      "4324it [03:03, 15.94it/s]Train epoch: 7 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004445\n",
      "4350it [03:04, 16.65it/s]Train epoch: 7 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004826\n",
      "4374it [03:06, 17.03it/s]Train epoch: 7 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004285\n",
      "4400it [03:07, 16.70it/s]Train epoch: 7 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003799\n",
      "4424it [03:08, 17.02it/s]Train epoch: 7 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004567\n",
      "4450it [03:10, 17.45it/s]Train epoch: 7 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003687\n",
      "4474it [03:11, 16.78it/s]Train epoch: 7 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004672\n",
      "4500it [03:13, 16.65it/s]Train epoch: 7 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005529\n",
      "4524it [03:14, 16.55it/s]Train epoch: 7 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004688\n",
      "4550it [03:16, 16.37it/s]Train epoch: 7 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004413\n",
      "4574it [03:17, 16.73it/s]Train epoch: 7 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.005110\n",
      "4600it [03:19, 16.32it/s]Train epoch: 7 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004217\n",
      "4624it [03:21, 15.55it/s]Train epoch: 7 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004309\n",
      "4650it [03:22, 16.73it/s]Train epoch: 7 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004923\n",
      "4674it [03:24, 16.21it/s]Train epoch: 7 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004694\n",
      "4700it [03:25, 15.95it/s]Train epoch: 7 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.004191\n",
      "4724it [03:27, 15.99it/s]Train epoch: 7 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004419\n",
      "4750it [03:28, 15.88it/s]Train epoch: 7 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.005137\n",
      "4774it [03:30, 15.61it/s]Train epoch: 7 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004519\n",
      "4800it [03:32, 15.61it/s]Train epoch: 7 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004720\n",
      "4824it [03:33, 15.59it/s]Train epoch: 7 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.004183\n",
      "4850it [03:35, 16.19it/s]Train epoch: 7 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004867\n",
      "4874it [03:36, 16.07it/s]Train epoch: 7 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.004166\n",
      "4900it [03:38, 15.32it/s]Train epoch: 7 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004621\n",
      "4924it [03:39, 15.33it/s]Train epoch: 7 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.004203\n",
      "4950it [03:41, 15.57it/s]Train epoch: 7 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004509\n",
      "4974it [03:43, 15.49it/s]Train epoch: 7 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004529\n",
      "5000it [03:44, 15.84it/s]Train epoch: 7 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004514\n",
      "5024it [03:46, 15.53it/s]Train epoch: 7 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004279\n",
      "5050it [03:48, 15.94it/s]Train epoch: 7 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5074it [03:49, 15.41it/s]Train epoch: 7 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004441\n",
      "5100it [03:51, 15.33it/s]Train epoch: 7 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004522\n",
      "5124it [03:52, 15.43it/s]Train epoch: 7 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004826\n",
      "5150it [03:54, 15.50it/s]Train epoch: 7 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004837\n",
      "5174it [03:56, 14.93it/s]Train epoch: 7 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004769\n",
      "5200it [03:57, 15.40it/s]Train epoch: 7 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004268\n",
      "5224it [03:59, 14.92it/s]Train epoch: 7 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004619\n",
      "5250it [04:01, 16.03it/s]Train epoch: 7 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004497\n",
      "5274it [04:02, 14.76it/s]Train epoch: 7 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004350\n",
      "5300it [04:04, 15.32it/s]Train epoch: 7 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004318\n",
      "5324it [04:05, 15.20it/s]Train epoch: 7 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004838\n",
      "5350it [04:07, 14.71it/s]Train epoch: 7 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004876\n",
      "5374it [04:09, 14.70it/s]Train epoch: 7 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004432\n",
      "5400it [04:10, 15.12it/s]Train epoch: 7 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004394\n",
      "5424it [04:12, 14.94it/s]Train epoch: 7 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004808\n",
      "5450it [04:14, 15.14it/s]Train epoch: 7 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004752\n",
      "5474it [04:15, 14.37it/s]Train epoch: 7 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005492\n",
      "5500it [04:17, 15.14it/s]Train epoch: 7 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.005089\n",
      "5524it [04:19, 14.47it/s]Train epoch: 7 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.004147\n",
      "5550it [04:21, 14.86it/s]Train epoch: 7 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004768\n",
      "5574it [04:22, 14.56it/s]Train epoch: 7 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004853\n",
      "5600it [04:24, 14.86it/s]Train epoch: 7 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.005139\n",
      "5624it [04:26, 14.93it/s]Train epoch: 7 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004746\n",
      "5650it [04:27, 14.67it/s]Train epoch: 7 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004366\n",
      "5674it [04:29, 14.90it/s]Train epoch: 7 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.005321\n",
      "5700it [04:31, 14.68it/s]Train epoch: 7 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004596\n",
      "5724it [04:32, 14.80it/s]Train epoch: 7 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004744\n",
      "5750it [04:34, 14.99it/s]Train epoch: 7 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005885\n",
      "5774it [04:36, 13.97it/s]Train epoch: 7 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.005010\n",
      "5800it [04:38, 14.30it/s]Train epoch: 7 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.005025\n",
      "5824it [04:39, 14.74it/s]Train epoch: 7 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004468\n",
      "5850it [04:41, 14.61it/s]Train epoch: 7 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005615\n",
      "5874it [04:43, 14.89it/s]Train epoch: 7 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005432\n",
      "5900it [04:44, 14.67it/s]Train epoch: 7 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005440\n",
      "5924it [04:46, 14.30it/s]Train epoch: 7 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004448\n",
      "5950it [04:48, 14.14it/s]Train epoch: 7 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004393\n",
      "5974it [04:49, 14.43it/s]Train epoch: 7 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005960\n",
      "6000it [04:51, 14.97it/s]Train epoch: 7 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.005148\n",
      "6024it [04:53, 14.42it/s]Train epoch: 7 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.005288\n",
      "6050it [04:55, 14.60it/s]Train epoch: 7 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004768\n",
      "6074it [04:56, 14.37it/s]Train epoch: 7 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004472\n",
      "6100it [04:58, 14.25it/s]Train epoch: 7 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004264\n",
      "6124it [05:00, 14.47it/s]Train epoch: 7 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004768\n",
      "6150it [05:02, 14.29it/s]Train epoch: 7 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004752\n",
      "6174it [05:03, 14.23it/s]Train epoch: 7 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005468\n",
      "6200it [05:05, 14.39it/s]Train epoch: 7 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004813\n",
      "6224it [05:07, 14.33it/s]Train epoch: 7 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.004202\n",
      "6250it [05:09, 14.50it/s]Train epoch: 7 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004598\n",
      "6274it [05:10, 14.08it/s]Train epoch: 7 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.004126\n",
      "6300it [05:12, 14.18it/s]Train epoch: 7 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004857\n",
      "6324it [05:14, 14.40it/s]Train epoch: 7 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005227\n",
      "6350it [05:16, 13.74it/s]Train epoch: 7 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005564\n",
      "6374it [05:17, 14.30it/s]Train epoch: 7 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004430\n",
      "6400it [05:19, 14.09it/s]Train epoch: 7 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004621\n",
      "6424it [05:21, 13.72it/s]Train epoch: 7 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.005322\n",
      "6450it [05:23, 13.91it/s]Train epoch: 7 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.005152\n",
      "6474it [05:24, 13.76it/s]Train epoch: 7 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004689\n",
      "6500it [05:26, 13.83it/s]Train epoch: 7 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.005305\n",
      "6524it [05:28, 14.39it/s]Train epoch: 7 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004554\n",
      "6550it [05:30, 13.72it/s]Train epoch: 7 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004689\n",
      "6574it [05:32, 13.85it/s]Train epoch: 7 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004894\n",
      "6600it [05:33, 13.71it/s]Train epoch: 7 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005911\n",
      "6624it [05:35, 13.79it/s]Train epoch: 7 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004814\n",
      "6650it [05:37, 13.42it/s]Train epoch: 7 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005442\n",
      "6674it [05:39, 13.37it/s]Train epoch: 7 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.005080\n",
      "6700it [05:41, 14.22it/s]Train epoch: 7 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.005065\n",
      "6724it [05:43, 13.18it/s]Train epoch: 7 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.005162\n",
      "6750it [05:45, 13.73it/s]Train epoch: 7 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004616\n",
      "6774it [05:46, 13.98it/s]Train epoch: 7 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005359\n",
      "6800it [05:48, 13.77it/s]Train epoch: 7 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005270\n",
      "6824it [05:50, 13.49it/s]Train epoch: 7 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005517\n",
      "6850it [05:52, 13.62it/s]Train epoch: 7 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005182\n",
      "6874it [05:54, 13.49it/s]Train epoch: 7 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004339\n",
      "6900it [05:56, 13.15it/s]Train epoch: 7 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.005066\n",
      "6924it [05:58, 13.14it/s]Train epoch: 7 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.005022\n",
      "6950it [06:00, 13.53it/s]Train epoch: 7 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005623\n",
      "6974it [06:01, 13.29it/s]Train epoch: 7 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.005194\n",
      "7000it [06:03, 13.00it/s]Train epoch: 7 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004926\n",
      "7024it [06:05, 13.55it/s]Train epoch: 7 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005742\n",
      "7050it [06:07, 13.51it/s]Train epoch: 7 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004552\n",
      "7074it [06:09, 13.02it/s]Train epoch: 7 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.005004\n",
      "7100it [06:11, 13.47it/s]Train epoch: 7 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7124it [06:13, 13.04it/s]Train epoch: 7 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004668\n",
      "7150it [06:15, 13.24it/s]Train epoch: 7 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005639\n",
      "7174it [06:17, 13.17it/s]Train epoch: 7 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.005160\n",
      "7200it [06:19, 12.99it/s]Train epoch: 7 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005533\n",
      "7224it [06:20, 12.78it/s]Train epoch: 7 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.005061\n",
      "7250it [06:22, 12.85it/s]Train epoch: 7 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.005172\n",
      "7274it [06:24, 12.71it/s]Train epoch: 7 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005596\n",
      "7300it [06:26, 12.67it/s]Train epoch: 7 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.006069\n",
      "7324it [06:28, 13.40it/s]Train epoch: 7 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004870\n",
      "7350it [06:30, 12.62it/s]Train epoch: 7 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005899\n",
      "7374it [06:32, 12.95it/s]Train epoch: 7 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005493\n",
      "7400it [06:34, 12.71it/s]Train epoch: 7 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004969\n",
      "7424it [06:36, 12.74it/s]Train epoch: 7 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005400\n",
      "7450it [06:38, 12.63it/s]Train epoch: 7 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005945\n",
      "7474it [06:40, 12.44it/s]Train epoch: 7 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.005132\n",
      "7500it [06:42, 12.42it/s]Train epoch: 7 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005498\n",
      "7524it [06:44, 12.67it/s]Train epoch: 7 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.005188\n",
      "7550it [06:46, 12.60it/s]Train epoch: 7 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.005070\n",
      "7574it [06:48, 12.91it/s]Train epoch: 7 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005602\n",
      "7600it [06:50, 12.61it/s]Train epoch: 7 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006537\n",
      "7624it [06:52, 12.57it/s]Train epoch: 7 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.006111\n",
      "7650it [06:54, 12.52it/s]Train epoch: 7 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.005197\n",
      "7674it [06:56, 12.78it/s]Train epoch: 7 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.005352\n",
      "7700it [06:58, 12.63it/s]Train epoch: 7 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005393\n",
      "7724it [07:00, 12.60it/s]Train epoch: 7 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005334\n",
      "7750it [07:02, 12.72it/s]Train epoch: 7 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005691\n",
      "7774it [07:04, 12.24it/s]Train epoch: 7 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.005002\n",
      "7800it [07:06, 12.62it/s]Train epoch: 7 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.005222\n",
      "7824it [07:08, 12.48it/s]Train epoch: 7 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005481\n",
      "7850it [07:10, 12.21it/s]Train epoch: 7 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004998\n",
      "7874it [07:12, 11.95it/s]Train epoch: 7 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.005285\n",
      "7900it [07:14, 12.14it/s]Train epoch: 7 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005450\n",
      "7924it [07:16, 12.19it/s]Train epoch: 7 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005441\n",
      "7950it [07:18, 12.33it/s]Train epoch: 7 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.006103\n",
      "7974it [07:20, 12.11it/s]Train epoch: 7 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.005312\n",
      "8000it [07:22, 11.97it/s]Train epoch: 7 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.005133\n",
      "8024it [07:24, 12.36it/s]Train epoch: 7 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005532\n",
      "8050it [07:26, 12.21it/s]Train epoch: 7 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004854\n",
      "8074it [07:28, 11.79it/s]Train epoch: 7 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005399\n",
      "8100it [07:30, 11.91it/s]Train epoch: 7 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005691\n",
      "8124it [07:32, 12.16it/s]Train epoch: 7 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005831\n",
      "8150it [07:35, 11.94it/s]Train epoch: 7 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.005077\n",
      "8174it [07:37, 11.66it/s]Train epoch: 7 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005837\n",
      "8200it [07:39, 11.88it/s]Train epoch: 7 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.005036\n",
      "8224it [07:41, 11.79it/s]Train epoch: 7 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006615\n",
      "8250it [07:43, 12.16it/s]Train epoch: 7 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.005210\n",
      "8274it [07:45, 11.89it/s]Train epoch: 7 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005884\n",
      "8300it [07:47, 11.92it/s]Train epoch: 7 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.005203\n",
      "8324it [07:49, 11.60it/s]Train epoch: 7 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005934\n",
      "8350it [07:51, 11.61it/s]Train epoch: 7 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.005102\n",
      "8374it [07:54, 11.50it/s]Train epoch: 7 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005871\n",
      "8400it [07:56, 11.31it/s]Train epoch: 7 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005419\n",
      "8424it [07:58, 11.55it/s]Train epoch: 7 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005506\n",
      "8450it [08:00, 11.59it/s]Train epoch: 7 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005839\n",
      "8474it [08:02, 11.71it/s]Train epoch: 7 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005550\n",
      "8500it [08:04, 11.50it/s]Train epoch: 7 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006436\n",
      "8524it [08:07, 11.37it/s]Train epoch: 7 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005493\n",
      "8550it [08:09, 11.49it/s]Train epoch: 7 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005779\n",
      "8574it [08:11, 11.22it/s]Train epoch: 7 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005441\n",
      "8600it [08:13, 11.56it/s]Train epoch: 7 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005508\n",
      "8624it [08:15, 11.18it/s]Train epoch: 7 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005642\n",
      "8650it [08:18, 11.26it/s]Train epoch: 7 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005820\n",
      "8674it [08:20, 11.21it/s]Train epoch: 7 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006457\n",
      "8700it [08:22, 11.01it/s]Train epoch: 7 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006486\n",
      "8724it [08:24, 11.33it/s]Train epoch: 7 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.006267\n",
      "8750it [08:27, 11.49it/s]Train epoch: 7 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005966\n",
      "8774it [08:29, 11.58it/s]Train epoch: 7 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005350\n",
      "8800it [08:31, 11.15it/s]Train epoch: 7 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005616\n",
      "8824it [08:33, 11.20it/s]Train epoch: 7 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005748\n",
      "8850it [08:35, 11.02it/s]Train epoch: 7 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005919\n",
      "8874it [08:38, 11.22it/s]Train epoch: 7 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005808\n",
      "8900it [08:40, 10.84it/s]Train epoch: 7 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005824\n",
      "8924it [08:42, 10.84it/s]Train epoch: 7 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005914\n",
      "8950it [08:45, 10.82it/s]Train epoch: 7 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006612\n",
      "8974it [08:47, 10.94it/s]Train epoch: 7 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.006188\n",
      "9000it [08:49, 10.77it/s]Train epoch: 7 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005732\n",
      "9024it [08:51, 11.27it/s]Train epoch: 7 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005856\n",
      "9050it [08:54, 10.69it/s]Train epoch: 7 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005451\n",
      "9074it [08:56, 10.84it/s]Train epoch: 7 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.005155\n",
      "9100it [08:58, 10.66it/s]Train epoch: 7 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.006003\n",
      "9124it [09:01, 10.56it/s]Train epoch: 7 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005683\n",
      "9150it [09:03, 10.98it/s]Train epoch: 7 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.005192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9174it [09:05, 10.62it/s]Train epoch: 7 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005586\n",
      "9200it [09:08, 10.46it/s]Train epoch: 7 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005440\n",
      "9224it [09:10, 10.93it/s]Train epoch: 7 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006536\n",
      "9250it [09:13, 10.37it/s]Train epoch: 7 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005708\n",
      "9274it [09:15, 10.44it/s]Train epoch: 7 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.006145\n",
      "9300it [09:17, 10.40it/s]Train epoch: 7 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006815\n",
      "9324it [09:20, 10.44it/s]Train epoch: 7 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006571\n",
      "9350it [09:22, 10.57it/s]Train epoch: 7 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006520\n",
      "9374it [09:24, 10.15it/s]Train epoch: 7 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005803\n",
      "9400it [09:27, 10.67it/s]Train epoch: 7 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.006082\n",
      "9424it [09:29, 10.19it/s]Train epoch: 7 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005775\n",
      "9450it [09:32, 10.22it/s]Train epoch: 7 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005733\n",
      "9474it [09:34, 10.27it/s]Train epoch: 7 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006444\n",
      "9500it [09:37,  9.97it/s]Train epoch: 7 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.006011\n",
      "9525it [09:39, 10.05it/s]Train epoch: 7 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006525\n",
      "9550it [09:42,  9.88it/s]Train epoch: 7 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006377\n",
      "9574it [09:44, 10.05it/s]Train epoch: 7 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006417\n",
      "9600it [09:47, 10.11it/s]Train epoch: 7 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.006177\n",
      "9624it [09:49,  9.87it/s]Train epoch: 7 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005643\n",
      "9650it [09:52,  9.88it/s]Train epoch: 7 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005730\n",
      "9675it [09:54,  9.85it/s]Train epoch: 7 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.006195\n",
      "9700it [09:57,  9.84it/s]Train epoch: 7 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005504\n",
      "9724it [09:59,  9.91it/s]Train epoch: 7 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.006183\n",
      "9750it [10:02,  9.67it/s]Train epoch: 7 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.006040\n",
      "9775it [10:04,  9.65it/s]Train epoch: 7 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006887\n",
      "9800it [10:07,  9.65it/s]Train epoch: 7 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006554\n",
      "9825it [10:09,  9.62it/s]Train epoch: 7 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006750\n",
      "9849it [10:12,  9.62it/s]Train epoch: 7 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.006098\n",
      "9874it [10:14,  9.56it/s]Train epoch: 7 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006658\n",
      "9900it [10:17,  9.76it/s]Train epoch: 7 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.007050\n",
      "9925it [10:20,  9.56it/s]Train epoch: 7 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006498\n",
      "9950it [10:22,  9.57it/s]Train epoch: 7 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.007207\n",
      "9974it [10:25,  9.34it/s]Train epoch: 7 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006681\n",
      "10000it [10:28,  9.20it/s]Train epoch: 7 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.006197\n",
      "10025it [10:30,  9.26it/s]Train epoch: 7 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.006156\n",
      "10050it [10:33,  9.27it/s]Train epoch: 7 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006703\n",
      "10075it [10:35,  9.38it/s]Train epoch: 7 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.007079\n",
      "10100it [10:38,  9.19it/s]Train epoch: 7 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006712\n",
      "10125it [10:41,  9.02it/s]Train epoch: 7 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.006165\n",
      "10150it [10:43,  9.00it/s]Train epoch: 7 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006643\n",
      "10175it [10:46,  9.06it/s]Train epoch: 7 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.006198\n",
      "10200it [10:49,  9.25it/s]Train epoch: 7 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006787\n",
      "10225it [10:52,  8.77it/s]Train epoch: 7 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006707\n",
      "10250it [10:54,  9.18it/s]Train epoch: 7 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.007203\n",
      "10275it [10:57,  9.22it/s]Train epoch: 7 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006360\n",
      "10300it [11:00,  9.27it/s]Train epoch: 7 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.007049\n",
      "10325it [11:03,  8.97it/s]Train epoch: 7 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006862\n",
      "10350it [11:05,  9.02it/s]Train epoch: 7 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006561\n",
      "10375it [11:08,  9.01it/s]Train epoch: 7 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006813\n",
      "10400it [11:11,  8.85it/s]Train epoch: 7 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006893\n",
      "10425it [11:14,  8.60it/s]Train epoch: 7 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006512\n",
      "10450it [11:17,  8.69it/s]Train epoch: 7 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006868\n",
      "10475it [11:20,  8.52it/s]Train epoch: 7 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.006033\n",
      "10500it [11:23,  8.45it/s]Train epoch: 7 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006846\n",
      "10525it [11:26,  8.25it/s]Train epoch: 7 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006585\n",
      "10550it [11:29,  8.25it/s]Train epoch: 7 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006861\n",
      "10575it [11:32,  8.40it/s]Train epoch: 7 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.006067\n",
      "10600it [11:35,  8.23it/s]Train epoch: 7 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.006314\n",
      "10625it [11:38,  8.39it/s]Train epoch: 7 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.007032\n",
      "10650it [11:41,  8.23it/s]Train epoch: 7 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006426\n",
      "10675it [11:44,  8.34it/s]Train epoch: 7 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006904\n",
      "10700it [11:47,  8.19it/s]Train epoch: 7 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006405\n",
      "10725it [11:50,  8.03it/s]Train epoch: 7 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.006025\n",
      "10750it [11:53,  8.13it/s]Train epoch: 7 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.007196\n",
      "10775it [11:56,  8.02it/s]Train epoch: 7 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.007122\n",
      "10800it [11:59,  8.08it/s]Train epoch: 7 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.007318\n",
      "10825it [12:02,  8.19it/s]Train epoch: 7 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.007232\n",
      "10850it [12:05,  7.90it/s]Train epoch: 7 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.007096\n",
      "10875it [12:09,  7.92it/s]Train epoch: 7 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.007242\n",
      "10900it [12:12,  7.89it/s]Train epoch: 7 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.007007\n",
      "10925it [12:15,  7.81it/s]Train epoch: 7 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006350\n",
      "10950it [12:18,  7.92it/s]Train epoch: 7 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006946\n",
      "10975it [12:21,  7.88it/s]Train epoch: 7 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006768\n",
      "11000it [12:24,  8.07it/s]Train epoch: 7 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006670\n",
      "11025it [12:28,  7.93it/s]Train epoch: 7 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006909\n",
      "11050it [12:31,  7.78it/s]Train epoch: 7 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007683\n",
      "11075it [12:34,  8.04it/s]Train epoch: 7 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.007150\n",
      "11100it [12:37,  7.81it/s]Train epoch: 7 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007891\n",
      "11125it [12:40,  7.76it/s]Train epoch: 7 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007392\n",
      "11150it [12:43,  7.81it/s]Train epoch: 7 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.007101\n",
      "11175it [12:46,  7.89it/s]Train epoch: 7 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.008230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200it [12:50,  7.86it/s]Train epoch: 7 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007387\n",
      "11225it [12:53,  7.87it/s]Train epoch: 7 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007399\n",
      "11250it [12:56,  7.94it/s]Train epoch: 7 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.008013\n",
      "11275it [12:59,  7.95it/s]Train epoch: 7 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007685\n",
      "11300it [13:02,  7.87it/s]Train epoch: 7 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006968\n",
      "11325it [13:05,  7.74it/s]Train epoch: 7 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.008186\n",
      "11350it [13:09,  7.88it/s]Train epoch: 7 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.008180\n",
      "11375it [13:12,  7.96it/s]Train epoch: 7 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.008394\n",
      "11400it [13:15,  8.16it/s]Train epoch: 7 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007369\n",
      "11425it [13:18,  7.67it/s]Train epoch: 7 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007973\n",
      "11450it [13:21,  7.94it/s]Train epoch: 7 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.007168\n",
      "11475it [13:24,  7.73it/s]Train epoch: 7 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008664\n",
      "11500it [13:28,  7.78it/s]Train epoch: 7 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.008306\n",
      "11525it [13:31,  8.27it/s]Train epoch: 7 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007625\n",
      "11550it [13:34,  7.79it/s]Train epoch: 7 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007547\n",
      "11575it [13:37,  8.13it/s]Train epoch: 7 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008715\n",
      "11600it [13:40,  7.83it/s]Train epoch: 7 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.008039\n",
      "11625it [13:43,  7.89it/s]Train epoch: 7 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007552\n",
      "11650it [13:46,  8.15it/s]Train epoch: 7 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.008164\n",
      "11675it [13:50,  7.91it/s]Train epoch: 7 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008616\n",
      "11700it [13:53,  7.92it/s]Train epoch: 7 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.009137\n",
      "11725it [13:56,  7.98it/s]Train epoch: 7 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.009020\n",
      "11750it [13:59,  8.07it/s]Train epoch: 7 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008789\n",
      "11775it [14:02,  7.88it/s]Train epoch: 7 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008894\n",
      "11800it [14:05,  7.68it/s]Train epoch: 7 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008644\n",
      "11825it [14:09,  7.84it/s]Train epoch: 7 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008922\n",
      "11850it [14:12,  7.94it/s]Train epoch: 7 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.009132\n",
      "11875it [14:15,  7.88it/s]Train epoch: 7 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.010033\n",
      "11900it [14:18,  7.83it/s]Train epoch: 7 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.012113\n",
      "11925it [14:21,  7.81it/s]Train epoch: 7 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010223\n",
      "11930it [14:22, 13.83it/s]\n",
      "epoch loss: 0.005158671041396708\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 129.82it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0248, 0.0376, 0.0394, 0.0385, 0.8724\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3117, 0.5464, 0.4206, 0.4753, 0.9805\n",
      "rec_at_8: 0.3403\n",
      "prec_at_8: 0.6324\n",
      "rec_at_15: 0.4728\n",
      "prec_at_15: 0.4878\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 131.39it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0241, 0.0396, 0.0387, 0.0391, 0.8653\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3051, 0.5449, 0.4094, 0.4675, 0.9801\n",
      "rec_at_8: 0.3282\n",
      "prec_at_8: 0.6331\n",
      "rec_at_15: 0.4566\n",
      "prec_at_15: 0.4896\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0248, 0.0376, 0.0394, 0.0385, 0.8724\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3117, 0.5464, 0.4206, 0.4753, 0.9805\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0070\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0241, 0.0396, 0.0387, 0.0391, 0.8653\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3051, 0.5449, 0.4094, 0.4675, 0.9801\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0073\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 8\n",
      "0it [00:00, ?it/s]Train epoch: 8 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006573\n",
      "25it [00:00, 45.63it/s]Train epoch: 8 [batch #25, batch_size 4, seq length 221]\tLoss: 0.004098\n",
      "49it [00:01, 43.84it/s]Train epoch: 8 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003867\n",
      "74it [00:01, 40.32it/s]Train epoch: 8 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003239\n",
      "99it [00:02, 39.94it/s]Train epoch: 8 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003328\n",
      "123it [00:02, 38.79it/s]Train epoch: 8 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003293\n",
      "147it [00:03, 35.36it/s]Train epoch: 8 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003160\n",
      "172it [00:04, 36.66it/s]Train epoch: 8 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003336\n",
      "200it [00:05, 35.00it/s]Train epoch: 8 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003096\n",
      "222it [00:05, 37.10it/s]Train epoch: 8 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003964\n",
      "250it [00:06, 32.10it/s]Train epoch: 8 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003229\n",
      "274it [00:07, 34.69it/s]Train epoch: 8 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002747\n",
      "298it [00:07, 33.28it/s]Train epoch: 8 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003566\n",
      "323it [00:08, 32.19it/s]Train epoch: 8 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002985\n",
      "347it [00:09, 33.71it/s]Train epoch: 8 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003506\n",
      "375it [00:10, 29.86it/s]Train epoch: 8 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003327\n",
      "400it [00:11, 29.59it/s]Train epoch: 8 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003401\n",
      "422it [00:11, 30.51it/s]Train epoch: 8 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003375\n",
      "450it [00:12, 31.47it/s]Train epoch: 8 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003343\n",
      "474it [00:13, 30.28it/s]Train epoch: 8 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003722\n",
      "498it [00:14, 30.84it/s]Train epoch: 8 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003204\n",
      "522it [00:15, 29.81it/s]Train epoch: 8 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003498\n",
      "550it [00:16, 31.64it/s]Train epoch: 8 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003421\n",
      "574it [00:16, 28.85it/s]Train epoch: 8 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003379\n",
      "600it [00:17, 29.26it/s]Train epoch: 8 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003651\n",
      "624it [00:18, 29.06it/s]Train epoch: 8 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003496\n",
      "647it [00:19, 30.30it/s]Train epoch: 8 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003168\n",
      "675it [00:20, 26.47it/s]Train epoch: 8 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002700\n",
      "699it [00:21, 28.54it/s]Train epoch: 8 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003343\n",
      "724it [00:22, 26.71it/s]Train epoch: 8 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003505\n",
      "748it [00:22, 28.67it/s]Train epoch: 8 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003246\n",
      "773it [00:23, 27.64it/s]Train epoch: 8 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003621\n",
      "800it [00:24, 28.03it/s]Train epoch: 8 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003529\n",
      "823it [00:25, 29.62it/s]Train epoch: 8 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003369\n",
      "848it [00:26, 27.82it/s]Train epoch: 8 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003869\n",
      "873it [00:27, 28.28it/s]Train epoch: 8 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003186\n",
      "898it [00:28, 27.85it/s]Train epoch: 8 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923it [00:29, 27.50it/s]Train epoch: 8 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003297\n",
      "949it [00:30, 26.81it/s]Train epoch: 8 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003285\n",
      "975it [00:31, 28.90it/s]Train epoch: 8 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002559\n",
      "998it [00:31, 29.14it/s]Train epoch: 8 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003400\n",
      "1025it [00:32, 27.81it/s]Train epoch: 8 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004634\n",
      "1048it [00:33, 28.67it/s]Train epoch: 8 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003209\n",
      "1072it [00:34, 29.92it/s]Train epoch: 8 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003628\n",
      "1099it [00:35, 28.64it/s]Train epoch: 8 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003685\n",
      "1125it [00:36, 25.92it/s]Train epoch: 8 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003746\n",
      "1150it [00:37, 26.66it/s]Train epoch: 8 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003761\n",
      "1175it [00:38, 27.23it/s]Train epoch: 8 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003655\n",
      "1200it [00:39, 28.01it/s]Train epoch: 8 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003806\n",
      "1224it [00:39, 26.68it/s]Train epoch: 8 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003893\n",
      "1250it [00:40, 27.93it/s]Train epoch: 8 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003617\n",
      "1275it [00:41, 26.66it/s]Train epoch: 8 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003195\n",
      "1299it [00:42, 27.14it/s]Train epoch: 8 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003235\n",
      "1323it [00:43, 26.29it/s]Train epoch: 8 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003257\n",
      "1348it [00:44, 26.35it/s]Train epoch: 8 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004358\n",
      "1375it [00:45, 25.71it/s]Train epoch: 8 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003564\n",
      "1400it [00:46, 26.10it/s]Train epoch: 8 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003496\n",
      "1425it [00:47, 26.57it/s]Train epoch: 8 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003161\n",
      "1449it [00:48, 26.20it/s]Train epoch: 8 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003405\n",
      "1473it [00:49, 26.38it/s]Train epoch: 8 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003571\n",
      "1499it [00:50, 26.64it/s]Train epoch: 8 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004717\n",
      "1523it [00:51, 24.49it/s]Train epoch: 8 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004446\n",
      "1550it [00:52, 24.08it/s]Train epoch: 8 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003445\n",
      "1574it [00:53, 25.83it/s]Train epoch: 8 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003763\n",
      "1598it [00:54, 24.07it/s]Train epoch: 8 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003238\n",
      "1625it [00:55, 27.16it/s]Train epoch: 8 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003931\n",
      "1649it [00:56, 25.73it/s]Train epoch: 8 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.004058\n",
      "1673it [00:57, 25.21it/s]Train epoch: 8 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003862\n",
      "1700it [00:58, 24.98it/s]Train epoch: 8 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003352\n",
      "1724it [00:59, 25.95it/s]Train epoch: 8 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002971\n",
      "1748it [01:00, 24.31it/s]Train epoch: 8 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004414\n",
      "1775it [01:01, 24.39it/s]Train epoch: 8 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003680\n",
      "1799it [01:02, 24.96it/s]Train epoch: 8 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003619\n",
      "1823it [01:03, 23.60it/s]Train epoch: 8 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.003041\n",
      "1850it [01:04, 22.95it/s]Train epoch: 8 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003732\n",
      "1874it [01:05, 25.20it/s]Train epoch: 8 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.004051\n",
      "1898it [01:06, 23.92it/s]Train epoch: 8 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.003025\n",
      "1925it [01:07, 24.50it/s]Train epoch: 8 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003221\n",
      "1949it [01:08, 23.87it/s]Train epoch: 8 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003244\n",
      "1973it [01:09, 24.43it/s]Train epoch: 8 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003790\n",
      "2000it [01:10, 25.07it/s]Train epoch: 8 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.003080\n",
      "2024it [01:11, 25.08it/s]Train epoch: 8 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003744\n",
      "2048it [01:12, 23.59it/s]Train epoch: 8 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003515\n",
      "2075it [01:13, 24.40it/s]Train epoch: 8 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003609\n",
      "2099it [01:14, 24.30it/s]Train epoch: 8 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003813\n",
      "2123it [01:15, 25.68it/s]Train epoch: 8 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.004067\n",
      "2150it [01:16, 23.79it/s]Train epoch: 8 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003470\n",
      "2174it [01:17, 24.59it/s]Train epoch: 8 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003944\n",
      "2198it [01:18, 25.08it/s]Train epoch: 8 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003760\n",
      "2225it [01:19, 24.28it/s]Train epoch: 8 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003529\n",
      "2249it [01:20, 23.39it/s]Train epoch: 8 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003403\n",
      "2273it [01:21, 24.51it/s]Train epoch: 8 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003710\n",
      "2300it [01:23, 21.94it/s]Train epoch: 8 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002878\n",
      "2324it [01:24, 22.57it/s]Train epoch: 8 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003572\n",
      "2348it [01:25, 22.74it/s]Train epoch: 8 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003323\n",
      "2375it [01:26, 23.30it/s]Train epoch: 8 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004719\n",
      "2399it [01:27, 23.00it/s]Train epoch: 8 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004446\n",
      "2423it [01:28, 23.68it/s]Train epoch: 8 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.003119\n",
      "2450it [01:29, 23.77it/s]Train epoch: 8 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003589\n",
      "2474it [01:30, 22.85it/s]Train epoch: 8 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.004028\n",
      "2498it [01:31, 23.65it/s]Train epoch: 8 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003499\n",
      "2525it [01:32, 23.86it/s]Train epoch: 8 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003397\n",
      "2549it [01:33, 24.41it/s]Train epoch: 8 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004712\n",
      "2573it [01:34, 22.80it/s]Train epoch: 8 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003335\n",
      "2600it [01:35, 23.75it/s]Train epoch: 8 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003631\n",
      "2624it [01:37, 23.72it/s]Train epoch: 8 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003638\n",
      "2648it [01:38, 22.84it/s]Train epoch: 8 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004239\n",
      "2675it [01:39, 21.41it/s]Train epoch: 8 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003781\n",
      "2699it [01:40, 21.10it/s]Train epoch: 8 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003319\n",
      "2723it [01:41, 20.54it/s]Train epoch: 8 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003598\n",
      "2750it [01:42, 21.68it/s]Train epoch: 8 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004268\n",
      "2774it [01:43, 21.77it/s]Train epoch: 8 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003742\n",
      "2798it [01:45, 22.03it/s]Train epoch: 8 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003484\n",
      "2825it [01:46, 21.93it/s]Train epoch: 8 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003898\n",
      "2849it [01:47, 21.93it/s]Train epoch: 8 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003704\n",
      "2873it [01:48, 21.48it/s]Train epoch: 8 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.004059\n",
      "2900it [01:49, 21.22it/s]Train epoch: 8 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003982\n",
      "2924it [01:50, 20.80it/s]Train epoch: 8 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.004108\n",
      "2948it [01:52, 21.16it/s]Train epoch: 8 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004214\n",
      "2975it [01:53, 22.70it/s]Train epoch: 8 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2999it [01:54, 20.94it/s]Train epoch: 8 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004506\n",
      "3023it [01:55, 21.59it/s]Train epoch: 8 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.004119\n",
      "3050it [01:56, 21.98it/s]Train epoch: 8 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003643\n",
      "3074it [01:57, 21.70it/s]Train epoch: 8 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.004145\n",
      "3098it [01:58, 21.72it/s]Train epoch: 8 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.004203\n",
      "3125it [02:00, 21.24it/s]Train epoch: 8 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003801\n",
      "3149it [02:01, 21.29it/s]Train epoch: 8 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003643\n",
      "3173it [02:02, 21.46it/s]Train epoch: 8 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003649\n",
      "3200it [02:03, 21.75it/s]Train epoch: 8 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004283\n",
      "3224it [02:04, 21.09it/s]Train epoch: 8 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004157\n",
      "3248it [02:05, 22.24it/s]Train epoch: 8 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004148\n",
      "3275it [02:07, 21.27it/s]Train epoch: 8 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003742\n",
      "3299it [02:08, 20.03it/s]Train epoch: 8 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004704\n",
      "3323it [02:09, 21.35it/s]Train epoch: 8 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003953\n",
      "3350it [02:10, 20.93it/s]Train epoch: 8 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003984\n",
      "3374it [02:11, 20.72it/s]Train epoch: 8 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.004169\n",
      "3398it [02:13, 21.05it/s]Train epoch: 8 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004253\n",
      "3425it [02:14, 20.69it/s]Train epoch: 8 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003704\n",
      "3449it [02:15, 20.76it/s]Train epoch: 8 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004340\n",
      "3475it [02:16, 20.20it/s]Train epoch: 8 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003900\n",
      "3498it [02:17, 20.45it/s]Train epoch: 8 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003949\n",
      "3525it [02:19, 20.34it/s]Train epoch: 8 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.004128\n",
      "3549it [02:20, 21.13it/s]Train epoch: 8 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004434\n",
      "3573it [02:21, 20.69it/s]Train epoch: 8 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003528\n",
      "3600it [02:22, 20.91it/s]Train epoch: 8 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004557\n",
      "3624it [02:24, 20.07it/s]Train epoch: 8 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.004180\n",
      "3650it [02:25, 18.71it/s]Train epoch: 8 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004283\n",
      "3674it [02:26, 18.38it/s]Train epoch: 8 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004307\n",
      "3700it [02:28, 17.87it/s]Train epoch: 8 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004374\n",
      "3725it [02:29, 17.95it/s]Train epoch: 8 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004393\n",
      "3750it [02:31, 18.26it/s]Train epoch: 8 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004428\n",
      "3774it [02:32, 17.68it/s]Train epoch: 8 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004270\n",
      "3800it [02:33, 17.79it/s]Train epoch: 8 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004692\n",
      "3824it [02:35, 17.99it/s]Train epoch: 8 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003982\n",
      "3850it [02:36, 16.20it/s]Train epoch: 8 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003745\n",
      "3874it [02:38, 16.34it/s]Train epoch: 8 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003632\n",
      "3900it [02:39, 16.79it/s]Train epoch: 8 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004694\n",
      "3925it [02:41, 16.95it/s]Train epoch: 8 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004246\n",
      "3949it [02:42, 17.01it/s]Train epoch: 8 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004674\n",
      "3975it [02:44, 17.44it/s]Train epoch: 8 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.005263\n",
      "3999it [02:45, 16.80it/s]Train epoch: 8 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003914\n",
      "4025it [02:47, 17.37it/s]Train epoch: 8 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004869\n",
      "4049it [02:48, 17.40it/s]Train epoch: 8 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004432\n",
      "4074it [02:49, 17.54it/s]Train epoch: 8 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004408\n",
      "4100it [02:51, 17.18it/s]Train epoch: 8 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004874\n",
      "4124it [02:52, 16.13it/s]Train epoch: 8 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004720\n",
      "4150it [02:54, 17.22it/s]Train epoch: 8 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.004033\n",
      "4174it [02:56, 15.94it/s]Train epoch: 8 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004302\n",
      "4200it [02:57, 16.42it/s]Train epoch: 8 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004670\n",
      "4224it [02:59, 16.75it/s]Train epoch: 8 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003974\n",
      "4250it [03:00, 16.64it/s]Train epoch: 8 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004547\n",
      "4274it [03:02, 16.42it/s]Train epoch: 8 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004198\n",
      "4300it [03:03, 16.90it/s]Train epoch: 8 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004957\n",
      "4324it [03:04, 17.25it/s]Train epoch: 8 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004307\n",
      "4350it [03:06, 17.42it/s]Train epoch: 8 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004735\n",
      "4374it [03:07, 17.18it/s]Train epoch: 8 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004234\n",
      "4400it [03:09, 17.42it/s]Train epoch: 8 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003710\n",
      "4425it [03:10, 16.81it/s]Train epoch: 8 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004478\n",
      "4449it [03:12, 16.48it/s]Train epoch: 8 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003602\n",
      "4475it [03:13, 16.28it/s]Train epoch: 8 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004595\n",
      "4499it [03:15, 15.53it/s]Train epoch: 8 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005365\n",
      "4525it [03:17, 16.31it/s]Train epoch: 8 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004598\n",
      "4549it [03:18, 16.59it/s]Train epoch: 8 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004336\n",
      "4575it [03:20, 16.16it/s]Train epoch: 8 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004967\n",
      "4599it [03:21, 16.65it/s]Train epoch: 8 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004097\n",
      "4625it [03:23, 15.56it/s]Train epoch: 8 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004176\n",
      "4649it [03:24, 16.12it/s]Train epoch: 8 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004822\n",
      "4675it [03:26, 15.55it/s]Train epoch: 8 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004513\n",
      "4699it [03:27, 15.43it/s]Train epoch: 8 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.004119\n",
      "4725it [03:29, 15.87it/s]Train epoch: 8 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004346\n",
      "4749it [03:31, 15.68it/s]Train epoch: 8 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.005049\n",
      "4775it [03:32, 16.00it/s]Train epoch: 8 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004447\n",
      "4799it [03:34, 15.14it/s]Train epoch: 8 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004639\n",
      "4825it [03:36, 14.78it/s]Train epoch: 8 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.004102\n",
      "4849it [03:37, 15.93it/s]Train epoch: 8 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004756\n",
      "4875it [03:39, 15.22it/s]Train epoch: 8 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.004086\n",
      "4899it [03:40, 15.77it/s]Train epoch: 8 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004496\n",
      "4925it [03:42, 15.64it/s]Train epoch: 8 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.004090\n",
      "4949it [03:44, 14.57it/s]Train epoch: 8 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004416\n",
      "4975it [03:45, 15.63it/s]Train epoch: 8 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004527\n",
      "4999it [03:47, 15.65it/s]Train epoch: 8 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004409\n",
      "5025it [03:49, 15.71it/s]Train epoch: 8 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5049it [03:50, 15.63it/s]Train epoch: 8 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004135\n",
      "5075it [03:52, 14.98it/s]Train epoch: 8 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004382\n",
      "5099it [03:53, 15.14it/s]Train epoch: 8 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004484\n",
      "5125it [03:55, 15.37it/s]Train epoch: 8 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004722\n",
      "5149it [03:57, 15.85it/s]Train epoch: 8 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004754\n",
      "5175it [03:58, 14.57it/s]Train epoch: 8 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004635\n",
      "5199it [04:00, 14.26it/s]Train epoch: 8 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004202\n",
      "5225it [04:02, 15.83it/s]Train epoch: 8 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004515\n",
      "5249it [04:04, 14.54it/s]Train epoch: 8 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004447\n",
      "5275it [04:05, 15.87it/s]Train epoch: 8 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004275\n",
      "5299it [04:07, 15.15it/s]Train epoch: 8 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004163\n",
      "5325it [04:09, 14.58it/s]Train epoch: 8 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004679\n",
      "5349it [04:10, 15.22it/s]Train epoch: 8 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004771\n",
      "5375it [04:12, 14.83it/s]Train epoch: 8 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004328\n",
      "5399it [04:13, 15.19it/s]Train epoch: 8 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004373\n",
      "5425it [04:15, 15.06it/s]Train epoch: 8 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004774\n",
      "5449it [04:17, 14.26it/s]Train epoch: 8 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004720\n",
      "5475it [04:19, 14.39it/s]Train epoch: 8 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005354\n",
      "5499it [04:20, 13.91it/s]Train epoch: 8 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004950\n",
      "5525it [04:22, 14.64it/s]Train epoch: 8 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.004073\n",
      "5549it [04:24, 13.92it/s]Train epoch: 8 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004670\n",
      "5575it [04:26, 14.00it/s]Train epoch: 8 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004724\n",
      "5599it [04:27, 14.52it/s]Train epoch: 8 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.005054\n",
      "5625it [04:29, 14.25it/s]Train epoch: 8 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004699\n",
      "5649it [04:31, 14.62it/s]Train epoch: 8 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004242\n",
      "5675it [04:33, 14.59it/s]Train epoch: 8 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.005233\n",
      "5699it [04:34, 14.74it/s]Train epoch: 8 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004517\n",
      "5725it [04:36, 13.74it/s]Train epoch: 8 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004694\n",
      "5749it [04:38, 14.18it/s]Train epoch: 8 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005750\n",
      "5775it [04:40, 14.49it/s]Train epoch: 8 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004925\n",
      "5799it [04:41, 14.40it/s]Train epoch: 8 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004956\n",
      "5825it [04:43, 14.56it/s]Train epoch: 8 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004398\n",
      "5849it [04:45, 14.46it/s]Train epoch: 8 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005572\n",
      "5875it [04:47, 13.99it/s]Train epoch: 8 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005331\n",
      "5899it [04:48, 14.09it/s]Train epoch: 8 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005323\n",
      "5925it [04:50, 13.11it/s]Train epoch: 8 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004329\n",
      "5949it [04:52, 14.40it/s]Train epoch: 8 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004300\n",
      "5975it [04:54, 14.14it/s]Train epoch: 8 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005848\n",
      "5999it [04:56, 13.85it/s]Train epoch: 8 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004996\n",
      "6025it [04:57, 14.21it/s]Train epoch: 8 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.005152\n",
      "6049it [04:59, 13.77it/s]Train epoch: 8 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004651\n",
      "6075it [05:01, 14.47it/s]Train epoch: 8 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004388\n",
      "6099it [05:03, 14.16it/s]Train epoch: 8 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004214\n",
      "6125it [05:04, 13.83it/s]Train epoch: 8 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004726\n",
      "6149it [05:06, 14.31it/s]Train epoch: 8 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004677\n",
      "6175it [05:08, 13.98it/s]Train epoch: 8 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005402\n",
      "6199it [05:10, 14.33it/s]Train epoch: 8 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004700\n",
      "6225it [05:11, 13.94it/s]Train epoch: 8 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.004150\n",
      "6249it [05:13, 12.98it/s]Train epoch: 8 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004500\n",
      "6275it [05:15, 13.92it/s]Train epoch: 8 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.004022\n",
      "6299it [05:17, 13.97it/s]Train epoch: 8 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004763\n",
      "6325it [05:19, 13.79it/s]Train epoch: 8 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005155\n",
      "6349it [05:20, 14.21it/s]Train epoch: 8 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005516\n",
      "6375it [05:22, 13.73it/s]Train epoch: 8 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004353\n",
      "6399it [05:24, 13.86it/s]Train epoch: 8 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004508\n",
      "6425it [05:26, 13.82it/s]Train epoch: 8 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.005286\n",
      "6449it [05:28, 12.95it/s]Train epoch: 8 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.005115\n",
      "6475it [05:30, 13.65it/s]Train epoch: 8 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004608\n",
      "6499it [05:31, 13.68it/s]Train epoch: 8 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.005211\n",
      "6525it [05:33, 13.49it/s]Train epoch: 8 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004485\n",
      "6549it [05:35, 13.46it/s]Train epoch: 8 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004614\n",
      "6575it [05:37, 13.71it/s]Train epoch: 8 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004780\n",
      "6599it [05:39, 12.81it/s]Train epoch: 8 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005788\n",
      "6625it [05:41, 13.62it/s]Train epoch: 8 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004738\n",
      "6649it [05:43, 13.44it/s]Train epoch: 8 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005342\n",
      "6675it [05:45, 13.49it/s]Train epoch: 8 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004943\n",
      "6699it [05:46, 13.16it/s]Train epoch: 8 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.005023\n",
      "6725it [05:48, 13.32it/s]Train epoch: 8 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.005043\n",
      "6749it [05:50, 13.79it/s]Train epoch: 8 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004526\n",
      "6775it [05:52, 13.48it/s]Train epoch: 8 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005247\n",
      "6799it [05:54, 13.54it/s]Train epoch: 8 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005214\n",
      "6825it [05:56, 12.80it/s]Train epoch: 8 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005436\n",
      "6849it [05:58, 13.63it/s]Train epoch: 8 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005135\n",
      "6875it [06:00, 13.44it/s]Train epoch: 8 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004220\n",
      "6899it [06:01, 13.40it/s]Train epoch: 8 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004985\n",
      "6925it [06:03, 13.36it/s]Train epoch: 8 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004912\n",
      "6949it [06:05, 13.15it/s]Train epoch: 8 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005514\n",
      "6975it [06:07, 13.30it/s]Train epoch: 8 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.005122\n",
      "6999it [06:09, 12.73it/s]Train epoch: 8 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004810\n",
      "7025it [06:11, 13.23it/s]Train epoch: 8 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005599\n",
      "7049it [06:13, 13.68it/s]Train epoch: 8 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004493\n",
      "7075it [06:15, 12.88it/s]Train epoch: 8 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7099it [06:17, 12.73it/s]Train epoch: 8 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005351\n",
      "7125it [06:19, 12.76it/s]Train epoch: 8 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004589\n",
      "7149it [06:20, 13.09it/s]Train epoch: 8 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005578\n",
      "7175it [06:22, 13.27it/s]Train epoch: 8 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.005103\n",
      "7199it [06:24, 12.97it/s]Train epoch: 8 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005475\n",
      "7225it [06:26, 12.88it/s]Train epoch: 8 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004921\n",
      "7249it [06:28, 13.08it/s]Train epoch: 8 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.005101\n",
      "7275it [06:30, 13.14it/s]Train epoch: 8 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005509\n",
      "7299it [06:32, 12.65it/s]Train epoch: 8 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005982\n",
      "7325it [06:34, 12.85it/s]Train epoch: 8 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004791\n",
      "7349it [06:36, 12.97it/s]Train epoch: 8 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005750\n",
      "7375it [06:38, 12.81it/s]Train epoch: 8 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005398\n",
      "7399it [06:40, 12.80it/s]Train epoch: 8 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004886\n",
      "7425it [06:42, 12.67it/s]Train epoch: 8 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005286\n",
      "7449it [06:44, 12.87it/s]Train epoch: 8 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005900\n",
      "7475it [06:46, 12.75it/s]Train epoch: 8 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.005065\n",
      "7499it [06:48, 12.63it/s]Train epoch: 8 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005375\n",
      "7525it [06:50, 12.53it/s]Train epoch: 8 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.005092\n",
      "7549it [06:52, 12.68it/s]Train epoch: 8 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004943\n",
      "7575it [06:54, 13.00it/s]Train epoch: 8 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005526\n",
      "7599it [06:56, 12.58it/s]Train epoch: 8 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006440\n",
      "7625it [06:58, 12.53it/s]Train epoch: 8 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.006036\n",
      "7649it [07:00, 12.02it/s]Train epoch: 8 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.005073\n",
      "7675it [07:02, 12.58it/s]Train epoch: 8 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.005240\n",
      "7699it [07:04, 12.28it/s]Train epoch: 8 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005296\n",
      "7725it [07:06, 12.32it/s]Train epoch: 8 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005273\n",
      "7749it [07:08, 12.07it/s]Train epoch: 8 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005566\n",
      "7775it [07:10, 12.09it/s]Train epoch: 8 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004907\n",
      "7799it [07:12, 12.63it/s]Train epoch: 8 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.005130\n",
      "7825it [07:14, 11.99it/s]Train epoch: 8 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005382\n",
      "7849it [07:16, 11.92it/s]Train epoch: 8 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004928\n",
      "7875it [07:18, 11.97it/s]Train epoch: 8 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.005150\n",
      "7899it [07:20, 12.19it/s]Train epoch: 8 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005344\n",
      "7925it [07:22, 11.58it/s]Train epoch: 8 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005341\n",
      "7949it [07:24, 11.91it/s]Train epoch: 8 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005939\n",
      "7975it [07:27, 12.02it/s]Train epoch: 8 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.005213\n",
      "7999it [07:29, 12.30it/s]Train epoch: 8 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.005031\n",
      "8025it [07:31, 12.04it/s]Train epoch: 8 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005420\n",
      "8049it [07:33, 10.99it/s]Train epoch: 8 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004718\n",
      "8075it [07:35, 11.38it/s]Train epoch: 8 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005270\n",
      "8099it [07:37, 12.05it/s]Train epoch: 8 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005601\n",
      "8125it [07:40, 11.79it/s]Train epoch: 8 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005751\n",
      "8149it [07:42, 10.73it/s]Train epoch: 8 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004978\n",
      "8175it [07:44, 11.04it/s]Train epoch: 8 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005749\n",
      "8199it [07:46, 11.37it/s]Train epoch: 8 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004972\n",
      "8225it [07:48, 11.72it/s]Train epoch: 8 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006476\n",
      "8249it [07:51, 11.77it/s]Train epoch: 8 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.005108\n",
      "8275it [07:53, 11.53it/s]Train epoch: 8 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005760\n",
      "8299it [07:55, 11.74it/s]Train epoch: 8 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.005156\n",
      "8325it [07:57, 11.51it/s]Train epoch: 8 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005798\n",
      "8349it [07:59, 11.00it/s]Train epoch: 8 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004990\n",
      "8375it [08:01, 11.65it/s]Train epoch: 8 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005753\n",
      "8399it [08:04, 11.46it/s]Train epoch: 8 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005356\n",
      "8425it [08:06, 11.67it/s]Train epoch: 8 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005374\n",
      "8449it [08:08, 11.37it/s]Train epoch: 8 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005738\n",
      "8475it [08:10, 11.40it/s]Train epoch: 8 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005412\n",
      "8499it [08:12, 11.36it/s]Train epoch: 8 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006346\n",
      "8525it [08:15, 11.41it/s]Train epoch: 8 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005423\n",
      "8549it [08:17, 10.99it/s]Train epoch: 8 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005627\n",
      "8575it [08:19, 11.28it/s]Train epoch: 8 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005341\n",
      "8599it [08:21, 11.18it/s]Train epoch: 8 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005446\n",
      "8625it [08:24, 11.12it/s]Train epoch: 8 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005554\n",
      "8649it [08:26, 11.31it/s]Train epoch: 8 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005717\n",
      "8675it [08:28, 11.12it/s]Train epoch: 8 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006356\n",
      "8699it [08:30, 10.63it/s]Train epoch: 8 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006357\n",
      "8725it [08:33, 11.20it/s]Train epoch: 8 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.006181\n",
      "8749it [08:35, 11.01it/s]Train epoch: 8 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005840\n",
      "8775it [08:37, 11.00it/s]Train epoch: 8 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005281\n",
      "8799it [08:40, 10.32it/s]Train epoch: 8 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005533\n",
      "8824it [08:42, 10.39it/s]Train epoch: 8 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005645\n",
      "8850it [08:45, 10.35it/s]Train epoch: 8 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005855\n",
      "8874it [08:47, 10.33it/s]Train epoch: 8 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005606\n",
      "8900it [08:49, 10.67it/s]Train epoch: 8 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005700\n",
      "8924it [08:52, 10.93it/s]Train epoch: 8 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005808\n",
      "8950it [08:54, 10.72it/s]Train epoch: 8 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006499\n",
      "8974it [08:56, 10.49it/s]Train epoch: 8 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.006068\n",
      "9000it [08:59, 10.70it/s]Train epoch: 8 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005650\n",
      "9024it [09:01, 10.65it/s]Train epoch: 8 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005808\n",
      "9050it [09:03, 10.79it/s]Train epoch: 8 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005376\n",
      "9074it [09:06, 10.41it/s]Train epoch: 8 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.005059\n",
      "9100it [09:08, 10.54it/s]Train epoch: 8 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005917\n",
      "9124it [09:11, 10.29it/s]Train epoch: 8 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9150it [09:13, 10.92it/s]Train epoch: 8 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.005094\n",
      "9174it [09:15, 10.33it/s]Train epoch: 8 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005472\n",
      "9200it [09:18, 10.55it/s]Train epoch: 8 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005384\n",
      "9224it [09:20, 10.62it/s]Train epoch: 8 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006429\n",
      "9250it [09:22, 10.65it/s]Train epoch: 8 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005607\n",
      "9274it [09:25, 10.27it/s]Train epoch: 8 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.006001\n",
      "9300it [09:27,  9.94it/s]Train epoch: 8 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006670\n",
      "9324it [09:30,  9.94it/s]Train epoch: 8 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006458\n",
      "9349it [09:32, 10.57it/s]Train epoch: 8 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006374\n",
      "9374it [09:35, 10.31it/s]Train epoch: 8 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005745\n",
      "9400it [09:37, 10.18it/s]Train epoch: 8 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005980\n",
      "9425it [09:40,  9.66it/s]Train epoch: 8 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005707\n",
      "9450it [09:42,  9.94it/s]Train epoch: 8 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005626\n",
      "9475it [09:45,  9.98it/s]Train epoch: 8 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006331\n",
      "9500it [09:47,  9.88it/s]Train epoch: 8 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005970\n",
      "9525it [09:50,  9.38it/s]Train epoch: 8 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006427\n",
      "9550it [09:53,  9.38it/s]Train epoch: 8 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006274\n",
      "9575it [09:55,  8.85it/s]Train epoch: 8 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006349\n",
      "9600it [09:58,  9.52it/s]Train epoch: 8 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.006116\n",
      "9624it [10:01,  9.48it/s]Train epoch: 8 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005551\n",
      "9650it [10:03,  9.50it/s]Train epoch: 8 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005644\n",
      "9675it [10:06,  9.77it/s]Train epoch: 8 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.006128\n",
      "9700it [10:08,  9.71it/s]Train epoch: 8 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005422\n",
      "9725it [10:11,  9.45it/s]Train epoch: 8 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.006071\n",
      "9750it [10:13,  9.45it/s]Train epoch: 8 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005937\n",
      "9775it [10:16,  9.44it/s]Train epoch: 8 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006737\n",
      "9800it [10:19,  9.00it/s]Train epoch: 8 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006487\n",
      "9825it [10:21,  9.58it/s]Train epoch: 8 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006614\n",
      "9850it [10:24,  9.43it/s]Train epoch: 8 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.006020\n",
      "9875it [10:27,  9.35it/s]Train epoch: 8 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006497\n",
      "9900it [10:29,  9.58it/s]Train epoch: 8 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006899\n",
      "9925it [10:32,  8.78it/s]Train epoch: 8 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006394\n",
      "9950it [10:35,  9.13it/s]Train epoch: 8 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.007079\n",
      "9975it [10:37,  9.57it/s]Train epoch: 8 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006594\n",
      "10000it [10:40,  9.06it/s]Train epoch: 8 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.006113\n",
      "10025it [10:43,  8.72it/s]Train epoch: 8 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.006070\n",
      "10050it [10:46,  9.29it/s]Train epoch: 8 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006576\n",
      "10075it [10:49,  8.42it/s]Train epoch: 8 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006966\n",
      "10100it [10:51,  8.50it/s]Train epoch: 8 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006609\n",
      "10125it [10:54,  8.95it/s]Train epoch: 8 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.006057\n",
      "10150it [10:57,  9.00it/s]Train epoch: 8 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006584\n",
      "10175it [11:00,  8.99it/s]Train epoch: 8 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.006129\n",
      "10200it [11:03,  8.31it/s]Train epoch: 8 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006672\n",
      "10225it [11:05,  9.04it/s]Train epoch: 8 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006621\n",
      "10250it [11:08,  8.96it/s]Train epoch: 8 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.007080\n",
      "10275it [11:11,  8.97it/s]Train epoch: 8 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006263\n",
      "10300it [11:14,  8.79it/s]Train epoch: 8 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006991\n",
      "10325it [11:17,  8.80it/s]Train epoch: 8 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006764\n",
      "10350it [11:20,  8.61it/s]Train epoch: 8 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006443\n",
      "10375it [11:22,  8.69it/s]Train epoch: 8 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006719\n",
      "10400it [11:25,  8.49it/s]Train epoch: 8 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006780\n",
      "10425it [11:28,  8.34it/s]Train epoch: 8 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006323\n",
      "10450it [11:31,  8.29it/s]Train epoch: 8 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006761\n",
      "10475it [11:34,  8.38it/s]Train epoch: 8 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005899\n",
      "10500it [11:37,  8.56it/s]Train epoch: 8 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006741\n",
      "10525it [11:40,  8.57it/s]Train epoch: 8 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006447\n",
      "10550it [11:43,  8.32it/s]Train epoch: 8 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006776\n",
      "10575it [11:46,  8.15it/s]Train epoch: 8 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005965\n",
      "10600it [11:49,  8.18it/s]Train epoch: 8 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.006181\n",
      "10625it [11:52,  8.25it/s]Train epoch: 8 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006913\n",
      "10650it [11:56,  8.14it/s]Train epoch: 8 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006356\n",
      "10675it [11:59,  7.93it/s]Train epoch: 8 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006845\n",
      "10700it [12:02,  8.14it/s]Train epoch: 8 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006348\n",
      "10725it [12:05,  7.79it/s]Train epoch: 8 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005964\n",
      "10750it [12:08,  7.82it/s]Train epoch: 8 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.007114\n",
      "10775it [12:11,  7.92it/s]Train epoch: 8 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.007003\n",
      "10800it [12:14,  8.01it/s]Train epoch: 8 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.007217\n",
      "10825it [12:18,  7.75it/s]Train epoch: 8 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.007102\n",
      "10850it [12:21,  7.85it/s]Train epoch: 8 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.007004\n",
      "10875it [12:24,  7.96it/s]Train epoch: 8 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.007078\n",
      "10900it [12:27,  8.00it/s]Train epoch: 8 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006946\n",
      "10925it [12:30,  7.76it/s]Train epoch: 8 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006231\n",
      "10950it [12:34,  7.71it/s]Train epoch: 8 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006893\n",
      "10975it [12:37,  7.62it/s]Train epoch: 8 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006662\n",
      "11000it [12:40,  7.66it/s]Train epoch: 8 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006561\n",
      "11025it [12:43,  7.87it/s]Train epoch: 8 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006794\n",
      "11050it [12:46,  7.85it/s]Train epoch: 8 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007609\n",
      "11075it [12:50,  7.72it/s]Train epoch: 8 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.007044\n",
      "11100it [12:53,  7.70it/s]Train epoch: 8 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007738\n",
      "11125it [12:56,  7.87it/s]Train epoch: 8 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007240\n",
      "11150it [12:59,  7.79it/s]Train epoch: 8 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11175it [13:02,  7.83it/s]Train epoch: 8 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.008101\n",
      "11200it [13:06,  7.89it/s]Train epoch: 8 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007314\n",
      "11225it [13:09,  7.51it/s]Train epoch: 8 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007287\n",
      "11250it [13:12,  7.82it/s]Train epoch: 8 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007904\n",
      "11275it [13:15,  8.17it/s]Train epoch: 8 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007538\n",
      "11300it [13:18,  7.78it/s]Train epoch: 8 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006921\n",
      "11325it [13:22,  7.83it/s]Train epoch: 8 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.008132\n",
      "11350it [13:25,  7.76it/s]Train epoch: 8 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.008076\n",
      "11375it [13:28,  7.82it/s]Train epoch: 8 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.008292\n",
      "11400it [13:31,  7.78it/s]Train epoch: 8 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007269\n",
      "11425it [13:34,  7.73it/s]Train epoch: 8 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007954\n",
      "11450it [13:38,  7.77it/s]Train epoch: 8 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.007065\n",
      "11475it [13:41,  7.76it/s]Train epoch: 8 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008532\n",
      "11500it [13:44,  7.92it/s]Train epoch: 8 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.008110\n",
      "11525it [13:47,  7.89it/s]Train epoch: 8 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007510\n",
      "11550it [13:51,  7.93it/s]Train epoch: 8 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007471\n",
      "11575it [13:54,  8.02it/s]Train epoch: 8 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008606\n",
      "11600it [13:57,  7.78it/s]Train epoch: 8 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007881\n",
      "11625it [14:00,  7.77it/s]Train epoch: 8 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007452\n",
      "11650it [14:03,  7.63it/s]Train epoch: 8 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007994\n",
      "11675it [14:07,  7.77it/s]Train epoch: 8 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008466\n",
      "11700it [14:10,  7.80it/s]Train epoch: 8 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008960\n",
      "11725it [14:13,  7.78it/s]Train epoch: 8 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008926\n",
      "11750it [14:16,  7.94it/s]Train epoch: 8 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008708\n",
      "11775it [14:19,  7.97it/s]Train epoch: 8 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008798\n",
      "11800it [14:23,  7.72it/s]Train epoch: 8 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008515\n",
      "11825it [14:26,  7.72it/s]Train epoch: 8 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008754\n",
      "11850it [14:29,  7.88it/s]Train epoch: 8 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.009074\n",
      "11875it [14:32,  7.81it/s]Train epoch: 8 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.010016\n",
      "11900it [14:36,  7.73it/s]Train epoch: 8 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.012028\n",
      "11925it [14:39,  7.78it/s]Train epoch: 8 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010110\n",
      "11930it [14:39, 13.56it/s]\n",
      "epoch loss: 0.005067371511829928\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 126.30it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0266, 0.0394, 0.0421, 0.0407, 0.8746\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3162, 0.5478, 0.4279, 0.4805, 0.9809\n",
      "rec_at_8: 0.3443\n",
      "prec_at_8: 0.6378\n",
      "rec_at_15: 0.4786\n",
      "prec_at_15: 0.4938\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 127.93it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0263, 0.0435, 0.0423, 0.0429, 0.8672\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3106, 0.5461, 0.4186, 0.4739, 0.9806\n",
      "rec_at_8: 0.3327\n",
      "prec_at_8: 0.6406\n",
      "rec_at_15: 0.4613\n",
      "prec_at_15: 0.4942\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 8\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0266, 0.0394, 0.0421, 0.0407, 0.8746\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3162, 0.5478, 0.4279, 0.4805, 0.9809\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 8\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0263, 0.0435, 0.0423, 0.0429, 0.8672\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3106, 0.5461, 0.4186, 0.4739, 0.9806\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0072\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 9\n",
      "0it [00:00, ?it/s]Train epoch: 9 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006543\n",
      "22it [00:00, 47.66it/s]Train epoch: 9 [batch #25, batch_size 4, seq length 221]\tLoss: 0.004040\n",
      "47it [00:01, 42.19it/s]Train epoch: 9 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003847\n",
      "72it [00:01, 42.87it/s]Train epoch: 9 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003183\n",
      "97it [00:02, 43.09it/s]Train epoch: 9 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003318\n",
      "125it [00:02, 37.31it/s]Train epoch: 9 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003221\n",
      "147it [00:03, 39.04it/s]Train epoch: 9 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003126\n",
      "173it [00:04, 38.23it/s]Train epoch: 9 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003242\n",
      "197it [00:04, 35.20it/s]Train epoch: 9 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003107\n",
      "225it [00:05, 34.67it/s]Train epoch: 9 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003865\n",
      "249it [00:06, 33.58it/s]Train epoch: 9 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003193\n",
      "273it [00:07, 31.53it/s]Train epoch: 9 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002675\n",
      "297it [00:07, 32.66it/s]Train epoch: 9 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003492\n",
      "325it [00:08, 32.25it/s]Train epoch: 9 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002953\n",
      "349it [00:09, 31.81it/s]Train epoch: 9 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003439\n",
      "373it [00:10, 32.09it/s]Train epoch: 9 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003312\n",
      "397it [00:10, 31.14it/s]Train epoch: 9 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003355\n",
      "425it [00:11, 32.71it/s]Train epoch: 9 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003327\n",
      "449it [00:12, 31.14it/s]Train epoch: 9 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003280\n",
      "473it [00:13, 31.25it/s]Train epoch: 9 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003663\n",
      "500it [00:14, 29.45it/s]Train epoch: 9 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003181\n",
      "524it [00:15, 30.44it/s]Train epoch: 9 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003376\n",
      "549it [00:15, 28.96it/s]Train epoch: 9 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003360\n",
      "572it [00:16, 29.71it/s]Train epoch: 9 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003285\n",
      "599it [00:17, 29.65it/s]Train epoch: 9 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003563\n",
      "622it [00:18, 30.53it/s]Train epoch: 9 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003467\n",
      "648it [00:19, 29.23it/s]Train epoch: 9 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003103\n",
      "672it [00:20, 28.22it/s]Train epoch: 9 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002625\n",
      "700it [00:21, 29.81it/s]Train epoch: 9 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003254\n",
      "724it [00:21, 28.60it/s]Train epoch: 9 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003451\n",
      "749it [00:22, 27.40it/s]Train epoch: 9 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003195\n",
      "775it [00:23, 28.22it/s]Train epoch: 9 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003547\n",
      "799it [00:24, 28.02it/s]Train epoch: 9 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003452\n",
      "823it [00:25, 27.08it/s]Train epoch: 9 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003297\n",
      "848it [00:26, 28.27it/s]Train epoch: 9 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874it [00:27, 28.88it/s]Train epoch: 9 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003154\n",
      "899it [00:28, 28.31it/s]Train epoch: 9 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003437\n",
      "924it [00:28, 27.38it/s]Train epoch: 9 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003258\n",
      "950it [00:29, 28.74it/s]Train epoch: 9 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003194\n",
      "974it [00:30, 27.02it/s]Train epoch: 9 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002519\n",
      "999it [00:31, 26.30it/s]Train epoch: 9 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003341\n",
      "1025it [00:32, 28.44it/s]Train epoch: 9 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004556\n",
      "1049it [00:33, 25.26it/s]Train epoch: 9 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003110\n",
      "1072it [00:34, 27.38it/s]Train epoch: 9 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003594\n",
      "1098it [00:35, 26.49it/s]Train epoch: 9 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003625\n",
      "1124it [00:36, 28.00it/s]Train epoch: 9 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003704\n",
      "1149it [00:37, 25.95it/s]Train epoch: 9 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003715\n",
      "1173it [00:38, 27.83it/s]Train epoch: 9 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003524\n",
      "1200it [00:39, 27.03it/s]Train epoch: 9 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003731\n",
      "1225it [00:39, 26.53it/s]Train epoch: 9 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003844\n",
      "1250it [00:40, 26.78it/s]Train epoch: 9 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003582\n",
      "1275it [00:41, 26.15it/s]Train epoch: 9 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003134\n",
      "1299it [00:42, 24.75it/s]Train epoch: 9 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003187\n",
      "1323it [00:43, 26.54it/s]Train epoch: 9 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003193\n",
      "1348it [00:44, 26.51it/s]Train epoch: 9 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004246\n",
      "1375it [00:45, 25.55it/s]Train epoch: 9 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003511\n",
      "1399it [00:46, 26.55it/s]Train epoch: 9 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003455\n",
      "1423it [00:47, 26.44it/s]Train epoch: 9 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003188\n",
      "1450it [00:48, 26.51it/s]Train epoch: 9 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003347\n",
      "1474it [00:49, 24.40it/s]Train epoch: 9 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003553\n",
      "1498it [00:50, 25.51it/s]Train epoch: 9 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004628\n",
      "1525it [00:51, 26.42it/s]Train epoch: 9 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004354\n",
      "1549it [00:52, 25.49it/s]Train epoch: 9 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003349\n",
      "1573it [00:53, 26.20it/s]Train epoch: 9 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003686\n",
      "1600it [00:54, 25.59it/s]Train epoch: 9 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003206\n",
      "1624it [00:55, 25.80it/s]Train epoch: 9 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003902\n",
      "1648it [00:56, 25.40it/s]Train epoch: 9 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003996\n",
      "1675it [00:57, 24.59it/s]Train epoch: 9 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003828\n",
      "1699it [00:58, 25.89it/s]Train epoch: 9 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003295\n",
      "1723it [00:59, 25.47it/s]Train epoch: 9 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002885\n",
      "1750it [01:00, 24.38it/s]Train epoch: 9 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004369\n",
      "1774it [01:01, 25.08it/s]Train epoch: 9 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003605\n",
      "1798it [01:02, 25.27it/s]Train epoch: 9 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003543\n",
      "1825it [01:03, 24.29it/s]Train epoch: 9 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002994\n",
      "1849it [01:04, 25.89it/s]Train epoch: 9 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003721\n",
      "1873it [01:05, 23.15it/s]Train epoch: 9 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.004039\n",
      "1898it [01:06, 24.49it/s]Train epoch: 9 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002896\n",
      "1925it [01:07, 24.59it/s]Train epoch: 9 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003227\n",
      "1950it [01:08, 25.42it/s]Train epoch: 9 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003130\n",
      "1974it [01:09, 25.54it/s]Train epoch: 9 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003733\n",
      "1998it [01:10, 24.60it/s]Train epoch: 9 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.003034\n",
      "2025it [01:11, 24.06it/s]Train epoch: 9 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003696\n",
      "2049it [01:12, 23.71it/s]Train epoch: 9 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003438\n",
      "2073it [01:13, 24.20it/s]Train epoch: 9 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003563\n",
      "2100it [01:14, 23.95it/s]Train epoch: 9 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003750\n",
      "2124it [01:15, 25.59it/s]Train epoch: 9 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.004000\n",
      "2148it [01:16, 25.71it/s]Train epoch: 9 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003441\n",
      "2175it [01:17, 24.32it/s]Train epoch: 9 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003896\n",
      "2199it [01:18, 23.96it/s]Train epoch: 9 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003680\n",
      "2223it [01:19, 23.23it/s]Train epoch: 9 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003463\n",
      "2250it [01:20, 23.22it/s]Train epoch: 9 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003279\n",
      "2274it [01:21, 22.65it/s]Train epoch: 9 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003678\n",
      "2298it [01:22, 24.32it/s]Train epoch: 9 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002820\n",
      "2325it [01:23, 23.66it/s]Train epoch: 9 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003526\n",
      "2349it [01:24, 24.33it/s]Train epoch: 9 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003280\n",
      "2373it [01:25, 24.16it/s]Train epoch: 9 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004727\n",
      "2400it [01:27, 23.60it/s]Train epoch: 9 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004356\n",
      "2424it [01:28, 22.68it/s]Train epoch: 9 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.003069\n",
      "2448it [01:29, 22.93it/s]Train epoch: 9 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003527\n",
      "2475it [01:30, 23.21it/s]Train epoch: 9 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003959\n",
      "2499it [01:31, 23.19it/s]Train epoch: 9 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003444\n",
      "2523it [01:32, 22.86it/s]Train epoch: 9 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003319\n",
      "2550it [01:33, 22.17it/s]Train epoch: 9 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004689\n",
      "2574it [01:34, 22.69it/s]Train epoch: 9 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003300\n",
      "2598it [01:35, 22.68it/s]Train epoch: 9 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003617\n",
      "2625it [01:36, 22.50it/s]Train epoch: 9 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003564\n",
      "2649it [01:37, 23.62it/s]Train epoch: 9 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004191\n",
      "2673it [01:39, 21.91it/s]Train epoch: 9 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003775\n",
      "2700it [01:40, 22.31it/s]Train epoch: 9 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003280\n",
      "2724it [01:41, 21.15it/s]Train epoch: 9 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003529\n",
      "2748it [01:42, 22.70it/s]Train epoch: 9 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004236\n",
      "2775it [01:43, 22.09it/s]Train epoch: 9 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003692\n",
      "2799it [01:44, 20.93it/s]Train epoch: 9 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003463\n",
      "2823it [01:45, 22.66it/s]Train epoch: 9 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003852\n",
      "2850it [01:47, 22.23it/s]Train epoch: 9 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003648\n",
      "2874it [01:48, 21.06it/s]Train epoch: 9 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003976\n",
      "2898it [01:49, 20.96it/s]Train epoch: 9 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003916\n",
      "2925it [01:50, 21.29it/s]Train epoch: 9 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.004015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2949it [01:51, 21.25it/s]Train epoch: 9 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004196\n",
      "2973it [01:52, 21.01it/s]Train epoch: 9 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003931\n",
      "3000it [01:54, 21.86it/s]Train epoch: 9 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004450\n",
      "3024it [01:55, 22.39it/s]Train epoch: 9 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.004075\n",
      "3048it [01:56, 22.49it/s]Train epoch: 9 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003570\n",
      "3075it [01:57, 22.12it/s]Train epoch: 9 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.004018\n",
      "3099it [01:58, 22.14it/s]Train epoch: 9 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.004081\n",
      "3123it [01:59, 21.46it/s]Train epoch: 9 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003764\n",
      "3150it [02:01, 20.70it/s]Train epoch: 9 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003651\n",
      "3174it [02:02, 21.94it/s]Train epoch: 9 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003623\n",
      "3198it [02:03, 21.97it/s]Train epoch: 9 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004243\n",
      "3225it [02:04, 21.79it/s]Train epoch: 9 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004109\n",
      "3249it [02:05, 21.21it/s]Train epoch: 9 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004124\n",
      "3273it [02:06, 22.01it/s]Train epoch: 9 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003652\n",
      "3300it [02:08, 19.61it/s]Train epoch: 9 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004538\n",
      "3324it [02:09, 21.03it/s]Train epoch: 9 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003926\n",
      "3350it [02:10, 20.00it/s]Train epoch: 9 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003941\n",
      "3374it [02:11, 20.88it/s]Train epoch: 9 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.004112\n",
      "3398it [02:12, 20.18it/s]Train epoch: 9 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004197\n",
      "3425it [02:14, 21.18it/s]Train epoch: 9 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003638\n",
      "3449it [02:15, 21.01it/s]Train epoch: 9 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004239\n",
      "3473it [02:16, 21.37it/s]Train epoch: 9 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003777\n",
      "3500it [02:17, 20.35it/s]Train epoch: 9 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003905\n",
      "3524it [02:18, 20.04it/s]Train epoch: 9 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.004062\n",
      "3548it [02:20, 20.19it/s]Train epoch: 9 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004389\n",
      "3575it [02:21, 20.20it/s]Train epoch: 9 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003463\n",
      "3599it [02:22, 19.68it/s]Train epoch: 9 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004478\n",
      "3623it [02:23, 20.10it/s]Train epoch: 9 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.004112\n",
      "3650it [02:25, 20.30it/s]Train epoch: 9 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004244\n",
      "3675it [02:26, 18.32it/s]Train epoch: 9 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004245\n",
      "3700it [02:27, 18.29it/s]Train epoch: 9 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004308\n",
      "3725it [02:29, 17.65it/s]Train epoch: 9 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004354\n",
      "3750it [02:30, 18.18it/s]Train epoch: 9 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004349\n",
      "3774it [02:31, 17.97it/s]Train epoch: 9 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004172\n",
      "3800it [02:33, 17.15it/s]Train epoch: 9 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004600\n",
      "3824it [02:34, 16.87it/s]Train epoch: 9 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003929\n",
      "3850it [02:36, 17.42it/s]Train epoch: 9 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003657\n",
      "3875it [02:37, 17.79it/s]Train epoch: 9 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003571\n",
      "3899it [02:39, 16.95it/s]Train epoch: 9 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004613\n",
      "3925it [02:40, 17.38it/s]Train epoch: 9 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004176\n",
      "3949it [02:41, 17.46it/s]Train epoch: 9 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004564\n",
      "3974it [02:43, 17.28it/s]Train epoch: 9 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.005127\n",
      "4000it [02:44, 17.72it/s]Train epoch: 9 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003860\n",
      "4025it [02:46, 17.84it/s]Train epoch: 9 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004805\n",
      "4049it [02:47, 18.03it/s]Train epoch: 9 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004333\n",
      "4075it [02:49, 17.37it/s]Train epoch: 9 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004351\n",
      "4100it [02:50, 17.65it/s]Train epoch: 9 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004785\n",
      "4124it [02:51, 17.14it/s]Train epoch: 9 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004622\n",
      "4150it [02:53, 17.33it/s]Train epoch: 9 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003945\n",
      "4174it [02:54, 16.97it/s]Train epoch: 9 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004233\n",
      "4200it [02:56, 16.85it/s]Train epoch: 9 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004589\n",
      "4224it [02:57, 16.84it/s]Train epoch: 9 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003962\n",
      "4250it [02:59, 17.64it/s]Train epoch: 9 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004467\n",
      "4274it [03:00, 16.93it/s]Train epoch: 9 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004165\n",
      "4300it [03:02, 17.30it/s]Train epoch: 9 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004893\n",
      "4324it [03:03, 17.26it/s]Train epoch: 9 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004281\n",
      "4350it [03:05, 16.70it/s]Train epoch: 9 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004654\n",
      "4374it [03:06, 18.00it/s]Train epoch: 9 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004152\n",
      "4400it [03:08, 17.12it/s]Train epoch: 9 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003611\n",
      "4424it [03:09, 17.17it/s]Train epoch: 9 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004423\n",
      "4450it [03:11, 17.39it/s]Train epoch: 9 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003573\n",
      "4474it [03:12, 16.06it/s]Train epoch: 9 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004574\n",
      "4500it [03:14, 16.58it/s]Train epoch: 9 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005217\n",
      "4524it [03:15, 16.36it/s]Train epoch: 9 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004550\n",
      "4550it [03:17, 16.72it/s]Train epoch: 9 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004244\n",
      "4574it [03:18, 16.22it/s]Train epoch: 9 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004863\n",
      "4600it [03:20, 15.91it/s]Train epoch: 9 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004063\n",
      "4624it [03:21, 15.15it/s]Train epoch: 9 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004116\n",
      "4650it [03:23, 15.56it/s]Train epoch: 9 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004747\n",
      "4674it [03:24, 15.12it/s]Train epoch: 9 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004504\n",
      "4700it [03:26, 16.04it/s]Train epoch: 9 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.004052\n",
      "4724it [03:28, 15.79it/s]Train epoch: 9 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004242\n",
      "4750it [03:29, 15.81it/s]Train epoch: 9 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004966\n",
      "4774it [03:31, 15.61it/s]Train epoch: 9 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004352\n",
      "4800it [03:32, 15.92it/s]Train epoch: 9 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004534\n",
      "4824it [03:34, 15.77it/s]Train epoch: 9 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.004037\n",
      "4850it [03:36, 15.71it/s]Train epoch: 9 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004701\n",
      "4874it [03:37, 15.85it/s]Train epoch: 9 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.004033\n",
      "4900it [03:39, 15.85it/s]Train epoch: 9 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004430\n",
      "4924it [03:40, 15.80it/s]Train epoch: 9 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.004063\n",
      "4950it [03:42, 15.33it/s]Train epoch: 9 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004393\n",
      "4974it [03:44, 14.96it/s]Train epoch: 9 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000it [03:45, 15.30it/s]Train epoch: 9 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004342\n",
      "5024it [03:47, 15.04it/s]Train epoch: 9 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004140\n",
      "5050it [03:49, 15.59it/s]Train epoch: 9 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004126\n",
      "5074it [03:50, 15.23it/s]Train epoch: 9 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004330\n",
      "5100it [03:52, 15.43it/s]Train epoch: 9 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004440\n",
      "5124it [03:53, 15.32it/s]Train epoch: 9 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004655\n",
      "5150it [03:55, 15.44it/s]Train epoch: 9 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004714\n",
      "5174it [03:57, 15.39it/s]Train epoch: 9 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004576\n",
      "5200it [03:58, 15.34it/s]Train epoch: 9 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004127\n",
      "5224it [04:00, 14.88it/s]Train epoch: 9 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004448\n",
      "5250it [04:02, 15.22it/s]Train epoch: 9 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004372\n",
      "5274it [04:03, 15.03it/s]Train epoch: 9 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004233\n",
      "5300it [04:05, 14.80it/s]Train epoch: 9 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004154\n",
      "5324it [04:07, 14.77it/s]Train epoch: 9 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004637\n",
      "5350it [04:08, 14.39it/s]Train epoch: 9 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004713\n",
      "5374it [04:10, 15.18it/s]Train epoch: 9 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004248\n",
      "5400it [04:12, 14.56it/s]Train epoch: 9 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004280\n",
      "5424it [04:13, 14.65it/s]Train epoch: 9 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004652\n",
      "5450it [04:15, 14.67it/s]Train epoch: 9 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004623\n",
      "5474it [04:17, 14.59it/s]Train epoch: 9 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005245\n",
      "5500it [04:18, 14.90it/s]Train epoch: 9 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004906\n",
      "5524it [04:20, 14.24it/s]Train epoch: 9 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003985\n",
      "5550it [04:22, 14.68it/s]Train epoch: 9 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004583\n",
      "5574it [04:23, 14.64it/s]Train epoch: 9 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004680\n",
      "5600it [04:25, 14.60it/s]Train epoch: 9 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004949\n",
      "5624it [04:27, 14.37it/s]Train epoch: 9 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004670\n",
      "5650it [04:29, 14.49it/s]Train epoch: 9 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004181\n",
      "5674it [04:30, 14.73it/s]Train epoch: 9 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.005142\n",
      "5700it [04:32, 14.91it/s]Train epoch: 9 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004482\n",
      "5724it [04:34, 14.11it/s]Train epoch: 9 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004608\n",
      "5750it [04:35, 14.44it/s]Train epoch: 9 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005721\n",
      "5774it [04:37, 14.66it/s]Train epoch: 9 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004819\n",
      "5800it [04:39, 14.46it/s]Train epoch: 9 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004785\n",
      "5824it [04:41, 14.34it/s]Train epoch: 9 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004335\n",
      "5850it [04:42, 14.03it/s]Train epoch: 9 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005462\n",
      "5874it [04:44, 14.33it/s]Train epoch: 9 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005258\n",
      "5900it [04:46, 14.31it/s]Train epoch: 9 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005237\n",
      "5924it [04:47, 14.13it/s]Train epoch: 9 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004313\n",
      "5950it [04:49, 14.64it/s]Train epoch: 9 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004222\n",
      "5974it [04:51, 14.50it/s]Train epoch: 9 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005764\n",
      "6000it [04:53, 13.92it/s]Train epoch: 9 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004924\n",
      "6024it [04:54, 14.47it/s]Train epoch: 9 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.005115\n",
      "6050it [04:56, 13.99it/s]Train epoch: 9 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004620\n",
      "6074it [04:58, 14.66it/s]Train epoch: 9 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004301\n",
      "6100it [05:00, 13.80it/s]Train epoch: 9 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004130\n",
      "6124it [05:01, 14.21it/s]Train epoch: 9 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004584\n",
      "6150it [05:03, 14.69it/s]Train epoch: 9 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004635\n",
      "6174it [05:05, 14.26it/s]Train epoch: 9 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005278\n",
      "6200it [05:07, 14.26it/s]Train epoch: 9 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004671\n",
      "6224it [05:08, 14.01it/s]Train epoch: 9 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.004047\n",
      "6250it [05:10, 13.90it/s]Train epoch: 9 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004411\n",
      "6274it [05:12, 14.09it/s]Train epoch: 9 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003987\n",
      "6300it [05:14, 14.55it/s]Train epoch: 9 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004638\n",
      "6324it [05:16, 13.74it/s]Train epoch: 9 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005107\n",
      "6350it [05:17, 14.27it/s]Train epoch: 9 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005430\n",
      "6374it [05:19, 13.92it/s]Train epoch: 9 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004305\n",
      "6400it [05:21, 13.77it/s]Train epoch: 9 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004452\n",
      "6424it [05:23, 13.41it/s]Train epoch: 9 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.005157\n",
      "6450it [05:25, 13.65it/s]Train epoch: 9 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004993\n",
      "6474it [05:26, 13.59it/s]Train epoch: 9 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004505\n",
      "6500it [05:28, 13.96it/s]Train epoch: 9 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.005146\n",
      "6524it [05:30, 13.68it/s]Train epoch: 9 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004404\n",
      "6550it [05:32, 13.10it/s]Train epoch: 9 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004506\n",
      "6574it [05:34, 13.73it/s]Train epoch: 9 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004735\n",
      "6600it [05:36, 13.56it/s]Train epoch: 9 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005739\n",
      "6624it [05:37, 13.39it/s]Train epoch: 9 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004653\n",
      "6650it [05:39, 13.56it/s]Train epoch: 9 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005246\n",
      "6674it [05:41, 13.87it/s]Train epoch: 9 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004885\n",
      "6700it [05:43, 13.18it/s]Train epoch: 9 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004902\n",
      "6724it [05:45, 13.53it/s]Train epoch: 9 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004999\n",
      "6750it [05:47, 13.00it/s]Train epoch: 9 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004482\n",
      "6774it [05:49, 13.19it/s]Train epoch: 9 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005118\n",
      "6800it [05:51, 13.16it/s]Train epoch: 9 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005143\n",
      "6824it [05:52, 13.17it/s]Train epoch: 9 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005374\n",
      "6850it [05:54, 13.17it/s]Train epoch: 9 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005072\n",
      "6874it [05:56, 13.35it/s]Train epoch: 9 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004177\n",
      "6900it [05:58, 13.17it/s]Train epoch: 9 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004849\n",
      "6924it [06:00, 13.05it/s]Train epoch: 9 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004906\n",
      "6950it [06:02, 12.92it/s]Train epoch: 9 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005443\n",
      "6974it [06:04, 12.99it/s]Train epoch: 9 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.005018\n",
      "7000it [06:06, 12.65it/s]Train epoch: 9 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004808\n",
      "7024it [06:08, 12.88it/s]Train epoch: 9 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7050it [06:10, 12.67it/s]Train epoch: 9 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004407\n",
      "7074it [06:12, 12.76it/s]Train epoch: 9 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004857\n",
      "7100it [06:14, 13.15it/s]Train epoch: 9 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005281\n",
      "7124it [06:15, 12.87it/s]Train epoch: 9 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004516\n",
      "7150it [06:17, 13.00it/s]Train epoch: 9 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005432\n",
      "7174it [06:19, 13.26it/s]Train epoch: 9 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.005028\n",
      "7200it [06:21, 12.90it/s]Train epoch: 9 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005383\n",
      "7224it [06:23, 13.10it/s]Train epoch: 9 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004860\n",
      "7250it [06:25, 12.86it/s]Train epoch: 9 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.005016\n",
      "7274it [06:27, 13.28it/s]Train epoch: 9 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005405\n",
      "7300it [06:29, 12.65it/s]Train epoch: 9 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005856\n",
      "7324it [06:31, 12.74it/s]Train epoch: 9 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004680\n",
      "7350it [06:33, 12.34it/s]Train epoch: 9 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005685\n",
      "7374it [06:35, 12.64it/s]Train epoch: 9 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005316\n",
      "7400it [06:37, 12.30it/s]Train epoch: 9 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004788\n",
      "7424it [06:39, 12.73it/s]Train epoch: 9 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005170\n",
      "7450it [06:41, 12.42it/s]Train epoch: 9 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005818\n",
      "7474it [06:43, 12.56it/s]Train epoch: 9 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004948\n",
      "7500it [06:45, 12.53it/s]Train epoch: 9 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005253\n",
      "7524it [06:47, 12.59it/s]Train epoch: 9 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.005024\n",
      "7550it [06:49, 12.59it/s]Train epoch: 9 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004928\n",
      "7574it [06:51, 12.69it/s]Train epoch: 9 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005424\n",
      "7600it [06:53, 12.78it/s]Train epoch: 9 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006370\n",
      "7624it [06:55, 12.42it/s]Train epoch: 9 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005900\n",
      "7650it [06:57, 12.37it/s]Train epoch: 9 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.005023\n",
      "7674it [06:59, 12.35it/s]Train epoch: 9 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.005122\n",
      "7700it [07:01, 12.53it/s]Train epoch: 9 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005180\n",
      "7724it [07:03, 12.77it/s]Train epoch: 9 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005191\n",
      "7750it [07:05, 12.32it/s]Train epoch: 9 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005479\n",
      "7774it [07:07, 11.99it/s]Train epoch: 9 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004807\n",
      "7800it [07:09, 11.97it/s]Train epoch: 9 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.005040\n",
      "7824it [07:11, 12.28it/s]Train epoch: 9 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005285\n",
      "7850it [07:13, 12.28it/s]Train epoch: 9 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004813\n",
      "7874it [07:15, 11.97it/s]Train epoch: 9 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.005027\n",
      "7900it [07:17, 12.14it/s]Train epoch: 9 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005286\n",
      "7924it [07:19, 11.69it/s]Train epoch: 9 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005259\n",
      "7950it [07:21, 11.70it/s]Train epoch: 9 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005834\n",
      "7974it [07:23, 12.35it/s]Train epoch: 9 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.005058\n",
      "8000it [07:26, 11.84it/s]Train epoch: 9 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004976\n",
      "8024it [07:28, 12.34it/s]Train epoch: 9 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005310\n",
      "8050it [07:30, 11.48it/s]Train epoch: 9 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004653\n",
      "8074it [07:32, 11.71it/s]Train epoch: 9 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005197\n",
      "8100it [07:34, 11.88it/s]Train epoch: 9 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005548\n",
      "8124it [07:36, 11.82it/s]Train epoch: 9 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005689\n",
      "8150it [07:38, 11.96it/s]Train epoch: 9 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004871\n",
      "8174it [07:40, 11.89it/s]Train epoch: 9 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005615\n",
      "8200it [07:42, 11.90it/s]Train epoch: 9 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004879\n",
      "8224it [07:45, 12.11it/s]Train epoch: 9 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006401\n",
      "8250it [07:47, 11.67it/s]Train epoch: 9 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.005031\n",
      "8274it [07:49, 12.08it/s]Train epoch: 9 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005693\n",
      "8300it [07:51, 11.59it/s]Train epoch: 9 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.005020\n",
      "8324it [07:53, 11.79it/s]Train epoch: 9 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005727\n",
      "8350it [07:55, 11.50it/s]Train epoch: 9 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004886\n",
      "8374it [07:57, 11.66it/s]Train epoch: 9 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005650\n",
      "8400it [08:00, 11.40it/s]Train epoch: 9 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005257\n",
      "8424it [08:02, 11.33it/s]Train epoch: 9 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005326\n",
      "8450it [08:04, 11.68it/s]Train epoch: 9 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005674\n",
      "8474it [08:06, 11.60it/s]Train epoch: 9 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005315\n",
      "8500it [08:08, 11.27it/s]Train epoch: 9 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006234\n",
      "8524it [08:10, 11.53it/s]Train epoch: 9 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005393\n",
      "8550it [08:13, 11.28it/s]Train epoch: 9 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005570\n",
      "8574it [08:15, 11.42it/s]Train epoch: 9 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005233\n",
      "8600it [08:17, 11.37it/s]Train epoch: 9 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005356\n",
      "8624it [08:19, 11.02it/s]Train epoch: 9 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005482\n",
      "8650it [08:22, 11.43it/s]Train epoch: 9 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005625\n",
      "8674it [08:24, 11.00it/s]Train epoch: 9 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006272\n",
      "8700it [08:26, 10.96it/s]Train epoch: 9 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006280\n",
      "8724it [08:28, 11.15it/s]Train epoch: 9 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.006044\n",
      "8750it [08:31, 11.28it/s]Train epoch: 9 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005732\n",
      "8774it [08:33, 11.28it/s]Train epoch: 9 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005205\n",
      "8800it [08:35, 10.97it/s]Train epoch: 9 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005467\n",
      "8824it [08:37, 11.24it/s]Train epoch: 9 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005550\n",
      "8850it [08:40, 11.03it/s]Train epoch: 9 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005782\n",
      "8874it [08:42, 10.88it/s]Train epoch: 9 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005520\n",
      "8900it [08:44, 10.94it/s]Train epoch: 9 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005681\n",
      "8924it [08:46, 10.64it/s]Train epoch: 9 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005706\n",
      "8950it [08:49, 10.92it/s]Train epoch: 9 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006412\n",
      "8974it [08:51, 10.88it/s]Train epoch: 9 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005988\n",
      "9000it [08:54, 10.59it/s]Train epoch: 9 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005572\n",
      "9024it [08:56, 10.62it/s]Train epoch: 9 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005714\n",
      "9050it [08:58, 10.37it/s]Train epoch: 9 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005269\n",
      "9074it [09:00, 11.01it/s]Train epoch: 9 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100it [09:03, 10.87it/s]Train epoch: 9 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005824\n",
      "9124it [09:05, 10.63it/s]Train epoch: 9 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005445\n",
      "9150it [09:08, 10.45it/s]Train epoch: 9 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.005011\n",
      "9174it [09:10, 10.37it/s]Train epoch: 9 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005407\n",
      "9200it [09:12, 10.47it/s]Train epoch: 9 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005258\n",
      "9224it [09:15, 10.33it/s]Train epoch: 9 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006321\n",
      "9250it [09:17, 10.54it/s]Train epoch: 9 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005544\n",
      "9274it [09:20, 10.24it/s]Train epoch: 9 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005957\n",
      "9300it [09:22, 10.36it/s]Train epoch: 9 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006555\n",
      "9324it [09:24, 10.50it/s]Train epoch: 9 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006332\n",
      "9350it [09:27, 10.16it/s]Train epoch: 9 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006278\n",
      "9375it [09:29,  9.82it/s]Train epoch: 9 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005648\n",
      "9399it [09:32, 10.55it/s]Train epoch: 9 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005817\n",
      "9425it [09:34, 10.33it/s]Train epoch: 9 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005671\n",
      "9449it [09:37,  9.87it/s]Train epoch: 9 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005595\n",
      "9475it [09:39, 10.13it/s]Train epoch: 9 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006286\n",
      "9500it [09:42,  9.88it/s]Train epoch: 9 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005899\n",
      "9525it [09:44,  9.92it/s]Train epoch: 9 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006330\n",
      "9550it [09:47,  9.80it/s]Train epoch: 9 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006197\n",
      "9574it [09:49, 10.00it/s]Train epoch: 9 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006280\n",
      "9600it [09:52,  9.82it/s]Train epoch: 9 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005999\n",
      "9625it [09:54,  9.59it/s]Train epoch: 9 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005484\n",
      "9649it [09:57,  9.84it/s]Train epoch: 9 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005565\n",
      "9675it [09:59,  9.75it/s]Train epoch: 9 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.006028\n",
      "9700it [10:02,  9.88it/s]Train epoch: 9 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005342\n",
      "9725it [10:04,  9.74it/s]Train epoch: 9 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005976\n",
      "9750it [10:07,  9.64it/s]Train epoch: 9 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005901\n",
      "9775it [10:10,  9.23it/s]Train epoch: 9 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006661\n",
      "9800it [10:12,  9.35it/s]Train epoch: 9 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006327\n",
      "9825it [10:15,  9.54it/s]Train epoch: 9 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006533\n",
      "9850it [10:18,  9.70it/s]Train epoch: 9 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005913\n",
      "9875it [10:20,  9.31it/s]Train epoch: 9 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006380\n",
      "9900it [10:23,  9.39it/s]Train epoch: 9 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006858\n",
      "9924it [10:25,  9.64it/s]Train epoch: 9 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006309\n",
      "9950it [10:28,  9.35it/s]Train epoch: 9 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006999\n",
      "9975it [10:31,  9.15it/s]Train epoch: 9 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006477\n",
      "10000it [10:33,  9.38it/s]Train epoch: 9 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005999\n",
      "10025it [10:36,  9.35it/s]Train epoch: 9 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005950\n",
      "10050it [10:39,  8.88it/s]Train epoch: 9 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006483\n",
      "10075it [10:42,  8.98it/s]Train epoch: 9 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006861\n",
      "10100it [10:44,  9.11it/s]Train epoch: 9 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006578\n",
      "10125it [10:47,  8.74it/s]Train epoch: 9 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005942\n",
      "10150it [10:50,  9.11it/s]Train epoch: 9 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006490\n",
      "10175it [10:53,  9.07it/s]Train epoch: 9 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005999\n",
      "10200it [10:55,  8.91it/s]Train epoch: 9 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006528\n",
      "10225it [10:58,  9.05it/s]Train epoch: 9 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006520\n",
      "10250it [11:01,  8.92it/s]Train epoch: 9 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006998\n",
      "10275it [11:04,  8.83it/s]Train epoch: 9 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006191\n",
      "10300it [11:07,  8.93it/s]Train epoch: 9 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006853\n",
      "10325it [11:09,  8.92it/s]Train epoch: 9 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006707\n",
      "10350it [11:12,  8.90it/s]Train epoch: 9 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006352\n",
      "10375it [11:15,  8.78it/s]Train epoch: 9 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006633\n",
      "10400it [11:18,  8.70it/s]Train epoch: 9 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006640\n",
      "10425it [11:21,  8.46it/s]Train epoch: 9 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006253\n",
      "10450it [11:24,  8.84it/s]Train epoch: 9 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006663\n",
      "10475it [11:27,  8.43it/s]Train epoch: 9 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005820\n",
      "10500it [11:30,  8.49it/s]Train epoch: 9 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006638\n",
      "10525it [11:33,  8.51it/s]Train epoch: 9 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006357\n",
      "10550it [11:36,  8.21it/s]Train epoch: 9 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006678\n",
      "10575it [11:39,  8.51it/s]Train epoch: 9 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005880\n",
      "10600it [11:42,  8.15it/s]Train epoch: 9 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.006121\n",
      "10625it [11:45,  8.23it/s]Train epoch: 9 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006830\n",
      "10650it [11:48,  8.13it/s]Train epoch: 9 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006232\n",
      "10675it [11:51,  8.18it/s]Train epoch: 9 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006819\n",
      "10700it [11:54,  7.99it/s]Train epoch: 9 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006293\n",
      "10725it [11:57,  8.30it/s]Train epoch: 9 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005907\n",
      "10750it [12:00,  8.15it/s]Train epoch: 9 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.007011\n",
      "10775it [12:03,  8.07it/s]Train epoch: 9 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006948\n",
      "10800it [12:06,  7.75it/s]Train epoch: 9 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.007070\n",
      "10825it [12:09,  7.68it/s]Train epoch: 9 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.007009\n",
      "10850it [12:13,  7.74it/s]Train epoch: 9 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006927\n",
      "10875it [12:16,  7.96it/s]Train epoch: 9 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.007024\n",
      "10900it [12:19,  7.97it/s]Train epoch: 9 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006812\n",
      "10925it [12:22,  7.70it/s]Train epoch: 9 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006183\n",
      "10950it [12:25,  7.81it/s]Train epoch: 9 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006803\n",
      "10975it [12:28,  7.99it/s]Train epoch: 9 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006528\n",
      "11000it [12:32,  7.92it/s]Train epoch: 9 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006486\n",
      "11025it [12:35,  7.92it/s]Train epoch: 9 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006722\n",
      "11050it [12:38,  7.82it/s]Train epoch: 9 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007527\n",
      "11075it [12:41,  8.24it/s]Train epoch: 9 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006981\n",
      "11100it [12:44,  7.76it/s]Train epoch: 9 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11125it [12:48,  7.88it/s]Train epoch: 9 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007160\n",
      "11150it [12:51,  7.88it/s]Train epoch: 9 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006917\n",
      "11175it [12:54,  7.84it/s]Train epoch: 9 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007966\n",
      "11200it [12:57,  7.97it/s]Train epoch: 9 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007224\n",
      "11225it [13:00,  7.86it/s]Train epoch: 9 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007162\n",
      "11250it [13:03,  7.85it/s]Train epoch: 9 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007840\n",
      "11275it [13:07,  8.03it/s]Train epoch: 9 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007460\n",
      "11300it [13:10,  7.99it/s]Train epoch: 9 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006844\n",
      "11325it [13:13,  7.83it/s]Train epoch: 9 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.008069\n",
      "11350it [13:16,  7.87it/s]Train epoch: 9 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007942\n",
      "11375it [13:19,  7.85it/s]Train epoch: 9 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.008164\n",
      "11400it [13:22,  7.90it/s]Train epoch: 9 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007166\n",
      "11425it [13:26,  7.64it/s]Train epoch: 9 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007837\n",
      "11450it [13:29,  7.76it/s]Train epoch: 9 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006948\n",
      "11475it [13:32,  7.86it/s]Train epoch: 9 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008406\n",
      "11500it [13:35,  8.10it/s]Train epoch: 9 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.008040\n",
      "11525it [13:38,  7.90it/s]Train epoch: 9 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007438\n",
      "11550it [13:41,  7.81it/s]Train epoch: 9 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007352\n",
      "11575it [13:45,  7.90it/s]Train epoch: 9 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008475\n",
      "11600it [13:48,  7.87it/s]Train epoch: 9 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007826\n",
      "11625it [13:51,  7.83it/s]Train epoch: 9 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007336\n",
      "11650it [13:54,  7.93it/s]Train epoch: 9 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007991\n",
      "11675it [13:57,  7.88it/s]Train epoch: 9 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008405\n",
      "11700it [14:01,  7.79it/s]Train epoch: 9 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008898\n",
      "11725it [14:04,  7.90it/s]Train epoch: 9 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008800\n",
      "11750it [14:07,  7.82it/s]Train epoch: 9 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008552\n",
      "11775it [14:10,  7.81it/s]Train epoch: 9 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008750\n",
      "11800it [14:13,  7.81it/s]Train epoch: 9 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008445\n",
      "11825it [14:17,  7.85it/s]Train epoch: 9 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008655\n",
      "11850it [14:20,  7.79it/s]Train epoch: 9 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008991\n",
      "11875it [14:23,  7.75it/s]Train epoch: 9 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009917\n",
      "11900it [14:26,  7.95it/s]Train epoch: 9 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011884\n",
      "11925it [14:29,  7.72it/s]Train epoch: 9 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010026\n",
      "11930it [14:30, 13.71it/s]\n",
      "epoch loss: 0.004993442784349238\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 128.00it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0285, 0.0424, 0.0447, 0.0435, 0.8768\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3201, 0.5476, 0.4351, 0.4849, 0.9813\n",
      "rec_at_8: 0.3464\n",
      "prec_at_8: 0.6407\n",
      "rec_at_15: 0.4835\n",
      "prec_at_15: 0.4979\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 130.00it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0285, 0.0466, 0.0455, 0.0461, 0.8688\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3147, 0.5463, 0.4260, 0.4787, 0.9809\n",
      "rec_at_8: 0.3340\n",
      "prec_at_8: 0.6426\n",
      "rec_at_15: 0.4652\n",
      "prec_at_15: 0.4982\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0285, 0.0424, 0.0447, 0.0435, 0.8768\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3201, 0.5476, 0.4351, 0.4849, 0.9813\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0285, 0.0466, 0.0455, 0.0461, 0.8688\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3147, 0.5463, 0.4260, 0.4787, 0.9809\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 10\n",
      "0it [00:00, ?it/s]Train epoch: 10 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006703\n",
      "24it [00:00, 44.03it/s]Train epoch: 10 [batch #25, batch_size 4, seq length 221]\tLoss: 0.004061\n",
      "50it [00:01, 45.31it/s]Train epoch: 10 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003782\n",
      "75it [00:01, 42.42it/s]Train epoch: 10 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003126\n",
      "98it [00:02, 37.70it/s]Train epoch: 10 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003304\n",
      "123it [00:02, 34.90it/s]Train epoch: 10 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003136\n",
      "148it [00:03, 37.96it/s]Train epoch: 10 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003072\n",
      "172it [00:04, 34.87it/s]Train epoch: 10 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003213\n",
      "200it [00:05, 34.19it/s]Train epoch: 10 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003024\n",
      "225it [00:05, 36.20it/s]Train epoch: 10 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003842\n",
      "249it [00:06, 32.95it/s]Train epoch: 10 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003120\n",
      "273it [00:07, 32.45it/s]Train epoch: 10 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002672\n",
      "297it [00:08, 33.16it/s]Train epoch: 10 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003475\n",
      "325it [00:08, 31.25it/s]Train epoch: 10 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002861\n",
      "349it [00:09, 31.94it/s]Train epoch: 10 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003434\n",
      "373it [00:10, 31.68it/s]Train epoch: 10 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003209\n",
      "397it [00:11, 30.75it/s]Train epoch: 10 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003244\n",
      "425it [00:12, 31.07it/s]Train epoch: 10 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003243\n",
      "449it [00:12, 30.50it/s]Train epoch: 10 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003194\n",
      "473it [00:13, 30.01it/s]Train epoch: 10 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003613\n",
      "500it [00:14, 29.78it/s]Train epoch: 10 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003104\n",
      "524it [00:15, 31.44it/s]Train epoch: 10 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003410\n",
      "548it [00:16, 31.49it/s]Train epoch: 10 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003284\n",
      "572it [00:16, 31.03it/s]Train epoch: 10 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003254\n",
      "600it [00:17, 28.97it/s]Train epoch: 10 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003563\n",
      "625it [00:18, 29.37it/s]Train epoch: 10 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003428\n",
      "650it [00:19, 29.45it/s]Train epoch: 10 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003080\n",
      "672it [00:20, 30.21it/s]Train epoch: 10 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002581\n",
      "699it [00:21, 27.21it/s]Train epoch: 10 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003232\n",
      "723it [00:22, 29.02it/s]Train epoch: 10 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003355\n",
      "749it [00:23, 28.61it/s]Train epoch: 10 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003158\n",
      "774it [00:23, 27.24it/s]Train epoch: 10 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003503\n",
      "798it [00:24, 27.26it/s]Train epoch: 10 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825it [00:25, 28.92it/s]Train epoch: 10 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003282\n",
      "849it [00:26, 29.46it/s]Train epoch: 10 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003746\n",
      "875it [00:27, 26.68it/s]Train epoch: 10 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003084\n",
      "900it [00:28, 27.30it/s]Train epoch: 10 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003363\n",
      "924it [00:29, 28.02it/s]Train epoch: 10 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003197\n",
      "947it [00:30, 29.58it/s]Train epoch: 10 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003146\n",
      "975it [00:31, 26.54it/s]Train epoch: 10 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002466\n",
      "997it [00:31, 27.63it/s]Train epoch: 10 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003293\n",
      "1025it [00:32, 26.31it/s]Train epoch: 10 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004469\n",
      "1050it [00:33, 26.77it/s]Train epoch: 10 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003091\n",
      "1072it [00:34, 27.46it/s]Train epoch: 10 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003545\n",
      "1099it [00:35, 28.16it/s]Train epoch: 10 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003627\n",
      "1123it [00:36, 26.08it/s]Train epoch: 10 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003671\n",
      "1150it [00:37, 29.77it/s]Train epoch: 10 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003591\n",
      "1174it [00:38, 26.44it/s]Train epoch: 10 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003532\n",
      "1198it [00:39, 25.74it/s]Train epoch: 10 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003700\n",
      "1225it [00:40, 27.04it/s]Train epoch: 10 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003756\n",
      "1249it [00:41, 27.06it/s]Train epoch: 10 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003513\n",
      "1273it [00:42, 25.24it/s]Train epoch: 10 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003087\n",
      "1300it [00:43, 25.77it/s]Train epoch: 10 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003193\n",
      "1324it [00:44, 25.93it/s]Train epoch: 10 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003146\n",
      "1349it [00:44, 27.34it/s]Train epoch: 10 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004129\n",
      "1373it [00:45, 25.15it/s]Train epoch: 10 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003484\n",
      "1400it [00:46, 26.08it/s]Train epoch: 10 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003420\n",
      "1424it [00:47, 26.62it/s]Train epoch: 10 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003098\n",
      "1448it [00:48, 24.95it/s]Train epoch: 10 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003286\n",
      "1475it [00:49, 26.49it/s]Train epoch: 10 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003461\n",
      "1499it [00:50, 27.34it/s]Train epoch: 10 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004650\n",
      "1523it [00:51, 26.49it/s]Train epoch: 10 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004314\n",
      "1550it [00:52, 25.20it/s]Train epoch: 10 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003308\n",
      "1574it [00:53, 27.58it/s]Train epoch: 10 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003635\n",
      "1598it [00:54, 25.08it/s]Train epoch: 10 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003166\n",
      "1625it [00:55, 23.52it/s]Train epoch: 10 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003829\n",
      "1650it [00:56, 25.57it/s]Train epoch: 10 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003910\n",
      "1674it [00:57, 24.74it/s]Train epoch: 10 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003777\n",
      "1698it [00:58, 25.28it/s]Train epoch: 10 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003227\n",
      "1725it [00:59, 23.73it/s]Train epoch: 10 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002873\n",
      "1749it [01:00, 24.19it/s]Train epoch: 10 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004290\n",
      "1773it [01:01, 24.10it/s]Train epoch: 10 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003609\n",
      "1800it [01:02, 24.59it/s]Train epoch: 10 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003500\n",
      "1824it [01:03, 24.63it/s]Train epoch: 10 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002951\n",
      "1848it [01:04, 25.03it/s]Train epoch: 10 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003645\n",
      "1875it [01:05, 25.26it/s]Train epoch: 10 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003996\n",
      "1899it [01:06, 24.82it/s]Train epoch: 10 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002922\n",
      "1923it [01:07, 25.21it/s]Train epoch: 10 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003177\n",
      "1950it [01:08, 23.59it/s]Train epoch: 10 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003139\n",
      "1974it [01:09, 25.27it/s]Train epoch: 10 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003654\n",
      "1998it [01:10, 24.71it/s]Train epoch: 10 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002950\n",
      "2025it [01:11, 24.49it/s]Train epoch: 10 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003606\n",
      "2049it [01:12, 25.39it/s]Train epoch: 10 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003383\n",
      "2073it [01:13, 22.02it/s]Train epoch: 10 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003544\n",
      "2100it [01:15, 23.60it/s]Train epoch: 10 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003712\n",
      "2124it [01:16, 23.62it/s]Train epoch: 10 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003960\n",
      "2148it [01:16, 24.41it/s]Train epoch: 10 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003355\n",
      "2175it [01:18, 24.65it/s]Train epoch: 10 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003832\n",
      "2200it [01:19, 24.38it/s]Train epoch: 10 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003693\n",
      "2224it [01:20, 23.74it/s]Train epoch: 10 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003430\n",
      "2248it [01:21, 25.63it/s]Train epoch: 10 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003272\n",
      "2275it [01:22, 24.10it/s]Train epoch: 10 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003666\n",
      "2299it [01:23, 24.36it/s]Train epoch: 10 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002762\n",
      "2323it [01:24, 22.84it/s]Train epoch: 10 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003497\n",
      "2350it [01:25, 23.22it/s]Train epoch: 10 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003209\n",
      "2374it [01:26, 24.92it/s]Train epoch: 10 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004581\n",
      "2398it [01:27, 23.64it/s]Train epoch: 10 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004359\n",
      "2425it [01:28, 23.62it/s]Train epoch: 10 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002999\n",
      "2449it [01:29, 22.74it/s]Train epoch: 10 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003506\n",
      "2473it [01:30, 22.18it/s]Train epoch: 10 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003922\n",
      "2500it [01:31, 22.71it/s]Train epoch: 10 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003384\n",
      "2524it [01:32, 23.80it/s]Train epoch: 10 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003297\n",
      "2548it [01:33, 23.94it/s]Train epoch: 10 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004627\n",
      "2575it [01:34, 22.89it/s]Train epoch: 10 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003252\n",
      "2599it [01:36, 22.90it/s]Train epoch: 10 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003574\n",
      "2623it [01:37, 22.42it/s]Train epoch: 10 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003536\n",
      "2650it [01:38, 22.62it/s]Train epoch: 10 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004134\n",
      "2674it [01:39, 23.29it/s]Train epoch: 10 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003701\n",
      "2698it [01:40, 22.93it/s]Train epoch: 10 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003227\n",
      "2725it [01:41, 23.02it/s]Train epoch: 10 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003524\n",
      "2749it [01:42, 22.46it/s]Train epoch: 10 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004152\n",
      "2773it [01:43, 21.12it/s]Train epoch: 10 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003599\n",
      "2800it [01:44, 22.10it/s]Train epoch: 10 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003454\n",
      "2824it [01:46, 21.67it/s]Train epoch: 10 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003828\n",
      "2848it [01:47, 22.07it/s]Train epoch: 10 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2875it [01:48, 23.05it/s]Train epoch: 10 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003941\n",
      "2899it [01:49, 22.34it/s]Train epoch: 10 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003855\n",
      "2923it [01:50, 21.94it/s]Train epoch: 10 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003974\n",
      "2950it [01:51, 22.21it/s]Train epoch: 10 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004026\n",
      "2974it [01:52, 21.51it/s]Train epoch: 10 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003867\n",
      "2998it [01:54, 22.17it/s]Train epoch: 10 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004382\n",
      "3025it [01:55, 22.08it/s]Train epoch: 10 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.004009\n",
      "3049it [01:56, 21.02it/s]Train epoch: 10 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003501\n",
      "3073it [01:57, 21.48it/s]Train epoch: 10 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.004050\n",
      "3100it [01:58, 21.72it/s]Train epoch: 10 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.004031\n",
      "3124it [01:59, 20.78it/s]Train epoch: 10 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003690\n",
      "3148it [02:00, 21.94it/s]Train epoch: 10 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003585\n",
      "3175it [02:02, 21.77it/s]Train epoch: 10 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003536\n",
      "3199it [02:03, 21.90it/s]Train epoch: 10 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004139\n",
      "3223it [02:04, 22.28it/s]Train epoch: 10 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004033\n",
      "3250it [02:05, 22.18it/s]Train epoch: 10 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004051\n",
      "3274it [02:06, 21.27it/s]Train epoch: 10 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003611\n",
      "3298it [02:07, 21.37it/s]Train epoch: 10 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004566\n",
      "3325it [02:09, 21.29it/s]Train epoch: 10 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003841\n",
      "3349it [02:10, 20.75it/s]Train epoch: 10 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003918\n",
      "3373it [02:11, 20.09it/s]Train epoch: 10 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.004063\n",
      "3400it [02:12, 21.13it/s]Train epoch: 10 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004143\n",
      "3424it [02:13, 21.31it/s]Train epoch: 10 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003622\n",
      "3448it [02:15, 20.79it/s]Train epoch: 10 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004247\n",
      "3475it [02:16, 20.91it/s]Train epoch: 10 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003701\n",
      "3499it [02:17, 20.80it/s]Train epoch: 10 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003809\n",
      "3523it [02:18, 20.70it/s]Train epoch: 10 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003981\n",
      "3550it [02:20, 21.34it/s]Train epoch: 10 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004318\n",
      "3574it [02:21, 21.71it/s]Train epoch: 10 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003412\n",
      "3598it [02:22, 21.11it/s]Train epoch: 10 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004436\n",
      "3625it [02:23, 20.74it/s]Train epoch: 10 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.004050\n",
      "3649it [02:24, 20.11it/s]Train epoch: 10 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004215\n",
      "3674it [02:26, 17.94it/s]Train epoch: 10 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004170\n",
      "3700it [02:27, 17.63it/s]Train epoch: 10 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004270\n",
      "3724it [02:28, 18.05it/s]Train epoch: 10 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004280\n",
      "3750it [02:30, 17.43it/s]Train epoch: 10 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004268\n",
      "3774it [02:31, 18.23it/s]Train epoch: 10 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004102\n",
      "3799it [02:33, 17.63it/s]Train epoch: 10 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004545\n",
      "3825it [02:34, 17.17it/s]Train epoch: 10 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003850\n",
      "3850it [02:35, 18.41it/s]Train epoch: 10 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003601\n",
      "3874it [02:37, 17.57it/s]Train epoch: 10 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003535\n",
      "3900it [02:38, 17.45it/s]Train epoch: 10 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004564\n",
      "3924it [02:40, 17.49it/s]Train epoch: 10 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004143\n",
      "3950it [02:41, 16.84it/s]Train epoch: 10 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004568\n",
      "3974it [02:42, 17.23it/s]Train epoch: 10 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.005049\n",
      "4000it [02:44, 17.66it/s]Train epoch: 10 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003820\n",
      "4024it [02:45, 17.13it/s]Train epoch: 10 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004739\n",
      "4050it [02:47, 16.80it/s]Train epoch: 10 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004285\n",
      "4074it [02:48, 17.08it/s]Train epoch: 10 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004263\n",
      "4099it [02:50, 17.42it/s]Train epoch: 10 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004730\n",
      "4124it [02:51, 16.79it/s]Train epoch: 10 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004608\n",
      "4150it [02:53, 16.64it/s]Train epoch: 10 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003921\n",
      "4174it [02:54, 16.89it/s]Train epoch: 10 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004233\n",
      "4200it [02:55, 17.18it/s]Train epoch: 10 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004559\n",
      "4224it [02:57, 17.16it/s]Train epoch: 10 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003869\n",
      "4250it [02:58, 17.32it/s]Train epoch: 10 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004433\n",
      "4274it [03:00, 16.89it/s]Train epoch: 10 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004113\n",
      "4300it [03:01, 16.57it/s]Train epoch: 10 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004820\n",
      "4324it [03:03, 16.97it/s]Train epoch: 10 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004201\n",
      "4350it [03:04, 16.61it/s]Train epoch: 10 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004587\n",
      "4374it [03:06, 17.82it/s]Train epoch: 10 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004139\n",
      "4400it [03:07, 16.78it/s]Train epoch: 10 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003547\n",
      "4424it [03:09, 17.22it/s]Train epoch: 10 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004378\n",
      "4450it [03:10, 16.47it/s]Train epoch: 10 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003522\n",
      "4474it [03:12, 17.32it/s]Train epoch: 10 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004522\n",
      "4500it [03:13, 17.27it/s]Train epoch: 10 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005148\n",
      "4524it [03:15, 16.92it/s]Train epoch: 10 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004444\n",
      "4550it [03:16, 16.31it/s]Train epoch: 10 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004197\n",
      "4574it [03:18, 16.60it/s]Train epoch: 10 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004762\n",
      "4600it [03:19, 16.35it/s]Train epoch: 10 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004046\n",
      "4624it [03:21, 16.41it/s]Train epoch: 10 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004035\n",
      "4650it [03:22, 15.93it/s]Train epoch: 10 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004694\n",
      "4674it [03:24, 15.49it/s]Train epoch: 10 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004476\n",
      "4700it [03:26, 15.73it/s]Train epoch: 10 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003965\n",
      "4724it [03:27, 15.13it/s]Train epoch: 10 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004210\n",
      "4750it [03:29, 15.47it/s]Train epoch: 10 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004859\n",
      "4774it [03:30, 15.93it/s]Train epoch: 10 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004299\n",
      "4800it [03:32, 15.92it/s]Train epoch: 10 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004506\n",
      "4824it [03:33, 16.06it/s]Train epoch: 10 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003938\n",
      "4850it [03:35, 16.04it/s]Train epoch: 10 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004638\n",
      "4874it [03:37, 15.42it/s]Train epoch: 10 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003975\n",
      "4900it [03:38, 15.77it/s]Train epoch: 10 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4924it [03:40, 15.72it/s]Train epoch: 10 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.004005\n",
      "4950it [03:42, 14.66it/s]Train epoch: 10 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004337\n",
      "4974it [03:43, 15.78it/s]Train epoch: 10 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004372\n",
      "5000it [03:45, 15.15it/s]Train epoch: 10 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004304\n",
      "5024it [03:46, 15.08it/s]Train epoch: 10 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004099\n",
      "5050it [03:48, 15.99it/s]Train epoch: 10 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004074\n",
      "5074it [03:50, 14.69it/s]Train epoch: 10 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004283\n",
      "5100it [03:51, 16.09it/s]Train epoch: 10 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004389\n",
      "5124it [03:53, 15.33it/s]Train epoch: 10 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004596\n",
      "5150it [03:55, 15.47it/s]Train epoch: 10 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004628\n",
      "5174it [03:56, 15.15it/s]Train epoch: 10 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004509\n",
      "5200it [03:58, 14.92it/s]Train epoch: 10 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004109\n",
      "5224it [03:59, 15.04it/s]Train epoch: 10 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004376\n",
      "5250it [04:01, 15.02it/s]Train epoch: 10 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004323\n",
      "5274it [04:03, 15.39it/s]Train epoch: 10 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004173\n",
      "5300it [04:04, 15.32it/s]Train epoch: 10 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004116\n",
      "5324it [04:06, 15.24it/s]Train epoch: 10 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004555\n",
      "5350it [04:08, 15.29it/s]Train epoch: 10 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004602\n",
      "5374it [04:09, 14.98it/s]Train epoch: 10 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004251\n",
      "5400it [04:11, 15.46it/s]Train epoch: 10 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004201\n",
      "5424it [04:13, 15.40it/s]Train epoch: 10 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004642\n",
      "5450it [04:14, 14.87it/s]Train epoch: 10 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004525\n",
      "5474it [04:16, 15.16it/s]Train epoch: 10 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005170\n",
      "5500it [04:18, 15.20it/s]Train epoch: 10 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004816\n",
      "5524it [04:19, 14.87it/s]Train epoch: 10 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003910\n",
      "5550it [04:21, 14.38it/s]Train epoch: 10 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004501\n",
      "5574it [04:23, 15.11it/s]Train epoch: 10 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004571\n",
      "5600it [04:25, 14.69it/s]Train epoch: 10 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004914\n",
      "5624it [04:26, 15.07it/s]Train epoch: 10 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004541\n",
      "5650it [04:28, 15.17it/s]Train epoch: 10 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004111\n",
      "5674it [04:30, 14.62it/s]Train epoch: 10 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.005040\n",
      "5700it [04:31, 14.25it/s]Train epoch: 10 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004364\n",
      "5724it [04:33, 14.45it/s]Train epoch: 10 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004566\n",
      "5750it [04:35, 15.05it/s]Train epoch: 10 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005645\n",
      "5774it [04:36, 14.95it/s]Train epoch: 10 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004748\n",
      "5800it [04:38, 15.09it/s]Train epoch: 10 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004752\n",
      "5824it [04:40, 14.53it/s]Train epoch: 10 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004304\n",
      "5850it [04:42, 14.51it/s]Train epoch: 10 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005363\n",
      "5874it [04:43, 14.49it/s]Train epoch: 10 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005201\n",
      "5900it [04:45, 14.75it/s]Train epoch: 10 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005168\n",
      "5924it [04:47, 14.41it/s]Train epoch: 10 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004237\n",
      "5950it [04:49, 14.06it/s]Train epoch: 10 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004179\n",
      "5974it [04:50, 13.96it/s]Train epoch: 10 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005720\n",
      "6000it [04:52, 14.49it/s]Train epoch: 10 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004843\n",
      "6024it [04:54, 14.19it/s]Train epoch: 10 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.005047\n",
      "6050it [04:55, 14.59it/s]Train epoch: 10 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004519\n",
      "6074it [04:57, 14.39it/s]Train epoch: 10 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004249\n",
      "6100it [04:59, 14.37it/s]Train epoch: 10 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004145\n",
      "6124it [05:01, 14.47it/s]Train epoch: 10 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004548\n",
      "6150it [05:02, 14.15it/s]Train epoch: 10 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004582\n",
      "6174it [05:04, 14.65it/s]Train epoch: 10 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005203\n",
      "6200it [05:06, 14.17it/s]Train epoch: 10 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004576\n",
      "6224it [05:08, 14.07it/s]Train epoch: 10 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.004017\n",
      "6250it [05:09, 14.29it/s]Train epoch: 10 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004337\n",
      "6274it [05:11, 14.35it/s]Train epoch: 10 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003938\n",
      "6300it [05:13, 13.71it/s]Train epoch: 10 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004619\n",
      "6324it [05:15, 13.64it/s]Train epoch: 10 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005046\n",
      "6350it [05:17, 13.85it/s]Train epoch: 10 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005378\n",
      "6374it [05:18, 14.12it/s]Train epoch: 10 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004251\n",
      "6400it [05:20, 14.16it/s]Train epoch: 10 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004417\n",
      "6424it [05:22, 13.73it/s]Train epoch: 10 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.005072\n",
      "6450it [05:24, 13.96it/s]Train epoch: 10 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004914\n",
      "6474it [05:25, 13.90it/s]Train epoch: 10 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004463\n",
      "6500it [05:27, 13.77it/s]Train epoch: 10 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.005082\n",
      "6524it [05:29, 13.39it/s]Train epoch: 10 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004342\n",
      "6550it [05:31, 13.58it/s]Train epoch: 10 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004499\n",
      "6574it [05:33, 13.47it/s]Train epoch: 10 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004660\n",
      "6600it [05:35, 13.62it/s]Train epoch: 10 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005684\n",
      "6624it [05:36, 13.55it/s]Train epoch: 10 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004617\n",
      "6650it [05:38, 13.51it/s]Train epoch: 10 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005154\n",
      "6674it [05:40, 13.57it/s]Train epoch: 10 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004769\n",
      "6700it [05:42, 13.47it/s]Train epoch: 10 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004884\n",
      "6724it [05:44, 13.16it/s]Train epoch: 10 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004894\n",
      "6750it [05:46, 13.76it/s]Train epoch: 10 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004378\n",
      "6774it [05:48, 13.44it/s]Train epoch: 10 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005111\n",
      "6800it [05:50, 13.70it/s]Train epoch: 10 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005099\n",
      "6824it [05:51, 13.34it/s]Train epoch: 10 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005270\n",
      "6850it [05:53, 13.53it/s]Train epoch: 10 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005005\n",
      "6874it [05:55, 13.51it/s]Train epoch: 10 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004116\n",
      "6900it [05:57, 12.82it/s]Train epoch: 10 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004805\n",
      "6924it [05:59, 12.92it/s]Train epoch: 10 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6950it [06:01, 13.01it/s]Train epoch: 10 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005347\n",
      "6974it [06:03, 13.03it/s]Train epoch: 10 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.005022\n",
      "7000it [06:05, 12.92it/s]Train epoch: 10 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004706\n",
      "7024it [06:06, 13.51it/s]Train epoch: 10 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005425\n",
      "7050it [06:08, 12.93it/s]Train epoch: 10 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004380\n",
      "7074it [06:10, 13.22it/s]Train epoch: 10 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004729\n",
      "7100it [06:12, 13.36it/s]Train epoch: 10 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005188\n",
      "7124it [06:14, 12.58it/s]Train epoch: 10 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004478\n",
      "7150it [06:16, 13.25it/s]Train epoch: 10 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005441\n",
      "7174it [06:18, 13.20it/s]Train epoch: 10 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004953\n",
      "7200it [06:20, 12.63it/s]Train epoch: 10 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005268\n",
      "7224it [06:22, 12.75it/s]Train epoch: 10 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004763\n",
      "7250it [06:24, 12.95it/s]Train epoch: 10 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004973\n",
      "7274it [06:26, 12.72it/s]Train epoch: 10 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005361\n",
      "7300it [06:28, 12.72it/s]Train epoch: 10 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005785\n",
      "7324it [06:30, 12.59it/s]Train epoch: 10 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004641\n",
      "7350it [06:32, 12.98it/s]Train epoch: 10 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005613\n",
      "7374it [06:33, 12.51it/s]Train epoch: 10 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005223\n",
      "7400it [06:36, 12.80it/s]Train epoch: 10 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004755\n",
      "7424it [06:37, 12.37it/s]Train epoch: 10 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005128\n",
      "7450it [06:39, 13.04it/s]Train epoch: 10 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005721\n",
      "7474it [06:41, 12.23it/s]Train epoch: 10 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004928\n",
      "7500it [06:43, 12.78it/s]Train epoch: 10 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005150\n",
      "7524it [06:45, 11.89it/s]Train epoch: 10 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004955\n",
      "7550it [06:48, 12.47it/s]Train epoch: 10 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004839\n",
      "7574it [06:49, 12.86it/s]Train epoch: 10 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005392\n",
      "7600it [06:51, 12.63it/s]Train epoch: 10 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006350\n",
      "7624it [06:53, 12.37it/s]Train epoch: 10 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005846\n",
      "7650it [06:55, 12.41it/s]Train epoch: 10 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004980\n",
      "7674it [06:57, 12.39it/s]Train epoch: 10 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.005086\n",
      "7700it [07:00, 12.28it/s]Train epoch: 10 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005155\n",
      "7724it [07:01, 12.01it/s]Train epoch: 10 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005140\n",
      "7750it [07:04, 12.24it/s]Train epoch: 10 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005449\n",
      "7774it [07:05, 12.40it/s]Train epoch: 10 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004820\n",
      "7800it [07:08, 11.90it/s]Train epoch: 10 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004993\n",
      "7824it [07:10, 12.23it/s]Train epoch: 10 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005272\n",
      "7850it [07:12, 12.52it/s]Train epoch: 10 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004770\n",
      "7874it [07:14, 12.77it/s]Train epoch: 10 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004951\n",
      "7900it [07:16, 12.18it/s]Train epoch: 10 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005201\n",
      "7924it [07:18, 11.98it/s]Train epoch: 10 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005184\n",
      "7950it [07:20, 11.97it/s]Train epoch: 10 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005786\n",
      "7974it [07:22, 12.13it/s]Train epoch: 10 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.005036\n",
      "8000it [07:24, 11.95it/s]Train epoch: 10 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004888\n",
      "8024it [07:26, 12.29it/s]Train epoch: 10 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005269\n",
      "8050it [07:28, 11.86it/s]Train epoch: 10 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004670\n",
      "8074it [07:30, 12.10it/s]Train epoch: 10 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005135\n",
      "8100it [07:32, 12.27it/s]Train epoch: 10 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005458\n",
      "8124it [07:34, 11.80it/s]Train epoch: 10 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005618\n",
      "8150it [07:37, 11.74it/s]Train epoch: 10 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004814\n",
      "8174it [07:39, 12.04it/s]Train epoch: 10 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005572\n",
      "8200it [07:41, 11.75it/s]Train epoch: 10 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004794\n",
      "8224it [07:43, 11.62it/s]Train epoch: 10 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006346\n",
      "8250it [07:45, 11.53it/s]Train epoch: 10 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004925\n",
      "8274it [07:47, 11.81it/s]Train epoch: 10 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005614\n",
      "8300it [07:49, 11.89it/s]Train epoch: 10 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004978\n",
      "8324it [07:51, 11.30it/s]Train epoch: 10 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005619\n",
      "8350it [07:54, 11.95it/s]Train epoch: 10 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004803\n",
      "8374it [07:56, 11.37it/s]Train epoch: 10 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005642\n",
      "8400it [07:58, 11.51it/s]Train epoch: 10 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005184\n",
      "8424it [08:00, 11.43it/s]Train epoch: 10 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005231\n",
      "8450it [08:02, 11.64it/s]Train epoch: 10 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005588\n",
      "8474it [08:04, 11.41it/s]Train epoch: 10 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005295\n",
      "8500it [08:07, 11.16it/s]Train epoch: 10 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006138\n",
      "8524it [08:09, 11.31it/s]Train epoch: 10 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005321\n",
      "8550it [08:11, 11.07it/s]Train epoch: 10 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005501\n",
      "8574it [08:13, 11.41it/s]Train epoch: 10 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005209\n",
      "8600it [08:15, 11.75it/s]Train epoch: 10 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005280\n",
      "8624it [08:18, 11.35it/s]Train epoch: 10 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005455\n",
      "8650it [08:20, 11.24it/s]Train epoch: 10 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005548\n",
      "8674it [08:22, 11.19it/s]Train epoch: 10 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006198\n",
      "8700it [08:24, 11.11it/s]Train epoch: 10 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006241\n",
      "8724it [08:27, 10.84it/s]Train epoch: 10 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005967\n",
      "8750it [08:29, 11.05it/s]Train epoch: 10 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005640\n",
      "8774it [08:31, 11.36it/s]Train epoch: 10 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005111\n",
      "8800it [08:33, 11.05it/s]Train epoch: 10 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005420\n",
      "8824it [08:36, 10.98it/s]Train epoch: 10 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005493\n",
      "8850it [08:38, 11.20it/s]Train epoch: 10 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005702\n",
      "8874it [08:40, 11.06it/s]Train epoch: 10 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005494\n",
      "8900it [08:43, 10.68it/s]Train epoch: 10 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005586\n",
      "8924it [08:45, 10.95it/s]Train epoch: 10 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005655\n",
      "8950it [08:47, 10.98it/s]Train epoch: 10 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8974it [08:49, 11.13it/s]Train epoch: 10 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005935\n",
      "9000it [08:52, 10.74it/s]Train epoch: 10 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005483\n",
      "9024it [08:54, 10.99it/s]Train epoch: 10 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005660\n",
      "9050it [08:56, 11.11it/s]Train epoch: 10 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005190\n",
      "9074it [08:59, 10.85it/s]Train epoch: 10 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004960\n",
      "9100it [09:01, 10.73it/s]Train epoch: 10 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005796\n",
      "9124it [09:03, 10.75it/s]Train epoch: 10 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005402\n",
      "9150it [09:06, 10.54it/s]Train epoch: 10 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004951\n",
      "9174it [09:08, 10.35it/s]Train epoch: 10 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005375\n",
      "9200it [09:10, 10.57it/s]Train epoch: 10 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005183\n",
      "9224it [09:13, 10.43it/s]Train epoch: 10 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006274\n",
      "9250it [09:15, 10.72it/s]Train epoch: 10 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005471\n",
      "9274it [09:17, 10.77it/s]Train epoch: 10 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005832\n",
      "9300it [09:20, 10.51it/s]Train epoch: 10 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006546\n",
      "9324it [09:22, 10.45it/s]Train epoch: 10 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006267\n",
      "9350it [09:25, 10.29it/s]Train epoch: 10 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006259\n",
      "9374it [09:27, 10.09it/s]Train epoch: 10 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005575\n",
      "9400it [09:29, 10.48it/s]Train epoch: 10 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005770\n",
      "9424it [09:32, 10.15it/s]Train epoch: 10 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005594\n",
      "9449it [09:34, 10.11it/s]Train epoch: 10 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005529\n",
      "9474it [09:37, 10.09it/s]Train epoch: 10 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006188\n",
      "9500it [09:39,  9.99it/s]Train epoch: 10 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005842\n",
      "9525it [09:42, 10.26it/s]Train epoch: 10 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006246\n",
      "9550it [09:44, 10.15it/s]Train epoch: 10 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006104\n",
      "9575it [09:47,  9.96it/s]Train epoch: 10 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006202\n",
      "9600it [09:49,  9.80it/s]Train epoch: 10 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005966\n",
      "9625it [09:52, 10.09it/s]Train epoch: 10 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005427\n",
      "9649it [09:54,  9.75it/s]Train epoch: 10 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005526\n",
      "9675it [09:57,  9.82it/s]Train epoch: 10 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005941\n",
      "9700it [09:59,  9.89it/s]Train epoch: 10 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005251\n",
      "9724it [10:02,  9.73it/s]Train epoch: 10 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005857\n",
      "9750it [10:04, 10.17it/s]Train epoch: 10 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005798\n",
      "9775it [10:07,  9.55it/s]Train epoch: 10 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006582\n",
      "9800it [10:10,  9.89it/s]Train epoch: 10 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006287\n",
      "9825it [10:12,  9.75it/s]Train epoch: 10 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006506\n",
      "9850it [10:15,  9.53it/s]Train epoch: 10 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005864\n",
      "9875it [10:17,  9.51it/s]Train epoch: 10 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006321\n",
      "9900it [10:20,  9.73it/s]Train epoch: 10 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006737\n",
      "9925it [10:23,  9.88it/s]Train epoch: 10 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006246\n",
      "9950it [10:25,  9.36it/s]Train epoch: 10 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006922\n",
      "9975it [10:28,  9.78it/s]Train epoch: 10 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006413\n",
      "10000it [10:31,  9.43it/s]Train epoch: 10 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005925\n",
      "10025it [10:33,  9.53it/s]Train epoch: 10 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005887\n",
      "10050it [10:36,  9.57it/s]Train epoch: 10 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006409\n",
      "10075it [10:38,  9.27it/s]Train epoch: 10 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006867\n",
      "10100it [10:41,  9.08it/s]Train epoch: 10 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006490\n",
      "10125it [10:44,  9.44it/s]Train epoch: 10 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005884\n",
      "10150it [10:47,  9.06it/s]Train epoch: 10 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006402\n",
      "10175it [10:49,  9.25it/s]Train epoch: 10 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005998\n",
      "10200it [10:52,  9.33it/s]Train epoch: 10 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006446\n",
      "10225it [10:55,  9.18it/s]Train epoch: 10 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006426\n",
      "10250it [10:57,  9.06it/s]Train epoch: 10 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006983\n",
      "10275it [11:00,  9.24it/s]Train epoch: 10 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006125\n",
      "10300it [11:03,  8.88it/s]Train epoch: 10 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006786\n",
      "10325it [11:06,  9.06it/s]Train epoch: 10 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006622\n",
      "10350it [11:09,  9.13it/s]Train epoch: 10 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006240\n",
      "10375it [11:11,  8.90it/s]Train epoch: 10 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006509\n",
      "10400it [11:14,  8.65it/s]Train epoch: 10 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006583\n",
      "10425it [11:17,  8.51it/s]Train epoch: 10 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006195\n",
      "10450it [11:20,  8.65it/s]Train epoch: 10 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006597\n",
      "10475it [11:23,  8.53it/s]Train epoch: 10 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005724\n",
      "10500it [11:26,  8.44it/s]Train epoch: 10 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006598\n",
      "10525it [11:29,  8.55it/s]Train epoch: 10 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006298\n",
      "10550it [11:32,  8.34it/s]Train epoch: 10 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006600\n",
      "10575it [11:35,  8.54it/s]Train epoch: 10 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005855\n",
      "10600it [11:38,  8.18it/s]Train epoch: 10 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.006023\n",
      "10625it [11:41,  8.22it/s]Train epoch: 10 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006852\n",
      "10650it [11:44,  8.36it/s]Train epoch: 10 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006195\n",
      "10675it [11:47,  8.19it/s]Train epoch: 10 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006676\n",
      "10700it [11:50,  8.07it/s]Train epoch: 10 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006258\n",
      "10725it [11:53,  8.05it/s]Train epoch: 10 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005856\n",
      "10750it [11:56,  8.01it/s]Train epoch: 10 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006905\n",
      "10775it [11:59,  8.04it/s]Train epoch: 10 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006819\n",
      "10800it [12:02,  8.05it/s]Train epoch: 10 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.007011\n",
      "10825it [12:05,  7.93it/s]Train epoch: 10 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006936\n",
      "10850it [12:08,  8.12it/s]Train epoch: 10 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006840\n",
      "10875it [12:12,  7.99it/s]Train epoch: 10 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006902\n",
      "10900it [12:15,  7.90it/s]Train epoch: 10 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006790\n",
      "10925it [12:18,  8.13it/s]Train epoch: 10 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006141\n",
      "10950it [12:21,  7.89it/s]Train epoch: 10 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006721\n",
      "10975it [12:24,  8.09it/s]Train epoch: 10 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000it [12:27,  8.01it/s]Train epoch: 10 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006416\n",
      "11025it [12:30,  8.00it/s]Train epoch: 10 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006626\n",
      "11050it [12:34,  7.88it/s]Train epoch: 10 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007399\n",
      "11075it [12:37,  7.91it/s]Train epoch: 10 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006914\n",
      "11100it [12:40,  7.83it/s]Train epoch: 10 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007613\n",
      "11125it [12:43,  8.03it/s]Train epoch: 10 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007082\n",
      "11150it [12:46,  8.01it/s]Train epoch: 10 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006786\n",
      "11175it [12:49,  7.86it/s]Train epoch: 10 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007907\n",
      "11200it [12:52,  8.12it/s]Train epoch: 10 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007164\n",
      "11225it [12:56,  7.96it/s]Train epoch: 10 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007125\n",
      "11250it [12:59,  7.92it/s]Train epoch: 10 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007723\n",
      "11275it [13:02,  8.09it/s]Train epoch: 10 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007459\n",
      "11300it [13:05,  8.02it/s]Train epoch: 10 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006775\n",
      "11325it [13:08,  7.88it/s]Train epoch: 10 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007969\n",
      "11350it [13:11,  7.72it/s]Train epoch: 10 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007895\n",
      "11375it [13:15,  8.20it/s]Train epoch: 10 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.008086\n",
      "11400it [13:18,  7.91it/s]Train epoch: 10 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007088\n",
      "11425it [13:21,  8.14it/s]Train epoch: 10 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007749\n",
      "11450it [13:24,  8.01it/s]Train epoch: 10 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006869\n",
      "11475it [13:27,  7.96it/s]Train epoch: 10 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008353\n",
      "11500it [13:30,  7.78it/s]Train epoch: 10 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007955\n",
      "11525it [13:33,  7.78it/s]Train epoch: 10 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007308\n",
      "11550it [13:37,  7.96it/s]Train epoch: 10 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007309\n",
      "11575it [13:40,  8.02it/s]Train epoch: 10 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008365\n",
      "11600it [13:43,  7.72it/s]Train epoch: 10 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007762\n",
      "11625it [13:46,  8.03it/s]Train epoch: 10 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007282\n",
      "11650it [13:49,  7.97it/s]Train epoch: 10 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007865\n",
      "11675it [13:52,  8.02it/s]Train epoch: 10 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008290\n",
      "11700it [13:55,  7.84it/s]Train epoch: 10 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008846\n",
      "11725it [13:59,  7.93it/s]Train epoch: 10 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008715\n",
      "11750it [14:02,  7.98it/s]Train epoch: 10 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008500\n",
      "11775it [14:05,  7.85it/s]Train epoch: 10 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008647\n",
      "11800it [14:08,  7.81it/s]Train epoch: 10 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008431\n",
      "11825it [14:11,  7.98it/s]Train epoch: 10 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008617\n",
      "11850it [14:14,  7.91it/s]Train epoch: 10 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008918\n",
      "11875it [14:18,  7.97it/s]Train epoch: 10 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009896\n",
      "11900it [14:21,  7.79it/s]Train epoch: 10 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011884\n",
      "11925it [14:24,  7.77it/s]Train epoch: 10 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009995\n",
      "11930it [14:25, 13.79it/s]\n",
      "epoch loss: 0.004933155808046074\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 129.48it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0300, 0.0445, 0.0467, 0.0456, 0.8781\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3233, 0.5494, 0.4399, 0.4886, 0.9815\n",
      "rec_at_8: 0.3487\n",
      "prec_at_8: 0.6441\n",
      "rec_at_15: 0.4870\n",
      "prec_at_15: 0.5016\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 131.75it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0296, 0.0484, 0.0474, 0.0479, 0.8696\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3174, 0.5465, 0.4309, 0.4818, 0.9811\n",
      "rec_at_8: 0.3374\n",
      "prec_at_8: 0.6479\n",
      "rec_at_15: 0.4682\n",
      "prec_at_15: 0.5012\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 10\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0300, 0.0445, 0.0467, 0.0456, 0.8781\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3233, 0.5494, 0.4399, 0.4886, 0.9815\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0068\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 10\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0296, 0.0484, 0.0474, 0.0479, 0.8696\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3174, 0.5465, 0.4309, 0.4818, 0.9811\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 11\n",
      "0it [00:00, ?it/s]Train epoch: 11 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006490\n",
      "25it [00:00, 42.06it/s]Train epoch: 11 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003981\n",
      "49it [00:01, 42.05it/s]Train epoch: 11 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003743\n",
      "75it [00:01, 43.01it/s]Train epoch: 11 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003064\n",
      "100it [00:02, 37.46it/s]Train epoch: 11 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003258\n",
      "122it [00:02, 38.56it/s]Train epoch: 11 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003219\n",
      "147it [00:03, 35.54it/s]Train epoch: 11 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003027\n",
      "171it [00:04, 36.56it/s]Train epoch: 11 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003178\n",
      "200it [00:05, 35.14it/s]Train epoch: 11 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002990\n",
      "224it [00:05, 34.22it/s]Train epoch: 11 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003806\n",
      "250it [00:06, 34.35it/s]Train epoch: 11 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003108\n",
      "274it [00:07, 31.90it/s]Train epoch: 11 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002623\n",
      "298it [00:08, 34.01it/s]Train epoch: 11 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003412\n",
      "322it [00:08, 34.49it/s]Train epoch: 11 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002818\n",
      "350it [00:09, 32.99it/s]Train epoch: 11 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003347\n",
      "374it [00:10, 33.46it/s]Train epoch: 11 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003195\n",
      "398it [00:10, 31.88it/s]Train epoch: 11 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003206\n",
      "422it [00:11, 30.10it/s]Train epoch: 11 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003210\n",
      "450it [00:12, 32.30it/s]Train epoch: 11 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003181\n",
      "474it [00:13, 32.52it/s]Train epoch: 11 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003605\n",
      "498it [00:14, 29.97it/s]Train epoch: 11 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003092\n",
      "522it [00:14, 30.17it/s]Train epoch: 11 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003320\n",
      "548it [00:15, 29.05it/s]Train epoch: 11 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003282\n",
      "575it [00:16, 29.32it/s]Train epoch: 11 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003215\n",
      "598it [00:17, 30.03it/s]Train epoch: 11 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003510\n",
      "622it [00:18, 30.14it/s]Train epoch: 11 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003402\n",
      "650it [00:19, 29.35it/s]Train epoch: 11 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674it [00:20, 29.31it/s]Train epoch: 11 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002564\n",
      "699it [00:20, 28.91it/s]Train epoch: 11 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003181\n",
      "725it [00:21, 28.77it/s]Train epoch: 11 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003387\n",
      "750it [00:22, 28.50it/s]Train epoch: 11 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003156\n",
      "772it [00:23, 29.11it/s]Train epoch: 11 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003466\n",
      "799it [00:24, 27.88it/s]Train epoch: 11 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003378\n",
      "825it [00:25, 26.93it/s]Train epoch: 11 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003269\n",
      "847it [00:26, 28.02it/s]Train epoch: 11 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003688\n",
      "873it [00:26, 29.58it/s]Train epoch: 11 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003077\n",
      "898it [00:27, 27.07it/s]Train epoch: 11 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003364\n",
      "924it [00:28, 27.37it/s]Train epoch: 11 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003149\n",
      "949it [00:29, 27.74it/s]Train epoch: 11 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003130\n",
      "974it [00:30, 28.14it/s]Train epoch: 11 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002433\n",
      "999it [00:31, 27.49it/s]Train epoch: 11 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003306\n",
      "1023it [00:32, 27.06it/s]Train epoch: 11 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004497\n",
      "1048it [00:33, 28.01it/s]Train epoch: 11 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003053\n",
      "1075it [00:34, 26.38it/s]Train epoch: 11 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003540\n",
      "1100it [00:35, 27.99it/s]Train epoch: 11 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003573\n",
      "1123it [00:36, 26.78it/s]Train epoch: 11 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003610\n",
      "1149it [00:37, 26.83it/s]Train epoch: 11 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003581\n",
      "1174it [00:38, 28.37it/s]Train epoch: 11 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003485\n",
      "1198it [00:38, 25.68it/s]Train epoch: 11 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003667\n",
      "1225it [00:39, 25.95it/s]Train epoch: 11 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003786\n",
      "1249it [00:40, 26.13it/s]Train epoch: 11 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003460\n",
      "1274it [00:41, 27.16it/s]Train epoch: 11 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003049\n",
      "1298it [00:42, 26.70it/s]Train epoch: 11 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003062\n",
      "1323it [00:43, 25.87it/s]Train epoch: 11 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003123\n",
      "1348it [00:44, 27.55it/s]Train epoch: 11 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004190\n",
      "1375it [00:45, 25.57it/s]Train epoch: 11 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003436\n",
      "1400it [00:46, 27.15it/s]Train epoch: 11 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003414\n",
      "1425it [00:47, 26.04it/s]Train epoch: 11 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003036\n",
      "1449it [00:48, 23.74it/s]Train epoch: 11 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003314\n",
      "1473it [00:49, 26.98it/s]Train epoch: 11 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003450\n",
      "1498it [00:50, 26.18it/s]Train epoch: 11 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004579\n",
      "1525it [00:51, 26.40it/s]Train epoch: 11 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004248\n",
      "1549it [00:52, 25.21it/s]Train epoch: 11 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003284\n",
      "1573it [00:53, 24.43it/s]Train epoch: 11 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003589\n",
      "1598it [00:54, 25.73it/s]Train epoch: 11 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003137\n",
      "1625it [00:55, 26.01it/s]Train epoch: 11 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003812\n",
      "1649it [00:56, 25.59it/s]Train epoch: 11 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003879\n",
      "1673it [00:57, 25.97it/s]Train epoch: 11 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003713\n",
      "1700it [00:58, 25.13it/s]Train epoch: 11 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003154\n",
      "1724it [00:59, 24.42it/s]Train epoch: 11 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002854\n",
      "1748it [01:00, 25.57it/s]Train epoch: 11 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004255\n",
      "1775it [01:01, 25.10it/s]Train epoch: 11 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003567\n",
      "1799it [01:02, 25.79it/s]Train epoch: 11 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003458\n",
      "1823it [01:03, 24.29it/s]Train epoch: 11 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002857\n",
      "1850it [01:04, 23.85it/s]Train epoch: 11 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003631\n",
      "1874it [01:05, 23.66it/s]Train epoch: 11 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003967\n",
      "1898it [01:06, 25.61it/s]Train epoch: 11 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002851\n",
      "1925it [01:07, 25.66it/s]Train epoch: 11 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003131\n",
      "1949it [01:08, 24.47it/s]Train epoch: 11 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003083\n",
      "1973it [01:09, 25.96it/s]Train epoch: 11 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003641\n",
      "2000it [01:10, 25.03it/s]Train epoch: 11 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002933\n",
      "2024it [01:11, 23.89it/s]Train epoch: 11 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003622\n",
      "2050it [01:12, 25.60it/s]Train epoch: 11 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003358\n",
      "2074it [01:13, 24.31it/s]Train epoch: 11 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003464\n",
      "2098it [01:14, 24.22it/s]Train epoch: 11 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003683\n",
      "2125it [01:15, 25.07it/s]Train epoch: 11 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003920\n",
      "2149it [01:16, 25.20it/s]Train epoch: 11 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003366\n",
      "2173it [01:17, 24.15it/s]Train epoch: 11 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003799\n",
      "2200it [01:18, 24.72it/s]Train epoch: 11 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003638\n",
      "2224it [01:19, 24.04it/s]Train epoch: 11 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003414\n",
      "2248it [01:20, 23.43it/s]Train epoch: 11 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003180\n",
      "2275it [01:21, 23.85it/s]Train epoch: 11 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003638\n",
      "2299it [01:22, 23.61it/s]Train epoch: 11 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002791\n",
      "2323it [01:23, 22.83it/s]Train epoch: 11 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003472\n",
      "2350it [01:24, 24.99it/s]Train epoch: 11 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003228\n",
      "2374it [01:25, 24.71it/s]Train epoch: 11 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004590\n",
      "2398it [01:26, 24.80it/s]Train epoch: 11 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004234\n",
      "2425it [01:27, 23.46it/s]Train epoch: 11 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002962\n",
      "2449it [01:28, 24.51it/s]Train epoch: 11 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003453\n",
      "2473it [01:29, 21.80it/s]Train epoch: 11 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003905\n",
      "2500it [01:31, 22.68it/s]Train epoch: 11 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003357\n",
      "2524it [01:32, 22.73it/s]Train epoch: 11 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003262\n",
      "2548it [01:33, 24.42it/s]Train epoch: 11 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004554\n",
      "2575it [01:34, 22.74it/s]Train epoch: 11 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003243\n",
      "2599it [01:35, 22.34it/s]Train epoch: 11 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003511\n",
      "2623it [01:36, 23.02it/s]Train epoch: 11 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003501\n",
      "2650it [01:37, 21.90it/s]Train epoch: 11 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004089\n",
      "2674it [01:38, 21.25it/s]Train epoch: 11 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003673\n",
      "2698it [01:39, 23.47it/s]Train epoch: 11 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2725it [01:40, 21.52it/s]Train epoch: 11 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003481\n",
      "2749it [01:41, 21.82it/s]Train epoch: 11 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004093\n",
      "2773it [01:43, 21.74it/s]Train epoch: 11 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003564\n",
      "2800it [01:44, 21.78it/s]Train epoch: 11 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003396\n",
      "2824it [01:45, 21.47it/s]Train epoch: 11 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003861\n",
      "2848it [01:46, 21.08it/s]Train epoch: 11 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003587\n",
      "2875it [01:47, 21.12it/s]Train epoch: 11 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003898\n",
      "2899it [01:48, 21.58it/s]Train epoch: 11 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003820\n",
      "2923it [01:49, 22.03it/s]Train epoch: 11 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003945\n",
      "2950it [01:51, 21.43it/s]Train epoch: 11 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004032\n",
      "2974it [01:52, 22.09it/s]Train epoch: 11 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003812\n",
      "2998it [01:53, 20.33it/s]Train epoch: 11 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004350\n",
      "3025it [01:54, 22.14it/s]Train epoch: 11 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003959\n",
      "3049it [01:55, 21.28it/s]Train epoch: 11 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003427\n",
      "3073it [01:56, 22.24it/s]Train epoch: 11 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003960\n",
      "3100it [01:58, 20.98it/s]Train epoch: 11 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003970\n",
      "3124it [01:59, 21.60it/s]Train epoch: 11 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003687\n",
      "3148it [02:00, 21.50it/s]Train epoch: 11 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003530\n",
      "3175it [02:01, 20.96it/s]Train epoch: 11 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003516\n",
      "3199it [02:02, 20.64it/s]Train epoch: 11 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004120\n",
      "3223it [02:03, 21.45it/s]Train epoch: 11 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004034\n",
      "3250it [02:05, 22.17it/s]Train epoch: 11 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004035\n",
      "3274it [02:06, 21.00it/s]Train epoch: 11 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003555\n",
      "3298it [02:07, 22.18it/s]Train epoch: 11 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004450\n",
      "3325it [02:08, 21.69it/s]Train epoch: 11 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003801\n",
      "3349it [02:09, 22.14it/s]Train epoch: 11 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003828\n",
      "3373it [02:10, 21.47it/s]Train epoch: 11 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.004044\n",
      "3400it [02:11, 21.80it/s]Train epoch: 11 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004113\n",
      "3424it [02:13, 20.72it/s]Train epoch: 11 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003567\n",
      "3448it [02:14, 20.61it/s]Train epoch: 11 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004181\n",
      "3475it [02:15, 20.86it/s]Train epoch: 11 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003715\n",
      "3499it [02:16, 20.75it/s]Train epoch: 11 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003789\n",
      "3523it [02:17, 21.58it/s]Train epoch: 11 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003933\n",
      "3550it [02:19, 20.70it/s]Train epoch: 11 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004256\n",
      "3574it [02:20, 21.30it/s]Train epoch: 11 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003373\n",
      "3598it [02:21, 20.58it/s]Train epoch: 11 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004434\n",
      "3625it [02:22, 20.99it/s]Train epoch: 11 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.004005\n",
      "3649it [02:23, 19.14it/s]Train epoch: 11 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004131\n",
      "3674it [02:25, 17.59it/s]Train epoch: 11 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004129\n",
      "3699it [02:26, 18.31it/s]Train epoch: 11 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004180\n",
      "3725it [02:28, 17.78it/s]Train epoch: 11 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004190\n",
      "3750it [02:29, 17.62it/s]Train epoch: 11 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004230\n",
      "3774it [02:30, 17.92it/s]Train epoch: 11 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004037\n",
      "3800it [02:32, 17.42it/s]Train epoch: 11 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004501\n",
      "3824it [02:33, 18.44it/s]Train epoch: 11 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003803\n",
      "3849it [02:35, 17.97it/s]Train epoch: 11 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003545\n",
      "3875it [02:36, 17.77it/s]Train epoch: 11 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003482\n",
      "3899it [02:37, 17.52it/s]Train epoch: 11 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004508\n",
      "3925it [02:39, 17.77it/s]Train epoch: 11 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004135\n",
      "3949it [02:40, 17.12it/s]Train epoch: 11 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004426\n",
      "3975it [02:42, 17.04it/s]Train epoch: 11 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.005019\n",
      "3999it [02:43, 17.24it/s]Train epoch: 11 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003760\n",
      "4025it [02:45, 17.13it/s]Train epoch: 11 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004684\n",
      "4049it [02:46, 17.49it/s]Train epoch: 11 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004233\n",
      "4075it [02:47, 17.61it/s]Train epoch: 11 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004204\n",
      "4099it [02:49, 17.42it/s]Train epoch: 11 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004632\n",
      "4124it [02:50, 17.49it/s]Train epoch: 11 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004511\n",
      "4150it [02:52, 17.37it/s]Train epoch: 11 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003842\n",
      "4174it [02:53, 17.54it/s]Train epoch: 11 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004171\n",
      "4200it [02:55, 17.58it/s]Train epoch: 11 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004525\n",
      "4224it [02:56, 17.79it/s]Train epoch: 11 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003810\n",
      "4249it [02:58, 17.54it/s]Train epoch: 11 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004380\n",
      "4274it [02:59, 16.85it/s]Train epoch: 11 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004056\n",
      "4299it [03:00, 18.32it/s]Train epoch: 11 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004760\n",
      "4325it [03:02, 17.14it/s]Train epoch: 11 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004196\n",
      "4349it [03:03, 17.63it/s]Train epoch: 11 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004554\n",
      "4375it [03:05, 16.89it/s]Train epoch: 11 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004069\n",
      "4399it [03:06, 17.26it/s]Train epoch: 11 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003499\n",
      "4425it [03:08, 17.15it/s]Train epoch: 11 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004296\n",
      "4449it [03:09, 17.12it/s]Train epoch: 11 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003451\n",
      "4475it [03:11, 16.40it/s]Train epoch: 11 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004467\n",
      "4499it [03:12, 16.73it/s]Train epoch: 11 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005068\n",
      "4525it [03:14, 17.00it/s]Train epoch: 11 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004441\n",
      "4549it [03:15, 16.85it/s]Train epoch: 11 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004105\n",
      "4575it [03:17, 17.03it/s]Train epoch: 11 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004719\n",
      "4599it [03:18, 15.52it/s]Train epoch: 11 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004005\n",
      "4625it [03:20, 16.40it/s]Train epoch: 11 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004046\n",
      "4649it [03:21, 16.22it/s]Train epoch: 11 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004599\n",
      "4675it [03:23, 16.27it/s]Train epoch: 11 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004416\n",
      "4699it [03:24, 15.28it/s]Train epoch: 11 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003927\n",
      "4725it [03:26, 15.37it/s]Train epoch: 11 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004130\n",
      "4749it [03:28, 15.89it/s]Train epoch: 11 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4775it [03:29, 16.08it/s]Train epoch: 11 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004261\n",
      "4799it [03:31, 16.63it/s]Train epoch: 11 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004404\n",
      "4825it [03:32, 15.75it/s]Train epoch: 11 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003930\n",
      "4849it [03:34, 15.83it/s]Train epoch: 11 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004558\n",
      "4875it [03:35, 15.41it/s]Train epoch: 11 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003923\n",
      "4899it [03:37, 15.64it/s]Train epoch: 11 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004332\n",
      "4925it [03:39, 15.60it/s]Train epoch: 11 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003934\n",
      "4949it [03:40, 15.66it/s]Train epoch: 11 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004233\n",
      "4975it [03:42, 14.98it/s]Train epoch: 11 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004328\n",
      "4999it [03:43, 15.60it/s]Train epoch: 11 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004219\n",
      "5025it [03:45, 15.87it/s]Train epoch: 11 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004016\n",
      "5049it [03:47, 15.59it/s]Train epoch: 11 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004010\n",
      "5075it [03:48, 15.22it/s]Train epoch: 11 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004238\n",
      "5099it [03:50, 15.91it/s]Train epoch: 11 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004342\n",
      "5125it [03:51, 15.15it/s]Train epoch: 11 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004559\n",
      "5149it [03:53, 14.68it/s]Train epoch: 11 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004574\n",
      "5175it [03:55, 15.72it/s]Train epoch: 11 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004500\n",
      "5199it [03:56, 15.50it/s]Train epoch: 11 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004061\n",
      "5225it [03:58, 15.18it/s]Train epoch: 11 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004332\n",
      "5249it [04:00, 14.65it/s]Train epoch: 11 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004287\n",
      "5275it [04:01, 15.65it/s]Train epoch: 11 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004130\n",
      "5299it [04:03, 15.39it/s]Train epoch: 11 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004092\n",
      "5325it [04:04, 14.86it/s]Train epoch: 11 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004528\n",
      "5349it [04:06, 14.96it/s]Train epoch: 11 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004557\n",
      "5375it [04:08, 15.14it/s]Train epoch: 11 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004187\n",
      "5399it [04:09, 15.20it/s]Train epoch: 11 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004209\n",
      "5425it [04:11, 14.78it/s]Train epoch: 11 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004565\n",
      "5449it [04:13, 15.04it/s]Train epoch: 11 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004445\n",
      "5475it [04:14, 15.39it/s]Train epoch: 11 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005106\n",
      "5499it [04:16, 14.90it/s]Train epoch: 11 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004764\n",
      "5525it [04:18, 14.68it/s]Train epoch: 11 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003914\n",
      "5549it [04:19, 15.05it/s]Train epoch: 11 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004462\n",
      "5575it [04:21, 15.38it/s]Train epoch: 11 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004541\n",
      "5599it [04:23, 15.11it/s]Train epoch: 11 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004824\n",
      "5625it [04:24, 14.61it/s]Train epoch: 11 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004548\n",
      "5649it [04:26, 15.08it/s]Train epoch: 11 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004065\n",
      "5675it [04:28, 14.82it/s]Train epoch: 11 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.004999\n",
      "5699it [04:29, 14.82it/s]Train epoch: 11 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004330\n",
      "5725it [04:31, 15.11it/s]Train epoch: 11 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004485\n",
      "5749it [04:33, 14.74it/s]Train epoch: 11 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005589\n",
      "5775it [04:35, 15.09it/s]Train epoch: 11 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004682\n",
      "5799it [04:36, 14.63it/s]Train epoch: 11 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004711\n",
      "5825it [04:38, 14.44it/s]Train epoch: 11 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004209\n",
      "5849it [04:40, 14.50it/s]Train epoch: 11 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005328\n",
      "5875it [04:41, 14.81it/s]Train epoch: 11 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005150\n",
      "5899it [04:43, 14.75it/s]Train epoch: 11 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005131\n",
      "5925it [04:45, 14.69it/s]Train epoch: 11 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004206\n",
      "5949it [04:46, 14.34it/s]Train epoch: 11 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004076\n",
      "5975it [04:48, 14.60it/s]Train epoch: 11 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005689\n",
      "5999it [04:50, 14.10it/s]Train epoch: 11 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004815\n",
      "6025it [04:52, 14.35it/s]Train epoch: 11 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.005028\n",
      "6049it [04:53, 14.44it/s]Train epoch: 11 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004500\n",
      "6075it [04:55, 15.01it/s]Train epoch: 11 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004197\n",
      "6099it [04:57, 14.30it/s]Train epoch: 11 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004047\n",
      "6125it [04:59, 14.30it/s]Train epoch: 11 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004481\n",
      "6149it [05:00, 14.66it/s]Train epoch: 11 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004534\n",
      "6175it [05:02, 14.59it/s]Train epoch: 11 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005208\n",
      "6199it [05:04, 14.44it/s]Train epoch: 11 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004584\n",
      "6225it [05:06, 14.26it/s]Train epoch: 11 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003958\n",
      "6249it [05:07, 14.35it/s]Train epoch: 11 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004313\n",
      "6275it [05:09, 14.30it/s]Train epoch: 11 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003882\n",
      "6299it [05:11, 14.70it/s]Train epoch: 11 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004537\n",
      "6325it [05:13, 14.46it/s]Train epoch: 11 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005038\n",
      "6349it [05:14, 14.44it/s]Train epoch: 11 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005341\n",
      "6375it [05:16, 13.89it/s]Train epoch: 11 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004193\n",
      "6399it [05:18, 14.24it/s]Train epoch: 11 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004348\n",
      "6425it [05:20, 13.76it/s]Train epoch: 11 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.005078\n",
      "6449it [05:21, 14.16it/s]Train epoch: 11 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004918\n",
      "6475it [05:23, 13.82it/s]Train epoch: 11 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004394\n",
      "6499it [05:25, 13.62it/s]Train epoch: 11 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004997\n",
      "6525it [05:27, 13.89it/s]Train epoch: 11 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004287\n",
      "6549it [05:28, 13.99it/s]Train epoch: 11 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004475\n",
      "6575it [05:30, 13.84it/s]Train epoch: 11 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004612\n",
      "6599it [05:32, 13.97it/s]Train epoch: 11 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005601\n",
      "6625it [05:34, 13.64it/s]Train epoch: 11 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004568\n",
      "6649it [05:36, 13.63it/s]Train epoch: 11 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005153\n",
      "6675it [05:38, 13.59it/s]Train epoch: 11 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004743\n",
      "6699it [05:39, 13.67it/s]Train epoch: 11 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004817\n",
      "6725it [05:41, 13.21it/s]Train epoch: 11 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004836\n",
      "6749it [05:43, 13.72it/s]Train epoch: 11 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004321\n",
      "6775it [05:45, 13.75it/s]Train epoch: 11 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6799it [05:47, 13.12it/s]Train epoch: 11 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005049\n",
      "6825it [05:49, 13.40it/s]Train epoch: 11 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005204\n",
      "6849it [05:50, 13.36it/s]Train epoch: 11 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005001\n",
      "6875it [05:52, 13.62it/s]Train epoch: 11 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004053\n",
      "6899it [05:54, 13.13it/s]Train epoch: 11 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004714\n",
      "6925it [05:56, 13.07it/s]Train epoch: 11 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004747\n",
      "6949it [05:58, 13.55it/s]Train epoch: 11 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005313\n",
      "6975it [06:00, 13.16it/s]Train epoch: 11 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004954\n",
      "6999it [06:02, 13.26it/s]Train epoch: 11 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004707\n",
      "7025it [06:04, 13.26it/s]Train epoch: 11 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005375\n",
      "7049it [06:06, 12.79it/s]Train epoch: 11 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004348\n",
      "7075it [06:08, 13.16it/s]Train epoch: 11 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004658\n",
      "7099it [06:09, 13.19it/s]Train epoch: 11 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005152\n",
      "7125it [06:11, 13.24it/s]Train epoch: 11 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004401\n",
      "7149it [06:13, 13.01it/s]Train epoch: 11 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005353\n",
      "7175it [06:15, 13.15it/s]Train epoch: 11 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004907\n",
      "7199it [06:17, 13.37it/s]Train epoch: 11 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005258\n",
      "7225it [06:19, 12.77it/s]Train epoch: 11 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004758\n",
      "7249it [06:21, 12.54it/s]Train epoch: 11 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004864\n",
      "7275it [06:23, 13.36it/s]Train epoch: 11 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005333\n",
      "7299it [06:25, 12.55it/s]Train epoch: 11 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005690\n",
      "7325it [06:27, 13.18it/s]Train epoch: 11 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004567\n",
      "7349it [06:29, 12.94it/s]Train epoch: 11 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005537\n",
      "7375it [06:31, 12.95it/s]Train epoch: 11 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005199\n",
      "7399it [06:33, 13.09it/s]Train epoch: 11 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004695\n",
      "7425it [06:35, 12.44it/s]Train epoch: 11 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005121\n",
      "7449it [06:37, 12.55it/s]Train epoch: 11 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005702\n",
      "7475it [06:39, 12.59it/s]Train epoch: 11 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004897\n",
      "7499it [06:40, 12.71it/s]Train epoch: 11 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005139\n",
      "7525it [06:42, 12.58it/s]Train epoch: 11 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004911\n",
      "7549it [06:44, 12.95it/s]Train epoch: 11 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004814\n",
      "7575it [06:46, 12.88it/s]Train epoch: 11 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005297\n",
      "7599it [06:48, 12.43it/s]Train epoch: 11 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006222\n",
      "7625it [06:50, 12.72it/s]Train epoch: 11 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005791\n",
      "7649it [06:52, 12.73it/s]Train epoch: 11 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004952\n",
      "7675it [06:54, 12.92it/s]Train epoch: 11 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.005035\n",
      "7699it [06:56, 12.51it/s]Train epoch: 11 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005062\n",
      "7725it [06:58, 12.27it/s]Train epoch: 11 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005078\n",
      "7749it [07:00, 12.30it/s]Train epoch: 11 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005404\n",
      "7775it [07:02, 12.17it/s]Train epoch: 11 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004707\n",
      "7799it [07:04, 12.54it/s]Train epoch: 11 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004922\n",
      "7825it [07:06, 12.63it/s]Train epoch: 11 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005221\n",
      "7849it [07:08, 12.70it/s]Train epoch: 11 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004683\n",
      "7875it [07:10, 12.35it/s]Train epoch: 11 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004915\n",
      "7899it [07:12, 12.43it/s]Train epoch: 11 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005167\n",
      "7925it [07:14, 12.26it/s]Train epoch: 11 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005122\n",
      "7949it [07:16, 12.48it/s]Train epoch: 11 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005769\n",
      "7975it [07:18, 12.06it/s]Train epoch: 11 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004950\n",
      "7999it [07:20, 12.17it/s]Train epoch: 11 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004883\n",
      "8025it [07:23, 12.51it/s]Train epoch: 11 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005245\n",
      "8049it [07:24, 12.01it/s]Train epoch: 11 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004567\n",
      "8075it [07:27, 11.93it/s]Train epoch: 11 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005086\n",
      "8099it [07:29, 12.31it/s]Train epoch: 11 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005421\n",
      "8125it [07:31, 12.13it/s]Train epoch: 11 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005600\n",
      "8149it [07:33, 11.79it/s]Train epoch: 11 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004765\n",
      "8175it [07:35, 12.11it/s]Train epoch: 11 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005534\n",
      "8199it [07:37, 11.86it/s]Train epoch: 11 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004801\n",
      "8225it [07:39, 11.78it/s]Train epoch: 11 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006282\n",
      "8249it [07:41, 12.03it/s]Train epoch: 11 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004892\n",
      "8275it [07:43, 11.75it/s]Train epoch: 11 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005491\n",
      "8299it [07:45, 11.88it/s]Train epoch: 11 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004926\n",
      "8325it [07:48, 11.59it/s]Train epoch: 11 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005658\n",
      "8349it [07:50, 11.84it/s]Train epoch: 11 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004777\n",
      "8375it [07:52, 11.68it/s]Train epoch: 11 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005552\n",
      "8399it [07:54, 11.83it/s]Train epoch: 11 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005169\n",
      "8425it [07:56, 11.57it/s]Train epoch: 11 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005159\n",
      "8449it [07:58, 11.47it/s]Train epoch: 11 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005547\n",
      "8475it [08:01, 11.21it/s]Train epoch: 11 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005225\n",
      "8499it [08:03, 11.47it/s]Train epoch: 11 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006081\n",
      "8525it [08:05, 11.53it/s]Train epoch: 11 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005282\n",
      "8549it [08:07, 11.41it/s]Train epoch: 11 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005483\n",
      "8575it [08:09, 11.53it/s]Train epoch: 11 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005107\n",
      "8599it [08:11, 11.05it/s]Train epoch: 11 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005228\n",
      "8625it [08:14, 11.27it/s]Train epoch: 11 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005381\n",
      "8649it [08:16, 11.06it/s]Train epoch: 11 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005472\n",
      "8675it [08:18, 11.25it/s]Train epoch: 11 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006145\n",
      "8699it [08:20, 11.20it/s]Train epoch: 11 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006188\n",
      "8725it [08:23, 11.62it/s]Train epoch: 11 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005943\n",
      "8749it [08:25, 11.47it/s]Train epoch: 11 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005568\n",
      "8775it [08:27, 11.17it/s]Train epoch: 11 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005095\n",
      "8799it [08:29, 11.19it/s]Train epoch: 11 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8825it [08:31, 11.30it/s]Train epoch: 11 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005451\n",
      "8849it [08:34, 11.09it/s]Train epoch: 11 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005600\n",
      "8875it [08:36, 11.20it/s]Train epoch: 11 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005361\n",
      "8899it [08:38, 11.25it/s]Train epoch: 11 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005518\n",
      "8925it [08:40, 11.30it/s]Train epoch: 11 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005561\n",
      "8949it [08:43, 10.94it/s]Train epoch: 11 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006283\n",
      "8975it [08:45, 10.83it/s]Train epoch: 11 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005826\n",
      "8999it [08:47, 10.67it/s]Train epoch: 11 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005502\n",
      "9025it [08:50, 11.05it/s]Train epoch: 11 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005613\n",
      "9049it [08:52, 10.77it/s]Train epoch: 11 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005135\n",
      "9075it [08:54, 10.63it/s]Train epoch: 11 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004892\n",
      "9099it [08:56, 10.77it/s]Train epoch: 11 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005789\n",
      "9125it [08:59, 10.67it/s]Train epoch: 11 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005321\n",
      "9149it [09:01, 10.86it/s]Train epoch: 11 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004899\n",
      "9175it [09:04, 10.55it/s]Train epoch: 11 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005261\n",
      "9199it [09:06, 10.45it/s]Train epoch: 11 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005127\n",
      "9225it [09:08, 10.64it/s]Train epoch: 11 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006162\n",
      "9249it [09:10, 10.45it/s]Train epoch: 11 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005435\n",
      "9275it [09:13, 10.44it/s]Train epoch: 11 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005782\n",
      "9299it [09:15, 10.21it/s]Train epoch: 11 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006448\n",
      "9325it [09:18, 10.37it/s]Train epoch: 11 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006219\n",
      "9349it [09:20, 10.37it/s]Train epoch: 11 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006203\n",
      "9375it [09:23, 10.43it/s]Train epoch: 11 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005508\n",
      "9399it [09:25, 10.38it/s]Train epoch: 11 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005706\n",
      "9425it [09:27, 10.42it/s]Train epoch: 11 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005508\n",
      "9449it [09:30, 10.23it/s]Train epoch: 11 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005503\n",
      "9475it [09:32, 10.08it/s]Train epoch: 11 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006135\n",
      "9499it [09:35, 10.10it/s]Train epoch: 11 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005761\n",
      "9525it [09:37, 10.12it/s]Train epoch: 11 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006220\n",
      "9550it [09:40,  9.66it/s]Train epoch: 11 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006047\n",
      "9575it [09:42, 10.03it/s]Train epoch: 11 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006092\n",
      "9600it [09:45, 10.27it/s]Train epoch: 11 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005935\n",
      "9624it [09:47, 10.02it/s]Train epoch: 11 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005369\n",
      "9649it [09:50,  9.88it/s]Train epoch: 11 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005495\n",
      "9675it [09:52, 10.08it/s]Train epoch: 11 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005815\n",
      "9700it [09:55, 10.40it/s]Train epoch: 11 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005189\n",
      "9724it [09:57,  9.92it/s]Train epoch: 11 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005827\n",
      "9749it [10:00,  9.66it/s]Train epoch: 11 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005798\n",
      "9775it [10:02,  9.80it/s]Train epoch: 11 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006523\n",
      "9800it [10:05,  9.46it/s]Train epoch: 11 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006261\n",
      "9825it [10:07,  9.76it/s]Train epoch: 11 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006430\n",
      "9850it [10:10,  9.38it/s]Train epoch: 11 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005853\n",
      "9875it [10:13,  9.59it/s]Train epoch: 11 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006229\n",
      "9900it [10:15,  9.44it/s]Train epoch: 11 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006636\n",
      "9925it [10:18,  9.46it/s]Train epoch: 11 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006194\n",
      "9950it [10:20,  9.54it/s]Train epoch: 11 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006838\n",
      "9974it [10:23,  9.25it/s]Train epoch: 11 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006305\n",
      "10000it [10:26,  9.25it/s]Train epoch: 11 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005876\n",
      "10025it [10:28,  9.32it/s]Train epoch: 11 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005836\n",
      "10050it [10:31,  9.47it/s]Train epoch: 11 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006305\n",
      "10075it [10:34,  9.20it/s]Train epoch: 11 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006787\n",
      "10100it [10:36,  9.26it/s]Train epoch: 11 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006409\n",
      "10125it [10:39,  9.44it/s]Train epoch: 11 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005833\n",
      "10150it [10:42,  9.27it/s]Train epoch: 11 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006368\n",
      "10175it [10:44,  9.07it/s]Train epoch: 11 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005896\n",
      "10200it [10:47,  9.29it/s]Train epoch: 11 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006430\n",
      "10225it [10:50,  9.19it/s]Train epoch: 11 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006336\n",
      "10250it [10:53,  9.14it/s]Train epoch: 11 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006828\n",
      "10275it [10:55,  9.21it/s]Train epoch: 11 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006075\n",
      "10300it [10:58,  9.13it/s]Train epoch: 11 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006772\n",
      "10325it [11:01,  9.04it/s]Train epoch: 11 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006539\n",
      "10350it [11:04,  8.95it/s]Train epoch: 11 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006182\n",
      "10375it [11:06,  9.06it/s]Train epoch: 11 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006445\n",
      "10400it [11:09,  8.70it/s]Train epoch: 11 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006456\n",
      "10425it [11:12,  8.78it/s]Train epoch: 11 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006164\n",
      "10450it [11:15,  8.45it/s]Train epoch: 11 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006531\n",
      "10475it [11:18,  8.41it/s]Train epoch: 11 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005757\n",
      "10500it [11:21,  8.57it/s]Train epoch: 11 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006537\n",
      "10525it [11:24,  8.42it/s]Train epoch: 11 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006216\n",
      "10550it [11:27,  8.38it/s]Train epoch: 11 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006522\n",
      "10575it [11:30,  8.34it/s]Train epoch: 11 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005760\n",
      "10600it [11:33,  8.43it/s]Train epoch: 11 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.006020\n",
      "10625it [11:36,  8.60it/s]Train epoch: 11 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006768\n",
      "10650it [11:39,  8.14it/s]Train epoch: 11 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006122\n",
      "10675it [11:42,  8.12it/s]Train epoch: 11 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006659\n",
      "10700it [11:45,  7.96it/s]Train epoch: 11 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006192\n",
      "10725it [11:48,  7.91it/s]Train epoch: 11 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005773\n",
      "10750it [11:51,  7.99it/s]Train epoch: 11 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006854\n",
      "10775it [11:54,  8.18it/s]Train epoch: 11 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006769\n",
      "10800it [11:57,  8.07it/s]Train epoch: 11 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006933\n",
      "10825it [12:00,  8.01it/s]Train epoch: 11 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10850it [12:03,  7.78it/s]Train epoch: 11 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006753\n",
      "10875it [12:07,  7.93it/s]Train epoch: 11 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006816\n",
      "10900it [12:10,  8.04it/s]Train epoch: 11 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006722\n",
      "10925it [12:13,  8.02it/s]Train epoch: 11 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006056\n",
      "10950it [12:16,  7.92it/s]Train epoch: 11 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006657\n",
      "10975it [12:19,  8.01it/s]Train epoch: 11 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006433\n",
      "11000it [12:22,  7.59it/s]Train epoch: 11 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006353\n",
      "11025it [12:26,  7.99it/s]Train epoch: 11 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006591\n",
      "11050it [12:29,  7.90it/s]Train epoch: 11 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007337\n",
      "11075it [12:32,  7.86it/s]Train epoch: 11 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006862\n",
      "11100it [12:35,  7.92it/s]Train epoch: 11 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007512\n",
      "11125it [12:38,  8.06it/s]Train epoch: 11 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007013\n",
      "11150it [12:41,  7.94it/s]Train epoch: 11 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006713\n",
      "11175it [12:44,  8.18it/s]Train epoch: 11 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007846\n",
      "11200it [12:47,  7.98it/s]Train epoch: 11 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007108\n",
      "11225it [12:51,  8.15it/s]Train epoch: 11 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007090\n",
      "11250it [12:54,  8.02it/s]Train epoch: 11 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007695\n",
      "11275it [12:57,  7.94it/s]Train epoch: 11 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007348\n",
      "11300it [13:00,  7.94it/s]Train epoch: 11 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006699\n",
      "11325it [13:03,  7.89it/s]Train epoch: 11 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007924\n",
      "11350it [13:06,  8.05it/s]Train epoch: 11 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007797\n",
      "11375it [13:09,  7.96it/s]Train epoch: 11 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007974\n",
      "11400it [13:13,  7.95it/s]Train epoch: 11 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007035\n",
      "11425it [13:16,  7.79it/s]Train epoch: 11 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007791\n",
      "11450it [13:19,  7.86it/s]Train epoch: 11 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006840\n",
      "11475it [13:22,  7.97it/s]Train epoch: 11 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008310\n",
      "11500it [13:25,  7.97it/s]Train epoch: 11 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007880\n",
      "11525it [13:28,  8.16it/s]Train epoch: 11 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007234\n",
      "11550it [13:31,  7.81it/s]Train epoch: 11 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007255\n",
      "11575it [13:35,  7.93it/s]Train epoch: 11 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008391\n",
      "11600it [13:38,  7.96it/s]Train epoch: 11 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007730\n",
      "11625it [13:41,  8.03it/s]Train epoch: 11 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007258\n",
      "11650it [13:44,  7.71it/s]Train epoch: 11 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007795\n",
      "11675it [13:47,  7.87it/s]Train epoch: 11 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008216\n",
      "11700it [13:50,  7.86it/s]Train epoch: 11 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008807\n",
      "11725it [13:54,  7.96it/s]Train epoch: 11 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008672\n",
      "11750it [13:57,  7.93it/s]Train epoch: 11 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008475\n",
      "11775it [14:00,  7.73it/s]Train epoch: 11 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008530\n",
      "11800it [14:03,  8.02it/s]Train epoch: 11 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008306\n",
      "11825it [14:06,  8.02it/s]Train epoch: 11 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008561\n",
      "11850it [14:09,  7.89it/s]Train epoch: 11 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008900\n",
      "11875it [14:13,  7.96it/s]Train epoch: 11 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009787\n",
      "11900it [14:16,  7.84it/s]Train epoch: 11 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011767\n",
      "11925it [14:19,  7.81it/s]Train epoch: 11 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009988\n",
      "11930it [14:20, 13.87it/s]\n",
      "epoch loss: 0.004886385570566169\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 129.67it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0311, 0.0457, 0.0482, 0.0469, 0.8785\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3262, 0.5489, 0.4456, 0.4919, 0.9816\n",
      "rec_at_8: 0.3524\n",
      "prec_at_8: 0.6508\n",
      "rec_at_15: 0.4888\n",
      "prec_at_15: 0.5035\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 131.93it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0311, 0.0499, 0.0499, 0.0499, 0.8700\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3213, 0.5481, 0.4371, 0.4863, 0.9813\n",
      "rec_at_8: 0.3389\n",
      "prec_at_8: 0.6509\n",
      "rec_at_15: 0.4713\n",
      "prec_at_15: 0.5045\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 11\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0311, 0.0457, 0.0482, 0.0469, 0.8785\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3262, 0.5489, 0.4456, 0.4919, 0.9816\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0068\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 11\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0311, 0.0499, 0.0499, 0.0499, 0.8700\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3213, 0.5481, 0.4371, 0.4863, 0.9813\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0070\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 12\n",
      "0it [00:00, ?it/s]Train epoch: 12 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006520\n",
      "21it [00:00, 46.44it/s]Train epoch: 12 [batch #25, batch_size 4, seq length 221]\tLoss: 0.004025\n",
      "47it [00:00, 47.75it/s]Train epoch: 12 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003781\n",
      "72it [00:01, 43.05it/s]Train epoch: 12 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003037\n",
      "97it [00:02, 41.71it/s]Train epoch: 12 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003235\n",
      "122it [00:02, 39.69it/s]Train epoch: 12 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003132\n",
      "147it [00:03, 36.16it/s]Train epoch: 12 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003069\n",
      "172it [00:04, 34.18it/s]Train epoch: 12 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003186\n",
      "200it [00:05, 35.56it/s]Train epoch: 12 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002983\n",
      "224it [00:05, 32.78it/s]Train epoch: 12 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003745\n",
      "249it [00:06, 34.52it/s]Train epoch: 12 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003070\n",
      "274it [00:07, 33.91it/s]Train epoch: 12 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002604\n",
      "298it [00:07, 32.22it/s]Train epoch: 12 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003409\n",
      "322it [00:08, 31.21it/s]Train epoch: 12 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002805\n",
      "350it [00:09, 32.05it/s]Train epoch: 12 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003334\n",
      "374it [00:10, 31.38it/s]Train epoch: 12 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003202\n",
      "398it [00:11, 31.89it/s]Train epoch: 12 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003193\n",
      "422it [00:11, 32.61it/s]Train epoch: 12 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003181\n",
      "450it [00:12, 28.77it/s]Train epoch: 12 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003153\n",
      "473it [00:13, 32.97it/s]Train epoch: 12 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003603\n",
      "497it [00:14, 30.30it/s]Train epoch: 12 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525it [00:15, 30.03it/s]Train epoch: 12 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003276\n",
      "548it [00:15, 30.78it/s]Train epoch: 12 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003235\n",
      "572it [00:16, 30.94it/s]Train epoch: 12 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003183\n",
      "600it [00:17, 29.88it/s]Train epoch: 12 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003504\n",
      "623it [00:18, 29.01it/s]Train epoch: 12 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003332\n",
      "647it [00:19, 30.08it/s]Train epoch: 12 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003024\n",
      "673it [00:20, 28.66it/s]Train epoch: 12 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002533\n",
      "698it [00:21, 28.93it/s]Train epoch: 12 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003201\n",
      "722it [00:21, 30.71it/s]Train epoch: 12 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003307\n",
      "750it [00:22, 29.85it/s]Train epoch: 12 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003074\n",
      "775it [00:23, 27.26it/s]Train epoch: 12 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003429\n",
      "799it [00:24, 26.70it/s]Train epoch: 12 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003288\n",
      "825it [00:25, 28.78it/s]Train epoch: 12 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003228\n",
      "847it [00:26, 30.50it/s]Train epoch: 12 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003647\n",
      "875it [00:27, 27.77it/s]Train epoch: 12 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003034\n",
      "898it [00:28, 26.91it/s]Train epoch: 12 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003359\n",
      "923it [00:28, 26.44it/s]Train epoch: 12 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003113\n",
      "950it [00:29, 26.11it/s]Train epoch: 12 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003055\n",
      "974it [00:30, 28.09it/s]Train epoch: 12 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002420\n",
      "1000it [00:31, 28.29it/s]Train epoch: 12 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003226\n",
      "1024it [00:32, 26.31it/s]Train epoch: 12 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004432\n",
      "1049it [00:33, 27.08it/s]Train epoch: 12 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003045\n",
      "1072it [00:34, 27.57it/s]Train epoch: 12 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003527\n",
      "1098it [00:35, 27.70it/s]Train epoch: 12 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003572\n",
      "1124it [00:36, 27.04it/s]Train epoch: 12 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003545\n",
      "1148it [00:37, 27.22it/s]Train epoch: 12 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003546\n",
      "1175it [00:38, 26.58it/s]Train epoch: 12 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003423\n",
      "1197it [00:38, 26.37it/s]Train epoch: 12 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003595\n",
      "1225it [00:39, 27.70it/s]Train epoch: 12 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003725\n",
      "1249it [00:40, 26.60it/s]Train epoch: 12 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003402\n",
      "1273it [00:41, 26.79it/s]Train epoch: 12 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.002998\n",
      "1300it [00:42, 25.95it/s]Train epoch: 12 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003027\n",
      "1324it [00:43, 25.92it/s]Train epoch: 12 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003118\n",
      "1348it [00:44, 26.09it/s]Train epoch: 12 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004107\n",
      "1375it [00:45, 27.20it/s]Train epoch: 12 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003365\n",
      "1399it [00:46, 26.62it/s]Train epoch: 12 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003360\n",
      "1423it [00:47, 25.64it/s]Train epoch: 12 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.002994\n",
      "1450it [00:48, 27.38it/s]Train epoch: 12 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003216\n",
      "1474it [00:49, 26.47it/s]Train epoch: 12 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003457\n",
      "1499it [00:50, 26.84it/s]Train epoch: 12 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004521\n",
      "1523it [00:51, 26.70it/s]Train epoch: 12 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004258\n",
      "1550it [00:52, 25.33it/s]Train epoch: 12 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003221\n",
      "1574it [00:53, 25.73it/s]Train epoch: 12 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003537\n",
      "1599it [00:54, 26.30it/s]Train epoch: 12 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003114\n",
      "1623it [00:55, 26.35it/s]Train epoch: 12 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003791\n",
      "1650it [00:56, 24.97it/s]Train epoch: 12 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003896\n",
      "1674it [00:57, 25.12it/s]Train epoch: 12 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003759\n",
      "1698it [00:58, 24.99it/s]Train epoch: 12 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003158\n",
      "1725it [00:59, 25.63it/s]Train epoch: 12 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002820\n",
      "1749it [01:00, 24.00it/s]Train epoch: 12 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004197\n",
      "1773it [01:01, 24.82it/s]Train epoch: 12 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003526\n",
      "1800it [01:02, 25.77it/s]Train epoch: 12 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003413\n",
      "1824it [01:03, 25.35it/s]Train epoch: 12 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002875\n",
      "1848it [01:04, 25.17it/s]Train epoch: 12 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003601\n",
      "1875it [01:05, 25.33it/s]Train epoch: 12 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003908\n",
      "1899it [01:06, 24.16it/s]Train epoch: 12 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002819\n",
      "1923it [01:07, 25.49it/s]Train epoch: 12 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003064\n",
      "1950it [01:08, 24.86it/s]Train epoch: 12 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003092\n",
      "1974it [01:09, 24.52it/s]Train epoch: 12 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003630\n",
      "1998it [01:10, 24.76it/s]Train epoch: 12 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002947\n",
      "2025it [01:11, 23.79it/s]Train epoch: 12 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003550\n",
      "2049it [01:12, 23.74it/s]Train epoch: 12 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003343\n",
      "2073it [01:13, 24.15it/s]Train epoch: 12 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003463\n",
      "2100it [01:14, 24.44it/s]Train epoch: 12 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003614\n",
      "2124it [01:15, 25.14it/s]Train epoch: 12 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003855\n",
      "2148it [01:16, 24.44it/s]Train epoch: 12 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003364\n",
      "2175it [01:17, 23.79it/s]Train epoch: 12 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003811\n",
      "2199it [01:18, 22.18it/s]Train epoch: 12 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003593\n",
      "2223it [01:19, 23.80it/s]Train epoch: 12 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003378\n",
      "2250it [01:20, 24.03it/s]Train epoch: 12 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003201\n",
      "2274it [01:21, 23.93it/s]Train epoch: 12 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003592\n",
      "2298it [01:22, 24.00it/s]Train epoch: 12 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002725\n",
      "2325it [01:23, 23.36it/s]Train epoch: 12 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003452\n",
      "2349it [01:24, 24.39it/s]Train epoch: 12 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003155\n",
      "2373it [01:25, 24.03it/s]Train epoch: 12 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004518\n",
      "2400it [01:26, 23.36it/s]Train epoch: 12 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004227\n",
      "2424it [01:27, 22.91it/s]Train epoch: 12 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002944\n",
      "2448it [01:29, 21.88it/s]Train epoch: 12 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003410\n",
      "2475it [01:30, 24.02it/s]Train epoch: 12 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003883\n",
      "2499it [01:31, 23.05it/s]Train epoch: 12 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003305\n",
      "2523it [01:32, 22.39it/s]Train epoch: 12 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003216\n",
      "2550it [01:33, 24.31it/s]Train epoch: 12 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004499\n",
      "2574it [01:34, 22.32it/s]Train epoch: 12 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2598it [01:35, 23.51it/s]Train epoch: 12 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003506\n",
      "2625it [01:36, 22.34it/s]Train epoch: 12 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003530\n",
      "2649it [01:37, 22.60it/s]Train epoch: 12 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004053\n",
      "2673it [01:38, 22.94it/s]Train epoch: 12 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003637\n",
      "2700it [01:39, 22.82it/s]Train epoch: 12 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003172\n",
      "2724it [01:40, 23.98it/s]Train epoch: 12 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003433\n",
      "2748it [01:42, 22.89it/s]Train epoch: 12 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004081\n",
      "2775it [01:43, 22.23it/s]Train epoch: 12 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003556\n",
      "2799it [01:44, 22.27it/s]Train epoch: 12 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003382\n",
      "2823it [01:45, 22.18it/s]Train epoch: 12 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003811\n",
      "2850it [01:46, 22.02it/s]Train epoch: 12 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003490\n",
      "2874it [01:47, 22.26it/s]Train epoch: 12 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003838\n",
      "2898it [01:48, 21.69it/s]Train epoch: 12 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003746\n",
      "2925it [01:50, 22.92it/s]Train epoch: 12 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003891\n",
      "2949it [01:51, 22.24it/s]Train epoch: 12 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.003970\n",
      "2973it [01:52, 22.28it/s]Train epoch: 12 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003781\n",
      "3000it [01:53, 21.31it/s]Train epoch: 12 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004311\n",
      "3024it [01:54, 22.67it/s]Train epoch: 12 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003914\n",
      "3048it [01:55, 21.26it/s]Train epoch: 12 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003424\n",
      "3075it [01:56, 21.61it/s]Train epoch: 12 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003926\n",
      "3099it [01:58, 20.50it/s]Train epoch: 12 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003973\n",
      "3123it [01:59, 21.62it/s]Train epoch: 12 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003646\n",
      "3150it [02:00, 21.41it/s]Train epoch: 12 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003532\n",
      "3174it [02:01, 22.51it/s]Train epoch: 12 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003532\n",
      "3198it [02:02, 21.83it/s]Train epoch: 12 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004125\n",
      "3225it [02:03, 21.45it/s]Train epoch: 12 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004001\n",
      "3249it [02:04, 21.20it/s]Train epoch: 12 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.003958\n",
      "3273it [02:06, 21.94it/s]Train epoch: 12 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003579\n",
      "3300it [02:07, 21.38it/s]Train epoch: 12 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004465\n",
      "3324it [02:08, 20.96it/s]Train epoch: 12 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003788\n",
      "3348it [02:09, 21.33it/s]Train epoch: 12 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003843\n",
      "3375it [02:10, 20.54it/s]Train epoch: 12 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.003974\n",
      "3399it [02:12, 21.45it/s]Train epoch: 12 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004074\n",
      "3423it [02:13, 21.23it/s]Train epoch: 12 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003507\n",
      "3450it [02:14, 21.12it/s]Train epoch: 12 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004095\n",
      "3474it [02:15, 21.03it/s]Train epoch: 12 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003653\n",
      "3498it [02:16, 21.67it/s]Train epoch: 12 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003776\n",
      "3525it [02:17, 21.16it/s]Train epoch: 12 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003961\n",
      "3549it [02:19, 21.25it/s]Train epoch: 12 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004238\n",
      "3573it [02:20, 21.64it/s]Train epoch: 12 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003309\n",
      "3600it [02:21, 21.17it/s]Train epoch: 12 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004355\n",
      "3624it [02:22, 21.04it/s]Train epoch: 12 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.003934\n",
      "3650it [02:23, 19.76it/s]Train epoch: 12 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004083\n",
      "3674it [02:25, 18.24it/s]Train epoch: 12 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004083\n",
      "3699it [02:26, 18.69it/s]Train epoch: 12 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004116\n",
      "3724it [02:27, 17.72it/s]Train epoch: 12 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004161\n",
      "3750it [02:29, 18.45it/s]Train epoch: 12 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004166\n",
      "3775it [02:30, 17.64it/s]Train epoch: 12 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004042\n",
      "3800it [02:32, 18.39it/s]Train epoch: 12 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004467\n",
      "3823it [02:33, 17.73it/s]Train epoch: 12 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003803\n",
      "3850it [02:34, 17.61it/s]Train epoch: 12 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003528\n",
      "3873it [02:36, 18.19it/s]Train epoch: 12 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003457\n",
      "3900it [02:37, 16.71it/s]Train epoch: 12 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004453\n",
      "3924it [02:39, 17.37it/s]Train epoch: 12 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004102\n",
      "3949it [02:40, 17.97it/s]Train epoch: 12 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004433\n",
      "3974it [02:41, 17.62it/s]Train epoch: 12 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.004963\n",
      "4000it [02:43, 17.26it/s]Train epoch: 12 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003742\n",
      "4024it [02:44, 18.11it/s]Train epoch: 12 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004651\n",
      "4050it [02:46, 17.08it/s]Train epoch: 12 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004178\n",
      "4074it [02:47, 17.09it/s]Train epoch: 12 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004205\n",
      "4100it [02:49, 17.68it/s]Train epoch: 12 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004581\n",
      "4124it [02:50, 17.48it/s]Train epoch: 12 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004525\n",
      "4150it [02:52, 17.41it/s]Train epoch: 12 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003841\n",
      "4174it [02:53, 18.13it/s]Train epoch: 12 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004162\n",
      "4200it [02:54, 17.68it/s]Train epoch: 12 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004448\n",
      "4224it [02:56, 17.09it/s]Train epoch: 12 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003788\n",
      "4250it [02:57, 17.37it/s]Train epoch: 12 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004317\n",
      "4274it [02:59, 17.48it/s]Train epoch: 12 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004001\n",
      "4300it [03:00, 17.56it/s]Train epoch: 12 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004701\n",
      "4324it [03:02, 16.97it/s]Train epoch: 12 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004091\n",
      "4350it [03:03, 16.52it/s]Train epoch: 12 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004512\n",
      "4374it [03:05, 17.34it/s]Train epoch: 12 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004029\n",
      "4400it [03:06, 17.37it/s]Train epoch: 12 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003475\n",
      "4424it [03:07, 17.27it/s]Train epoch: 12 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004259\n",
      "4450it [03:09, 16.19it/s]Train epoch: 12 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003508\n",
      "4475it [03:10, 17.19it/s]Train epoch: 12 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004433\n",
      "4499it [03:12, 16.25it/s]Train epoch: 12 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005057\n",
      "4525it [03:13, 17.39it/s]Train epoch: 12 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004389\n",
      "4550it [03:15, 17.47it/s]Train epoch: 12 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004097\n",
      "4574it [03:16, 16.84it/s]Train epoch: 12 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004667\n",
      "4600it [03:18, 16.93it/s]Train epoch: 12 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004032\n",
      "4624it [03:19, 16.44it/s]Train epoch: 12 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4650it [03:21, 16.16it/s]Train epoch: 12 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004564\n",
      "4674it [03:22, 16.30it/s]Train epoch: 12 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004361\n",
      "4700it [03:24, 15.78it/s]Train epoch: 12 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003904\n",
      "4724it [03:26, 15.68it/s]Train epoch: 12 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004114\n",
      "4750it [03:27, 16.06it/s]Train epoch: 12 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004751\n",
      "4774it [03:29, 15.99it/s]Train epoch: 12 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004244\n",
      "4800it [03:30, 15.75it/s]Train epoch: 12 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004410\n",
      "4824it [03:32, 15.87it/s]Train epoch: 12 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003852\n",
      "4850it [03:34, 15.28it/s]Train epoch: 12 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004558\n",
      "4874it [03:35, 15.92it/s]Train epoch: 12 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003905\n",
      "4900it [03:37, 15.56it/s]Train epoch: 12 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004271\n",
      "4924it [03:38, 15.52it/s]Train epoch: 12 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003911\n",
      "4950it [03:40, 16.20it/s]Train epoch: 12 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004228\n",
      "4974it [03:42, 15.66it/s]Train epoch: 12 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004287\n",
      "5000it [03:43, 15.33it/s]Train epoch: 12 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004239\n",
      "5024it [03:45, 15.33it/s]Train epoch: 12 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004007\n",
      "5050it [03:46, 15.52it/s]Train epoch: 12 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004013\n",
      "5074it [03:48, 15.79it/s]Train epoch: 12 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004225\n",
      "5100it [03:50, 15.30it/s]Train epoch: 12 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004295\n",
      "5124it [03:51, 15.48it/s]Train epoch: 12 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004485\n",
      "5150it [03:53, 15.27it/s]Train epoch: 12 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004543\n",
      "5174it [03:54, 14.87it/s]Train epoch: 12 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004453\n",
      "5200it [03:56, 15.11it/s]Train epoch: 12 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004035\n",
      "5224it [03:58, 15.60it/s]Train epoch: 12 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004247\n",
      "5250it [03:59, 15.59it/s]Train epoch: 12 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004244\n",
      "5274it [04:01, 15.05it/s]Train epoch: 12 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004106\n",
      "5300it [04:03, 15.05it/s]Train epoch: 12 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004047\n",
      "5324it [04:04, 14.64it/s]Train epoch: 12 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004492\n",
      "5350it [04:06, 15.08it/s]Train epoch: 12 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004523\n",
      "5374it [04:07, 15.27it/s]Train epoch: 12 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004171\n",
      "5400it [04:09, 15.11it/s]Train epoch: 12 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004092\n",
      "5424it [04:11, 15.20it/s]Train epoch: 12 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004578\n",
      "5450it [04:12, 15.24it/s]Train epoch: 12 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004406\n",
      "5474it [04:14, 15.13it/s]Train epoch: 12 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005061\n",
      "5500it [04:16, 14.99it/s]Train epoch: 12 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004718\n",
      "5524it [04:17, 14.90it/s]Train epoch: 12 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003879\n",
      "5550it [04:19, 14.97it/s]Train epoch: 12 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004434\n",
      "5574it [04:21, 14.99it/s]Train epoch: 12 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004566\n",
      "5600it [04:23, 14.54it/s]Train epoch: 12 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004806\n",
      "5624it [04:24, 15.41it/s]Train epoch: 12 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004534\n",
      "5650it [04:26, 15.93it/s]Train epoch: 12 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004045\n",
      "5674it [04:28, 14.99it/s]Train epoch: 12 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.005022\n",
      "5700it [04:29, 14.47it/s]Train epoch: 12 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004358\n",
      "5724it [04:31, 14.84it/s]Train epoch: 12 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004479\n",
      "5750it [04:33, 14.63it/s]Train epoch: 12 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005561\n",
      "5774it [04:34, 14.56it/s]Train epoch: 12 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004651\n",
      "5800it [04:36, 15.34it/s]Train epoch: 12 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004661\n",
      "5824it [04:38, 14.57it/s]Train epoch: 12 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004207\n",
      "5850it [04:39, 14.57it/s]Train epoch: 12 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005279\n",
      "5874it [04:41, 14.49it/s]Train epoch: 12 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005148\n",
      "5900it [04:43, 14.81it/s]Train epoch: 12 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005076\n",
      "5924it [04:44, 14.03it/s]Train epoch: 12 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004171\n",
      "5950it [04:46, 14.42it/s]Train epoch: 12 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004056\n",
      "5974it [04:48, 14.64it/s]Train epoch: 12 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005615\n",
      "6000it [04:50, 13.69it/s]Train epoch: 12 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004789\n",
      "6024it [04:51, 14.53it/s]Train epoch: 12 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.004986\n",
      "6050it [04:53, 14.38it/s]Train epoch: 12 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004428\n",
      "6074it [04:55, 14.76it/s]Train epoch: 12 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004189\n",
      "6100it [04:57, 14.13it/s]Train epoch: 12 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004011\n",
      "6124it [04:58, 15.05it/s]Train epoch: 12 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004494\n",
      "6150it [05:00, 14.29it/s]Train epoch: 12 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004455\n",
      "6174it [05:02, 14.50it/s]Train epoch: 12 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005129\n",
      "6200it [05:04, 14.41it/s]Train epoch: 12 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004476\n",
      "6224it [05:05, 14.60it/s]Train epoch: 12 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003946\n",
      "6250it [05:07, 14.10it/s]Train epoch: 12 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004231\n",
      "6274it [05:09, 14.51it/s]Train epoch: 12 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003862\n",
      "6300it [05:11, 14.18it/s]Train epoch: 12 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004507\n",
      "6324it [05:12, 14.52it/s]Train epoch: 12 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.004974\n",
      "6350it [05:14, 14.11it/s]Train epoch: 12 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005287\n",
      "6374it [05:16, 14.26it/s]Train epoch: 12 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004153\n",
      "6400it [05:18, 14.56it/s]Train epoch: 12 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004373\n",
      "6424it [05:19, 13.84it/s]Train epoch: 12 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.004976\n",
      "6450it [05:21, 14.25it/s]Train epoch: 12 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004817\n",
      "6474it [05:23, 13.97it/s]Train epoch: 12 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004382\n",
      "6500it [05:25, 13.84it/s]Train epoch: 12 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004957\n",
      "6524it [05:27, 13.37it/s]Train epoch: 12 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004236\n",
      "6550it [05:29, 13.73it/s]Train epoch: 12 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004396\n",
      "6574it [05:30, 13.75it/s]Train epoch: 12 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004556\n",
      "6600it [05:32, 13.37it/s]Train epoch: 12 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005554\n",
      "6624it [05:34, 13.50it/s]Train epoch: 12 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004500\n",
      "6650it [05:36, 13.56it/s]Train epoch: 12 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6674it [05:38, 13.55it/s]Train epoch: 12 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004689\n",
      "6700it [05:40, 12.96it/s]Train epoch: 12 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004826\n",
      "6724it [05:41, 13.60it/s]Train epoch: 12 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004818\n",
      "6750it [05:43, 13.80it/s]Train epoch: 12 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004313\n",
      "6774it [05:45, 13.61it/s]Train epoch: 12 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005007\n",
      "6800it [05:47, 13.60it/s]Train epoch: 12 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005064\n",
      "6824it [05:49, 13.50it/s]Train epoch: 12 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005140\n",
      "6850it [05:51, 13.46it/s]Train epoch: 12 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.004991\n",
      "6874it [05:52, 13.84it/s]Train epoch: 12 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004058\n",
      "6900it [05:54, 13.64it/s]Train epoch: 12 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004705\n",
      "6924it [05:56, 13.02it/s]Train epoch: 12 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004767\n",
      "6950it [05:58, 13.29it/s]Train epoch: 12 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005247\n",
      "6974it [06:00, 13.15it/s]Train epoch: 12 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004874\n",
      "7000it [06:02, 12.72it/s]Train epoch: 12 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004669\n",
      "7024it [06:04, 12.85it/s]Train epoch: 12 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005338\n",
      "7050it [06:06, 13.44it/s]Train epoch: 12 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004267\n",
      "7074it [06:08, 12.66it/s]Train epoch: 12 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004691\n",
      "7100it [06:10, 13.24it/s]Train epoch: 12 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005104\n",
      "7124it [06:11, 12.87it/s]Train epoch: 12 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004376\n",
      "7150it [06:13, 12.65it/s]Train epoch: 12 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005288\n",
      "7174it [06:15, 13.09it/s]Train epoch: 12 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004869\n",
      "7200it [06:17, 12.96it/s]Train epoch: 12 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005220\n",
      "7224it [06:19, 13.13it/s]Train epoch: 12 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004754\n",
      "7250it [06:21, 12.72it/s]Train epoch: 12 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004826\n",
      "7274it [06:23, 12.89it/s]Train epoch: 12 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005250\n",
      "7300it [06:25, 12.59it/s]Train epoch: 12 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005679\n",
      "7324it [06:27, 12.91it/s]Train epoch: 12 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004547\n",
      "7350it [06:29, 13.05it/s]Train epoch: 12 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005538\n",
      "7374it [06:31, 12.75it/s]Train epoch: 12 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005136\n",
      "7400it [06:33, 12.41it/s]Train epoch: 12 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004650\n",
      "7424it [06:35, 12.91it/s]Train epoch: 12 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005041\n",
      "7450it [06:37, 13.06it/s]Train epoch: 12 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005656\n",
      "7474it [06:38, 12.76it/s]Train epoch: 12 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004871\n",
      "7500it [06:41, 12.60it/s]Train epoch: 12 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005115\n",
      "7524it [06:42, 13.27it/s]Train epoch: 12 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004891\n",
      "7550it [06:44, 12.74it/s]Train epoch: 12 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004778\n",
      "7574it [06:46, 12.66it/s]Train epoch: 12 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005233\n",
      "7600it [06:48, 12.76it/s]Train epoch: 12 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006209\n",
      "7624it [06:50, 12.42it/s]Train epoch: 12 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005731\n",
      "7650it [06:52, 12.85it/s]Train epoch: 12 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004855\n",
      "7674it [06:54, 12.74it/s]Train epoch: 12 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.004971\n",
      "7700it [06:56, 12.58it/s]Train epoch: 12 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005038\n",
      "7724it [06:58, 12.20it/s]Train epoch: 12 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005018\n",
      "7750it [07:00, 12.52it/s]Train epoch: 12 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005335\n",
      "7774it [07:02, 12.23it/s]Train epoch: 12 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004695\n",
      "7800it [07:04, 12.52it/s]Train epoch: 12 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004897\n",
      "7824it [07:06, 12.43it/s]Train epoch: 12 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005160\n",
      "7850it [07:08, 12.31it/s]Train epoch: 12 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004673\n",
      "7874it [07:10, 12.19it/s]Train epoch: 12 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004857\n",
      "7900it [07:13, 12.13it/s]Train epoch: 12 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005119\n",
      "7924it [07:14, 12.48it/s]Train epoch: 12 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005087\n",
      "7950it [07:17, 12.30it/s]Train epoch: 12 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005701\n",
      "7974it [07:18, 12.66it/s]Train epoch: 12 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004913\n",
      "8000it [07:21, 12.29it/s]Train epoch: 12 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004805\n",
      "8024it [07:23, 12.00it/s]Train epoch: 12 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005219\n",
      "8050it [07:25, 11.97it/s]Train epoch: 12 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004531\n",
      "8074it [07:27, 11.97it/s]Train epoch: 12 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005047\n",
      "8100it [07:29, 11.74it/s]Train epoch: 12 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005374\n",
      "8124it [07:31, 12.12it/s]Train epoch: 12 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005560\n",
      "8150it [07:33, 11.87it/s]Train epoch: 12 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004721\n",
      "8174it [07:35, 12.00it/s]Train epoch: 12 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005472\n",
      "8200it [07:37, 12.11it/s]Train epoch: 12 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004715\n",
      "8224it [07:39, 11.79it/s]Train epoch: 12 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006250\n",
      "8250it [07:42, 11.75it/s]Train epoch: 12 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004869\n",
      "8274it [07:44, 11.91it/s]Train epoch: 12 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005474\n",
      "8300it [07:46, 11.71it/s]Train epoch: 12 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004907\n",
      "8324it [07:48, 11.45it/s]Train epoch: 12 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005551\n",
      "8350it [07:50, 11.66it/s]Train epoch: 12 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004734\n",
      "8374it [07:52, 11.47it/s]Train epoch: 12 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005561\n",
      "8400it [07:54, 11.81it/s]Train epoch: 12 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005132\n",
      "8424it [07:56, 11.62it/s]Train epoch: 12 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005152\n",
      "8450it [07:59, 11.30it/s]Train epoch: 12 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005485\n",
      "8474it [08:01, 11.68it/s]Train epoch: 12 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005195\n",
      "8500it [08:03, 11.72it/s]Train epoch: 12 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006014\n",
      "8524it [08:05, 11.25it/s]Train epoch: 12 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005276\n",
      "8550it [08:07, 11.28it/s]Train epoch: 12 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005448\n",
      "8574it [08:10, 11.28it/s]Train epoch: 12 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005069\n",
      "8600it [08:12, 11.47it/s]Train epoch: 12 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005206\n",
      "8624it [08:14, 11.19it/s]Train epoch: 12 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005359\n",
      "8650it [08:16, 11.61it/s]Train epoch: 12 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005467\n",
      "8674it [08:18, 11.24it/s]Train epoch: 12 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700it [08:21, 11.24it/s]Train epoch: 12 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006133\n",
      "8724it [08:23, 10.99it/s]Train epoch: 12 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005927\n",
      "8750it [08:25, 11.15it/s]Train epoch: 12 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005533\n",
      "8774it [08:27, 10.92it/s]Train epoch: 12 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005030\n",
      "8800it [08:30, 11.30it/s]Train epoch: 12 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005286\n",
      "8824it [08:32, 11.39it/s]Train epoch: 12 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005385\n",
      "8850it [08:34, 11.24it/s]Train epoch: 12 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005607\n",
      "8874it [08:36, 11.14it/s]Train epoch: 12 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005359\n",
      "8900it [08:39, 10.90it/s]Train epoch: 12 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005430\n",
      "8924it [08:41, 11.04it/s]Train epoch: 12 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005553\n",
      "8950it [08:43, 10.85it/s]Train epoch: 12 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006242\n",
      "8974it [08:45, 11.11it/s]Train epoch: 12 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005727\n",
      "9000it [08:48, 10.93it/s]Train epoch: 12 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005462\n",
      "9024it [08:50, 10.89it/s]Train epoch: 12 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005561\n",
      "9050it [08:52, 10.71it/s]Train epoch: 12 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005113\n",
      "9074it [08:55, 10.77it/s]Train epoch: 12 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004874\n",
      "9100it [08:57, 10.80it/s]Train epoch: 12 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005711\n",
      "9124it [08:59, 10.83it/s]Train epoch: 12 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005267\n",
      "9150it [09:02, 10.72it/s]Train epoch: 12 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004866\n",
      "9174it [09:04, 10.59it/s]Train epoch: 12 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005250\n",
      "9200it [09:06, 10.51it/s]Train epoch: 12 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005082\n",
      "9224it [09:09, 10.45it/s]Train epoch: 12 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006142\n",
      "9250it [09:11, 10.35it/s]Train epoch: 12 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005380\n",
      "9274it [09:13, 10.39it/s]Train epoch: 12 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005755\n",
      "9300it [09:16, 10.33it/s]Train epoch: 12 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006405\n",
      "9324it [09:18, 10.39it/s]Train epoch: 12 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006192\n",
      "9350it [09:21, 10.29it/s]Train epoch: 12 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006131\n",
      "9374it [09:23, 10.20it/s]Train epoch: 12 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005465\n",
      "9400it [09:26, 10.36it/s]Train epoch: 12 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005664\n",
      "9424it [09:28, 10.02it/s]Train epoch: 12 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005492\n",
      "9450it [09:31, 10.18it/s]Train epoch: 12 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005463\n",
      "9475it [09:33, 10.12it/s]Train epoch: 12 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006092\n",
      "9499it [09:35, 10.11it/s]Train epoch: 12 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005717\n",
      "9524it [09:38,  9.99it/s]Train epoch: 12 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006158\n",
      "9550it [09:41,  9.92it/s]Train epoch: 12 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.005994\n",
      "9574it [09:43, 10.00it/s]Train epoch: 12 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006073\n",
      "9600it [09:45, 10.04it/s]Train epoch: 12 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005855\n",
      "9624it [09:48, 10.26it/s]Train epoch: 12 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005338\n",
      "9650it [09:51, 10.06it/s]Train epoch: 12 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005491\n",
      "9675it [09:53,  9.87it/s]Train epoch: 12 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005805\n",
      "9700it [09:56,  9.63it/s]Train epoch: 12 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005194\n",
      "9725it [09:58, 10.00it/s]Train epoch: 12 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005788\n",
      "9750it [10:01,  9.88it/s]Train epoch: 12 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005745\n",
      "9774it [10:03,  9.42it/s]Train epoch: 12 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006497\n",
      "9800it [10:06,  9.85it/s]Train epoch: 12 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006187\n",
      "9825it [10:08,  9.43it/s]Train epoch: 12 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006406\n",
      "9850it [10:11,  9.55it/s]Train epoch: 12 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005787\n",
      "9875it [10:13,  9.87it/s]Train epoch: 12 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006200\n",
      "9899it [10:16,  9.39it/s]Train epoch: 12 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006556\n",
      "9925it [10:19,  9.86it/s]Train epoch: 12 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006156\n",
      "9950it [10:21,  9.54it/s]Train epoch: 12 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006840\n",
      "9975it [10:24,  9.06it/s]Train epoch: 12 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006296\n",
      "10000it [10:26,  9.76it/s]Train epoch: 12 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005880\n",
      "10024it [10:29,  9.33it/s]Train epoch: 12 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005802\n",
      "10050it [10:32,  9.53it/s]Train epoch: 12 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006283\n",
      "10075it [10:35,  8.90it/s]Train epoch: 12 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006749\n",
      "10100it [10:37,  9.61it/s]Train epoch: 12 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006358\n",
      "10125it [10:40,  9.32it/s]Train epoch: 12 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005825\n",
      "10150it [10:43,  9.03it/s]Train epoch: 12 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006317\n",
      "10175it [10:45,  9.49it/s]Train epoch: 12 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005884\n",
      "10200it [10:48,  9.02it/s]Train epoch: 12 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006343\n",
      "10225it [10:51,  8.92it/s]Train epoch: 12 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006306\n",
      "10250it [10:54,  8.79it/s]Train epoch: 12 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006831\n",
      "10275it [10:56,  9.12it/s]Train epoch: 12 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006051\n",
      "10300it [10:59,  8.89it/s]Train epoch: 12 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006704\n",
      "10325it [11:02,  8.83it/s]Train epoch: 12 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006483\n",
      "10350it [11:05,  8.75it/s]Train epoch: 12 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006145\n",
      "10375it [11:08,  8.89it/s]Train epoch: 12 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006451\n",
      "10400it [11:10,  8.54it/s]Train epoch: 12 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006422\n",
      "10425it [11:13,  8.56it/s]Train epoch: 12 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006089\n",
      "10450it [11:16,  8.67it/s]Train epoch: 12 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006436\n",
      "10475it [11:19,  8.49it/s]Train epoch: 12 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005717\n",
      "10500it [11:22,  8.69it/s]Train epoch: 12 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006481\n",
      "10525it [11:25,  8.41it/s]Train epoch: 12 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006233\n",
      "10550it [11:28,  8.45it/s]Train epoch: 12 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006470\n",
      "10575it [11:31,  8.20it/s]Train epoch: 12 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005729\n",
      "10600it [11:34,  8.23it/s]Train epoch: 12 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.005995\n",
      "10625it [11:37,  8.24it/s]Train epoch: 12 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006698\n",
      "10650it [11:40,  8.03it/s]Train epoch: 12 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006089\n",
      "10675it [11:43,  8.37it/s]Train epoch: 12 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006600\n",
      "10700it [11:46,  8.12it/s]Train epoch: 12 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10725it [11:49,  8.12it/s]Train epoch: 12 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005755\n",
      "10750it [11:52,  8.09it/s]Train epoch: 12 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006849\n",
      "10775it [11:55,  7.79it/s]Train epoch: 12 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006699\n",
      "10800it [11:58,  7.91it/s]Train epoch: 12 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006877\n",
      "10825it [12:02,  8.01it/s]Train epoch: 12 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006706\n",
      "10850it [12:05,  7.99it/s]Train epoch: 12 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006712\n",
      "10875it [12:08,  7.93it/s]Train epoch: 12 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006832\n",
      "10900it [12:11,  7.93it/s]Train epoch: 12 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006678\n",
      "10925it [12:14,  8.04it/s]Train epoch: 12 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006012\n",
      "10950it [12:17,  7.98it/s]Train epoch: 12 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006589\n",
      "10975it [12:21,  8.43it/s]Train epoch: 12 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006367\n",
      "11000it [12:24,  7.82it/s]Train epoch: 12 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006316\n",
      "11025it [12:27,  7.99it/s]Train epoch: 12 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006562\n",
      "11050it [12:30,  7.92it/s]Train epoch: 12 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007289\n",
      "11075it [12:33,  8.00it/s]Train epoch: 12 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006853\n",
      "11100it [12:36,  7.83it/s]Train epoch: 12 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007500\n",
      "11125it [12:40,  7.84it/s]Train epoch: 12 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006954\n",
      "11150it [12:43,  7.97it/s]Train epoch: 12 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006661\n",
      "11175it [12:46,  7.84it/s]Train epoch: 12 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007802\n",
      "11200it [12:49,  7.82it/s]Train epoch: 12 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007043\n",
      "11225it [12:52,  8.07it/s]Train epoch: 12 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006974\n",
      "11250it [12:55,  7.87it/s]Train epoch: 12 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007567\n",
      "11275it [12:59,  7.85it/s]Train epoch: 12 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007276\n",
      "11300it [13:02,  8.02it/s]Train epoch: 12 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006700\n",
      "11325it [13:05,  7.79it/s]Train epoch: 12 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007848\n",
      "11350it [13:08,  7.71it/s]Train epoch: 12 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007721\n",
      "11375it [13:11,  8.26it/s]Train epoch: 12 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007934\n",
      "11400it [13:14,  7.99it/s]Train epoch: 12 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006974\n",
      "11425it [13:17,  7.88it/s]Train epoch: 12 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007751\n",
      "11450it [13:21,  8.03it/s]Train epoch: 12 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006774\n",
      "11475it [13:24,  7.88it/s]Train epoch: 12 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008234\n",
      "11500it [13:27,  7.89it/s]Train epoch: 12 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007777\n",
      "11525it [13:30,  7.68it/s]Train epoch: 12 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007191\n",
      "11550it [13:33,  7.89it/s]Train epoch: 12 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007238\n",
      "11575it [13:36,  7.98it/s]Train epoch: 12 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008317\n",
      "11600it [13:40,  7.80it/s]Train epoch: 12 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007672\n",
      "11625it [13:43,  8.04it/s]Train epoch: 12 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007160\n",
      "11650it [13:46,  7.94it/s]Train epoch: 12 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007769\n",
      "11675it [13:49,  7.93it/s]Train epoch: 12 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008132\n",
      "11700it [13:52,  7.87it/s]Train epoch: 12 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008690\n",
      "11725it [13:55,  7.91it/s]Train epoch: 12 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008658\n",
      "11750it [13:59,  7.77it/s]Train epoch: 12 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008391\n",
      "11775it [14:02,  7.85it/s]Train epoch: 12 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008526\n",
      "11800it [14:05,  7.68it/s]Train epoch: 12 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008188\n",
      "11825it [14:08,  7.82it/s]Train epoch: 12 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008559\n",
      "11850it [14:11,  7.89it/s]Train epoch: 12 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008879\n",
      "11875it [14:14,  7.95it/s]Train epoch: 12 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009786\n",
      "11900it [14:18,  7.87it/s]Train epoch: 12 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011772\n",
      "11925it [14:21,  7.88it/s]Train epoch: 12 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009892\n",
      "11930it [14:21, 13.84it/s]\n",
      "epoch loss: 0.004848409009024373\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 128.71it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0321, 0.0469, 0.0503, 0.0485, 0.8794\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3282, 0.5450, 0.4520, 0.4942, 0.9818\n",
      "rec_at_8: 0.3545\n",
      "prec_at_8: 0.6536\n",
      "rec_at_15: 0.4913\n",
      "prec_at_15: 0.5064\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 130.79it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0319, 0.0504, 0.0516, 0.0510, 0.8707\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3243, 0.5444, 0.4451, 0.4898, 0.9815\n",
      "rec_at_8: 0.3402\n",
      "prec_at_8: 0.6532\n",
      "rec_at_15: 0.4739\n",
      "prec_at_15: 0.5070\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 12\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0321, 0.0469, 0.0503, 0.0485, 0.8794\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3282, 0.5450, 0.4520, 0.4942, 0.9818\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0068\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 12\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0319, 0.0504, 0.0516, 0.0510, 0.8707\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3243, 0.5444, 0.4451, 0.4898, 0.9815\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0070\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 13\n",
      "0it [00:00, ?it/s]Train epoch: 13 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006586\n",
      "20it [00:00, 43.33it/s]Train epoch: 13 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003966\n",
      "46it [00:01, 42.29it/s]Train epoch: 13 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003679\n",
      "72it [00:01, 43.99it/s]Train epoch: 13 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003076\n",
      "98it [00:02, 41.45it/s]Train epoch: 13 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003278\n",
      "122it [00:02, 38.65it/s]Train epoch: 13 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003080\n",
      "150it [00:03, 38.21it/s]Train epoch: 13 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003046\n",
      "175it [00:04, 37.24it/s]Train epoch: 13 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003121\n",
      "200it [00:05, 35.57it/s]Train epoch: 13 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003034\n",
      "224it [00:05, 33.79it/s]Train epoch: 13 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003721\n",
      "248it [00:06, 34.93it/s]Train epoch: 13 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003046\n",
      "272it [00:07, 33.52it/s]Train epoch: 13 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002581\n",
      "300it [00:08, 30.61it/s]Train epoch: 13 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003387\n",
      "324it [00:08, 31.46it/s]Train epoch: 13 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002815\n",
      "348it [00:09, 32.63it/s]Train epoch: 13 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003325\n",
      "372it [00:10, 33.21it/s]Train epoch: 13 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400it [00:11, 30.68it/s]Train epoch: 13 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003159\n",
      "424it [00:11, 31.05it/s]Train epoch: 13 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003212\n",
      "448it [00:12, 31.19it/s]Train epoch: 13 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003109\n",
      "472it [00:13, 30.61it/s]Train epoch: 13 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003538\n",
      "500it [00:14, 29.07it/s]Train epoch: 13 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003045\n",
      "523it [00:15, 31.70it/s]Train epoch: 13 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003242\n",
      "547it [00:15, 30.49it/s]Train epoch: 13 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003205\n",
      "575it [00:16, 30.35it/s]Train epoch: 13 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003161\n",
      "600it [00:17, 29.27it/s]Train epoch: 13 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003488\n",
      "624it [00:18, 29.71it/s]Train epoch: 13 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003319\n",
      "650it [00:19, 30.20it/s]Train epoch: 13 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003042\n",
      "674it [00:20, 30.26it/s]Train epoch: 13 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002514\n",
      "697it [00:20, 29.47it/s]Train epoch: 13 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003205\n",
      "724it [00:21, 28.33it/s]Train epoch: 13 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003281\n",
      "749it [00:22, 28.63it/s]Train epoch: 13 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003070\n",
      "774it [00:23, 29.75it/s]Train epoch: 13 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003399\n",
      "800it [00:24, 29.96it/s]Train epoch: 13 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003272\n",
      "823it [00:25, 28.11it/s]Train epoch: 13 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003181\n",
      "850it [00:26, 28.56it/s]Train epoch: 13 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003605\n",
      "874it [00:27, 26.85it/s]Train epoch: 13 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003018\n",
      "899it [00:28, 26.54it/s]Train epoch: 13 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003287\n",
      "923it [00:28, 28.60it/s]Train epoch: 13 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003091\n",
      "950it [00:29, 28.42it/s]Train epoch: 13 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003052\n",
      "972it [00:30, 28.06it/s]Train epoch: 13 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002398\n",
      "998it [00:31, 26.96it/s]Train epoch: 13 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003207\n",
      "1023it [00:32, 28.01it/s]Train epoch: 13 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004465\n",
      "1049it [00:33, 27.52it/s]Train epoch: 13 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003035\n",
      "1073it [00:34, 26.31it/s]Train epoch: 13 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003461\n",
      "1100it [00:35, 26.65it/s]Train epoch: 13 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003533\n",
      "1122it [00:36, 27.15it/s]Train epoch: 13 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003544\n",
      "1149it [00:37, 26.94it/s]Train epoch: 13 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003547\n",
      "1173it [00:37, 27.70it/s]Train epoch: 13 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003440\n",
      "1200it [00:38, 27.25it/s]Train epoch: 13 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003579\n",
      "1224it [00:39, 26.84it/s]Train epoch: 13 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003711\n",
      "1248it [00:40, 28.71it/s]Train epoch: 13 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003427\n",
      "1273it [00:41, 26.39it/s]Train epoch: 13 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.002956\n",
      "1300it [00:42, 25.72it/s]Train epoch: 13 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003018\n",
      "1324it [00:43, 26.45it/s]Train epoch: 13 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003069\n",
      "1348it [00:44, 26.84it/s]Train epoch: 13 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004074\n",
      "1375it [00:45, 26.25it/s]Train epoch: 13 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003379\n",
      "1399it [00:46, 26.16it/s]Train epoch: 13 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003361\n",
      "1423it [00:47, 25.05it/s]Train epoch: 13 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.002932\n",
      "1448it [00:48, 26.46it/s]Train epoch: 13 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003254\n",
      "1475it [00:49, 26.58it/s]Train epoch: 13 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003448\n",
      "1499it [00:50, 25.06it/s]Train epoch: 13 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004499\n",
      "1523it [00:51, 25.37it/s]Train epoch: 13 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004273\n",
      "1550it [00:52, 26.19it/s]Train epoch: 13 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003251\n",
      "1574it [00:53, 26.30it/s]Train epoch: 13 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003501\n",
      "1598it [00:54, 26.49it/s]Train epoch: 13 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003102\n",
      "1625it [00:55, 26.14it/s]Train epoch: 13 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003787\n",
      "1649it [00:56, 24.46it/s]Train epoch: 13 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003854\n",
      "1673it [00:57, 24.65it/s]Train epoch: 13 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003740\n",
      "1700it [00:58, 25.39it/s]Train epoch: 13 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003131\n",
      "1724it [00:59, 25.22it/s]Train epoch: 13 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002783\n",
      "1748it [00:59, 26.10it/s]Train epoch: 13 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004158\n",
      "1775it [01:01, 24.88it/s]Train epoch: 13 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003516\n",
      "1799it [01:01, 25.66it/s]Train epoch: 13 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003400\n",
      "1823it [01:02, 24.89it/s]Train epoch: 13 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002799\n",
      "1850it [01:03, 25.36it/s]Train epoch: 13 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003588\n",
      "1874it [01:04, 25.49it/s]Train epoch: 13 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003885\n",
      "1898it [01:05, 25.02it/s]Train epoch: 13 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002797\n",
      "1925it [01:06, 24.96it/s]Train epoch: 13 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003026\n",
      "1949it [01:07, 25.81it/s]Train epoch: 13 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003063\n",
      "1973it [01:08, 24.29it/s]Train epoch: 13 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003642\n",
      "2000it [01:09, 25.87it/s]Train epoch: 13 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002875\n",
      "2024it [01:10, 23.37it/s]Train epoch: 13 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003568\n",
      "2048it [01:11, 25.68it/s]Train epoch: 13 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003322\n",
      "2075it [01:13, 24.64it/s]Train epoch: 13 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003460\n",
      "2099it [01:14, 24.41it/s]Train epoch: 13 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003603\n",
      "2123it [01:15, 23.67it/s]Train epoch: 13 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003836\n",
      "2150it [01:16, 24.61it/s]Train epoch: 13 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003291\n",
      "2174it [01:17, 24.00it/s]Train epoch: 13 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003731\n",
      "2198it [01:18, 22.47it/s]Train epoch: 13 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003572\n",
      "2225it [01:19, 24.30it/s]Train epoch: 13 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003374\n",
      "2249it [01:20, 24.75it/s]Train epoch: 13 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003181\n",
      "2273it [01:21, 22.64it/s]Train epoch: 13 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003529\n",
      "2300it [01:22, 24.07it/s]Train epoch: 13 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002703\n",
      "2324it [01:23, 23.42it/s]Train epoch: 13 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003383\n",
      "2348it [01:24, 23.96it/s]Train epoch: 13 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003165\n",
      "2375it [01:25, 24.30it/s]Train epoch: 13 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004517\n",
      "2399it [01:26, 23.02it/s]Train epoch: 13 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004119\n",
      "2423it [01:27, 23.66it/s]Train epoch: 13 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002920\n",
      "2450it [01:28, 22.89it/s]Train epoch: 13 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2474it [01:29, 22.21it/s]Train epoch: 13 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003831\n",
      "2498it [01:30, 22.59it/s]Train epoch: 13 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003293\n",
      "2525it [01:32, 22.51it/s]Train epoch: 13 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003170\n",
      "2549it [01:33, 24.52it/s]Train epoch: 13 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004517\n",
      "2573it [01:34, 24.36it/s]Train epoch: 13 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003151\n",
      "2600it [01:35, 22.81it/s]Train epoch: 13 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003501\n",
      "2624it [01:36, 23.71it/s]Train epoch: 13 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003481\n",
      "2648it [01:37, 23.90it/s]Train epoch: 13 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004059\n",
      "2675it [01:38, 22.72it/s]Train epoch: 13 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003604\n",
      "2699it [01:39, 22.90it/s]Train epoch: 13 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003159\n",
      "2723it [01:40, 22.60it/s]Train epoch: 13 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003386\n",
      "2750it [01:41, 22.41it/s]Train epoch: 13 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004060\n",
      "2774it [01:42, 22.25it/s]Train epoch: 13 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003503\n",
      "2798it [01:44, 23.11it/s]Train epoch: 13 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003356\n",
      "2825it [01:45, 23.13it/s]Train epoch: 13 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003764\n",
      "2849it [01:46, 21.99it/s]Train epoch: 13 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003520\n",
      "2873it [01:47, 22.29it/s]Train epoch: 13 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003880\n",
      "2900it [01:48, 22.79it/s]Train epoch: 13 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003716\n",
      "2924it [01:49, 20.91it/s]Train epoch: 13 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003891\n",
      "2948it [01:50, 21.14it/s]Train epoch: 13 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004006\n",
      "2975it [01:52, 21.90it/s]Train epoch: 13 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003778\n",
      "2999it [01:53, 22.40it/s]Train epoch: 13 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004320\n",
      "3023it [01:54, 21.17it/s]Train epoch: 13 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003873\n",
      "3050it [01:55, 22.52it/s]Train epoch: 13 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003380\n",
      "3074it [01:56, 21.64it/s]Train epoch: 13 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003865\n",
      "3098it [01:57, 21.17it/s]Train epoch: 13 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003884\n",
      "3125it [01:58, 21.09it/s]Train epoch: 13 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003629\n",
      "3149it [02:00, 22.26it/s]Train epoch: 13 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003478\n",
      "3173it [02:01, 20.33it/s]Train epoch: 13 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003475\n",
      "3200it [02:02, 21.66it/s]Train epoch: 13 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004101\n",
      "3224it [02:03, 22.24it/s]Train epoch: 13 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.003958\n",
      "3248it [02:04, 21.19it/s]Train epoch: 13 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.003964\n",
      "3275it [02:05, 20.88it/s]Train epoch: 13 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003478\n",
      "3299it [02:07, 20.27it/s]Train epoch: 13 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004434\n",
      "3323it [02:08, 20.94it/s]Train epoch: 13 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003742\n",
      "3350it [02:09, 20.55it/s]Train epoch: 13 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003753\n",
      "3374it [02:10, 20.83it/s]Train epoch: 13 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.003972\n",
      "3398it [02:11, 19.90it/s]Train epoch: 13 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004035\n",
      "3424it [02:13, 20.25it/s]Train epoch: 13 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003514\n",
      "3449it [02:14, 19.56it/s]Train epoch: 13 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004096\n",
      "3473it [02:15, 20.78it/s]Train epoch: 13 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003633\n",
      "3500it [02:16, 21.24it/s]Train epoch: 13 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003765\n",
      "3524it [02:18, 20.41it/s]Train epoch: 13 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003896\n",
      "3548it [02:19, 19.94it/s]Train epoch: 13 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004198\n",
      "3574it [02:20, 20.09it/s]Train epoch: 13 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003292\n",
      "3600it [02:21, 19.17it/s]Train epoch: 13 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004304\n",
      "3624it [02:23, 21.21it/s]Train epoch: 13 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.003965\n",
      "3650it [02:24, 18.54it/s]Train epoch: 13 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004027\n",
      "3674it [02:25, 17.82it/s]Train epoch: 13 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004056\n",
      "3700it [02:27, 16.87it/s]Train epoch: 13 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004079\n",
      "3725it [02:28, 16.64it/s]Train epoch: 13 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004149\n",
      "3749it [02:30, 16.71it/s]Train epoch: 13 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004141\n",
      "3774it [02:31, 17.25it/s]Train epoch: 13 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004006\n",
      "3800it [02:32, 17.01it/s]Train epoch: 13 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004463\n",
      "3825it [02:34, 17.46it/s]Train epoch: 13 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003694\n",
      "3849it [02:35, 17.07it/s]Train epoch: 13 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003503\n",
      "3874it [02:37, 17.63it/s]Train epoch: 13 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003420\n",
      "3900it [02:38, 16.04it/s]Train epoch: 13 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004411\n",
      "3924it [02:40, 16.60it/s]Train epoch: 13 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004039\n",
      "3950it [02:41, 17.33it/s]Train epoch: 13 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004404\n",
      "3974it [02:43, 16.30it/s]Train epoch: 13 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.004920\n",
      "4000it [02:44, 17.47it/s]Train epoch: 13 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003723\n",
      "4024it [02:46, 17.50it/s]Train epoch: 13 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004621\n",
      "4050it [02:47, 16.65it/s]Train epoch: 13 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004133\n",
      "4074it [02:49, 17.36it/s]Train epoch: 13 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004201\n",
      "4100it [02:50, 17.12it/s]Train epoch: 13 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004607\n",
      "4124it [02:51, 16.98it/s]Train epoch: 13 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004472\n",
      "4150it [02:53, 16.82it/s]Train epoch: 13 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003806\n",
      "4174it [02:54, 16.89it/s]Train epoch: 13 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004120\n",
      "4200it [02:56, 17.25it/s]Train epoch: 13 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004458\n",
      "4225it [02:57, 17.41it/s]Train epoch: 13 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003718\n",
      "4249it [02:59, 16.47it/s]Train epoch: 13 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004281\n",
      "4275it [03:00, 16.74it/s]Train epoch: 13 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004012\n",
      "4299it [03:02, 16.37it/s]Train epoch: 13 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004704\n",
      "4325it [03:03, 16.97it/s]Train epoch: 13 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004100\n",
      "4349it [03:05, 16.96it/s]Train epoch: 13 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004442\n",
      "4375it [03:06, 16.40it/s]Train epoch: 13 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.003980\n",
      "4399it [03:08, 17.59it/s]Train epoch: 13 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003454\n",
      "4425it [03:09, 17.04it/s]Train epoch: 13 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004228\n",
      "4449it [03:11, 16.61it/s]Train epoch: 13 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003396\n",
      "4475it [03:12, 16.37it/s]Train epoch: 13 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004440\n",
      "4499it [03:14, 16.44it/s]Train epoch: 13 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4524it [03:15, 16.96it/s]Train epoch: 13 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004337\n",
      "4550it [03:17, 15.79it/s]Train epoch: 13 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004091\n",
      "4574it [03:18, 16.18it/s]Train epoch: 13 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004632\n",
      "4600it [03:20, 16.49it/s]Train epoch: 13 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.003927\n",
      "4624it [03:21, 15.60it/s]Train epoch: 13 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.003956\n",
      "4650it [03:23, 15.38it/s]Train epoch: 13 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004587\n",
      "4674it [03:25, 15.66it/s]Train epoch: 13 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004363\n",
      "4700it [03:26, 15.90it/s]Train epoch: 13 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003863\n",
      "4724it [03:28, 14.64it/s]Train epoch: 13 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004090\n",
      "4750it [03:30, 15.00it/s]Train epoch: 13 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004742\n",
      "4774it [03:31, 14.62it/s]Train epoch: 13 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004167\n",
      "4800it [03:33, 14.51it/s]Train epoch: 13 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004314\n",
      "4824it [03:35, 15.66it/s]Train epoch: 13 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003798\n",
      "4850it [03:36, 15.18it/s]Train epoch: 13 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004522\n",
      "4874it [03:38, 14.94it/s]Train epoch: 13 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003894\n",
      "4900it [03:40, 14.97it/s]Train epoch: 13 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004239\n",
      "4924it [03:41, 14.74it/s]Train epoch: 13 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003906\n",
      "4950it [03:43, 15.32it/s]Train epoch: 13 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004207\n",
      "4974it [03:44, 15.68it/s]Train epoch: 13 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004252\n",
      "5000it [03:46, 14.69it/s]Train epoch: 13 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004226\n",
      "5024it [03:48, 15.67it/s]Train epoch: 13 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.003981\n",
      "5050it [03:49, 15.42it/s]Train epoch: 13 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.003939\n",
      "5074it [03:51, 15.61it/s]Train epoch: 13 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004201\n",
      "5100it [03:53, 15.70it/s]Train epoch: 13 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004279\n",
      "5124it [03:54, 15.30it/s]Train epoch: 13 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004439\n",
      "5150it [03:56, 14.88it/s]Train epoch: 13 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004513\n",
      "5174it [03:58, 14.60it/s]Train epoch: 13 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004444\n",
      "5200it [03:59, 15.22it/s]Train epoch: 13 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.003977\n",
      "5224it [04:01, 15.55it/s]Train epoch: 13 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004239\n",
      "5250it [04:03, 14.95it/s]Train epoch: 13 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004206\n",
      "5274it [04:04, 15.54it/s]Train epoch: 13 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004047\n",
      "5300it [04:06, 14.82it/s]Train epoch: 13 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004008\n",
      "5324it [04:07, 15.54it/s]Train epoch: 13 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004467\n",
      "5350it [04:09, 15.17it/s]Train epoch: 13 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004507\n",
      "5374it [04:11, 15.14it/s]Train epoch: 13 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004109\n",
      "5400it [04:12, 15.53it/s]Train epoch: 13 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004101\n",
      "5424it [04:14, 15.07it/s]Train epoch: 13 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004528\n",
      "5450it [04:16, 15.28it/s]Train epoch: 13 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004379\n",
      "5474it [04:17, 14.81it/s]Train epoch: 13 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005032\n",
      "5500it [04:19, 15.76it/s]Train epoch: 13 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004699\n",
      "5524it [04:21, 14.81it/s]Train epoch: 13 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003767\n",
      "5550it [04:22, 15.17it/s]Train epoch: 13 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004422\n",
      "5574it [04:24, 14.70it/s]Train epoch: 13 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004472\n",
      "5600it [04:26, 14.81it/s]Train epoch: 13 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004754\n",
      "5624it [04:27, 15.06it/s]Train epoch: 13 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004480\n",
      "5650it [04:29, 14.91it/s]Train epoch: 13 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.003980\n",
      "5674it [04:31, 14.96it/s]Train epoch: 13 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.004901\n",
      "5700it [04:32, 15.05it/s]Train epoch: 13 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004286\n",
      "5724it [04:34, 14.29it/s]Train epoch: 13 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004416\n",
      "5750it [04:36, 15.21it/s]Train epoch: 13 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005510\n",
      "5774it [04:37, 14.94it/s]Train epoch: 13 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004643\n",
      "5800it [04:39, 14.91it/s]Train epoch: 13 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004606\n",
      "5824it [04:41, 14.16it/s]Train epoch: 13 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004178\n",
      "5850it [04:43, 13.90it/s]Train epoch: 13 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005238\n",
      "5874it [04:44, 14.72it/s]Train epoch: 13 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005044\n",
      "5900it [04:46, 14.70it/s]Train epoch: 13 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.004994\n",
      "5924it [04:48, 14.57it/s]Train epoch: 13 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004118\n",
      "5950it [04:49, 14.20it/s]Train epoch: 13 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004027\n",
      "5974it [04:51, 14.87it/s]Train epoch: 13 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005582\n",
      "6000it [04:53, 13.96it/s]Train epoch: 13 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004721\n",
      "6024it [04:55, 14.12it/s]Train epoch: 13 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.004978\n",
      "6050it [04:56, 14.84it/s]Train epoch: 13 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004460\n",
      "6074it [04:58, 13.74it/s]Train epoch: 13 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004140\n",
      "6100it [05:00, 14.16it/s]Train epoch: 13 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004032\n",
      "6124it [05:02, 14.06it/s]Train epoch: 13 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004406\n",
      "6150it [05:04, 14.64it/s]Train epoch: 13 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004458\n",
      "6174it [05:05, 13.96it/s]Train epoch: 13 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005108\n",
      "6200it [05:07, 13.88it/s]Train epoch: 13 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004501\n",
      "6224it [05:09, 13.35it/s]Train epoch: 13 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003956\n",
      "6250it [05:11, 13.30it/s]Train epoch: 13 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004244\n",
      "6274it [05:13, 13.88it/s]Train epoch: 13 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003849\n",
      "6300it [05:14, 14.34it/s]Train epoch: 13 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004462\n",
      "6324it [05:16, 13.62it/s]Train epoch: 13 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.004951\n",
      "6350it [05:18, 12.88it/s]Train epoch: 13 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005237\n",
      "6374it [05:20, 13.76it/s]Train epoch: 13 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004091\n",
      "6400it [05:22, 14.03it/s]Train epoch: 13 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004291\n",
      "6424it [05:24, 13.55it/s]Train epoch: 13 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.004957\n",
      "6450it [05:25, 13.96it/s]Train epoch: 13 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004877\n",
      "6474it [05:27, 13.66it/s]Train epoch: 13 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004310\n",
      "6500it [05:29, 13.16it/s]Train epoch: 13 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004917\n",
      "6524it [05:31, 13.12it/s]Train epoch: 13 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6550it [05:33, 13.35it/s]Train epoch: 13 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004405\n",
      "6574it [05:35, 13.03it/s]Train epoch: 13 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004551\n",
      "6600it [05:37, 13.38it/s]Train epoch: 13 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005513\n",
      "6624it [05:39, 13.15it/s]Train epoch: 13 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004503\n",
      "6650it [05:41, 12.90it/s]Train epoch: 13 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005105\n",
      "6674it [05:42, 12.88it/s]Train epoch: 13 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004661\n",
      "6700it [05:44, 13.50it/s]Train epoch: 13 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004765\n",
      "6724it [05:46, 13.41it/s]Train epoch: 13 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004768\n",
      "6750it [05:48, 13.24it/s]Train epoch: 13 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004299\n",
      "6774it [05:50, 13.31it/s]Train epoch: 13 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.004972\n",
      "6800it [05:52, 12.41it/s]Train epoch: 13 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.004972\n",
      "6824it [05:54, 13.02it/s]Train epoch: 13 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005084\n",
      "6850it [05:56, 12.19it/s]Train epoch: 13 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.004941\n",
      "6874it [05:58, 12.80it/s]Train epoch: 13 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004001\n",
      "6900it [06:00, 12.93it/s]Train epoch: 13 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004663\n",
      "6924it [06:02, 12.01it/s]Train epoch: 13 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004712\n",
      "6950it [06:04, 12.64it/s]Train epoch: 13 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005185\n",
      "6974it [06:06, 12.73it/s]Train epoch: 13 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004858\n",
      "7000it [06:08, 12.32it/s]Train epoch: 13 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004627\n",
      "7024it [06:10, 12.64it/s]Train epoch: 13 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005283\n",
      "7050it [06:12, 12.54it/s]Train epoch: 13 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004326\n",
      "7074it [06:14, 12.72it/s]Train epoch: 13 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004628\n",
      "7100it [06:16, 12.56it/s]Train epoch: 13 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005040\n",
      "7124it [06:18, 12.68it/s]Train epoch: 13 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004369\n",
      "7150it [06:20, 12.49it/s]Train epoch: 13 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005276\n",
      "7174it [06:22, 12.35it/s]Train epoch: 13 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004856\n",
      "7200it [06:24, 11.99it/s]Train epoch: 13 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005178\n",
      "7224it [06:26, 12.59it/s]Train epoch: 13 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004723\n",
      "7250it [06:28, 11.89it/s]Train epoch: 13 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004803\n",
      "7274it [06:30, 12.68it/s]Train epoch: 13 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005192\n",
      "7300it [06:32, 12.68it/s]Train epoch: 13 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005630\n",
      "7324it [06:34, 12.88it/s]Train epoch: 13 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004493\n",
      "7350it [06:36, 11.54it/s]Train epoch: 13 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005465\n",
      "7374it [06:38, 11.78it/s]Train epoch: 13 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005093\n",
      "7400it [06:40, 12.45it/s]Train epoch: 13 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004599\n",
      "7424it [06:42, 12.72it/s]Train epoch: 13 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005061\n",
      "7450it [06:44, 12.11it/s]Train epoch: 13 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005596\n",
      "7474it [06:46, 12.07it/s]Train epoch: 13 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004818\n",
      "7500it [06:48, 12.42it/s]Train epoch: 13 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005075\n",
      "7524it [06:50, 12.17it/s]Train epoch: 13 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004841\n",
      "7550it [06:52, 12.34it/s]Train epoch: 13 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004794\n",
      "7574it [06:54, 12.46it/s]Train epoch: 13 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005216\n",
      "7600it [06:56, 12.37it/s]Train epoch: 13 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006171\n",
      "7624it [06:58, 12.41it/s]Train epoch: 13 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005742\n",
      "7650it [07:00, 11.90it/s]Train epoch: 13 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004848\n",
      "7674it [07:02, 11.67it/s]Train epoch: 13 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.004923\n",
      "7700it [07:05, 11.90it/s]Train epoch: 13 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.004964\n",
      "7724it [07:07, 12.18it/s]Train epoch: 13 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005012\n",
      "7750it [07:09, 12.01it/s]Train epoch: 13 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005279\n",
      "7774it [07:11, 12.18it/s]Train epoch: 13 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004666\n",
      "7800it [07:13, 11.77it/s]Train epoch: 13 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004835\n",
      "7824it [07:15, 11.91it/s]Train epoch: 13 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005150\n",
      "7850it [07:17, 11.97it/s]Train epoch: 13 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004633\n",
      "7874it [07:19, 11.86it/s]Train epoch: 13 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004869\n",
      "7900it [07:21, 11.46it/s]Train epoch: 13 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005067\n",
      "7924it [07:23, 11.90it/s]Train epoch: 13 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005060\n",
      "7950it [07:25, 11.62it/s]Train epoch: 13 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005712\n",
      "7974it [07:27, 11.36it/s]Train epoch: 13 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004885\n",
      "8000it [07:30, 11.47it/s]Train epoch: 13 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004720\n",
      "8024it [07:32, 11.82it/s]Train epoch: 13 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005138\n",
      "8050it [07:34, 11.97it/s]Train epoch: 13 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004541\n",
      "8074it [07:36, 11.65it/s]Train epoch: 13 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005009\n",
      "8100it [07:38, 11.86it/s]Train epoch: 13 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005359\n",
      "8124it [07:40, 11.95it/s]Train epoch: 13 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005517\n",
      "8150it [07:43, 11.59it/s]Train epoch: 13 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004748\n",
      "8174it [07:45, 11.82it/s]Train epoch: 13 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005452\n",
      "8200it [07:47, 12.23it/s]Train epoch: 13 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004723\n",
      "8224it [07:49, 11.38it/s]Train epoch: 13 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006203\n",
      "8250it [07:51, 11.37it/s]Train epoch: 13 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004863\n",
      "8274it [07:53, 11.24it/s]Train epoch: 13 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005417\n",
      "8300it [07:56, 11.45it/s]Train epoch: 13 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004878\n",
      "8324it [07:58, 11.64it/s]Train epoch: 13 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005542\n",
      "8350it [08:00, 10.46it/s]Train epoch: 13 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004712\n",
      "8374it [08:02, 10.64it/s]Train epoch: 13 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005448\n",
      "8400it [08:05, 11.27it/s]Train epoch: 13 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005114\n",
      "8424it [08:07, 11.11it/s]Train epoch: 13 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005095\n",
      "8450it [08:09, 11.04it/s]Train epoch: 13 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005419\n",
      "8474it [08:11, 11.31it/s]Train epoch: 13 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005167\n",
      "8500it [08:14, 11.08it/s]Train epoch: 13 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006029\n",
      "8524it [08:16, 11.33it/s]Train epoch: 13 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005214\n",
      "8550it [08:18, 10.26it/s]Train epoch: 13 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8574it [08:20, 11.23it/s]Train epoch: 13 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005098\n",
      "8600it [08:23, 10.96it/s]Train epoch: 13 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005113\n",
      "8624it [08:25, 10.91it/s]Train epoch: 13 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005295\n",
      "8650it [08:28, 10.54it/s]Train epoch: 13 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005459\n",
      "8674it [08:30, 10.93it/s]Train epoch: 13 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006028\n",
      "8700it [08:32, 10.21it/s]Train epoch: 13 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006126\n",
      "8724it [08:34, 10.76it/s]Train epoch: 13 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005871\n",
      "8750it [08:37, 11.13it/s]Train epoch: 13 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005463\n",
      "8774it [08:39, 10.78it/s]Train epoch: 13 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005071\n",
      "8800it [08:41, 10.92it/s]Train epoch: 13 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005248\n",
      "8824it [08:44, 10.95it/s]Train epoch: 13 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005407\n",
      "8850it [08:46,  9.76it/s]Train epoch: 13 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005567\n",
      "8875it [08:49, 10.03it/s]Train epoch: 13 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005277\n",
      "8899it [08:51, 10.30it/s]Train epoch: 13 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005429\n",
      "8925it [08:54, 10.74it/s]Train epoch: 13 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005510\n",
      "8949it [08:56, 10.79it/s]Train epoch: 13 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006189\n",
      "8975it [08:58, 10.98it/s]Train epoch: 13 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005751\n",
      "8999it [09:01, 10.61it/s]Train epoch: 13 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005402\n",
      "9025it [09:03, 10.22it/s]Train epoch: 13 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005499\n",
      "9049it [09:05, 10.26it/s]Train epoch: 13 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005046\n",
      "9075it [09:08, 10.44it/s]Train epoch: 13 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004807\n",
      "9099it [09:10, 10.69it/s]Train epoch: 13 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005702\n",
      "9125it [09:13, 10.64it/s]Train epoch: 13 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005280\n",
      "9149it [09:15, 10.46it/s]Train epoch: 13 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004826\n",
      "9175it [09:17, 10.48it/s]Train epoch: 13 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005238\n",
      "9199it [09:20, 10.45it/s]Train epoch: 13 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005062\n",
      "9225it [09:22, 10.47it/s]Train epoch: 13 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006122\n",
      "9249it [09:25, 10.18it/s]Train epoch: 13 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005332\n",
      "9275it [09:27,  9.36it/s]Train epoch: 13 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005643\n",
      "9299it [09:29, 10.23it/s]Train epoch: 13 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006332\n",
      "9325it [09:32, 10.37it/s]Train epoch: 13 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006155\n",
      "9349it [09:34, 10.13it/s]Train epoch: 13 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006021\n",
      "9375it [09:37, 10.12it/s]Train epoch: 13 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005425\n",
      "9399it [09:39, 10.22it/s]Train epoch: 13 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005661\n",
      "9425it [09:42, 10.43it/s]Train epoch: 13 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005456\n",
      "9449it [09:44,  9.16it/s]Train epoch: 13 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005434\n",
      "9475it [09:47,  9.74it/s]Train epoch: 13 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006039\n",
      "9500it [09:49,  9.93it/s]Train epoch: 13 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005709\n",
      "9525it [09:52,  9.89it/s]Train epoch: 13 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006093\n",
      "9550it [09:55,  9.91it/s]Train epoch: 13 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006010\n",
      "9574it [09:57, 10.05it/s]Train epoch: 13 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006081\n",
      "9599it [09:59,  9.82it/s]Train epoch: 13 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005858\n",
      "9625it [10:02, 10.04it/s]Train epoch: 13 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005282\n",
      "9650it [10:05,  9.74it/s]Train epoch: 13 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005395\n",
      "9675it [10:07,  9.69it/s]Train epoch: 13 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005760\n",
      "9700it [10:10,  9.82it/s]Train epoch: 13 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005129\n",
      "9725it [10:12,  9.64it/s]Train epoch: 13 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005759\n",
      "9750it [10:15,  9.60it/s]Train epoch: 13 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005688\n",
      "9774it [10:17,  9.43it/s]Train epoch: 13 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006421\n",
      "9800it [10:20,  9.56it/s]Train epoch: 13 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006145\n",
      "9825it [10:23,  9.66it/s]Train epoch: 13 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006359\n",
      "9850it [10:25,  9.58it/s]Train epoch: 13 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005785\n",
      "9875it [10:28,  9.34it/s]Train epoch: 13 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006131\n",
      "9900it [10:31,  9.32it/s]Train epoch: 13 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006567\n",
      "9925it [10:33,  9.12it/s]Train epoch: 13 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006144\n",
      "9950it [10:36,  9.14it/s]Train epoch: 13 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006754\n",
      "9975it [10:39,  9.34it/s]Train epoch: 13 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006262\n",
      "10000it [10:41,  9.40it/s]Train epoch: 13 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005802\n",
      "10025it [10:44,  9.47it/s]Train epoch: 13 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005778\n",
      "10050it [10:47,  8.97it/s]Train epoch: 13 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006262\n",
      "10075it [10:49,  9.26it/s]Train epoch: 13 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006762\n",
      "10100it [10:52,  9.03it/s]Train epoch: 13 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006371\n",
      "10125it [10:55,  9.04it/s]Train epoch: 13 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005779\n",
      "10150it [10:58,  9.07it/s]Train epoch: 13 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006276\n",
      "10175it [11:01,  8.94it/s]Train epoch: 13 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005853\n",
      "10200it [11:03,  8.88it/s]Train epoch: 13 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006291\n",
      "10225it [11:06,  9.07it/s]Train epoch: 13 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006301\n",
      "10250it [11:09,  9.01it/s]Train epoch: 13 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006787\n",
      "10275it [11:12,  9.12it/s]Train epoch: 13 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006045\n",
      "10300it [11:15,  8.79it/s]Train epoch: 13 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006639\n",
      "10325it [11:18,  8.90it/s]Train epoch: 13 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006470\n",
      "10350it [11:20,  8.91it/s]Train epoch: 13 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006088\n",
      "10375it [11:23,  8.54it/s]Train epoch: 13 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006370\n",
      "10400it [11:26,  8.48it/s]Train epoch: 13 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006378\n",
      "10425it [11:29,  8.16it/s]Train epoch: 13 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006070\n",
      "10450it [11:32,  8.05it/s]Train epoch: 13 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006418\n",
      "10475it [11:35,  8.09it/s]Train epoch: 13 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005666\n",
      "10500it [11:38,  8.23it/s]Train epoch: 13 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006469\n",
      "10525it [11:41,  8.25it/s]Train epoch: 13 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006188\n",
      "10550it [11:45,  7.92it/s]Train epoch: 13 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006417\n",
      "10575it [11:48,  7.92it/s]Train epoch: 13 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10600it [11:51,  8.22it/s]Train epoch: 13 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.005975\n",
      "10625it [11:54,  8.07it/s]Train epoch: 13 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006674\n",
      "10650it [11:57,  8.18it/s]Train epoch: 13 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.005969\n",
      "10675it [12:00,  8.09it/s]Train epoch: 13 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006517\n",
      "10700it [12:03,  7.67it/s]Train epoch: 13 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006122\n",
      "10725it [12:06,  7.95it/s]Train epoch: 13 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005760\n",
      "10750it [12:10,  7.53it/s]Train epoch: 13 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006779\n",
      "10775it [12:13,  7.73it/s]Train epoch: 13 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006714\n",
      "10800it [12:16,  7.72it/s]Train epoch: 13 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006852\n",
      "10825it [12:19,  7.74it/s]Train epoch: 13 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006703\n",
      "10850it [12:23,  7.12it/s]Train epoch: 13 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006688\n",
      "10875it [12:26,  7.78it/s]Train epoch: 13 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006793\n",
      "10900it [12:29,  7.71it/s]Train epoch: 13 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006610\n",
      "10925it [12:32,  7.77it/s]Train epoch: 13 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005995\n",
      "10950it [12:36,  7.04it/s]Train epoch: 13 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006606\n",
      "10975it [12:39,  7.68it/s]Train epoch: 13 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006363\n",
      "11000it [12:42,  7.83it/s]Train epoch: 13 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006293\n",
      "11025it [12:46,  7.33it/s]Train epoch: 13 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006556\n",
      "11050it [12:49,  6.97it/s]Train epoch: 13 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007228\n",
      "11075it [12:52,  7.76it/s]Train epoch: 13 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006771\n",
      "11100it [12:55,  7.77it/s]Train epoch: 13 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007396\n",
      "11125it [12:59,  7.75it/s]Train epoch: 13 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006918\n",
      "11150it [13:02,  7.78it/s]Train epoch: 13 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006647\n",
      "11175it [13:05,  7.93it/s]Train epoch: 13 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007739\n",
      "11200it [13:08,  7.80it/s]Train epoch: 13 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007020\n",
      "11225it [13:12,  7.63it/s]Train epoch: 13 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006919\n",
      "11250it [13:15,  7.67it/s]Train epoch: 13 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007585\n",
      "11275it [13:18,  7.84it/s]Train epoch: 13 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007306\n",
      "11300it [13:21,  7.59it/s]Train epoch: 13 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006622\n",
      "11325it [13:25,  7.82it/s]Train epoch: 13 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007853\n",
      "11350it [13:28,  7.45it/s]Train epoch: 13 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007708\n",
      "11375it [13:31,  7.77it/s]Train epoch: 13 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007932\n",
      "11400it [13:34,  7.77it/s]Train epoch: 13 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006912\n",
      "11425it [13:38,  7.81it/s]Train epoch: 13 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007760\n",
      "11450it [13:41,  7.32it/s]Train epoch: 13 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006738\n",
      "11475it [13:44,  7.78it/s]Train epoch: 13 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008235\n",
      "11500it [13:47,  7.78it/s]Train epoch: 13 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007717\n",
      "11525it [13:51,  7.42it/s]Train epoch: 13 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007229\n",
      "11550it [13:54,  7.11it/s]Train epoch: 13 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007169\n",
      "11575it [13:57,  7.72it/s]Train epoch: 13 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008301\n",
      "11600it [14:01,  7.62it/s]Train epoch: 13 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007619\n",
      "11625it [14:04,  7.72it/s]Train epoch: 13 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007081\n",
      "11650it [14:07,  8.05it/s]Train epoch: 13 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007720\n",
      "11675it [14:10,  7.75it/s]Train epoch: 13 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008116\n",
      "11700it [14:14,  7.94it/s]Train epoch: 13 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008737\n",
      "11725it [14:17,  7.61it/s]Train epoch: 13 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008571\n",
      "11750it [14:20,  7.77it/s]Train epoch: 13 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008413\n",
      "11775it [14:23,  7.61it/s]Train epoch: 13 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008545\n",
      "11800it [14:27,  7.69it/s]Train epoch: 13 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008208\n",
      "11825it [14:30,  7.56it/s]Train epoch: 13 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008539\n",
      "11850it [14:33,  7.49it/s]Train epoch: 13 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008910\n",
      "11875it [14:37,  7.55it/s]Train epoch: 13 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009748\n",
      "11900it [14:40,  7.40it/s]Train epoch: 13 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011855\n",
      "11925it [14:43,  7.45it/s]Train epoch: 13 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009913\n",
      "11930it [14:44, 13.49it/s]\n",
      "epoch loss: 0.004818942617392363\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:13, 124.91it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0330, 0.0480, 0.0520, 0.0499, 0.8798\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3313, 0.5401, 0.4615, 0.4977, 0.9819\n",
      "rec_at_8: 0.3555\n",
      "prec_at_8: 0.6555\n",
      "rec_at_15: 0.4943\n",
      "prec_at_15: 0.5093\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 127.77it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0327, 0.0509, 0.0534, 0.0521, 0.8713\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3273, 0.5396, 0.4541, 0.4932, 0.9816\n",
      "rec_at_8: 0.3427\n",
      "prec_at_8: 0.6570\n",
      "rec_at_15: 0.4776\n",
      "prec_at_15: 0.5107\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 13\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0330, 0.0480, 0.0520, 0.0499, 0.8798\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3313, 0.5401, 0.4615, 0.4977, 0.9819\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0068\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 13\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0327, 0.0509, 0.0534, 0.0521, 0.8713\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3273, 0.5396, 0.4541, 0.4932, 0.9816\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0070\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "EPOCH 14\n",
      "0it [00:00, ?it/s]Train epoch: 14 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006578\n",
      "23it [00:00, 51.02it/s]Train epoch: 14 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003931\n",
      "48it [00:01, 44.01it/s]Train epoch: 14 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003780\n",
      "74it [00:01, 43.51it/s]Train epoch: 14 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003080\n",
      "99it [00:02, 40.16it/s]Train epoch: 14 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003251\n",
      "123it [00:02, 38.91it/s]Train epoch: 14 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003072\n",
      "147it [00:03, 33.72it/s]Train epoch: 14 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003091\n",
      "172it [00:04, 34.97it/s]Train epoch: 14 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003115\n",
      "200it [00:05, 34.75it/s]Train epoch: 14 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002991\n",
      "225it [00:05, 32.43it/s]Train epoch: 14 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003739\n",
      "249it [00:06, 31.78it/s]Train epoch: 14 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273it [00:07, 33.66it/s]Train epoch: 14 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002565\n",
      "297it [00:08, 33.26it/s]Train epoch: 14 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003356\n",
      "325it [00:08, 30.59it/s]Train epoch: 14 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002783\n",
      "347it [00:09, 28.82it/s]Train epoch: 14 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003266\n",
      "374it [00:10, 31.26it/s]Train epoch: 14 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003114\n",
      "398it [00:11, 30.49it/s]Train epoch: 14 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003173\n",
      "422it [00:12, 30.35it/s]Train epoch: 14 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003154\n",
      "450it [00:13, 30.57it/s]Train epoch: 14 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003058\n",
      "474it [00:13, 31.76it/s]Train epoch: 14 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003478\n",
      "498it [00:14, 31.32it/s]Train epoch: 14 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003041\n",
      "525it [00:15, 29.92it/s]Train epoch: 14 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003233\n",
      "548it [00:16, 29.20it/s]Train epoch: 14 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003167\n",
      "575it [00:17, 29.42it/s]Train epoch: 14 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003157\n",
      "599it [00:17, 28.81it/s]Train epoch: 14 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003519\n",
      "625it [00:18, 29.23it/s]Train epoch: 14 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003279\n",
      "649it [00:19, 31.51it/s]Train epoch: 14 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003046\n",
      "673it [00:20, 29.57it/s]Train epoch: 14 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002540\n",
      "699it [00:21, 27.58it/s]Train epoch: 14 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003137\n",
      "724it [00:22, 27.31it/s]Train epoch: 14 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003295\n",
      "747it [00:23, 28.56it/s]Train epoch: 14 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003054\n",
      "775it [00:23, 28.01it/s]Train epoch: 14 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003404\n",
      "800it [00:24, 27.68it/s]Train epoch: 14 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003254\n",
      "824it [00:25, 29.88it/s]Train epoch: 14 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003236\n",
      "849it [00:26, 26.93it/s]Train epoch: 14 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003587\n",
      "875it [00:27, 28.55it/s]Train epoch: 14 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003000\n",
      "899it [00:28, 28.24it/s]Train epoch: 14 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003287\n",
      "925it [00:29, 29.02it/s]Train epoch: 14 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003063\n",
      "947it [00:30, 28.83it/s]Train epoch: 14 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003061\n",
      "973it [00:31, 26.22it/s]Train epoch: 14 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002404\n",
      "998it [00:32, 26.98it/s]Train epoch: 14 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003221\n",
      "1024it [00:33, 26.96it/s]Train epoch: 14 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004422\n",
      "1049it [00:33, 26.53it/s]Train epoch: 14 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003044\n",
      "1074it [00:34, 28.19it/s]Train epoch: 14 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003433\n",
      "1098it [00:35, 26.14it/s]Train epoch: 14 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003486\n",
      "1123it [00:36, 27.12it/s]Train epoch: 14 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003500\n",
      "1150it [00:37, 27.07it/s]Train epoch: 14 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003532\n",
      "1174it [00:38, 26.74it/s]Train epoch: 14 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003410\n",
      "1198it [00:39, 26.22it/s]Train epoch: 14 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003621\n",
      "1223it [00:40, 26.29it/s]Train epoch: 14 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003685\n",
      "1249it [00:41, 27.00it/s]Train epoch: 14 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003438\n",
      "1274it [00:42, 26.23it/s]Train epoch: 14 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.002956\n",
      "1298it [00:43, 25.33it/s]Train epoch: 14 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003050\n",
      "1325it [00:44, 25.19it/s]Train epoch: 14 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003021\n",
      "1350it [00:45, 26.67it/s]Train epoch: 14 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004079\n",
      "1374it [00:46, 24.89it/s]Train epoch: 14 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003331\n",
      "1398it [00:47, 26.94it/s]Train epoch: 14 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003355\n",
      "1423it [00:48, 25.52it/s]Train epoch: 14 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.002986\n",
      "1450it [00:49, 25.14it/s]Train epoch: 14 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003251\n",
      "1474it [00:50, 26.75it/s]Train epoch: 14 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003433\n",
      "1498it [00:50, 26.57it/s]Train epoch: 14 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004518\n",
      "1525it [00:52, 24.41it/s]Train epoch: 14 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004177\n",
      "1549it [00:53, 26.39it/s]Train epoch: 14 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003172\n",
      "1575it [00:53, 26.15it/s]Train epoch: 14 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003465\n",
      "1600it [00:54, 25.15it/s]Train epoch: 14 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003110\n",
      "1624it [00:55, 24.17it/s]Train epoch: 14 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003774\n",
      "1648it [00:56, 22.99it/s]Train epoch: 14 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003856\n",
      "1673it [00:57, 24.17it/s]Train epoch: 14 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003732\n",
      "1700it [00:59, 24.36it/s]Train epoch: 14 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003113\n",
      "1724it [01:00, 24.74it/s]Train epoch: 14 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002795\n",
      "1748it [01:01, 24.95it/s]Train epoch: 14 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004191\n",
      "1775it [01:02, 24.93it/s]Train epoch: 14 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003472\n",
      "1800it [01:03, 26.19it/s]Train epoch: 14 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003398\n",
      "1824it [01:04, 24.91it/s]Train epoch: 14 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002816\n",
      "1848it [01:05, 24.43it/s]Train epoch: 14 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003588\n",
      "1875it [01:06, 25.58it/s]Train epoch: 14 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003903\n",
      "1899it [01:07, 23.68it/s]Train epoch: 14 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002784\n",
      "1923it [01:08, 24.96it/s]Train epoch: 14 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003075\n",
      "1950it [01:09, 25.63it/s]Train epoch: 14 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003072\n",
      "1974it [01:10, 24.00it/s]Train epoch: 14 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003604\n",
      "1998it [01:11, 24.88it/s]Train epoch: 14 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002857\n",
      "2025it [01:12, 23.70it/s]Train epoch: 14 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003470\n",
      "2049it [01:13, 25.12it/s]Train epoch: 14 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003276\n",
      "2073it [01:14, 23.71it/s]Train epoch: 14 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003410\n",
      "2100it [01:15, 23.76it/s]Train epoch: 14 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003590\n",
      "2124it [01:16, 25.40it/s]Train epoch: 14 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003862\n",
      "2149it [01:17, 24.66it/s]Train epoch: 14 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003273\n",
      "2173it [01:18, 23.85it/s]Train epoch: 14 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003701\n",
      "2200it [01:19, 22.55it/s]Train epoch: 14 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003595\n",
      "2224it [01:20, 23.41it/s]Train epoch: 14 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003396\n",
      "2248it [01:21, 23.60it/s]Train epoch: 14 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003165\n",
      "2275it [01:22, 22.99it/s]Train epoch: 14 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003485\n",
      "2299it [01:23, 23.95it/s]Train epoch: 14 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002732\n",
      "2323it [01:24, 23.30it/s]Train epoch: 14 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350it [01:25, 23.12it/s]Train epoch: 14 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003144\n",
      "2374it [01:26, 23.34it/s]Train epoch: 14 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004509\n",
      "2398it [01:27, 22.31it/s]Train epoch: 14 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004134\n",
      "2425it [01:29, 22.03it/s]Train epoch: 14 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002928\n",
      "2449it [01:30, 22.96it/s]Train epoch: 14 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003385\n",
      "2473it [01:31, 22.41it/s]Train epoch: 14 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003857\n",
      "2500it [01:32, 23.65it/s]Train epoch: 14 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003279\n",
      "2524it [01:33, 23.51it/s]Train epoch: 14 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003176\n",
      "2548it [01:34, 23.30it/s]Train epoch: 14 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004448\n",
      "2575it [01:35, 23.33it/s]Train epoch: 14 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003143\n",
      "2599it [01:36, 22.49it/s]Train epoch: 14 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003430\n",
      "2623it [01:37, 22.17it/s]Train epoch: 14 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003508\n",
      "2650it [01:39, 22.20it/s]Train epoch: 14 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004028\n",
      "2674it [01:40, 20.86it/s]Train epoch: 14 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003609\n",
      "2698it [01:41, 21.81it/s]Train epoch: 14 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003136\n",
      "2725it [01:42, 23.40it/s]Train epoch: 14 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003388\n",
      "2749it [01:43, 21.16it/s]Train epoch: 14 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004045\n",
      "2773it [01:44, 22.00it/s]Train epoch: 14 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003511\n",
      "2800it [01:46, 21.76it/s]Train epoch: 14 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003321\n",
      "2824it [01:47, 20.99it/s]Train epoch: 14 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003792\n",
      "2848it [01:48, 20.81it/s]Train epoch: 14 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003497\n",
      "2875it [01:49, 21.48it/s]Train epoch: 14 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003800\n",
      "2899it [01:50, 20.96it/s]Train epoch: 14 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003699\n",
      "2925it [01:52, 19.63it/s]Train epoch: 14 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003846\n",
      "2950it [01:53, 21.28it/s]Train epoch: 14 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.003972\n",
      "2974it [01:54, 22.74it/s]Train epoch: 14 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003733\n",
      "2998it [01:55, 21.69it/s]Train epoch: 14 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004238\n",
      "3025it [01:56, 22.91it/s]Train epoch: 14 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003893\n",
      "3049it [01:57, 20.43it/s]Train epoch: 14 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003363\n",
      "3073it [01:58, 22.46it/s]Train epoch: 14 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003890\n",
      "3100it [02:00, 21.86it/s]Train epoch: 14 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003873\n",
      "3124it [02:01, 21.57it/s]Train epoch: 14 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003575\n",
      "3148it [02:02, 21.19it/s]Train epoch: 14 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003453\n",
      "3175it [02:03, 21.87it/s]Train epoch: 14 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003466\n",
      "3199it [02:04, 21.61it/s]Train epoch: 14 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004030\n",
      "3223it [02:05, 20.53it/s]Train epoch: 14 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.003939\n",
      "3250it [02:07, 21.63it/s]Train epoch: 14 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.003930\n",
      "3274it [02:08, 20.67it/s]Train epoch: 14 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003474\n",
      "3298it [02:09, 20.96it/s]Train epoch: 14 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004392\n",
      "3323it [02:10, 20.28it/s]Train epoch: 14 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003695\n",
      "3350it [02:12, 20.14it/s]Train epoch: 14 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003766\n",
      "3374it [02:13, 20.98it/s]Train epoch: 14 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.003948\n",
      "3398it [02:14, 20.56it/s]Train epoch: 14 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004041\n",
      "3424it [02:15, 21.25it/s]Train epoch: 14 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003468\n",
      "3450it [02:16, 20.02it/s]Train epoch: 14 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004032\n",
      "3474it [02:18, 19.67it/s]Train epoch: 14 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003604\n",
      "3500it [02:19, 21.14it/s]Train epoch: 14 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003722\n",
      "3523it [02:20, 20.50it/s]Train epoch: 14 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003855\n",
      "3549it [02:21, 19.66it/s]Train epoch: 14 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004179\n",
      "3573it [02:23, 18.87it/s]Train epoch: 14 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003267\n",
      "3600it [02:24, 19.49it/s]Train epoch: 14 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004307\n",
      "3623it [02:25, 19.89it/s]Train epoch: 14 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.003944\n",
      "3650it [02:26, 18.36it/s]Train epoch: 14 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004032\n",
      "3674it [02:28, 17.37it/s]Train epoch: 14 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004024\n",
      "3700it [02:29, 18.31it/s]Train epoch: 14 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004103\n",
      "3724it [02:31, 17.63it/s]Train epoch: 14 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004146\n",
      "3750it [02:32, 17.59it/s]Train epoch: 14 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004141\n",
      "3774it [02:33, 17.66it/s]Train epoch: 14 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.003982\n",
      "3800it [02:35, 17.74it/s]Train epoch: 14 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004400\n",
      "3824it [02:36, 16.37it/s]Train epoch: 14 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003742\n",
      "3850it [02:38, 17.71it/s]Train epoch: 14 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003443\n",
      "3874it [02:39, 16.89it/s]Train epoch: 14 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003414\n",
      "3900it [02:41, 17.44it/s]Train epoch: 14 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004370\n",
      "3924it [02:42, 16.03it/s]Train epoch: 14 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004053\n",
      "3950it [02:44, 17.01it/s]Train epoch: 14 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004396\n",
      "3975it [02:45, 17.67it/s]Train epoch: 14 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.004879\n",
      "4000it [02:47, 16.47it/s]Train epoch: 14 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003706\n",
      "4024it [02:48, 16.90it/s]Train epoch: 14 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004586\n",
      "4050it [02:50, 17.87it/s]Train epoch: 14 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004112\n",
      "4075it [02:51, 17.54it/s]Train epoch: 14 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004161\n",
      "4099it [02:52, 17.17it/s]Train epoch: 14 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004612\n",
      "4125it [02:54, 16.43it/s]Train epoch: 14 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004403\n",
      "4149it [02:55, 16.91it/s]Train epoch: 14 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003790\n",
      "4175it [02:57, 16.86it/s]Train epoch: 14 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004076\n",
      "4199it [02:58, 17.08it/s]Train epoch: 14 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004383\n",
      "4225it [03:00, 17.12it/s]Train epoch: 14 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003755\n",
      "4250it [03:01, 16.80it/s]Train epoch: 14 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004310\n",
      "4274it [03:03, 17.34it/s]Train epoch: 14 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.003955\n",
      "4300it [03:04, 17.57it/s]Train epoch: 14 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004675\n",
      "4324it [03:06, 16.50it/s]Train epoch: 14 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004087\n",
      "4350it [03:07, 15.98it/s]Train epoch: 14 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004391\n",
      "4374it [03:09, 16.78it/s]Train epoch: 14 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.003979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400it [03:10, 17.07it/s]Train epoch: 14 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003449\n",
      "4424it [03:12, 16.51it/s]Train epoch: 14 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004211\n",
      "4450it [03:13, 16.52it/s]Train epoch: 14 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003431\n",
      "4474it [03:15, 17.10it/s]Train epoch: 14 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004396\n",
      "4500it [03:16, 16.73it/s]Train epoch: 14 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.004980\n",
      "4524it [03:18, 17.11it/s]Train epoch: 14 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004346\n",
      "4550it [03:19, 16.86it/s]Train epoch: 14 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004075\n",
      "4574it [03:21, 16.40it/s]Train epoch: 14 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004611\n",
      "4600it [03:22, 16.03it/s]Train epoch: 14 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.003949\n",
      "4624it [03:24, 15.23it/s]Train epoch: 14 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.003901\n",
      "4650it [03:26, 15.53it/s]Train epoch: 14 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004520\n",
      "4674it [03:27, 15.87it/s]Train epoch: 14 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004347\n",
      "4700it [03:29, 16.06it/s]Train epoch: 14 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003877\n",
      "4724it [03:30, 15.98it/s]Train epoch: 14 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004077\n",
      "4750it [03:32, 15.50it/s]Train epoch: 14 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004678\n",
      "4774it [03:33, 15.72it/s]Train epoch: 14 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004146\n",
      "4800it [03:35, 15.52it/s]Train epoch: 14 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004297\n",
      "4824it [03:37, 15.33it/s]Train epoch: 14 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003813\n",
      "4850it [03:38, 15.53it/s]Train epoch: 14 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004514\n",
      "4874it [03:40, 15.51it/s]Train epoch: 14 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003878\n",
      "4900it [03:42, 15.77it/s]Train epoch: 14 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004208\n",
      "4924it [03:43, 15.15it/s]Train epoch: 14 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003873\n",
      "4950it [03:45, 15.58it/s]Train epoch: 14 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004169\n",
      "4974it [03:46, 15.61it/s]Train epoch: 14 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004254\n",
      "5000it [03:48, 15.47it/s]Train epoch: 14 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004142\n",
      "5024it [03:50, 14.93it/s]Train epoch: 14 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.003940\n",
      "5050it [03:51, 15.34it/s]Train epoch: 14 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.003928\n",
      "5074it [03:53, 14.55it/s]Train epoch: 14 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004216\n",
      "5100it [03:55, 14.97it/s]Train epoch: 14 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004255\n",
      "5124it [03:56, 14.70it/s]Train epoch: 14 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004434\n",
      "5150it [03:58, 15.51it/s]Train epoch: 14 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004494\n",
      "5174it [04:00, 14.97it/s]Train epoch: 14 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004382\n",
      "5200it [04:01, 14.96it/s]Train epoch: 14 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.003950\n",
      "5224it [04:03, 15.16it/s]Train epoch: 14 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004224\n",
      "5250it [04:05, 15.03it/s]Train epoch: 14 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004212\n",
      "5274it [04:06, 15.05it/s]Train epoch: 14 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004060\n",
      "5300it [04:08, 15.16it/s]Train epoch: 14 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.003977\n",
      "5324it [04:10, 14.65it/s]Train epoch: 14 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004449\n",
      "5350it [04:11, 14.59it/s]Train epoch: 14 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004459\n",
      "5374it [04:13, 15.13it/s]Train epoch: 14 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004141\n",
      "5400it [04:15, 14.61it/s]Train epoch: 14 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004104\n",
      "5424it [04:16, 14.96it/s]Train epoch: 14 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004516\n",
      "5450it [04:18, 14.64it/s]Train epoch: 14 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004419\n",
      "5474it [04:20, 14.42it/s]Train epoch: 14 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.004968\n",
      "5500it [04:22, 15.02it/s]Train epoch: 14 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004698\n",
      "5524it [04:23, 14.75it/s]Train epoch: 14 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003777\n",
      "5550it [04:25, 14.63it/s]Train epoch: 14 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004344\n",
      "5574it [04:27, 14.46it/s]Train epoch: 14 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004520\n",
      "5600it [04:28, 14.60it/s]Train epoch: 14 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004771\n",
      "5624it [04:30, 14.81it/s]Train epoch: 14 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004498\n",
      "5650it [04:32, 14.49it/s]Train epoch: 14 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.003996\n",
      "5674it [04:33, 14.96it/s]Train epoch: 14 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.004939\n",
      "5700it [04:35, 14.47it/s]Train epoch: 14 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004268\n",
      "5724it [04:37, 15.00it/s]Train epoch: 14 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004386\n",
      "5750it [04:39, 14.56it/s]Train epoch: 14 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005487\n",
      "5774it [04:40, 14.53it/s]Train epoch: 14 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004562\n",
      "5800it [04:42, 14.11it/s]Train epoch: 14 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004582\n",
      "5824it [04:44, 14.39it/s]Train epoch: 14 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004146\n",
      "5850it [04:46, 14.82it/s]Train epoch: 14 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005176\n",
      "5874it [04:47, 14.07it/s]Train epoch: 14 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005054\n",
      "5900it [04:49, 13.69it/s]Train epoch: 14 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005006\n",
      "5924it [04:51, 14.48it/s]Train epoch: 14 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004139\n",
      "5950it [04:53, 14.35it/s]Train epoch: 14 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004027\n",
      "5974it [04:54, 13.58it/s]Train epoch: 14 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005527\n",
      "6000it [04:56, 13.88it/s]Train epoch: 14 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004686\n",
      "6024it [04:58, 14.50it/s]Train epoch: 14 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.004957\n",
      "6050it [05:00, 14.13it/s]Train epoch: 14 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004401\n",
      "6074it [05:02, 13.81it/s]Train epoch: 14 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004115\n",
      "6100it [05:03, 14.25it/s]Train epoch: 14 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.003998\n",
      "6124it [05:05, 14.36it/s]Train epoch: 14 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004394\n",
      "6150it [05:07, 14.36it/s]Train epoch: 14 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004454\n",
      "6174it [05:09, 14.26it/s]Train epoch: 14 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005104\n",
      "6200it [05:10, 13.66it/s]Train epoch: 14 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004466\n",
      "6224it [05:12, 13.26it/s]Train epoch: 14 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003914\n",
      "6250it [05:14, 13.90it/s]Train epoch: 14 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004178\n",
      "6274it [05:16, 13.77it/s]Train epoch: 14 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003799\n",
      "6300it [05:18, 13.85it/s]Train epoch: 14 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004412\n",
      "6324it [05:19, 13.94it/s]Train epoch: 14 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.004883\n",
      "6350it [05:21, 13.77it/s]Train epoch: 14 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005232\n",
      "6374it [05:23, 13.83it/s]Train epoch: 14 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004075\n",
      "6400it [05:25, 13.83it/s]Train epoch: 14 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6424it [05:27, 13.61it/s]Train epoch: 14 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.004947\n",
      "6450it [05:28, 13.62it/s]Train epoch: 14 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004833\n",
      "6474it [05:30, 13.96it/s]Train epoch: 14 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004270\n",
      "6500it [05:32, 13.54it/s]Train epoch: 14 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004923\n",
      "6524it [05:34, 13.79it/s]Train epoch: 14 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004239\n",
      "6550it [05:36, 13.73it/s]Train epoch: 14 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004357\n",
      "6574it [05:38, 13.36it/s]Train epoch: 14 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004504\n",
      "6600it [05:39, 13.78it/s]Train epoch: 14 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005507\n",
      "6624it [05:41, 13.22it/s]Train epoch: 14 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004432\n",
      "6650it [05:43, 13.04it/s]Train epoch: 14 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005054\n",
      "6674it [05:45, 13.36it/s]Train epoch: 14 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004615\n",
      "6700it [05:47, 13.48it/s]Train epoch: 14 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004766\n",
      "6724it [05:49, 13.17it/s]Train epoch: 14 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004704\n",
      "6750it [05:51, 13.38it/s]Train epoch: 14 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004273\n",
      "6774it [05:53, 12.95it/s]Train epoch: 14 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.004908\n",
      "6800it [05:55, 13.44it/s]Train epoch: 14 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.004952\n",
      "6824it [05:56, 12.83it/s]Train epoch: 14 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005098\n",
      "6850it [05:58, 13.13it/s]Train epoch: 14 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.004875\n",
      "6874it [06:00, 12.93it/s]Train epoch: 14 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.003999\n",
      "6900it [06:02, 13.32it/s]Train epoch: 14 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004628\n",
      "6924it [06:04, 13.14it/s]Train epoch: 14 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004738\n",
      "6950it [06:06, 12.88it/s]Train epoch: 14 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005193\n",
      "6974it [06:08, 13.19it/s]Train epoch: 14 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004870\n",
      "7000it [06:10, 13.16it/s]Train epoch: 14 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004624\n",
      "7024it [06:12, 13.19it/s]Train epoch: 14 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005258\n",
      "7050it [06:14, 12.82it/s]Train epoch: 14 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004240\n",
      "7074it [06:15, 12.76it/s]Train epoch: 14 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004593\n",
      "7100it [06:17, 12.81it/s]Train epoch: 14 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005073\n",
      "7124it [06:19, 12.74it/s]Train epoch: 14 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004318\n",
      "7150it [06:21, 13.20it/s]Train epoch: 14 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005223\n",
      "7174it [06:23, 13.00it/s]Train epoch: 14 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004797\n",
      "7200it [06:25, 12.75it/s]Train epoch: 14 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005156\n",
      "7224it [06:27, 12.78it/s]Train epoch: 14 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004659\n",
      "7250it [06:29, 12.66it/s]Train epoch: 14 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004768\n",
      "7274it [06:31, 12.54it/s]Train epoch: 14 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005206\n",
      "7300it [06:33, 13.03it/s]Train epoch: 14 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005688\n",
      "7324it [06:35, 12.91it/s]Train epoch: 14 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004492\n",
      "7350it [06:37, 12.55it/s]Train epoch: 14 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005419\n",
      "7374it [06:39, 12.33it/s]Train epoch: 14 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005090\n",
      "7400it [06:41, 12.06it/s]Train epoch: 14 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004587\n",
      "7424it [06:43, 11.91it/s]Train epoch: 14 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005034\n",
      "7450it [06:45, 12.55it/s]Train epoch: 14 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005570\n",
      "7474it [06:47, 12.67it/s]Train epoch: 14 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004840\n",
      "7500it [06:49, 12.39it/s]Train epoch: 14 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005064\n",
      "7524it [06:51, 12.61it/s]Train epoch: 14 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004782\n",
      "7550it [06:53, 12.48it/s]Train epoch: 14 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004739\n",
      "7574it [06:55, 12.50it/s]Train epoch: 14 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005207\n",
      "7600it [06:57, 12.65it/s]Train epoch: 14 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006126\n",
      "7624it [06:59, 12.16it/s]Train epoch: 14 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005711\n",
      "7650it [07:01, 12.82it/s]Train epoch: 14 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004812\n",
      "7674it [07:03, 12.19it/s]Train epoch: 14 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.004939\n",
      "7700it [07:05, 12.47it/s]Train epoch: 14 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.004979\n",
      "7724it [07:07, 12.37it/s]Train epoch: 14 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005000\n",
      "7750it [07:09, 12.50it/s]Train epoch: 14 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005257\n",
      "7774it [07:11, 12.09it/s]Train epoch: 14 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004626\n",
      "7800it [07:13, 11.96it/s]Train epoch: 14 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004813\n",
      "7824it [07:15, 11.99it/s]Train epoch: 14 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005110\n",
      "7850it [07:18, 11.96it/s]Train epoch: 14 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004606\n",
      "7874it [07:20, 11.96it/s]Train epoch: 14 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004881\n",
      "7900it [07:22, 12.20it/s]Train epoch: 14 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005070\n",
      "7924it [07:24, 12.34it/s]Train epoch: 14 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005027\n",
      "7950it [07:26, 12.35it/s]Train epoch: 14 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005683\n",
      "7974it [07:28, 12.04it/s]Train epoch: 14 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004886\n",
      "8000it [07:30, 12.25it/s]Train epoch: 14 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004715\n",
      "8024it [07:32, 12.05it/s]Train epoch: 14 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005130\n",
      "8050it [07:34, 11.97it/s]Train epoch: 14 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004509\n",
      "8074it [07:36, 11.96it/s]Train epoch: 14 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.004934\n",
      "8100it [07:38, 12.06it/s]Train epoch: 14 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005314\n",
      "8124it [07:40, 11.76it/s]Train epoch: 14 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005488\n",
      "8150it [07:43, 11.70it/s]Train epoch: 14 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004685\n",
      "8174it [07:45, 12.02it/s]Train epoch: 14 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005400\n",
      "8200it [07:47, 11.76it/s]Train epoch: 14 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004709\n",
      "8224it [07:49, 11.70it/s]Train epoch: 14 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006245\n",
      "8250it [07:51, 11.80it/s]Train epoch: 14 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004825\n",
      "8274it [07:53, 11.77it/s]Train epoch: 14 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005376\n",
      "8300it [07:55, 11.69it/s]Train epoch: 14 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004852\n",
      "8324it [07:57, 11.51it/s]Train epoch: 14 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005480\n",
      "8350it [08:00, 11.53it/s]Train epoch: 14 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004685\n",
      "8374it [08:02, 11.42it/s]Train epoch: 14 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005466\n",
      "8400it [08:04, 11.49it/s]Train epoch: 14 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005092\n",
      "8424it [08:06, 11.36it/s]Train epoch: 14 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8450it [08:08, 11.27it/s]Train epoch: 14 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005426\n",
      "8474it [08:11, 11.39it/s]Train epoch: 14 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005173\n",
      "8500it [08:13, 11.59it/s]Train epoch: 14 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.005964\n",
      "8524it [08:15, 11.09it/s]Train epoch: 14 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005191\n",
      "8550it [08:17, 10.81it/s]Train epoch: 14 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005359\n",
      "8574it [08:19, 11.55it/s]Train epoch: 14 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005068\n",
      "8600it [08:22, 11.16it/s]Train epoch: 14 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005145\n",
      "8624it [08:24, 11.23it/s]Train epoch: 14 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005296\n",
      "8650it [08:26, 11.01it/s]Train epoch: 14 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005387\n",
      "8674it [08:28, 11.33it/s]Train epoch: 14 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006022\n",
      "8700it [08:31, 11.11it/s]Train epoch: 14 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006076\n",
      "8724it [08:33, 11.43it/s]Train epoch: 14 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005855\n",
      "8750it [08:35, 10.77it/s]Train epoch: 14 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005454\n",
      "8774it [08:37, 11.01it/s]Train epoch: 14 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005003\n",
      "8800it [08:40, 11.00it/s]Train epoch: 14 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005248\n",
      "8824it [08:42, 11.00it/s]Train epoch: 14 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005282\n",
      "8850it [08:44, 11.16it/s]Train epoch: 14 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005565\n",
      "8874it [08:47, 10.50it/s]Train epoch: 14 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005308\n",
      "8900it [08:49, 10.85it/s]Train epoch: 14 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005402\n",
      "8924it [08:51, 10.90it/s]Train epoch: 14 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005462\n",
      "8950it [08:54, 10.90it/s]Train epoch: 14 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006147\n",
      "8974it [08:56, 10.76it/s]Train epoch: 14 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005705\n",
      "9000it [08:58, 10.81it/s]Train epoch: 14 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005371\n",
      "9024it [09:00, 10.99it/s]Train epoch: 14 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005480\n",
      "9050it [09:03, 10.47it/s]Train epoch: 14 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005089\n",
      "9074it [09:05, 10.60it/s]Train epoch: 14 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004853\n",
      "9100it [09:07, 10.87it/s]Train epoch: 14 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005664\n",
      "9124it [09:10, 10.84it/s]Train epoch: 14 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005283\n",
      "9150it [09:12, 10.68it/s]Train epoch: 14 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004795\n",
      "9174it [09:14, 10.46it/s]Train epoch: 14 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005225\n",
      "9200it [09:17, 10.26it/s]Train epoch: 14 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005057\n",
      "9224it [09:19, 10.33it/s]Train epoch: 14 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006106\n",
      "9250it [09:22, 10.36it/s]Train epoch: 14 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005305\n",
      "9274it [09:24, 10.55it/s]Train epoch: 14 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005715\n",
      "9300it [09:26, 10.21it/s]Train epoch: 14 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006308\n",
      "9324it [09:29, 10.12it/s]Train epoch: 14 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006170\n",
      "9350it [09:31, 10.38it/s]Train epoch: 14 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006025\n",
      "9374it [09:34, 10.58it/s]Train epoch: 14 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005443\n",
      "9400it [09:36, 10.50it/s]Train epoch: 14 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005648\n",
      "9424it [09:39, 10.14it/s]Train epoch: 14 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005442\n",
      "9450it [09:41, 10.21it/s]Train epoch: 14 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005437\n",
      "9474it [09:43, 10.04it/s]Train epoch: 14 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006035\n",
      "9499it [09:46, 10.27it/s]Train epoch: 14 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005667\n",
      "9525it [09:49, 10.06it/s]Train epoch: 14 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006080\n",
      "9550it [09:51,  9.80it/s]Train epoch: 14 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.005983\n",
      "9575it [09:54,  9.83it/s]Train epoch: 14 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006081\n",
      "9600it [09:56,  9.78it/s]Train epoch: 14 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005818\n",
      "9624it [09:59,  9.83it/s]Train epoch: 14 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005253\n",
      "9650it [10:01,  9.86it/s]Train epoch: 14 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005348\n",
      "9675it [10:04,  9.89it/s]Train epoch: 14 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005793\n",
      "9699it [10:06, 10.18it/s]Train epoch: 14 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005097\n",
      "9725it [10:09,  9.65it/s]Train epoch: 14 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005746\n",
      "9749it [10:11,  9.92it/s]Train epoch: 14 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005675\n",
      "9775it [10:14,  9.96it/s]Train epoch: 14 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006431\n",
      "9800it [10:17,  9.47it/s]Train epoch: 14 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006215\n",
      "9825it [10:19,  9.38it/s]Train epoch: 14 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006333\n",
      "9850it [10:22,  9.53it/s]Train epoch: 14 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005719\n",
      "9875it [10:24,  9.33it/s]Train epoch: 14 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006125\n",
      "9900it [10:27,  9.69it/s]Train epoch: 14 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006540\n",
      "9925it [10:30,  9.29it/s]Train epoch: 14 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006175\n",
      "9949it [10:32,  9.40it/s]Train epoch: 14 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006709\n",
      "9975it [10:35,  9.26it/s]Train epoch: 14 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006230\n",
      "10000it [10:38,  9.30it/s]Train epoch: 14 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005756\n",
      "10025it [10:40,  8.95it/s]Train epoch: 14 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005723\n",
      "10050it [10:43,  9.03it/s]Train epoch: 14 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006251\n",
      "10075it [10:46,  9.27it/s]Train epoch: 14 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006693\n",
      "10100it [10:49,  9.06it/s]Train epoch: 14 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006372\n",
      "10125it [10:51,  9.21it/s]Train epoch: 14 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005729\n",
      "10150it [10:54,  9.11it/s]Train epoch: 14 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006254\n",
      "10175it [10:57,  8.98it/s]Train epoch: 14 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005881\n",
      "10200it [11:00,  9.00it/s]Train epoch: 14 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006297\n",
      "10225it [11:02,  8.98it/s]Train epoch: 14 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006299\n",
      "10250it [11:05,  8.81it/s]Train epoch: 14 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006804\n",
      "10275it [11:08,  8.67it/s]Train epoch: 14 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.005989\n",
      "10300it [11:11,  9.01it/s]Train epoch: 14 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006641\n",
      "10325it [11:14,  8.74it/s]Train epoch: 14 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006505\n",
      "10350it [11:17,  8.86it/s]Train epoch: 14 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006059\n",
      "10375it [11:19,  8.80it/s]Train epoch: 14 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006378\n",
      "10400it [11:22,  8.61it/s]Train epoch: 14 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006333\n",
      "10425it [11:25,  8.24it/s]Train epoch: 14 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006104\n",
      "10450it [11:28,  8.43it/s]Train epoch: 14 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10475it [11:31,  8.38it/s]Train epoch: 14 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005667\n",
      "10500it [11:34,  8.46it/s]Train epoch: 14 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006411\n",
      "10525it [11:37,  8.20it/s]Train epoch: 14 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006138\n",
      "10550it [11:40,  8.20it/s]Train epoch: 14 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006465\n",
      "10575it [11:43,  8.13it/s]Train epoch: 14 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005697\n",
      "10600it [11:46,  8.50it/s]Train epoch: 14 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.005903\n",
      "10625it [11:49,  7.98it/s]Train epoch: 14 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006650\n",
      "10650it [11:52,  8.19it/s]Train epoch: 14 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006017\n",
      "10675it [11:55,  7.92it/s]Train epoch: 14 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006566\n",
      "10700it [11:59,  8.07it/s]Train epoch: 14 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006099\n",
      "10725it [12:02,  8.29it/s]Train epoch: 14 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005742\n",
      "10750it [12:05,  7.79it/s]Train epoch: 14 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006754\n",
      "10775it [12:08,  8.04it/s]Train epoch: 14 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006696\n",
      "10800it [12:11,  8.04it/s]Train epoch: 14 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006848\n",
      "10825it [12:14,  7.64it/s]Train epoch: 14 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006699\n",
      "10850it [12:18,  7.84it/s]Train epoch: 14 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006608\n",
      "10875it [12:21,  7.97it/s]Train epoch: 14 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006763\n",
      "10900it [12:24,  7.90it/s]Train epoch: 14 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006612\n",
      "10925it [12:27,  7.76it/s]Train epoch: 14 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006003\n",
      "10950it [12:30,  7.70it/s]Train epoch: 14 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006618\n",
      "10975it [12:33,  7.89it/s]Train epoch: 14 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006321\n",
      "11000it [12:37,  7.92it/s]Train epoch: 14 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006293\n",
      "11025it [12:40,  7.75it/s]Train epoch: 14 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006552\n",
      "11050it [12:43,  7.80it/s]Train epoch: 14 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007232\n",
      "11075it [12:46,  7.66it/s]Train epoch: 14 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006799\n",
      "11100it [12:49,  7.96it/s]Train epoch: 14 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007414\n",
      "11125it [12:53,  7.80it/s]Train epoch: 14 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006931\n",
      "11150it [12:56,  7.98it/s]Train epoch: 14 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006631\n",
      "11175it [12:59,  7.89it/s]Train epoch: 14 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007810\n",
      "11200it [13:02,  7.77it/s]Train epoch: 14 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007005\n",
      "11225it [13:05,  7.68it/s]Train epoch: 14 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006920\n",
      "11250it [13:09,  7.77it/s]Train epoch: 14 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007581\n",
      "11275it [13:12,  7.91it/s]Train epoch: 14 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007318\n",
      "11300it [13:15,  7.90it/s]Train epoch: 14 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006646\n",
      "11325it [13:18,  7.78it/s]Train epoch: 14 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007881\n",
      "11350it [13:21,  7.92it/s]Train epoch: 14 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007732\n",
      "11375it [13:24,  7.80it/s]Train epoch: 14 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007880\n",
      "11400it [13:28,  7.78it/s]Train epoch: 14 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006941\n",
      "11425it [13:31,  7.73it/s]Train epoch: 14 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007709\n",
      "11450it [13:34,  7.85it/s]Train epoch: 14 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006749\n",
      "11475it [13:37,  7.78it/s]Train epoch: 14 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008240\n",
      "11500it [13:41,  7.63it/s]Train epoch: 14 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007772\n",
      "11525it [13:44,  7.89it/s]Train epoch: 14 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007168\n",
      "11550it [13:47,  7.81it/s]Train epoch: 14 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007191\n",
      "11575it [13:50,  7.43it/s]Train epoch: 14 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008265\n",
      "11600it [13:53,  7.65it/s]Train epoch: 14 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007651\n",
      "11625it [13:57,  7.45it/s]Train epoch: 14 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007147\n",
      "11650it [14:00,  7.44it/s]Train epoch: 14 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007657\n",
      "11675it [14:03,  7.62it/s]Train epoch: 14 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008163\n",
      "11700it [14:06,  7.73it/s]Train epoch: 14 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008703\n",
      "11725it [14:10,  7.78it/s]Train epoch: 14 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008671\n",
      "11750it [14:13,  7.48it/s]Train epoch: 14 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008445\n",
      "11775it [14:16,  7.72it/s]Train epoch: 14 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008550\n",
      "11800it [14:19,  7.80it/s]Train epoch: 14 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008305\n",
      "11825it [14:23,  7.71it/s]Train epoch: 14 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008560\n",
      "11850it [14:26,  7.68it/s]Train epoch: 14 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.009025\n",
      "11875it [14:29,  7.64it/s]Train epoch: 14 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009872\n",
      "11900it [14:32,  7.62it/s]Train epoch: 14 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.012049\n",
      "11925it [14:35,  7.67it/s]Train epoch: 14 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010271\n",
      "11930it [14:36, 13.61it/s]\n",
      "epoch loss: 0.004804288017673204\n",
      "last epoch: testing on test and train sets\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 126.48it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0310, 0.0487, 0.0439, 0.0462, 0.8810\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3314, 0.6041, 0.4234, 0.4978, 0.9820\n",
      "rec_at_8: 0.3612\n",
      "prec_at_8: 0.6652\n",
      "rec_at_15: 0.4998\n",
      "prec_at_15: 0.5155\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 128.47it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0306, 0.0510, 0.0443, 0.0474, 0.8722\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3261, 0.6025, 0.4154, 0.4918, 0.9817\n",
      "rec_at_8: 0.3486\n",
      "prec_at_8: 0.6681\n",
      "rec_at_15: 0.4848\n",
      "prec_at_15: 0.5187\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 14\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0310, 0.0487, 0.0439, 0.0462, 0.8810\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3314, 0.6041, 0.4234, 0.4978, 0.9820\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0062\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 14\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0306, 0.0510, 0.0443, 0.0474, 0.8722\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3261, 0.6025, 0.4154, 0.4918, 0.9817\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0064\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n",
      "\n",
      "TOTAL ELAPSED TIME FOR bert-tiny-caml MODEL AND 15 EPOCHS: 13905.534579\n"
     ]
    }
   ],
   "source": [
    "# bert-tiny 2500 word2vec\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny-caml \\\n",
    "    15 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience 10 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 4 \\\n",
    "    --last_module caml_attn \\\n",
    "    --max_sequence_length 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(Y='full', batch_size=4, bert_parallel_count=None, bert_parallel_final_layer='sum', bidirectional=None, cell_type='gru', code_emb=None, criterion='prec_at_8', cuda_device_no=None, data_path='./mimicdata/mimic3/train_full.csv', dropout=0.2, embed_file='./mimicdata/mimic3/processed_full.embed', embed_size=100, filter_size='10', from_prev_result='./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37', from_scratch=False, gpu=True, last_module='caml_attn', lmbda=0, lr=5e-05, max_sequence_length=2500, model='bert-tiny-caml', n_epochs=15, num_filter_maps=50, patience=10, pool=None, pos=False, pretrain=False, pretrain_batch_size=2, pretrain_datafile='./mimicdata/mimic3/pretrain_bert_tiny_2500', pretrain_epochs=3, pretrain_lr=0.0001, public_model=None, quiet=None, redefined_tokenizer=False, rnn_dim=128, rnn_layers=1, samples=None, seed=2484, stack_filters=None, test_model=None, tokenizer_path='./tokenizers/bert-tiny-mimic3-full-100-limit-100000-vocab.txt', version='mimic3', vocab='./mimicdata/mimic3/vocab.csv', warmup_steps=0, weight_decay=0)\n",
      "loading lookups...\n",
      "loading pretrained embeddings...\n",
      "adding unk embedding\n",
      "BertWithCAMLForMedical(\n",
      "  (bert): BertModel(\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (embed): Embedding(51919, 100, padding_idx=0)\n",
      "  (expand_linear): Linear(in_features=100, out_features=128, bias=False)\n",
      "  (bert_pool): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (bert_attention): Linear(in_features=128, out_features=8921, bias=False)\n",
      "  (bert_classifier): Linear(in_features=128, out_features=8921, bias=True)\n",
      ")\n",
      "EPOCH 0\n",
      "0it [00:00, ?it/s]Train epoch: 0 [batch #0, batch_size 4, seq length 68]\tLoss: 0.007058\n",
      "23it [00:00, 40.00it/s]Train epoch: 0 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003752\n",
      "48it [00:01, 37.53it/s]Train epoch: 0 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003602\n",
      "74it [00:01, 40.37it/s]Train epoch: 0 [batch #75, batch_size 4, seq length 307]\tLoss: 0.002977\n",
      "97it [00:02, 38.33it/s]Train epoch: 0 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003161\n",
      "123it [00:03, 38.14it/s]Train epoch: 0 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003062\n",
      "147it [00:03, 37.59it/s]Train epoch: 0 [batch #150, batch_size 4, seq length 370]\tLoss: 0.003053\n",
      "175it [00:04, 36.51it/s]Train epoch: 0 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003116\n",
      "199it [00:05, 33.69it/s]Train epoch: 0 [batch #200, batch_size 4, seq length 400]\tLoss: 0.003051\n",
      "223it [00:05, 33.80it/s]Train epoch: 0 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003708\n",
      "247it [00:06, 34.42it/s]Train epoch: 0 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003009\n",
      "275it [00:07, 33.68it/s]Train epoch: 0 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002598\n",
      "299it [00:08, 33.13it/s]Train epoch: 0 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003384\n",
      "323it [00:08, 33.31it/s]Train epoch: 0 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002824\n",
      "347it [00:09, 33.27it/s]Train epoch: 0 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003302\n",
      "375it [00:10, 31.56it/s]Train epoch: 0 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003191\n",
      "399it [00:11, 32.18it/s]Train epoch: 0 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003173\n",
      "423it [00:12, 31.88it/s]Train epoch: 0 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003194\n",
      "447it [00:12, 32.11it/s]Train epoch: 0 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003109\n",
      "475it [00:13, 30.45it/s]Train epoch: 0 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003556\n",
      "497it [00:14, 31.03it/s]Train epoch: 0 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003097\n",
      "525it [00:15, 32.87it/s]Train epoch: 0 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003333\n",
      "549it [00:16, 32.68it/s]Train epoch: 0 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003294\n",
      "573it [00:16, 33.24it/s]Train epoch: 0 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003250\n",
      "597it [00:17, 30.20it/s]Train epoch: 0 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003496\n",
      "624it [00:18, 28.99it/s]Train epoch: 0 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003435\n",
      "649it [00:19, 28.56it/s]Train epoch: 0 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003053\n",
      "672it [00:20, 27.94it/s]Train epoch: 0 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002585\n",
      "700it [00:21, 29.75it/s]Train epoch: 0 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003173\n",
      "723it [00:21, 31.64it/s]Train epoch: 0 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003368\n",
      "750it [00:22, 29.61it/s]Train epoch: 0 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003103\n",
      "774it [00:23, 29.61it/s]Train epoch: 0 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003597\n",
      "798it [00:24, 30.35it/s]Train epoch: 0 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003346\n",
      "823it [00:25, 29.22it/s]Train epoch: 0 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003285\n",
      "848it [00:26, 27.55it/s]Train epoch: 0 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003731\n",
      "873it [00:27, 28.12it/s]Train epoch: 0 [batch #875, batch_size 4, seq length 612]\tLoss: 0.003093\n",
      "899it [00:27, 26.37it/s]Train epoch: 0 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003386\n",
      "924it [00:28, 27.35it/s]Train epoch: 0 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003210\n",
      "949it [00:29, 27.96it/s]Train epoch: 0 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003119\n",
      "975it [00:30, 28.87it/s]Train epoch: 0 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002458\n",
      "1000it [00:31, 27.51it/s]Train epoch: 0 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003400\n",
      "1022it [00:32, 26.85it/s]Train epoch: 0 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004549\n",
      "1049it [00:33, 27.41it/s]Train epoch: 0 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003105\n",
      "1075it [00:34, 28.12it/s]Train epoch: 0 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003548\n",
      "1099it [00:35, 28.66it/s]Train epoch: 0 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1123it [00:35, 27.65it/s]Train epoch: 0 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003685\n",
      "1150it [00:36, 25.61it/s]Train epoch: 0 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003698\n",
      "1174it [00:37, 26.48it/s]Train epoch: 0 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003533\n",
      "1199it [00:38, 25.94it/s]Train epoch: 0 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003678\n",
      "1225it [00:39, 26.67it/s]Train epoch: 0 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003727\n",
      "1247it [00:40, 25.79it/s]Train epoch: 0 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003513\n",
      "1275it [00:41, 28.09it/s]Train epoch: 0 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003094\n",
      "1300it [00:42, 27.21it/s]Train epoch: 0 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003185\n",
      "1324it [00:43, 27.26it/s]Train epoch: 0 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003167\n",
      "1348it [00:44, 27.24it/s]Train epoch: 0 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004293\n",
      "1373it [00:45, 26.18it/s]Train epoch: 0 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003438\n",
      "1400it [00:46, 27.83it/s]Train epoch: 0 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003481\n",
      "1424it [00:47, 26.37it/s]Train epoch: 0 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003049\n",
      "1448it [00:48, 26.61it/s]Train epoch: 0 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003302\n",
      "1473it [00:49, 25.30it/s]Train epoch: 0 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003517\n",
      "1498it [00:49, 25.88it/s]Train epoch: 0 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004690\n",
      "1525it [00:51, 24.70it/s]Train epoch: 0 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004417\n",
      "1549it [00:52, 25.35it/s]Train epoch: 0 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003307\n",
      "1573it [00:52, 25.79it/s]Train epoch: 0 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003733\n",
      "1597it [00:53, 25.42it/s]Train epoch: 0 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003190\n",
      "1625it [00:54, 25.22it/s]Train epoch: 0 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003891\n",
      "1649it [00:55, 25.12it/s]Train epoch: 0 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003972\n",
      "1673it [00:56, 25.64it/s]Train epoch: 0 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003794\n",
      "1700it [00:57, 25.49it/s]Train epoch: 0 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003314\n",
      "1725it [00:58, 24.97it/s]Train epoch: 0 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002868\n",
      "1749it [00:59, 26.24it/s]Train epoch: 0 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004307\n",
      "1773it [01:00, 25.87it/s]Train epoch: 0 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003559\n",
      "1800it [01:01, 25.45it/s]Train epoch: 0 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003622\n",
      "1824it [01:02, 24.89it/s]Train epoch: 0 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002938\n",
      "1848it [01:03, 26.17it/s]Train epoch: 0 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003660\n",
      "1875it [01:04, 23.25it/s]Train epoch: 0 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.004025\n",
      "1899it [01:05, 24.88it/s]Train epoch: 0 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002923\n",
      "1923it [01:06, 24.90it/s]Train epoch: 0 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003164\n",
      "1950it [01:07, 23.46it/s]Train epoch: 0 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.003157\n",
      "1974it [01:08, 25.01it/s]Train epoch: 0 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003789\n",
      "1998it [01:09, 24.43it/s]Train epoch: 0 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002981\n",
      "2025it [01:10, 24.28it/s]Train epoch: 0 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003663\n",
      "2049it [01:11, 22.24it/s]Train epoch: 0 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003482\n",
      "2073it [01:13, 23.70it/s]Train epoch: 0 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003558\n",
      "2100it [01:14, 23.47it/s]Train epoch: 0 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003650\n",
      "2124it [01:15, 22.16it/s]Train epoch: 0 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.004057\n",
      "2148it [01:16, 25.08it/s]Train epoch: 0 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003383\n",
      "2175it [01:17, 24.72it/s]Train epoch: 0 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003926\n",
      "2199it [01:18, 24.42it/s]Train epoch: 0 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003720\n",
      "2223it [01:19, 22.32it/s]Train epoch: 0 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003519\n",
      "2250it [01:20, 23.66it/s]Train epoch: 0 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003285\n",
      "2274it [01:21, 24.22it/s]Train epoch: 0 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003771\n",
      "2298it [01:22, 24.41it/s]Train epoch: 0 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002752\n",
      "2325it [01:23, 22.81it/s]Train epoch: 0 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003538\n",
      "2349it [01:24, 23.90it/s]Train epoch: 0 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003251\n",
      "2373it [01:25, 23.05it/s]Train epoch: 0 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004628\n",
      "2400it [01:26, 23.48it/s]Train epoch: 0 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004377\n",
      "2424it [01:27, 23.57it/s]Train epoch: 0 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002983\n",
      "2448it [01:28, 23.43it/s]Train epoch: 0 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003555\n",
      "2475it [01:30, 23.02it/s]Train epoch: 0 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003928\n",
      "2499it [01:31, 23.85it/s]Train epoch: 0 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003455\n",
      "2523it [01:32, 22.97it/s]Train epoch: 0 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003355\n",
      "2550it [01:33, 23.53it/s]Train epoch: 0 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004759\n",
      "2574it [01:34, 23.20it/s]Train epoch: 0 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003292\n",
      "2598it [01:35, 21.28it/s]Train epoch: 0 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003596\n",
      "2625it [01:36, 22.48it/s]Train epoch: 0 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003530\n",
      "2649it [01:37, 23.13it/s]Train epoch: 0 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004206\n",
      "2673it [01:38, 21.52it/s]Train epoch: 0 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003759\n",
      "2700it [01:39, 21.81it/s]Train epoch: 0 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003306\n",
      "2724it [01:41, 20.97it/s]Train epoch: 0 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003544\n",
      "2748it [01:42, 21.73it/s]Train epoch: 0 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004155\n",
      "2775it [01:43, 22.15it/s]Train epoch: 0 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003714\n",
      "2799it [01:44, 23.29it/s]Train epoch: 0 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003432\n",
      "2823it [01:45, 22.39it/s]Train epoch: 0 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003853\n",
      "2850it [01:46, 22.82it/s]Train epoch: 0 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003631\n",
      "2874it [01:47, 21.22it/s]Train epoch: 0 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.004036\n",
      "2898it [01:48, 22.78it/s]Train epoch: 0 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003979\n",
      "2925it [01:50, 22.74it/s]Train epoch: 0 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003972\n",
      "2949it [01:51, 21.55it/s]Train epoch: 0 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.004135\n",
      "2973it [01:52, 23.37it/s]Train epoch: 0 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003966\n",
      "3000it [01:53, 21.41it/s]Train epoch: 0 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004518\n",
      "3024it [01:54, 21.96it/s]Train epoch: 0 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.004094\n",
      "3048it [01:55, 22.04it/s]Train epoch: 0 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003548\n",
      "3075it [01:56, 21.22it/s]Train epoch: 0 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.004084\n",
      "3099it [01:57, 20.51it/s]Train epoch: 0 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.004024\n",
      "3123it [01:59, 20.73it/s]Train epoch: 0 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003721\n",
      "3150it [02:00, 20.60it/s]Train epoch: 0 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003604\n",
      "3174it [02:01, 22.40it/s]Train epoch: 0 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198it [02:02, 21.09it/s]Train epoch: 0 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004225\n",
      "3225it [02:03, 21.14it/s]Train epoch: 0 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.004128\n",
      "3249it [02:05, 21.50it/s]Train epoch: 0 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.004142\n",
      "3273it [02:06, 21.23it/s]Train epoch: 0 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003700\n",
      "3300it [02:07, 20.53it/s]Train epoch: 0 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004673\n",
      "3324it [02:08, 21.11it/s]Train epoch: 0 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003938\n",
      "3350it [02:09, 21.67it/s]Train epoch: 0 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003916\n",
      "3374it [02:10, 22.12it/s]Train epoch: 0 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.004083\n",
      "3398it [02:12, 19.94it/s]Train epoch: 0 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004186\n",
      "3425it [02:13, 21.70it/s]Train epoch: 0 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003663\n",
      "3449it [02:14, 21.70it/s]Train epoch: 0 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004344\n",
      "3473it [02:15, 20.44it/s]Train epoch: 0 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003865\n",
      "3500it [02:17, 20.92it/s]Train epoch: 0 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003857\n",
      "3524it [02:18, 20.08it/s]Train epoch: 0 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.004068\n",
      "3548it [02:19, 20.36it/s]Train epoch: 0 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004485\n",
      "3574it [02:20, 19.53it/s]Train epoch: 0 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003458\n",
      "3598it [02:21, 20.48it/s]Train epoch: 0 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004534\n",
      "3624it [02:23, 19.02it/s]Train epoch: 0 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.004127\n",
      "3649it [02:24, 18.04it/s]Train epoch: 0 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004279\n",
      "3674it [02:25, 17.03it/s]Train epoch: 0 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004321\n",
      "3700it [02:27, 17.40it/s]Train epoch: 0 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004341\n",
      "3724it [02:28, 17.02it/s]Train epoch: 0 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004423\n",
      "3750it [02:30, 16.80it/s]Train epoch: 0 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004314\n",
      "3774it [02:31, 16.26it/s]Train epoch: 0 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004228\n",
      "3800it [02:33, 17.70it/s]Train epoch: 0 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004724\n",
      "3824it [02:34, 16.81it/s]Train epoch: 0 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003890\n",
      "3849it [02:36, 17.71it/s]Train epoch: 0 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003720\n",
      "3874it [02:37, 18.12it/s]Train epoch: 0 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003596\n",
      "3900it [02:38, 17.36it/s]Train epoch: 0 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004670\n",
      "3924it [02:40, 16.50it/s]Train epoch: 0 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004261\n",
      "3950it [02:41, 16.92it/s]Train epoch: 0 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004595\n",
      "3973it [02:43, 17.29it/s]Train epoch: 0 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.005145\n",
      "3999it [02:44, 16.44it/s]Train epoch: 0 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003915\n",
      "4025it [02:46, 15.88it/s]Train epoch: 0 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004790\n",
      "4049it [02:47, 17.73it/s]Train epoch: 0 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004446\n",
      "4075it [02:49, 16.97it/s]Train epoch: 0 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004377\n",
      "4099it [02:50, 17.36it/s]Train epoch: 0 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004793\n",
      "4125it [02:52, 16.08it/s]Train epoch: 0 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004643\n",
      "4149it [02:53, 17.53it/s]Train epoch: 0 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003975\n",
      "4175it [02:55, 17.08it/s]Train epoch: 0 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004291\n",
      "4199it [02:56, 16.50it/s]Train epoch: 0 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004593\n",
      "4225it [02:58, 16.90it/s]Train epoch: 0 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003959\n",
      "4249it [02:59, 16.29it/s]Train epoch: 0 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004522\n",
      "4275it [03:01, 17.20it/s]Train epoch: 0 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004193\n",
      "4299it [03:02, 16.15it/s]Train epoch: 0 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004889\n",
      "4325it [03:04, 16.65it/s]Train epoch: 0 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004333\n",
      "4349it [03:05, 16.46it/s]Train epoch: 0 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004686\n",
      "4375it [03:07, 17.01it/s]Train epoch: 0 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004192\n",
      "4399it [03:08, 16.29it/s]Train epoch: 0 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003630\n",
      "4425it [03:10, 16.70it/s]Train epoch: 0 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004546\n",
      "4449it [03:11, 16.23it/s]Train epoch: 0 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003596\n",
      "4475it [03:13, 17.20it/s]Train epoch: 0 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004596\n",
      "4499it [03:14, 16.79it/s]Train epoch: 0 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005275\n",
      "4525it [03:16, 16.17it/s]Train epoch: 0 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004545\n",
      "4549it [03:17, 15.78it/s]Train epoch: 0 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004282\n",
      "4575it [03:19, 17.10it/s]Train epoch: 0 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004848\n",
      "4599it [03:20, 15.47it/s]Train epoch: 0 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.004114\n",
      "4625it [03:22, 16.02it/s]Train epoch: 0 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.004164\n",
      "4649it [03:23, 15.06it/s]Train epoch: 0 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004809\n",
      "4675it [03:25, 15.49it/s]Train epoch: 0 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004538\n",
      "4699it [03:27, 15.44it/s]Train epoch: 0 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.004070\n",
      "4725it [03:28, 15.87it/s]Train epoch: 0 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004292\n",
      "4749it [03:30, 15.93it/s]Train epoch: 0 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004911\n",
      "4775it [03:31, 16.02it/s]Train epoch: 0 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004422\n",
      "4799it [03:33, 15.25it/s]Train epoch: 0 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004634\n",
      "4825it [03:35, 15.59it/s]Train epoch: 0 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.004049\n",
      "4849it [03:36, 15.64it/s]Train epoch: 0 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004637\n",
      "4875it [03:38, 16.11it/s]Train epoch: 0 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.004052\n",
      "4899it [03:39, 16.23it/s]Train epoch: 0 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004415\n",
      "4925it [03:41, 16.22it/s]Train epoch: 0 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.004071\n",
      "4949it [03:43, 15.65it/s]Train epoch: 0 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004388\n",
      "4975it [03:44, 15.42it/s]Train epoch: 0 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004481\n",
      "4999it [03:46, 15.51it/s]Train epoch: 0 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004385\n",
      "5025it [03:47, 15.99it/s]Train epoch: 0 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004206\n",
      "5049it [03:49, 14.96it/s]Train epoch: 0 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.004130\n",
      "5075it [03:51, 15.72it/s]Train epoch: 0 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004436\n",
      "5099it [03:52, 16.20it/s]Train epoch: 0 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004466\n",
      "5125it [03:54, 15.61it/s]Train epoch: 0 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004702\n",
      "5149it [03:55, 16.11it/s]Train epoch: 0 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004632\n",
      "5175it [03:57, 15.81it/s]Train epoch: 0 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004591\n",
      "5199it [03:59, 15.36it/s]Train epoch: 0 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004203\n",
      "5225it [04:00, 15.26it/s]Train epoch: 0 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5249it [04:02, 15.26it/s]Train epoch: 0 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004412\n",
      "5275it [04:04, 15.44it/s]Train epoch: 0 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004191\n",
      "5299it [04:05, 15.47it/s]Train epoch: 0 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.004165\n",
      "5325it [04:07, 15.06it/s]Train epoch: 0 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004604\n",
      "5349it [04:08, 14.97it/s]Train epoch: 0 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004724\n",
      "5375it [04:10, 15.51it/s]Train epoch: 0 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004374\n",
      "5399it [04:12, 15.05it/s]Train epoch: 0 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004310\n",
      "5425it [04:13, 15.78it/s]Train epoch: 0 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004686\n",
      "5449it [04:15, 14.75it/s]Train epoch: 0 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004577\n",
      "5475it [04:17, 15.72it/s]Train epoch: 0 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005246\n",
      "5499it [04:18, 14.70it/s]Train epoch: 0 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004959\n",
      "5525it [04:20, 14.29it/s]Train epoch: 0 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.004002\n",
      "5549it [04:22, 14.48it/s]Train epoch: 0 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004551\n",
      "5575it [04:23, 15.05it/s]Train epoch: 0 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004655\n",
      "5599it [04:25, 15.18it/s]Train epoch: 0 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004956\n",
      "5625it [04:27, 14.19it/s]Train epoch: 0 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004659\n",
      "5649it [04:28, 14.65it/s]Train epoch: 0 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004216\n",
      "5675it [04:30, 14.98it/s]Train epoch: 0 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.005146\n",
      "5699it [04:32, 15.08it/s]Train epoch: 0 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004422\n",
      "5725it [04:33, 14.86it/s]Train epoch: 0 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004626\n",
      "5749it [04:35, 15.04it/s]Train epoch: 0 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005774\n",
      "5775it [04:37, 15.11it/s]Train epoch: 0 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004864\n",
      "5799it [04:38, 14.78it/s]Train epoch: 0 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004879\n",
      "5825it [04:40, 14.91it/s]Train epoch: 0 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004390\n",
      "5849it [04:42, 13.68it/s]Train epoch: 0 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005421\n",
      "5875it [04:44, 13.48it/s]Train epoch: 0 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005369\n",
      "5899it [04:45, 13.36it/s]Train epoch: 0 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005279\n",
      "5925it [04:47, 14.80it/s]Train epoch: 0 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004361\n",
      "5949it [04:49, 14.25it/s]Train epoch: 0 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004292\n",
      "5975it [04:51, 14.43it/s]Train epoch: 0 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005842\n",
      "5999it [04:52, 14.37it/s]Train epoch: 0 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004973\n",
      "6025it [04:54, 13.99it/s]Train epoch: 0 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.005210\n",
      "6049it [04:56, 13.66it/s]Train epoch: 0 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004567\n",
      "6075it [04:58, 14.20it/s]Train epoch: 0 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004306\n",
      "6099it [05:00, 14.54it/s]Train epoch: 0 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004183\n",
      "6125it [05:01, 14.21it/s]Train epoch: 0 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004648\n",
      "6149it [05:03, 13.64it/s]Train epoch: 0 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004681\n",
      "6175it [05:05, 13.94it/s]Train epoch: 0 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005258\n",
      "6199it [05:07, 14.10it/s]Train epoch: 0 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004612\n",
      "6225it [05:09, 14.18it/s]Train epoch: 0 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.004070\n",
      "6249it [05:10, 13.33it/s]Train epoch: 0 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004497\n",
      "6275it [05:12, 13.44it/s]Train epoch: 0 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.004041\n",
      "6299it [05:14, 13.41it/s]Train epoch: 0 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004709\n",
      "6325it [05:16, 13.43it/s]Train epoch: 0 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.005152\n",
      "6349it [05:18, 14.56it/s]Train epoch: 0 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005401\n",
      "6375it [05:20, 13.77it/s]Train epoch: 0 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004325\n",
      "6399it [05:21, 14.38it/s]Train epoch: 0 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004527\n",
      "6425it [05:23, 13.39it/s]Train epoch: 0 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.005180\n",
      "6449it [05:25, 13.91it/s]Train epoch: 0 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.005047\n",
      "6475it [05:27, 13.31it/s]Train epoch: 0 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004580\n",
      "6499it [05:29, 13.62it/s]Train epoch: 0 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.005170\n",
      "6525it [05:31, 13.63it/s]Train epoch: 0 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004362\n",
      "6549it [05:32, 13.65it/s]Train epoch: 0 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004574\n",
      "6575it [05:34, 13.44it/s]Train epoch: 0 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004736\n",
      "6599it [05:36, 13.73it/s]Train epoch: 0 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005777\n",
      "6625it [05:38, 13.39it/s]Train epoch: 0 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004804\n",
      "6649it [05:40, 13.88it/s]Train epoch: 0 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005226\n",
      "6675it [05:42, 13.46it/s]Train epoch: 0 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004797\n",
      "6699it [05:43, 13.21it/s]Train epoch: 0 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004912\n",
      "6725it [05:45, 13.09it/s]Train epoch: 0 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004944\n",
      "6749it [05:47, 13.12it/s]Train epoch: 0 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004430\n",
      "6775it [05:49, 13.67it/s]Train epoch: 0 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005137\n",
      "6799it [05:51, 13.22it/s]Train epoch: 0 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005175\n",
      "6825it [05:53, 13.12it/s]Train epoch: 0 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005348\n",
      "6849it [05:55, 13.17it/s]Train epoch: 0 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.005084\n",
      "6875it [05:57, 13.01it/s]Train epoch: 0 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004169\n",
      "6899it [05:58, 13.65it/s]Train epoch: 0 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004846\n",
      "6925it [06:01, 12.78it/s]Train epoch: 0 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004915\n",
      "6949it [06:02, 13.15it/s]Train epoch: 0 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005498\n",
      "6975it [06:04, 13.01it/s]Train epoch: 0 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.005098\n",
      "6999it [06:06, 13.21it/s]Train epoch: 0 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004768\n",
      "7025it [06:08, 12.91it/s]Train epoch: 0 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005468\n",
      "7049it [06:10, 12.89it/s]Train epoch: 0 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004436\n",
      "7075it [06:12, 12.20it/s]Train epoch: 0 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004844\n",
      "7099it [06:14, 13.17it/s]Train epoch: 0 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005265\n",
      "7125it [06:16, 12.85it/s]Train epoch: 0 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004601\n",
      "7149it [06:18, 13.23it/s]Train epoch: 0 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005445\n",
      "7175it [06:20, 12.98it/s]Train epoch: 0 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004956\n",
      "7199it [06:22, 13.14it/s]Train epoch: 0 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005491\n",
      "7225it [06:24, 12.63it/s]Train epoch: 0 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004881\n",
      "7249it [06:26, 12.92it/s]Train epoch: 0 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.005068\n",
      "7275it [06:28, 12.79it/s]Train epoch: 0 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7299it [06:30, 12.74it/s]Train epoch: 0 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005835\n",
      "7325it [06:32, 12.64it/s]Train epoch: 0 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004679\n",
      "7349it [06:34, 12.72it/s]Train epoch: 0 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005731\n",
      "7375it [06:36, 12.28it/s]Train epoch: 0 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005326\n",
      "7399it [06:38, 12.61it/s]Train epoch: 0 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004777\n",
      "7425it [06:40, 12.79it/s]Train epoch: 0 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005235\n",
      "7449it [06:42, 12.14it/s]Train epoch: 0 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005761\n",
      "7475it [06:44, 12.38it/s]Train epoch: 0 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.005040\n",
      "7499it [06:45, 12.88it/s]Train epoch: 0 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005339\n",
      "7525it [06:48, 12.44it/s]Train epoch: 0 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.005073\n",
      "7549it [06:50, 12.47it/s]Train epoch: 0 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004900\n",
      "7575it [06:52, 12.62it/s]Train epoch: 0 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005451\n",
      "7599it [06:54, 12.75it/s]Train epoch: 0 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006504\n",
      "7625it [06:56, 12.64it/s]Train epoch: 0 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005914\n",
      "7649it [06:58, 12.78it/s]Train epoch: 0 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.005031\n",
      "7675it [07:00, 12.53it/s]Train epoch: 0 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.005070\n",
      "7699it [07:02, 12.17it/s]Train epoch: 0 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005290\n",
      "7725it [07:04, 12.58it/s]Train epoch: 0 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.005199\n",
      "7749it [07:06, 12.51it/s]Train epoch: 0 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005492\n",
      "7775it [07:08, 12.29it/s]Train epoch: 0 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004844\n",
      "7799it [07:10, 12.00it/s]Train epoch: 0 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.005067\n",
      "7825it [07:12, 12.22it/s]Train epoch: 0 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005308\n",
      "7849it [07:14, 12.13it/s]Train epoch: 0 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004781\n",
      "7875it [07:16, 12.18it/s]Train epoch: 0 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.005036\n",
      "7899it [07:18, 12.03it/s]Train epoch: 0 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005215\n",
      "7925it [07:20, 11.92it/s]Train epoch: 0 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005246\n",
      "7949it [07:22, 12.30it/s]Train epoch: 0 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005866\n",
      "7975it [07:24, 11.91it/s]Train epoch: 0 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.005121\n",
      "7999it [07:26, 11.68it/s]Train epoch: 0 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004882\n",
      "8025it [07:29, 11.83it/s]Train epoch: 0 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005385\n",
      "8049it [07:31, 11.62it/s]Train epoch: 0 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004698\n",
      "8075it [07:33, 12.17it/s]Train epoch: 0 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005244\n",
      "8099it [07:35, 11.73it/s]Train epoch: 0 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005564\n",
      "8125it [07:37, 11.72it/s]Train epoch: 0 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005750\n",
      "8149it [07:39, 12.05it/s]Train epoch: 0 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004934\n",
      "8175it [07:41, 11.77it/s]Train epoch: 0 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005649\n",
      "8199it [07:43, 11.54it/s]Train epoch: 0 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004894\n",
      "8225it [07:46, 11.94it/s]Train epoch: 0 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006537\n",
      "8249it [07:48, 11.90it/s]Train epoch: 0 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.005013\n",
      "8275it [07:50, 11.69it/s]Train epoch: 0 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005716\n",
      "8299it [07:52, 11.64it/s]Train epoch: 0 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.005029\n",
      "8325it [07:54, 11.78it/s]Train epoch: 0 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005710\n",
      "8349it [07:56, 11.63it/s]Train epoch: 0 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004946\n",
      "8375it [07:58, 11.22it/s]Train epoch: 0 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005738\n",
      "8399it [08:01, 11.40it/s]Train epoch: 0 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005225\n",
      "8425it [08:03, 11.42it/s]Train epoch: 0 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005296\n",
      "8449it [08:05, 11.49it/s]Train epoch: 0 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005587\n",
      "8475it [08:07, 11.06it/s]Train epoch: 0 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005321\n",
      "8499it [08:09, 11.25it/s]Train epoch: 0 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006228\n",
      "8525it [08:12, 11.15it/s]Train epoch: 0 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005437\n",
      "8549it [08:14, 11.50it/s]Train epoch: 0 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005539\n",
      "8575it [08:16, 11.12it/s]Train epoch: 0 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005260\n",
      "8599it [08:18, 11.29it/s]Train epoch: 0 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005338\n",
      "8625it [08:20, 11.21it/s]Train epoch: 0 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005460\n",
      "8649it [08:23, 11.21it/s]Train epoch: 0 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005627\n",
      "8675it [08:25, 11.09it/s]Train epoch: 0 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006351\n",
      "8699it [08:27, 10.61it/s]Train epoch: 0 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006309\n",
      "8725it [08:29, 11.44it/s]Train epoch: 0 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.006090\n",
      "8749it [08:32, 11.54it/s]Train epoch: 0 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005842\n",
      "8775it [08:34, 11.03it/s]Train epoch: 0 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005216\n",
      "8799it [08:36, 10.99it/s]Train epoch: 0 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005522\n",
      "8825it [08:39, 10.78it/s]Train epoch: 0 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005562\n",
      "8849it [08:41, 11.05it/s]Train epoch: 0 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005764\n",
      "8875it [08:43, 10.93it/s]Train epoch: 0 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005530\n",
      "8899it [08:45, 10.77it/s]Train epoch: 0 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005680\n",
      "8925it [08:48, 10.82it/s]Train epoch: 0 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005688\n",
      "8949it [08:50, 10.58it/s]Train epoch: 0 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006377\n",
      "8975it [08:52, 10.58it/s]Train epoch: 0 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005961\n",
      "8999it [08:55, 10.80it/s]Train epoch: 0 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005588\n",
      "9025it [08:57, 10.97it/s]Train epoch: 0 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005695\n",
      "9049it [08:59, 10.72it/s]Train epoch: 0 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005245\n",
      "9075it [09:02, 10.61it/s]Train epoch: 0 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004990\n",
      "9099it [09:04, 10.70it/s]Train epoch: 0 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005837\n",
      "9125it [09:06, 10.79it/s]Train epoch: 0 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005459\n",
      "9149it [09:09, 10.19it/s]Train epoch: 0 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004993\n",
      "9175it [09:11, 10.60it/s]Train epoch: 0 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005389\n",
      "9199it [09:14, 10.42it/s]Train epoch: 0 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005211\n",
      "9225it [09:16, 10.48it/s]Train epoch: 0 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006331\n",
      "9249it [09:18, 10.23it/s]Train epoch: 0 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005562\n",
      "9275it [09:21, 10.37it/s]Train epoch: 0 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005932\n",
      "9299it [09:23, 10.26it/s]Train epoch: 0 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006597\n",
      "9325it [09:26, 10.22it/s]Train epoch: 0 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9349it [09:28, 10.34it/s]Train epoch: 0 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006301\n",
      "9375it [09:31, 10.35it/s]Train epoch: 0 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005599\n",
      "9399it [09:33, 10.01it/s]Train epoch: 0 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005872\n",
      "9425it [09:36,  9.65it/s]Train epoch: 0 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005672\n",
      "9449it [09:38, 10.05it/s]Train epoch: 0 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005609\n",
      "9475it [09:41,  9.85it/s]Train epoch: 0 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006362\n",
      "9500it [09:43, 10.12it/s]Train epoch: 0 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005813\n",
      "9524it [09:45, 10.14it/s]Train epoch: 0 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006360\n",
      "9550it [09:48,  9.55it/s]Train epoch: 0 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.006158\n",
      "9575it [09:51,  9.90it/s]Train epoch: 0 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006279\n",
      "9600it [09:53,  9.92it/s]Train epoch: 0 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.006042\n",
      "9625it [09:56,  9.71it/s]Train epoch: 0 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005573\n",
      "9649it [09:58,  9.82it/s]Train epoch: 0 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005573\n",
      "9674it [10:01,  9.84it/s]Train epoch: 0 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005931\n",
      "9700it [10:03,  9.84it/s]Train epoch: 0 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005305\n",
      "9725it [10:06,  9.48it/s]Train epoch: 0 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005878\n",
      "9750it [10:08, 10.06it/s]Train epoch: 0 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005899\n",
      "9775it [10:11,  9.38it/s]Train epoch: 0 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006683\n",
      "9799it [10:14,  9.78it/s]Train epoch: 0 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006423\n",
      "9825it [10:16,  9.77it/s]Train epoch: 0 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006556\n",
      "9850it [10:19,  9.58it/s]Train epoch: 0 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005969\n",
      "9875it [10:22,  9.25it/s]Train epoch: 0 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006383\n",
      "9900it [10:24,  9.60it/s]Train epoch: 0 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006743\n",
      "9924it [10:27,  9.45it/s]Train epoch: 0 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006343\n",
      "9950it [10:30,  9.22it/s]Train epoch: 0 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006967\n",
      "9975it [10:32,  9.09it/s]Train epoch: 0 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006438\n",
      "10000it [10:35,  8.99it/s]Train epoch: 0 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.006037\n",
      "10025it [10:38,  9.18it/s]Train epoch: 0 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005917\n",
      "10050it [10:40,  8.83it/s]Train epoch: 0 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006501\n",
      "10075it [10:43,  9.27it/s]Train epoch: 0 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006853\n",
      "10100it [10:46,  9.02it/s]Train epoch: 0 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006553\n",
      "10125it [10:49,  9.03it/s]Train epoch: 0 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005957\n",
      "10150it [10:52,  9.11it/s]Train epoch: 0 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006484\n",
      "10175it [10:54,  8.80it/s]Train epoch: 0 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.006041\n",
      "10200it [10:57,  9.12it/s]Train epoch: 0 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006556\n",
      "10225it [11:00,  8.81it/s]Train epoch: 0 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006524\n",
      "10250it [11:03,  8.98it/s]Train epoch: 0 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006992\n",
      "10275it [11:06,  8.87it/s]Train epoch: 0 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006276\n",
      "10300it [11:08,  8.62it/s]Train epoch: 0 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006880\n",
      "10325it [11:11,  8.60it/s]Train epoch: 0 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006748\n",
      "10350it [11:14,  9.15it/s]Train epoch: 0 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006323\n",
      "10375it [11:17,  8.59it/s]Train epoch: 0 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006661\n",
      "10400it [11:20,  8.53it/s]Train epoch: 0 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006663\n",
      "10425it [11:23,  8.33it/s]Train epoch: 0 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006317\n",
      "10450it [11:26,  8.43it/s]Train epoch: 0 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006705\n",
      "10475it [11:29,  8.41it/s]Train epoch: 0 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005793\n",
      "10500it [11:32,  8.23it/s]Train epoch: 0 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006680\n",
      "10525it [11:35,  8.13it/s]Train epoch: 0 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006349\n",
      "10550it [11:38,  8.23it/s]Train epoch: 0 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006662\n",
      "10575it [11:41,  8.18it/s]Train epoch: 0 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005807\n",
      "10600it [11:44,  8.27it/s]Train epoch: 0 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.006082\n",
      "10625it [11:47,  8.13it/s]Train epoch: 0 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006939\n",
      "10650it [11:50,  7.80it/s]Train epoch: 0 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006237\n",
      "10675it [11:53,  8.03it/s]Train epoch: 0 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006711\n",
      "10700it [11:56,  8.07it/s]Train epoch: 0 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006348\n",
      "10725it [12:00,  8.06it/s]Train epoch: 0 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005886\n",
      "10750it [12:03,  7.89it/s]Train epoch: 0 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006971\n",
      "10775it [12:06,  7.97it/s]Train epoch: 0 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006888\n",
      "10800it [12:09,  7.75it/s]Train epoch: 0 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.007080\n",
      "10825it [12:12,  7.58it/s]Train epoch: 0 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006899\n",
      "10850it [12:16,  7.96it/s]Train epoch: 0 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006883\n",
      "10875it [12:19,  7.85it/s]Train epoch: 0 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.007036\n",
      "10900it [12:22,  7.84it/s]Train epoch: 0 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006731\n",
      "10925it [12:25,  7.92it/s]Train epoch: 0 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.006191\n",
      "10950it [12:28,  7.83it/s]Train epoch: 0 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006745\n",
      "10975it [12:32,  7.86it/s]Train epoch: 0 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006469\n",
      "11000it [12:35,  7.76it/s]Train epoch: 0 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006511\n",
      "11025it [12:38,  7.81it/s]Train epoch: 0 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006625\n",
      "11050it [12:41,  7.64it/s]Train epoch: 0 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007481\n",
      "11075it [12:44,  7.76it/s]Train epoch: 0 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.007003\n",
      "11100it [12:48,  7.90it/s]Train epoch: 0 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007616\n",
      "11125it [12:51,  7.93it/s]Train epoch: 0 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.007169\n",
      "11150it [12:54,  7.80it/s]Train epoch: 0 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006820\n",
      "11175it [12:57,  7.87it/s]Train epoch: 0 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007987\n",
      "11200it [13:00,  8.00it/s]Train epoch: 0 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007284\n",
      "11225it [13:04,  7.80it/s]Train epoch: 0 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007153\n",
      "11250it [13:07,  7.75it/s]Train epoch: 0 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007772\n",
      "11275it [13:10,  7.75it/s]Train epoch: 0 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007506\n",
      "11300it [13:13,  7.64it/s]Train epoch: 0 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006853\n",
      "11325it [13:16,  7.67it/s]Train epoch: 0 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007975\n",
      "11350it [13:20,  7.85it/s]Train epoch: 0 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11375it [13:23,  7.75it/s]Train epoch: 0 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.008088\n",
      "11400it [13:26,  7.69it/s]Train epoch: 0 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.007116\n",
      "11425it [13:29,  7.72it/s]Train epoch: 0 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007844\n",
      "11450it [13:33,  7.79it/s]Train epoch: 0 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006961\n",
      "11475it [13:36,  7.81it/s]Train epoch: 0 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008438\n",
      "11500it [13:39,  7.63it/s]Train epoch: 0 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007999\n",
      "11525it [13:42,  7.83it/s]Train epoch: 0 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007389\n",
      "11550it [13:45,  7.82it/s]Train epoch: 0 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007317\n",
      "11575it [13:49,  7.81it/s]Train epoch: 0 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008384\n",
      "11600it [13:52,  7.70it/s]Train epoch: 0 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007831\n",
      "11625it [13:55,  7.71it/s]Train epoch: 0 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007318\n",
      "11650it [13:58,  7.79it/s]Train epoch: 0 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007848\n",
      "11675it [14:02,  7.65it/s]Train epoch: 0 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008435\n",
      "11700it [14:05,  7.68it/s]Train epoch: 0 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008976\n",
      "11725it [14:08,  7.69it/s]Train epoch: 0 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008864\n",
      "11750it [14:11,  7.83it/s]Train epoch: 0 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008527\n",
      "11775it [14:14,  7.96it/s]Train epoch: 0 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008607\n",
      "11800it [14:18,  7.82it/s]Train epoch: 0 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008476\n",
      "11825it [14:21,  7.81it/s]Train epoch: 0 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008646\n",
      "11850it [14:24,  7.72it/s]Train epoch: 0 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008957\n",
      "11875it [14:27,  7.98it/s]Train epoch: 0 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009890\n",
      "11900it [14:31,  7.87it/s]Train epoch: 0 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011933\n",
      "11925it [14:34,  7.73it/s]Train epoch: 0 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.010155\n",
      "11930it [14:34, 13.64it/s]\n",
      "epoch loss: 0.004994631414450018\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 126.12it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0305, 0.0459, 0.0480, 0.0469, 0.8778\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3209, 0.5474, 0.4368, 0.4859, 0.9809\n",
      "rec_at_8: 0.3470\n",
      "prec_at_8: 0.6402\n",
      "rec_at_15: 0.4840\n",
      "prec_at_15: 0.4983\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 127.77it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0310, 0.0516, 0.0499, 0.0507, 0.8671\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3150, 0.5439, 0.4280, 0.4791, 0.9805\n",
      "rec_at_8: 0.3328\n",
      "prec_at_8: 0.6385\n",
      "rec_at_15: 0.4646\n",
      "prec_at_15: 0.4979\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 0\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0305, 0.0459, 0.0480, 0.0469, 0.8778\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3209, 0.5474, 0.4368, 0.4859, 0.9809\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 0\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0310, 0.0516, 0.0499, 0.0507, 0.8671\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3150, 0.5439, 0.4280, 0.4791, 0.9805\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0072\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "\n",
      "EPOCH 1\n",
      "0it [00:00, ?it/s]Train epoch: 1 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006031\n",
      "21it [00:00, 48.61it/s]Train epoch: 1 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003835\n",
      "46it [00:00, 45.97it/s]Train epoch: 1 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003653\n",
      "71it [00:01, 42.31it/s]Train epoch: 1 [batch #75, batch_size 4, seq length 307]\tLoss: 0.003017\n",
      "96it [00:02, 40.36it/s]Train epoch: 1 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003206\n",
      "121it [00:02, 39.98it/s]Train epoch: 1 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003065\n",
      "147it [00:03, 36.81it/s]Train epoch: 1 [batch #150, batch_size 4, seq length 370]\tLoss: 0.002992\n",
      "172it [00:04, 35.32it/s]Train epoch: 1 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003089\n",
      "200it [00:05, 34.44it/s]Train epoch: 1 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002986\n",
      "224it [00:05, 34.14it/s]Train epoch: 1 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003675\n",
      "248it [00:06, 33.36it/s]Train epoch: 1 [batch #250, batch_size 4, seq length 428]\tLoss: 0.003040\n",
      "272it [00:07, 32.88it/s]Train epoch: 1 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002528\n",
      "300it [00:08, 32.67it/s]Train epoch: 1 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003294\n",
      "324it [00:08, 32.08it/s]Train epoch: 1 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002787\n",
      "348it [00:09, 30.01it/s]Train epoch: 1 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003364\n",
      "372it [00:10, 31.71it/s]Train epoch: 1 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003102\n",
      "400it [00:11, 30.14it/s]Train epoch: 1 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003180\n",
      "423it [00:12, 30.68it/s]Train epoch: 1 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003177\n",
      "447it [00:12, 32.24it/s]Train epoch: 1 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003099\n",
      "475it [00:13, 30.37it/s]Train epoch: 1 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003472\n",
      "500it [00:14, 27.14it/s]Train epoch: 1 [batch #500, batch_size 4, seq length 519]\tLoss: 0.003029\n",
      "525it [00:15, 29.31it/s]Train epoch: 1 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003281\n",
      "548it [00:16, 29.08it/s]Train epoch: 1 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003150\n",
      "575it [00:17, 29.98it/s]Train epoch: 1 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003164\n",
      "597it [00:17, 30.64it/s]Train epoch: 1 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003424\n",
      "625it [00:18, 29.85it/s]Train epoch: 1 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003332\n",
      "649it [00:19, 29.32it/s]Train epoch: 1 [batch #650, batch_size 4, seq length 559]\tLoss: 0.003020\n",
      "675it [00:20, 28.06it/s]Train epoch: 1 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002529\n",
      "697it [00:21, 29.08it/s]Train epoch: 1 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003119\n",
      "722it [00:22, 29.69it/s]Train epoch: 1 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003292\n",
      "750it [00:23, 27.70it/s]Train epoch: 1 [batch #750, batch_size 4, seq length 584]\tLoss: 0.003050\n",
      "775it [00:24, 27.42it/s]Train epoch: 1 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003414\n",
      "800it [00:24, 28.22it/s]Train epoch: 1 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003266\n",
      "823it [00:25, 28.80it/s]Train epoch: 1 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003201\n",
      "850it [00:26, 27.83it/s]Train epoch: 1 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003558\n",
      "873it [00:27, 28.79it/s]Train epoch: 1 [batch #875, batch_size 4, seq length 612]\tLoss: 0.002977\n",
      "898it [00:28, 26.02it/s]Train epoch: 1 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003314\n",
      "924it [00:29, 28.64it/s]Train epoch: 1 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003088\n",
      "949it [00:30, 28.37it/s]Train epoch: 1 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003089\n",
      "973it [00:31, 28.75it/s]Train epoch: 1 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002428\n",
      "1000it [00:32, 27.13it/s]Train epoch: 1 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003191\n",
      "1023it [00:32, 26.39it/s]Train epoch: 1 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004420\n",
      "1048it [00:33, 26.98it/s]Train epoch: 1 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.003051\n",
      "1075it [00:34, 26.51it/s]Train epoch: 1 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099it [00:35, 27.79it/s]Train epoch: 1 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003461\n",
      "1123it [00:36, 27.99it/s]Train epoch: 1 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003561\n",
      "1149it [00:37, 26.97it/s]Train epoch: 1 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003536\n",
      "1174it [00:38, 27.00it/s]Train epoch: 1 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003406\n",
      "1199it [00:39, 26.08it/s]Train epoch: 1 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003574\n",
      "1223it [00:40, 26.35it/s]Train epoch: 1 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003653\n",
      "1248it [00:41, 28.34it/s]Train epoch: 1 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003386\n",
      "1275it [00:42, 27.92it/s]Train epoch: 1 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.003004\n",
      "1299it [00:43, 27.26it/s]Train epoch: 1 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.003105\n",
      "1323it [00:44, 27.30it/s]Train epoch: 1 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003089\n",
      "1349it [00:45, 27.97it/s]Train epoch: 1 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004101\n",
      "1373it [00:45, 26.18it/s]Train epoch: 1 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003335\n",
      "1400it [00:46, 26.12it/s]Train epoch: 1 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003416\n",
      "1424it [00:47, 25.08it/s]Train epoch: 1 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.003023\n",
      "1448it [00:48, 25.86it/s]Train epoch: 1 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003219\n",
      "1475it [00:49, 25.92it/s]Train epoch: 1 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003424\n",
      "1499it [00:50, 26.91it/s]Train epoch: 1 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004503\n",
      "1523it [00:51, 25.82it/s]Train epoch: 1 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004275\n",
      "1550it [00:52, 25.29it/s]Train epoch: 1 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003237\n",
      "1574it [00:53, 24.99it/s]Train epoch: 1 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003510\n",
      "1598it [00:54, 25.56it/s]Train epoch: 1 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003117\n",
      "1625it [00:55, 25.27it/s]Train epoch: 1 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003722\n",
      "1649it [00:56, 25.27it/s]Train epoch: 1 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003842\n",
      "1673it [00:57, 24.87it/s]Train epoch: 1 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003711\n",
      "1700it [00:58, 25.05it/s]Train epoch: 1 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003129\n",
      "1724it [00:59, 24.20it/s]Train epoch: 1 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002787\n",
      "1748it [01:00, 25.62it/s]Train epoch: 1 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004186\n",
      "1775it [01:01, 22.84it/s]Train epoch: 1 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003497\n",
      "1799it [01:02, 24.73it/s]Train epoch: 1 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003458\n",
      "1823it [01:03, 25.91it/s]Train epoch: 1 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002879\n",
      "1850it [01:04, 25.42it/s]Train epoch: 1 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003564\n",
      "1874it [01:05, 24.82it/s]Train epoch: 1 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003849\n",
      "1898it [01:06, 24.54it/s]Train epoch: 1 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002799\n",
      "1925it [01:07, 24.97it/s]Train epoch: 1 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.003022\n",
      "1949it [01:08, 23.56it/s]Train epoch: 1 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.002977\n",
      "1973it [01:09, 24.79it/s]Train epoch: 1 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003713\n",
      "2000it [01:10, 23.92it/s]Train epoch: 1 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002877\n",
      "2024it [01:11, 25.05it/s]Train epoch: 1 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003473\n",
      "2048it [01:12, 23.98it/s]Train epoch: 1 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003287\n",
      "2075it [01:14, 24.45it/s]Train epoch: 1 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003441\n",
      "2099it [01:15, 24.01it/s]Train epoch: 1 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003550\n",
      "2123it [01:16, 24.22it/s]Train epoch: 1 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003895\n",
      "2150it [01:17, 21.91it/s]Train epoch: 1 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003327\n",
      "2174it [01:18, 22.65it/s]Train epoch: 1 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003717\n",
      "2198it [01:19, 22.86it/s]Train epoch: 1 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003503\n",
      "2225it [01:20, 23.42it/s]Train epoch: 1 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003379\n",
      "2249it [01:21, 23.99it/s]Train epoch: 1 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003178\n",
      "2273it [01:22, 22.73it/s]Train epoch: 1 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003586\n",
      "2300it [01:23, 23.23it/s]Train epoch: 1 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002658\n",
      "2324it [01:24, 23.02it/s]Train epoch: 1 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003400\n",
      "2348it [01:25, 23.37it/s]Train epoch: 1 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003171\n",
      "2375it [01:26, 23.69it/s]Train epoch: 1 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004520\n",
      "2399it [01:27, 24.10it/s]Train epoch: 1 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004198\n",
      "2423it [01:28, 23.95it/s]Train epoch: 1 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002890\n",
      "2450it [01:30, 22.71it/s]Train epoch: 1 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003389\n",
      "2474it [01:31, 22.30it/s]Train epoch: 1 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003774\n",
      "2498it [01:32, 22.96it/s]Train epoch: 1 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003306\n",
      "2525it [01:33, 23.69it/s]Train epoch: 1 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003190\n",
      "2549it [01:34, 22.42it/s]Train epoch: 1 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004543\n",
      "2573it [01:35, 21.74it/s]Train epoch: 1 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003171\n",
      "2600it [01:36, 22.73it/s]Train epoch: 1 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003521\n",
      "2624it [01:37, 24.33it/s]Train epoch: 1 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003427\n",
      "2648it [01:38, 22.56it/s]Train epoch: 1 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.004045\n",
      "2675it [01:40, 23.21it/s]Train epoch: 1 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003630\n",
      "2699it [01:41, 22.10it/s]Train epoch: 1 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003173\n",
      "2723it [01:42, 22.27it/s]Train epoch: 1 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003434\n",
      "2750it [01:43, 22.04it/s]Train epoch: 1 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004078\n",
      "2774it [01:44, 23.30it/s]Train epoch: 1 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003576\n",
      "2798it [01:45, 21.89it/s]Train epoch: 1 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003338\n",
      "2825it [01:46, 21.90it/s]Train epoch: 1 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003767\n",
      "2849it [01:47, 22.38it/s]Train epoch: 1 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003466\n",
      "2873it [01:48, 21.68it/s]Train epoch: 1 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003825\n",
      "2900it [01:50, 22.47it/s]Train epoch: 1 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003696\n",
      "2924it [01:51, 22.29it/s]Train epoch: 1 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003878\n",
      "2948it [01:52, 21.52it/s]Train epoch: 1 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.003953\n",
      "2975it [01:53, 21.41it/s]Train epoch: 1 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003772\n",
      "2999it [01:54, 22.60it/s]Train epoch: 1 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004311\n",
      "3023it [01:55, 21.79it/s]Train epoch: 1 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003952\n",
      "3050it [01:57, 21.43it/s]Train epoch: 1 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003384\n",
      "3074it [01:58, 22.11it/s]Train epoch: 1 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003963\n",
      "3098it [01:59, 21.18it/s]Train epoch: 1 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003911\n",
      "3125it [02:00, 22.04it/s]Train epoch: 1 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003688\n",
      "3149it [02:01, 20.80it/s]Train epoch: 1 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173it [02:02, 20.65it/s]Train epoch: 1 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003528\n",
      "3200it [02:04, 20.21it/s]Train epoch: 1 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004095\n",
      "3224it [02:05, 22.00it/s]Train epoch: 1 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.003974\n",
      "3248it [02:06, 21.40it/s]Train epoch: 1 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.003981\n",
      "3275it [02:07, 21.78it/s]Train epoch: 1 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003514\n",
      "3299it [02:08, 21.13it/s]Train epoch: 1 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004475\n",
      "3323it [02:09, 20.65it/s]Train epoch: 1 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003742\n",
      "3350it [02:11, 21.76it/s]Train epoch: 1 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003784\n",
      "3374it [02:12, 21.19it/s]Train epoch: 1 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.003945\n",
      "3398it [02:13, 20.52it/s]Train epoch: 1 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.004048\n",
      "3425it [02:14, 20.61it/s]Train epoch: 1 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003526\n",
      "3449it [02:15, 21.16it/s]Train epoch: 1 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.004105\n",
      "3473it [02:17, 21.42it/s]Train epoch: 1 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003678\n",
      "3500it [02:18, 21.10it/s]Train epoch: 1 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003746\n",
      "3524it [02:19, 21.36it/s]Train epoch: 1 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003899\n",
      "3548it [02:20, 20.47it/s]Train epoch: 1 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004240\n",
      "3575it [02:21, 20.35it/s]Train epoch: 1 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003324\n",
      "3599it [02:23, 21.65it/s]Train epoch: 1 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004365\n",
      "3623it [02:24, 21.31it/s]Train epoch: 1 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.003983\n",
      "3650it [02:25, 19.37it/s]Train epoch: 1 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.004089\n",
      "3674it [02:26, 17.52it/s]Train epoch: 1 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004091\n",
      "3700it [02:28, 18.15it/s]Train epoch: 1 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004073\n",
      "3724it [02:29, 17.12it/s]Train epoch: 1 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004223\n",
      "3750it [02:31, 17.28it/s]Train epoch: 1 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004177\n",
      "3774it [02:32, 17.56it/s]Train epoch: 1 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.004073\n",
      "3799it [02:34, 17.48it/s]Train epoch: 1 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004504\n",
      "3825it [02:35, 18.28it/s]Train epoch: 1 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003791\n",
      "3849it [02:36, 17.42it/s]Train epoch: 1 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003556\n",
      "3875it [02:38, 17.38it/s]Train epoch: 1 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003418\n",
      "3900it [02:39, 17.05it/s]Train epoch: 1 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004434\n",
      "3924it [02:41, 17.58it/s]Train epoch: 1 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.004129\n",
      "3949it [02:42, 17.51it/s]Train epoch: 1 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004415\n",
      "3975it [02:44, 17.48it/s]Train epoch: 1 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.004958\n",
      "3999it [02:45, 17.06it/s]Train epoch: 1 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003744\n",
      "4024it [02:46, 17.89it/s]Train epoch: 1 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004653\n",
      "4050it [02:48, 16.83it/s]Train epoch: 1 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004259\n",
      "4074it [02:49, 16.45it/s]Train epoch: 1 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004257\n",
      "4100it [02:51, 16.71it/s]Train epoch: 1 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004606\n",
      "4125it [02:52, 16.04it/s]Train epoch: 1 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004484\n",
      "4149it [02:54, 16.78it/s]Train epoch: 1 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003834\n",
      "4175it [02:55, 17.13it/s]Train epoch: 1 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004154\n",
      "4199it [02:57, 16.65it/s]Train epoch: 1 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004459\n",
      "4225it [02:58, 16.63it/s]Train epoch: 1 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003780\n",
      "4249it [03:00, 17.21it/s]Train epoch: 1 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004355\n",
      "4275it [03:01, 16.98it/s]Train epoch: 1 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.004000\n",
      "4299it [03:03, 16.37it/s]Train epoch: 1 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004753\n",
      "4325it [03:04, 16.92it/s]Train epoch: 1 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004122\n",
      "4349it [03:06, 16.75it/s]Train epoch: 1 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004465\n",
      "4375it [03:07, 16.99it/s]Train epoch: 1 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.004023\n",
      "4399it [03:09, 16.16it/s]Train epoch: 1 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003456\n",
      "4425it [03:10, 16.62it/s]Train epoch: 1 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004385\n",
      "4449it [03:12, 17.59it/s]Train epoch: 1 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003420\n",
      "4475it [03:13, 17.28it/s]Train epoch: 1 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004442\n",
      "4499it [03:15, 16.93it/s]Train epoch: 1 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.005035\n",
      "4525it [03:16, 16.55it/s]Train epoch: 1 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004389\n",
      "4549it [03:18, 16.03it/s]Train epoch: 1 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004144\n",
      "4575it [03:19, 17.19it/s]Train epoch: 1 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004650\n",
      "4599it [03:21, 16.47it/s]Train epoch: 1 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.003939\n",
      "4625it [03:22, 15.43it/s]Train epoch: 1 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.003972\n",
      "4649it [03:24, 15.48it/s]Train epoch: 1 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004591\n",
      "4675it [03:25, 16.31it/s]Train epoch: 1 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004410\n",
      "4699it [03:27, 15.33it/s]Train epoch: 1 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003870\n",
      "4725it [03:29, 15.52it/s]Train epoch: 1 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004175\n",
      "4749it [03:30, 14.85it/s]Train epoch: 1 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004819\n",
      "4775it [03:32, 14.80it/s]Train epoch: 1 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004210\n",
      "4799it [03:33, 15.84it/s]Train epoch: 1 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004401\n",
      "4825it [03:35, 15.31it/s]Train epoch: 1 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003852\n",
      "4849it [03:37, 15.87it/s]Train epoch: 1 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004537\n",
      "4875it [03:38, 15.59it/s]Train epoch: 1 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003904\n",
      "4899it [03:40, 15.92it/s]Train epoch: 1 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004265\n",
      "4925it [03:41, 15.53it/s]Train epoch: 1 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003903\n",
      "4949it [03:43, 14.96it/s]Train epoch: 1 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004206\n",
      "4975it [03:45, 14.99it/s]Train epoch: 1 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004276\n",
      "4999it [03:46, 15.76it/s]Train epoch: 1 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004228\n",
      "5025it [03:48, 14.87it/s]Train epoch: 1 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.004062\n",
      "5049it [03:50, 14.71it/s]Train epoch: 1 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.003987\n",
      "5075it [03:51, 14.82it/s]Train epoch: 1 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004235\n",
      "5099it [03:53, 15.05it/s]Train epoch: 1 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004338\n",
      "5125it [03:55, 15.29it/s]Train epoch: 1 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004520\n",
      "5149it [03:56, 15.23it/s]Train epoch: 1 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004472\n",
      "5175it [03:58, 15.79it/s]Train epoch: 1 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004393\n",
      "5199it [03:59, 15.02it/s]Train epoch: 1 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.004023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5225it [04:01, 14.96it/s]Train epoch: 1 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004254\n",
      "5249it [04:03, 14.64it/s]Train epoch: 1 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004219\n",
      "5275it [04:05, 15.05it/s]Train epoch: 1 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004029\n",
      "5299it [04:06, 14.71it/s]Train epoch: 1 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.003982\n",
      "5325it [04:08, 14.84it/s]Train epoch: 1 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004501\n",
      "5349it [04:09, 15.42it/s]Train epoch: 1 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004525\n",
      "5375it [04:11, 14.72it/s]Train epoch: 1 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004196\n",
      "5399it [04:13, 14.84it/s]Train epoch: 1 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004131\n",
      "5425it [04:15, 14.81it/s]Train epoch: 1 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004554\n",
      "5449it [04:16, 14.72it/s]Train epoch: 1 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004482\n",
      "5475it [04:18, 14.76it/s]Train epoch: 1 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.005085\n",
      "5499it [04:20, 14.36it/s]Train epoch: 1 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004721\n",
      "5525it [04:21, 14.52it/s]Train epoch: 1 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003870\n",
      "5549it [04:23, 14.85it/s]Train epoch: 1 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004422\n",
      "5575it [04:25, 14.60it/s]Train epoch: 1 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004519\n",
      "5599it [04:26, 14.62it/s]Train epoch: 1 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004812\n",
      "5625it [04:28, 15.04it/s]Train epoch: 1 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004506\n",
      "5649it [04:30, 14.66it/s]Train epoch: 1 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004070\n",
      "5675it [04:32, 13.92it/s]Train epoch: 1 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.004961\n",
      "5699it [04:33, 14.53it/s]Train epoch: 1 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004308\n",
      "5725it [04:35, 15.19it/s]Train epoch: 1 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004425\n",
      "5749it [04:37, 14.41it/s]Train epoch: 1 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005552\n",
      "5775it [04:38, 14.54it/s]Train epoch: 1 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004683\n",
      "5799it [04:40, 14.35it/s]Train epoch: 1 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004699\n",
      "5825it [04:42, 15.69it/s]Train epoch: 1 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004271\n",
      "5849it [04:44, 14.64it/s]Train epoch: 1 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005320\n",
      "5875it [04:45, 14.70it/s]Train epoch: 1 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005180\n",
      "5899it [04:47, 14.87it/s]Train epoch: 1 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.005052\n",
      "5925it [04:49, 14.42it/s]Train epoch: 1 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004173\n",
      "5949it [04:50, 14.21it/s]Train epoch: 1 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004140\n",
      "5975it [04:52, 14.15it/s]Train epoch: 1 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005631\n",
      "5999it [04:54, 14.78it/s]Train epoch: 1 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004700\n",
      "6025it [04:56, 14.07it/s]Train epoch: 1 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.004971\n",
      "6049it [04:57, 14.37it/s]Train epoch: 1 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004450\n",
      "6075it [04:59, 14.08it/s]Train epoch: 1 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004148\n",
      "6099it [05:01, 14.08it/s]Train epoch: 1 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004097\n",
      "6125it [05:03, 14.17it/s]Train epoch: 1 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004482\n",
      "6149it [05:04, 14.27it/s]Train epoch: 1 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004499\n",
      "6175it [05:06, 14.26it/s]Train epoch: 1 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.005126\n",
      "6199it [05:08, 14.26it/s]Train epoch: 1 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004458\n",
      "6225it [05:10, 14.44it/s]Train epoch: 1 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003976\n",
      "6249it [05:11, 14.51it/s]Train epoch: 1 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004280\n",
      "6275it [05:13, 14.30it/s]Train epoch: 1 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003897\n",
      "6299it [05:15, 14.25it/s]Train epoch: 1 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004526\n",
      "6325it [05:17, 14.07it/s]Train epoch: 1 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.004973\n",
      "6349it [05:18, 14.30it/s]Train epoch: 1 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005317\n",
      "6375it [05:20, 13.73it/s]Train epoch: 1 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004103\n",
      "6399it [05:22, 14.78it/s]Train epoch: 1 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004385\n",
      "6425it [05:24, 13.99it/s]Train epoch: 1 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.004968\n",
      "6449it [05:26, 13.75it/s]Train epoch: 1 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004922\n",
      "6475it [05:27, 13.87it/s]Train epoch: 1 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004354\n",
      "6499it [05:29, 13.68it/s]Train epoch: 1 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004892\n",
      "6525it [05:31, 13.46it/s]Train epoch: 1 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004256\n",
      "6549it [05:33, 13.57it/s]Train epoch: 1 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004370\n",
      "6575it [05:35, 13.67it/s]Train epoch: 1 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004541\n",
      "6599it [05:37, 13.69it/s]Train epoch: 1 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005518\n",
      "6625it [05:38, 13.92it/s]Train epoch: 1 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004540\n",
      "6649it [05:40, 13.55it/s]Train epoch: 1 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.005060\n",
      "6675it [05:42, 13.66it/s]Train epoch: 1 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004697\n",
      "6699it [05:44, 13.29it/s]Train epoch: 1 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004738\n",
      "6725it [05:46, 13.31it/s]Train epoch: 1 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004780\n",
      "6749it [05:48, 13.53it/s]Train epoch: 1 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004269\n",
      "6775it [05:50, 13.36it/s]Train epoch: 1 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.005004\n",
      "6799it [05:51, 13.06it/s]Train epoch: 1 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.005018\n",
      "6825it [05:53, 13.10it/s]Train epoch: 1 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005100\n",
      "6849it [05:55, 13.41it/s]Train epoch: 1 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.004938\n",
      "6875it [05:57, 13.34it/s]Train epoch: 1 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.004061\n",
      "6899it [05:59, 13.26it/s]Train epoch: 1 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004653\n",
      "6925it [06:01, 13.47it/s]Train epoch: 1 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004779\n",
      "6949it [06:03, 13.13it/s]Train epoch: 1 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005250\n",
      "6975it [06:05, 13.09it/s]Train epoch: 1 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004919\n",
      "6999it [06:07, 13.08it/s]Train epoch: 1 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004651\n",
      "7025it [06:09, 13.11it/s]Train epoch: 1 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005360\n",
      "7049it [06:10, 12.87it/s]Train epoch: 1 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004305\n",
      "7075it [06:12, 13.04it/s]Train epoch: 1 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004599\n",
      "7099it [06:14, 12.94it/s]Train epoch: 1 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.005021\n",
      "7125it [06:16, 12.70it/s]Train epoch: 1 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004443\n",
      "7149it [06:18, 12.89it/s]Train epoch: 1 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005286\n",
      "7175it [06:20, 13.39it/s]Train epoch: 1 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004867\n",
      "7199it [06:22, 13.21it/s]Train epoch: 1 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005246\n",
      "7225it [06:24, 12.75it/s]Train epoch: 1 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004726\n",
      "7249it [06:26, 12.76it/s]Train epoch: 1 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7275it [06:28, 13.37it/s]Train epoch: 1 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005290\n",
      "7299it [06:30, 13.01it/s]Train epoch: 1 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005640\n",
      "7325it [06:32, 12.54it/s]Train epoch: 1 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004498\n",
      "7349it [06:34, 12.83it/s]Train epoch: 1 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005557\n",
      "7375it [06:36, 13.08it/s]Train epoch: 1 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005129\n",
      "7399it [06:37, 12.77it/s]Train epoch: 1 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004574\n",
      "7425it [06:40, 12.57it/s]Train epoch: 1 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.005064\n",
      "7449it [06:41, 13.02it/s]Train epoch: 1 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005575\n",
      "7475it [06:43, 12.89it/s]Train epoch: 1 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004852\n",
      "7499it [06:45, 12.76it/s]Train epoch: 1 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005077\n",
      "7525it [06:47, 12.43it/s]Train epoch: 1 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004873\n",
      "7549it [06:49, 12.53it/s]Train epoch: 1 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004796\n",
      "7575it [06:51, 12.54it/s]Train epoch: 1 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005288\n",
      "7599it [06:53, 12.56it/s]Train epoch: 1 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006206\n",
      "7625it [06:55, 12.19it/s]Train epoch: 1 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005729\n",
      "7649it [06:57, 12.39it/s]Train epoch: 1 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004875\n",
      "7675it [06:59, 12.42it/s]Train epoch: 1 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.004888\n",
      "7699it [07:01, 12.68it/s]Train epoch: 1 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.005092\n",
      "7725it [07:03, 12.41it/s]Train epoch: 1 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.004992\n",
      "7749it [07:05, 12.57it/s]Train epoch: 1 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005378\n",
      "7775it [07:08, 11.98it/s]Train epoch: 1 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004696\n",
      "7799it [07:09, 12.11it/s]Train epoch: 1 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004895\n",
      "7825it [07:12, 12.47it/s]Train epoch: 1 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005104\n",
      "7849it [07:14, 12.16it/s]Train epoch: 1 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004642\n",
      "7875it [07:16, 12.16it/s]Train epoch: 1 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004937\n",
      "7899it [07:18, 12.36it/s]Train epoch: 1 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.005093\n",
      "7925it [07:20, 12.27it/s]Train epoch: 1 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.005087\n",
      "7949it [07:22, 12.22it/s]Train epoch: 1 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005741\n",
      "7975it [07:24, 11.86it/s]Train epoch: 1 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004893\n",
      "7999it [07:26, 12.01it/s]Train epoch: 1 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004738\n",
      "8025it [07:28, 11.98it/s]Train epoch: 1 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005216\n",
      "8049it [07:30, 12.20it/s]Train epoch: 1 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004578\n",
      "8075it [07:32, 11.69it/s]Train epoch: 1 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.005036\n",
      "8099it [07:34, 12.09it/s]Train epoch: 1 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005435\n",
      "8125it [07:36, 11.83it/s]Train epoch: 1 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005553\n",
      "8149it [07:39, 11.66it/s]Train epoch: 1 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004782\n",
      "8175it [07:41, 11.97it/s]Train epoch: 1 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005489\n",
      "8199it [07:43, 11.84it/s]Train epoch: 1 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004647\n",
      "8225it [07:45, 11.57it/s]Train epoch: 1 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006306\n",
      "8249it [07:47, 11.92it/s]Train epoch: 1 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004864\n",
      "8275it [07:49, 11.68it/s]Train epoch: 1 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005494\n",
      "8299it [07:51, 12.07it/s]Train epoch: 1 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004909\n",
      "8325it [07:54, 11.31it/s]Train epoch: 1 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005516\n",
      "8349it [07:56, 11.57it/s]Train epoch: 1 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004720\n",
      "8375it [07:58, 11.53it/s]Train epoch: 1 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005507\n",
      "8399it [08:00, 11.36it/s]Train epoch: 1 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005101\n",
      "8425it [08:02, 11.15it/s]Train epoch: 1 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005111\n",
      "8449it [08:04, 11.44it/s]Train epoch: 1 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005434\n",
      "8475it [08:07, 11.35it/s]Train epoch: 1 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005177\n",
      "8499it [08:09, 11.34it/s]Train epoch: 1 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.006007\n",
      "8525it [08:11, 11.65it/s]Train epoch: 1 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005260\n",
      "8549it [08:13, 11.27it/s]Train epoch: 1 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005399\n",
      "8575it [08:15, 11.57it/s]Train epoch: 1 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.005091\n",
      "8599it [08:17, 11.15it/s]Train epoch: 1 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005136\n",
      "8625it [08:20, 11.28it/s]Train epoch: 1 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005269\n",
      "8649it [08:22, 10.98it/s]Train epoch: 1 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005469\n",
      "8675it [08:24, 11.14it/s]Train epoch: 1 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006218\n",
      "8699it [08:26, 11.02it/s]Train epoch: 1 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.006088\n",
      "8725it [08:29, 10.75it/s]Train epoch: 1 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005902\n",
      "8749it [08:31, 10.95it/s]Train epoch: 1 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005587\n",
      "8775it [08:33, 11.24it/s]Train epoch: 1 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.005047\n",
      "8799it [08:35, 11.14it/s]Train epoch: 1 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005379\n",
      "8825it [08:38, 11.05it/s]Train epoch: 1 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005377\n",
      "8849it [08:40, 10.95it/s]Train epoch: 1 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005562\n",
      "8875it [08:42, 10.68it/s]Train epoch: 1 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005333\n",
      "8899it [08:45, 11.30it/s]Train epoch: 1 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005484\n",
      "8925it [08:47, 10.55it/s]Train epoch: 1 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005564\n",
      "8949it [08:49, 10.51it/s]Train epoch: 1 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006142\n",
      "8975it [08:52, 10.81it/s]Train epoch: 1 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005809\n",
      "8999it [08:54, 10.95it/s]Train epoch: 1 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005398\n",
      "9025it [08:56, 10.77it/s]Train epoch: 1 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005537\n",
      "9049it [08:59, 10.65it/s]Train epoch: 1 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.005107\n",
      "9075it [09:01, 10.73it/s]Train epoch: 1 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004861\n",
      "9099it [09:03, 10.69it/s]Train epoch: 1 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005716\n",
      "9125it [09:06, 10.74it/s]Train epoch: 1 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005231\n",
      "9149it [09:08, 10.39it/s]Train epoch: 1 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004828\n",
      "9175it [09:10, 10.74it/s]Train epoch: 1 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005195\n",
      "9199it [09:13, 10.54it/s]Train epoch: 1 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.005029\n",
      "9225it [09:15, 10.04it/s]Train epoch: 1 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006094\n",
      "9249it [09:18, 10.44it/s]Train epoch: 1 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005373\n",
      "9275it [09:20, 10.47it/s]Train epoch: 1 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005752\n",
      "9299it [09:22, 10.46it/s]Train epoch: 1 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9325it [09:25,  9.98it/s]Train epoch: 1 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006167\n",
      "9349it [09:27, 10.29it/s]Train epoch: 1 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006063\n",
      "9375it [09:30, 10.32it/s]Train epoch: 1 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005420\n",
      "9399it [09:32, 10.57it/s]Train epoch: 1 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005721\n",
      "9425it [09:34, 10.33it/s]Train epoch: 1 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005509\n",
      "9449it [09:37, 10.06it/s]Train epoch: 1 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005459\n",
      "9475it [09:39,  9.92it/s]Train epoch: 1 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.006127\n",
      "9499it [09:42, 10.47it/s]Train epoch: 1 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005605\n",
      "9524it [09:44, 10.13it/s]Train epoch: 1 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006114\n",
      "9549it [09:47, 10.05it/s]Train epoch: 1 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.005983\n",
      "9575it [09:49, 10.22it/s]Train epoch: 1 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006105\n",
      "9599it [09:52,  9.93it/s]Train epoch: 1 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005948\n",
      "9625it [09:54, 10.11it/s]Train epoch: 1 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005405\n",
      "9650it [09:57, 10.04it/s]Train epoch: 1 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005359\n",
      "9675it [09:59,  9.76it/s]Train epoch: 1 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005790\n",
      "9699it [10:02, 10.03it/s]Train epoch: 1 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005112\n",
      "9724it [10:04,  9.42it/s]Train epoch: 1 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005691\n",
      "9749it [10:07,  9.62it/s]Train epoch: 1 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005713\n",
      "9775it [10:09,  9.68it/s]Train epoch: 1 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006442\n",
      "9799it [10:12,  9.60it/s]Train epoch: 1 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006239\n",
      "9825it [10:15,  9.64it/s]Train epoch: 1 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006407\n",
      "9850it [10:17,  9.49it/s]Train epoch: 1 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005732\n",
      "9875it [10:20,  9.57it/s]Train epoch: 1 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006184\n",
      "9900it [10:22,  9.05it/s]Train epoch: 1 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006569\n",
      "9925it [10:25,  9.31it/s]Train epoch: 1 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006136\n",
      "9950it [10:28,  9.23it/s]Train epoch: 1 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006776\n",
      "9975it [10:30,  9.21it/s]Train epoch: 1 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006243\n",
      "10000it [10:33,  9.14it/s]Train epoch: 1 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005797\n",
      "10025it [10:36,  9.22it/s]Train epoch: 1 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005734\n",
      "10050it [10:38,  9.01it/s]Train epoch: 1 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006261\n",
      "10075it [10:41,  8.98it/s]Train epoch: 1 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006710\n",
      "10100it [10:44,  9.50it/s]Train epoch: 1 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006362\n",
      "10125it [10:47,  9.09it/s]Train epoch: 1 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005780\n",
      "10150it [10:49,  8.84it/s]Train epoch: 1 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006272\n",
      "10175it [10:52,  9.16it/s]Train epoch: 1 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005883\n",
      "10200it [10:55,  9.09it/s]Train epoch: 1 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006303\n",
      "10225it [10:58,  9.22it/s]Train epoch: 1 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006399\n",
      "10250it [11:00,  9.11it/s]Train epoch: 1 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006835\n",
      "10275it [11:03,  9.08it/s]Train epoch: 1 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.006038\n",
      "10300it [11:06,  8.73it/s]Train epoch: 1 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006781\n",
      "10325it [11:09,  8.80it/s]Train epoch: 1 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006532\n",
      "10350it [11:12,  8.87it/s]Train epoch: 1 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.006130\n",
      "10375it [11:14,  8.80it/s]Train epoch: 1 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006419\n",
      "10400it [11:17,  8.55it/s]Train epoch: 1 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006473\n",
      "10425it [11:20,  8.46it/s]Train epoch: 1 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.006075\n",
      "10450it [11:23,  8.62it/s]Train epoch: 1 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006494\n",
      "10475it [11:26,  8.39it/s]Train epoch: 1 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005610\n",
      "10500it [11:29,  8.39it/s]Train epoch: 1 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006432\n",
      "10525it [11:32,  8.02it/s]Train epoch: 1 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006119\n",
      "10550it [11:35,  8.22it/s]Train epoch: 1 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006418\n",
      "10575it [11:38,  8.36it/s]Train epoch: 1 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005711\n",
      "10600it [11:41,  8.05it/s]Train epoch: 1 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.005978\n",
      "10625it [11:44,  8.09it/s]Train epoch: 1 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006697\n",
      "10650it [11:47,  8.21it/s]Train epoch: 1 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.006128\n",
      "10675it [11:50,  8.08it/s]Train epoch: 1 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006472\n",
      "10700it [11:53,  8.07it/s]Train epoch: 1 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.006103\n",
      "10725it [11:56,  8.02it/s]Train epoch: 1 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005705\n",
      "10750it [12:00,  7.93it/s]Train epoch: 1 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006723\n",
      "10775it [12:03,  7.89it/s]Train epoch: 1 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006662\n",
      "10800it [12:06,  7.98it/s]Train epoch: 1 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006933\n",
      "10825it [12:09,  7.77it/s]Train epoch: 1 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006742\n",
      "10850it [12:12,  7.99it/s]Train epoch: 1 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006644\n",
      "10875it [12:15,  7.83it/s]Train epoch: 1 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006770\n",
      "10900it [12:19,  7.87it/s]Train epoch: 1 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006448\n",
      "10925it [12:22,  7.87it/s]Train epoch: 1 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005989\n",
      "10950it [12:25,  7.97it/s]Train epoch: 1 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006538\n",
      "10975it [12:28,  7.70it/s]Train epoch: 1 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006292\n",
      "11000it [12:31,  8.02it/s]Train epoch: 1 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006334\n",
      "11025it [12:34,  7.97it/s]Train epoch: 1 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006479\n",
      "11050it [12:38,  8.08it/s]Train epoch: 1 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007289\n",
      "11075it [12:41,  7.76it/s]Train epoch: 1 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006782\n",
      "11100it [12:44,  7.71it/s]Train epoch: 1 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007456\n",
      "11125it [12:47,  8.07it/s]Train epoch: 1 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006976\n",
      "11150it [12:50,  7.86it/s]Train epoch: 1 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006724\n",
      "11175it [12:53,  7.85it/s]Train epoch: 1 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007808\n",
      "11200it [12:57,  7.82it/s]Train epoch: 1 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.007057\n",
      "11225it [13:00,  7.76it/s]Train epoch: 1 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.007050\n",
      "11250it [13:03,  7.69it/s]Train epoch: 1 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007519\n",
      "11275it [13:06,  7.86it/s]Train epoch: 1 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007282\n",
      "11300it [13:10,  7.83it/s]Train epoch: 1 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006646\n",
      "11325it [13:13,  7.91it/s]Train epoch: 1 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11350it [13:16,  7.91it/s]Train epoch: 1 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007700\n",
      "11375it [13:19,  7.81it/s]Train epoch: 1 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007913\n",
      "11400it [13:22,  7.82it/s]Train epoch: 1 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006918\n",
      "11425it [13:25,  7.82it/s]Train epoch: 1 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007704\n",
      "11450it [13:29,  7.82it/s]Train epoch: 1 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006767\n",
      "11475it [13:32,  7.89it/s]Train epoch: 1 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.008171\n",
      "11500it [13:35,  7.81it/s]Train epoch: 1 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007841\n",
      "11525it [13:38,  7.95it/s]Train epoch: 1 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007159\n",
      "11550it [13:41,  7.62it/s]Train epoch: 1 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007165\n",
      "11575it [13:45,  7.98it/s]Train epoch: 1 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008184\n",
      "11600it [13:48,  7.76it/s]Train epoch: 1 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007613\n",
      "11625it [13:51,  7.96it/s]Train epoch: 1 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007210\n",
      "11650it [13:54,  7.69it/s]Train epoch: 1 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007635\n",
      "11675it [13:57,  7.76it/s]Train epoch: 1 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.008192\n",
      "11700it [14:01,  7.79it/s]Train epoch: 1 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008732\n",
      "11725it [14:04,  7.61it/s]Train epoch: 1 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008613\n",
      "11750it [14:07,  7.84it/s]Train epoch: 1 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008344\n",
      "11775it [14:10,  7.66it/s]Train epoch: 1 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008481\n",
      "11800it [14:13,  7.82it/s]Train epoch: 1 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008215\n",
      "11825it [14:17,  8.06it/s]Train epoch: 1 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008507\n",
      "11850it [14:20,  7.80it/s]Train epoch: 1 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008807\n",
      "11875it [14:23,  7.92it/s]Train epoch: 1 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009716\n",
      "11900it [14:26,  7.68it/s]Train epoch: 1 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011692\n",
      "11925it [14:29,  7.68it/s]Train epoch: 1 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009827\n",
      "11930it [14:30, 13.70it/s]\n",
      "epoch loss: 0.004834026004518956\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 127.33it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0330, 0.0484, 0.0520, 0.0502, 0.8796\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3226, 0.5435, 0.4424, 0.4878, 0.9815\n",
      "rec_at_8: 0.3482\n",
      "prec_at_8: 0.6418\n",
      "rec_at_15: 0.4877\n",
      "prec_at_15: 0.5014\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 129.07it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0333, 0.0549, 0.0541, 0.0545, 0.8711\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3173, 0.5399, 0.4350, 0.4818, 0.9812\n",
      "rec_at_8: 0.3341\n",
      "prec_at_8: 0.6402\n",
      "rec_at_15: 0.4671\n",
      "prec_at_15: 0.5006\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 1\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0330, 0.0484, 0.0520, 0.0502, 0.8796\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3226, 0.5435, 0.4424, 0.4878, 0.9815\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 1\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0333, 0.0549, 0.0541, 0.0545, 0.8711\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3173, 0.5399, 0.4350, 0.4818, 0.9812\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "\n",
      "EPOCH 2\n",
      "0it [00:00, ?it/s]Train epoch: 2 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006159\n",
      "22it [00:00, 48.12it/s]Train epoch: 2 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003798\n",
      "46it [00:01, 43.30it/s]Train epoch: 2 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003543\n",
      "71it [00:01, 41.91it/s]Train epoch: 2 [batch #75, batch_size 4, seq length 307]\tLoss: 0.002960\n",
      "96it [00:02, 40.32it/s]Train epoch: 2 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003154\n",
      "123it [00:02, 39.74it/s]Train epoch: 2 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003101\n",
      "149it [00:03, 38.72it/s]Train epoch: 2 [batch #150, batch_size 4, seq length 370]\tLoss: 0.002961\n",
      "173it [00:04, 35.58it/s]Train epoch: 2 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003083\n",
      "198it [00:04, 37.20it/s]Train epoch: 2 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002907\n",
      "222it [00:05, 34.60it/s]Train epoch: 2 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003649\n",
      "250it [00:06, 32.72it/s]Train epoch: 2 [batch #250, batch_size 4, seq length 428]\tLoss: 0.002944\n",
      "274it [00:07, 34.59it/s]Train epoch: 2 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002510\n",
      "298it [00:07, 32.96it/s]Train epoch: 2 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003307\n",
      "322it [00:08, 32.23it/s]Train epoch: 2 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002703\n",
      "350it [00:09, 33.08it/s]Train epoch: 2 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003255\n",
      "374it [00:10, 30.65it/s]Train epoch: 2 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003032\n",
      "398it [00:11, 32.03it/s]Train epoch: 2 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003133\n",
      "422it [00:11, 31.55it/s]Train epoch: 2 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003085\n",
      "450it [00:12, 30.32it/s]Train epoch: 2 [batch #450, batch_size 4, seq length 504]\tLoss: 0.003008\n",
      "474it [00:13, 29.54it/s]Train epoch: 2 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003421\n",
      "498it [00:14, 30.41it/s]Train epoch: 2 [batch #500, batch_size 4, seq length 519]\tLoss: 0.002918\n",
      "522it [00:15, 29.87it/s]Train epoch: 2 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003186\n",
      "550it [00:16, 28.75it/s]Train epoch: 2 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003145\n",
      "573it [00:16, 29.50it/s]Train epoch: 2 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003057\n",
      "597it [00:17, 30.64it/s]Train epoch: 2 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003385\n",
      "625it [00:18, 29.69it/s]Train epoch: 2 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003322\n",
      "649it [00:19, 29.44it/s]Train epoch: 2 [batch #650, batch_size 4, seq length 559]\tLoss: 0.002916\n",
      "675it [00:20, 28.25it/s]Train epoch: 2 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002485\n",
      "698it [00:21, 29.20it/s]Train epoch: 2 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003034\n",
      "724it [00:21, 28.89it/s]Train epoch: 2 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003189\n",
      "750it [00:22, 30.73it/s]Train epoch: 2 [batch #750, batch_size 4, seq length 584]\tLoss: 0.002998\n",
      "774it [00:23, 28.59it/s]Train epoch: 2 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003351\n",
      "798it [00:24, 29.74it/s]Train epoch: 2 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003222\n",
      "824it [00:25, 28.53it/s]Train epoch: 2 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003157\n",
      "847it [00:26, 27.98it/s]Train epoch: 2 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003531\n",
      "875it [00:27, 30.05it/s]Train epoch: 2 [batch #875, batch_size 4, seq length 612]\tLoss: 0.002936\n",
      "899it [00:28, 28.94it/s]Train epoch: 2 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003333\n",
      "924it [00:28, 28.55it/s]Train epoch: 2 [batch #925, batch_size 4, seq length 622]\tLoss: 0.003069\n",
      "948it [00:29, 28.19it/s]Train epoch: 2 [batch #950, batch_size 4, seq length 627]\tLoss: 0.003039\n",
      "974it [00:30, 28.04it/s]Train epoch: 2 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002384\n",
      "1000it [00:31, 27.86it/s]Train epoch: 2 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003147\n",
      "1023it [00:32, 28.70it/s]Train epoch: 2 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004279\n",
      "1050it [00:33, 28.63it/s]Train epoch: 2 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.002992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1073it [00:34, 27.41it/s]Train epoch: 2 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003390\n",
      "1100it [00:35, 26.10it/s]Train epoch: 2 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003476\n",
      "1125it [00:36, 26.71it/s]Train epoch: 2 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003491\n",
      "1149it [00:37, 25.37it/s]Train epoch: 2 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003387\n",
      "1174it [00:37, 27.12it/s]Train epoch: 2 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003360\n",
      "1198it [00:38, 26.13it/s]Train epoch: 2 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003511\n",
      "1225it [00:39, 25.31it/s]Train epoch: 2 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003625\n",
      "1249it [00:40, 27.26it/s]Train epoch: 2 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003335\n",
      "1273it [00:41, 27.73it/s]Train epoch: 2 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.002914\n",
      "1300it [00:42, 26.74it/s]Train epoch: 2 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.002994\n",
      "1325it [00:43, 26.60it/s]Train epoch: 2 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.003067\n",
      "1349it [00:44, 25.43it/s]Train epoch: 2 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.004040\n",
      "1373it [00:45, 26.44it/s]Train epoch: 2 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003264\n",
      "1397it [00:46, 26.42it/s]Train epoch: 2 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003349\n",
      "1425it [00:47, 25.40it/s]Train epoch: 2 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.002945\n",
      "1449it [00:48, 26.54it/s]Train epoch: 2 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003154\n",
      "1473it [00:49, 26.70it/s]Train epoch: 2 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003325\n",
      "1500it [00:50, 25.30it/s]Train epoch: 2 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004499\n",
      "1524it [00:51, 24.96it/s]Train epoch: 2 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004155\n",
      "1548it [00:52, 25.08it/s]Train epoch: 2 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003111\n",
      "1575it [00:53, 25.74it/s]Train epoch: 2 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003455\n",
      "1599it [00:54, 26.53it/s]Train epoch: 2 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003081\n",
      "1623it [00:55, 25.87it/s]Train epoch: 2 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003725\n",
      "1650it [00:56, 25.51it/s]Train epoch: 2 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003756\n",
      "1675it [00:57, 25.57it/s]Train epoch: 2 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003655\n",
      "1699it [00:58, 24.59it/s]Train epoch: 2 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003081\n",
      "1723it [00:59, 25.66it/s]Train epoch: 2 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002721\n",
      "1750it [01:00, 24.81it/s]Train epoch: 2 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004069\n",
      "1774it [01:01, 24.52it/s]Train epoch: 2 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003385\n",
      "1798it [01:02, 23.17it/s]Train epoch: 2 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003420\n",
      "1825it [01:03, 24.80it/s]Train epoch: 2 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002815\n",
      "1849it [01:04, 25.47it/s]Train epoch: 2 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003507\n",
      "1873it [01:05, 25.01it/s]Train epoch: 2 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003766\n",
      "1900it [01:06, 24.67it/s]Train epoch: 2 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002732\n",
      "1924it [01:07, 26.67it/s]Train epoch: 2 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.002969\n",
      "1948it [01:08, 24.64it/s]Train epoch: 2 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.002950\n",
      "1975it [01:09, 25.40it/s]Train epoch: 2 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003550\n",
      "1999it [01:10, 26.04it/s]Train epoch: 2 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002785\n",
      "2023it [01:11, 23.15it/s]Train epoch: 2 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003402\n",
      "2050it [01:12, 23.46it/s]Train epoch: 2 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003166\n",
      "2074it [01:13, 24.08it/s]Train epoch: 2 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003344\n",
      "2098it [01:14, 22.73it/s]Train epoch: 2 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003510\n",
      "2125it [01:15, 24.26it/s]Train epoch: 2 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003769\n",
      "2149it [01:16, 24.66it/s]Train epoch: 2 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003221\n",
      "2173it [01:17, 23.74it/s]Train epoch: 2 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003647\n",
      "2200it [01:18, 23.15it/s]Train epoch: 2 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003499\n",
      "2224it [01:19, 22.62it/s]Train epoch: 2 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003366\n",
      "2248it [01:20, 23.88it/s]Train epoch: 2 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003118\n",
      "2275it [01:21, 24.29it/s]Train epoch: 2 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003487\n",
      "2299it [01:22, 23.04it/s]Train epoch: 2 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002575\n",
      "2323it [01:23, 23.51it/s]Train epoch: 2 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003334\n",
      "2350it [01:25, 22.52it/s]Train epoch: 2 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003071\n",
      "2374it [01:26, 22.52it/s]Train epoch: 2 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004404\n",
      "2398it [01:27, 23.69it/s]Train epoch: 2 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004128\n",
      "2425it [01:28, 24.07it/s]Train epoch: 2 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002817\n",
      "2449it [01:29, 22.70it/s]Train epoch: 2 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003294\n",
      "2473it [01:30, 21.81it/s]Train epoch: 2 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003739\n",
      "2500it [01:31, 21.60it/s]Train epoch: 2 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003237\n",
      "2524it [01:32, 22.61it/s]Train epoch: 2 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003159\n",
      "2548it [01:33, 22.81it/s]Train epoch: 2 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004474\n",
      "2575it [01:35, 22.07it/s]Train epoch: 2 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003133\n",
      "2599it [01:36, 22.32it/s]Train epoch: 2 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003399\n",
      "2623it [01:37, 22.73it/s]Train epoch: 2 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003388\n",
      "2650it [01:38, 24.05it/s]Train epoch: 2 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.003985\n",
      "2674it [01:39, 23.03it/s]Train epoch: 2 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003508\n",
      "2698it [01:40, 23.37it/s]Train epoch: 2 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003099\n",
      "2725it [01:41, 21.94it/s]Train epoch: 2 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003321\n",
      "2749it [01:42, 22.56it/s]Train epoch: 2 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.004001\n",
      "2773it [01:43, 21.93it/s]Train epoch: 2 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003501\n",
      "2800it [01:45, 22.29it/s]Train epoch: 2 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003226\n",
      "2824it [01:46, 22.15it/s]Train epoch: 2 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003708\n",
      "2848it [01:47, 21.93it/s]Train epoch: 2 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003460\n",
      "2875it [01:48, 21.06it/s]Train epoch: 2 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003816\n",
      "2899it [01:49, 20.70it/s]Train epoch: 2 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003626\n",
      "2923it [01:50, 21.98it/s]Train epoch: 2 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003804\n",
      "2950it [01:51, 21.77it/s]Train epoch: 2 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.003920\n",
      "2974it [01:53, 21.19it/s]Train epoch: 2 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003658\n",
      "2998it [01:54, 21.12it/s]Train epoch: 2 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004240\n",
      "3025it [01:55, 22.19it/s]Train epoch: 2 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003918\n",
      "3049it [01:56, 22.03it/s]Train epoch: 2 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003298\n",
      "3073it [01:57, 21.97it/s]Train epoch: 2 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003844\n",
      "3100it [01:58, 21.68it/s]Train epoch: 2 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003839\n",
      "3124it [02:00, 21.33it/s]Train epoch: 2 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3148it [02:01, 21.11it/s]Train epoch: 2 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003413\n",
      "3175it [02:02, 21.41it/s]Train epoch: 2 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003401\n",
      "3199it [02:03, 21.39it/s]Train epoch: 2 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.004014\n",
      "3223it [02:04, 21.44it/s]Train epoch: 2 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.003885\n",
      "3250it [02:05, 21.80it/s]Train epoch: 2 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.003914\n",
      "3274it [02:07, 20.80it/s]Train epoch: 2 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003431\n",
      "3298it [02:08, 21.04it/s]Train epoch: 2 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004380\n",
      "3325it [02:09, 20.76it/s]Train epoch: 2 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003660\n",
      "3349it [02:10, 21.51it/s]Train epoch: 2 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003688\n",
      "3373it [02:11, 20.86it/s]Train epoch: 2 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.003866\n",
      "3400it [02:13, 20.63it/s]Train epoch: 2 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.003939\n",
      "3424it [02:14, 20.17it/s]Train epoch: 2 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003492\n",
      "3448it [02:15, 21.33it/s]Train epoch: 2 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.003981\n",
      "3475it [02:16, 20.10it/s]Train epoch: 2 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003597\n",
      "3499it [02:17, 20.96it/s]Train epoch: 2 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003655\n",
      "3523it [02:18, 20.89it/s]Train epoch: 2 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003770\n",
      "3550it [02:20, 20.23it/s]Train epoch: 2 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.004060\n",
      "3574it [02:21, 21.10it/s]Train epoch: 2 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003224\n",
      "3598it [02:22, 21.57it/s]Train epoch: 2 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004251\n",
      "3625it [02:23, 21.62it/s]Train epoch: 2 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.003953\n",
      "3648it [02:24, 18.85it/s]Train epoch: 2 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.003962\n",
      "3674it [02:26, 18.97it/s]Train epoch: 2 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.004013\n",
      "3700it [02:27, 17.66it/s]Train epoch: 2 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.004015\n",
      "3724it [02:29, 17.81it/s]Train epoch: 2 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004126\n",
      "3750it [02:30, 18.08it/s]Train epoch: 2 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004084\n",
      "3775it [02:32, 18.35it/s]Train epoch: 2 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.003992\n",
      "3799it [02:33, 17.74it/s]Train epoch: 2 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004396\n",
      "3825it [02:34, 16.76it/s]Train epoch: 2 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003697\n",
      "3850it [02:36, 18.19it/s]Train epoch: 2 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003451\n",
      "3874it [02:37, 16.93it/s]Train epoch: 2 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003375\n",
      "3900it [02:39, 18.03it/s]Train epoch: 2 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004403\n",
      "3924it [02:40, 17.37it/s]Train epoch: 2 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.003999\n",
      "3949it [02:42, 17.88it/s]Train epoch: 2 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004335\n",
      "3975it [02:43, 17.31it/s]Train epoch: 2 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.004810\n",
      "3999it [02:44, 16.96it/s]Train epoch: 2 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003627\n",
      "4025it [02:46, 16.61it/s]Train epoch: 2 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004526\n",
      "4049it [02:47, 18.05it/s]Train epoch: 2 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004136\n",
      "4075it [02:49, 17.66it/s]Train epoch: 2 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004148\n",
      "4099it [02:50, 16.44it/s]Train epoch: 2 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004525\n",
      "4125it [02:52, 17.34it/s]Train epoch: 2 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004384\n",
      "4150it [02:53, 16.60it/s]Train epoch: 2 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003734\n",
      "4174it [02:55, 17.40it/s]Train epoch: 2 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.004015\n",
      "4200it [02:56, 17.07it/s]Train epoch: 2 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004343\n",
      "4224it [02:58, 17.28it/s]Train epoch: 2 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003694\n",
      "4250it [02:59, 16.23it/s]Train epoch: 2 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004283\n",
      "4274it [03:00, 17.05it/s]Train epoch: 2 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.003862\n",
      "4300it [03:02, 16.92it/s]Train epoch: 2 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004626\n",
      "4324it [03:03, 16.86it/s]Train epoch: 2 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.004041\n",
      "4350it [03:05, 17.69it/s]Train epoch: 2 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004404\n",
      "4374it [03:06, 16.68it/s]Train epoch: 2 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.003931\n",
      "4400it [03:08, 16.54it/s]Train epoch: 2 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003395\n",
      "4424it [03:09, 16.76it/s]Train epoch: 2 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004233\n",
      "4450it [03:11, 16.69it/s]Train epoch: 2 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003417\n",
      "4474it [03:12, 16.88it/s]Train epoch: 2 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004359\n",
      "4500it [03:14, 16.55it/s]Train epoch: 2 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.004920\n",
      "4524it [03:15, 16.69it/s]Train epoch: 2 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004278\n",
      "4550it [03:17, 16.99it/s]Train epoch: 2 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.004035\n",
      "4574it [03:18, 16.64it/s]Train epoch: 2 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004539\n",
      "4600it [03:20, 16.35it/s]Train epoch: 2 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.003812\n",
      "4624it [03:21, 15.58it/s]Train epoch: 2 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.003867\n",
      "4650it [03:23, 15.74it/s]Train epoch: 2 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004511\n",
      "4674it [03:25, 15.72it/s]Train epoch: 2 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004330\n",
      "4700it [03:26, 15.15it/s]Train epoch: 2 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003788\n",
      "4724it [03:28, 15.63it/s]Train epoch: 2 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.004007\n",
      "4750it [03:29, 15.30it/s]Train epoch: 2 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004693\n",
      "4774it [03:31, 15.43it/s]Train epoch: 2 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004134\n",
      "4800it [03:33, 14.98it/s]Train epoch: 2 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004332\n",
      "4824it [03:34, 16.03it/s]Train epoch: 2 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003750\n",
      "4850it [03:36, 15.54it/s]Train epoch: 2 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004425\n",
      "4874it [03:37, 15.96it/s]Train epoch: 2 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003837\n",
      "4900it [03:39, 15.42it/s]Train epoch: 2 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004113\n",
      "4924it [03:41, 15.53it/s]Train epoch: 2 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003798\n",
      "4950it [03:42, 15.78it/s]Train epoch: 2 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004100\n",
      "4974it [03:44, 15.34it/s]Train epoch: 2 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004237\n",
      "5000it [03:45, 15.58it/s]Train epoch: 2 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004050\n",
      "5024it [03:47, 15.33it/s]Train epoch: 2 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.003908\n",
      "5050it [03:49, 15.28it/s]Train epoch: 2 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.003868\n",
      "5074it [03:50, 15.17it/s]Train epoch: 2 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004141\n",
      "5100it [03:52, 14.27it/s]Train epoch: 2 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004266\n",
      "5124it [03:54, 15.26it/s]Train epoch: 2 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004458\n",
      "5150it [03:55, 15.11it/s]Train epoch: 2 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004440\n",
      "5174it [03:57, 15.30it/s]Train epoch: 2 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200it [03:59, 15.44it/s]Train epoch: 2 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.003935\n",
      "5224it [04:00, 15.25it/s]Train epoch: 2 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004195\n",
      "5250it [04:02, 15.10it/s]Train epoch: 2 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004132\n",
      "5274it [04:04, 14.87it/s]Train epoch: 2 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.004014\n",
      "5300it [04:05, 14.98it/s]Train epoch: 2 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.003867\n",
      "5324it [04:07, 14.92it/s]Train epoch: 2 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004356\n",
      "5350it [04:09, 14.98it/s]Train epoch: 2 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004427\n",
      "5374it [04:10, 15.25it/s]Train epoch: 2 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004087\n",
      "5400it [04:12, 15.41it/s]Train epoch: 2 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.004057\n",
      "5424it [04:13, 15.42it/s]Train epoch: 2 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004436\n",
      "5450it [04:15, 15.19it/s]Train epoch: 2 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004301\n",
      "5474it [04:17, 14.82it/s]Train epoch: 2 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.004908\n",
      "5500it [04:19, 15.24it/s]Train epoch: 2 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004556\n",
      "5524it [04:20, 15.93it/s]Train epoch: 2 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003796\n",
      "5550it [04:22, 14.77it/s]Train epoch: 2 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004297\n",
      "5574it [04:23, 15.39it/s]Train epoch: 2 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004370\n",
      "5600it [04:25, 15.08it/s]Train epoch: 2 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004739\n",
      "5624it [04:27, 15.49it/s]Train epoch: 2 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004322\n",
      "5650it [04:29, 14.56it/s]Train epoch: 2 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.004001\n",
      "5674it [04:30, 15.15it/s]Train epoch: 2 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.004840\n",
      "5700it [04:32, 15.04it/s]Train epoch: 2 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004244\n",
      "5724it [04:33, 15.44it/s]Train epoch: 2 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004324\n",
      "5750it [04:35, 14.51it/s]Train epoch: 2 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005445\n",
      "5774it [04:37, 15.06it/s]Train epoch: 2 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004573\n",
      "5800it [04:39, 14.43it/s]Train epoch: 2 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004538\n",
      "5824it [04:40, 14.87it/s]Train epoch: 2 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004161\n",
      "5850it [04:42, 14.69it/s]Train epoch: 2 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005218\n",
      "5874it [04:44, 14.37it/s]Train epoch: 2 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.005024\n",
      "5900it [04:45, 14.64it/s]Train epoch: 2 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.004998\n",
      "5924it [04:47, 14.92it/s]Train epoch: 2 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004137\n",
      "5950it [04:49, 14.57it/s]Train epoch: 2 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004073\n",
      "5974it [04:50, 14.89it/s]Train epoch: 2 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005491\n",
      "6000it [04:52, 14.36it/s]Train epoch: 2 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004644\n",
      "6024it [04:54, 15.17it/s]Train epoch: 2 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.004847\n",
      "6050it [04:56, 14.48it/s]Train epoch: 2 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004312\n",
      "6074it [04:57, 14.66it/s]Train epoch: 2 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.004050\n",
      "6100it [04:59, 14.91it/s]Train epoch: 2 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.004001\n",
      "6124it [05:01, 14.64it/s]Train epoch: 2 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004441\n",
      "6150it [05:03, 13.91it/s]Train epoch: 2 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004383\n",
      "6174it [05:04, 13.99it/s]Train epoch: 2 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.004984\n",
      "6200it [05:06, 14.93it/s]Train epoch: 2 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004358\n",
      "6224it [05:08, 13.97it/s]Train epoch: 2 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003888\n",
      "6250it [05:10, 14.32it/s]Train epoch: 2 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004204\n",
      "6274it [05:11, 14.30it/s]Train epoch: 2 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003776\n",
      "6300it [05:13, 14.54it/s]Train epoch: 2 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004384\n",
      "6324it [05:15, 13.70it/s]Train epoch: 2 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.004912\n",
      "6350it [05:17, 14.48it/s]Train epoch: 2 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005157\n",
      "6374it [05:18, 14.10it/s]Train epoch: 2 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.004009\n",
      "6400it [05:20, 14.13it/s]Train epoch: 2 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004316\n",
      "6424it [05:22, 14.30it/s]Train epoch: 2 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.004857\n",
      "6450it [05:24, 14.01it/s]Train epoch: 2 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004852\n",
      "6474it [05:25, 14.05it/s]Train epoch: 2 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004238\n",
      "6500it [05:27, 13.79it/s]Train epoch: 2 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004791\n",
      "6524it [05:29, 13.15it/s]Train epoch: 2 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004130\n",
      "6550it [05:31, 13.83it/s]Train epoch: 2 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004302\n",
      "6574it [05:33, 13.39it/s]Train epoch: 2 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004467\n",
      "6600it [05:35, 13.67it/s]Train epoch: 2 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005434\n",
      "6624it [05:36, 13.99it/s]Train epoch: 2 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004392\n",
      "6650it [05:38, 13.52it/s]Train epoch: 2 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.004946\n",
      "6674it [05:40, 13.56it/s]Train epoch: 2 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004541\n",
      "6700it [05:42, 13.41it/s]Train epoch: 2 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004692\n",
      "6724it [05:44, 13.43it/s]Train epoch: 2 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004659\n",
      "6750it [05:46, 13.83it/s]Train epoch: 2 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004199\n",
      "6774it [05:47, 13.26it/s]Train epoch: 2 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.004865\n",
      "6800it [05:49, 13.29it/s]Train epoch: 2 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.004894\n",
      "6824it [05:51, 13.50it/s]Train epoch: 2 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.005020\n",
      "6850it [05:53, 13.16it/s]Train epoch: 2 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.004795\n",
      "6874it [05:55, 13.31it/s]Train epoch: 2 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.003980\n",
      "6900it [05:57, 13.44it/s]Train epoch: 2 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004572\n",
      "6924it [05:59, 13.43it/s]Train epoch: 2 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004689\n",
      "6950it [06:00, 13.44it/s]Train epoch: 2 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005130\n",
      "6974it [06:02, 12.91it/s]Train epoch: 2 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004867\n",
      "7000it [06:04, 13.30it/s]Train epoch: 2 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004552\n",
      "7024it [06:06, 13.05it/s]Train epoch: 2 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005237\n",
      "7050it [06:08, 13.38it/s]Train epoch: 2 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004169\n",
      "7074it [06:10, 13.35it/s]Train epoch: 2 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004515\n",
      "7100it [06:12, 13.12it/s]Train epoch: 2 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.004885\n",
      "7124it [06:14, 12.69it/s]Train epoch: 2 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004319\n",
      "7150it [06:16, 12.97it/s]Train epoch: 2 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005150\n",
      "7174it [06:17, 13.04it/s]Train epoch: 2 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004711\n",
      "7200it [06:19, 12.90it/s]Train epoch: 2 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005153\n",
      "7224it [06:21, 13.21it/s]Train epoch: 2 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7250it [06:23, 13.06it/s]Train epoch: 2 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004678\n",
      "7274it [06:25, 13.40it/s]Train epoch: 2 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005181\n",
      "7300it [06:27, 12.77it/s]Train epoch: 2 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005534\n",
      "7324it [06:29, 12.79it/s]Train epoch: 2 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004407\n",
      "7350it [06:31, 12.70it/s]Train epoch: 2 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005465\n",
      "7374it [06:33, 12.77it/s]Train epoch: 2 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.005050\n",
      "7400it [06:35, 12.79it/s]Train epoch: 2 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004481\n",
      "7424it [06:37, 12.93it/s]Train epoch: 2 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.004930\n",
      "7450it [06:39, 12.72it/s]Train epoch: 2 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005423\n",
      "7474it [06:41, 12.70it/s]Train epoch: 2 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004726\n",
      "7500it [06:43, 12.69it/s]Train epoch: 2 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.005034\n",
      "7524it [06:45, 12.61it/s]Train epoch: 2 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004726\n",
      "7550it [06:47, 12.42it/s]Train epoch: 2 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004653\n",
      "7574it [06:49, 12.49it/s]Train epoch: 2 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005156\n",
      "7600it [06:51, 12.50it/s]Train epoch: 2 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.006051\n",
      "7624it [06:53, 12.55it/s]Train epoch: 2 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005582\n",
      "7650it [06:55, 12.55it/s]Train epoch: 2 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004815\n",
      "7674it [06:57, 12.68it/s]Train epoch: 2 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.004804\n",
      "7700it [06:59, 12.57it/s]Train epoch: 2 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.004944\n",
      "7724it [07:01, 12.24it/s]Train epoch: 2 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.004886\n",
      "7750it [07:03, 12.50it/s]Train epoch: 2 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005261\n",
      "7774it [07:05, 12.43it/s]Train epoch: 2 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004555\n",
      "7800it [07:07, 12.82it/s]Train epoch: 2 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004770\n",
      "7824it [07:09, 12.71it/s]Train epoch: 2 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.005021\n",
      "7850it [07:11, 12.40it/s]Train epoch: 2 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004515\n",
      "7874it [07:13, 12.58it/s]Train epoch: 2 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004813\n",
      "7900it [07:15, 12.43it/s]Train epoch: 2 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.004956\n",
      "7924it [07:17, 12.22it/s]Train epoch: 2 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.004961\n",
      "7950it [07:19, 12.00it/s]Train epoch: 2 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005636\n",
      "7974it [07:21, 12.02it/s]Train epoch: 2 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004768\n",
      "8000it [07:23, 12.16it/s]Train epoch: 2 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004654\n",
      "8024it [07:25, 12.37it/s]Train epoch: 2 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.005065\n",
      "8050it [07:27, 11.75it/s]Train epoch: 2 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004430\n",
      "8074it [07:29, 11.74it/s]Train epoch: 2 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.004964\n",
      "8100it [07:31, 12.10it/s]Train epoch: 2 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005299\n",
      "8124it [07:33, 11.84it/s]Train epoch: 2 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005419\n",
      "8150it [07:35, 11.65it/s]Train epoch: 2 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004696\n",
      "8174it [07:37, 11.68it/s]Train epoch: 2 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005377\n",
      "8200it [07:40, 11.73it/s]Train epoch: 2 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004592\n",
      "8224it [07:42, 12.17it/s]Train epoch: 2 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006168\n",
      "8250it [07:44, 12.03it/s]Train epoch: 2 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004748\n",
      "8274it [07:46, 11.76it/s]Train epoch: 2 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005367\n",
      "8300it [07:48, 11.85it/s]Train epoch: 2 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004756\n",
      "8324it [07:50, 11.50it/s]Train epoch: 2 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005428\n",
      "8350it [07:52, 11.75it/s]Train epoch: 2 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004657\n",
      "8374it [07:54, 11.70it/s]Train epoch: 2 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005442\n",
      "8400it [07:57, 11.41it/s]Train epoch: 2 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.005009\n",
      "8424it [07:59, 11.52it/s]Train epoch: 2 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.005014\n",
      "8450it [08:01, 11.38it/s]Train epoch: 2 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005355\n",
      "8474it [08:03, 11.26it/s]Train epoch: 2 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005062\n",
      "8500it [08:05, 11.60it/s]Train epoch: 2 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.005910\n",
      "8524it [08:07, 11.61it/s]Train epoch: 2 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005128\n",
      "8550it [08:10, 11.05it/s]Train epoch: 2 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005309\n",
      "8574it [08:12, 11.51it/s]Train epoch: 2 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.004950\n",
      "8600it [08:14, 11.52it/s]Train epoch: 2 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.005080\n",
      "8624it [08:16, 11.33it/s]Train epoch: 2 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005188\n",
      "8650it [08:18, 11.60it/s]Train epoch: 2 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005373\n",
      "8674it [08:21, 11.56it/s]Train epoch: 2 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.006054\n",
      "8700it [08:23, 11.50it/s]Train epoch: 2 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.005989\n",
      "8724it [08:25, 11.18it/s]Train epoch: 2 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005800\n",
      "8750it [08:27, 11.26it/s]Train epoch: 2 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005469\n",
      "8774it [08:29, 11.17it/s]Train epoch: 2 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.004936\n",
      "8800it [08:32, 11.32it/s]Train epoch: 2 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005272\n",
      "8824it [08:34, 11.25it/s]Train epoch: 2 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005246\n",
      "8850it [08:36, 11.04it/s]Train epoch: 2 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005373\n",
      "8874it [08:38, 11.07it/s]Train epoch: 2 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005227\n",
      "8900it [08:41, 10.96it/s]Train epoch: 2 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005347\n",
      "8924it [08:43, 11.01it/s]Train epoch: 2 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005444\n",
      "8950it [08:45, 11.46it/s]Train epoch: 2 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006078\n",
      "8974it [08:48, 10.53it/s]Train epoch: 2 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005643\n",
      "9000it [08:50, 10.77it/s]Train epoch: 2 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005224\n",
      "9024it [08:52, 10.81it/s]Train epoch: 2 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005461\n",
      "9050it [08:55, 10.78it/s]Train epoch: 2 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.004953\n",
      "9074it [08:57, 10.94it/s]Train epoch: 2 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004746\n",
      "9100it [08:59, 10.93it/s]Train epoch: 2 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005603\n",
      "9124it [09:01, 10.81it/s]Train epoch: 2 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005135\n",
      "9150it [09:04, 10.90it/s]Train epoch: 2 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004706\n",
      "9174it [09:06, 10.64it/s]Train epoch: 2 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.005113\n",
      "9200it [09:09, 10.46it/s]Train epoch: 2 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.004921\n",
      "9224it [09:11, 10.65it/s]Train epoch: 2 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.006033\n",
      "9250it [09:13, 10.17it/s]Train epoch: 2 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005219\n",
      "9274it [09:16, 10.63it/s]Train epoch: 2 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9300it [09:18, 10.45it/s]Train epoch: 2 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006231\n",
      "9324it [09:20, 10.32it/s]Train epoch: 2 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.006060\n",
      "9350it [09:23, 10.54it/s]Train epoch: 2 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.006003\n",
      "9374it [09:25, 10.82it/s]Train epoch: 2 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005260\n",
      "9400it [09:28, 10.34it/s]Train epoch: 2 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005608\n",
      "9424it [09:30, 10.39it/s]Train epoch: 2 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005411\n",
      "9450it [09:32, 10.03it/s]Train epoch: 2 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005336\n",
      "9474it [09:35, 10.23it/s]Train epoch: 2 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.005967\n",
      "9500it [09:37, 10.21it/s]Train epoch: 2 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005565\n",
      "9524it [09:40, 10.12it/s]Train epoch: 2 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.006010\n",
      "9550it [09:42, 10.07it/s]Train epoch: 2 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.005813\n",
      "9575it [09:45,  9.97it/s]Train epoch: 2 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.006019\n",
      "9599it [09:47, 10.23it/s]Train epoch: 2 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005768\n",
      "9625it [09:50, 10.15it/s]Train epoch: 2 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005267\n",
      "9649it [09:52, 10.29it/s]Train epoch: 2 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005335\n",
      "9675it [09:55, 10.09it/s]Train epoch: 2 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005644\n",
      "9700it [09:57,  9.96it/s]Train epoch: 2 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.005024\n",
      "9725it [10:00,  9.94it/s]Train epoch: 2 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005542\n",
      "9750it [10:02,  9.38it/s]Train epoch: 2 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005631\n",
      "9775it [10:05,  9.75it/s]Train epoch: 2 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006375\n",
      "9799it [10:07,  9.40it/s]Train epoch: 2 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.006012\n",
      "9825it [10:10,  9.64it/s]Train epoch: 2 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006211\n",
      "9849it [10:12,  9.55it/s]Train epoch: 2 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005634\n",
      "9875it [10:15,  9.66it/s]Train epoch: 2 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.006000\n",
      "9900it [10:18,  9.75it/s]Train epoch: 2 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006346\n",
      "9925it [10:20,  9.28it/s]Train epoch: 2 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.006006\n",
      "9950it [10:23,  9.47it/s]Train epoch: 2 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006660\n",
      "9975it [10:25,  9.51it/s]Train epoch: 2 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.006136\n",
      "10000it [10:28,  9.64it/s]Train epoch: 2 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005666\n",
      "10025it [10:31,  9.07it/s]Train epoch: 2 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005557\n",
      "10050it [10:33,  9.26it/s]Train epoch: 2 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.006088\n",
      "10075it [10:36,  9.22it/s]Train epoch: 2 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006639\n",
      "10100it [10:39,  9.31it/s]Train epoch: 2 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006270\n",
      "10125it [10:41,  9.02it/s]Train epoch: 2 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005716\n",
      "10150it [10:44,  9.40it/s]Train epoch: 2 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006128\n",
      "10175it [10:47,  9.13it/s]Train epoch: 2 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005712\n",
      "10200it [10:50,  9.13it/s]Train epoch: 2 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006209\n",
      "10225it [10:52,  8.96it/s]Train epoch: 2 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006265\n",
      "10250it [10:55,  9.09it/s]Train epoch: 2 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006741\n",
      "10275it [10:58,  8.99it/s]Train epoch: 2 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.005918\n",
      "10300it [11:01,  9.14it/s]Train epoch: 2 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006601\n",
      "10325it [11:03,  8.95it/s]Train epoch: 2 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006352\n",
      "10350it [11:06,  8.96it/s]Train epoch: 2 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.005956\n",
      "10375it [11:09,  9.10it/s]Train epoch: 2 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006303\n",
      "10400it [11:12,  9.05it/s]Train epoch: 2 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006306\n",
      "10425it [11:15,  8.55it/s]Train epoch: 2 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.005930\n",
      "10450it [11:17,  8.55it/s]Train epoch: 2 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006336\n",
      "10475it [11:20,  8.70it/s]Train epoch: 2 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005529\n",
      "10500it [11:23,  8.60it/s]Train epoch: 2 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006362\n",
      "10525it [11:26,  8.61it/s]Train epoch: 2 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.006054\n",
      "10550it [11:29,  8.53it/s]Train epoch: 2 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006301\n",
      "10575it [11:32,  8.45it/s]Train epoch: 2 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005623\n",
      "10600it [11:35,  8.39it/s]Train epoch: 2 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.005847\n",
      "10625it [11:38,  8.34it/s]Train epoch: 2 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006587\n",
      "10650it [11:41,  8.36it/s]Train epoch: 2 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.005948\n",
      "10675it [11:44,  8.34it/s]Train epoch: 2 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006360\n",
      "10700it [11:47,  8.51it/s]Train epoch: 2 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.005978\n",
      "10725it [11:50,  8.05it/s]Train epoch: 2 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005626\n",
      "10750it [11:53,  8.25it/s]Train epoch: 2 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006540\n",
      "10775it [11:56,  7.88it/s]Train epoch: 2 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006522\n",
      "10800it [11:59,  7.90it/s]Train epoch: 2 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006762\n",
      "10825it [12:02,  7.84it/s]Train epoch: 2 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006646\n",
      "10850it [12:06,  7.82it/s]Train epoch: 2 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006484\n",
      "10875it [12:09,  7.93it/s]Train epoch: 2 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006634\n",
      "10900it [12:12,  7.94it/s]Train epoch: 2 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006402\n",
      "10925it [12:15,  7.87it/s]Train epoch: 2 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005837\n",
      "10950it [12:18,  7.91it/s]Train epoch: 2 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006402\n",
      "10975it [12:21,  7.83it/s]Train epoch: 2 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006186\n",
      "11000it [12:24,  7.88it/s]Train epoch: 2 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006184\n",
      "11025it [12:28,  7.80it/s]Train epoch: 2 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006364\n",
      "11050it [12:31,  8.23it/s]Train epoch: 2 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007142\n",
      "11075it [12:34,  7.96it/s]Train epoch: 2 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006652\n",
      "11100it [12:37,  7.93it/s]Train epoch: 2 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007319\n",
      "11125it [12:40,  7.88it/s]Train epoch: 2 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006807\n",
      "11150it [12:43,  7.85it/s]Train epoch: 2 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006590\n",
      "11175it [12:47,  8.03it/s]Train epoch: 2 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007616\n",
      "11200it [12:50,  7.88it/s]Train epoch: 2 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006883\n",
      "11225it [12:53,  8.05it/s]Train epoch: 2 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006869\n",
      "11250it [12:56,  7.98it/s]Train epoch: 2 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007418\n",
      "11275it [12:59,  7.75it/s]Train epoch: 2 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007204\n",
      "11300it [13:02,  7.96it/s]Train epoch: 2 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11325it [13:05,  8.04it/s]Train epoch: 2 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007645\n",
      "11350it [13:09,  8.07it/s]Train epoch: 2 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007505\n",
      "11375it [13:12,  7.91it/s]Train epoch: 2 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007736\n",
      "11400it [13:15,  7.93it/s]Train epoch: 2 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006760\n",
      "11425it [13:18,  7.81it/s]Train epoch: 2 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007548\n",
      "11450it [13:21,  8.03it/s]Train epoch: 2 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006619\n",
      "11475it [13:24,  7.94it/s]Train epoch: 2 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007954\n",
      "11500it [13:27,  7.84it/s]Train epoch: 2 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007690\n",
      "11525it [13:31,  7.98it/s]Train epoch: 2 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.007055\n",
      "11550it [13:34,  7.71it/s]Train epoch: 2 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.007045\n",
      "11575it [13:37,  7.93it/s]Train epoch: 2 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.008080\n",
      "11600it [13:40,  8.02it/s]Train epoch: 2 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007516\n",
      "11625it [13:43,  8.01it/s]Train epoch: 2 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.007071\n",
      "11650it [13:46,  7.91it/s]Train epoch: 2 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007506\n",
      "11675it [13:50,  8.08it/s]Train epoch: 2 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007996\n",
      "11700it [13:53,  7.86it/s]Train epoch: 2 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008577\n",
      "11725it [13:56,  7.76it/s]Train epoch: 2 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008465\n",
      "11750it [13:59,  7.91it/s]Train epoch: 2 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008210\n",
      "11775it [14:02,  7.78it/s]Train epoch: 2 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008293\n",
      "11800it [14:05,  7.94it/s]Train epoch: 2 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.008047\n",
      "11825it [14:09,  7.76it/s]Train epoch: 2 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008315\n",
      "11850it [14:12,  7.67it/s]Train epoch: 2 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008694\n",
      "11875it [14:15,  8.02it/s]Train epoch: 2 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009537\n",
      "11900it [14:18,  8.01it/s]Train epoch: 2 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011608\n",
      "11925it [14:21,  7.86it/s]Train epoch: 2 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009697\n",
      "11930it [14:22, 13.83it/s]\n",
      "epoch loss: 0.004733961637689844\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 129.70it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0346, 0.0510, 0.0555, 0.0531, 0.8799\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3234, 0.5359, 0.4493, 0.4888, 0.9816\n",
      "rec_at_8: 0.3496\n",
      "prec_at_8: 0.6441\n",
      "rec_at_15: 0.4880\n",
      "prec_at_15: 0.5009\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 131.50it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0353, 0.0572, 0.0579, 0.0575, 0.8711\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3197, 0.5327, 0.4442, 0.4845, 0.9813\n",
      "rec_at_8: 0.3353\n",
      "prec_at_8: 0.6414\n",
      "rec_at_15: 0.4687\n",
      "prec_at_15: 0.5011\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 2\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0346, 0.0510, 0.0555, 0.0531, 0.8799\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3234, 0.5359, 0.4493, 0.4888, 0.9816\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0069\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 2\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0353, 0.0572, 0.0579, 0.0575, 0.8711\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3197, 0.5327, 0.4442, 0.4845, 0.9813\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0071\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "\n",
      "EPOCH 3\n",
      "0it [00:00, ?it/s]Train epoch: 3 [batch #0, batch_size 4, seq length 68]\tLoss: 0.005747\n",
      "23it [00:00, 40.74it/s]Train epoch: 3 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003824\n",
      "48it [00:01, 44.40it/s]Train epoch: 3 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003561\n",
      "73it [00:01, 42.41it/s]Train epoch: 3 [batch #75, batch_size 4, seq length 307]\tLoss: 0.002884\n",
      "98it [00:02, 41.09it/s]Train epoch: 3 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003065\n",
      "123it [00:02, 38.42it/s]Train epoch: 3 [batch #125, batch_size 4, seq length 354]\tLoss: 0.003018\n",
      "147it [00:03, 37.41it/s]Train epoch: 3 [batch #150, batch_size 4, seq length 370]\tLoss: 0.002855\n",
      "175it [00:04, 35.74it/s]Train epoch: 3 [batch #175, batch_size 4, seq length 386]\tLoss: 0.003046\n",
      "197it [00:04, 37.35it/s]Train epoch: 3 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002905\n",
      "221it [00:05, 37.79it/s]Train epoch: 3 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003592\n",
      "247it [00:06, 36.14it/s]Train epoch: 3 [batch #250, batch_size 4, seq length 428]\tLoss: 0.002889\n",
      "275it [00:07, 34.16it/s]Train epoch: 3 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002491\n",
      "299it [00:07, 31.50it/s]Train epoch: 3 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003246\n",
      "323it [00:08, 32.10it/s]Train epoch: 3 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002662\n",
      "347it [00:09, 32.25it/s]Train epoch: 3 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003210\n",
      "375it [00:10, 34.12it/s]Train epoch: 3 [batch #375, batch_size 4, seq length 480]\tLoss: 0.003024\n",
      "399it [00:10, 31.00it/s]Train epoch: 3 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003106\n",
      "423it [00:11, 31.75it/s]Train epoch: 3 [batch #425, batch_size 4, seq length 497]\tLoss: 0.003035\n",
      "447it [00:12, 30.69it/s]Train epoch: 3 [batch #450, batch_size 4, seq length 504]\tLoss: 0.002984\n",
      "475it [00:13, 32.15it/s]Train epoch: 3 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003358\n",
      "499it [00:14, 33.18it/s]Train epoch: 3 [batch #500, batch_size 4, seq length 519]\tLoss: 0.002861\n",
      "523it [00:14, 30.80it/s]Train epoch: 3 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003133\n",
      "547it [00:15, 30.93it/s]Train epoch: 3 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003054\n",
      "575it [00:16, 30.69it/s]Train epoch: 3 [batch #575, batch_size 4, seq length 541]\tLoss: 0.003027\n",
      "597it [00:17, 30.52it/s]Train epoch: 3 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003313\n",
      "624it [00:18, 29.97it/s]Train epoch: 3 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003248\n",
      "648it [00:19, 29.48it/s]Train epoch: 3 [batch #650, batch_size 4, seq length 559]\tLoss: 0.002912\n",
      "674it [00:19, 31.14it/s]Train epoch: 3 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002436\n",
      "698it [00:20, 29.33it/s]Train epoch: 3 [batch #700, batch_size 4, seq length 573]\tLoss: 0.003015\n",
      "724it [00:21, 28.26it/s]Train epoch: 3 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003157\n",
      "749it [00:22, 28.71it/s]Train epoch: 3 [batch #750, batch_size 4, seq length 584]\tLoss: 0.002942\n",
      "773it [00:23, 27.64it/s]Train epoch: 3 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003290\n",
      "799it [00:24, 27.39it/s]Train epoch: 3 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003143\n",
      "822it [00:25, 29.13it/s]Train epoch: 3 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003103\n",
      "850it [00:26, 28.32it/s]Train epoch: 3 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003486\n",
      "874it [00:26, 30.25it/s]Train epoch: 3 [batch #875, batch_size 4, seq length 612]\tLoss: 0.002876\n",
      "898it [00:27, 29.94it/s]Train epoch: 3 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003240\n",
      "925it [00:28, 27.32it/s]Train epoch: 3 [batch #925, batch_size 4, seq length 622]\tLoss: 0.002965\n",
      "949it [00:29, 29.08it/s]Train epoch: 3 [batch #950, batch_size 4, seq length 627]\tLoss: 0.002998\n",
      "973it [00:30, 26.66it/s]Train epoch: 3 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002344\n",
      "999it [00:31, 27.94it/s]Train epoch: 3 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003155\n",
      "1025it [00:32, 28.18it/s]Train epoch: 3 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049it [00:33, 27.06it/s]Train epoch: 3 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.002956\n",
      "1073it [00:33, 26.14it/s]Train epoch: 3 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003330\n",
      "1099it [00:34, 27.38it/s]Train epoch: 3 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003420\n",
      "1125it [00:35, 28.49it/s]Train epoch: 3 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003414\n",
      "1150it [00:36, 27.84it/s]Train epoch: 3 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003368\n",
      "1174it [00:37, 26.29it/s]Train epoch: 3 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003253\n",
      "1198it [00:38, 25.84it/s]Train epoch: 3 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003471\n",
      "1223it [00:39, 26.90it/s]Train epoch: 3 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003513\n",
      "1250it [00:40, 27.83it/s]Train epoch: 3 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003355\n",
      "1274it [00:41, 26.28it/s]Train epoch: 3 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.002882\n",
      "1298it [00:42, 27.55it/s]Train epoch: 3 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.002924\n",
      "1323it [00:43, 27.58it/s]Train epoch: 3 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.002977\n",
      "1349it [00:44, 27.39it/s]Train epoch: 3 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.003951\n",
      "1373it [00:45, 26.47it/s]Train epoch: 3 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003244\n",
      "1397it [00:45, 25.75it/s]Train epoch: 3 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003195\n",
      "1425it [00:46, 27.17it/s]Train epoch: 3 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.002862\n",
      "1449it [00:47, 26.02it/s]Train epoch: 3 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003083\n",
      "1473it [00:48, 26.71it/s]Train epoch: 3 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003301\n",
      "1500it [00:49, 26.50it/s]Train epoch: 3 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004420\n",
      "1525it [00:50, 24.96it/s]Train epoch: 3 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.004098\n",
      "1549it [00:51, 26.95it/s]Train epoch: 3 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003064\n",
      "1573it [00:52, 24.44it/s]Train epoch: 3 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003429\n",
      "1600it [00:53, 23.38it/s]Train epoch: 3 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.003034\n",
      "1624it [00:54, 26.44it/s]Train epoch: 3 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003602\n",
      "1648it [00:55, 23.95it/s]Train epoch: 3 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003664\n",
      "1675it [00:56, 25.06it/s]Train epoch: 3 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003596\n",
      "1699it [00:57, 24.74it/s]Train epoch: 3 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.003042\n",
      "1723it [00:58, 25.69it/s]Train epoch: 3 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002623\n",
      "1750it [00:59, 26.43it/s]Train epoch: 3 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.004002\n",
      "1774it [01:00, 26.03it/s]Train epoch: 3 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003367\n",
      "1799it [01:01, 24.61it/s]Train epoch: 3 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003341\n",
      "1823it [01:02, 25.03it/s]Train epoch: 3 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002724\n",
      "1850it [01:03, 24.73it/s]Train epoch: 3 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003404\n",
      "1874it [01:04, 23.99it/s]Train epoch: 3 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003683\n",
      "1898it [01:05, 25.26it/s]Train epoch: 3 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002672\n",
      "1925it [01:06, 25.01it/s]Train epoch: 3 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.002911\n",
      "1949it [01:07, 23.48it/s]Train epoch: 3 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.002844\n",
      "1973it [01:08, 24.80it/s]Train epoch: 3 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003549\n",
      "2000it [01:09, 25.24it/s]Train epoch: 3 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002737\n",
      "2024it [01:10, 24.75it/s]Train epoch: 3 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003361\n",
      "2048it [01:11, 23.31it/s]Train epoch: 3 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003107\n",
      "2075it [01:12, 24.20it/s]Train epoch: 3 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003284\n",
      "2099it [01:13, 23.15it/s]Train epoch: 3 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003408\n",
      "2123it [01:14, 23.87it/s]Train epoch: 3 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003706\n",
      "2150it [01:15, 24.31it/s]Train epoch: 3 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003178\n",
      "2174it [01:16, 23.71it/s]Train epoch: 3 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003538\n",
      "2198it [01:17, 23.58it/s]Train epoch: 3 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003450\n",
      "2225it [01:18, 22.82it/s]Train epoch: 3 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003328\n",
      "2249it [01:20, 22.42it/s]Train epoch: 3 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003038\n",
      "2273it [01:21, 24.69it/s]Train epoch: 3 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003447\n",
      "2300it [01:22, 23.46it/s]Train epoch: 3 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002615\n",
      "2324it [01:23, 24.78it/s]Train epoch: 3 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003313\n",
      "2348it [01:24, 22.78it/s]Train epoch: 3 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.003042\n",
      "2375it [01:25, 23.30it/s]Train epoch: 3 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004337\n",
      "2399it [01:26, 23.55it/s]Train epoch: 3 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.004063\n",
      "2423it [01:27, 22.81it/s]Train epoch: 3 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002761\n",
      "2450it [01:28, 23.64it/s]Train epoch: 3 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003210\n",
      "2474it [01:29, 22.68it/s]Train epoch: 3 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003654\n",
      "2498it [01:30, 23.23it/s]Train epoch: 3 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003138\n",
      "2525it [01:31, 22.68it/s]Train epoch: 3 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003077\n",
      "2549it [01:32, 23.58it/s]Train epoch: 3 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004431\n",
      "2573it [01:33, 22.55it/s]Train epoch: 3 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003088\n",
      "2600it [01:35, 22.80it/s]Train epoch: 3 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003369\n",
      "2624it [01:36, 23.23it/s]Train epoch: 3 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003349\n",
      "2648it [01:37, 22.93it/s]Train epoch: 3 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.003906\n",
      "2675it [01:38, 22.12it/s]Train epoch: 3 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003480\n",
      "2699it [01:39, 22.88it/s]Train epoch: 3 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003041\n",
      "2723it [01:40, 22.07it/s]Train epoch: 3 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003277\n",
      "2750it [01:41, 23.15it/s]Train epoch: 3 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.003926\n",
      "2774it [01:42, 21.67it/s]Train epoch: 3 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003412\n",
      "2798it [01:43, 22.51it/s]Train epoch: 3 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003158\n",
      "2825it [01:45, 22.21it/s]Train epoch: 3 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003637\n",
      "2849it [01:46, 22.27it/s]Train epoch: 3 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003314\n",
      "2873it [01:47, 22.38it/s]Train epoch: 3 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003725\n",
      "2900it [01:48, 22.77it/s]Train epoch: 3 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003539\n",
      "2924it [01:49, 22.80it/s]Train epoch: 3 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003757\n",
      "2948it [01:50, 21.96it/s]Train epoch: 3 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.003832\n",
      "2975it [01:51, 21.52it/s]Train epoch: 3 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003577\n",
      "2999it [01:52, 21.54it/s]Train epoch: 3 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004204\n",
      "3023it [01:54, 21.83it/s]Train epoch: 3 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003805\n",
      "3050it [01:55, 21.59it/s]Train epoch: 3 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003223\n",
      "3074it [01:56, 21.95it/s]Train epoch: 3 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003811\n",
      "3098it [01:57, 22.74it/s]Train epoch: 3 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125it [01:58, 21.20it/s]Train epoch: 3 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003512\n",
      "3149it [01:59, 21.99it/s]Train epoch: 3 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003325\n",
      "3173it [02:00, 21.32it/s]Train epoch: 3 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003385\n",
      "3200it [02:02, 21.94it/s]Train epoch: 3 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.003902\n",
      "3224it [02:03, 20.94it/s]Train epoch: 3 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.003776\n",
      "3248it [02:04, 21.52it/s]Train epoch: 3 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.003816\n",
      "3275it [02:05, 21.86it/s]Train epoch: 3 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003374\n",
      "3299it [02:06, 22.05it/s]Train epoch: 3 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004240\n",
      "3323it [02:07, 21.08it/s]Train epoch: 3 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003657\n",
      "3350it [02:09, 20.50it/s]Train epoch: 3 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003634\n",
      "3374it [02:10, 22.41it/s]Train epoch: 3 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.003754\n",
      "3398it [02:11, 20.74it/s]Train epoch: 3 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.003898\n",
      "3425it [02:12, 21.74it/s]Train epoch: 3 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003374\n",
      "3449it [02:13, 21.94it/s]Train epoch: 3 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.003952\n",
      "3473it [02:14, 20.33it/s]Train epoch: 3 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003547\n",
      "3500it [02:16, 20.57it/s]Train epoch: 3 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003552\n",
      "3524it [02:17, 20.51it/s]Train epoch: 3 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003681\n",
      "3548it [02:18, 21.80it/s]Train epoch: 3 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.003959\n",
      "3575it [02:19, 21.31it/s]Train epoch: 3 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003208\n",
      "3599it [02:20, 21.42it/s]Train epoch: 3 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004238\n",
      "3623it [02:21, 21.53it/s]Train epoch: 3 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.003814\n",
      "3649it [02:23, 18.86it/s]Train epoch: 3 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.003911\n",
      "3675it [02:24, 17.29it/s]Train epoch: 3 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.003954\n",
      "3700it [02:26, 18.14it/s]Train epoch: 3 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.003876\n",
      "3724it [02:27, 17.71it/s]Train epoch: 3 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.004035\n",
      "3748it [02:28, 18.55it/s]Train epoch: 3 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.004034\n",
      "3775it [02:30, 17.34it/s]Train epoch: 3 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.003880\n",
      "3799it [02:31, 18.08it/s]Train epoch: 3 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004304\n",
      "3825it [02:33, 17.67it/s]Train epoch: 3 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003629\n",
      "3849it [02:34, 17.15it/s]Train epoch: 3 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003335\n",
      "3874it [02:35, 17.97it/s]Train epoch: 3 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003263\n",
      "3900it [02:37, 17.51it/s]Train epoch: 3 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004336\n",
      "3924it [02:38, 17.31it/s]Train epoch: 3 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.003989\n",
      "3950it [02:40, 18.05it/s]Train epoch: 3 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004267\n",
      "3975it [02:41, 17.64it/s]Train epoch: 3 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.004624\n",
      "3999it [02:43, 17.33it/s]Train epoch: 3 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003626\n",
      "4025it [02:44, 18.30it/s]Train epoch: 3 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004495\n",
      "4049it [02:45, 17.48it/s]Train epoch: 3 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004056\n",
      "4075it [02:47, 17.58it/s]Train epoch: 3 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004049\n",
      "4099it [02:48, 17.12it/s]Train epoch: 3 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004467\n",
      "4125it [02:50, 17.46it/s]Train epoch: 3 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004260\n",
      "4149it [02:51, 17.45it/s]Train epoch: 3 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003699\n",
      "4175it [02:53, 17.38it/s]Train epoch: 3 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.003968\n",
      "4199it [02:54, 17.45it/s]Train epoch: 3 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004310\n",
      "4225it [02:55, 17.69it/s]Train epoch: 3 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003636\n",
      "4250it [02:57, 17.56it/s]Train epoch: 3 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004213\n",
      "4274it [02:58, 17.65it/s]Train epoch: 3 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.003820\n",
      "4300it [03:00, 16.83it/s]Train epoch: 3 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004550\n",
      "4324it [03:01, 16.98it/s]Train epoch: 3 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.003952\n",
      "4350it [03:03, 16.70it/s]Train epoch: 3 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004325\n",
      "4374it [03:04, 17.24it/s]Train epoch: 3 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.003816\n",
      "4399it [03:06, 17.14it/s]Train epoch: 3 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003300\n",
      "4424it [03:07, 16.34it/s]Train epoch: 3 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004131\n",
      "4450it [03:09, 17.49it/s]Train epoch: 3 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003343\n",
      "4474it [03:10, 16.30it/s]Train epoch: 3 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004266\n",
      "4500it [03:12, 17.34it/s]Train epoch: 3 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.004833\n",
      "4524it [03:13, 16.47it/s]Train epoch: 3 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004212\n",
      "4550it [03:15, 17.05it/s]Train epoch: 3 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.003984\n",
      "4574it [03:16, 16.62it/s]Train epoch: 3 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004353\n",
      "4600it [03:18, 16.68it/s]Train epoch: 3 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.003806\n",
      "4624it [03:19, 16.57it/s]Train epoch: 3 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.003758\n",
      "4650it [03:21, 15.60it/s]Train epoch: 3 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004462\n",
      "4674it [03:22, 15.64it/s]Train epoch: 3 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004226\n",
      "4700it [03:24, 15.39it/s]Train epoch: 3 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003697\n",
      "4724it [03:25, 15.88it/s]Train epoch: 3 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.003978\n",
      "4750it [03:27, 16.10it/s]Train epoch: 3 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004583\n",
      "4774it [03:28, 16.28it/s]Train epoch: 3 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.004045\n",
      "4800it [03:30, 16.48it/s]Train epoch: 3 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004202\n",
      "4824it [03:32, 15.85it/s]Train epoch: 3 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003713\n",
      "4850it [03:33, 15.68it/s]Train epoch: 3 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004372\n",
      "4874it [03:35, 15.26it/s]Train epoch: 3 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003799\n",
      "4900it [03:36, 15.16it/s]Train epoch: 3 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.004088\n",
      "4924it [03:38, 15.64it/s]Train epoch: 3 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003705\n",
      "4950it [03:40, 15.69it/s]Train epoch: 3 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.004019\n",
      "4974it [03:41, 16.00it/s]Train epoch: 3 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004136\n",
      "5000it [03:43, 15.93it/s]Train epoch: 3 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.004006\n",
      "5024it [03:44, 15.41it/s]Train epoch: 3 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.003842\n",
      "5050it [03:46, 15.35it/s]Train epoch: 3 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.003772\n",
      "5074it [03:48, 15.54it/s]Train epoch: 3 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.004070\n",
      "5100it [03:49, 15.52it/s]Train epoch: 3 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004176\n",
      "5124it [03:51, 15.44it/s]Train epoch: 3 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004321\n",
      "5150it [03:52, 15.36it/s]Train epoch: 3 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5174it [03:54, 15.98it/s]Train epoch: 3 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004236\n",
      "5200it [03:56, 15.41it/s]Train epoch: 3 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.003844\n",
      "5224it [03:57, 15.47it/s]Train epoch: 3 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004077\n",
      "5250it [03:59, 15.51it/s]Train epoch: 3 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004072\n",
      "5274it [04:00, 15.70it/s]Train epoch: 3 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.003914\n",
      "5300it [04:02, 15.74it/s]Train epoch: 3 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.003783\n",
      "5324it [04:04, 15.27it/s]Train epoch: 3 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004316\n",
      "5350it [04:05, 15.04it/s]Train epoch: 3 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004327\n",
      "5374it [04:07, 14.97it/s]Train epoch: 3 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.004010\n",
      "5400it [04:09, 14.83it/s]Train epoch: 3 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.003926\n",
      "5424it [04:10, 14.97it/s]Train epoch: 3 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004378\n",
      "5450it [04:12, 15.49it/s]Train epoch: 3 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004199\n",
      "5474it [04:14, 14.77it/s]Train epoch: 3 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.004800\n",
      "5500it [04:15, 15.32it/s]Train epoch: 3 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004483\n",
      "5524it [04:17, 14.96it/s]Train epoch: 3 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003710\n",
      "5550it [04:19, 15.12it/s]Train epoch: 3 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004255\n",
      "5574it [04:20, 15.03it/s]Train epoch: 3 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004324\n",
      "5600it [04:22, 15.07it/s]Train epoch: 3 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004603\n",
      "5624it [04:24, 15.43it/s]Train epoch: 3 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004308\n",
      "5650it [04:25, 15.10it/s]Train epoch: 3 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.003898\n",
      "5674it [04:27, 14.80it/s]Train epoch: 3 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.004790\n",
      "5700it [04:29, 15.05it/s]Train epoch: 3 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004195\n",
      "5724it [04:30, 14.65it/s]Train epoch: 3 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004206\n",
      "5750it [04:32, 14.79it/s]Train epoch: 3 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005422\n",
      "5774it [04:34, 14.76it/s]Train epoch: 3 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004466\n",
      "5800it [04:35, 14.59it/s]Train epoch: 3 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004509\n",
      "5824it [04:37, 15.20it/s]Train epoch: 3 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.004054\n",
      "5850it [04:39, 15.28it/s]Train epoch: 3 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005106\n",
      "5874it [04:40, 14.83it/s]Train epoch: 3 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.004901\n",
      "5900it [04:42, 14.41it/s]Train epoch: 3 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.004930\n",
      "5924it [04:44, 14.65it/s]Train epoch: 3 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.004047\n",
      "5950it [04:46, 14.85it/s]Train epoch: 3 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.004012\n",
      "5974it [04:47, 15.10it/s]Train epoch: 3 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005396\n",
      "6000it [04:49, 15.05it/s]Train epoch: 3 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004497\n",
      "6024it [04:51, 14.58it/s]Train epoch: 3 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.004877\n",
      "6050it [04:52, 14.67it/s]Train epoch: 3 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004261\n",
      "6074it [04:54, 14.77it/s]Train epoch: 3 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.003964\n",
      "6100it [04:56, 14.23it/s]Train epoch: 3 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.003906\n",
      "6124it [04:57, 14.01it/s]Train epoch: 3 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004394\n",
      "6150it [04:59, 14.64it/s]Train epoch: 3 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004368\n",
      "6174it [05:01, 14.27it/s]Train epoch: 3 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.004878\n",
      "6200it [05:03, 14.87it/s]Train epoch: 3 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004299\n",
      "6224it [05:04, 14.46it/s]Train epoch: 3 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003814\n",
      "6250it [05:06, 13.96it/s]Train epoch: 3 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004103\n",
      "6274it [05:08, 13.83it/s]Train epoch: 3 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003709\n",
      "6300it [05:10, 14.10it/s]Train epoch: 3 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004321\n",
      "6324it [05:11, 14.50it/s]Train epoch: 3 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.004832\n",
      "6350it [05:13, 14.70it/s]Train epoch: 3 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.005051\n",
      "6374it [05:15, 14.28it/s]Train epoch: 3 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.003921\n",
      "6400it [05:17, 14.25it/s]Train epoch: 3 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004282\n",
      "6424it [05:18, 14.05it/s]Train epoch: 3 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.004814\n",
      "6450it [05:20, 13.99it/s]Train epoch: 3 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004762\n",
      "6474it [05:22, 13.95it/s]Train epoch: 3 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004187\n",
      "6500it [05:24, 13.50it/s]Train epoch: 3 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004732\n",
      "6524it [05:26, 13.92it/s]Train epoch: 3 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.004028\n",
      "6550it [05:27, 13.88it/s]Train epoch: 3 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004211\n",
      "6574it [05:29, 13.85it/s]Train epoch: 3 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004408\n",
      "6600it [05:31, 13.58it/s]Train epoch: 3 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005323\n",
      "6624it [05:33, 13.34it/s]Train epoch: 3 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004315\n",
      "6650it [05:35, 13.60it/s]Train epoch: 3 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.004812\n",
      "6674it [05:36, 14.00it/s]Train epoch: 3 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004450\n",
      "6700it [05:38, 13.22it/s]Train epoch: 3 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004574\n",
      "6724it [05:40, 13.22it/s]Train epoch: 3 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004603\n",
      "6750it [05:42, 13.25it/s]Train epoch: 3 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004157\n",
      "6774it [05:44, 13.68it/s]Train epoch: 3 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.004773\n",
      "6800it [05:46, 13.17it/s]Train epoch: 3 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.004850\n",
      "6824it [05:48, 13.47it/s]Train epoch: 3 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.004899\n",
      "6850it [05:50, 13.68it/s]Train epoch: 3 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.004715\n",
      "6874it [05:51, 13.06it/s]Train epoch: 3 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.003955\n",
      "6900it [05:53, 13.24it/s]Train epoch: 3 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004493\n",
      "6924it [05:55, 13.31it/s]Train epoch: 3 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004659\n",
      "6950it [05:57, 13.67it/s]Train epoch: 3 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.005073\n",
      "6974it [05:59, 13.10it/s]Train epoch: 3 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004732\n",
      "7000it [06:01, 13.40it/s]Train epoch: 3 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004529\n",
      "7024it [06:03, 13.17it/s]Train epoch: 3 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005138\n",
      "7050it [06:05, 13.34it/s]Train epoch: 3 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004130\n",
      "7074it [06:06, 12.97it/s]Train epoch: 3 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004443\n",
      "7100it [06:08, 13.44it/s]Train epoch: 3 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.004843\n",
      "7124it [06:10, 13.28it/s]Train epoch: 3 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004305\n",
      "7150it [06:12, 13.17it/s]Train epoch: 3 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005085\n",
      "7174it [06:14, 12.97it/s]Train epoch: 3 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004699\n",
      "7200it [06:16, 13.03it/s]Train epoch: 3 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.005065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7224it [06:18, 12.70it/s]Train epoch: 3 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004456\n",
      "7250it [06:20, 12.59it/s]Train epoch: 3 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004614\n",
      "7274it [06:22, 13.08it/s]Train epoch: 3 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.005073\n",
      "7300it [06:24, 12.81it/s]Train epoch: 3 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005442\n",
      "7324it [06:26, 12.85it/s]Train epoch: 3 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004368\n",
      "7350it [06:28, 13.02it/s]Train epoch: 3 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005380\n",
      "7374it [06:30, 12.68it/s]Train epoch: 3 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.004982\n",
      "7400it [06:32, 12.67it/s]Train epoch: 3 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004444\n",
      "7424it [06:33, 12.43it/s]Train epoch: 3 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.004916\n",
      "7450it [06:35, 12.96it/s]Train epoch: 3 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005313\n",
      "7474it [06:37, 12.85it/s]Train epoch: 3 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004656\n",
      "7500it [06:39, 13.09it/s]Train epoch: 3 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.004929\n",
      "7524it [06:41, 12.63it/s]Train epoch: 3 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004682\n",
      "7550it [06:43, 12.59it/s]Train epoch: 3 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004543\n",
      "7574it [06:45, 12.65it/s]Train epoch: 3 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.005037\n",
      "7600it [06:47, 13.08it/s]Train epoch: 3 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.005945\n",
      "7624it [06:49, 12.63it/s]Train epoch: 3 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005531\n",
      "7650it [06:51, 12.43it/s]Train epoch: 3 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004735\n",
      "7674it [06:53, 12.46it/s]Train epoch: 3 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.004700\n",
      "7700it [06:55, 12.18it/s]Train epoch: 3 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.004804\n",
      "7724it [06:57, 12.42it/s]Train epoch: 3 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.004837\n",
      "7750it [06:59, 12.33it/s]Train epoch: 3 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005172\n",
      "7774it [07:01, 12.49it/s]Train epoch: 3 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004453\n",
      "7800it [07:03, 12.39it/s]Train epoch: 3 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004701\n",
      "7824it [07:05, 12.49it/s]Train epoch: 3 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.004886\n",
      "7850it [07:07, 12.00it/s]Train epoch: 3 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004473\n",
      "7874it [07:09, 12.18it/s]Train epoch: 3 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004701\n",
      "7900it [07:11, 12.28it/s]Train epoch: 3 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.004861\n",
      "7924it [07:13, 12.43it/s]Train epoch: 3 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.004886\n",
      "7950it [07:15, 12.08it/s]Train epoch: 3 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005536\n",
      "7974it [07:17, 12.19it/s]Train epoch: 3 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004656\n",
      "8000it [07:20, 12.19it/s]Train epoch: 3 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004535\n",
      "8024it [07:21, 12.29it/s]Train epoch: 3 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.004989\n",
      "8050it [07:24, 12.07it/s]Train epoch: 3 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004341\n",
      "8074it [07:26, 12.15it/s]Train epoch: 3 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.004857\n",
      "8100it [07:28, 11.86it/s]Train epoch: 3 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005246\n",
      "8124it [07:30, 11.87it/s]Train epoch: 3 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005281\n",
      "8150it [07:32, 12.25it/s]Train epoch: 3 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004582\n",
      "8174it [07:34, 12.08it/s]Train epoch: 3 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005270\n",
      "8200it [07:36, 11.73it/s]Train epoch: 3 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004476\n",
      "8224it [07:38, 12.17it/s]Train epoch: 3 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.006068\n",
      "8250it [07:40, 12.02it/s]Train epoch: 3 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004636\n",
      "8274it [07:42, 11.95it/s]Train epoch: 3 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005296\n",
      "8300it [07:45, 11.91it/s]Train epoch: 3 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004692\n",
      "8324it [07:47, 12.03it/s]Train epoch: 3 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005329\n",
      "8350it [07:49, 11.56it/s]Train epoch: 3 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004636\n",
      "8374it [07:51, 11.31it/s]Train epoch: 3 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005311\n",
      "8400it [07:53, 11.82it/s]Train epoch: 3 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.004883\n",
      "8424it [07:55, 11.48it/s]Train epoch: 3 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.004937\n",
      "8450it [07:57, 11.41it/s]Train epoch: 3 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005235\n",
      "8474it [08:00, 11.34it/s]Train epoch: 3 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.005002\n",
      "8500it [08:02, 11.50it/s]Train epoch: 3 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.005731\n",
      "8524it [08:04, 11.26it/s]Train epoch: 3 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.005061\n",
      "8550it [08:06, 11.51it/s]Train epoch: 3 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005276\n",
      "8574it [08:08, 11.38it/s]Train epoch: 3 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.004845\n",
      "8600it [08:11, 11.39it/s]Train epoch: 3 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.004942\n",
      "8624it [08:13, 11.57it/s]Train epoch: 3 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005150\n",
      "8650it [08:15, 11.36it/s]Train epoch: 3 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005271\n",
      "8674it [08:17, 11.26it/s]Train epoch: 3 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.005949\n",
      "8700it [08:19, 11.05it/s]Train epoch: 3 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.005871\n",
      "8724it [08:22, 11.64it/s]Train epoch: 3 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005706\n",
      "8750it [08:24, 11.41it/s]Train epoch: 3 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005313\n",
      "8774it [08:26, 11.03it/s]Train epoch: 3 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.004850\n",
      "8800it [08:28, 11.11it/s]Train epoch: 3 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005136\n",
      "8824it [08:30, 11.07it/s]Train epoch: 3 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005097\n",
      "8850it [08:33, 11.16it/s]Train epoch: 3 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005284\n",
      "8874it [08:35, 11.05it/s]Train epoch: 3 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005183\n",
      "8900it [08:37, 11.02it/s]Train epoch: 3 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005239\n",
      "8924it [08:40, 10.96it/s]Train epoch: 3 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005325\n",
      "8950it [08:42, 10.84it/s]Train epoch: 3 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.006005\n",
      "8974it [08:44, 10.93it/s]Train epoch: 3 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005484\n",
      "9000it [08:46, 11.11it/s]Train epoch: 3 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005197\n",
      "9024it [08:49, 10.72it/s]Train epoch: 3 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005299\n",
      "9050it [08:51, 10.46it/s]Train epoch: 3 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.004899\n",
      "9074it [08:53, 10.87it/s]Train epoch: 3 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004691\n",
      "9100it [08:56, 10.92it/s]Train epoch: 3 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005471\n",
      "9124it [08:58, 10.68it/s]Train epoch: 3 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.005063\n",
      "9150it [09:00, 10.50it/s]Train epoch: 3 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004614\n",
      "9174it [09:03, 11.07it/s]Train epoch: 3 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.004987\n",
      "9200it [09:05, 10.72it/s]Train epoch: 3 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.004817\n",
      "9224it [09:07, 10.25it/s]Train epoch: 3 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.005899\n",
      "9250it [09:10, 10.51it/s]Train epoch: 3 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9274it [09:12, 10.39it/s]Train epoch: 3 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005488\n",
      "9300it [09:15, 10.65it/s]Train epoch: 3 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006177\n",
      "9324it [09:17, 10.36it/s]Train epoch: 3 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.005918\n",
      "9350it [09:19, 10.28it/s]Train epoch: 3 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.005831\n",
      "9374it [09:22, 10.29it/s]Train epoch: 3 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005173\n",
      "9400it [09:24, 10.53it/s]Train epoch: 3 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005525\n",
      "9424it [09:26, 10.58it/s]Train epoch: 3 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005314\n",
      "9450it [09:29,  9.91it/s]Train epoch: 3 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005288\n",
      "9475it [09:31,  9.95it/s]Train epoch: 3 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.005892\n",
      "9499it [09:34, 10.16it/s]Train epoch: 3 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005440\n",
      "9525it [09:36, 10.17it/s]Train epoch: 3 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.005935\n",
      "9549it [09:39, 10.23it/s]Train epoch: 3 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.005732\n",
      "9575it [09:41, 10.37it/s]Train epoch: 3 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.005858\n",
      "9600it [09:44, 10.15it/s]Train epoch: 3 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005732\n",
      "9624it [09:46, 10.01it/s]Train epoch: 3 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005206\n",
      "9650it [09:49, 10.01it/s]Train epoch: 3 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005219\n",
      "9675it [09:51, 10.03it/s]Train epoch: 3 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005498\n",
      "9699it [09:54, 10.26it/s]Train epoch: 3 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.004927\n",
      "9725it [09:56,  9.75it/s]Train epoch: 3 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005394\n",
      "9750it [09:59,  9.84it/s]Train epoch: 3 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005513\n",
      "9775it [10:01, 10.08it/s]Train epoch: 3 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006246\n",
      "9799it [10:04,  9.83it/s]Train epoch: 3 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.005920\n",
      "9825it [10:06,  9.87it/s]Train epoch: 3 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.006136\n",
      "9850it [10:09,  9.35it/s]Train epoch: 3 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005542\n",
      "9874it [10:11,  9.71it/s]Train epoch: 3 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.005947\n",
      "9900it [10:14,  9.57it/s]Train epoch: 3 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006307\n",
      "9925it [10:17,  9.65it/s]Train epoch: 3 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.005890\n",
      "9949it [10:19,  9.45it/s]Train epoch: 3 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006550\n",
      "9975it [10:22,  9.51it/s]Train epoch: 3 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.005989\n",
      "10000it [10:25,  9.58it/s]Train epoch: 3 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005540\n",
      "10025it [10:27,  9.13it/s]Train epoch: 3 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005464\n",
      "10050it [10:30,  9.63it/s]Train epoch: 3 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.005996\n",
      "10074it [10:32,  9.72it/s]Train epoch: 3 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006479\n",
      "10100it [10:35,  9.15it/s]Train epoch: 3 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006170\n",
      "10125it [10:38,  9.22it/s]Train epoch: 3 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005567\n",
      "10150it [10:41,  8.86it/s]Train epoch: 3 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.006058\n",
      "10175it [10:43,  9.10it/s]Train epoch: 3 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005684\n",
      "10200it [10:46,  9.23it/s]Train epoch: 3 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.006115\n",
      "10225it [10:49,  9.24it/s]Train epoch: 3 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006163\n",
      "10250it [10:52,  9.29it/s]Train epoch: 3 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006629\n",
      "10275it [10:54,  9.04it/s]Train epoch: 3 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.005840\n",
      "10300it [10:57,  8.94it/s]Train epoch: 3 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006455\n",
      "10325it [11:00,  8.80it/s]Train epoch: 3 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006243\n",
      "10350it [11:03,  9.22it/s]Train epoch: 3 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.005864\n",
      "10375it [11:05,  9.04it/s]Train epoch: 3 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006181\n",
      "10400it [11:08,  8.81it/s]Train epoch: 3 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006161\n",
      "10425it [11:11,  8.68it/s]Train epoch: 3 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.005833\n",
      "10450it [11:14,  8.53it/s]Train epoch: 3 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006216\n",
      "10475it [11:17,  8.51it/s]Train epoch: 3 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005410\n",
      "10500it [11:20,  8.69it/s]Train epoch: 3 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006222\n",
      "10525it [11:23,  8.65it/s]Train epoch: 3 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.005904\n",
      "10550it [11:26,  8.31it/s]Train epoch: 3 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006202\n",
      "10575it [11:29,  8.39it/s]Train epoch: 3 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005540\n",
      "10600it [11:32,  8.44it/s]Train epoch: 3 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.005756\n",
      "10625it [11:35,  8.08it/s]Train epoch: 3 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006441\n",
      "10650it [11:38,  8.70it/s]Train epoch: 3 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.005905\n",
      "10675it [11:41,  8.30it/s]Train epoch: 3 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006259\n",
      "10700it [11:44,  8.31it/s]Train epoch: 3 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.005864\n",
      "10725it [11:47,  8.22it/s]Train epoch: 3 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005505\n",
      "10750it [11:50,  8.15it/s]Train epoch: 3 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006480\n",
      "10775it [11:53,  7.99it/s]Train epoch: 3 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006443\n",
      "10800it [11:56,  8.18it/s]Train epoch: 3 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006677\n",
      "10825it [11:59,  8.10it/s]Train epoch: 3 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006580\n",
      "10850it [12:02,  7.99it/s]Train epoch: 3 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006390\n",
      "10875it [12:05,  7.95it/s]Train epoch: 3 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006559\n",
      "10900it [12:09,  7.93it/s]Train epoch: 3 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006236\n",
      "10925it [12:12,  7.97it/s]Train epoch: 3 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005764\n",
      "10950it [12:15,  7.90it/s]Train epoch: 3 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006255\n",
      "10975it [12:18,  7.82it/s]Train epoch: 3 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006076\n",
      "11000it [12:21,  7.94it/s]Train epoch: 3 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.006071\n",
      "11025it [12:24,  7.99it/s]Train epoch: 3 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006309\n",
      "11050it [12:27,  8.07it/s]Train epoch: 3 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.007035\n",
      "11075it [12:31,  8.00it/s]Train epoch: 3 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006509\n",
      "11100it [12:34,  7.96it/s]Train epoch: 3 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007222\n",
      "11125it [12:37,  7.86it/s]Train epoch: 3 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006665\n",
      "11150it [12:40,  7.86it/s]Train epoch: 3 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006478\n",
      "11175it [12:43,  8.10it/s]Train epoch: 3 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007477\n",
      "11200it [12:46,  7.93it/s]Train epoch: 3 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006827\n",
      "11225it [12:49,  7.85it/s]Train epoch: 3 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006712\n",
      "11250it [12:53,  8.00it/s]Train epoch: 3 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007295\n",
      "11275it [12:56,  8.01it/s]Train epoch: 3 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.007046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11300it [12:59,  7.89it/s]Train epoch: 3 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006441\n",
      "11325it [13:02,  8.13it/s]Train epoch: 3 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007583\n",
      "11350it [13:05,  8.12it/s]Train epoch: 3 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007448\n",
      "11375it [13:08,  7.88it/s]Train epoch: 3 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007590\n",
      "11400it [13:11,  8.16it/s]Train epoch: 3 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006715\n",
      "11425it [13:15,  8.06it/s]Train epoch: 3 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007445\n",
      "11450it [13:18,  8.06it/s]Train epoch: 3 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006554\n",
      "11475it [13:21,  8.03it/s]Train epoch: 3 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007908\n",
      "11500it [13:24,  8.04it/s]Train epoch: 3 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007590\n",
      "11525it [13:27,  7.90it/s]Train epoch: 3 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006938\n",
      "11550it [13:30,  7.77it/s]Train epoch: 3 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.006923\n",
      "11575it [13:33,  7.95it/s]Train epoch: 3 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007923\n",
      "11600it [13:37,  7.97it/s]Train epoch: 3 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007356\n",
      "11625it [13:40,  7.91it/s]Train epoch: 3 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006990\n",
      "11650it [13:43,  8.05it/s]Train epoch: 3 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007385\n",
      "11675it [13:46,  7.89it/s]Train epoch: 3 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007848\n",
      "11700it [13:49,  8.04it/s]Train epoch: 3 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008448\n",
      "11725it [13:52,  7.76it/s]Train epoch: 3 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008374\n",
      "11750it [13:56,  7.89it/s]Train epoch: 3 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008160\n",
      "11775it [13:59,  7.85it/s]Train epoch: 3 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008172\n",
      "11800it [14:02,  7.87it/s]Train epoch: 3 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007976\n",
      "11825it [14:05,  7.90it/s]Train epoch: 3 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008209\n",
      "11850it [14:08,  7.81it/s]Train epoch: 3 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008567\n",
      "11875it [14:11,  7.82it/s]Train epoch: 3 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009436\n",
      "11900it [14:15,  7.73it/s]Train epoch: 3 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011359\n",
      "11925it [14:18,  8.05it/s]Train epoch: 3 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009624\n",
      "11930it [14:18, 13.89it/s]\n",
      "epoch loss: 0.004652268641950541\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 129.14it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0358, 0.0515, 0.0566, 0.0539, 0.8805\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3263, 0.5413, 0.4511, 0.4921, 0.9818\n",
      "rec_at_8: 0.3527\n",
      "prec_at_8: 0.6481\n",
      "rec_at_15: 0.4904\n",
      "prec_at_15: 0.5041\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 131.05it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0367, 0.0591, 0.0599, 0.0595, 0.8717\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3216, 0.5364, 0.4454, 0.4867, 0.9816\n",
      "rec_at_8: 0.3366\n",
      "prec_at_8: 0.6442\n",
      "rec_at_15: 0.4730\n",
      "prec_at_15: 0.5055\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 3\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0358, 0.0515, 0.0566, 0.0539, 0.8805\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3263, 0.5413, 0.4511, 0.4921, 0.9818\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0068\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 3\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0367, 0.0591, 0.0599, 0.0595, 0.8717\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3216, 0.5364, 0.4454, 0.4867, 0.9816\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0070\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "\n",
      "EPOCH 4\n",
      "0it [00:00, ?it/s]Train epoch: 4 [batch #0, batch_size 4, seq length 68]\tLoss: 0.005751\n",
      "24it [00:00, 45.40it/s]Train epoch: 4 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003798\n",
      "50it [00:01, 45.69it/s]Train epoch: 4 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003526\n",
      "75it [00:01, 43.01it/s]Train epoch: 4 [batch #75, batch_size 4, seq length 307]\tLoss: 0.002882\n",
      "100it [00:02, 40.44it/s]Train epoch: 4 [batch #100, batch_size 4, seq length 333]\tLoss: 0.003147\n",
      "125it [00:02, 39.44it/s]Train epoch: 4 [batch #125, batch_size 4, seq length 354]\tLoss: 0.002944\n",
      "146it [00:03, 37.31it/s]Train epoch: 4 [batch #150, batch_size 4, seq length 370]\tLoss: 0.002863\n",
      "174it [00:04, 35.13it/s]Train epoch: 4 [batch #175, batch_size 4, seq length 386]\tLoss: 0.002978\n",
      "199it [00:04, 38.07it/s]Train epoch: 4 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002861\n",
      "223it [00:05, 36.03it/s]Train epoch: 4 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003540\n",
      "247it [00:06, 33.53it/s]Train epoch: 4 [batch #250, batch_size 4, seq length 428]\tLoss: 0.002874\n",
      "275it [00:07, 33.72it/s]Train epoch: 4 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002466\n",
      "299it [00:07, 31.91it/s]Train epoch: 4 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003198\n",
      "323it [00:08, 32.89it/s]Train epoch: 4 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002613\n",
      "347it [00:09, 34.30it/s]Train epoch: 4 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003194\n",
      "375it [00:10, 30.72it/s]Train epoch: 4 [batch #375, batch_size 4, seq length 480]\tLoss: 0.002993\n",
      "399it [00:10, 32.51it/s]Train epoch: 4 [batch #400, batch_size 4, seq length 489]\tLoss: 0.003038\n",
      "423it [00:11, 31.53it/s]Train epoch: 4 [batch #425, batch_size 4, seq length 497]\tLoss: 0.002968\n",
      "447it [00:12, 31.38it/s]Train epoch: 4 [batch #450, batch_size 4, seq length 504]\tLoss: 0.002908\n",
      "475it [00:13, 30.98it/s]Train epoch: 4 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003341\n",
      "499it [00:14, 33.35it/s]Train epoch: 4 [batch #500, batch_size 4, seq length 519]\tLoss: 0.002864\n",
      "523it [00:14, 32.91it/s]Train epoch: 4 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003103\n",
      "547it [00:15, 30.62it/s]Train epoch: 4 [batch #550, batch_size 4, seq length 534]\tLoss: 0.003047\n",
      "572it [00:16, 29.54it/s]Train epoch: 4 [batch #575, batch_size 4, seq length 541]\tLoss: 0.002984\n",
      "600it [00:17, 30.81it/s]Train epoch: 4 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003304\n",
      "623it [00:18, 29.40it/s]Train epoch: 4 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003236\n",
      "647it [00:19, 30.03it/s]Train epoch: 4 [batch #650, batch_size 4, seq length 559]\tLoss: 0.002849\n",
      "675it [00:19, 30.42it/s]Train epoch: 4 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002408\n",
      "698it [00:20, 30.11it/s]Train epoch: 4 [batch #700, batch_size 4, seq length 573]\tLoss: 0.002983\n",
      "725it [00:21, 26.95it/s]Train epoch: 4 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003052\n",
      "750it [00:22, 28.70it/s]Train epoch: 4 [batch #750, batch_size 4, seq length 584]\tLoss: 0.002921\n",
      "773it [00:23, 28.56it/s]Train epoch: 4 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003230\n",
      "800it [00:24, 28.61it/s]Train epoch: 4 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003112\n",
      "822it [00:25, 27.01it/s]Train epoch: 4 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003073\n",
      "849it [00:26, 28.64it/s]Train epoch: 4 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003433\n",
      "873it [00:26, 30.24it/s]Train epoch: 4 [batch #875, batch_size 4, seq length 612]\tLoss: 0.002851\n",
      "899it [00:27, 27.52it/s]Train epoch: 4 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003236\n",
      "925it [00:28, 28.79it/s]Train epoch: 4 [batch #925, batch_size 4, seq length 622]\tLoss: 0.002940\n",
      "948it [00:29, 27.51it/s]Train epoch: 4 [batch #950, batch_size 4, seq length 627]\tLoss: 0.002911\n",
      "974it [00:30, 27.61it/s]Train epoch: 4 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002291\n",
      "999it [00:31, 27.35it/s]Train epoch: 4 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022it [00:32, 27.02it/s]Train epoch: 4 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004219\n",
      "1050it [00:33, 26.84it/s]Train epoch: 4 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.002869\n",
      "1072it [00:34, 28.97it/s]Train epoch: 4 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003318\n",
      "1100it [00:35, 26.97it/s]Train epoch: 4 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003345\n",
      "1125it [00:36, 26.12it/s]Train epoch: 4 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003323\n",
      "1149it [00:36, 27.03it/s]Train epoch: 4 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003280\n",
      "1174it [00:37, 27.63it/s]Train epoch: 4 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003236\n",
      "1198it [00:38, 26.90it/s]Train epoch: 4 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003368\n",
      "1225it [00:39, 27.25it/s]Train epoch: 4 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003444\n",
      "1249it [00:40, 26.37it/s]Train epoch: 4 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003267\n",
      "1274it [00:41, 26.61it/s]Train epoch: 4 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.002856\n",
      "1299it [00:42, 27.69it/s]Train epoch: 4 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.002820\n",
      "1323it [00:43, 26.05it/s]Train epoch: 4 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.002948\n",
      "1348it [00:44, 26.80it/s]Train epoch: 4 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.003850\n",
      "1375it [00:45, 25.11it/s]Train epoch: 4 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003189\n",
      "1399it [00:46, 25.51it/s]Train epoch: 4 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003235\n",
      "1423it [00:47, 25.98it/s]Train epoch: 4 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.002859\n",
      "1450it [00:48, 25.54it/s]Train epoch: 4 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.003029\n",
      "1474it [00:49, 25.64it/s]Train epoch: 4 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003240\n",
      "1498it [00:50, 25.52it/s]Train epoch: 4 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004336\n",
      "1525it [00:51, 24.78it/s]Train epoch: 4 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.003974\n",
      "1549it [00:52, 25.19it/s]Train epoch: 4 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003008\n",
      "1573it [00:52, 25.67it/s]Train epoch: 4 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003354\n",
      "1600it [00:54, 26.28it/s]Train epoch: 4 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.002931\n",
      "1624it [00:55, 23.76it/s]Train epoch: 4 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003522\n",
      "1648it [00:55, 24.00it/s]Train epoch: 4 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003603\n",
      "1675it [00:57, 23.68it/s]Train epoch: 4 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003528\n",
      "1699it [00:58, 24.33it/s]Train epoch: 4 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.002983\n",
      "1723it [00:58, 26.00it/s]Train epoch: 4 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002637\n",
      "1750it [00:59, 26.19it/s]Train epoch: 4 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.003913\n",
      "1774it [01:00, 25.12it/s]Train epoch: 4 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003320\n",
      "1798it [01:01, 23.55it/s]Train epoch: 4 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003243\n",
      "1825it [01:03, 24.12it/s]Train epoch: 4 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002712\n",
      "1849it [01:03, 25.21it/s]Train epoch: 4 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003334\n",
      "1873it [01:04, 25.42it/s]Train epoch: 4 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003684\n",
      "1900it [01:06, 24.53it/s]Train epoch: 4 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002623\n",
      "1924it [01:06, 24.93it/s]Train epoch: 4 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.002841\n",
      "1948it [01:07, 24.82it/s]Train epoch: 4 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.002818\n",
      "1975it [01:09, 24.88it/s]Train epoch: 4 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003471\n",
      "1999it [01:09, 25.21it/s]Train epoch: 4 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002692\n",
      "2023it [01:10, 23.79it/s]Train epoch: 4 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003332\n",
      "2050it [01:12, 24.92it/s]Train epoch: 4 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003096\n",
      "2074it [01:13, 24.22it/s]Train epoch: 4 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003250\n",
      "2098it [01:14, 24.44it/s]Train epoch: 4 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003337\n",
      "2125it [01:15, 22.88it/s]Train epoch: 4 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003658\n",
      "2149it [01:16, 24.07it/s]Train epoch: 4 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003131\n",
      "2173it [01:17, 24.50it/s]Train epoch: 4 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003470\n",
      "2200it [01:18, 23.45it/s]Train epoch: 4 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003332\n",
      "2224it [01:19, 24.68it/s]Train epoch: 4 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003301\n",
      "2248it [01:20, 22.96it/s]Train epoch: 4 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.003020\n",
      "2275it [01:21, 24.29it/s]Train epoch: 4 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003421\n",
      "2299it [01:22, 23.40it/s]Train epoch: 4 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002590\n",
      "2323it [01:23, 23.87it/s]Train epoch: 4 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003232\n",
      "2350it [01:24, 23.90it/s]Train epoch: 4 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.002932\n",
      "2374it [01:25, 22.63it/s]Train epoch: 4 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004270\n",
      "2398it [01:26, 24.30it/s]Train epoch: 4 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.003974\n",
      "2425it [01:27, 24.00it/s]Train epoch: 4 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002728\n",
      "2449it [01:28, 23.24it/s]Train epoch: 4 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003209\n",
      "2473it [01:29, 23.34it/s]Train epoch: 4 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003563\n",
      "2500it [01:30, 24.53it/s]Train epoch: 4 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.003084\n",
      "2524it [01:31, 22.98it/s]Train epoch: 4 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003021\n",
      "2548it [01:33, 23.00it/s]Train epoch: 4 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004342\n",
      "2575it [01:34, 22.65it/s]Train epoch: 4 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.003048\n",
      "2599it [01:35, 22.30it/s]Train epoch: 4 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003324\n",
      "2623it [01:36, 22.27it/s]Train epoch: 4 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003332\n",
      "2650it [01:37, 23.92it/s]Train epoch: 4 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.003812\n",
      "2674it [01:38, 23.01it/s]Train epoch: 4 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003436\n",
      "2698it [01:39, 23.07it/s]Train epoch: 4 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.003009\n",
      "2725it [01:40, 21.32it/s]Train epoch: 4 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003218\n",
      "2749it [01:41, 23.88it/s]Train epoch: 4 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.003882\n",
      "2773it [01:42, 21.94it/s]Train epoch: 4 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003368\n",
      "2800it [01:44, 23.41it/s]Train epoch: 4 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003138\n",
      "2824it [01:45, 23.43it/s]Train epoch: 4 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003543\n",
      "2848it [01:46, 22.37it/s]Train epoch: 4 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003310\n",
      "2875it [01:47, 21.65it/s]Train epoch: 4 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003661\n",
      "2899it [01:48, 22.49it/s]Train epoch: 4 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003491\n",
      "2923it [01:49, 20.78it/s]Train epoch: 4 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003655\n",
      "2950it [01:50, 22.21it/s]Train epoch: 4 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.003798\n",
      "2974it [01:52, 22.18it/s]Train epoch: 4 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003517\n",
      "2998it [01:53, 21.99it/s]Train epoch: 4 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004108\n",
      "3025it [01:54, 21.34it/s]Train epoch: 4 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003774\n",
      "3049it [01:55, 21.19it/s]Train epoch: 4 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003184\n",
      "3073it [01:56, 21.94it/s]Train epoch: 4 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100it [01:57, 21.80it/s]Train epoch: 4 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003633\n",
      "3124it [01:58, 22.09it/s]Train epoch: 4 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003429\n",
      "3148it [01:59, 22.60it/s]Train epoch: 4 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003281\n",
      "3175it [02:01, 21.15it/s]Train epoch: 4 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003294\n",
      "3199it [02:02, 21.60it/s]Train epoch: 4 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.003843\n",
      "3223it [02:03, 22.04it/s]Train epoch: 4 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.003708\n",
      "3250it [02:04, 21.68it/s]Train epoch: 4 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.003755\n",
      "3274it [02:05, 22.21it/s]Train epoch: 4 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003290\n",
      "3298it [02:06, 22.01it/s]Train epoch: 4 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004216\n",
      "3325it [02:08, 22.28it/s]Train epoch: 4 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003518\n",
      "3349it [02:09, 20.33it/s]Train epoch: 4 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003543\n",
      "3373it [02:10, 20.91it/s]Train epoch: 4 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.003715\n",
      "3400it [02:11, 21.02it/s]Train epoch: 4 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.003819\n",
      "3424it [02:12, 21.39it/s]Train epoch: 4 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003315\n",
      "3448it [02:13, 21.71it/s]Train epoch: 4 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.003898\n",
      "3475it [02:15, 19.96it/s]Train epoch: 4 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003476\n",
      "3499it [02:16, 22.32it/s]Train epoch: 4 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003555\n",
      "3523it [02:17, 20.67it/s]Train epoch: 4 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003637\n",
      "3550it [02:18, 20.76it/s]Train epoch: 4 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.003890\n",
      "3574it [02:19, 20.58it/s]Train epoch: 4 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003154\n",
      "3598it [02:20, 21.02it/s]Train epoch: 4 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004089\n",
      "3625it [02:22, 20.08it/s]Train epoch: 4 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.003790\n",
      "3649it [02:23, 19.87it/s]Train epoch: 4 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.003828\n",
      "3675it [02:24, 17.91it/s]Train epoch: 4 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.003906\n",
      "3700it [02:26, 18.39it/s]Train epoch: 4 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.003819\n",
      "3725it [02:27, 18.27it/s]Train epoch: 4 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.003937\n",
      "3749it [02:29, 17.31it/s]Train epoch: 4 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.003905\n",
      "3775it [02:30, 18.04it/s]Train epoch: 4 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.003816\n",
      "3800it [02:31, 17.80it/s]Train epoch: 4 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004190\n",
      "3824it [02:33, 18.70it/s]Train epoch: 4 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003588\n",
      "3850it [02:34, 17.88it/s]Train epoch: 4 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003293\n",
      "3874it [02:36, 17.01it/s]Train epoch: 4 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003214\n",
      "3900it [02:37, 17.69it/s]Train epoch: 4 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004201\n",
      "3925it [02:38, 17.97it/s]Train epoch: 4 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.003866\n",
      "3949it [02:40, 17.33it/s]Train epoch: 4 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004226\n",
      "3975it [02:41, 18.04it/s]Train epoch: 4 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.004649\n",
      "3999it [02:43, 17.57it/s]Train epoch: 4 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003525\n",
      "4023it [02:44, 17.68it/s]Train epoch: 4 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004452\n",
      "4050it [02:46, 16.93it/s]Train epoch: 4 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.004006\n",
      "4074it [02:47, 17.07it/s]Train epoch: 4 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.004019\n",
      "4100it [02:48, 17.33it/s]Train epoch: 4 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004404\n",
      "4124it [02:50, 17.23it/s]Train epoch: 4 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004159\n",
      "4150it [02:51, 17.71it/s]Train epoch: 4 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003575\n",
      "4174it [02:53, 16.66it/s]Train epoch: 4 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.003908\n",
      "4200it [02:54, 17.11it/s]Train epoch: 4 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004190\n",
      "4224it [02:56, 17.47it/s]Train epoch: 4 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003586\n",
      "4250it [02:57, 17.09it/s]Train epoch: 4 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004180\n",
      "4274it [02:58, 17.16it/s]Train epoch: 4 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.003752\n",
      "4300it [03:00, 17.31it/s]Train epoch: 4 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004442\n",
      "4325it [03:01, 17.61it/s]Train epoch: 4 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.003850\n",
      "4350it [03:03, 16.83it/s]Train epoch: 4 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004219\n",
      "4374it [03:04, 17.21it/s]Train epoch: 4 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.003750\n",
      "4400it [03:06, 16.73it/s]Train epoch: 4 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003272\n",
      "4424it [03:07, 17.52it/s]Train epoch: 4 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.004061\n",
      "4450it [03:09, 17.19it/s]Train epoch: 4 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003330\n",
      "4474it [03:10, 17.64it/s]Train epoch: 4 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004182\n",
      "4500it [03:12, 16.48it/s]Train epoch: 4 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.004793\n",
      "4524it [03:13, 16.42it/s]Train epoch: 4 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004121\n",
      "4550it [03:15, 16.36it/s]Train epoch: 4 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.003880\n",
      "4574it [03:16, 16.92it/s]Train epoch: 4 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004363\n",
      "4600it [03:18, 15.68it/s]Train epoch: 4 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.003708\n",
      "4624it [03:19, 16.15it/s]Train epoch: 4 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.003695\n",
      "4650it [03:21, 16.02it/s]Train epoch: 4 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004396\n",
      "4674it [03:22, 15.26it/s]Train epoch: 4 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004145\n",
      "4700it [03:24, 16.49it/s]Train epoch: 4 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003651\n",
      "4724it [03:25, 15.91it/s]Train epoch: 4 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.003866\n",
      "4750it [03:27, 16.47it/s]Train epoch: 4 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004492\n",
      "4774it [03:28, 15.70it/s]Train epoch: 4 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.003956\n",
      "4800it [03:30, 15.86it/s]Train epoch: 4 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004136\n",
      "4824it [03:32, 15.72it/s]Train epoch: 4 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003636\n",
      "4850it [03:33, 15.93it/s]Train epoch: 4 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004309\n",
      "4874it [03:35, 16.05it/s]Train epoch: 4 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003717\n",
      "4900it [03:36, 15.53it/s]Train epoch: 4 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.003983\n",
      "4924it [03:38, 15.48it/s]Train epoch: 4 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003569\n",
      "4950it [03:40, 15.89it/s]Train epoch: 4 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.003942\n",
      "4974it [03:41, 15.53it/s]Train epoch: 4 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004041\n",
      "5000it [03:43, 15.48it/s]Train epoch: 4 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.003917\n",
      "5024it [03:44, 15.28it/s]Train epoch: 4 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.003771\n",
      "5050it [03:46, 15.75it/s]Train epoch: 4 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.003696\n",
      "5074it [03:48, 15.77it/s]Train epoch: 4 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.003989\n",
      "5100it [03:49, 15.39it/s]Train epoch: 4 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004134\n",
      "5124it [03:51, 15.60it/s]Train epoch: 4 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5150it [03:53, 16.04it/s]Train epoch: 4 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004311\n",
      "5174it [03:54, 14.99it/s]Train epoch: 4 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004148\n",
      "5200it [03:56, 15.51it/s]Train epoch: 4 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.003831\n",
      "5224it [03:57, 15.82it/s]Train epoch: 4 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.004049\n",
      "5250it [03:59, 15.40it/s]Train epoch: 4 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.004076\n",
      "5274it [04:01, 15.19it/s]Train epoch: 4 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.003902\n",
      "5300it [04:02, 15.03it/s]Train epoch: 4 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.003721\n",
      "5324it [04:04, 14.80it/s]Train epoch: 4 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004198\n",
      "5350it [04:06, 15.90it/s]Train epoch: 4 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004245\n",
      "5374it [04:07, 15.62it/s]Train epoch: 4 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.003917\n",
      "5400it [04:09, 14.90it/s]Train epoch: 4 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.003850\n",
      "5424it [04:10, 15.25it/s]Train epoch: 4 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004295\n",
      "5450it [04:12, 15.09it/s]Train epoch: 4 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004118\n",
      "5474it [04:14, 14.83it/s]Train epoch: 4 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.004709\n",
      "5500it [04:15, 15.23it/s]Train epoch: 4 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004343\n",
      "5524it [04:17, 15.28it/s]Train epoch: 4 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003643\n",
      "5550it [04:19, 14.69it/s]Train epoch: 4 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004181\n",
      "5574it [04:20, 14.87it/s]Train epoch: 4 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004251\n",
      "5600it [04:22, 14.41it/s]Train epoch: 4 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004556\n",
      "5624it [04:24, 15.43it/s]Train epoch: 4 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004265\n",
      "5650it [04:26, 14.99it/s]Train epoch: 4 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.003845\n",
      "5674it [04:27, 14.68it/s]Train epoch: 4 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.004643\n",
      "5700it [04:29, 14.71it/s]Train epoch: 4 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004064\n",
      "5724it [04:31, 14.89it/s]Train epoch: 4 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004111\n",
      "5750it [04:32, 14.96it/s]Train epoch: 4 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005312\n",
      "5774it [04:34, 14.83it/s]Train epoch: 4 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004438\n",
      "5800it [04:36, 15.00it/s]Train epoch: 4 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004429\n",
      "5824it [04:37, 14.67it/s]Train epoch: 4 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.003956\n",
      "5850it [04:39, 14.96it/s]Train epoch: 4 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.005088\n",
      "5874it [04:41, 14.81it/s]Train epoch: 4 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.004877\n",
      "5900it [04:42, 15.15it/s]Train epoch: 4 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.004827\n",
      "5924it [04:44, 14.56it/s]Train epoch: 4 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.003976\n",
      "5950it [04:46, 14.34it/s]Train epoch: 4 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.003851\n",
      "5974it [04:48, 14.99it/s]Train epoch: 4 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005276\n",
      "6000it [04:49, 14.41it/s]Train epoch: 4 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004400\n",
      "6024it [04:51, 14.81it/s]Train epoch: 4 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.004729\n",
      "6050it [04:53, 14.50it/s]Train epoch: 4 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004208\n",
      "6074it [04:54, 14.40it/s]Train epoch: 4 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.003883\n",
      "6100it [04:56, 14.66it/s]Train epoch: 4 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.003880\n",
      "6124it [04:58, 14.38it/s]Train epoch: 4 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004253\n",
      "6150it [05:00, 13.85it/s]Train epoch: 4 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004255\n",
      "6174it [05:01, 14.06it/s]Train epoch: 4 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.004806\n",
      "6200it [05:03, 14.60it/s]Train epoch: 4 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004254\n",
      "6224it [05:05, 14.75it/s]Train epoch: 4 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003754\n",
      "6250it [05:07, 14.23it/s]Train epoch: 4 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.004024\n",
      "6274it [05:08, 14.33it/s]Train epoch: 4 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003559\n",
      "6300it [05:10, 14.39it/s]Train epoch: 4 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004224\n",
      "6324it [05:12, 14.04it/s]Train epoch: 4 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.004766\n",
      "6350it [05:14, 13.84it/s]Train epoch: 4 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.004978\n",
      "6374it [05:15, 14.13it/s]Train epoch: 4 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.003811\n",
      "6400it [05:17, 14.13it/s]Train epoch: 4 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004132\n",
      "6424it [05:19, 13.97it/s]Train epoch: 4 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.004670\n",
      "6450it [05:21, 14.19it/s]Train epoch: 4 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004637\n",
      "6474it [05:22, 13.78it/s]Train epoch: 4 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.004108\n",
      "6500it [05:24, 13.75it/s]Train epoch: 4 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004588\n",
      "6524it [05:26, 13.82it/s]Train epoch: 4 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.003968\n",
      "6550it [05:28, 13.73it/s]Train epoch: 4 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004156\n",
      "6574it [05:30, 13.90it/s]Train epoch: 4 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004334\n",
      "6600it [05:32, 14.22it/s]Train epoch: 4 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005313\n",
      "6624it [05:33, 13.87it/s]Train epoch: 4 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004260\n",
      "6650it [05:35, 13.18it/s]Train epoch: 4 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.004801\n",
      "6674it [05:37, 13.33it/s]Train epoch: 4 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004342\n",
      "6700it [05:39, 13.66it/s]Train epoch: 4 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004541\n",
      "6724it [05:41, 13.16it/s]Train epoch: 4 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004519\n",
      "6750it [05:43, 13.79it/s]Train epoch: 4 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004062\n",
      "6774it [05:44, 13.58it/s]Train epoch: 4 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.004775\n",
      "6800it [05:46, 13.25it/s]Train epoch: 4 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.004721\n",
      "6824it [05:48, 12.75it/s]Train epoch: 4 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.004817\n",
      "6850it [05:50, 13.37it/s]Train epoch: 4 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.004635\n",
      "6874it [05:52, 13.72it/s]Train epoch: 4 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.003866\n",
      "6900it [05:54, 13.82it/s]Train epoch: 4 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004384\n",
      "6924it [05:55, 13.72it/s]Train epoch: 4 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004586\n",
      "6950it [05:57, 13.54it/s]Train epoch: 4 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.004983\n",
      "6974it [05:59, 13.29it/s]Train epoch: 4 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004654\n",
      "7000it [06:01, 13.54it/s]Train epoch: 4 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004469\n",
      "7024it [06:03, 13.12it/s]Train epoch: 4 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.004995\n",
      "7050it [06:05, 13.01it/s]Train epoch: 4 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004066\n",
      "7074it [06:07, 13.52it/s]Train epoch: 4 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004339\n",
      "7100it [06:09, 13.01it/s]Train epoch: 4 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.004774\n",
      "7124it [06:11, 13.00it/s]Train epoch: 4 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004190\n",
      "7150it [06:13, 12.93it/s]Train epoch: 4 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.005040\n",
      "7174it [06:14, 12.95it/s]Train epoch: 4 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200it [06:16, 13.06it/s]Train epoch: 4 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.004971\n",
      "7224it [06:18, 13.31it/s]Train epoch: 4 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004442\n",
      "7250it [06:20, 13.13it/s]Train epoch: 4 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004493\n",
      "7274it [06:22, 12.62it/s]Train epoch: 4 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.004994\n",
      "7300it [06:24, 13.01it/s]Train epoch: 4 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005326\n",
      "7324it [06:26, 12.93it/s]Train epoch: 4 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004215\n",
      "7350it [06:28, 12.82it/s]Train epoch: 4 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005253\n",
      "7374it [06:30, 12.51it/s]Train epoch: 4 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.004873\n",
      "7400it [06:32, 12.76it/s]Train epoch: 4 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004359\n",
      "7424it [06:34, 12.52it/s]Train epoch: 4 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.004852\n",
      "7450it [06:36, 12.85it/s]Train epoch: 4 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005316\n",
      "7474it [06:38, 12.29it/s]Train epoch: 4 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004576\n",
      "7500it [06:40, 13.26it/s]Train epoch: 4 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.004816\n",
      "7524it [06:42, 12.75it/s]Train epoch: 4 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004627\n",
      "7550it [06:44, 12.29it/s]Train epoch: 4 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004437\n",
      "7574it [06:46, 12.57it/s]Train epoch: 4 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.004908\n",
      "7600it [06:48, 12.66it/s]Train epoch: 4 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.005808\n",
      "7624it [06:50, 12.37it/s]Train epoch: 4 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005474\n",
      "7650it [06:52, 12.56it/s]Train epoch: 4 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004691\n",
      "7674it [06:54, 12.29it/s]Train epoch: 4 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.004619\n",
      "7700it [06:56, 12.65it/s]Train epoch: 4 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.004763\n",
      "7724it [06:58, 12.50it/s]Train epoch: 4 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.004751\n",
      "7750it [07:00, 12.67it/s]Train epoch: 4 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005137\n",
      "7774it [07:02, 12.55it/s]Train epoch: 4 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004351\n",
      "7800it [07:04, 12.25it/s]Train epoch: 4 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004606\n",
      "7824it [07:06, 12.34it/s]Train epoch: 4 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.004876\n",
      "7850it [07:08, 12.16it/s]Train epoch: 4 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004386\n",
      "7874it [07:10, 12.07it/s]Train epoch: 4 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004651\n",
      "7900it [07:12, 12.12it/s]Train epoch: 4 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.004809\n",
      "7924it [07:14, 12.11it/s]Train epoch: 4 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.004800\n",
      "7950it [07:16, 12.18it/s]Train epoch: 4 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005450\n",
      "7974it [07:18, 12.05it/s]Train epoch: 4 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004536\n",
      "8000it [07:20, 12.17it/s]Train epoch: 4 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004458\n",
      "8024it [07:22, 12.22it/s]Train epoch: 4 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.004956\n",
      "8050it [07:24, 12.16it/s]Train epoch: 4 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004278\n",
      "8074it [07:26, 11.96it/s]Train epoch: 4 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.004726\n",
      "8100it [07:28, 12.27it/s]Train epoch: 4 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005129\n",
      "8124it [07:30, 11.91it/s]Train epoch: 4 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005266\n",
      "8150it [07:32, 11.85it/s]Train epoch: 4 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004551\n",
      "8174it [07:34, 11.75it/s]Train epoch: 4 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005148\n",
      "8200it [07:37, 11.74it/s]Train epoch: 4 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004408\n",
      "8224it [07:39, 11.78it/s]Train epoch: 4 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.005982\n",
      "8250it [07:41, 11.64it/s]Train epoch: 4 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004582\n",
      "8274it [07:43, 11.58it/s]Train epoch: 4 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005227\n",
      "8300it [07:45, 11.87it/s]Train epoch: 4 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004586\n",
      "8324it [07:47, 11.90it/s]Train epoch: 4 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005269\n",
      "8350it [07:49, 11.52it/s]Train epoch: 4 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004511\n",
      "8374it [07:51, 11.23it/s]Train epoch: 4 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005237\n",
      "8400it [07:54, 11.60it/s]Train epoch: 4 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.004860\n",
      "8424it [07:56, 11.49it/s]Train epoch: 4 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.004853\n",
      "8450it [07:58, 11.36it/s]Train epoch: 4 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005176\n",
      "8474it [08:00, 11.50it/s]Train epoch: 4 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.004914\n",
      "8500it [08:02, 11.78it/s]Train epoch: 4 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.005707\n",
      "8524it [08:04, 11.46it/s]Train epoch: 4 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.004978\n",
      "8550it [08:07, 11.49it/s]Train epoch: 4 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005180\n",
      "8574it [08:09, 11.29it/s]Train epoch: 4 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.004766\n",
      "8600it [08:11, 11.69it/s]Train epoch: 4 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.004911\n",
      "8624it [08:13, 11.07it/s]Train epoch: 4 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.005020\n",
      "8650it [08:15, 11.45it/s]Train epoch: 4 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005136\n",
      "8674it [08:18, 11.05it/s]Train epoch: 4 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.005849\n",
      "8700it [08:20, 11.34it/s]Train epoch: 4 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.005798\n",
      "8724it [08:22, 11.03it/s]Train epoch: 4 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005608\n",
      "8750it [08:24, 11.08it/s]Train epoch: 4 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005264\n",
      "8774it [08:27, 10.95it/s]Train epoch: 4 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.004783\n",
      "8800it [08:29, 11.29it/s]Train epoch: 4 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.005036\n",
      "8824it [08:31, 11.27it/s]Train epoch: 4 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.005118\n",
      "8850it [08:33, 11.31it/s]Train epoch: 4 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005150\n",
      "8874it [08:36, 11.09it/s]Train epoch: 4 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.005076\n",
      "8900it [08:38, 10.91it/s]Train epoch: 4 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005158\n",
      "8924it [08:40, 11.08it/s]Train epoch: 4 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005232\n",
      "8950it [08:43, 10.97it/s]Train epoch: 4 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.005903\n",
      "8974it [08:45, 10.92it/s]Train epoch: 4 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005390\n",
      "9000it [08:47, 10.88it/s]Train epoch: 4 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005136\n",
      "9024it [08:49, 10.88it/s]Train epoch: 4 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005309\n",
      "9050it [08:52, 10.70it/s]Train epoch: 4 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.004819\n",
      "9074it [08:54, 10.83it/s]Train epoch: 4 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004560\n",
      "9100it [08:56, 10.85it/s]Train epoch: 4 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005485\n",
      "9124it [08:59, 10.85it/s]Train epoch: 4 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.004996\n",
      "9150it [09:01, 10.65it/s]Train epoch: 4 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004563\n",
      "9174it [09:03, 10.48it/s]Train epoch: 4 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.004893\n",
      "9200it [09:06, 10.76it/s]Train epoch: 4 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.004753\n",
      "9224it [09:08, 10.76it/s]Train epoch: 4 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.005810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9250it [09:10, 10.57it/s]Train epoch: 4 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005083\n",
      "9274it [09:13, 10.56it/s]Train epoch: 4 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005391\n",
      "9300it [09:15, 10.52it/s]Train epoch: 4 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.006053\n",
      "9324it [09:18, 10.01it/s]Train epoch: 4 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.005813\n",
      "9350it [09:20, 10.63it/s]Train epoch: 4 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.005787\n",
      "9374it [09:22, 10.56it/s]Train epoch: 4 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005112\n",
      "9400it [09:25, 10.16it/s]Train epoch: 4 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005386\n",
      "9424it [09:27, 10.21it/s]Train epoch: 4 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005264\n",
      "9450it [09:30, 10.07it/s]Train epoch: 4 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005197\n",
      "9474it [09:32, 10.14it/s]Train epoch: 4 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.005804\n",
      "9500it [09:35, 10.09it/s]Train epoch: 4 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005385\n",
      "9524it [09:37, 10.23it/s]Train epoch: 4 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.005854\n",
      "9549it [09:39, 10.12it/s]Train epoch: 4 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.005600\n",
      "9574it [09:42, 10.16it/s]Train epoch: 4 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.005765\n",
      "9599it [09:44, 10.05it/s]Train epoch: 4 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005574\n",
      "9625it [09:47, 10.39it/s]Train epoch: 4 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005067\n",
      "9649it [09:49, 10.08it/s]Train epoch: 4 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005203\n",
      "9675it [09:52,  9.96it/s]Train epoch: 4 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005437\n",
      "9700it [09:54,  9.94it/s]Train epoch: 4 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.004840\n",
      "9725it [09:57,  9.78it/s]Train epoch: 4 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005298\n",
      "9749it [09:59,  9.79it/s]Train epoch: 4 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005425\n",
      "9775it [10:02,  9.72it/s]Train epoch: 4 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006179\n",
      "9800it [10:05,  9.86it/s]Train epoch: 4 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.005812\n",
      "9824it [10:07,  9.61it/s]Train epoch: 4 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.005968\n",
      "9850it [10:10,  9.66it/s]Train epoch: 4 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005460\n",
      "9875it [10:12,  9.61it/s]Train epoch: 4 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.005874\n",
      "9899it [10:15,  9.47it/s]Train epoch: 4 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006103\n",
      "9925it [10:17,  9.56it/s]Train epoch: 4 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.005869\n",
      "9950it [10:20,  9.59it/s]Train epoch: 4 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006431\n",
      "9975it [10:23,  9.41it/s]Train epoch: 4 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.005895\n",
      "9999it [10:25,  9.00it/s]Train epoch: 4 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005474\n",
      "10025it [10:28,  9.73it/s]Train epoch: 4 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005443\n",
      "10050it [10:31,  9.23it/s]Train epoch: 4 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.005927\n",
      "10075it [10:33,  9.55it/s]Train epoch: 4 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006365\n",
      "10100it [10:36,  9.21it/s]Train epoch: 4 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006066\n",
      "10125it [10:39,  9.27it/s]Train epoch: 4 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005475\n",
      "10150it [10:41,  9.25it/s]Train epoch: 4 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.005964\n",
      "10175it [10:44,  9.07it/s]Train epoch: 4 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005578\n",
      "10200it [10:47,  9.04it/s]Train epoch: 4 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.005983\n",
      "10225it [10:50,  8.79it/s]Train epoch: 4 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006101\n",
      "10250it [10:52,  9.11it/s]Train epoch: 4 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006585\n",
      "10275it [10:55,  8.95it/s]Train epoch: 4 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.005767\n",
      "10300it [10:58,  8.79it/s]Train epoch: 4 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006421\n",
      "10325it [11:01,  8.72it/s]Train epoch: 4 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006222\n",
      "10350it [11:03,  8.94it/s]Train epoch: 4 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.005760\n",
      "10375it [11:06,  8.93it/s]Train epoch: 4 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006044\n",
      "10400it [11:09,  8.77it/s]Train epoch: 4 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.006079\n",
      "10425it [11:12,  8.64it/s]Train epoch: 4 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.005743\n",
      "10450it [11:15,  8.47it/s]Train epoch: 4 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006153\n",
      "10475it [11:18,  8.50it/s]Train epoch: 4 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005340\n",
      "10500it [11:21,  8.43it/s]Train epoch: 4 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006130\n",
      "10525it [11:24,  8.46it/s]Train epoch: 4 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.005874\n",
      "10550it [11:27,  8.21it/s]Train epoch: 4 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006102\n",
      "10575it [11:30,  8.37it/s]Train epoch: 4 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005482\n",
      "10600it [11:33,  8.25it/s]Train epoch: 4 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.005690\n",
      "10625it [11:36,  8.33it/s]Train epoch: 4 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006400\n",
      "10650it [11:39,  8.19it/s]Train epoch: 4 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.005751\n",
      "10675it [11:42,  8.21it/s]Train epoch: 4 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006172\n",
      "10700it [11:45,  8.27it/s]Train epoch: 4 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.005868\n",
      "10725it [11:48,  8.14it/s]Train epoch: 4 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005475\n",
      "10750it [11:51,  8.05it/s]Train epoch: 4 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006412\n",
      "10775it [11:54,  8.18it/s]Train epoch: 4 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006304\n",
      "10800it [11:57,  8.15it/s]Train epoch: 4 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006569\n",
      "10825it [12:00,  7.96it/s]Train epoch: 4 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006443\n",
      "10850it [12:03,  8.23it/s]Train epoch: 4 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006324\n",
      "10875it [12:07,  7.98it/s]Train epoch: 4 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006412\n",
      "10900it [12:10,  8.01it/s]Train epoch: 4 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006181\n",
      "10925it [12:13,  7.79it/s]Train epoch: 4 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005695\n",
      "10950it [12:16,  7.78it/s]Train epoch: 4 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006229\n",
      "10975it [12:19,  7.93it/s]Train epoch: 4 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.006008\n",
      "11000it [12:22,  7.73it/s]Train epoch: 4 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.005981\n",
      "11025it [12:26,  8.40it/s]Train epoch: 4 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006186\n",
      "11050it [12:29,  8.06it/s]Train epoch: 4 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.006949\n",
      "11075it [12:32,  7.94it/s]Train epoch: 4 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006502\n",
      "11100it [12:35,  7.83it/s]Train epoch: 4 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007089\n",
      "11125it [12:38,  7.91it/s]Train epoch: 4 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006558\n",
      "11150it [12:41,  8.02it/s]Train epoch: 4 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006424\n",
      "11175it [12:44,  8.01it/s]Train epoch: 4 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007369\n",
      "11200it [12:48,  7.97it/s]Train epoch: 4 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006710\n",
      "11225it [12:51,  7.90it/s]Train epoch: 4 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006625\n",
      "11250it [12:54,  7.86it/s]Train epoch: 4 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11275it [12:57,  8.05it/s]Train epoch: 4 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.006887\n",
      "11300it [13:00,  7.95it/s]Train epoch: 4 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006387\n",
      "11325it [13:03,  7.77it/s]Train epoch: 4 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007475\n",
      "11350it [13:07,  7.86it/s]Train epoch: 4 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007305\n",
      "11375it [13:10,  8.12it/s]Train epoch: 4 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007464\n",
      "11400it [13:13,  7.96it/s]Train epoch: 4 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006581\n",
      "11425it [13:16,  7.74it/s]Train epoch: 4 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007289\n",
      "11450it [13:19,  8.11it/s]Train epoch: 4 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006425\n",
      "11475it [13:22,  7.83it/s]Train epoch: 4 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007790\n",
      "11500it [13:26,  7.70it/s]Train epoch: 4 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007476\n",
      "11525it [13:29,  8.00it/s]Train epoch: 4 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006884\n",
      "11550it [13:32,  8.14it/s]Train epoch: 4 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.006887\n",
      "11575it [13:35,  7.77it/s]Train epoch: 4 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007823\n",
      "11600it [13:38,  7.84it/s]Train epoch: 4 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007234\n",
      "11625it [13:41,  7.84it/s]Train epoch: 4 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006910\n",
      "11650it [13:44,  7.85it/s]Train epoch: 4 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007267\n",
      "11675it [13:48,  7.77it/s]Train epoch: 4 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007760\n",
      "11700it [13:51,  7.93it/s]Train epoch: 4 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008355\n",
      "11725it [13:54,  7.91it/s]Train epoch: 4 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008233\n",
      "11750it [13:57,  7.86it/s]Train epoch: 4 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.008034\n",
      "11775it [14:00,  7.85it/s]Train epoch: 4 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.008070\n",
      "11800it [14:03,  8.05it/s]Train epoch: 4 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007820\n",
      "11825it [14:07,  7.83it/s]Train epoch: 4 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008150\n",
      "11850it [14:10,  7.96it/s]Train epoch: 4 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008571\n",
      "11875it [14:13,  7.77it/s]Train epoch: 4 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009366\n",
      "11900it [14:16,  7.88it/s]Train epoch: 4 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011251\n",
      "11925it [14:19,  7.69it/s]Train epoch: 4 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009550\n",
      "11930it [14:20, 13.87it/s]\n",
      "epoch loss: 0.004578611122361132\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 129.08it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0367, 0.0532, 0.0576, 0.0553, 0.8809\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3270, 0.5420, 0.4519, 0.4928, 0.9819\n",
      "rec_at_8: 0.3527\n",
      "prec_at_8: 0.6497\n",
      "rec_at_15: 0.4937\n",
      "prec_at_15: 0.5071\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:25, 131.36it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0385, 0.0609, 0.0619, 0.0614, 0.8724\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3221, 0.5352, 0.4472, 0.4873, 0.9817\n",
      "rec_at_8: 0.3378\n",
      "prec_at_8: 0.6454\n",
      "rec_at_15: 0.4740\n",
      "prec_at_15: 0.5066\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0367, 0.0532, 0.0576, 0.0553, 0.8809\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3270, 0.5420, 0.4519, 0.4928, 0.9819\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0067\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0385, 0.0609, 0.0619, 0.0614, 0.8724\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3221, 0.5352, 0.4472, 0.4873, 0.9817\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0070\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "\n",
      "EPOCH 5\n",
      "0it [00:00, ?it/s]Train epoch: 5 [batch #0, batch_size 4, seq length 68]\tLoss: 0.006077\n",
      "20it [00:00, 43.56it/s]Train epoch: 5 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003698\n",
      "47it [00:01, 45.11it/s]Train epoch: 5 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003485\n",
      "72it [00:01, 40.17it/s]Train epoch: 5 [batch #75, batch_size 4, seq length 307]\tLoss: 0.002821\n",
      "97it [00:02, 40.64it/s]Train epoch: 5 [batch #100, batch_size 4, seq length 333]\tLoss: 0.002988\n",
      "124it [00:02, 38.18it/s]Train epoch: 5 [batch #125, batch_size 4, seq length 354]\tLoss: 0.002931\n",
      "149it [00:03, 37.19it/s]Train epoch: 5 [batch #150, batch_size 4, seq length 370]\tLoss: 0.002763\n",
      "175it [00:04, 36.42it/s]Train epoch: 5 [batch #175, batch_size 4, seq length 386]\tLoss: 0.002866\n",
      "199it [00:05, 34.08it/s]Train epoch: 5 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002834\n",
      "224it [00:05, 37.16it/s]Train epoch: 5 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003445\n",
      "248it [00:06, 34.74it/s]Train epoch: 5 [batch #250, batch_size 4, seq length 428]\tLoss: 0.002800\n",
      "272it [00:07, 35.31it/s]Train epoch: 5 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002437\n",
      "300it [00:07, 34.95it/s]Train epoch: 5 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003145\n",
      "324it [00:08, 31.99it/s]Train epoch: 5 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002584\n",
      "348it [00:09, 32.91it/s]Train epoch: 5 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003149\n",
      "372it [00:10, 34.82it/s]Train epoch: 5 [batch #375, batch_size 4, seq length 480]\tLoss: 0.002936\n",
      "400it [00:10, 32.09it/s]Train epoch: 5 [batch #400, batch_size 4, seq length 489]\tLoss: 0.002973\n",
      "423it [00:11, 29.60it/s]Train epoch: 5 [batch #425, batch_size 4, seq length 497]\tLoss: 0.002909\n",
      "447it [00:12, 31.85it/s]Train epoch: 5 [batch #450, batch_size 4, seq length 504]\tLoss: 0.002921\n",
      "475it [00:13, 31.90it/s]Train epoch: 5 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003266\n",
      "500it [00:14, 28.69it/s]Train epoch: 5 [batch #500, batch_size 4, seq length 519]\tLoss: 0.002787\n",
      "525it [00:15, 31.34it/s]Train epoch: 5 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003022\n",
      "549it [00:15, 31.52it/s]Train epoch: 5 [batch #550, batch_size 4, seq length 534]\tLoss: 0.002927\n",
      "573it [00:16, 29.93it/s]Train epoch: 5 [batch #575, batch_size 4, seq length 541]\tLoss: 0.002949\n",
      "600it [00:17, 29.80it/s]Train epoch: 5 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003242\n",
      "623it [00:18, 28.14it/s]Train epoch: 5 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003209\n",
      "650it [00:19, 29.58it/s]Train epoch: 5 [batch #650, batch_size 4, seq length 559]\tLoss: 0.002850\n",
      "675it [00:20, 29.55it/s]Train epoch: 5 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002356\n",
      "697it [00:20, 29.11it/s]Train epoch: 5 [batch #700, batch_size 4, seq length 573]\tLoss: 0.002912\n",
      "723it [00:21, 29.07it/s]Train epoch: 5 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003081\n",
      "749it [00:22, 27.58it/s]Train epoch: 5 [batch #750, batch_size 4, seq length 584]\tLoss: 0.002848\n",
      "775it [00:23, 30.77it/s]Train epoch: 5 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003221\n",
      "799it [00:24, 27.92it/s]Train epoch: 5 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003058\n",
      "824it [00:25, 28.15it/s]Train epoch: 5 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003020\n",
      "848it [00:26, 29.52it/s]Train epoch: 5 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003370\n",
      "875it [00:27, 26.74it/s]Train epoch: 5 [batch #875, batch_size 4, seq length 612]\tLoss: 0.002825\n",
      "898it [00:27, 27.96it/s]Train epoch: 5 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003190\n",
      "923it [00:28, 29.14it/s]Train epoch: 5 [batch #925, batch_size 4, seq length 622]\tLoss: 0.002911\n",
      "948it [00:29, 28.89it/s]Train epoch: 5 [batch #950, batch_size 4, seq length 627]\tLoss: 0.002895\n",
      "975it [00:30, 28.75it/s]Train epoch: 5 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000it [00:31, 26.93it/s]Train epoch: 5 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003057\n",
      "1025it [00:32, 28.31it/s]Train epoch: 5 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004157\n",
      "1050it [00:33, 27.79it/s]Train epoch: 5 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.002858\n",
      "1075it [00:34, 26.62it/s]Train epoch: 5 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003228\n",
      "1099it [00:35, 27.78it/s]Train epoch: 5 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003288\n",
      "1124it [00:36, 26.10it/s]Train epoch: 5 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003251\n",
      "1150it [00:36, 26.82it/s]Train epoch: 5 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003262\n",
      "1172it [00:37, 27.61it/s]Train epoch: 5 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003219\n",
      "1200it [00:38, 26.44it/s]Train epoch: 5 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003291\n",
      "1222it [00:39, 27.24it/s]Train epoch: 5 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003416\n",
      "1250it [00:40, 26.38it/s]Train epoch: 5 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003205\n",
      "1274it [00:41, 26.13it/s]Train epoch: 5 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.002791\n",
      "1298it [00:42, 28.20it/s]Train epoch: 5 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.002852\n",
      "1323it [00:43, 27.36it/s]Train epoch: 5 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.002931\n",
      "1348it [00:44, 26.16it/s]Train epoch: 5 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.003855\n",
      "1373it [00:45, 25.80it/s]Train epoch: 5 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003155\n",
      "1398it [00:46, 26.15it/s]Train epoch: 5 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003167\n",
      "1425it [00:47, 26.35it/s]Train epoch: 5 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.002784\n",
      "1449it [00:48, 25.70it/s]Train epoch: 5 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.002985\n",
      "1474it [00:49, 25.69it/s]Train epoch: 5 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003191\n",
      "1498it [00:50, 26.83it/s]Train epoch: 5 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004335\n",
      "1525it [00:51, 25.53it/s]Train epoch: 5 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.003946\n",
      "1550it [00:52, 25.94it/s]Train epoch: 5 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.003013\n",
      "1574it [00:52, 25.76it/s]Train epoch: 5 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003278\n",
      "1598it [00:53, 24.83it/s]Train epoch: 5 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.002951\n",
      "1625it [00:54, 26.73it/s]Train epoch: 5 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003476\n",
      "1649it [00:55, 23.94it/s]Train epoch: 5 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003564\n",
      "1673it [00:56, 25.32it/s]Train epoch: 5 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003518\n",
      "1700it [00:57, 24.46it/s]Train epoch: 5 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.002905\n",
      "1724it [00:58, 26.57it/s]Train epoch: 5 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002626\n",
      "1748it [00:59, 26.48it/s]Train epoch: 5 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.003915\n",
      "1775it [01:00, 25.31it/s]Train epoch: 5 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003303\n",
      "1799it [01:01, 24.87it/s]Train epoch: 5 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003166\n",
      "1823it [01:02, 24.01it/s]Train epoch: 5 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002664\n",
      "1850it [01:03, 25.21it/s]Train epoch: 5 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003313\n",
      "1874it [01:04, 24.92it/s]Train epoch: 5 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003592\n",
      "1898it [01:05, 26.14it/s]Train epoch: 5 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002608\n",
      "1925it [01:06, 24.32it/s]Train epoch: 5 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.002842\n",
      "1949it [01:07, 24.99it/s]Train epoch: 5 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.002775\n",
      "1973it [01:08, 24.62it/s]Train epoch: 5 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003387\n",
      "2000it [01:09, 25.09it/s]Train epoch: 5 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002653\n",
      "2024it [01:10, 23.39it/s]Train epoch: 5 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003243\n",
      "2048it [01:11, 23.98it/s]Train epoch: 5 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003047\n",
      "2075it [01:13, 24.48it/s]Train epoch: 5 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003269\n",
      "2099it [01:14, 22.02it/s]Train epoch: 5 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003297\n",
      "2123it [01:15, 23.95it/s]Train epoch: 5 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003607\n",
      "2150it [01:16, 22.60it/s]Train epoch: 5 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003100\n",
      "2174it [01:17, 24.52it/s]Train epoch: 5 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003443\n",
      "2198it [01:18, 25.14it/s]Train epoch: 5 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003237\n",
      "2225it [01:19, 24.51it/s]Train epoch: 5 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003221\n",
      "2249it [01:20, 23.64it/s]Train epoch: 5 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.002933\n",
      "2273it [01:21, 23.65it/s]Train epoch: 5 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003404\n",
      "2300it [01:22, 24.52it/s]Train epoch: 5 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002540\n",
      "2324it [01:23, 23.38it/s]Train epoch: 5 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003202\n",
      "2348it [01:24, 24.63it/s]Train epoch: 5 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.002854\n",
      "2375it [01:25, 23.93it/s]Train epoch: 5 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004136\n",
      "2399it [01:26, 23.34it/s]Train epoch: 5 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.003895\n",
      "2423it [01:27, 24.49it/s]Train epoch: 5 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002697\n",
      "2450it [01:28, 23.56it/s]Train epoch: 5 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003129\n",
      "2474it [01:29, 23.79it/s]Train epoch: 5 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003573\n",
      "2498it [01:30, 23.46it/s]Train epoch: 5 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.002994\n",
      "2525it [01:31, 21.65it/s]Train epoch: 5 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.003001\n",
      "2549it [01:33, 22.86it/s]Train epoch: 5 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004303\n",
      "2573it [01:34, 21.85it/s]Train epoch: 5 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.002976\n",
      "2600it [01:35, 21.74it/s]Train epoch: 5 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003261\n",
      "2624it [01:36, 24.17it/s]Train epoch: 5 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003263\n",
      "2648it [01:37, 23.00it/s]Train epoch: 5 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.003856\n",
      "2675it [01:38, 23.21it/s]Train epoch: 5 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003370\n",
      "2699it [01:39, 21.75it/s]Train epoch: 5 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.002939\n",
      "2723it [01:40, 21.51it/s]Train epoch: 5 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003168\n",
      "2750it [01:41, 23.11it/s]Train epoch: 5 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.003803\n",
      "2774it [01:43, 22.34it/s]Train epoch: 5 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003322\n",
      "2798it [01:44, 23.91it/s]Train epoch: 5 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003121\n",
      "2825it [01:45, 22.33it/s]Train epoch: 5 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003511\n",
      "2849it [01:46, 21.92it/s]Train epoch: 5 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003254\n",
      "2873it [01:47, 21.01it/s]Train epoch: 5 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003624\n",
      "2900it [01:48, 21.49it/s]Train epoch: 5 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003434\n",
      "2924it [01:49, 22.70it/s]Train epoch: 5 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003599\n",
      "2948it [01:50, 21.78it/s]Train epoch: 5 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.003741\n",
      "2975it [01:52, 21.85it/s]Train epoch: 5 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003458\n",
      "2999it [01:53, 21.88it/s]Train epoch: 5 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.004047\n",
      "3023it [01:54, 22.19it/s]Train epoch: 5 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003746\n",
      "3050it [01:55, 21.51it/s]Train epoch: 5 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3074it [01:56, 20.96it/s]Train epoch: 5 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003695\n",
      "3098it [01:57, 21.78it/s]Train epoch: 5 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003565\n",
      "3125it [01:58, 21.40it/s]Train epoch: 5 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003398\n",
      "3149it [01:59, 22.54it/s]Train epoch: 5 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003238\n",
      "3173it [02:01, 20.50it/s]Train epoch: 5 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003228\n",
      "3200it [02:02, 21.10it/s]Train epoch: 5 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.003777\n",
      "3224it [02:03, 20.53it/s]Train epoch: 5 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.003700\n",
      "3248it [02:04, 21.72it/s]Train epoch: 5 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.003628\n",
      "3275it [02:05, 21.32it/s]Train epoch: 5 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003221\n",
      "3299it [02:07, 21.50it/s]Train epoch: 5 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004154\n",
      "3323it [02:08, 20.49it/s]Train epoch: 5 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003470\n",
      "3350it [02:09, 20.77it/s]Train epoch: 5 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003479\n",
      "3374it [02:10, 21.38it/s]Train epoch: 5 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.003719\n",
      "3398it [02:11, 21.67it/s]Train epoch: 5 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.003780\n",
      "3425it [02:13, 21.79it/s]Train epoch: 5 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003290\n",
      "3449it [02:14, 21.13it/s]Train epoch: 5 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.003766\n",
      "3473it [02:15, 21.02it/s]Train epoch: 5 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003411\n",
      "3500it [02:16, 21.15it/s]Train epoch: 5 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003507\n",
      "3524it [02:17, 20.84it/s]Train epoch: 5 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003566\n",
      "3548it [02:18, 20.90it/s]Train epoch: 5 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.003840\n",
      "3575it [02:20, 21.76it/s]Train epoch: 5 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003109\n",
      "3599it [02:21, 22.43it/s]Train epoch: 5 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.004067\n",
      "3623it [02:22, 21.47it/s]Train epoch: 5 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.003662\n",
      "3649it [02:23, 18.81it/s]Train epoch: 5 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.003869\n",
      "3675it [02:25, 17.82it/s]Train epoch: 5 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.003805\n",
      "3700it [02:26, 18.23it/s]Train epoch: 5 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.003690\n",
      "3725it [02:27, 18.56it/s]Train epoch: 5 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.003954\n",
      "3749it [02:29, 17.75it/s]Train epoch: 5 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.003837\n",
      "3774it [02:30, 17.22it/s]Train epoch: 5 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.003744\n",
      "3800it [02:32, 17.97it/s]Train epoch: 5 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004088\n",
      "3824it [02:33, 18.19it/s]Train epoch: 5 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003497\n",
      "3849it [02:34, 18.46it/s]Train epoch: 5 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003230\n",
      "3875it [02:36, 17.96it/s]Train epoch: 5 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003171\n",
      "3899it [02:37, 17.60it/s]Train epoch: 5 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004139\n",
      "3925it [02:39, 17.36it/s]Train epoch: 5 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.003824\n",
      "3949it [02:40, 16.57it/s]Train epoch: 5 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004099\n",
      "3975it [02:42, 17.06it/s]Train epoch: 5 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.004525\n",
      "3999it [02:43, 17.02it/s]Train epoch: 5 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003475\n",
      "4024it [02:44, 17.80it/s]Train epoch: 5 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004369\n",
      "4050it [02:46, 17.66it/s]Train epoch: 5 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.003951\n",
      "4074it [02:47, 16.55it/s]Train epoch: 5 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.003951\n",
      "4099it [02:49, 17.81it/s]Train epoch: 5 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004336\n",
      "4125it [02:50, 17.24it/s]Train epoch: 5 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.004106\n",
      "4149it [02:52, 17.17it/s]Train epoch: 5 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003531\n",
      "4174it [02:53, 18.33it/s]Train epoch: 5 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.003824\n",
      "4200it [02:55, 16.59it/s]Train epoch: 5 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004140\n",
      "4224it [02:56, 17.03it/s]Train epoch: 5 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003550\n",
      "4249it [02:57, 17.46it/s]Train epoch: 5 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004067\n",
      "4275it [02:59, 16.38it/s]Train epoch: 5 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.003661\n",
      "4300it [03:00, 17.26it/s]Train epoch: 5 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004401\n",
      "4324it [03:02, 17.49it/s]Train epoch: 5 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.003761\n",
      "4350it [03:03, 16.98it/s]Train epoch: 5 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004166\n",
      "4374it [03:05, 17.12it/s]Train epoch: 5 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.003718\n",
      "4400it [03:06, 17.71it/s]Train epoch: 5 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003167\n",
      "4424it [03:08, 16.84it/s]Train epoch: 5 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.003962\n",
      "4450it [03:09, 17.10it/s]Train epoch: 5 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003266\n",
      "4474it [03:11, 16.98it/s]Train epoch: 5 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004113\n",
      "4500it [03:12, 16.34it/s]Train epoch: 5 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.004678\n",
      "4524it [03:14, 16.21it/s]Train epoch: 5 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004071\n",
      "4550it [03:15, 16.93it/s]Train epoch: 5 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.003872\n",
      "4574it [03:17, 17.01it/s]Train epoch: 5 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004277\n",
      "4600it [03:18, 16.03it/s]Train epoch: 5 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.003657\n",
      "4624it [03:20, 16.42it/s]Train epoch: 5 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.003633\n",
      "4650it [03:21, 16.26it/s]Train epoch: 5 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004311\n",
      "4674it [03:23, 16.49it/s]Train epoch: 5 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004115\n",
      "4700it [03:24, 15.61it/s]Train epoch: 5 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003579\n",
      "4724it [03:26, 16.08it/s]Train epoch: 5 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.003832\n",
      "4750it [03:28, 15.85it/s]Train epoch: 5 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004383\n",
      "4774it [03:29, 16.02it/s]Train epoch: 5 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.003928\n",
      "4800it [03:31, 15.36it/s]Train epoch: 5 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004086\n",
      "4824it [03:32, 15.84it/s]Train epoch: 5 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003561\n",
      "4850it [03:34, 15.96it/s]Train epoch: 5 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004194\n",
      "4874it [03:35, 15.11it/s]Train epoch: 5 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003698\n",
      "4900it [03:37, 15.47it/s]Train epoch: 5 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.003835\n",
      "4924it [03:39, 15.85it/s]Train epoch: 5 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003524\n",
      "4950it [03:40, 16.11it/s]Train epoch: 5 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.003912\n",
      "4974it [03:42, 15.22it/s]Train epoch: 5 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.004008\n",
      "5000it [03:44, 15.38it/s]Train epoch: 5 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.003907\n",
      "5024it [03:45, 15.23it/s]Train epoch: 5 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.003754\n",
      "5050it [03:47, 15.54it/s]Train epoch: 5 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.003663\n",
      "5074it [03:48, 15.30it/s]Train epoch: 5 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.003906\n",
      "5100it [03:50, 15.53it/s]Train epoch: 5 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5124it [03:52, 15.29it/s]Train epoch: 5 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004165\n",
      "5150it [03:53, 15.40it/s]Train epoch: 5 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004222\n",
      "5174it [03:55, 15.58it/s]Train epoch: 5 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004077\n",
      "5200it [03:56, 15.20it/s]Train epoch: 5 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.003757\n",
      "5224it [03:58, 15.23it/s]Train epoch: 5 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.003947\n",
      "5250it [04:00, 15.35it/s]Train epoch: 5 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.003976\n",
      "5274it [04:01, 15.11it/s]Train epoch: 5 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.003849\n",
      "5300it [04:03, 15.13it/s]Train epoch: 5 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.003648\n",
      "5324it [04:05, 15.98it/s]Train epoch: 5 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004189\n",
      "5350it [04:06, 15.11it/s]Train epoch: 5 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004202\n",
      "5374it [04:08, 15.11it/s]Train epoch: 5 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.003893\n",
      "5400it [04:10, 15.20it/s]Train epoch: 5 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.003784\n",
      "5424it [04:11, 15.26it/s]Train epoch: 5 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004234\n",
      "5450it [04:13, 14.86it/s]Train epoch: 5 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004018\n",
      "5474it [04:15, 15.18it/s]Train epoch: 5 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.004616\n",
      "5500it [04:16, 14.93it/s]Train epoch: 5 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004319\n",
      "5524it [04:18, 15.82it/s]Train epoch: 5 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003570\n",
      "5550it [04:20, 14.49it/s]Train epoch: 5 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004143\n",
      "5574it [04:21, 15.06it/s]Train epoch: 5 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004226\n",
      "5600it [04:23, 15.03it/s]Train epoch: 5 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004424\n",
      "5624it [04:25, 15.14it/s]Train epoch: 5 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004132\n",
      "5650it [04:26, 15.29it/s]Train epoch: 5 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.003744\n",
      "5674it [04:28, 14.96it/s]Train epoch: 5 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.004591\n",
      "5700it [04:30, 15.18it/s]Train epoch: 5 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.004049\n",
      "5724it [04:31, 15.01it/s]Train epoch: 5 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004109\n",
      "5750it [04:33, 15.00it/s]Train epoch: 5 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005223\n",
      "5774it [04:35, 14.99it/s]Train epoch: 5 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004283\n",
      "5800it [04:36, 15.03it/s]Train epoch: 5 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004343\n",
      "5824it [04:38, 14.72it/s]Train epoch: 5 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.003876\n",
      "5850it [04:40, 14.75it/s]Train epoch: 5 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.004941\n",
      "5874it [04:41, 14.66it/s]Train epoch: 5 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.004815\n",
      "5900it [04:43, 14.69it/s]Train epoch: 5 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.004740\n",
      "5924it [04:45, 14.49it/s]Train epoch: 5 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.003911\n",
      "5950it [04:47, 14.63it/s]Train epoch: 5 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.003798\n",
      "5974it [04:48, 14.30it/s]Train epoch: 5 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005202\n",
      "6000it [04:50, 14.53it/s]Train epoch: 5 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004337\n",
      "6024it [04:52, 14.73it/s]Train epoch: 5 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.004656\n",
      "6050it [04:53, 14.50it/s]Train epoch: 5 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004155\n",
      "6074it [04:55, 14.46it/s]Train epoch: 5 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.003770\n",
      "6100it [04:57, 14.60it/s]Train epoch: 5 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.003890\n",
      "6124it [04:59, 13.91it/s]Train epoch: 5 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004238\n",
      "6150it [05:00, 14.11it/s]Train epoch: 5 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004191\n",
      "6174it [05:02, 14.38it/s]Train epoch: 5 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.004739\n",
      "6200it [05:04, 14.80it/s]Train epoch: 5 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004227\n",
      "6224it [05:06, 14.19it/s]Train epoch: 5 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003667\n",
      "6250it [05:07, 14.09it/s]Train epoch: 5 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.003985\n",
      "6274it [05:09, 14.05it/s]Train epoch: 5 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003550\n",
      "6300it [05:11, 13.56it/s]Train epoch: 5 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004182\n",
      "6324it [05:13, 13.32it/s]Train epoch: 5 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.004684\n",
      "6350it [05:15, 13.46it/s]Train epoch: 5 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.004906\n",
      "6374it [05:16, 13.76it/s]Train epoch: 5 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.003732\n",
      "6400it [05:18, 12.58it/s]Train epoch: 5 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.004122\n",
      "6424it [05:20, 13.56it/s]Train epoch: 5 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.004603\n",
      "6450it [05:22, 12.74it/s]Train epoch: 5 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004618\n",
      "6474it [05:24, 12.58it/s]Train epoch: 5 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.003997\n",
      "6500it [05:26, 12.86it/s]Train epoch: 5 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004567\n",
      "6524it [05:28, 13.99it/s]Train epoch: 5 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.003943\n",
      "6550it [05:30, 13.88it/s]Train epoch: 5 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.004082\n",
      "6574it [05:31, 13.88it/s]Train epoch: 5 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004218\n",
      "6600it [05:33, 13.78it/s]Train epoch: 5 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005170\n",
      "6624it [05:35, 13.21it/s]Train epoch: 5 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004198\n",
      "6650it [05:37, 13.32it/s]Train epoch: 5 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.004662\n",
      "6674it [05:39, 13.39it/s]Train epoch: 5 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004285\n",
      "6700it [05:41, 13.13it/s]Train epoch: 5 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004461\n",
      "6724it [05:43, 13.32it/s]Train epoch: 5 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004449\n",
      "6750it [05:45, 12.31it/s]Train epoch: 5 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.004037\n",
      "6774it [05:47, 12.36it/s]Train epoch: 5 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.004599\n",
      "6800it [05:49, 12.07it/s]Train epoch: 5 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.004726\n",
      "6824it [05:51, 12.17it/s]Train epoch: 5 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.004755\n",
      "6850it [05:53, 12.74it/s]Train epoch: 5 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.004552\n",
      "6874it [05:55, 12.23it/s]Train epoch: 5 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.003808\n",
      "6900it [05:57, 13.03it/s]Train epoch: 5 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004320\n",
      "6924it [05:59, 12.23it/s]Train epoch: 5 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004575\n",
      "6950it [06:01, 12.60it/s]Train epoch: 5 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.004915\n",
      "6974it [06:03, 12.30it/s]Train epoch: 5 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004557\n",
      "7000it [06:05, 11.91it/s]Train epoch: 5 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004433\n",
      "7024it [06:07, 12.66it/s]Train epoch: 5 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.005003\n",
      "7050it [06:09, 12.12it/s]Train epoch: 5 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.004065\n",
      "7074it [06:11, 12.16it/s]Train epoch: 5 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004356\n",
      "7100it [06:13, 12.79it/s]Train epoch: 5 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.004629\n",
      "7124it [06:15, 11.99it/s]Train epoch: 5 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004162\n",
      "7150it [06:17, 13.15it/s]Train epoch: 5 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.004953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7174it [06:19, 12.29it/s]Train epoch: 5 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004570\n",
      "7200it [06:21, 11.77it/s]Train epoch: 5 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.004887\n",
      "7224it [06:23, 12.32it/s]Train epoch: 5 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004326\n",
      "7250it [06:25, 11.87it/s]Train epoch: 5 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004444\n",
      "7274it [06:27, 12.72it/s]Train epoch: 5 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.004936\n",
      "7300it [06:29, 12.32it/s]Train epoch: 5 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005303\n",
      "7324it [06:31, 11.68it/s]Train epoch: 5 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004240\n",
      "7350it [06:33, 11.92it/s]Train epoch: 5 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005221\n",
      "7374it [06:35, 11.38it/s]Train epoch: 5 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.004836\n",
      "7400it [06:38, 12.24it/s]Train epoch: 5 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004266\n",
      "7424it [06:40, 11.51it/s]Train epoch: 5 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.004721\n",
      "7450it [06:42, 12.29it/s]Train epoch: 5 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005158\n",
      "7474it [06:44, 12.99it/s]Train epoch: 5 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004458\n",
      "7500it [06:46, 12.34it/s]Train epoch: 5 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.004763\n",
      "7524it [06:48, 11.96it/s]Train epoch: 5 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004501\n",
      "7550it [06:50, 12.43it/s]Train epoch: 5 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004465\n",
      "7574it [06:52, 12.10it/s]Train epoch: 5 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.004921\n",
      "7600it [06:54, 12.29it/s]Train epoch: 5 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.005770\n",
      "7624it [06:56, 12.67it/s]Train epoch: 5 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005411\n",
      "7650it [06:58, 12.26it/s]Train epoch: 5 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004648\n",
      "7674it [07:00, 12.38it/s]Train epoch: 5 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.004548\n",
      "7700it [07:02, 12.05it/s]Train epoch: 5 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.004595\n",
      "7724it [07:04, 12.15it/s]Train epoch: 5 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.004732\n",
      "7750it [07:06, 12.22it/s]Train epoch: 5 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.005046\n",
      "7774it [07:08, 11.95it/s]Train epoch: 5 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004390\n",
      "7800it [07:10, 11.77it/s]Train epoch: 5 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004554\n",
      "7824it [07:12, 12.17it/s]Train epoch: 5 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.004792\n",
      "7850it [07:15, 11.75it/s]Train epoch: 5 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004320\n",
      "7874it [07:17, 11.69it/s]Train epoch: 5 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004590\n",
      "7900it [07:19, 11.53it/s]Train epoch: 5 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.004698\n",
      "7924it [07:21, 12.05it/s]Train epoch: 5 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.004754\n",
      "7950it [07:23, 11.98it/s]Train epoch: 5 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005405\n",
      "7974it [07:25, 11.93it/s]Train epoch: 5 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004530\n",
      "8000it [07:27, 11.43it/s]Train epoch: 5 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004409\n",
      "8024it [07:29, 12.03it/s]Train epoch: 5 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.004907\n",
      "8050it [07:32, 11.65it/s]Train epoch: 5 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004244\n",
      "8074it [07:34, 11.69it/s]Train epoch: 5 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.004724\n",
      "8100it [07:36, 11.61it/s]Train epoch: 5 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.005073\n",
      "8124it [07:38, 11.43it/s]Train epoch: 5 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005109\n",
      "8150it [07:40, 11.90it/s]Train epoch: 5 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004446\n",
      "8174it [07:42, 10.99it/s]Train epoch: 5 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005100\n",
      "8200it [07:45, 11.33it/s]Train epoch: 5 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004369\n",
      "8224it [07:47, 10.96it/s]Train epoch: 5 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.005888\n",
      "8250it [07:49, 11.19it/s]Train epoch: 5 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004524\n",
      "8274it [07:51, 11.24it/s]Train epoch: 5 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005160\n",
      "8300it [07:54, 11.64it/s]Train epoch: 5 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004598\n",
      "8324it [07:56, 11.40it/s]Train epoch: 5 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005183\n",
      "8350it [07:58, 11.23it/s]Train epoch: 5 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004440\n",
      "8374it [08:00, 11.36it/s]Train epoch: 5 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005168\n",
      "8400it [08:03, 11.26it/s]Train epoch: 5 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.004777\n",
      "8424it [08:05, 11.63it/s]Train epoch: 5 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.004754\n",
      "8450it [08:07, 11.46it/s]Train epoch: 5 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005176\n",
      "8474it [08:09, 11.22it/s]Train epoch: 5 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.004823\n",
      "8500it [08:11, 11.39it/s]Train epoch: 5 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.005622\n",
      "8524it [08:14, 11.29it/s]Train epoch: 5 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.004820\n",
      "8550it [08:16, 11.11it/s]Train epoch: 5 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005122\n",
      "8574it [08:18, 11.10it/s]Train epoch: 5 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.004634\n",
      "8600it [08:20, 11.27it/s]Train epoch: 5 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.004816\n",
      "8624it [08:22, 11.28it/s]Train epoch: 5 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.004954\n",
      "8650it [08:25, 10.97it/s]Train epoch: 5 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005075\n",
      "8674it [08:27, 11.22it/s]Train epoch: 5 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.005745\n",
      "8700it [08:29, 11.11it/s]Train epoch: 5 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.005731\n",
      "8724it [08:31, 11.28it/s]Train epoch: 5 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005553\n",
      "8750it [08:34, 10.88it/s]Train epoch: 5 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005168\n",
      "8774it [08:36, 10.85it/s]Train epoch: 5 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.004660\n",
      "8800it [08:38, 10.97it/s]Train epoch: 5 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.004976\n",
      "8824it [08:41, 11.35it/s]Train epoch: 5 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.004981\n",
      "8850it [08:43, 10.77it/s]Train epoch: 5 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005074\n",
      "8874it [08:45, 10.72it/s]Train epoch: 5 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.004975\n",
      "8900it [08:48, 10.92it/s]Train epoch: 5 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005121\n",
      "8924it [08:50, 10.80it/s]Train epoch: 5 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005189\n",
      "8950it [08:52, 10.78it/s]Train epoch: 5 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.005835\n",
      "8974it [08:54, 10.17it/s]Train epoch: 5 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005326\n",
      "9000it [08:57, 11.10it/s]Train epoch: 5 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.005037\n",
      "9024it [08:59, 10.71it/s]Train epoch: 5 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005229\n",
      "9050it [09:02, 10.41it/s]Train epoch: 5 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.004765\n",
      "9074it [09:04, 10.71it/s]Train epoch: 5 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004521\n",
      "9100it [09:06, 10.74it/s]Train epoch: 5 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005340\n",
      "9124it [09:09, 10.42it/s]Train epoch: 5 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.004955\n",
      "9150it [09:11, 10.40it/s]Train epoch: 5 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004557\n",
      "9174it [09:13, 10.48it/s]Train epoch: 5 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.004836\n",
      "9200it [09:16, 10.32it/s]Train epoch: 5 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.004710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9224it [09:18, 10.45it/s]Train epoch: 5 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.005731\n",
      "9250it [09:21, 10.17it/s]Train epoch: 5 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.005026\n",
      "9274it [09:23, 10.64it/s]Train epoch: 5 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005314\n",
      "9300it [09:25, 10.48it/s]Train epoch: 5 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.005924\n",
      "9324it [09:28, 10.28it/s]Train epoch: 5 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.005707\n",
      "9350it [09:30, 10.18it/s]Train epoch: 5 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.005681\n",
      "9374it [09:33, 10.47it/s]Train epoch: 5 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.005025\n",
      "9400it [09:35, 10.38it/s]Train epoch: 5 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005330\n",
      "9424it [09:37, 10.17it/s]Train epoch: 5 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005147\n",
      "9450it [09:40, 10.06it/s]Train epoch: 5 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005108\n",
      "9475it [09:43, 10.26it/s]Train epoch: 5 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.005728\n",
      "9500it [09:45, 10.18it/s]Train epoch: 5 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005335\n",
      "9525it [09:47,  9.93it/s]Train epoch: 5 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.005786\n",
      "9549it [09:50,  9.75it/s]Train epoch: 5 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.005490\n",
      "9575it [09:53,  9.86it/s]Train epoch: 5 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.005646\n",
      "9600it [09:55, 10.01it/s]Train epoch: 5 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005559\n",
      "9624it [09:57,  9.77it/s]Train epoch: 5 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.005023\n",
      "9650it [10:00,  9.97it/s]Train epoch: 5 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005108\n",
      "9675it [10:03,  9.77it/s]Train epoch: 5 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005391\n",
      "9700it [10:05,  9.82it/s]Train epoch: 5 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.004809\n",
      "9724it [10:08,  9.73it/s]Train epoch: 5 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005293\n",
      "9749it [10:10,  9.32it/s]Train epoch: 5 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005385\n",
      "9775it [10:13,  9.69it/s]Train epoch: 5 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006089\n",
      "9800it [10:16,  9.47it/s]Train epoch: 5 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.005687\n",
      "9825it [10:18,  9.64it/s]Train epoch: 5 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.005862\n",
      "9850it [10:21,  9.20it/s]Train epoch: 5 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005393\n",
      "9875it [10:23,  9.08it/s]Train epoch: 5 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.005707\n",
      "9900it [10:26,  9.41it/s]Train epoch: 5 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006105\n",
      "9925it [10:29,  9.35it/s]Train epoch: 5 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.005770\n",
      "9950it [10:31,  9.25it/s]Train epoch: 5 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006322\n",
      "9975it [10:34,  9.27it/s]Train epoch: 5 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.005835\n",
      "10000it [10:37,  9.37it/s]Train epoch: 5 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005374\n",
      "10025it [10:39,  9.04it/s]Train epoch: 5 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005342\n",
      "10050it [10:42,  9.24it/s]Train epoch: 5 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.005865\n",
      "10074it [10:45,  9.34it/s]Train epoch: 5 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006290\n",
      "10100it [10:48,  8.96it/s]Train epoch: 5 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.006035\n",
      "10125it [10:50,  8.73it/s]Train epoch: 5 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005395\n",
      "10150it [10:53,  8.88it/s]Train epoch: 5 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.005894\n",
      "10175it [10:56,  8.91it/s]Train epoch: 5 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005500\n",
      "10200it [10:59,  8.81it/s]Train epoch: 5 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.005959\n",
      "10225it [11:02,  8.94it/s]Train epoch: 5 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.006003\n",
      "10250it [11:04,  8.95it/s]Train epoch: 5 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006479\n",
      "10275it [11:07,  8.64it/s]Train epoch: 5 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.005682\n",
      "10300it [11:10,  8.87it/s]Train epoch: 5 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006327\n",
      "10325it [11:13,  8.73it/s]Train epoch: 5 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006061\n",
      "10350it [11:16,  8.69it/s]Train epoch: 5 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.005670\n",
      "10375it [11:19,  8.72it/s]Train epoch: 5 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.006017\n",
      "10400it [11:21,  8.49it/s]Train epoch: 5 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.005928\n",
      "10425it [11:24,  8.78it/s]Train epoch: 5 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.005678\n",
      "10450it [11:27,  8.41it/s]Train epoch: 5 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006045\n",
      "10475it [11:30,  8.42it/s]Train epoch: 5 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005284\n",
      "10500it [11:33,  8.32it/s]Train epoch: 5 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006077\n",
      "10525it [11:36,  8.34it/s]Train epoch: 5 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.005772\n",
      "10550it [11:39,  8.11it/s]Train epoch: 5 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006047\n",
      "10575it [11:42,  8.54it/s]Train epoch: 5 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005341\n",
      "10600it [11:45,  8.19it/s]Train epoch: 5 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.005618\n",
      "10625it [11:48,  8.08it/s]Train epoch: 5 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006312\n",
      "10650it [11:52,  8.05it/s]Train epoch: 5 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.005773\n",
      "10675it [11:55,  8.10it/s]Train epoch: 5 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.006073\n",
      "10700it [11:58,  8.04it/s]Train epoch: 5 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.005719\n",
      "10725it [12:01,  8.05it/s]Train epoch: 5 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005434\n",
      "10750it [12:04,  7.86it/s]Train epoch: 5 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006308\n",
      "10775it [12:07,  7.68it/s]Train epoch: 5 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006210\n",
      "10800it [12:10,  8.01it/s]Train epoch: 5 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006567\n",
      "10825it [12:14,  7.69it/s]Train epoch: 5 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006286\n",
      "10850it [12:17,  7.80it/s]Train epoch: 5 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006236\n",
      "10875it [12:20,  7.89it/s]Train epoch: 5 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006279\n",
      "10900it [12:23,  7.64it/s]Train epoch: 5 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.006162\n",
      "10925it [12:26,  7.83it/s]Train epoch: 5 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005637\n",
      "10950it [12:30,  7.55it/s]Train epoch: 5 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006099\n",
      "10975it [12:33,  7.82it/s]Train epoch: 5 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.005958\n",
      "11000it [12:36,  7.79it/s]Train epoch: 5 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.005901\n",
      "11025it [12:39,  7.97it/s]Train epoch: 5 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006088\n",
      "11050it [12:43,  7.65it/s]Train epoch: 5 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.006824\n",
      "11075it [12:46,  7.91it/s]Train epoch: 5 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006340\n",
      "11100it [12:49,  8.01it/s]Train epoch: 5 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.007039\n",
      "11125it [12:52,  7.89it/s]Train epoch: 5 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006454\n",
      "11150it [12:55,  7.88it/s]Train epoch: 5 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006276\n",
      "11175it [12:58,  7.71it/s]Train epoch: 5 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007315\n",
      "11200it [13:02,  7.69it/s]Train epoch: 5 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006655\n",
      "11225it [13:05,  7.80it/s]Train epoch: 5 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250it [13:08,  7.87it/s]Train epoch: 5 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007099\n",
      "11275it [13:11,  7.68it/s]Train epoch: 5 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.006851\n",
      "11300it [13:15,  7.72it/s]Train epoch: 5 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006308\n",
      "11325it [13:18,  7.99it/s]Train epoch: 5 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007432\n",
      "11350it [13:21,  7.83it/s]Train epoch: 5 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007183\n",
      "11375it [13:24,  7.73it/s]Train epoch: 5 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007423\n",
      "11400it [13:27,  7.68it/s]Train epoch: 5 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006473\n",
      "11425it [13:31,  7.74it/s]Train epoch: 5 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007200\n",
      "11450it [13:34,  7.89it/s]Train epoch: 5 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006338\n",
      "11475it [13:37,  7.76it/s]Train epoch: 5 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007658\n",
      "11500it [13:40,  7.81it/s]Train epoch: 5 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007387\n",
      "11525it [13:43,  7.70it/s]Train epoch: 5 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006755\n",
      "11550it [13:47,  8.15it/s]Train epoch: 5 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.006762\n",
      "11575it [13:50,  7.87it/s]Train epoch: 5 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007796\n",
      "11600it [13:53,  7.71it/s]Train epoch: 5 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007190\n",
      "11625it [13:56,  7.63it/s]Train epoch: 5 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006826\n",
      "11650it [14:00,  7.82it/s]Train epoch: 5 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007186\n",
      "11675it [14:03,  7.83it/s]Train epoch: 5 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007643\n",
      "11700it [14:06,  7.79it/s]Train epoch: 5 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008297\n",
      "11725it [14:09,  7.66it/s]Train epoch: 5 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008193\n",
      "11750it [14:12,  7.88it/s]Train epoch: 5 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.007903\n",
      "11775it [14:16,  7.72it/s]Train epoch: 5 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.007985\n",
      "11800it [14:19,  7.38it/s]Train epoch: 5 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007808\n",
      "11825it [14:22,  7.79it/s]Train epoch: 5 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.008011\n",
      "11850it [14:26,  7.46it/s]Train epoch: 5 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008421\n",
      "11875it [14:29,  7.41it/s]Train epoch: 5 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009249\n",
      "11900it [14:32,  7.64it/s]Train epoch: 5 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.011100\n",
      "11925it [14:36,  7.93it/s]Train epoch: 5 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009377\n",
      "11930it [14:36, 13.61it/s]\n",
      "epoch loss: 0.004514158414065922\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:13, 124.45it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0380, 0.0549, 0.0610, 0.0578, 0.8804\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3271, 0.5329, 0.4586, 0.4930, 0.9817\n",
      "rec_at_8: 0.3506\n",
      "prec_at_8: 0.6452\n",
      "rec_at_15: 0.4931\n",
      "prec_at_15: 0.5060\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:26, 125.10it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0393, 0.0611, 0.0646, 0.0628, 0.8716\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3224, 0.5280, 0.4529, 0.4876, 0.9816\n",
      "rec_at_8: 0.3371\n",
      "prec_at_8: 0.6437\n",
      "rec_at_15: 0.4728\n",
      "prec_at_15: 0.5045\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0367, 0.0532, 0.0576, 0.0553, 0.8809\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3270, 0.5420, 0.4519, 0.4928, 0.9819\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0067\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0385, 0.0609, 0.0619, 0.0614, 0.8724\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3221, 0.5352, 0.4472, 0.4873, 0.9817\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0070\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "\n",
      "EPOCH 6\n",
      "0it [00:00, ?it/s]Train epoch: 6 [batch #0, batch_size 4, seq length 68]\tLoss: 0.005809\n",
      "25it [00:00, 42.89it/s]Train epoch: 6 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003674\n",
      "46it [00:01, 43.65it/s]Train epoch: 6 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003421\n",
      "71it [00:01, 43.43it/s]Train epoch: 6 [batch #75, batch_size 4, seq length 307]\tLoss: 0.002796\n",
      "100it [00:02, 38.63it/s]Train epoch: 6 [batch #100, batch_size 4, seq length 333]\tLoss: 0.002977\n",
      "125it [00:03, 35.84it/s]Train epoch: 6 [batch #125, batch_size 4, seq length 354]\tLoss: 0.002875\n",
      "149it [00:03, 35.73it/s]Train epoch: 6 [batch #150, batch_size 4, seq length 370]\tLoss: 0.002786\n",
      "173it [00:04, 36.73it/s]Train epoch: 6 [batch #175, batch_size 4, seq length 386]\tLoss: 0.002915\n",
      "197it [00:05, 34.66it/s]Train epoch: 6 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002771\n",
      "222it [00:05, 34.84it/s]Train epoch: 6 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003401\n",
      "250it [00:06, 31.98it/s]Train epoch: 6 [batch #250, batch_size 4, seq length 428]\tLoss: 0.002788\n",
      "274it [00:07, 33.31it/s]Train epoch: 6 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002404\n",
      "299it [00:08, 31.41it/s]Train epoch: 6 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003148\n",
      "323it [00:08, 31.76it/s]Train epoch: 6 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002553\n",
      "347it [00:09, 31.05it/s]Train epoch: 6 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003066\n",
      "375it [00:10, 31.96it/s]Train epoch: 6 [batch #375, batch_size 4, seq length 480]\tLoss: 0.002921\n",
      "399it [00:11, 30.11it/s]Train epoch: 6 [batch #400, batch_size 4, seq length 489]\tLoss: 0.002916\n",
      "423it [00:12, 29.65it/s]Train epoch: 6 [batch #425, batch_size 4, seq length 497]\tLoss: 0.002929\n",
      "447it [00:12, 30.25it/s]Train epoch: 6 [batch #450, batch_size 4, seq length 504]\tLoss: 0.002861\n",
      "474it [00:13, 30.43it/s]Train epoch: 6 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003273\n",
      "498it [00:14, 31.76it/s]Train epoch: 6 [batch #500, batch_size 4, seq length 519]\tLoss: 0.002816\n",
      "522it [00:15, 31.15it/s]Train epoch: 6 [batch #525, batch_size 4, seq length 527]\tLoss: 0.003038\n",
      "550it [00:16, 29.66it/s]Train epoch: 6 [batch #550, batch_size 4, seq length 534]\tLoss: 0.002917\n",
      "575it [00:17, 30.55it/s]Train epoch: 6 [batch #575, batch_size 4, seq length 541]\tLoss: 0.002853\n",
      "599it [00:18, 28.85it/s]Train epoch: 6 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003233\n",
      "623it [00:18, 29.53it/s]Train epoch: 6 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003178\n",
      "649it [00:19, 28.88it/s]Train epoch: 6 [batch #650, batch_size 4, seq length 559]\tLoss: 0.002768\n",
      "674it [00:20, 28.01it/s]Train epoch: 6 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002340\n",
      "698it [00:21, 28.95it/s]Train epoch: 6 [batch #700, batch_size 4, seq length 573]\tLoss: 0.002898\n",
      "722it [00:22, 29.79it/s]Train epoch: 6 [batch #725, batch_size 4, seq length 578]\tLoss: 0.003027\n",
      "749it [00:23, 29.44it/s]Train epoch: 6 [batch #750, batch_size 4, seq length 584]\tLoss: 0.002816\n",
      "775it [00:23, 28.69it/s]Train epoch: 6 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003199\n",
      "800it [00:24, 27.35it/s]Train epoch: 6 [batch #800, batch_size 4, seq length 596]\tLoss: 0.003018\n",
      "823it [00:25, 27.85it/s]Train epoch: 6 [batch #825, batch_size 4, seq length 601]\tLoss: 0.003003\n",
      "850it [00:26, 27.52it/s]Train epoch: 6 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003323\n",
      "873it [00:27, 29.30it/s]Train epoch: 6 [batch #875, batch_size 4, seq length 612]\tLoss: 0.002774\n",
      "898it [00:28, 26.34it/s]Train epoch: 6 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003139\n",
      "925it [00:29, 28.33it/s]Train epoch: 6 [batch #925, batch_size 4, seq length 622]\tLoss: 0.002866\n",
      "950it [00:30, 27.66it/s]Train epoch: 6 [batch #950, batch_size 4, seq length 627]\tLoss: 0.002840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973it [00:31, 27.82it/s]Train epoch: 6 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002196\n",
      "998it [00:31, 28.34it/s]Train epoch: 6 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003038\n",
      "1023it [00:32, 28.87it/s]Train epoch: 6 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004033\n",
      "1048it [00:33, 27.33it/s]Train epoch: 6 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.002811\n",
      "1074it [00:34, 27.94it/s]Train epoch: 6 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003181\n",
      "1098it [00:35, 25.82it/s]Train epoch: 6 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003249\n",
      "1125it [00:36, 25.65it/s]Train epoch: 6 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003223\n",
      "1148it [00:37, 28.12it/s]Train epoch: 6 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003199\n",
      "1174it [00:38, 28.34it/s]Train epoch: 6 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003159\n",
      "1199it [00:39, 27.00it/s]Train epoch: 6 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003269\n",
      "1224it [00:40, 27.71it/s]Train epoch: 6 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003372\n",
      "1249it [00:41, 27.08it/s]Train epoch: 6 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003171\n",
      "1273it [00:42, 26.59it/s]Train epoch: 6 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.002784\n",
      "1298it [00:42, 26.76it/s]Train epoch: 6 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.002774\n",
      "1325it [00:44, 25.57it/s]Train epoch: 6 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.002915\n",
      "1349it [00:44, 25.78it/s]Train epoch: 6 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.003769\n",
      "1373it [00:45, 25.11it/s]Train epoch: 6 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003121\n",
      "1398it [00:46, 25.44it/s]Train epoch: 6 [batch #1400, batch_size 4, seq length 710]\tLoss: 0.003110\n",
      "1424it [00:47, 26.63it/s]Train epoch: 6 [batch #1425, batch_size 4, seq length 714]\tLoss: 0.002752\n",
      "1448it [00:48, 25.36it/s]Train epoch: 6 [batch #1450, batch_size 4, seq length 717]\tLoss: 0.002985\n",
      "1475it [00:49, 25.64it/s]Train epoch: 6 [batch #1475, batch_size 4, seq length 721]\tLoss: 0.003118\n",
      "1499it [00:50, 25.73it/s]Train epoch: 6 [batch #1500, batch_size 4, seq length 726]\tLoss: 0.004306\n",
      "1523it [00:51, 26.26it/s]Train epoch: 6 [batch #1525, batch_size 4, seq length 730]\tLoss: 0.003950\n",
      "1550it [00:52, 25.21it/s]Train epoch: 6 [batch #1550, batch_size 4, seq length 734]\tLoss: 0.002946\n",
      "1574it [00:53, 25.80it/s]Train epoch: 6 [batch #1575, batch_size 4, seq length 738]\tLoss: 0.003228\n",
      "1598it [00:54, 25.78it/s]Train epoch: 6 [batch #1600, batch_size 4, seq length 742]\tLoss: 0.002879\n",
      "1624it [00:55, 27.59it/s]Train epoch: 6 [batch #1625, batch_size 4, seq length 746]\tLoss: 0.003446\n",
      "1649it [00:56, 26.16it/s]Train epoch: 6 [batch #1650, batch_size 4, seq length 750]\tLoss: 0.003558\n",
      "1673it [00:57, 26.57it/s]Train epoch: 6 [batch #1675, batch_size 4, seq length 754]\tLoss: 0.003466\n",
      "1698it [00:58, 25.88it/s]Train epoch: 6 [batch #1700, batch_size 4, seq length 757]\tLoss: 0.002885\n",
      "1725it [00:59, 26.17it/s]Train epoch: 6 [batch #1725, batch_size 4, seq length 761]\tLoss: 0.002491\n",
      "1749it [01:00, 25.52it/s]Train epoch: 6 [batch #1750, batch_size 4, seq length 765]\tLoss: 0.003834\n",
      "1773it [01:01, 24.15it/s]Train epoch: 6 [batch #1775, batch_size 4, seq length 770]\tLoss: 0.003248\n",
      "1800it [01:02, 25.00it/s]Train epoch: 6 [batch #1800, batch_size 4, seq length 773]\tLoss: 0.003139\n",
      "1824it [01:03, 23.77it/s]Train epoch: 6 [batch #1825, batch_size 4, seq length 777]\tLoss: 0.002625\n",
      "1848it [01:04, 24.75it/s]Train epoch: 6 [batch #1850, batch_size 4, seq length 781]\tLoss: 0.003272\n",
      "1873it [01:05, 25.12it/s]Train epoch: 6 [batch #1875, batch_size 4, seq length 784]\tLoss: 0.003620\n",
      "1900it [01:06, 25.14it/s]Train epoch: 6 [batch #1900, batch_size 4, seq length 788]\tLoss: 0.002533\n",
      "1924it [01:07, 25.27it/s]Train epoch: 6 [batch #1925, batch_size 4, seq length 792]\tLoss: 0.002769\n",
      "1948it [01:08, 24.44it/s]Train epoch: 6 [batch #1950, batch_size 4, seq length 796]\tLoss: 0.002730\n",
      "1975it [01:09, 25.41it/s]Train epoch: 6 [batch #1975, batch_size 4, seq length 799]\tLoss: 0.003319\n",
      "2000it [01:10, 24.17it/s]Train epoch: 6 [batch #2000, batch_size 4, seq length 803]\tLoss: 0.002623\n",
      "2024it [01:11, 23.80it/s]Train epoch: 6 [batch #2025, batch_size 4, seq length 807]\tLoss: 0.003211\n",
      "2048it [01:12, 24.46it/s]Train epoch: 6 [batch #2050, batch_size 4, seq length 810]\tLoss: 0.003052\n",
      "2075it [01:13, 23.87it/s]Train epoch: 6 [batch #2075, batch_size 4, seq length 813]\tLoss: 0.003157\n",
      "2099it [01:14, 25.01it/s]Train epoch: 6 [batch #2100, batch_size 4, seq length 817]\tLoss: 0.003250\n",
      "2123it [01:15, 23.74it/s]Train epoch: 6 [batch #2125, batch_size 4, seq length 821]\tLoss: 0.003572\n",
      "2150it [01:16, 23.15it/s]Train epoch: 6 [batch #2150, batch_size 4, seq length 825]\tLoss: 0.003102\n",
      "2174it [01:17, 24.39it/s]Train epoch: 6 [batch #2175, batch_size 4, seq length 828]\tLoss: 0.003390\n",
      "2198it [01:18, 24.51it/s]Train epoch: 6 [batch #2200, batch_size 4, seq length 832]\tLoss: 0.003221\n",
      "2225it [01:19, 25.02it/s]Train epoch: 6 [batch #2225, batch_size 4, seq length 835]\tLoss: 0.003160\n",
      "2249it [01:20, 23.05it/s]Train epoch: 6 [batch #2250, batch_size 4, seq length 838]\tLoss: 0.002896\n",
      "2273it [01:21, 23.97it/s]Train epoch: 6 [batch #2275, batch_size 4, seq length 842]\tLoss: 0.003279\n",
      "2300it [01:22, 23.90it/s]Train epoch: 6 [batch #2300, batch_size 4, seq length 846]\tLoss: 0.002562\n",
      "2324it [01:24, 24.01it/s]Train epoch: 6 [batch #2325, batch_size 4, seq length 849]\tLoss: 0.003173\n",
      "2348it [01:25, 23.97it/s]Train epoch: 6 [batch #2350, batch_size 4, seq length 852]\tLoss: 0.002861\n",
      "2375it [01:26, 24.07it/s]Train epoch: 6 [batch #2375, batch_size 4, seq length 856]\tLoss: 0.004091\n",
      "2399it [01:27, 23.16it/s]Train epoch: 6 [batch #2400, batch_size 4, seq length 859]\tLoss: 0.003822\n",
      "2423it [01:28, 22.63it/s]Train epoch: 6 [batch #2425, batch_size 4, seq length 863]\tLoss: 0.002638\n",
      "2450it [01:29, 24.09it/s]Train epoch: 6 [batch #2450, batch_size 4, seq length 866]\tLoss: 0.003106\n",
      "2474it [01:30, 23.27it/s]Train epoch: 6 [batch #2475, batch_size 4, seq length 870]\tLoss: 0.003468\n",
      "2498it [01:31, 23.90it/s]Train epoch: 6 [batch #2500, batch_size 4, seq length 873]\tLoss: 0.002988\n",
      "2525it [01:32, 22.48it/s]Train epoch: 6 [batch #2525, batch_size 4, seq length 877]\tLoss: 0.002946\n",
      "2549it [01:33, 22.46it/s]Train epoch: 6 [batch #2550, batch_size 4, seq length 880]\tLoss: 0.004264\n",
      "2573it [01:34, 22.08it/s]Train epoch: 6 [batch #2575, batch_size 4, seq length 883]\tLoss: 0.002958\n",
      "2600it [01:35, 23.44it/s]Train epoch: 6 [batch #2600, batch_size 4, seq length 886]\tLoss: 0.003170\n",
      "2624it [01:36, 23.86it/s]Train epoch: 6 [batch #2625, batch_size 4, seq length 890]\tLoss: 0.003228\n",
      "2648it [01:38, 22.06it/s]Train epoch: 6 [batch #2650, batch_size 4, seq length 894]\tLoss: 0.003777\n",
      "2675it [01:39, 23.61it/s]Train epoch: 6 [batch #2675, batch_size 4, seq length 897]\tLoss: 0.003280\n",
      "2699it [01:40, 22.79it/s]Train epoch: 6 [batch #2700, batch_size 4, seq length 901]\tLoss: 0.002945\n",
      "2723it [01:41, 23.01it/s]Train epoch: 6 [batch #2725, batch_size 4, seq length 905]\tLoss: 0.003131\n",
      "2750it [01:42, 22.34it/s]Train epoch: 6 [batch #2750, batch_size 4, seq length 908]\tLoss: 0.003806\n",
      "2774it [01:43, 21.24it/s]Train epoch: 6 [batch #2775, batch_size 4, seq length 911]\tLoss: 0.003272\n",
      "2798it [01:44, 21.17it/s]Train epoch: 6 [batch #2800, batch_size 4, seq length 915]\tLoss: 0.003054\n",
      "2825it [01:45, 22.26it/s]Train epoch: 6 [batch #2825, batch_size 4, seq length 918]\tLoss: 0.003467\n",
      "2849it [01:46, 22.21it/s]Train epoch: 6 [batch #2850, batch_size 4, seq length 922]\tLoss: 0.003231\n",
      "2873it [01:48, 22.63it/s]Train epoch: 6 [batch #2875, batch_size 4, seq length 925]\tLoss: 0.003553\n",
      "2900it [01:49, 21.47it/s]Train epoch: 6 [batch #2900, batch_size 4, seq length 928]\tLoss: 0.003328\n",
      "2924it [01:50, 22.05it/s]Train epoch: 6 [batch #2925, batch_size 4, seq length 931]\tLoss: 0.003528\n",
      "2948it [01:51, 22.09it/s]Train epoch: 6 [batch #2950, batch_size 4, seq length 935]\tLoss: 0.003691\n",
      "2975it [01:52, 21.85it/s]Train epoch: 6 [batch #2975, batch_size 4, seq length 938]\tLoss: 0.003417\n",
      "2999it [01:53, 21.97it/s]Train epoch: 6 [batch #3000, batch_size 4, seq length 941]\tLoss: 0.003977\n",
      "3023it [01:54, 21.73it/s]Train epoch: 6 [batch #3025, batch_size 4, seq length 944]\tLoss: 0.003676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3050it [01:56, 21.92it/s]Train epoch: 6 [batch #3050, batch_size 4, seq length 948]\tLoss: 0.003115\n",
      "3074it [01:57, 22.19it/s]Train epoch: 6 [batch #3075, batch_size 4, seq length 951]\tLoss: 0.003588\n",
      "3098it [01:58, 21.78it/s]Train epoch: 6 [batch #3100, batch_size 4, seq length 954]\tLoss: 0.003548\n",
      "3125it [01:59, 21.30it/s]Train epoch: 6 [batch #3125, batch_size 4, seq length 957]\tLoss: 0.003352\n",
      "3149it [02:00, 21.91it/s]Train epoch: 6 [batch #3150, batch_size 4, seq length 960]\tLoss: 0.003143\n",
      "3173it [02:01, 22.13it/s]Train epoch: 6 [batch #3175, batch_size 4, seq length 965]\tLoss: 0.003168\n",
      "3200it [02:03, 20.78it/s]Train epoch: 6 [batch #3200, batch_size 4, seq length 968]\tLoss: 0.003712\n",
      "3224it [02:04, 21.61it/s]Train epoch: 6 [batch #3225, batch_size 4, seq length 971]\tLoss: 0.003585\n",
      "3248it [02:05, 21.65it/s]Train epoch: 6 [batch #3250, batch_size 4, seq length 975]\tLoss: 0.003639\n",
      "3275it [02:06, 22.44it/s]Train epoch: 6 [batch #3275, batch_size 4, seq length 978]\tLoss: 0.003194\n",
      "3299it [02:07, 21.73it/s]Train epoch: 6 [batch #3300, batch_size 4, seq length 981]\tLoss: 0.004090\n",
      "3323it [02:08, 22.53it/s]Train epoch: 6 [batch #3325, batch_size 4, seq length 984]\tLoss: 0.003502\n",
      "3350it [02:10, 21.18it/s]Train epoch: 6 [batch #3350, batch_size 4, seq length 988]\tLoss: 0.003446\n",
      "3374it [02:11, 21.47it/s]Train epoch: 6 [batch #3375, batch_size 4, seq length 990]\tLoss: 0.003626\n",
      "3398it [02:12, 20.91it/s]Train epoch: 6 [batch #3400, batch_size 4, seq length 993]\tLoss: 0.003698\n",
      "3425it [02:13, 21.59it/s]Train epoch: 6 [batch #3425, batch_size 4, seq length 997]\tLoss: 0.003195\n",
      "3449it [02:14, 20.74it/s]Train epoch: 6 [batch #3450, batch_size 4, seq length 1000]\tLoss: 0.003775\n",
      "3473it [02:15, 20.45it/s]Train epoch: 6 [batch #3475, batch_size 4, seq length 1003]\tLoss: 0.003323\n",
      "3499it [02:17, 20.79it/s]Train epoch: 6 [batch #3500, batch_size 4, seq length 1006]\tLoss: 0.003438\n",
      "3523it [02:18, 20.95it/s]Train epoch: 6 [batch #3525, batch_size 4, seq length 1009]\tLoss: 0.003494\n",
      "3550it [02:19, 21.02it/s]Train epoch: 6 [batch #3550, batch_size 4, seq length 1012]\tLoss: 0.003752\n",
      "3574it [02:20, 20.07it/s]Train epoch: 6 [batch #3575, batch_size 4, seq length 1016]\tLoss: 0.003047\n",
      "3598it [02:21, 20.60it/s]Train epoch: 6 [batch #3600, batch_size 4, seq length 1019]\tLoss: 0.003987\n",
      "3625it [02:23, 21.19it/s]Train epoch: 6 [batch #3625, batch_size 4, seq length 1023]\tLoss: 0.003563\n",
      "3649it [02:24, 19.29it/s]Train epoch: 6 [batch #3650, batch_size 4, seq length 1026]\tLoss: 0.003718\n",
      "3675it [02:25, 17.81it/s]Train epoch: 6 [batch #3675, batch_size 4, seq length 1030]\tLoss: 0.003752\n",
      "3700it [02:27, 17.61it/s]Train epoch: 6 [batch #3700, batch_size 4, seq length 1032]\tLoss: 0.003726\n",
      "3724it [02:28, 17.01it/s]Train epoch: 6 [batch #3725, batch_size 4, seq length 1036]\tLoss: 0.003903\n",
      "3750it [02:30, 18.99it/s]Train epoch: 6 [batch #3750, batch_size 4, seq length 1039]\tLoss: 0.003769\n",
      "3774it [02:31, 17.56it/s]Train epoch: 6 [batch #3775, batch_size 4, seq length 1042]\tLoss: 0.003688\n",
      "3799it [02:32, 18.02it/s]Train epoch: 6 [batch #3800, batch_size 4, seq length 1046]\tLoss: 0.004031\n",
      "3825it [02:34, 16.68it/s]Train epoch: 6 [batch #3825, batch_size 4, seq length 1049]\tLoss: 0.003508\n",
      "3850it [02:35, 17.71it/s]Train epoch: 6 [batch #3850, batch_size 4, seq length 1052]\tLoss: 0.003155\n",
      "3874it [02:37, 16.76it/s]Train epoch: 6 [batch #3875, batch_size 4, seq length 1056]\tLoss: 0.003084\n",
      "3900it [02:38, 16.81it/s]Train epoch: 6 [batch #3900, batch_size 4, seq length 1059]\tLoss: 0.004074\n",
      "3925it [02:40, 17.05it/s]Train epoch: 6 [batch #3925, batch_size 4, seq length 1062]\tLoss: 0.003718\n",
      "3949it [02:41, 16.58it/s]Train epoch: 6 [batch #3950, batch_size 4, seq length 1066]\tLoss: 0.004081\n",
      "3975it [02:43, 16.12it/s]Train epoch: 6 [batch #3975, batch_size 4, seq length 1069]\tLoss: 0.004493\n",
      "3999it [02:44, 16.42it/s]Train epoch: 6 [batch #4000, batch_size 4, seq length 1073]\tLoss: 0.003428\n",
      "4025it [02:46, 16.99it/s]Train epoch: 6 [batch #4025, batch_size 4, seq length 1075]\tLoss: 0.004300\n",
      "4049it [02:47, 16.19it/s]Train epoch: 6 [batch #4050, batch_size 4, seq length 1079]\tLoss: 0.003895\n",
      "4075it [02:49, 16.53it/s]Train epoch: 6 [batch #4075, batch_size 4, seq length 1082]\tLoss: 0.003864\n",
      "4099it [02:50, 16.19it/s]Train epoch: 6 [batch #4100, batch_size 4, seq length 1084]\tLoss: 0.004256\n",
      "4124it [02:52, 16.51it/s]Train epoch: 6 [batch #4125, batch_size 4, seq length 1088]\tLoss: 0.003997\n",
      "4150it [02:53, 15.87it/s]Train epoch: 6 [batch #4150, batch_size 4, seq length 1091]\tLoss: 0.003497\n",
      "4174it [02:55, 16.58it/s]Train epoch: 6 [batch #4175, batch_size 4, seq length 1095]\tLoss: 0.003734\n",
      "4200it [02:56, 16.52it/s]Train epoch: 6 [batch #4200, batch_size 4, seq length 1098]\tLoss: 0.004131\n",
      "4224it [02:58, 15.94it/s]Train epoch: 6 [batch #4225, batch_size 4, seq length 1101]\tLoss: 0.003461\n",
      "4250it [02:59, 17.01it/s]Train epoch: 6 [batch #4250, batch_size 4, seq length 1105]\tLoss: 0.004028\n",
      "4274it [03:01, 17.30it/s]Train epoch: 6 [batch #4275, batch_size 4, seq length 1108]\tLoss: 0.003643\n",
      "4300it [03:02, 15.90it/s]Train epoch: 6 [batch #4300, batch_size 4, seq length 1112]\tLoss: 0.004321\n",
      "4324it [03:04, 15.81it/s]Train epoch: 6 [batch #4325, batch_size 4, seq length 1116]\tLoss: 0.003751\n",
      "4350it [03:05, 16.88it/s]Train epoch: 6 [batch #4350, batch_size 4, seq length 1119]\tLoss: 0.004108\n",
      "4374it [03:07, 16.62it/s]Train epoch: 6 [batch #4375, batch_size 4, seq length 1122]\tLoss: 0.003670\n",
      "4400it [03:08, 16.42it/s]Train epoch: 6 [batch #4400, batch_size 4, seq length 1125]\tLoss: 0.003200\n",
      "4424it [03:10, 16.25it/s]Train epoch: 6 [batch #4425, batch_size 4, seq length 1129]\tLoss: 0.003896\n",
      "4450it [03:12, 16.05it/s]Train epoch: 6 [batch #4450, batch_size 4, seq length 1132]\tLoss: 0.003224\n",
      "4474it [03:13, 16.31it/s]Train epoch: 6 [batch #4475, batch_size 4, seq length 1135]\tLoss: 0.004080\n",
      "4500it [03:15, 15.67it/s]Train epoch: 6 [batch #4500, batch_size 4, seq length 1139]\tLoss: 0.004587\n",
      "4524it [03:16, 16.11it/s]Train epoch: 6 [batch #4525, batch_size 4, seq length 1143]\tLoss: 0.004014\n",
      "4550it [03:18, 16.37it/s]Train epoch: 6 [batch #4550, batch_size 4, seq length 1146]\tLoss: 0.003782\n",
      "4574it [03:19, 16.12it/s]Train epoch: 6 [batch #4575, batch_size 4, seq length 1150]\tLoss: 0.004207\n",
      "4600it [03:21, 15.14it/s]Train epoch: 6 [batch #4600, batch_size 4, seq length 1153]\tLoss: 0.003638\n",
      "4624it [03:22, 15.08it/s]Train epoch: 6 [batch #4625, batch_size 4, seq length 1157]\tLoss: 0.003586\n",
      "4650it [03:24, 15.42it/s]Train epoch: 6 [batch #4650, batch_size 4, seq length 1160]\tLoss: 0.004203\n",
      "4674it [03:26, 15.31it/s]Train epoch: 6 [batch #4675, batch_size 4, seq length 1163]\tLoss: 0.004067\n",
      "4700it [03:27, 15.71it/s]Train epoch: 6 [batch #4700, batch_size 4, seq length 1166]\tLoss: 0.003518\n",
      "4724it [03:29, 15.45it/s]Train epoch: 6 [batch #4725, batch_size 4, seq length 1170]\tLoss: 0.003740\n",
      "4750it [03:31, 15.56it/s]Train epoch: 6 [batch #4750, batch_size 4, seq length 1173]\tLoss: 0.004369\n",
      "4774it [03:32, 15.61it/s]Train epoch: 6 [batch #4775, batch_size 4, seq length 1177]\tLoss: 0.003865\n",
      "4800it [03:34, 15.09it/s]Train epoch: 6 [batch #4800, batch_size 4, seq length 1180]\tLoss: 0.004026\n",
      "4824it [03:35, 15.12it/s]Train epoch: 6 [batch #4825, batch_size 4, seq length 1184]\tLoss: 0.003548\n",
      "4850it [03:37, 14.79it/s]Train epoch: 6 [batch #4850, batch_size 4, seq length 1187]\tLoss: 0.004150\n",
      "4874it [03:39, 14.05it/s]Train epoch: 6 [batch #4875, batch_size 4, seq length 1190]\tLoss: 0.003673\n",
      "4900it [03:41, 15.10it/s]Train epoch: 6 [batch #4900, batch_size 4, seq length 1194]\tLoss: 0.003817\n",
      "4924it [03:42, 15.65it/s]Train epoch: 6 [batch #4925, batch_size 4, seq length 1197]\tLoss: 0.003523\n",
      "4950it [03:44, 14.68it/s]Train epoch: 6 [batch #4950, batch_size 4, seq length 1201]\tLoss: 0.003850\n",
      "4974it [03:46, 15.45it/s]Train epoch: 6 [batch #4975, batch_size 4, seq length 1204]\tLoss: 0.003989\n",
      "5000it [03:47, 14.56it/s]Train epoch: 6 [batch #5000, batch_size 4, seq length 1208]\tLoss: 0.003820\n",
      "5024it [03:49, 15.24it/s]Train epoch: 6 [batch #5025, batch_size 4, seq length 1211]\tLoss: 0.003638\n",
      "5050it [03:51, 15.09it/s]Train epoch: 6 [batch #5050, batch_size 4, seq length 1214]\tLoss: 0.003611\n",
      "5074it [03:52, 15.00it/s]Train epoch: 6 [batch #5075, batch_size 4, seq length 1217]\tLoss: 0.003884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100it [03:54, 14.88it/s]Train epoch: 6 [batch #5100, batch_size 4, seq length 1220]\tLoss: 0.004030\n",
      "5124it [03:56, 14.83it/s]Train epoch: 6 [batch #5125, batch_size 4, seq length 1224]\tLoss: 0.004112\n",
      "5150it [03:57, 14.88it/s]Train epoch: 6 [batch #5150, batch_size 4, seq length 1227]\tLoss: 0.004143\n",
      "5174it [03:59, 13.69it/s]Train epoch: 6 [batch #5175, batch_size 4, seq length 1231]\tLoss: 0.004028\n",
      "5200it [04:01, 15.21it/s]Train epoch: 6 [batch #5200, batch_size 4, seq length 1234]\tLoss: 0.003691\n",
      "5224it [04:02, 14.83it/s]Train epoch: 6 [batch #5225, batch_size 4, seq length 1237]\tLoss: 0.003886\n",
      "5250it [04:04, 14.44it/s]Train epoch: 6 [batch #5250, batch_size 4, seq length 1241]\tLoss: 0.003925\n",
      "5274it [04:06, 14.97it/s]Train epoch: 6 [batch #5275, batch_size 4, seq length 1244]\tLoss: 0.003825\n",
      "5300it [04:08, 14.90it/s]Train epoch: 6 [batch #5300, batch_size 4, seq length 1248]\tLoss: 0.003626\n",
      "5324it [04:09, 15.65it/s]Train epoch: 6 [batch #5325, batch_size 4, seq length 1251]\tLoss: 0.004092\n",
      "5350it [04:11, 14.56it/s]Train epoch: 6 [batch #5350, batch_size 4, seq length 1255]\tLoss: 0.004137\n",
      "5374it [04:13, 14.68it/s]Train epoch: 6 [batch #5375, batch_size 4, seq length 1258]\tLoss: 0.003789\n",
      "5400it [04:15, 14.19it/s]Train epoch: 6 [batch #5400, batch_size 4, seq length 1262]\tLoss: 0.003762\n",
      "5424it [04:16, 13.94it/s]Train epoch: 6 [batch #5425, batch_size 4, seq length 1266]\tLoss: 0.004208\n",
      "5450it [04:18, 14.69it/s]Train epoch: 6 [batch #5450, batch_size 4, seq length 1269]\tLoss: 0.004000\n",
      "5474it [04:20, 14.15it/s]Train epoch: 6 [batch #5475, batch_size 4, seq length 1272]\tLoss: 0.004651\n",
      "5500it [04:22, 14.40it/s]Train epoch: 6 [batch #5500, batch_size 4, seq length 1276]\tLoss: 0.004236\n",
      "5524it [04:23, 14.80it/s]Train epoch: 6 [batch #5525, batch_size 4, seq length 1279]\tLoss: 0.003554\n",
      "5550it [04:25, 13.99it/s]Train epoch: 6 [batch #5550, batch_size 4, seq length 1283]\tLoss: 0.004098\n",
      "5574it [04:27, 14.01it/s]Train epoch: 6 [batch #5575, batch_size 4, seq length 1286]\tLoss: 0.004166\n",
      "5600it [04:29, 15.32it/s]Train epoch: 6 [batch #5600, batch_size 4, seq length 1289]\tLoss: 0.004406\n",
      "5624it [04:30, 14.81it/s]Train epoch: 6 [batch #5625, batch_size 4, seq length 1293]\tLoss: 0.004169\n",
      "5650it [04:32, 14.37it/s]Train epoch: 6 [batch #5650, batch_size 4, seq length 1296]\tLoss: 0.003712\n",
      "5674it [04:34, 14.43it/s]Train epoch: 6 [batch #5675, batch_size 4, seq length 1300]\tLoss: 0.004538\n",
      "5700it [04:35, 14.25it/s]Train epoch: 6 [batch #5700, batch_size 4, seq length 1304]\tLoss: 0.003991\n",
      "5724it [04:37, 14.12it/s]Train epoch: 6 [batch #5725, batch_size 4, seq length 1308]\tLoss: 0.004016\n",
      "5750it [04:39, 14.37it/s]Train epoch: 6 [batch #5750, batch_size 4, seq length 1311]\tLoss: 0.005130\n",
      "5774it [04:41, 14.32it/s]Train epoch: 6 [batch #5775, batch_size 4, seq length 1315]\tLoss: 0.004238\n",
      "5800it [04:42, 14.11it/s]Train epoch: 6 [batch #5800, batch_size 4, seq length 1319]\tLoss: 0.004293\n",
      "5824it [04:44, 14.57it/s]Train epoch: 6 [batch #5825, batch_size 4, seq length 1322]\tLoss: 0.003806\n",
      "5850it [04:46, 14.24it/s]Train epoch: 6 [batch #5850, batch_size 4, seq length 1325]\tLoss: 0.004964\n",
      "5874it [04:48, 13.66it/s]Train epoch: 6 [batch #5875, batch_size 4, seq length 1329]\tLoss: 0.004679\n",
      "5900it [04:49, 14.53it/s]Train epoch: 6 [batch #5900, batch_size 4, seq length 1332]\tLoss: 0.004679\n",
      "5924it [04:51, 14.19it/s]Train epoch: 6 [batch #5925, batch_size 4, seq length 1336]\tLoss: 0.003886\n",
      "5950it [04:53, 14.07it/s]Train epoch: 6 [batch #5950, batch_size 4, seq length 1339]\tLoss: 0.003761\n",
      "5974it [04:55, 14.19it/s]Train epoch: 6 [batch #5975, batch_size 4, seq length 1343]\tLoss: 0.005118\n",
      "6000it [04:57, 14.13it/s]Train epoch: 6 [batch #6000, batch_size 4, seq length 1346]\tLoss: 0.004267\n",
      "6024it [04:58, 14.36it/s]Train epoch: 6 [batch #6025, batch_size 4, seq length 1350]\tLoss: 0.004591\n",
      "6050it [05:00, 14.21it/s]Train epoch: 6 [batch #6050, batch_size 4, seq length 1353]\tLoss: 0.004063\n",
      "6074it [05:02, 13.96it/s]Train epoch: 6 [batch #6075, batch_size 4, seq length 1357]\tLoss: 0.003709\n",
      "6100it [05:04, 14.52it/s]Train epoch: 6 [batch #6100, batch_size 4, seq length 1361]\tLoss: 0.003783\n",
      "6124it [05:05, 13.70it/s]Train epoch: 6 [batch #6125, batch_size 4, seq length 1365]\tLoss: 0.004121\n",
      "6150it [05:07, 12.87it/s]Train epoch: 6 [batch #6150, batch_size 4, seq length 1369]\tLoss: 0.004141\n",
      "6174it [05:09, 14.35it/s]Train epoch: 6 [batch #6175, batch_size 4, seq length 1372]\tLoss: 0.004659\n",
      "6200it [05:11, 13.57it/s]Train epoch: 6 [batch #6200, batch_size 4, seq length 1376]\tLoss: 0.004198\n",
      "6224it [05:12, 14.43it/s]Train epoch: 6 [batch #6225, batch_size 4, seq length 1380]\tLoss: 0.003648\n",
      "6250it [05:14, 14.23it/s]Train epoch: 6 [batch #6250, batch_size 4, seq length 1384]\tLoss: 0.003943\n",
      "6274it [05:16, 13.05it/s]Train epoch: 6 [batch #6275, batch_size 4, seq length 1388]\tLoss: 0.003548\n",
      "6300it [05:18, 13.90it/s]Train epoch: 6 [batch #6300, batch_size 4, seq length 1392]\tLoss: 0.004138\n",
      "6324it [05:20, 13.25it/s]Train epoch: 6 [batch #6325, batch_size 4, seq length 1396]\tLoss: 0.004604\n",
      "6350it [05:22, 13.49it/s]Train epoch: 6 [batch #6350, batch_size 4, seq length 1399]\tLoss: 0.004849\n",
      "6374it [05:24, 13.76it/s]Train epoch: 6 [batch #6375, batch_size 4, seq length 1402]\tLoss: 0.003698\n",
      "6400it [05:25, 13.61it/s]Train epoch: 6 [batch #6400, batch_size 4, seq length 1406]\tLoss: 0.003993\n",
      "6424it [05:27, 13.35it/s]Train epoch: 6 [batch #6425, batch_size 4, seq length 1410]\tLoss: 0.004597\n",
      "6450it [05:29, 13.24it/s]Train epoch: 6 [batch #6450, batch_size 4, seq length 1414]\tLoss: 0.004488\n",
      "6474it [05:31, 13.36it/s]Train epoch: 6 [batch #6475, batch_size 4, seq length 1418]\tLoss: 0.003983\n",
      "6500it [05:33, 12.88it/s]Train epoch: 6 [batch #6500, batch_size 4, seq length 1422]\tLoss: 0.004448\n",
      "6524it [05:35, 13.40it/s]Train epoch: 6 [batch #6525, batch_size 4, seq length 1426]\tLoss: 0.003898\n",
      "6550it [05:37, 13.31it/s]Train epoch: 6 [batch #6550, batch_size 4, seq length 1429]\tLoss: 0.003997\n",
      "6574it [05:38, 13.65it/s]Train epoch: 6 [batch #6575, batch_size 4, seq length 1433]\tLoss: 0.004200\n",
      "6600it [05:40, 13.35it/s]Train epoch: 6 [batch #6600, batch_size 4, seq length 1436]\tLoss: 0.005106\n",
      "6624it [05:42, 13.73it/s]Train epoch: 6 [batch #6625, batch_size 4, seq length 1441]\tLoss: 0.004078\n",
      "6650it [05:44, 12.38it/s]Train epoch: 6 [batch #6650, batch_size 4, seq length 1446]\tLoss: 0.004634\n",
      "6674it [05:46, 12.72it/s]Train epoch: 6 [batch #6675, batch_size 4, seq length 1449]\tLoss: 0.004274\n",
      "6700it [05:48, 12.78it/s]Train epoch: 6 [batch #6700, batch_size 4, seq length 1453]\tLoss: 0.004417\n",
      "6724it [05:50, 12.69it/s]Train epoch: 6 [batch #6725, batch_size 4, seq length 1457]\tLoss: 0.004385\n",
      "6750it [05:52, 12.89it/s]Train epoch: 6 [batch #6750, batch_size 4, seq length 1461]\tLoss: 0.003958\n",
      "6774it [05:54, 13.06it/s]Train epoch: 6 [batch #6775, batch_size 4, seq length 1465]\tLoss: 0.004592\n",
      "6800it [05:56, 12.83it/s]Train epoch: 6 [batch #6800, batch_size 4, seq length 1468]\tLoss: 0.004625\n",
      "6824it [05:58, 12.80it/s]Train epoch: 6 [batch #6825, batch_size 4, seq length 1472]\tLoss: 0.004639\n",
      "6850it [06:00, 12.92it/s]Train epoch: 6 [batch #6850, batch_size 4, seq length 1475]\tLoss: 0.004543\n",
      "6874it [06:02, 13.02it/s]Train epoch: 6 [batch #6875, batch_size 4, seq length 1480]\tLoss: 0.003757\n",
      "6900it [06:04, 12.75it/s]Train epoch: 6 [batch #6900, batch_size 4, seq length 1484]\tLoss: 0.004256\n",
      "6924it [06:06, 13.13it/s]Train epoch: 6 [batch #6925, batch_size 4, seq length 1488]\tLoss: 0.004493\n",
      "6950it [06:08, 13.05it/s]Train epoch: 6 [batch #6950, batch_size 4, seq length 1492]\tLoss: 0.004851\n",
      "6974it [06:09, 13.07it/s]Train epoch: 6 [batch #6975, batch_size 4, seq length 1497]\tLoss: 0.004492\n",
      "7000it [06:11, 13.21it/s]Train epoch: 6 [batch #7000, batch_size 4, seq length 1501]\tLoss: 0.004306\n",
      "7024it [06:13, 13.05it/s]Train epoch: 6 [batch #7025, batch_size 4, seq length 1505]\tLoss: 0.004877\n",
      "7050it [06:15, 12.01it/s]Train epoch: 6 [batch #7050, batch_size 4, seq length 1510]\tLoss: 0.003980\n",
      "7074it [06:17, 12.18it/s]Train epoch: 6 [batch #7075, batch_size 4, seq length 1514]\tLoss: 0.004263\n",
      "7100it [06:19, 12.49it/s]Train epoch: 6 [batch #7100, batch_size 4, seq length 1518]\tLoss: 0.004589\n",
      "7124it [06:22, 11.66it/s]Train epoch: 6 [batch #7125, batch_size 4, seq length 1521]\tLoss: 0.004099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7150it [06:24, 12.08it/s]Train epoch: 6 [batch #7150, batch_size 4, seq length 1525]\tLoss: 0.004936\n",
      "7174it [06:26, 12.61it/s]Train epoch: 6 [batch #7175, batch_size 4, seq length 1529]\tLoss: 0.004476\n",
      "7200it [06:28, 12.46it/s]Train epoch: 6 [batch #7200, batch_size 4, seq length 1533]\tLoss: 0.004851\n",
      "7224it [06:30, 12.30it/s]Train epoch: 6 [batch #7225, batch_size 4, seq length 1536]\tLoss: 0.004299\n",
      "7250it [06:32, 11.88it/s]Train epoch: 6 [batch #7250, batch_size 4, seq length 1540]\tLoss: 0.004367\n",
      "7274it [06:34, 12.03it/s]Train epoch: 6 [batch #7275, batch_size 4, seq length 1543]\tLoss: 0.004848\n",
      "7300it [06:36, 12.34it/s]Train epoch: 6 [batch #7300, batch_size 4, seq length 1548]\tLoss: 0.005214\n",
      "7324it [06:38, 12.63it/s]Train epoch: 6 [batch #7325, batch_size 4, seq length 1552]\tLoss: 0.004148\n",
      "7350it [06:40, 12.33it/s]Train epoch: 6 [batch #7350, batch_size 4, seq length 1556]\tLoss: 0.005135\n",
      "7374it [06:42, 12.42it/s]Train epoch: 6 [batch #7375, batch_size 4, seq length 1562]\tLoss: 0.004767\n",
      "7400it [06:44, 12.66it/s]Train epoch: 6 [batch #7400, batch_size 4, seq length 1566]\tLoss: 0.004274\n",
      "7424it [06:46, 12.50it/s]Train epoch: 6 [batch #7425, batch_size 4, seq length 1569]\tLoss: 0.004657\n",
      "7450it [06:48, 12.56it/s]Train epoch: 6 [batch #7450, batch_size 4, seq length 1573]\tLoss: 0.005103\n",
      "7474it [06:50, 12.71it/s]Train epoch: 6 [batch #7475, batch_size 4, seq length 1577]\tLoss: 0.004473\n",
      "7500it [06:52, 12.30it/s]Train epoch: 6 [batch #7500, batch_size 4, seq length 1582]\tLoss: 0.004687\n",
      "7524it [06:54, 12.42it/s]Train epoch: 6 [batch #7525, batch_size 4, seq length 1585]\tLoss: 0.004477\n",
      "7550it [06:56, 11.70it/s]Train epoch: 6 [batch #7550, batch_size 4, seq length 1590]\tLoss: 0.004373\n",
      "7574it [06:58, 11.98it/s]Train epoch: 6 [batch #7575, batch_size 4, seq length 1594]\tLoss: 0.004825\n",
      "7600it [07:00, 11.64it/s]Train epoch: 6 [batch #7600, batch_size 4, seq length 1598]\tLoss: 0.005650\n",
      "7624it [07:02, 12.26it/s]Train epoch: 6 [batch #7625, batch_size 4, seq length 1602]\tLoss: 0.005333\n",
      "7650it [07:04, 11.94it/s]Train epoch: 6 [batch #7650, batch_size 4, seq length 1606]\tLoss: 0.004592\n",
      "7674it [07:06, 11.14it/s]Train epoch: 6 [batch #7675, batch_size 4, seq length 1610]\tLoss: 0.004482\n",
      "7700it [07:09, 12.10it/s]Train epoch: 6 [batch #7700, batch_size 4, seq length 1615]\tLoss: 0.004606\n",
      "7724it [07:11, 11.93it/s]Train epoch: 6 [batch #7725, batch_size 4, seq length 1619]\tLoss: 0.004686\n",
      "7750it [07:13, 12.03it/s]Train epoch: 6 [batch #7750, batch_size 4, seq length 1624]\tLoss: 0.004988\n",
      "7774it [07:15, 12.13it/s]Train epoch: 6 [batch #7775, batch_size 4, seq length 1628]\tLoss: 0.004328\n",
      "7800it [07:17, 11.75it/s]Train epoch: 6 [batch #7800, batch_size 4, seq length 1632]\tLoss: 0.004493\n",
      "7824it [07:19, 11.63it/s]Train epoch: 6 [batch #7825, batch_size 4, seq length 1637]\tLoss: 0.004703\n",
      "7850it [07:21, 11.63it/s]Train epoch: 6 [batch #7850, batch_size 4, seq length 1642]\tLoss: 0.004221\n",
      "7874it [07:23, 11.76it/s]Train epoch: 6 [batch #7875, batch_size 4, seq length 1646]\tLoss: 0.004586\n",
      "7900it [07:25, 11.31it/s]Train epoch: 6 [batch #7900, batch_size 4, seq length 1650]\tLoss: 0.004634\n",
      "7924it [07:27, 11.76it/s]Train epoch: 6 [batch #7925, batch_size 4, seq length 1655]\tLoss: 0.004647\n",
      "7950it [07:30, 11.57it/s]Train epoch: 6 [batch #7950, batch_size 4, seq length 1660]\tLoss: 0.005347\n",
      "7974it [07:32, 12.28it/s]Train epoch: 6 [batch #7975, batch_size 4, seq length 1665]\tLoss: 0.004396\n",
      "8000it [07:34, 12.01it/s]Train epoch: 6 [batch #8000, batch_size 4, seq length 1669]\tLoss: 0.004405\n",
      "8024it [07:36, 11.27it/s]Train epoch: 6 [batch #8025, batch_size 4, seq length 1674]\tLoss: 0.004809\n",
      "8050it [07:38, 11.95it/s]Train epoch: 6 [batch #8050, batch_size 4, seq length 1678]\tLoss: 0.004190\n",
      "8074it [07:40, 11.34it/s]Train epoch: 6 [batch #8075, batch_size 4, seq length 1682]\tLoss: 0.004582\n",
      "8100it [07:43, 11.62it/s]Train epoch: 6 [batch #8100, batch_size 4, seq length 1687]\tLoss: 0.004925\n",
      "8124it [07:45, 11.78it/s]Train epoch: 6 [batch #8125, batch_size 4, seq length 1692]\tLoss: 0.005073\n",
      "8150it [07:47, 11.18it/s]Train epoch: 6 [batch #8150, batch_size 4, seq length 1697]\tLoss: 0.004360\n",
      "8174it [07:49, 11.48it/s]Train epoch: 6 [batch #8175, batch_size 4, seq length 1702]\tLoss: 0.005036\n",
      "8200it [07:51, 11.58it/s]Train epoch: 6 [batch #8200, batch_size 4, seq length 1706]\tLoss: 0.004322\n",
      "8224it [07:53, 11.35it/s]Train epoch: 6 [batch #8225, batch_size 4, seq length 1712]\tLoss: 0.005809\n",
      "8250it [07:56, 10.92it/s]Train epoch: 6 [batch #8250, batch_size 4, seq length 1716]\tLoss: 0.004530\n",
      "8274it [07:58, 11.68it/s]Train epoch: 6 [batch #8275, batch_size 4, seq length 1722]\tLoss: 0.005072\n",
      "8300it [08:00, 11.75it/s]Train epoch: 6 [batch #8300, batch_size 4, seq length 1727]\tLoss: 0.004479\n",
      "8324it [08:02, 10.97it/s]Train epoch: 6 [batch #8325, batch_size 4, seq length 1732]\tLoss: 0.005123\n",
      "8350it [08:05, 11.10it/s]Train epoch: 6 [batch #8350, batch_size 4, seq length 1737]\tLoss: 0.004431\n",
      "8374it [08:07, 11.37it/s]Train epoch: 6 [batch #8375, batch_size 4, seq length 1743]\tLoss: 0.005096\n",
      "8400it [08:09, 11.10it/s]Train epoch: 6 [batch #8400, batch_size 4, seq length 1747]\tLoss: 0.004724\n",
      "8424it [08:11, 11.70it/s]Train epoch: 6 [batch #8425, batch_size 4, seq length 1752]\tLoss: 0.004685\n",
      "8450it [08:13, 10.98it/s]Train epoch: 6 [batch #8450, batch_size 4, seq length 1758]\tLoss: 0.005133\n",
      "8474it [08:16, 10.58it/s]Train epoch: 6 [batch #8475, batch_size 4, seq length 1762]\tLoss: 0.004746\n",
      "8500it [08:18, 11.19it/s]Train epoch: 6 [batch #8500, batch_size 4, seq length 1767]\tLoss: 0.005537\n",
      "8524it [08:20, 11.12it/s]Train epoch: 6 [batch #8525, batch_size 4, seq length 1773]\tLoss: 0.004804\n",
      "8550it [08:23, 10.81it/s]Train epoch: 6 [batch #8550, batch_size 4, seq length 1777]\tLoss: 0.005041\n",
      "8574it [08:25, 11.34it/s]Train epoch: 6 [batch #8575, batch_size 4, seq length 1781]\tLoss: 0.004593\n",
      "8600it [08:27, 11.03it/s]Train epoch: 6 [batch #8600, batch_size 4, seq length 1786]\tLoss: 0.004773\n",
      "8624it [08:29, 11.08it/s]Train epoch: 6 [batch #8625, batch_size 4, seq length 1792]\tLoss: 0.004869\n",
      "8650it [08:32, 11.13it/s]Train epoch: 6 [batch #8650, batch_size 4, seq length 1797]\tLoss: 0.005044\n",
      "8674it [08:34, 10.60it/s]Train epoch: 6 [batch #8675, batch_size 4, seq length 1803]\tLoss: 0.005664\n",
      "8700it [08:36, 11.29it/s]Train epoch: 6 [batch #8700, batch_size 4, seq length 1809]\tLoss: 0.005633\n",
      "8724it [08:38, 11.09it/s]Train epoch: 6 [batch #8725, batch_size 4, seq length 1814]\tLoss: 0.005444\n",
      "8750it [08:41, 11.04it/s]Train epoch: 6 [batch #8750, batch_size 4, seq length 1820]\tLoss: 0.005137\n",
      "8774it [08:43, 10.62it/s]Train epoch: 6 [batch #8775, batch_size 4, seq length 1827]\tLoss: 0.004635\n",
      "8800it [08:45, 10.73it/s]Train epoch: 6 [batch #8800, batch_size 4, seq length 1832]\tLoss: 0.004908\n",
      "8824it [08:48, 10.95it/s]Train epoch: 6 [batch #8825, batch_size 4, seq length 1839]\tLoss: 0.004924\n",
      "8850it [08:50, 10.66it/s]Train epoch: 6 [batch #8850, batch_size 4, seq length 1844]\tLoss: 0.005042\n",
      "8874it [08:52, 10.62it/s]Train epoch: 6 [batch #8875, batch_size 4, seq length 1849]\tLoss: 0.004938\n",
      "8900it [08:55, 10.20it/s]Train epoch: 6 [batch #8900, batch_size 4, seq length 1854]\tLoss: 0.005013\n",
      "8924it [08:57, 10.69it/s]Train epoch: 6 [batch #8925, batch_size 4, seq length 1860]\tLoss: 0.005146\n",
      "8950it [09:00, 10.82it/s]Train epoch: 6 [batch #8950, batch_size 4, seq length 1866]\tLoss: 0.005761\n",
      "8974it [09:02, 10.58it/s]Train epoch: 6 [batch #8975, batch_size 4, seq length 1872]\tLoss: 0.005265\n",
      "9000it [09:04, 10.78it/s]Train epoch: 6 [batch #9000, batch_size 4, seq length 1877]\tLoss: 0.004979\n",
      "9024it [09:07, 10.36it/s]Train epoch: 6 [batch #9025, batch_size 4, seq length 1883]\tLoss: 0.005166\n",
      "9050it [09:09, 10.77it/s]Train epoch: 6 [batch #9050, batch_size 4, seq length 1888]\tLoss: 0.004728\n",
      "9074it [09:11, 10.72it/s]Train epoch: 6 [batch #9075, batch_size 4, seq length 1895]\tLoss: 0.004490\n",
      "9100it [09:14, 10.38it/s]Train epoch: 6 [batch #9100, batch_size 4, seq length 1900]\tLoss: 0.005343\n",
      "9124it [09:16, 10.28it/s]Train epoch: 6 [batch #9125, batch_size 4, seq length 1907]\tLoss: 0.004829\n",
      "9149it [09:19, 10.18it/s]Train epoch: 6 [batch #9150, batch_size 4, seq length 1914]\tLoss: 0.004458\n",
      "9175it [09:21, 10.50it/s]Train epoch: 6 [batch #9175, batch_size 4, seq length 1920]\tLoss: 0.004784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199it [09:23, 10.38it/s]Train epoch: 6 [batch #9200, batch_size 4, seq length 1926]\tLoss: 0.004636\n",
      "9225it [09:26, 10.38it/s]Train epoch: 6 [batch #9225, batch_size 4, seq length 1933]\tLoss: 0.005674\n",
      "9249it [09:28,  9.65it/s]Train epoch: 6 [batch #9250, batch_size 4, seq length 1939]\tLoss: 0.004960\n",
      "9275it [09:31, 10.02it/s]Train epoch: 6 [batch #9275, batch_size 4, seq length 1945]\tLoss: 0.005275\n",
      "9300it [09:33, 10.26it/s]Train epoch: 6 [batch #9300, batch_size 4, seq length 1952]\tLoss: 0.005902\n",
      "9324it [09:36, 10.44it/s]Train epoch: 6 [batch #9325, batch_size 4, seq length 1959]\tLoss: 0.005631\n",
      "9349it [09:38,  9.90it/s]Train epoch: 6 [batch #9350, batch_size 4, seq length 1967]\tLoss: 0.005593\n",
      "9375it [09:41, 10.03it/s]Train epoch: 6 [batch #9375, batch_size 4, seq length 1973]\tLoss: 0.004999\n",
      "9400it [09:43, 10.10it/s]Train epoch: 6 [batch #9400, batch_size 4, seq length 1979]\tLoss: 0.005260\n",
      "9425it [09:46,  9.49it/s]Train epoch: 6 [batch #9425, batch_size 4, seq length 1985]\tLoss: 0.005082\n",
      "9449it [09:48, 10.00it/s]Train epoch: 6 [batch #9450, batch_size 4, seq length 1992]\tLoss: 0.005018\n",
      "9475it [09:51,  9.41it/s]Train epoch: 6 [batch #9475, batch_size 4, seq length 1998]\tLoss: 0.005670\n",
      "9500it [09:53,  9.82it/s]Train epoch: 6 [batch #9500, batch_size 4, seq length 2006]\tLoss: 0.005285\n",
      "9524it [09:56,  9.66it/s]Train epoch: 6 [batch #9525, batch_size 4, seq length 2012]\tLoss: 0.005707\n",
      "9550it [09:58,  9.59it/s]Train epoch: 6 [batch #9550, batch_size 4, seq length 2019]\tLoss: 0.005503\n",
      "9575it [10:01,  9.73it/s]Train epoch: 6 [batch #9575, batch_size 4, seq length 2026]\tLoss: 0.005600\n",
      "9600it [10:04,  9.78it/s]Train epoch: 6 [batch #9600, batch_size 4, seq length 2033]\tLoss: 0.005478\n",
      "9625it [10:06,  9.44it/s]Train epoch: 6 [batch #9625, batch_size 4, seq length 2040]\tLoss: 0.004990\n",
      "9650it [10:09,  9.69it/s]Train epoch: 6 [batch #9650, batch_size 4, seq length 2047]\tLoss: 0.005083\n",
      "9675it [10:11,  9.67it/s]Train epoch: 6 [batch #9675, batch_size 4, seq length 2055]\tLoss: 0.005307\n",
      "9699it [10:14,  9.87it/s]Train epoch: 6 [batch #9700, batch_size 4, seq length 2062]\tLoss: 0.004751\n",
      "9725it [10:16,  9.97it/s]Train epoch: 6 [batch #9725, batch_size 4, seq length 2071]\tLoss: 0.005204\n",
      "9750it [10:19,  9.02it/s]Train epoch: 6 [batch #9750, batch_size 4, seq length 2078]\tLoss: 0.005333\n",
      "9775it [10:22,  9.37it/s]Train epoch: 6 [batch #9775, batch_size 4, seq length 2086]\tLoss: 0.006025\n",
      "9800it [10:24,  8.84it/s]Train epoch: 6 [batch #9800, batch_size 4, seq length 2093]\tLoss: 0.005685\n",
      "9825it [10:27,  9.10it/s]Train epoch: 6 [batch #9825, batch_size 4, seq length 2101]\tLoss: 0.005840\n",
      "9850it [10:30,  9.62it/s]Train epoch: 6 [batch #9850, batch_size 4, seq length 2108]\tLoss: 0.005361\n",
      "9875it [10:32,  9.47it/s]Train epoch: 6 [batch #9875, batch_size 4, seq length 2117]\tLoss: 0.005661\n",
      "9900it [10:35,  8.88it/s]Train epoch: 6 [batch #9900, batch_size 4, seq length 2125]\tLoss: 0.006037\n",
      "9925it [10:38,  8.79it/s]Train epoch: 6 [batch #9925, batch_size 4, seq length 2134]\tLoss: 0.005591\n",
      "9950it [10:40,  9.45it/s]Train epoch: 6 [batch #9950, batch_size 4, seq length 2142]\tLoss: 0.006284\n",
      "9975it [10:43,  9.15it/s]Train epoch: 6 [batch #9975, batch_size 4, seq length 2151]\tLoss: 0.005776\n",
      "10000it [10:46,  8.91it/s]Train epoch: 6 [batch #10000, batch_size 4, seq length 2159]\tLoss: 0.005334\n",
      "10025it [10:49,  9.17it/s]Train epoch: 6 [batch #10025, batch_size 4, seq length 2168]\tLoss: 0.005333\n",
      "10050it [10:51,  8.89it/s]Train epoch: 6 [batch #10050, batch_size 4, seq length 2178]\tLoss: 0.005808\n",
      "10075it [10:54,  8.21it/s]Train epoch: 6 [batch #10075, batch_size 4, seq length 2184]\tLoss: 0.006247\n",
      "10100it [10:57,  8.86it/s]Train epoch: 6 [batch #10100, batch_size 4, seq length 2191]\tLoss: 0.005897\n",
      "10125it [11:00,  8.47it/s]Train epoch: 6 [batch #10125, batch_size 4, seq length 2201]\tLoss: 0.005358\n",
      "10150it [11:03,  9.00it/s]Train epoch: 6 [batch #10150, batch_size 4, seq length 2209]\tLoss: 0.005800\n",
      "10175it [11:05,  8.71it/s]Train epoch: 6 [batch #10175, batch_size 4, seq length 2218]\tLoss: 0.005377\n",
      "10200it [11:08,  8.85it/s]Train epoch: 6 [batch #10200, batch_size 4, seq length 2227]\tLoss: 0.005869\n",
      "10225it [11:11,  8.78it/s]Train epoch: 6 [batch #10225, batch_size 4, seq length 2236]\tLoss: 0.005964\n",
      "10250it [11:14,  8.91it/s]Train epoch: 6 [batch #10250, batch_size 4, seq length 2245]\tLoss: 0.006434\n",
      "10275it [11:17,  8.40it/s]Train epoch: 6 [batch #10275, batch_size 4, seq length 2254]\tLoss: 0.005585\n",
      "10300it [11:20,  9.09it/s]Train epoch: 6 [batch #10300, batch_size 4, seq length 2265]\tLoss: 0.006254\n",
      "10325it [11:22,  8.66it/s]Train epoch: 6 [batch #10325, batch_size 4, seq length 2277]\tLoss: 0.006081\n",
      "10350it [11:25,  8.83it/s]Train epoch: 6 [batch #10350, batch_size 4, seq length 2287]\tLoss: 0.005639\n",
      "10375it [11:28,  8.42it/s]Train epoch: 6 [batch #10375, batch_size 4, seq length 2295]\tLoss: 0.005955\n",
      "10400it [11:31,  8.06it/s]Train epoch: 6 [batch #10400, batch_size 4, seq length 2305]\tLoss: 0.005822\n",
      "10425it [11:34,  8.20it/s]Train epoch: 6 [batch #10425, batch_size 4, seq length 2317]\tLoss: 0.005558\n",
      "10450it [11:37,  7.62it/s]Train epoch: 6 [batch #10450, batch_size 4, seq length 2327]\tLoss: 0.006034\n",
      "10475it [11:40,  8.17it/s]Train epoch: 6 [batch #10475, batch_size 4, seq length 2338]\tLoss: 0.005202\n",
      "10500it [11:43,  8.60it/s]Train epoch: 6 [batch #10500, batch_size 4, seq length 2348]\tLoss: 0.006026\n",
      "10525it [11:46,  8.03it/s]Train epoch: 6 [batch #10525, batch_size 4, seq length 2359]\tLoss: 0.005714\n",
      "10550it [11:49,  8.34it/s]Train epoch: 6 [batch #10550, batch_size 4, seq length 2368]\tLoss: 0.006062\n",
      "10575it [11:52,  8.52it/s]Train epoch: 6 [batch #10575, batch_size 4, seq length 2379]\tLoss: 0.005288\n",
      "10600it [11:55,  8.13it/s]Train epoch: 6 [batch #10600, batch_size 4, seq length 2390]\tLoss: 0.005606\n",
      "10625it [11:59,  8.01it/s]Train epoch: 6 [batch #10625, batch_size 4, seq length 2401]\tLoss: 0.006231\n",
      "10650it [12:02,  8.13it/s]Train epoch: 6 [batch #10650, batch_size 4, seq length 2412]\tLoss: 0.005650\n",
      "10675it [12:05,  7.85it/s]Train epoch: 6 [batch #10675, batch_size 4, seq length 2425]\tLoss: 0.005994\n",
      "10700it [12:08,  7.42it/s]Train epoch: 6 [batch #10700, batch_size 4, seq length 2437]\tLoss: 0.005682\n",
      "10725it [12:11,  7.99it/s]Train epoch: 6 [batch #10725, batch_size 4, seq length 2450]\tLoss: 0.005350\n",
      "10750it [12:14,  8.11it/s]Train epoch: 6 [batch #10750, batch_size 4, seq length 2464]\tLoss: 0.006190\n",
      "10775it [12:18,  8.18it/s]Train epoch: 6 [batch #10775, batch_size 4, seq length 2477]\tLoss: 0.006192\n",
      "10800it [12:21,  7.91it/s]Train epoch: 6 [batch #10800, batch_size 4, seq length 2490]\tLoss: 0.006400\n",
      "10825it [12:24,  7.69it/s]Train epoch: 6 [batch #10825, batch_size 4, seq length 2500]\tLoss: 0.006236\n",
      "10850it [12:27,  7.74it/s]Train epoch: 6 [batch #10850, batch_size 4, seq length 2500]\tLoss: 0.006083\n",
      "10875it [12:30,  7.73it/s]Train epoch: 6 [batch #10875, batch_size 4, seq length 2500]\tLoss: 0.006171\n",
      "10900it [12:34,  7.74it/s]Train epoch: 6 [batch #10900, batch_size 4, seq length 2500]\tLoss: 0.005992\n",
      "10925it [12:37,  7.77it/s]Train epoch: 6 [batch #10925, batch_size 4, seq length 2500]\tLoss: 0.005615\n",
      "10950it [12:40,  7.97it/s]Train epoch: 6 [batch #10950, batch_size 4, seq length 2500]\tLoss: 0.006040\n",
      "10975it [12:43,  7.27it/s]Train epoch: 6 [batch #10975, batch_size 4, seq length 2500]\tLoss: 0.005884\n",
      "11000it [12:47,  7.58it/s]Train epoch: 6 [batch #11000, batch_size 4, seq length 2500]\tLoss: 0.005834\n",
      "11025it [12:50,  8.14it/s]Train epoch: 6 [batch #11025, batch_size 4, seq length 2500]\tLoss: 0.006065\n",
      "11050it [12:53,  7.50it/s]Train epoch: 6 [batch #11050, batch_size 4, seq length 2500]\tLoss: 0.006773\n",
      "11075it [12:56,  7.83it/s]Train epoch: 6 [batch #11075, batch_size 4, seq length 2500]\tLoss: 0.006303\n",
      "11100it [13:00,  7.88it/s]Train epoch: 6 [batch #11100, batch_size 4, seq length 2500]\tLoss: 0.006984\n",
      "11125it [13:03,  7.79it/s]Train epoch: 6 [batch #11125, batch_size 4, seq length 2500]\tLoss: 0.006418\n",
      "11150it [13:06,  7.52it/s]Train epoch: 6 [batch #11150, batch_size 4, seq length 2500]\tLoss: 0.006265\n",
      "11175it [13:09,  7.81it/s]Train epoch: 6 [batch #11175, batch_size 4, seq length 2500]\tLoss: 0.007191\n",
      "11200it [13:12,  7.63it/s]Train epoch: 6 [batch #11200, batch_size 4, seq length 2500]\tLoss: 0.006513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11225it [13:16,  7.80it/s]Train epoch: 6 [batch #11225, batch_size 4, seq length 2500]\tLoss: 0.006465\n",
      "11250it [13:19,  8.11it/s]Train epoch: 6 [batch #11250, batch_size 4, seq length 2500]\tLoss: 0.007033\n",
      "11275it [13:22,  7.93it/s]Train epoch: 6 [batch #11275, batch_size 4, seq length 2500]\tLoss: 0.006730\n",
      "11300it [13:25,  7.74it/s]Train epoch: 6 [batch #11300, batch_size 4, seq length 2500]\tLoss: 0.006231\n",
      "11325it [13:29,  7.99it/s]Train epoch: 6 [batch #11325, batch_size 4, seq length 2500]\tLoss: 0.007332\n",
      "11350it [13:32,  7.74it/s]Train epoch: 6 [batch #11350, batch_size 4, seq length 2500]\tLoss: 0.007141\n",
      "11375it [13:35,  7.77it/s]Train epoch: 6 [batch #11375, batch_size 4, seq length 2500]\tLoss: 0.007328\n",
      "11400it [13:38,  7.77it/s]Train epoch: 6 [batch #11400, batch_size 4, seq length 2500]\tLoss: 0.006425\n",
      "11425it [13:41,  7.77it/s]Train epoch: 6 [batch #11425, batch_size 4, seq length 2500]\tLoss: 0.007251\n",
      "11450it [13:45,  7.70it/s]Train epoch: 6 [batch #11450, batch_size 4, seq length 2500]\tLoss: 0.006324\n",
      "11475it [13:48,  7.84it/s]Train epoch: 6 [batch #11475, batch_size 4, seq length 2500]\tLoss: 0.007580\n",
      "11500it [13:51,  7.49it/s]Train epoch: 6 [batch #11500, batch_size 4, seq length 2500]\tLoss: 0.007252\n",
      "11525it [13:54,  7.52it/s]Train epoch: 6 [batch #11525, batch_size 4, seq length 2500]\tLoss: 0.006742\n",
      "11550it [13:58,  7.91it/s]Train epoch: 6 [batch #11550, batch_size 4, seq length 2500]\tLoss: 0.006598\n",
      "11575it [14:01,  7.76it/s]Train epoch: 6 [batch #11575, batch_size 4, seq length 2500]\tLoss: 0.007696\n",
      "11600it [14:04,  7.54it/s]Train epoch: 6 [batch #11600, batch_size 4, seq length 2500]\tLoss: 0.007104\n",
      "11625it [14:08,  7.55it/s]Train epoch: 6 [batch #11625, batch_size 4, seq length 2500]\tLoss: 0.006715\n",
      "11650it [14:11,  7.87it/s]Train epoch: 6 [batch #11650, batch_size 4, seq length 2500]\tLoss: 0.007137\n",
      "11675it [14:14,  7.44it/s]Train epoch: 6 [batch #11675, batch_size 4, seq length 2500]\tLoss: 0.007563\n",
      "11700it [14:17,  7.33it/s]Train epoch: 6 [batch #11700, batch_size 4, seq length 2500]\tLoss: 0.008236\n",
      "11725it [14:21,  7.54it/s]Train epoch: 6 [batch #11725, batch_size 4, seq length 2500]\tLoss: 0.008046\n",
      "11750it [14:24,  7.76it/s]Train epoch: 6 [batch #11750, batch_size 4, seq length 2500]\tLoss: 0.007828\n",
      "11775it [14:27,  7.43it/s]Train epoch: 6 [batch #11775, batch_size 4, seq length 2500]\tLoss: 0.007889\n",
      "11800it [14:30,  7.93it/s]Train epoch: 6 [batch #11800, batch_size 4, seq length 2500]\tLoss: 0.007656\n",
      "11825it [14:34,  7.61it/s]Train epoch: 6 [batch #11825, batch_size 4, seq length 2500]\tLoss: 0.007971\n",
      "11850it [14:37,  7.75it/s]Train epoch: 6 [batch #11850, batch_size 4, seq length 2500]\tLoss: 0.008342\n",
      "11875it [14:40,  7.74it/s]Train epoch: 6 [batch #11875, batch_size 4, seq length 2500]\tLoss: 0.009154\n",
      "11900it [14:44,  7.62it/s]Train epoch: 6 [batch #11900, batch_size 4, seq length 2500]\tLoss: 0.010964\n",
      "11925it [14:47,  7.57it/s]Train epoch: 6 [batch #11925, batch_size 4, seq length 2500]\tLoss: 0.009328\n",
      "11930it [14:48, 13.43it/s]\n",
      "epoch loss: 0.004456635589044102\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:12, 126.31it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0385, 0.0559, 0.0610, 0.0583, 0.8802\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3291, 0.5363, 0.4599, 0.4952, 0.9817\n",
      "rec_at_8: 0.3532\n",
      "prec_at_8: 0.6493\n",
      "rec_at_15: 0.4954\n",
      "prec_at_15: 0.5086\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [00:27, 123.09it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0403, 0.0634, 0.0654, 0.0644, 0.8712\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3242, 0.5307, 0.4546, 0.4897, 0.9816\n",
      "rec_at_8: 0.3375\n",
      "prec_at_8: 0.6448\n",
      "rec_at_15: 0.4756\n",
      "prec_at_15: 0.5081\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0367, 0.0532, 0.0576, 0.0553, 0.8809\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3270, 0.5420, 0.4519, 0.4928, 0.9819\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0067\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0385, 0.0609, 0.0619, 0.0614, 0.8724\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.3221, 0.5352, 0.4472, 0.4873, 0.9817\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0070\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny-caml_Jun_28_01:08:37\n",
      "\n",
      "EPOCH 7\n",
      "0it [00:00, ?it/s]Train epoch: 7 [batch #0, batch_size 4, seq length 68]\tLoss: 0.005724\n",
      "23it [00:00, 40.25it/s]Train epoch: 7 [batch #25, batch_size 4, seq length 221]\tLoss: 0.003608\n",
      "50it [00:01, 39.88it/s]Train epoch: 7 [batch #50, batch_size 4, seq length 270]\tLoss: 0.003412\n",
      "72it [00:01, 38.41it/s]Train epoch: 7 [batch #75, batch_size 4, seq length 307]\tLoss: 0.002804\n",
      "97it [00:02, 36.61it/s]Train epoch: 7 [batch #100, batch_size 4, seq length 333]\tLoss: 0.002930\n",
      "122it [00:03, 32.82it/s]Train epoch: 7 [batch #125, batch_size 4, seq length 354]\tLoss: 0.002830\n",
      "150it [00:04, 33.50it/s]Train epoch: 7 [batch #150, batch_size 4, seq length 370]\tLoss: 0.002764\n",
      "174it [00:04, 33.53it/s]Train epoch: 7 [batch #175, batch_size 4, seq length 386]\tLoss: 0.002872\n",
      "198it [00:05, 31.98it/s]Train epoch: 7 [batch #200, batch_size 4, seq length 400]\tLoss: 0.002782\n",
      "222it [00:06, 32.17it/s]Train epoch: 7 [batch #225, batch_size 4, seq length 414]\tLoss: 0.003356\n",
      "250it [00:07, 31.55it/s]Train epoch: 7 [batch #250, batch_size 4, seq length 428]\tLoss: 0.002712\n",
      "274it [00:07, 31.13it/s]Train epoch: 7 [batch #275, batch_size 4, seq length 439]\tLoss: 0.002346\n",
      "298it [00:08, 29.30it/s]Train epoch: 7 [batch #300, batch_size 4, seq length 450]\tLoss: 0.003117\n",
      "324it [00:09, 29.55it/s]Train epoch: 7 [batch #325, batch_size 4, seq length 463]\tLoss: 0.002511\n",
      "348it [00:10, 28.58it/s]Train epoch: 7 [batch #350, batch_size 4, seq length 472]\tLoss: 0.003052\n",
      "373it [00:11, 29.88it/s]Train epoch: 7 [batch #375, batch_size 4, seq length 480]\tLoss: 0.002887\n",
      "398it [00:12, 28.87it/s]Train epoch: 7 [batch #400, batch_size 4, seq length 489]\tLoss: 0.002870\n",
      "424it [00:13, 30.09it/s]Train epoch: 7 [batch #425, batch_size 4, seq length 497]\tLoss: 0.002909\n",
      "448it [00:13, 29.91it/s]Train epoch: 7 [batch #450, batch_size 4, seq length 504]\tLoss: 0.002759\n",
      "472it [00:14, 30.84it/s]Train epoch: 7 [batch #475, batch_size 4, seq length 512]\tLoss: 0.003197\n",
      "497it [00:15, 28.36it/s]Train epoch: 7 [batch #500, batch_size 4, seq length 519]\tLoss: 0.002741\n",
      "523it [00:16, 27.76it/s]Train epoch: 7 [batch #525, batch_size 4, seq length 527]\tLoss: 0.002970\n",
      "548it [00:17, 29.97it/s]Train epoch: 7 [batch #550, batch_size 4, seq length 534]\tLoss: 0.002871\n",
      "575it [00:18, 29.11it/s]Train epoch: 7 [batch #575, batch_size 4, seq length 541]\tLoss: 0.002881\n",
      "600it [00:19, 26.98it/s]Train epoch: 7 [batch #600, batch_size 4, seq length 547]\tLoss: 0.003129\n",
      "623it [00:19, 27.87it/s]Train epoch: 7 [batch #625, batch_size 4, seq length 553]\tLoss: 0.003107\n",
      "650it [00:20, 28.94it/s]Train epoch: 7 [batch #650, batch_size 4, seq length 559]\tLoss: 0.002761\n",
      "674it [00:21, 27.39it/s]Train epoch: 7 [batch #675, batch_size 4, seq length 566]\tLoss: 0.002333\n",
      "698it [00:22, 27.54it/s]Train epoch: 7 [batch #700, batch_size 4, seq length 573]\tLoss: 0.002847\n",
      "725it [00:23, 26.89it/s]Train epoch: 7 [batch #725, batch_size 4, seq length 578]\tLoss: 0.002962\n",
      "747it [00:24, 27.64it/s]Train epoch: 7 [batch #750, batch_size 4, seq length 584]\tLoss: 0.002774\n",
      "775it [00:25, 27.91it/s]Train epoch: 7 [batch #775, batch_size 4, seq length 589]\tLoss: 0.003102\n",
      "800it [00:26, 27.56it/s]Train epoch: 7 [batch #800, batch_size 4, seq length 596]\tLoss: 0.002991\n",
      "824it [00:27, 26.80it/s]Train epoch: 7 [batch #825, batch_size 4, seq length 601]\tLoss: 0.002992\n",
      "849it [00:28, 25.52it/s]Train epoch: 7 [batch #850, batch_size 4, seq length 606]\tLoss: 0.003270\n",
      "875it [00:29, 26.64it/s]Train epoch: 7 [batch #875, batch_size 4, seq length 612]\tLoss: 0.002797\n",
      "899it [00:30, 26.58it/s]Train epoch: 7 [batch #900, batch_size 4, seq length 617]\tLoss: 0.003105\n",
      "924it [00:31, 25.31it/s]Train epoch: 7 [batch #925, batch_size 4, seq length 622]\tLoss: 0.002856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949it [00:31, 25.65it/s]Train epoch: 7 [batch #950, batch_size 4, seq length 627]\tLoss: 0.002790\n",
      "973it [00:32, 27.08it/s]Train epoch: 7 [batch #975, batch_size 4, seq length 632]\tLoss: 0.002191\n",
      "1000it [00:33, 24.92it/s]Train epoch: 7 [batch #1000, batch_size 4, seq length 637]\tLoss: 0.003020\n",
      "1024it [00:34, 25.99it/s]Train epoch: 7 [batch #1025, batch_size 4, seq length 642]\tLoss: 0.004003\n",
      "1048it [00:35, 26.15it/s]Train epoch: 7 [batch #1050, batch_size 4, seq length 646]\tLoss: 0.002799\n",
      "1073it [00:36, 26.52it/s]Train epoch: 7 [batch #1075, batch_size 4, seq length 651]\tLoss: 0.003218\n",
      "1098it [00:37, 25.85it/s]Train epoch: 7 [batch #1100, batch_size 4, seq length 656]\tLoss: 0.003214\n",
      "1123it [00:38, 25.46it/s]Train epoch: 7 [batch #1125, batch_size 4, seq length 661]\tLoss: 0.003142\n",
      "1150it [00:39, 25.08it/s]Train epoch: 7 [batch #1150, batch_size 4, seq length 665]\tLoss: 0.003161\n",
      "1174it [00:40, 25.77it/s]Train epoch: 7 [batch #1175, batch_size 4, seq length 669]\tLoss: 0.003080\n",
      "1198it [00:41, 24.65it/s]Train epoch: 7 [batch #1200, batch_size 4, seq length 674]\tLoss: 0.003224\n",
      "1223it [00:42, 22.92it/s]Train epoch: 7 [batch #1225, batch_size 4, seq length 679]\tLoss: 0.003351\n",
      "1250it [00:43, 25.40it/s]Train epoch: 7 [batch #1250, batch_size 4, seq length 683]\tLoss: 0.003189\n",
      "1274it [00:44, 23.73it/s]Train epoch: 7 [batch #1275, batch_size 4, seq length 688]\tLoss: 0.002739\n",
      "1298it [00:45, 24.77it/s]Train epoch: 7 [batch #1300, batch_size 4, seq length 692]\tLoss: 0.002758\n",
      "1325it [00:46, 25.30it/s]Train epoch: 7 [batch #1325, batch_size 4, seq length 697]\tLoss: 0.002886\n",
      "1350it [00:47, 25.70it/s]Train epoch: 7 [batch #1350, batch_size 4, seq length 700]\tLoss: 0.003777\n",
      "1374it [00:48, 23.88it/s]Train epoch: 7 [batch #1375, batch_size 4, seq length 705]\tLoss: 0.003041\n",
      "1395it [00:49, 25.77it/s]^C\n",
      "1395it [00:49, 28.12it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"training.py\", line 882, in <module>\n",
      "    main(args)\n",
      "  File \"training.py\", line 52, in main\n",
      "    epochs_trained = train_epochs(args, model, optimizer, params, dicts, scheduler, labels_weight)\n",
      "  File \"training.py\", line 172, in train_epochs\n",
      "    labels_weight, \\\n",
      "  File \"training.py\", line 307, in one_epoch\n",
      "    labels_weight, \\\n",
      "  File \"training.py\", line 455, in train\n",
      "    loss.backward()\n",
      "  File \"/home/voyageth/develop/anaconda3/envs/mlhc/lib/python3.7/site-packages/torch/tensor.py\", line 198, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/voyageth/develop/anaconda3/envs/mlhc/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 100, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# 16 epoch 부터 다시 돌림\n",
    "# bert-tiny 2500 word2vec\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny-caml \\\n",
    "    15 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience 10 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 4 \\\n",
    "    --last_module caml_attn \\\n",
    "    --max_sequence_length 2500 \\\n",
    "    --from_prev_result ./outputs/debug3/bert-tiny-caml_Jun_27_21:08:37\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(Y='full', batch_size=8, bert_parallel_count=None, bert_parallel_final_layer='sum', bidirectional=None, cell_type='gru', code_emb=None, criterion='prec_at_8', cuda_device_no=None, data_path='./mimicdata/mimic3/train_full.csv', dropout=0.2, embed_file='./mimicdata/mimic3/processed_full.embed', embed_size=100, filter_size='10', from_prev_result=None, from_scratch=False, gpu=True, last_module='caml_attn', lmbda=0, lr=5e-05, max_sequence_length=512, model='bert-tiny', n_epochs=50, num_filter_maps=50, patience=3, pool=None, pos=False, pretrain=False, pretrain_batch_size=2, pretrain_datafile='./mimicdata/mimic3/pretrain_bert_tiny_2500', pretrain_epochs=3, pretrain_lr=0.0001, public_model=None, quiet=None, redefined_tokenizer=True, rnn_dim=128, rnn_layers=1, samples=None, seed=3902, stack_filters=None, test_model=None, tokenizer_path='./tokenizers/bert-tiny-mimic3-full-100-limit-100000-vocab.txt', version='mimic3', vocab='./mimicdata/mimic3/vocab.csv', warmup_steps=0, weight_decay=0)\n",
      "loading lookups...\n",
      "BertForMedical(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (redefined_word_embeddings): Embedding(100000, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (bert_pool): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (bert_attention): Linear(in_features=128, out_features=8921, bias=False)\n",
      "  (bert_classifier): Linear(in_features=128, out_features=8921, bias=True)\n",
      ")\n",
      "EPOCH 0\n",
      "0it [00:00, ?it/s]Train epoch: 0 [batch #0, batch_size 8, seq length 512]\tLoss: 0.696047\n",
      "24it [00:01, 15.67it/s]Train epoch: 0 [batch #25, batch_size 8, seq length 512]\tLoss: 0.628568\n",
      "50it [00:03, 13.91it/s]Train epoch: 0 [batch #50, batch_size 8, seq length 512]\tLoss: 0.495322\n",
      "74it [00:05, 13.57it/s]Train epoch: 0 [batch #75, batch_size 8, seq length 512]\tLoss: 0.356773\n",
      "100it [00:07, 13.14it/s]Train epoch: 0 [batch #100, batch_size 8, seq length 512]\tLoss: 0.246004\n",
      "124it [00:09, 12.74it/s]Train epoch: 0 [batch #125, batch_size 8, seq length 512]\tLoss: 0.167409\n",
      "150it [00:11, 12.07it/s]Train epoch: 0 [batch #150, batch_size 8, seq length 512]\tLoss: 0.115656\n",
      "174it [00:13, 11.66it/s]Train epoch: 0 [batch #175, batch_size 8, seq length 512]\tLoss: 0.082721\n",
      "200it [00:15, 11.34it/s]Train epoch: 0 [batch #200, batch_size 8, seq length 512]\tLoss: 0.060863\n",
      "224it [00:17, 11.91it/s]Train epoch: 0 [batch #225, batch_size 8, seq length 512]\tLoss: 0.046904\n",
      "250it [00:19, 11.27it/s]Train epoch: 0 [batch #250, batch_size 8, seq length 512]\tLoss: 0.037289\n",
      "274it [00:22, 11.42it/s]Train epoch: 0 [batch #275, batch_size 8, seq length 512]\tLoss: 0.030550\n",
      "300it [00:24, 11.25it/s]Train epoch: 0 [batch #300, batch_size 8, seq length 512]\tLoss: 0.026320\n",
      "324it [00:26, 11.13it/s]Train epoch: 0 [batch #325, batch_size 8, seq length 512]\tLoss: 0.022312\n",
      "350it [00:28, 10.94it/s]Train epoch: 0 [batch #350, batch_size 8, seq length 512]\tLoss: 0.019603\n",
      "374it [00:31, 10.45it/s]Train epoch: 0 [batch #375, batch_size 8, seq length 512]\tLoss: 0.017334\n",
      "400it [00:33, 10.23it/s]Train epoch: 0 [batch #400, batch_size 8, seq length 512]\tLoss: 0.015422\n",
      "424it [00:36, 10.16it/s]Train epoch: 0 [batch #425, batch_size 8, seq length 512]\tLoss: 0.014848\n",
      "450it [00:38,  9.80it/s]Train epoch: 0 [batch #450, batch_size 8, seq length 512]\tLoss: 0.013249\n",
      "475it [00:41, 10.27it/s]Train epoch: 0 [batch #475, batch_size 8, seq length 512]\tLoss: 0.012049\n",
      "500it [00:43,  9.91it/s]Train epoch: 0 [batch #500, batch_size 8, seq length 512]\tLoss: 0.011992\n",
      "525it [00:46,  9.85it/s]Train epoch: 0 [batch #525, batch_size 8, seq length 512]\tLoss: 0.011188\n",
      "550it [00:48, 10.03it/s]Train epoch: 0 [batch #550, batch_size 8, seq length 512]\tLoss: 0.010863\n",
      "575it [00:51,  9.94it/s]Train epoch: 0 [batch #575, batch_size 8, seq length 512]\tLoss: 0.010524\n",
      "600it [00:53,  9.80it/s]Train epoch: 0 [batch #600, batch_size 8, seq length 512]\tLoss: 0.009817\n",
      "625it [00:56,  9.69it/s]Train epoch: 0 [batch #625, batch_size 8, seq length 512]\tLoss: 0.009578\n",
      "650it [00:58,  9.67it/s]Train epoch: 0 [batch #650, batch_size 8, seq length 512]\tLoss: 0.009217\n",
      "675it [01:01,  9.62it/s]Train epoch: 0 [batch #675, batch_size 8, seq length 512]\tLoss: 0.009829\n",
      "700it [01:04,  8.80it/s]Train epoch: 0 [batch #700, batch_size 8, seq length 512]\tLoss: 0.008985\n",
      "725it [01:06,  9.22it/s]Train epoch: 0 [batch #725, batch_size 8, seq length 512]\tLoss: 0.008595\n",
      "750it [01:09,  9.23it/s]Train epoch: 0 [batch #750, batch_size 8, seq length 512]\tLoss: 0.009345\n",
      "775it [01:12,  9.24it/s]Train epoch: 0 [batch #775, batch_size 8, seq length 512]\tLoss: 0.008006\n",
      "800it [01:14,  9.36it/s]Train epoch: 0 [batch #800, batch_size 8, seq length 512]\tLoss: 0.007747\n",
      "825it [01:17,  9.35it/s]Train epoch: 0 [batch #825, batch_size 8, seq length 512]\tLoss: 0.008098\n",
      "850it [01:20,  9.35it/s]Train epoch: 0 [batch #850, batch_size 8, seq length 512]\tLoss: 0.007864\n",
      "875it [01:23,  8.83it/s]Train epoch: 0 [batch #875, batch_size 8, seq length 512]\tLoss: 0.008271\n",
      "900it [01:25,  8.55it/s]Train epoch: 0 [batch #900, batch_size 8, seq length 512]\tLoss: 0.007971\n",
      "925it [01:28,  9.07it/s]Train epoch: 0 [batch #925, batch_size 8, seq length 512]\tLoss: 0.008108\n",
      "950it [01:31,  8.60it/s]Train epoch: 0 [batch #950, batch_size 8, seq length 512]\tLoss: 0.006912\n",
      "975it [01:34,  9.02it/s]Train epoch: 0 [batch #975, batch_size 8, seq length 512]\tLoss: 0.008099\n",
      "1000it [01:37,  9.24it/s]Train epoch: 0 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.007420\n",
      "1025it [01:40,  8.82it/s]Train epoch: 0 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.007262\n",
      "1050it [01:42,  8.85it/s]Train epoch: 0 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.007585\n",
      "1075it [01:45,  8.69it/s]Train epoch: 0 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.007414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100it [01:48,  8.37it/s]Train epoch: 0 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.007605\n",
      "1125it [01:51,  8.19it/s]Train epoch: 0 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.007371\n",
      "1150it [01:54,  8.35it/s]Train epoch: 0 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.006683\n",
      "1175it [01:57,  8.20it/s]Train epoch: 0 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.007755\n",
      "1200it [02:00,  8.54it/s]Train epoch: 0 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.007777\n",
      "1225it [02:03,  8.36it/s]Train epoch: 0 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.007410\n",
      "1250it [02:06,  8.36it/s]Train epoch: 0 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.007138\n",
      "1275it [02:09,  8.48it/s]Train epoch: 0 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.008634\n",
      "1300it [02:12,  8.32it/s]Train epoch: 0 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.007190\n",
      "1325it [02:15,  8.20it/s]Train epoch: 0 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.007517\n",
      "1350it [02:18,  7.69it/s]Train epoch: 0 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.007014\n",
      "1375it [02:22,  8.50it/s]Train epoch: 0 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.008239\n",
      "1400it [02:25,  8.07it/s]Train epoch: 0 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.007051\n",
      "1425it [02:28,  7.95it/s]Train epoch: 0 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.007297\n",
      "1450it [02:31,  8.17it/s]Train epoch: 0 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.007460\n",
      "1475it [02:34,  7.94it/s]Train epoch: 0 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.007429\n",
      "1500it [02:37,  8.33it/s]Train epoch: 0 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.008082\n",
      "1525it [02:40,  8.16it/s]Train epoch: 0 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.007766\n",
      "1550it [02:43,  7.89it/s]Train epoch: 0 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.007393\n",
      "1575it [02:47,  7.64it/s]Train epoch: 0 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.007117\n",
      "1600it [02:50,  8.04it/s]Train epoch: 0 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.007983\n",
      "1625it [02:53,  7.91it/s]Train epoch: 0 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.007543\n",
      "1650it [02:56,  7.68it/s]Train epoch: 0 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.008181\n",
      "1675it [03:00,  7.57it/s]Train epoch: 0 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.007759\n",
      "1700it [03:03,  7.86it/s]Train epoch: 0 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.007697\n",
      "1725it [03:06,  7.71it/s]Train epoch: 0 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.007608\n",
      "1750it [03:09,  7.41it/s]Train epoch: 0 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.007628\n",
      "1775it [03:13,  7.68it/s]Train epoch: 0 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.007755\n",
      "1800it [03:16,  7.61it/s]Train epoch: 0 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.007893\n",
      "1825it [03:19,  7.19it/s]Train epoch: 0 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.007487\n",
      "1850it [03:23,  7.08it/s]Train epoch: 0 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.007236\n",
      "1875it [03:26,  7.48it/s]Train epoch: 0 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.007689\n",
      "1900it [03:29,  7.22it/s]Train epoch: 0 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.008368\n",
      "1925it [03:33,  7.52it/s]Train epoch: 0 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.007449\n",
      "1950it [03:36,  7.28it/s]Train epoch: 0 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.007846\n",
      "1975it [03:40,  7.45it/s]Train epoch: 0 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.008336\n",
      "2000it [03:43,  7.16it/s]Train epoch: 0 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.007257\n",
      "2025it [03:47,  7.29it/s]Train epoch: 0 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.007613\n",
      "2050it [03:50,  7.35it/s]Train epoch: 0 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.007897\n",
      "2075it [03:54,  7.28it/s]Train epoch: 0 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.007579\n",
      "2100it [03:57,  7.16it/s]Train epoch: 0 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.008018\n",
      "2125it [04:01,  6.88it/s]Train epoch: 0 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.007833\n",
      "2150it [04:04,  7.08it/s]Train epoch: 0 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.008248\n",
      "2175it [04:08,  7.06it/s]Train epoch: 0 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.007953\n",
      "2200it [04:11,  7.03it/s]Train epoch: 0 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.007779\n",
      "2225it [04:15,  7.12it/s]Train epoch: 0 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.007453\n",
      "2250it [04:18,  7.19it/s]Train epoch: 0 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.008361\n",
      "2275it [04:22,  7.02it/s]Train epoch: 0 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.007490\n",
      "2300it [04:25,  6.99it/s]Train epoch: 0 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.007261\n",
      "2325it [04:29,  6.74it/s]Train epoch: 0 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.008149\n",
      "2350it [04:33,  6.72it/s]Train epoch: 0 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.007637\n",
      "2375it [04:36,  6.84it/s]Train epoch: 0 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.008277\n",
      "2400it [04:40,  6.73it/s]Train epoch: 0 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.008325\n",
      "2425it [04:44,  6.57it/s]Train epoch: 0 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.008209\n",
      "2450it [04:48,  6.73it/s]Train epoch: 0 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.008081\n",
      "2475it [04:51,  6.89it/s]Train epoch: 0 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.007538\n",
      "2500it [04:55,  6.71it/s]Train epoch: 0 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.007989\n",
      "2525it [04:59,  6.66it/s]Train epoch: 0 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.007538\n",
      "2550it [05:03,  6.40it/s]Train epoch: 0 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.007612\n",
      "2575it [05:06,  6.78it/s]Train epoch: 0 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.008278\n",
      "2600it [05:10,  6.58it/s]Train epoch: 0 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.007723\n",
      "2625it [05:14,  6.58it/s]Train epoch: 0 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.008083\n",
      "2650it [05:18,  6.71it/s]Train epoch: 0 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.007720\n",
      "2675it [05:21,  6.45it/s]Train epoch: 0 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.008321\n",
      "2700it [05:25,  6.50it/s]Train epoch: 0 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.009030\n",
      "2725it [05:29,  6.52it/s]Train epoch: 0 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.008402\n",
      "2750it [05:33,  6.61it/s]Train epoch: 0 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.009177\n",
      "2775it [05:37,  6.31it/s]Train epoch: 0 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.008009\n",
      "2800it [05:41,  6.52it/s]Train epoch: 0 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.008708\n",
      "2825it [05:44,  6.37it/s]Train epoch: 0 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.007551\n",
      "2850it [05:48,  6.60it/s]Train epoch: 0 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.008424\n",
      "2875it [05:52,  6.59it/s]Train epoch: 0 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.008998\n",
      "2900it [05:56,  6.27it/s]Train epoch: 0 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.008373\n",
      "2925it [06:00,  6.45it/s]Train epoch: 0 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.008694\n",
      "2950it [06:04,  6.49it/s]Train epoch: 0 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.009107\n",
      "2975it [06:08,  6.52it/s]Train epoch: 0 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.008079\n",
      "3000it [06:12,  6.08it/s]Train epoch: 0 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.008425\n",
      "3025it [06:16,  6.35it/s]Train epoch: 0 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.008312\n",
      "3050it [06:20,  6.11it/s]Train epoch: 0 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.008135\n",
      "3075it [06:24,  6.40it/s]Train epoch: 0 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.008436\n",
      "3100it [06:28,  6.40it/s]Train epoch: 0 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.008500\n",
      "3125it [06:32,  6.17it/s]Train epoch: 0 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.008118\n",
      "3150it [06:36,  6.06it/s]Train epoch: 0 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.008495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175it [06:40,  6.13it/s]Train epoch: 0 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.008880\n",
      "3200it [06:44,  6.12it/s]Train epoch: 0 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.008181\n",
      "3225it [06:48,  5.91it/s]Train epoch: 0 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.008448\n",
      "3250it [06:52,  6.08it/s]Train epoch: 0 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.008816\n",
      "3275it [06:56,  6.03it/s]Train epoch: 0 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.008473\n",
      "3300it [07:01,  6.05it/s]Train epoch: 0 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.008998\n",
      "3325it [07:05,  5.70it/s]Train epoch: 0 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.008809\n",
      "3350it [07:09,  5.76it/s]Train epoch: 0 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.009161\n",
      "3375it [07:13,  5.94it/s]Train epoch: 0 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.008129\n",
      "3400it [07:18,  5.96it/s]Train epoch: 0 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.008774\n",
      "3425it [07:22,  5.97it/s]Train epoch: 0 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.008773\n",
      "3450it [07:26,  5.85it/s]Train epoch: 0 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.008391\n",
      "3475it [07:31,  5.80it/s]Train epoch: 0 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.009188\n",
      "3500it [07:35,  5.80it/s]Train epoch: 0 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.008583\n",
      "3525it [07:39,  5.81it/s]Train epoch: 0 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.008187\n",
      "3550it [07:43,  5.79it/s]Train epoch: 0 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.009220\n",
      "3575it [07:48,  5.68it/s]Train epoch: 0 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.008736\n",
      "3600it [07:52,  5.51it/s]Train epoch: 0 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.009451\n",
      "3625it [07:57,  5.60it/s]Train epoch: 0 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.008604\n",
      "3650it [08:01,  5.64it/s]Train epoch: 0 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.009359\n",
      "3675it [08:05,  5.68it/s]Train epoch: 0 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.009152\n",
      "3700it [08:10,  5.50it/s]Train epoch: 0 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.008778\n",
      "3725it [08:14,  5.66it/s]Train epoch: 0 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.009221\n",
      "3750it [08:19,  5.75it/s]Train epoch: 0 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.009019\n",
      "3775it [08:23,  5.70it/s]Train epoch: 0 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.009268\n",
      "3800it [08:28,  5.31it/s]Train epoch: 0 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.009843\n",
      "3825it [08:32,  5.62it/s]Train epoch: 0 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.009027\n",
      "3850it [08:37,  5.74it/s]Train epoch: 0 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.008713\n",
      "3875it [08:41,  5.62it/s]Train epoch: 0 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.009199\n",
      "3900it [08:46,  5.34it/s]Train epoch: 0 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.009305\n",
      "3925it [08:50,  5.62it/s]Train epoch: 0 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.008458\n",
      "3950it [08:55,  5.34it/s]Train epoch: 0 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.008843\n",
      "3975it [09:00,  5.08it/s]Train epoch: 0 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.009422\n",
      "4000it [09:05,  5.42it/s]Train epoch: 0 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.008775\n",
      "4025it [09:09,  5.27it/s]Train epoch: 0 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.008920\n",
      "4050it [09:14,  5.19it/s]Train epoch: 0 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.008838\n",
      "4075it [09:19,  5.34it/s]Train epoch: 0 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.008723\n",
      "4100it [09:24,  5.21it/s]Train epoch: 0 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.009024\n",
      "4125it [09:28,  5.09it/s]Train epoch: 0 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.009270\n",
      "4150it [09:33,  5.28it/s]Train epoch: 0 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.009451\n",
      "4175it [09:38,  5.08it/s]Train epoch: 0 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.008880\n",
      "4200it [09:43,  5.18it/s]Train epoch: 0 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.008478\n",
      "4225it [09:48,  5.24it/s]Train epoch: 0 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.009180\n",
      "4250it [09:53,  5.14it/s]Train epoch: 0 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.009751\n",
      "4275it [09:58,  5.26it/s]Train epoch: 0 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.009615\n",
      "4300it [10:03,  5.18it/s]Train epoch: 0 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.009289\n",
      "4325it [10:08,  5.20it/s]Train epoch: 0 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.009543\n",
      "4350it [10:12,  5.14it/s]Train epoch: 0 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.009882\n",
      "4375it [10:17,  5.03it/s]Train epoch: 0 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.009464\n",
      "4400it [10:23,  4.98it/s]Train epoch: 0 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.009260\n",
      "4425it [10:28,  5.00it/s]Train epoch: 0 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.009709\n",
      "4450it [10:33,  4.98it/s]Train epoch: 0 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.009273\n",
      "4475it [10:38,  4.61it/s]Train epoch: 0 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.010579\n",
      "4500it [10:43,  4.90it/s]Train epoch: 0 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.010030\n",
      "4525it [10:48,  4.85it/s]Train epoch: 0 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.009766\n",
      "4550it [10:53,  4.75it/s]Train epoch: 0 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.009697\n",
      "4575it [10:58,  4.94it/s]Train epoch: 0 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.009156\n",
      "4600it [11:03,  4.89it/s]Train epoch: 0 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.009493\n",
      "4625it [11:08,  4.88it/s]Train epoch: 0 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.009777\n",
      "4650it [11:14,  4.86it/s]Train epoch: 0 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.010110\n",
      "4675it [11:19,  4.88it/s]Train epoch: 0 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.010049\n",
      "4700it [11:24,  4.46it/s]Train epoch: 0 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.009560\n",
      "4725it [11:30,  4.72it/s]Train epoch: 0 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.010314\n",
      "4750it [11:35,  4.60it/s]Train epoch: 0 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.009923\n",
      "4775it [11:41,  4.68it/s]Train epoch: 0 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.009899\n",
      "4800it [11:46,  4.61it/s]Train epoch: 0 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.010359\n",
      "4825it [11:51,  4.60it/s]Train epoch: 0 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.009181\n",
      "4850it [11:57,  4.68it/s]Train epoch: 0 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.009726\n",
      "4875it [12:02,  4.45it/s]Train epoch: 0 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.009855\n",
      "4900it [12:08,  4.53it/s]Train epoch: 0 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.010149\n",
      "4925it [12:13,  4.37it/s]Train epoch: 0 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.010307\n",
      "4950it [12:19,  4.53it/s]Train epoch: 0 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.010424\n",
      "4975it [12:25,  4.31it/s]Train epoch: 0 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.010638\n",
      "5000it [12:30,  4.40it/s]Train epoch: 0 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.010140\n",
      "5025it [12:36,  4.34it/s]Train epoch: 0 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.010938\n",
      "5050it [12:42,  4.33it/s]Train epoch: 0 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.010586\n",
      "5075it [12:48,  4.26it/s]Train epoch: 0 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.010124\n",
      "5100it [12:53,  4.33it/s]Train epoch: 0 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.010215\n",
      "5125it [12:59,  4.11it/s]Train epoch: 0 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.011191\n",
      "5150it [13:05,  4.19it/s]Train epoch: 0 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.010694\n",
      "5175it [13:11,  4.15it/s]Train epoch: 0 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.010743\n",
      "5200it [13:17,  4.23it/s]Train epoch: 0 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.011400\n",
      "5225it [13:23,  4.10it/s]Train epoch: 0 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.011053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5250it [13:29,  4.06it/s]Train epoch: 0 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.010614\n",
      "5275it [13:35,  4.24it/s]Train epoch: 0 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.010743\n",
      "5300it [13:41,  4.15it/s]Train epoch: 0 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.010469\n",
      "5325it [13:48,  4.10it/s]Train epoch: 0 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.010495\n",
      "5350it [13:54,  4.05it/s]Train epoch: 0 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.010979\n",
      "5375it [14:00,  4.06it/s]Train epoch: 0 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.011209\n",
      "5400it [14:06,  3.89it/s]Train epoch: 0 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.011240\n",
      "5425it [14:13,  3.71it/s]Train epoch: 0 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.011051\n",
      "5450it [14:19,  3.81it/s]Train epoch: 0 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.011109\n",
      "5475it [14:26,  3.75it/s]Train epoch: 0 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.011091\n",
      "5500it [14:32,  3.70it/s]Train epoch: 0 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.011298\n",
      "5525it [14:39,  3.73it/s]Train epoch: 0 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.011812\n",
      "5550it [14:46,  3.82it/s]Train epoch: 0 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.011854\n",
      "5575it [14:52,  3.60it/s]Train epoch: 0 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.010787\n",
      "5600it [14:59,  3.61it/s]Train epoch: 0 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.011154\n",
      "5625it [15:06,  3.41it/s]Train epoch: 0 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.012020\n",
      "5650it [15:13,  3.46it/s]Train epoch: 0 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.010794\n",
      "5675it [15:21,  3.43it/s]Train epoch: 0 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.012110\n",
      "5700it [15:28,  3.38it/s]Train epoch: 0 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.011635\n",
      "5725it [15:35,  3.39it/s]Train epoch: 0 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.012207\n",
      "5750it [15:43,  3.18it/s]Train epoch: 0 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.012615\n",
      "5775it [15:51,  3.27it/s]Train epoch: 0 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.012040\n",
      "5800it [15:59,  3.17it/s]Train epoch: 0 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.012419\n",
      "5825it [16:07,  2.99it/s]Train epoch: 0 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.012716\n",
      "5850it [16:15,  2.98it/s]Train epoch: 0 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.012308\n",
      "5875it [16:24,  2.85it/s]Train epoch: 0 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.013234\n",
      "5900it [16:33,  2.59it/s]Train epoch: 0 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.012133\n",
      "5925it [16:43,  2.52it/s]Train epoch: 0 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.014001\n",
      "5950it [16:54,  2.12it/s]Train epoch: 0 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.014617\n",
      "5965it [17:02,  5.83it/s]\n",
      "epoch loss: 0.01948308652666556\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:35, 45.61it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0001, 0.0001, 0.0001, 0.0001, 0.6256\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0134, 0.3342, 0.0138, 0.0264, 0.9432\n",
      "rec_at_8: 0.0933\n",
      "prec_at_8: 0.2092\n",
      "rec_at_15: 0.1420\n",
      "prec_at_15: 0.1694\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:12, 46.25it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0001, 0.0001, 0.0001, 0.0001, 0.6230\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0130, 0.3298, 0.0133, 0.0256, 0.9415\n",
      "rec_at_8: 0.0921\n",
      "prec_at_8: 0.2148\n",
      "rec_at_15: 0.1409\n",
      "prec_at_15: 0.1751\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 0\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0001, 0.0001, 0.0001, 0.0001, 0.6256\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0134, 0.3342, 0.0138, 0.0264, 0.9432\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0100\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 0\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0001, 0.0001, 0.0001, 0.0001, 0.6230\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0130, 0.3298, 0.0133, 0.0256, 0.9415\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0103\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 1\n",
      "0it [00:00, ?it/s]Train epoch: 1 [batch #0, batch_size 8, seq length 512]\tLoss: 0.006994\n",
      "24it [00:01, 14.60it/s]Train epoch: 1 [batch #25, batch_size 8, seq length 512]\tLoss: 0.006538\n",
      "50it [00:03, 13.55it/s]Train epoch: 1 [batch #50, batch_size 8, seq length 512]\tLoss: 0.006069\n",
      "74it [00:05, 13.46it/s]Train epoch: 1 [batch #75, batch_size 8, seq length 512]\tLoss: 0.005757\n",
      "100it [00:07, 13.00it/s]Train epoch: 1 [batch #100, batch_size 8, seq length 512]\tLoss: 0.005932\n",
      "124it [00:09, 12.36it/s]Train epoch: 1 [batch #125, batch_size 8, seq length 512]\tLoss: 0.005878\n",
      "150it [00:11, 11.97it/s]Train epoch: 1 [batch #150, batch_size 8, seq length 512]\tLoss: 0.005624\n",
      "174it [00:13, 11.99it/s]Train epoch: 1 [batch #175, batch_size 8, seq length 512]\tLoss: 0.006188\n",
      "200it [00:15, 11.20it/s]Train epoch: 1 [batch #200, batch_size 8, seq length 512]\tLoss: 0.005258\n",
      "224it [00:17, 11.96it/s]Train epoch: 1 [batch #225, batch_size 8, seq length 512]\tLoss: 0.005762\n",
      "250it [00:19, 11.14it/s]Train epoch: 1 [batch #250, batch_size 8, seq length 512]\tLoss: 0.005631\n",
      "274it [00:21, 11.29it/s]Train epoch: 1 [batch #275, batch_size 8, seq length 512]\tLoss: 0.005767\n",
      "300it [00:24, 10.89it/s]Train epoch: 1 [batch #300, batch_size 8, seq length 512]\tLoss: 0.006280\n",
      "324it [00:26, 10.72it/s]Train epoch: 1 [batch #325, batch_size 8, seq length 512]\tLoss: 0.005902\n",
      "350it [00:28, 10.61it/s]Train epoch: 1 [batch #350, batch_size 8, seq length 512]\tLoss: 0.005916\n",
      "374it [00:31, 11.00it/s]Train epoch: 1 [batch #375, batch_size 8, seq length 512]\tLoss: 0.005776\n",
      "400it [00:33, 10.84it/s]Train epoch: 1 [batch #400, batch_size 8, seq length 512]\tLoss: 0.005490\n",
      "424it [00:35, 10.59it/s]Train epoch: 1 [batch #425, batch_size 8, seq length 512]\tLoss: 0.006401\n",
      "450it [00:38, 10.33it/s]Train epoch: 1 [batch #450, batch_size 8, seq length 512]\tLoss: 0.005783\n",
      "474it [00:40, 10.23it/s]Train epoch: 1 [batch #475, batch_size 8, seq length 512]\tLoss: 0.005494\n",
      "500it [00:43, 10.00it/s]Train epoch: 1 [batch #500, batch_size 8, seq length 512]\tLoss: 0.006227\n",
      "524it [00:45,  9.77it/s]Train epoch: 1 [batch #525, batch_size 8, seq length 512]\tLoss: 0.005882\n",
      "550it [00:48,  9.56it/s]Train epoch: 1 [batch #550, batch_size 8, seq length 512]\tLoss: 0.006341\n",
      "575it [00:50,  9.72it/s]Train epoch: 1 [batch #575, batch_size 8, seq length 512]\tLoss: 0.006410\n",
      "600it [00:53,  9.90it/s]Train epoch: 1 [batch #600, batch_size 8, seq length 512]\tLoss: 0.006038\n",
      "624it [00:55,  9.65it/s]Train epoch: 1 [batch #625, batch_size 8, seq length 512]\tLoss: 0.006077\n",
      "650it [00:58,  9.44it/s]Train epoch: 1 [batch #650, batch_size 8, seq length 512]\tLoss: 0.006120\n",
      "675it [01:01,  9.55it/s]Train epoch: 1 [batch #675, batch_size 8, seq length 512]\tLoss: 0.006990\n",
      "700it [01:03,  9.48it/s]Train epoch: 1 [batch #700, batch_size 8, seq length 512]\tLoss: 0.006217\n",
      "725it [01:06,  8.94it/s]Train epoch: 1 [batch #725, batch_size 8, seq length 512]\tLoss: 0.005990\n",
      "750it [01:09,  9.42it/s]Train epoch: 1 [batch #750, batch_size 8, seq length 512]\tLoss: 0.007075\n",
      "775it [01:11,  9.21it/s]Train epoch: 1 [batch #775, batch_size 8, seq length 512]\tLoss: 0.005791\n",
      "799it [01:14,  8.99it/s]Train epoch: 1 [batch #800, batch_size 8, seq length 512]\tLoss: 0.005658\n",
      "825it [01:17,  9.07it/s]Train epoch: 1 [batch #825, batch_size 8, seq length 512]\tLoss: 0.006105\n",
      "850it [01:20,  8.98it/s]Train epoch: 1 [batch #850, batch_size 8, seq length 512]\tLoss: 0.006139\n",
      "875it [01:22,  9.17it/s]Train epoch: 1 [batch #875, batch_size 8, seq length 512]\tLoss: 0.006447\n",
      "900it [01:25,  8.81it/s]Train epoch: 1 [batch #900, batch_size 8, seq length 512]\tLoss: 0.006195\n",
      "925it [01:28,  8.90it/s]Train epoch: 1 [batch #925, batch_size 8, seq length 512]\tLoss: 0.006513\n",
      "950it [01:31,  8.89it/s]Train epoch: 1 [batch #950, batch_size 8, seq length 512]\tLoss: 0.005258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975it [01:34,  8.30it/s]Train epoch: 1 [batch #975, batch_size 8, seq length 512]\tLoss: 0.006576\n",
      "1000it [01:37,  9.08it/s]Train epoch: 1 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.005903\n",
      "1025it [01:39,  8.76it/s]Train epoch: 1 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.005816\n",
      "1050it [01:42,  8.66it/s]Train epoch: 1 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.006258\n",
      "1075it [01:45,  8.11it/s]Train epoch: 1 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.006069\n",
      "1100it [01:48,  8.57it/s]Train epoch: 1 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.006324\n",
      "1125it [01:51,  8.66it/s]Train epoch: 1 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.006159\n",
      "1150it [01:54,  8.00it/s]Train epoch: 1 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.005368\n",
      "1175it [01:57,  8.42it/s]Train epoch: 1 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.006441\n",
      "1200it [02:00,  8.23it/s]Train epoch: 1 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.006643\n",
      "1225it [02:03,  8.49it/s]Train epoch: 1 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.006214\n",
      "1250it [02:06,  8.33it/s]Train epoch: 1 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.006031\n",
      "1275it [02:09,  8.38it/s]Train epoch: 1 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.007501\n",
      "1300it [02:12,  7.94it/s]Train epoch: 1 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.006050\n",
      "1325it [02:15,  8.45it/s]Train epoch: 1 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.006456\n",
      "1350it [02:18,  8.00it/s]Train epoch: 1 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.005888\n",
      "1375it [02:21,  8.28it/s]Train epoch: 1 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.007264\n",
      "1400it [02:24,  7.84it/s]Train epoch: 1 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.005973\n",
      "1425it [02:27,  8.05it/s]Train epoch: 1 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.006227\n",
      "1450it [02:30,  7.93it/s]Train epoch: 1 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.006518\n",
      "1475it [02:33,  8.11it/s]Train epoch: 1 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.006436\n",
      "1500it [02:37,  7.93it/s]Train epoch: 1 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.007054\n",
      "1525it [02:40,  7.78it/s]Train epoch: 1 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.006809\n",
      "1550it [02:43,  7.95it/s]Train epoch: 1 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.006558\n",
      "1575it [02:46,  8.11it/s]Train epoch: 1 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.006230\n",
      "1600it [02:49,  7.90it/s]Train epoch: 1 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.007026\n",
      "1625it [02:52,  7.77it/s]Train epoch: 1 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.006536\n",
      "1650it [02:56,  7.89it/s]Train epoch: 1 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.007252\n",
      "1675it [02:59,  7.74it/s]Train epoch: 1 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.006635\n",
      "1700it [03:02,  7.84it/s]Train epoch: 1 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.006633\n",
      "1725it [03:05,  7.57it/s]Train epoch: 1 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.006674\n",
      "1750it [03:09,  7.49it/s]Train epoch: 1 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.006634\n",
      "1775it [03:12,  7.76it/s]Train epoch: 1 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.006907\n",
      "1800it [03:15,  7.77it/s]Train epoch: 1 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.006947\n",
      "1825it [03:19,  7.56it/s]Train epoch: 1 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.006450\n",
      "1850it [03:22,  7.59it/s]Train epoch: 1 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.006435\n",
      "1875it [03:25,  7.57it/s]Train epoch: 1 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.006769\n",
      "1900it [03:29,  7.59it/s]Train epoch: 1 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.007464\n",
      "1925it [03:32,  7.46it/s]Train epoch: 1 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.006653\n",
      "1950it [03:35,  7.54it/s]Train epoch: 1 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.007007\n",
      "1975it [03:38,  7.41it/s]Train epoch: 1 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.007436\n",
      "2000it [03:42,  6.81it/s]Train epoch: 1 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.006430\n",
      "2025it [03:45,  7.26it/s]Train epoch: 1 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.006814\n",
      "2050it [03:49,  7.13it/s]Train epoch: 1 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.007096\n",
      "2075it [03:52,  7.05it/s]Train epoch: 1 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.006672\n",
      "2100it [03:56,  7.41it/s]Train epoch: 1 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.007278\n",
      "2125it [03:59,  7.35it/s]Train epoch: 1 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.006959\n",
      "2150it [04:03,  7.27it/s]Train epoch: 1 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.007243\n",
      "2175it [04:06,  7.27it/s]Train epoch: 1 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.007041\n",
      "2200it [04:10,  7.10it/s]Train epoch: 1 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.006845\n",
      "2225it [04:13,  7.25it/s]Train epoch: 1 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.006563\n",
      "2250it [04:17,  6.86it/s]Train epoch: 1 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.007644\n",
      "2275it [04:20,  7.12it/s]Train epoch: 1 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.006716\n",
      "2300it [04:24,  6.84it/s]Train epoch: 1 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.006537\n",
      "2325it [04:27,  6.82it/s]Train epoch: 1 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.007218\n",
      "2350it [04:31,  6.48it/s]Train epoch: 1 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.006895\n",
      "2375it [04:35,  6.97it/s]Train epoch: 1 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.007510\n",
      "2400it [04:38,  6.80it/s]Train epoch: 1 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.007318\n",
      "2425it [04:42,  6.89it/s]Train epoch: 1 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.007319\n",
      "2450it [04:46,  6.94it/s]Train epoch: 1 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.007357\n",
      "2475it [04:49,  6.75it/s]Train epoch: 1 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.006837\n",
      "2500it [04:53,  6.83it/s]Train epoch: 1 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.007181\n",
      "2525it [04:57,  6.71it/s]Train epoch: 1 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.006936\n",
      "2550it [05:00,  6.82it/s]Train epoch: 1 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.006942\n",
      "2575it [05:04,  6.56it/s]Train epoch: 1 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.007559\n",
      "2600it [05:08,  6.61it/s]Train epoch: 1 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.006922\n",
      "2625it [05:12,  6.64it/s]Train epoch: 1 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.007375\n",
      "2650it [05:15,  6.81it/s]Train epoch: 1 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.006787\n",
      "2675it [05:19,  6.62it/s]Train epoch: 1 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.007333\n",
      "2700it [05:23,  6.72it/s]Train epoch: 1 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.008191\n",
      "2725it [05:27,  6.48it/s]Train epoch: 1 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.007531\n",
      "2750it [05:30,  6.60it/s]Train epoch: 1 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.008451\n",
      "2775it [05:34,  6.47it/s]Train epoch: 1 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.007239\n",
      "2800it [05:38,  6.57it/s]Train epoch: 1 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.007896\n",
      "2825it [05:42,  6.80it/s]Train epoch: 1 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.006730\n",
      "2850it [05:46,  6.52it/s]Train epoch: 1 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.007590\n",
      "2875it [05:49,  6.56it/s]Train epoch: 1 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.008329\n",
      "2900it [05:53,  6.50it/s]Train epoch: 1 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.007501\n",
      "2925it [05:57,  6.50it/s]Train epoch: 1 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.007850\n",
      "2950it [06:01,  6.41it/s]Train epoch: 1 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.008420\n",
      "2975it [06:05,  6.46it/s]Train epoch: 1 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.007257\n",
      "3000it [06:09,  6.24it/s]Train epoch: 1 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.007466\n",
      "3025it [06:13,  6.08it/s]Train epoch: 1 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.007516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3050it [06:17,  6.30it/s]Train epoch: 1 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.007251\n",
      "3075it [06:21,  6.15it/s]Train epoch: 1 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.007424\n",
      "3100it [06:25,  6.27it/s]Train epoch: 1 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.007429\n",
      "3125it [06:29,  6.08it/s]Train epoch: 1 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.007309\n",
      "3150it [06:33,  6.00it/s]Train epoch: 1 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.007661\n",
      "3175it [06:37,  5.98it/s]Train epoch: 1 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.008028\n",
      "3200it [06:41,  6.13it/s]Train epoch: 1 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.007496\n",
      "3225it [06:46,  6.05it/s]Train epoch: 1 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.007683\n",
      "3250it [06:50,  6.00it/s]Train epoch: 1 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.007933\n",
      "3275it [06:54,  6.08it/s]Train epoch: 1 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.007831\n",
      "3300it [06:58,  6.24it/s]Train epoch: 1 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.007984\n",
      "3325it [07:02,  5.99it/s]Train epoch: 1 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.007902\n",
      "3350it [07:06,  5.95it/s]Train epoch: 1 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.008187\n",
      "3375it [07:10,  6.05it/s]Train epoch: 1 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.007307\n",
      "3400it [07:14,  5.96it/s]Train epoch: 1 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.007913\n",
      "3425it [07:19,  6.04it/s]Train epoch: 1 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.007777\n",
      "3450it [07:23,  6.01it/s]Train epoch: 1 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.007683\n",
      "3475it [07:27,  5.83it/s]Train epoch: 1 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.008442\n",
      "3500it [07:31,  5.86it/s]Train epoch: 1 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.007766\n",
      "3525it [07:36,  5.68it/s]Train epoch: 1 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.007415\n",
      "3550it [07:40,  5.87it/s]Train epoch: 1 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.008085\n",
      "3575it [07:44,  5.75it/s]Train epoch: 1 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.008094\n",
      "3600it [07:48,  5.74it/s]Train epoch: 1 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.008578\n",
      "3625it [07:53,  5.89it/s]Train epoch: 1 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.007586\n",
      "3650it [07:57,  5.74it/s]Train epoch: 1 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.008413\n",
      "3675it [08:01,  5.74it/s]Train epoch: 1 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.008393\n",
      "3700it [08:06,  5.67it/s]Train epoch: 1 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.007715\n",
      "3725it [08:10,  5.68it/s]Train epoch: 1 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.008279\n",
      "3750it [08:15,  5.69it/s]Train epoch: 1 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.008039\n",
      "3775it [08:19,  5.72it/s]Train epoch: 1 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.008404\n",
      "3800it [08:23,  5.69it/s]Train epoch: 1 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.008979\n",
      "3825it [08:28,  5.68it/s]Train epoch: 1 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.007987\n",
      "3850it [08:32,  5.67it/s]Train epoch: 1 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.007883\n",
      "3875it [08:37,  5.61it/s]Train epoch: 1 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.008401\n",
      "3900it [08:41,  5.58it/s]Train epoch: 1 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.008452\n",
      "3925it [08:46,  5.54it/s]Train epoch: 1 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.007510\n",
      "3950it [08:50,  5.57it/s]Train epoch: 1 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.007828\n",
      "3975it [08:55,  5.60it/s]Train epoch: 1 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.008470\n",
      "4000it [08:59,  5.49it/s]Train epoch: 1 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.007850\n",
      "4025it [09:04,  5.46it/s]Train epoch: 1 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.007835\n",
      "4050it [09:09,  5.35it/s]Train epoch: 1 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.007734\n",
      "4075it [09:13,  5.19it/s]Train epoch: 1 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.007882\n",
      "4100it [09:18,  5.44it/s]Train epoch: 1 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.008171\n",
      "4125it [09:23,  5.38it/s]Train epoch: 1 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.008315\n",
      "4150it [09:27,  5.43it/s]Train epoch: 1 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.008333\n",
      "4175it [09:32,  5.27it/s]Train epoch: 1 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.007921\n",
      "4200it [09:37,  5.23it/s]Train epoch: 1 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.007555\n",
      "4225it [09:42,  5.23it/s]Train epoch: 1 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.008315\n",
      "4250it [09:46,  5.31it/s]Train epoch: 1 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.008816\n",
      "4275it [09:51,  5.26it/s]Train epoch: 1 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.008674\n",
      "4300it [09:56,  5.19it/s]Train epoch: 1 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.008247\n",
      "4325it [10:01,  5.18it/s]Train epoch: 1 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.008568\n",
      "4350it [10:06,  5.06it/s]Train epoch: 1 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.009037\n",
      "4375it [10:11,  5.12it/s]Train epoch: 1 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.008522\n",
      "4400it [10:15,  5.09it/s]Train epoch: 1 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.008390\n",
      "4425it [10:21,  4.81it/s]Train epoch: 1 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.008692\n",
      "4450it [10:26,  5.05it/s]Train epoch: 1 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.008330\n",
      "4475it [10:31,  4.97it/s]Train epoch: 1 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.009608\n",
      "4500it [10:36,  4.96it/s]Train epoch: 1 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.008854\n",
      "4525it [10:41,  4.92it/s]Train epoch: 1 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.008586\n",
      "4550it [10:46,  5.01it/s]Train epoch: 1 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.008709\n",
      "4575it [10:51,  5.06it/s]Train epoch: 1 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.008204\n",
      "4600it [10:56,  4.93it/s]Train epoch: 1 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.008428\n",
      "4625it [11:01,  4.95it/s]Train epoch: 1 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.008852\n",
      "4650it [11:06,  4.91it/s]Train epoch: 1 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.009246\n",
      "4675it [11:11,  4.75it/s]Train epoch: 1 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.009154\n",
      "4700it [11:16,  4.90it/s]Train epoch: 1 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.008625\n",
      "4725it [11:21,  4.84it/s]Train epoch: 1 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.008968\n",
      "4750it [11:27,  4.71it/s]Train epoch: 1 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.008889\n",
      "4775it [11:32,  4.71it/s]Train epoch: 1 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.008900\n",
      "4800it [11:37,  4.72it/s]Train epoch: 1 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.009271\n",
      "4825it [11:43,  4.67it/s]Train epoch: 1 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.008162\n",
      "4850it [11:48,  4.58it/s]Train epoch: 1 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.008801\n",
      "4875it [11:54,  4.58it/s]Train epoch: 1 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.009051\n",
      "4900it [11:59,  4.51it/s]Train epoch: 1 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.009172\n",
      "4925it [12:05,  4.53it/s]Train epoch: 1 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.009345\n",
      "4950it [12:10,  4.45it/s]Train epoch: 1 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.009632\n",
      "4975it [12:16,  4.47it/s]Train epoch: 1 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.009560\n",
      "5000it [12:21,  4.49it/s]Train epoch: 1 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.009104\n",
      "5025it [12:27,  4.42it/s]Train epoch: 1 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.010008\n",
      "5050it [12:33,  4.47it/s]Train epoch: 1 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.009500\n",
      "5075it [12:38,  4.38it/s]Train epoch: 1 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.009012\n",
      "5100it [12:44,  4.32it/s]Train epoch: 1 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.008968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125it [12:50,  4.25it/s]Train epoch: 1 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.009888\n",
      "5150it [12:56,  4.26it/s]Train epoch: 1 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.009734\n",
      "5175it [13:02,  4.23it/s]Train epoch: 1 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.009857\n",
      "5200it [13:08,  4.20it/s]Train epoch: 1 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.010328\n",
      "5225it [13:14,  4.20it/s]Train epoch: 1 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.009957\n",
      "5250it [13:20,  4.22it/s]Train epoch: 1 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.009605\n",
      "5275it [13:26,  4.12it/s]Train epoch: 1 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.009686\n",
      "5300it [13:32,  4.11it/s]Train epoch: 1 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.009533\n",
      "5325it [13:38,  4.06it/s]Train epoch: 1 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.009490\n",
      "5350it [13:44,  3.95it/s]Train epoch: 1 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.009982\n",
      "5375it [13:50,  3.97it/s]Train epoch: 1 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.010192\n",
      "5400it [13:57,  3.94it/s]Train epoch: 1 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.009991\n",
      "5425it [14:03,  3.91it/s]Train epoch: 1 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.010019\n",
      "5450it [14:10,  3.86it/s]Train epoch: 1 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.010102\n",
      "5475it [14:16,  3.88it/s]Train epoch: 1 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.010050\n",
      "5500it [14:23,  3.79it/s]Train epoch: 1 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.010331\n",
      "5525it [14:29,  3.74it/s]Train epoch: 1 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.010790\n",
      "5550it [14:36,  3.58it/s]Train epoch: 1 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.010782\n",
      "5575it [14:43,  3.70it/s]Train epoch: 1 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.009883\n",
      "5600it [14:49,  3.68it/s]Train epoch: 1 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.010277\n",
      "5625it [14:56,  3.52it/s]Train epoch: 1 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.011000\n",
      "5650it [15:03,  3.56it/s]Train epoch: 1 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.009766\n",
      "5675it [15:10,  3.53it/s]Train epoch: 1 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.011109\n",
      "5700it [15:18,  3.44it/s]Train epoch: 1 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.010724\n",
      "5725it [15:25,  3.38it/s]Train epoch: 1 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.011081\n",
      "5750it [15:32,  3.27it/s]Train epoch: 1 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.011538\n",
      "5775it [15:40,  3.14it/s]Train epoch: 1 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.011020\n",
      "5800it [15:48,  3.13it/s]Train epoch: 1 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.011531\n",
      "5825it [15:56,  3.09it/s]Train epoch: 1 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.011631\n",
      "5850it [16:04,  3.00it/s]Train epoch: 1 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.011365\n",
      "5875it [16:13,  2.83it/s]Train epoch: 1 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.012224\n",
      "5900it [16:22,  2.73it/s]Train epoch: 1 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.011122\n",
      "5925it [16:32,  2.52it/s]Train epoch: 1 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.012734\n",
      "5950it [16:43,  2.16it/s]Train epoch: 1 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.013634\n",
      "5965it [16:51,  5.90it/s]\n",
      "epoch loss: 0.007842634704661901\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 46.89it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0011, 0.0024, 0.0015, 0.0018, 0.7424\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0812, 0.5247, 0.0877, 0.1502, 0.9590\n",
      "rec_at_8: 0.1609\n",
      "prec_at_8: 0.3330\n",
      "rec_at_15: 0.2366\n",
      "prec_at_15: 0.2634\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:12, 46.65it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0011, 0.0030, 0.0015, 0.0020, 0.7359\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0820, 0.5285, 0.0884, 0.1515, 0.9580\n",
      "rec_at_8: 0.1579\n",
      "prec_at_8: 0.3381\n",
      "rec_at_15: 0.2277\n",
      "prec_at_15: 0.2629\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 1\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0011, 0.0024, 0.0015, 0.0018, 0.7424\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0812, 0.5247, 0.0877, 0.1502, 0.9590\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0090\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 1\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0011, 0.0030, 0.0015, 0.0020, 0.7359\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0820, 0.5285, 0.0884, 0.1515, 0.9580\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0093\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 2\n",
      "0it [00:00, ?it/s]Train epoch: 2 [batch #0, batch_size 8, seq length 512]\tLoss: 0.007570\n",
      "24it [00:01, 15.46it/s]Train epoch: 2 [batch #25, batch_size 8, seq length 512]\tLoss: 0.005946\n",
      "50it [00:03, 13.01it/s]Train epoch: 2 [batch #50, batch_size 8, seq length 512]\tLoss: 0.004959\n",
      "74it [00:05, 13.48it/s]Train epoch: 2 [batch #75, batch_size 8, seq length 512]\tLoss: 0.004550\n",
      "100it [00:07, 13.56it/s]Train epoch: 2 [batch #100, batch_size 8, seq length 512]\tLoss: 0.004939\n",
      "124it [00:08, 12.88it/s]Train epoch: 2 [batch #125, batch_size 8, seq length 512]\tLoss: 0.004856\n",
      "150it [00:10, 12.60it/s]Train epoch: 2 [batch #150, batch_size 8, seq length 512]\tLoss: 0.004628\n",
      "174it [00:12, 12.47it/s]Train epoch: 2 [batch #175, batch_size 8, seq length 512]\tLoss: 0.004965\n",
      "200it [00:15, 11.93it/s]Train epoch: 2 [batch #200, batch_size 8, seq length 512]\tLoss: 0.004258\n",
      "224it [00:17, 11.50it/s]Train epoch: 2 [batch #225, batch_size 8, seq length 512]\tLoss: 0.004881\n",
      "250it [00:19, 11.43it/s]Train epoch: 2 [batch #250, batch_size 8, seq length 512]\tLoss: 0.004639\n",
      "274it [00:21, 11.35it/s]Train epoch: 2 [batch #275, batch_size 8, seq length 512]\tLoss: 0.004828\n",
      "300it [00:23, 11.06it/s]Train epoch: 2 [batch #300, batch_size 8, seq length 512]\tLoss: 0.005085\n",
      "324it [00:25, 11.24it/s]Train epoch: 2 [batch #325, batch_size 8, seq length 512]\tLoss: 0.004740\n",
      "350it [00:28, 10.84it/s]Train epoch: 2 [batch #350, batch_size 8, seq length 512]\tLoss: 0.004779\n",
      "374it [00:30, 10.94it/s]Train epoch: 2 [batch #375, batch_size 8, seq length 512]\tLoss: 0.004740\n",
      "400it [00:33, 10.41it/s]Train epoch: 2 [batch #400, batch_size 8, seq length 512]\tLoss: 0.004540\n",
      "424it [00:35, 10.49it/s]Train epoch: 2 [batch #425, batch_size 8, seq length 512]\tLoss: 0.005220\n",
      "450it [00:37, 10.14it/s]Train epoch: 2 [batch #450, batch_size 8, seq length 512]\tLoss: 0.004660\n",
      "474it [00:40, 10.13it/s]Train epoch: 2 [batch #475, batch_size 8, seq length 512]\tLoss: 0.004487\n",
      "500it [00:42, 10.13it/s]Train epoch: 2 [batch #500, batch_size 8, seq length 512]\tLoss: 0.005124\n",
      "524it [00:45, 10.06it/s]Train epoch: 2 [batch #525, batch_size 8, seq length 512]\tLoss: 0.004780\n",
      "550it [00:47,  9.91it/s]Train epoch: 2 [batch #550, batch_size 8, seq length 512]\tLoss: 0.005220\n",
      "574it [00:50,  9.73it/s]Train epoch: 2 [batch #575, batch_size 8, seq length 512]\tLoss: 0.005388\n",
      "600it [00:52,  9.71it/s]Train epoch: 2 [batch #600, batch_size 8, seq length 512]\tLoss: 0.004989\n",
      "624it [00:55,  9.74it/s]Train epoch: 2 [batch #625, batch_size 8, seq length 512]\tLoss: 0.005058\n",
      "650it [00:57,  9.90it/s]Train epoch: 2 [batch #650, batch_size 8, seq length 512]\tLoss: 0.005140\n",
      "675it [01:00,  9.22it/s]Train epoch: 2 [batch #675, batch_size 8, seq length 512]\tLoss: 0.005987\n",
      "700it [01:03,  9.58it/s]Train epoch: 2 [batch #700, batch_size 8, seq length 512]\tLoss: 0.005113\n",
      "724it [01:05,  9.23it/s]Train epoch: 2 [batch #725, batch_size 8, seq length 512]\tLoss: 0.004893\n",
      "749it [01:08,  9.39it/s]Train epoch: 2 [batch #750, batch_size 8, seq length 512]\tLoss: 0.005994\n",
      "775it [01:11,  8.89it/s]Train epoch: 2 [batch #775, batch_size 8, seq length 512]\tLoss: 0.004764\n",
      "800it [01:13,  9.38it/s]Train epoch: 2 [batch #800, batch_size 8, seq length 512]\tLoss: 0.004690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825it [01:16,  9.23it/s]Train epoch: 2 [batch #825, batch_size 8, seq length 512]\tLoss: 0.005077\n",
      "850it [01:19,  9.11it/s]Train epoch: 2 [batch #850, batch_size 8, seq length 512]\tLoss: 0.005145\n",
      "875it [01:22,  9.07it/s]Train epoch: 2 [batch #875, batch_size 8, seq length 512]\tLoss: 0.005473\n",
      "900it [01:24,  9.24it/s]Train epoch: 2 [batch #900, batch_size 8, seq length 512]\tLoss: 0.005172\n",
      "925it [01:27,  8.84it/s]Train epoch: 2 [batch #925, batch_size 8, seq length 512]\tLoss: 0.005457\n",
      "950it [01:30,  9.15it/s]Train epoch: 2 [batch #950, batch_size 8, seq length 512]\tLoss: 0.004408\n",
      "975it [01:33,  8.76it/s]Train epoch: 2 [batch #975, batch_size 8, seq length 512]\tLoss: 0.005543\n",
      "1000it [01:36,  8.91it/s]Train epoch: 2 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.004967\n",
      "1025it [01:39,  8.77it/s]Train epoch: 2 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.004917\n",
      "1050it [01:41,  8.41it/s]Train epoch: 2 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.005323\n",
      "1075it [01:44,  8.63it/s]Train epoch: 2 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.005136\n",
      "1100it [01:47,  8.67it/s]Train epoch: 2 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.005483\n",
      "1125it [01:50,  8.88it/s]Train epoch: 2 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.005286\n",
      "1150it [01:53,  8.74it/s]Train epoch: 2 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.004564\n",
      "1175it [01:56,  8.63it/s]Train epoch: 2 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.005332\n",
      "1200it [01:59,  8.62it/s]Train epoch: 2 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.005738\n",
      "1225it [02:02,  8.35it/s]Train epoch: 2 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.005449\n",
      "1250it [02:05,  8.38it/s]Train epoch: 2 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.005146\n",
      "1275it [02:08,  8.43it/s]Train epoch: 2 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.006527\n",
      "1300it [02:11,  8.37it/s]Train epoch: 2 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.005231\n",
      "1325it [02:14,  8.18it/s]Train epoch: 2 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.005609\n",
      "1350it [02:17,  8.39it/s]Train epoch: 2 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.005036\n",
      "1375it [02:20,  8.07it/s]Train epoch: 2 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.006242\n",
      "1400it [02:23,  8.41it/s]Train epoch: 2 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.005209\n",
      "1425it [02:26,  8.07it/s]Train epoch: 2 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.005440\n",
      "1450it [02:29,  8.17it/s]Train epoch: 2 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.005744\n",
      "1475it [02:32,  8.11it/s]Train epoch: 2 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.005589\n",
      "1500it [02:36,  8.23it/s]Train epoch: 2 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.006129\n",
      "1525it [02:39,  8.08it/s]Train epoch: 2 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.005911\n",
      "1550it [02:42,  7.99it/s]Train epoch: 2 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.005800\n",
      "1575it [02:45,  7.80it/s]Train epoch: 2 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.005459\n",
      "1600it [02:48,  8.03it/s]Train epoch: 2 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.006229\n",
      "1625it [02:51,  7.75it/s]Train epoch: 2 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.005817\n",
      "1650it [02:55,  7.71it/s]Train epoch: 2 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.006341\n",
      "1675it [02:58,  7.61it/s]Train epoch: 2 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.005871\n",
      "1700it [03:01,  7.78it/s]Train epoch: 2 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.005871\n",
      "1725it [03:04,  7.74it/s]Train epoch: 2 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.005947\n",
      "1750it [03:08,  7.90it/s]Train epoch: 2 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.005832\n",
      "1775it [03:11,  7.44it/s]Train epoch: 2 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.006217\n",
      "1800it [03:14,  7.71it/s]Train epoch: 2 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.006026\n",
      "1825it [03:17,  7.50it/s]Train epoch: 2 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.005736\n",
      "1850it [03:21,  7.26it/s]Train epoch: 2 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.005663\n",
      "1875it [03:24,  7.70it/s]Train epoch: 2 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.005940\n",
      "1900it [03:27,  7.29it/s]Train epoch: 2 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.006678\n",
      "1925it [03:31,  7.45it/s]Train epoch: 2 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.005881\n",
      "1950it [03:34,  7.50it/s]Train epoch: 2 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.006257\n",
      "1975it [03:38,  7.41it/s]Train epoch: 2 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.006542\n",
      "2000it [03:41,  7.34it/s]Train epoch: 2 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.005675\n",
      "2025it [03:44,  7.17it/s]Train epoch: 2 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.006133\n",
      "2050it [03:48,  7.43it/s]Train epoch: 2 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.006375\n",
      "2075it [03:51,  7.07it/s]Train epoch: 2 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.005937\n",
      "2100it [03:55,  7.25it/s]Train epoch: 2 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.006439\n",
      "2125it [03:58,  7.26it/s]Train epoch: 2 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.006072\n",
      "2150it [04:02,  7.21it/s]Train epoch: 2 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.006422\n",
      "2175it [04:05,  7.32it/s]Train epoch: 2 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.006149\n",
      "2200it [04:08,  7.40it/s]Train epoch: 2 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.006063\n",
      "2225it [04:12,  7.32it/s]Train epoch: 2 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.005914\n",
      "2250it [04:15,  7.30it/s]Train epoch: 2 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.006861\n",
      "2275it [04:19,  7.13it/s]Train epoch: 2 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.005989\n",
      "2300it [04:22,  7.20it/s]Train epoch: 2 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.005826\n",
      "2325it [04:26,  6.95it/s]Train epoch: 2 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.006522\n",
      "2350it [04:29,  7.00it/s]Train epoch: 2 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.006217\n",
      "2375it [04:33,  7.17it/s]Train epoch: 2 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.006639\n",
      "2400it [04:37,  6.88it/s]Train epoch: 2 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.006512\n",
      "2425it [04:40,  7.05it/s]Train epoch: 2 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.006522\n",
      "2450it [04:44,  6.82it/s]Train epoch: 2 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.006580\n",
      "2475it [04:48,  6.83it/s]Train epoch: 2 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.006070\n",
      "2500it [04:51,  6.68it/s]Train epoch: 2 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.006445\n",
      "2525it [04:55,  7.06it/s]Train epoch: 2 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.006034\n",
      "2550it [04:59,  6.87it/s]Train epoch: 2 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.006272\n",
      "2575it [05:02,  6.69it/s]Train epoch: 2 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.006707\n",
      "2600it [05:06,  6.68it/s]Train epoch: 2 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.006204\n",
      "2625it [05:10,  6.82it/s]Train epoch: 2 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.006518\n",
      "2650it [05:13,  6.56it/s]Train epoch: 2 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.006022\n",
      "2675it [05:17,  6.85it/s]Train epoch: 2 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.006661\n",
      "2700it [05:21,  6.72it/s]Train epoch: 2 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.007270\n",
      "2725it [05:25,  6.48it/s]Train epoch: 2 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.006758\n",
      "2750it [05:29,  6.59it/s]Train epoch: 2 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.007616\n",
      "2775it [05:32,  6.48it/s]Train epoch: 2 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.006579\n",
      "2800it [05:36,  6.59it/s]Train epoch: 2 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.007044\n",
      "2825it [05:40,  6.53it/s]Train epoch: 2 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.006080\n",
      "2850it [05:44,  6.55it/s]Train epoch: 2 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.006856\n",
      "2875it [05:48,  6.45it/s]Train epoch: 2 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.007619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900it [05:51,  6.48it/s]Train epoch: 2 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.006667\n",
      "2925it [05:55,  6.51it/s]Train epoch: 2 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.007007\n",
      "2950it [05:59,  6.36it/s]Train epoch: 2 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.007594\n",
      "2975it [06:03,  6.41it/s]Train epoch: 2 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.006545\n",
      "3000it [06:07,  6.32it/s]Train epoch: 2 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.006724\n",
      "3025it [06:11,  6.32it/s]Train epoch: 2 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.006601\n",
      "3050it [06:15,  6.26it/s]Train epoch: 2 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.006459\n",
      "3075it [06:19,  6.19it/s]Train epoch: 2 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.006719\n",
      "3100it [06:23,  6.21it/s]Train epoch: 2 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.006658\n",
      "3125it [06:27,  6.28it/s]Train epoch: 2 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.006556\n",
      "3150it [06:31,  6.27it/s]Train epoch: 2 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.006956\n",
      "3175it [06:35,  6.28it/s]Train epoch: 2 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.007267\n",
      "3200it [06:39,  6.00it/s]Train epoch: 2 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.006668\n",
      "3225it [06:43,  6.13it/s]Train epoch: 2 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.006902\n",
      "3250it [06:47,  6.26it/s]Train epoch: 2 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.007210\n",
      "3275it [06:51,  6.25it/s]Train epoch: 2 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.007179\n",
      "3300it [06:55,  6.10it/s]Train epoch: 2 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.007282\n",
      "3325it [06:59,  6.05it/s]Train epoch: 2 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.007236\n",
      "3350it [07:04,  5.92it/s]Train epoch: 2 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.007426\n",
      "3375it [07:08,  6.01it/s]Train epoch: 2 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.006679\n",
      "3400it [07:12,  5.95it/s]Train epoch: 2 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.007183\n",
      "3425it [07:16,  5.96it/s]Train epoch: 2 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.007045\n",
      "3450it [07:20,  5.92it/s]Train epoch: 2 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.007042\n",
      "3475it [07:25,  5.92it/s]Train epoch: 2 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.007675\n",
      "3500it [07:29,  5.94it/s]Train epoch: 2 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.007056\n",
      "3525it [07:33,  5.89it/s]Train epoch: 2 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.006800\n",
      "3550it [07:37,  5.81it/s]Train epoch: 2 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.007425\n",
      "3575it [07:42,  5.64it/s]Train epoch: 2 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.007507\n",
      "3600it [07:46,  5.85it/s]Train epoch: 2 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.007813\n",
      "3625it [07:50,  5.69it/s]Train epoch: 2 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.007003\n",
      "3650it [07:55,  5.76it/s]Train epoch: 2 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.007729\n",
      "3675it [07:59,  5.69it/s]Train epoch: 2 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.007690\n",
      "3700it [08:03,  5.78it/s]Train epoch: 2 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.007069\n",
      "3725it [08:08,  5.62it/s]Train epoch: 2 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.007574\n",
      "3750it [08:12,  5.70it/s]Train epoch: 2 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.007428\n",
      "3775it [08:17,  5.57it/s]Train epoch: 2 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.007724\n",
      "3800it [08:21,  5.65it/s]Train epoch: 2 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.008147\n",
      "3825it [08:25,  5.60it/s]Train epoch: 2 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.007326\n",
      "3850it [08:30,  5.58it/s]Train epoch: 2 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.007199\n",
      "3875it [08:34,  5.62it/s]Train epoch: 2 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.007727\n",
      "3900it [08:39,  5.58it/s]Train epoch: 2 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.007812\n",
      "3925it [08:43,  5.54it/s]Train epoch: 2 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.006810\n",
      "3950it [08:48,  5.40it/s]Train epoch: 2 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.007282\n",
      "3975it [08:53,  5.44it/s]Train epoch: 2 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.007768\n",
      "4000it [08:57,  5.46it/s]Train epoch: 2 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.007202\n",
      "4025it [09:02,  5.68it/s]Train epoch: 2 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.007132\n",
      "4050it [09:06,  5.49it/s]Train epoch: 2 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.007146\n",
      "4075it [09:11,  5.43it/s]Train epoch: 2 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.007227\n",
      "4100it [09:16,  5.46it/s]Train epoch: 2 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.007466\n",
      "4125it [09:20,  5.23it/s]Train epoch: 2 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.007657\n",
      "4150it [09:25,  5.26it/s]Train epoch: 2 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.007729\n",
      "4175it [09:30,  5.32it/s]Train epoch: 2 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.007299\n",
      "4200it [09:35,  5.25it/s]Train epoch: 2 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.006884\n",
      "4225it [09:39,  5.28it/s]Train epoch: 2 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.007757\n",
      "4250it [09:44,  5.29it/s]Train epoch: 2 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.008199\n",
      "4275it [09:49,  5.35it/s]Train epoch: 2 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.008034\n",
      "4300it [09:54,  5.17it/s]Train epoch: 2 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.007464\n",
      "4325it [09:59,  5.22it/s]Train epoch: 2 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.007969\n",
      "4350it [10:03,  5.17it/s]Train epoch: 2 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.008450\n",
      "4375it [10:08,  5.10it/s]Train epoch: 2 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.007971\n",
      "4400it [10:13,  5.04it/s]Train epoch: 2 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.007774\n",
      "4425it [10:18,  5.13it/s]Train epoch: 2 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.007998\n",
      "4450it [10:23,  5.03it/s]Train epoch: 2 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.007684\n",
      "4475it [10:28,  4.99it/s]Train epoch: 2 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.008940\n",
      "4500it [10:33,  4.99it/s]Train epoch: 2 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.008215\n",
      "4525it [10:38,  4.97it/s]Train epoch: 2 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.007970\n",
      "4550it [10:43,  4.94it/s]Train epoch: 2 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.008043\n",
      "4575it [10:48,  4.88it/s]Train epoch: 2 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.007632\n",
      "4600it [10:53,  4.85it/s]Train epoch: 2 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.007868\n",
      "4625it [10:59,  4.70it/s]Train epoch: 2 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.008310\n",
      "4650it [11:04,  4.88it/s]Train epoch: 2 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.008560\n",
      "4675it [11:09,  4.79it/s]Train epoch: 2 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.008530\n",
      "4700it [11:14,  4.76it/s]Train epoch: 2 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.008083\n",
      "4725it [11:19,  4.72it/s]Train epoch: 2 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.008270\n",
      "4750it [11:25,  4.77it/s]Train epoch: 2 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.008274\n",
      "4775it [11:30,  4.58it/s]Train epoch: 2 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.008405\n",
      "4800it [11:35,  4.72it/s]Train epoch: 2 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.008704\n",
      "4825it [11:40,  4.83it/s]Train epoch: 2 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.007619\n",
      "4850it [11:46,  4.64it/s]Train epoch: 2 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.008206\n",
      "4875it [11:51,  4.67it/s]Train epoch: 2 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.008640\n",
      "4900it [11:57,  4.62it/s]Train epoch: 2 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.008523\n",
      "4925it [12:02,  4.52it/s]Train epoch: 2 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.008762\n",
      "4950it [12:07,  4.58it/s]Train epoch: 2 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.009070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4975it [12:13,  4.55it/s]Train epoch: 2 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.009005\n",
      "5000it [12:19,  4.51it/s]Train epoch: 2 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.008472\n",
      "5025it [12:24,  4.53it/s]Train epoch: 2 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.009306\n",
      "5050it [12:30,  4.42it/s]Train epoch: 2 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.008942\n",
      "5075it [12:35,  4.30it/s]Train epoch: 2 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.008403\n",
      "5100it [12:41,  4.34it/s]Train epoch: 2 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.008397\n",
      "5125it [12:47,  4.37it/s]Train epoch: 2 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.009238\n",
      "5150it [12:53,  4.34it/s]Train epoch: 2 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.009189\n",
      "5175it [12:58,  4.25it/s]Train epoch: 2 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.009265\n",
      "5200it [13:04,  4.32it/s]Train epoch: 2 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.009680\n",
      "5225it [13:10,  4.33it/s]Train epoch: 2 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.009305\n",
      "5250it [13:16,  4.20it/s]Train epoch: 2 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.008999\n",
      "5275it [13:22,  4.12it/s]Train epoch: 2 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.009137\n",
      "5300it [13:28,  4.13it/s]Train epoch: 2 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.008957\n",
      "5325it [13:34,  4.17it/s]Train epoch: 2 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.008854\n",
      "5350it [13:40,  4.01it/s]Train epoch: 2 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.009443\n",
      "5375it [13:46,  4.07it/s]Train epoch: 2 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.009653\n",
      "5400it [13:53,  4.05it/s]Train epoch: 2 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.009438\n",
      "5425it [13:59,  3.97it/s]Train epoch: 2 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.009412\n",
      "5450it [14:05,  3.98it/s]Train epoch: 2 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.009551\n",
      "5475it [14:12,  3.90it/s]Train epoch: 2 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.009500\n",
      "5500it [14:18,  3.85it/s]Train epoch: 2 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.009814\n",
      "5525it [14:25,  3.84it/s]Train epoch: 2 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.010238\n",
      "5550it [14:31,  3.87it/s]Train epoch: 2 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.010226\n",
      "5575it [14:38,  3.74it/s]Train epoch: 2 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.009423\n",
      "5600it [14:44,  3.71it/s]Train epoch: 2 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.009806\n",
      "5625it [14:51,  3.66it/s]Train epoch: 2 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.010471\n",
      "5650it [14:58,  3.58it/s]Train epoch: 2 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.009280\n",
      "5675it [15:05,  3.49it/s]Train epoch: 2 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.010594\n",
      "5700it [15:12,  3.48it/s]Train epoch: 2 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.010098\n",
      "5725it [15:20,  3.40it/s]Train epoch: 2 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.010399\n",
      "5750it [15:27,  3.35it/s]Train epoch: 2 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.011094\n",
      "5775it [15:35,  3.30it/s]Train epoch: 2 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.010363\n",
      "5800it [15:42,  3.19it/s]Train epoch: 2 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.011041\n",
      "5825it [15:50,  3.15it/s]Train epoch: 2 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.011057\n",
      "5850it [15:58,  3.01it/s]Train epoch: 2 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.010777\n",
      "5875it [16:07,  2.89it/s]Train epoch: 2 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.011641\n",
      "5900it [16:16,  2.74it/s]Train epoch: 2 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.010605\n",
      "5925it [16:25,  2.52it/s]Train epoch: 2 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.012222\n",
      "5950it [16:36,  2.15it/s]Train epoch: 2 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.013014\n",
      "5965it [16:44,  5.94it/s]\n",
      "epoch loss: 0.007085274822138755\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 46.87it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0028, 0.0062, 0.0038, 0.0047, 0.7907\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1213, 0.5581, 0.1342, 0.2163, 0.9661\n",
      "rec_at_8: 0.2038\n",
      "prec_at_8: 0.4028\n",
      "rec_at_15: 0.2839\n",
      "prec_at_15: 0.3073\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:12, 46.78it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0027, 0.0068, 0.0037, 0.0048, 0.7856\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1195, 0.5640, 0.1317, 0.2135, 0.9652\n",
      "rec_at_8: 0.1934\n",
      "prec_at_8: 0.4029\n",
      "rec_at_15: 0.2714\n",
      "prec_at_15: 0.3076\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 2\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0028, 0.0062, 0.0038, 0.0047, 0.7907\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1213, 0.5581, 0.1342, 0.2163, 0.9661\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0085\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 2\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0027, 0.0068, 0.0037, 0.0048, 0.7856\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1195, 0.5640, 0.1317, 0.2135, 0.9652\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0088\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 3\n",
      "0it [00:00, ?it/s]Train epoch: 3 [batch #0, batch_size 8, seq length 512]\tLoss: 0.006808\n",
      "25it [00:01, 15.65it/s]Train epoch: 3 [batch #25, batch_size 8, seq length 512]\tLoss: 0.005303\n",
      "49it [00:03, 14.16it/s]Train epoch: 3 [batch #50, batch_size 8, seq length 512]\tLoss: 0.004484\n",
      "75it [00:05, 13.48it/s]Train epoch: 3 [batch #75, batch_size 8, seq length 512]\tLoss: 0.004113\n",
      "99it [00:06, 12.77it/s]Train epoch: 3 [batch #100, batch_size 8, seq length 512]\tLoss: 0.004521\n",
      "125it [00:08, 12.89it/s]Train epoch: 3 [batch #125, batch_size 8, seq length 512]\tLoss: 0.004422\n",
      "149it [00:10, 12.45it/s]Train epoch: 3 [batch #150, batch_size 8, seq length 512]\tLoss: 0.004224\n",
      "175it [00:12, 12.44it/s]Train epoch: 3 [batch #175, batch_size 8, seq length 512]\tLoss: 0.004569\n",
      "199it [00:14, 12.12it/s]Train epoch: 3 [batch #200, batch_size 8, seq length 512]\tLoss: 0.003849\n",
      "225it [00:17, 11.58it/s]Train epoch: 3 [batch #225, batch_size 8, seq length 512]\tLoss: 0.004473\n",
      "249it [00:19, 11.30it/s]Train epoch: 3 [batch #250, batch_size 8, seq length 512]\tLoss: 0.004286\n",
      "275it [00:21, 11.48it/s]Train epoch: 3 [batch #275, batch_size 8, seq length 512]\tLoss: 0.004462\n",
      "299it [00:23, 11.40it/s]Train epoch: 3 [batch #300, batch_size 8, seq length 512]\tLoss: 0.004646\n",
      "325it [00:25, 11.41it/s]Train epoch: 3 [batch #325, batch_size 8, seq length 512]\tLoss: 0.004405\n",
      "349it [00:28, 10.93it/s]Train epoch: 3 [batch #350, batch_size 8, seq length 512]\tLoss: 0.004354\n",
      "375it [00:30, 10.78it/s]Train epoch: 3 [batch #375, batch_size 8, seq length 512]\tLoss: 0.004365\n",
      "399it [00:32, 10.63it/s]Train epoch: 3 [batch #400, batch_size 8, seq length 512]\tLoss: 0.004135\n",
      "425it [00:35, 10.36it/s]Train epoch: 3 [batch #425, batch_size 8, seq length 512]\tLoss: 0.004857\n",
      "450it [00:37,  9.82it/s]Train epoch: 3 [batch #450, batch_size 8, seq length 512]\tLoss: 0.004300\n",
      "474it [00:40, 10.19it/s]Train epoch: 3 [batch #475, batch_size 8, seq length 512]\tLoss: 0.004094\n",
      "500it [00:42, 10.13it/s]Train epoch: 3 [batch #500, batch_size 8, seq length 512]\tLoss: 0.004715\n",
      "524it [00:45,  9.85it/s]Train epoch: 3 [batch #525, batch_size 8, seq length 512]\tLoss: 0.004428\n",
      "550it [00:47, 10.02it/s]Train epoch: 3 [batch #550, batch_size 8, seq length 512]\tLoss: 0.004830\n",
      "575it [00:50,  9.79it/s]Train epoch: 3 [batch #575, batch_size 8, seq length 512]\tLoss: 0.005005\n",
      "600it [00:52,  9.88it/s]Train epoch: 3 [batch #600, batch_size 8, seq length 512]\tLoss: 0.004621\n",
      "625it [00:55,  9.83it/s]Train epoch: 3 [batch #625, batch_size 8, seq length 512]\tLoss: 0.004711\n",
      "650it [00:57,  9.49it/s]Train epoch: 3 [batch #650, batch_size 8, seq length 512]\tLoss: 0.004723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675it [01:00,  9.28it/s]Train epoch: 3 [batch #675, batch_size 8, seq length 512]\tLoss: 0.005553\n",
      "700it [01:03,  9.45it/s]Train epoch: 3 [batch #700, batch_size 8, seq length 512]\tLoss: 0.004750\n",
      "725it [01:05,  9.45it/s]Train epoch: 3 [batch #725, batch_size 8, seq length 512]\tLoss: 0.004525\n",
      "750it [01:08,  9.51it/s]Train epoch: 3 [batch #750, batch_size 8, seq length 512]\tLoss: 0.005499\n",
      "775it [01:11,  8.83it/s]Train epoch: 3 [batch #775, batch_size 8, seq length 512]\tLoss: 0.004377\n",
      "799it [01:13,  8.88it/s]Train epoch: 3 [batch #800, batch_size 8, seq length 512]\tLoss: 0.004295\n",
      "825it [01:16,  9.04it/s]Train epoch: 3 [batch #825, batch_size 8, seq length 512]\tLoss: 0.004689\n",
      "850it [01:19,  8.98it/s]Train epoch: 3 [batch #850, batch_size 8, seq length 512]\tLoss: 0.004787\n",
      "875it [01:22,  8.52it/s]Train epoch: 3 [batch #875, batch_size 8, seq length 512]\tLoss: 0.005059\n",
      "900it [01:25,  8.70it/s]Train epoch: 3 [batch #900, batch_size 8, seq length 512]\tLoss: 0.004846\n",
      "925it [01:27,  9.01it/s]Train epoch: 3 [batch #925, batch_size 8, seq length 512]\tLoss: 0.005067\n",
      "950it [01:30,  8.92it/s]Train epoch: 3 [batch #950, batch_size 8, seq length 512]\tLoss: 0.004017\n",
      "975it [01:33,  8.68it/s]Train epoch: 3 [batch #975, batch_size 8, seq length 512]\tLoss: 0.005108\n",
      "1000it [01:36,  8.81it/s]Train epoch: 3 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.004564\n",
      "1025it [01:39,  8.85it/s]Train epoch: 3 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.004524\n",
      "1050it [01:42,  8.87it/s]Train epoch: 3 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.004947\n",
      "1075it [01:44,  8.70it/s]Train epoch: 3 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.004735\n",
      "1100it [01:47,  8.79it/s]Train epoch: 3 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.005092\n",
      "1125it [01:50,  8.48it/s]Train epoch: 3 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.004852\n",
      "1150it [01:53,  8.63it/s]Train epoch: 3 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.004231\n",
      "1175it [01:56,  8.61it/s]Train epoch: 3 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.004883\n",
      "1200it [01:59,  8.73it/s]Train epoch: 3 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.005326\n",
      "1225it [02:02,  8.39it/s]Train epoch: 3 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.005089\n",
      "1250it [02:05,  8.44it/s]Train epoch: 3 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.004709\n",
      "1275it [02:08,  8.43it/s]Train epoch: 3 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.006024\n",
      "1300it [02:11,  8.43it/s]Train epoch: 3 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.004887\n",
      "1325it [02:14,  8.32it/s]Train epoch: 3 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.005114\n",
      "1350it [02:17,  8.11it/s]Train epoch: 3 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.004603\n",
      "1375it [02:20,  8.18it/s]Train epoch: 3 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.005803\n",
      "1400it [02:23,  8.00it/s]Train epoch: 3 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.004783\n",
      "1425it [02:26,  8.19it/s]Train epoch: 3 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.005097\n",
      "1450it [02:29,  8.21it/s]Train epoch: 3 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.005351\n",
      "1475it [02:32,  8.03it/s]Train epoch: 3 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.005209\n",
      "1500it [02:35,  8.03it/s]Train epoch: 3 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.005709\n",
      "1525it [02:38,  7.81it/s]Train epoch: 3 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.005500\n",
      "1550it [02:41,  7.99it/s]Train epoch: 3 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.005341\n",
      "1575it [02:45,  8.13it/s]Train epoch: 3 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.005057\n",
      "1600it [02:48,  8.11it/s]Train epoch: 3 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.005820\n",
      "1625it [02:51,  7.86it/s]Train epoch: 3 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.005481\n",
      "1650it [02:54,  7.80it/s]Train epoch: 3 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.005873\n",
      "1675it [02:57,  7.71it/s]Train epoch: 3 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.005480\n",
      "1700it [03:01,  7.77it/s]Train epoch: 3 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.005494\n",
      "1725it [03:04,  7.92it/s]Train epoch: 3 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.005606\n",
      "1750it [03:07,  7.68it/s]Train epoch: 3 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.005392\n",
      "1775it [03:10,  7.73it/s]Train epoch: 3 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.005793\n",
      "1800it [03:13,  7.68it/s]Train epoch: 3 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.005660\n",
      "1825it [03:17,  7.29it/s]Train epoch: 3 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.005352\n",
      "1850it [03:20,  7.63it/s]Train epoch: 3 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.005231\n",
      "1875it [03:23,  7.67it/s]Train epoch: 3 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.005521\n",
      "1900it [03:27,  7.56it/s]Train epoch: 3 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.006250\n",
      "1925it [03:30,  7.46it/s]Train epoch: 3 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.005453\n",
      "1950it [03:33,  7.44it/s]Train epoch: 3 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.005777\n",
      "1975it [03:37,  7.50it/s]Train epoch: 3 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.006096\n",
      "2000it [03:40,  7.30it/s]Train epoch: 3 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.005262\n",
      "2025it [03:43,  7.31it/s]Train epoch: 3 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.005711\n",
      "2050it [03:47,  7.39it/s]Train epoch: 3 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.005928\n",
      "2075it [03:50,  7.32it/s]Train epoch: 3 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.005550\n",
      "2100it [03:54,  7.37it/s]Train epoch: 3 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.006012\n",
      "2125it [03:57,  7.52it/s]Train epoch: 3 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.005634\n",
      "2150it [04:00,  7.30it/s]Train epoch: 3 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.006032\n",
      "2175it [04:04,  7.38it/s]Train epoch: 3 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.005755\n",
      "2200it [04:07,  7.09it/s]Train epoch: 3 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.005637\n",
      "2225it [04:11,  7.04it/s]Train epoch: 3 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.005548\n",
      "2250it [04:14,  7.19it/s]Train epoch: 3 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.006384\n",
      "2275it [04:18,  7.05it/s]Train epoch: 3 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.005651\n",
      "2300it [04:21,  7.14it/s]Train epoch: 3 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.005445\n",
      "2325it [04:25,  7.07it/s]Train epoch: 3 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.006109\n",
      "2350it [04:29,  7.03it/s]Train epoch: 3 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.005806\n",
      "2375it [04:32,  7.05it/s]Train epoch: 3 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.006159\n",
      "2400it [04:36,  6.85it/s]Train epoch: 3 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.006095\n",
      "2425it [04:39,  6.59it/s]Train epoch: 3 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.006036\n",
      "2450it [04:43,  7.00it/s]Train epoch: 3 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.006141\n",
      "2475it [04:47,  6.85it/s]Train epoch: 3 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.005707\n",
      "2500it [04:50,  7.02it/s]Train epoch: 3 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.006073\n",
      "2525it [04:54,  6.97it/s]Train epoch: 3 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.005653\n",
      "2550it [04:57,  6.88it/s]Train epoch: 3 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.005949\n",
      "2575it [05:01,  6.58it/s]Train epoch: 3 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.006284\n",
      "2600it [05:05,  6.79it/s]Train epoch: 3 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.005846\n",
      "2625it [05:09,  6.76it/s]Train epoch: 3 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.006125\n",
      "2650it [05:12,  6.70it/s]Train epoch: 3 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.005638\n",
      "2675it [05:16,  6.69it/s]Train epoch: 3 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.006310\n",
      "2700it [05:20,  6.89it/s]Train epoch: 3 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.006865\n",
      "2725it [05:23,  6.55it/s]Train epoch: 3 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.006321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750it [05:27,  6.70it/s]Train epoch: 3 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.007172\n",
      "2775it [05:31,  6.68it/s]Train epoch: 3 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.006201\n",
      "2800it [05:35,  6.57it/s]Train epoch: 3 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.006611\n",
      "2825it [05:39,  6.63it/s]Train epoch: 3 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.005658\n",
      "2850it [05:43,  6.38it/s]Train epoch: 3 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.006474\n",
      "2875it [05:46,  6.54it/s]Train epoch: 3 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.007197\n",
      "2900it [05:50,  6.48it/s]Train epoch: 3 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.006289\n",
      "2925it [05:54,  6.40it/s]Train epoch: 3 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.006569\n",
      "2950it [05:58,  6.46it/s]Train epoch: 3 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.007134\n",
      "2975it [06:02,  6.57it/s]Train epoch: 3 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.006144\n",
      "3000it [06:06,  6.31it/s]Train epoch: 3 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.006327\n",
      "3025it [06:10,  6.14it/s]Train epoch: 3 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.006251\n",
      "3050it [06:14,  6.22it/s]Train epoch: 3 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.006071\n",
      "3075it [06:18,  6.29it/s]Train epoch: 3 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.006358\n",
      "3100it [06:22,  6.28it/s]Train epoch: 3 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.006222\n",
      "3125it [06:26,  6.18it/s]Train epoch: 3 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.006159\n",
      "3150it [06:30,  6.18it/s]Train epoch: 3 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.006488\n",
      "3175it [06:34,  6.02it/s]Train epoch: 3 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.006869\n",
      "3200it [06:38,  6.26it/s]Train epoch: 3 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.006193\n",
      "3225it [06:42,  6.24it/s]Train epoch: 3 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.006487\n",
      "3250it [06:46,  6.22it/s]Train epoch: 3 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.006775\n",
      "3275it [06:50,  6.09it/s]Train epoch: 3 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.006780\n",
      "3300it [06:54,  6.11it/s]Train epoch: 3 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.006890\n",
      "3325it [06:58,  5.93it/s]Train epoch: 3 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.006868\n",
      "3350it [07:02,  6.00it/s]Train epoch: 3 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.006963\n",
      "3375it [07:06,  6.16it/s]Train epoch: 3 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.006342\n",
      "3400it [07:11,  6.04it/s]Train epoch: 3 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.006779\n",
      "3425it [07:15,  5.92it/s]Train epoch: 3 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.006589\n",
      "3450it [07:19,  6.02it/s]Train epoch: 3 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.006653\n",
      "3475it [07:23,  5.94it/s]Train epoch: 3 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.007228\n",
      "3500it [07:27,  5.78it/s]Train epoch: 3 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.006634\n",
      "3525it [07:32,  5.87it/s]Train epoch: 3 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.006477\n",
      "3550it [07:36,  5.89it/s]Train epoch: 3 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.007054\n",
      "3575it [07:40,  5.74it/s]Train epoch: 3 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.007114\n",
      "3600it [07:44,  5.83it/s]Train epoch: 3 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.007372\n",
      "3625it [07:49,  5.85it/s]Train epoch: 3 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.006595\n",
      "3650it [07:53,  5.87it/s]Train epoch: 3 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.007278\n",
      "3675it [07:57,  5.81it/s]Train epoch: 3 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.007365\n",
      "3700it [08:02,  5.73it/s]Train epoch: 3 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.006712\n",
      "3725it [08:06,  5.76it/s]Train epoch: 3 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.007177\n",
      "3750it [08:10,  5.75it/s]Train epoch: 3 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.007056\n",
      "3775it [08:15,  5.65it/s]Train epoch: 3 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.007293\n",
      "3800it [08:19,  5.63it/s]Train epoch: 3 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.007697\n",
      "3825it [08:24,  5.65it/s]Train epoch: 3 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.006943\n",
      "3850it [08:28,  5.38it/s]Train epoch: 3 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.006846\n",
      "3875it [08:33,  5.64it/s]Train epoch: 3 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.007266\n",
      "3900it [08:37,  5.49it/s]Train epoch: 3 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.007471\n",
      "3925it [08:42,  5.61it/s]Train epoch: 3 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.006407\n",
      "3950it [08:46,  5.46it/s]Train epoch: 3 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.006883\n",
      "3975it [08:51,  5.48it/s]Train epoch: 3 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.007443\n",
      "4000it [08:55,  5.50it/s]Train epoch: 3 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.006848\n",
      "4025it [09:00,  5.52it/s]Train epoch: 3 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.006696\n",
      "4050it [09:04,  5.48it/s]Train epoch: 3 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.006767\n",
      "4075it [09:09,  5.41it/s]Train epoch: 3 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.006832\n",
      "4100it [09:13,  5.43it/s]Train epoch: 3 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.007107\n",
      "4125it [09:18,  5.28it/s]Train epoch: 3 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.007240\n",
      "4150it [09:23,  5.39it/s]Train epoch: 3 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.007395\n",
      "4175it [09:27,  5.41it/s]Train epoch: 3 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.006936\n",
      "4200it [09:32,  5.10it/s]Train epoch: 3 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.006508\n",
      "4225it [09:37,  5.20it/s]Train epoch: 3 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.007318\n",
      "4250it [09:42,  5.19it/s]Train epoch: 3 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.007770\n",
      "4275it [09:46,  5.24it/s]Train epoch: 3 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.007615\n",
      "4300it [09:51,  5.21it/s]Train epoch: 3 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.007011\n",
      "4325it [09:56,  5.19it/s]Train epoch: 3 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.007534\n",
      "4350it [10:01,  5.13it/s]Train epoch: 3 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.008043\n",
      "4375it [10:06,  5.11it/s]Train epoch: 3 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.007579\n",
      "4400it [10:11,  5.10it/s]Train epoch: 3 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.007362\n",
      "4425it [10:15,  5.09it/s]Train epoch: 3 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.007566\n",
      "4450it [10:20,  5.09it/s]Train epoch: 3 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.007347\n",
      "4475it [10:25,  4.93it/s]Train epoch: 3 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.008480\n",
      "4500it [10:30,  5.03it/s]Train epoch: 3 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.007845\n",
      "4525it [10:35,  5.06it/s]Train epoch: 3 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.007557\n",
      "4550it [10:40,  4.97it/s]Train epoch: 3 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.007652\n",
      "4575it [10:45,  4.98it/s]Train epoch: 3 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.007249\n",
      "4600it [10:50,  5.06it/s]Train epoch: 3 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.007457\n",
      "4625it [10:56,  4.88it/s]Train epoch: 3 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.007916\n",
      "4650it [11:01,  4.87it/s]Train epoch: 3 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.008196\n",
      "4675it [11:06,  4.81it/s]Train epoch: 3 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.008115\n",
      "4700it [11:11,  4.79it/s]Train epoch: 3 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.007695\n",
      "4725it [11:16,  4.79it/s]Train epoch: 3 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.007900\n",
      "4750it [11:21,  4.76it/s]Train epoch: 3 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.007807\n",
      "4775it [11:27,  4.71it/s]Train epoch: 3 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.008065\n",
      "4800it [11:32,  4.71it/s]Train epoch: 3 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.008349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4825it [11:37,  4.71it/s]Train epoch: 3 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.007253\n",
      "4850it [11:42,  4.71it/s]Train epoch: 3 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.007798\n",
      "4875it [11:48,  4.68it/s]Train epoch: 3 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.008191\n",
      "4900it [11:53,  4.62it/s]Train epoch: 3 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.008125\n",
      "4925it [11:59,  4.55it/s]Train epoch: 3 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.008447\n",
      "4950it [12:04,  4.62it/s]Train epoch: 3 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.008633\n",
      "4975it [12:10,  4.52it/s]Train epoch: 3 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.008575\n",
      "5000it [12:15,  4.51it/s]Train epoch: 3 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.008059\n",
      "5025it [12:21,  4.53it/s]Train epoch: 3 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.008922\n",
      "5050it [12:26,  4.52it/s]Train epoch: 3 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.008599\n",
      "5075it [12:32,  4.37it/s]Train epoch: 3 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.008090\n",
      "5100it [12:38,  4.37it/s]Train epoch: 3 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.008088\n",
      "5125it [12:43,  4.24it/s]Train epoch: 3 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.008838\n",
      "5150it [12:49,  4.45it/s]Train epoch: 3 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.008834\n",
      "5175it [12:55,  4.25it/s]Train epoch: 3 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.008830\n",
      "5200it [13:01,  4.26it/s]Train epoch: 3 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.009256\n",
      "5225it [13:07,  4.23it/s]Train epoch: 3 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.008869\n",
      "5250it [13:12,  4.10it/s]Train epoch: 3 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.008571\n",
      "5275it [13:18,  4.03it/s]Train epoch: 3 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.008775\n",
      "5300it [13:25,  4.12it/s]Train epoch: 3 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.008591\n",
      "5325it [13:31,  4.15it/s]Train epoch: 3 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.008398\n",
      "5350it [13:37,  4.14it/s]Train epoch: 3 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.009109\n",
      "5375it [13:43,  4.07it/s]Train epoch: 3 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.009268\n",
      "5400it [13:49,  3.94it/s]Train epoch: 3 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.008974\n",
      "5425it [13:55,  4.06it/s]Train epoch: 3 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.009021\n",
      "5450it [14:02,  3.94it/s]Train epoch: 3 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.009177\n",
      "5475it [14:08,  3.95it/s]Train epoch: 3 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.009104\n",
      "5500it [14:14,  3.85it/s]Train epoch: 3 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.009398\n",
      "5525it [14:21,  3.80it/s]Train epoch: 3 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.009809\n",
      "5550it [14:27,  3.77it/s]Train epoch: 3 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.009808\n",
      "5575it [14:34,  3.74it/s]Train epoch: 3 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.008984\n",
      "5600it [14:41,  3.64it/s]Train epoch: 3 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.009401\n",
      "5625it [14:48,  3.68it/s]Train epoch: 3 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.010059\n",
      "5650it [14:54,  3.63it/s]Train epoch: 3 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.008891\n",
      "5675it [15:02,  3.52it/s]Train epoch: 3 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.010200\n",
      "5700it [15:09,  3.46it/s]Train epoch: 3 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.009678\n",
      "5725it [15:16,  3.45it/s]Train epoch: 3 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.010052\n",
      "5750it [15:23,  3.35it/s]Train epoch: 3 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.010596\n",
      "5775it [15:31,  3.29it/s]Train epoch: 3 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.009983\n",
      "5800it [15:39,  3.20it/s]Train epoch: 3 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.010613\n",
      "5825it [15:46,  3.12it/s]Train epoch: 3 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.010633\n",
      "5850it [15:55,  3.01it/s]Train epoch: 3 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.010397\n",
      "5875it [16:03,  2.88it/s]Train epoch: 3 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.011138\n",
      "5900it [16:12,  2.77it/s]Train epoch: 3 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.010212\n",
      "5925it [16:22,  2.54it/s]Train epoch: 3 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.011745\n",
      "5950it [16:32,  2.18it/s]Train epoch: 3 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.012552\n",
      "5965it [16:40,  5.96it/s]\n",
      "epoch loss: 0.006680989131559395\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.21it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0050, 0.0106, 0.0069, 0.0083, 0.8109\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1531, 0.5750, 0.1727, 0.2656, 0.9694\n",
      "rec_at_8: 0.2291\n",
      "prec_at_8: 0.4477\n",
      "rec_at_15: 0.3186\n",
      "prec_at_15: 0.3418\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.03it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0047, 0.0116, 0.0064, 0.0082, 0.8088\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1482, 0.5785, 0.1661, 0.2581, 0.9687\n",
      "rec_at_8: 0.2205\n",
      "prec_at_8: 0.4494\n",
      "rec_at_15: 0.3080\n",
      "prec_at_15: 0.3424\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 3\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0050, 0.0106, 0.0069, 0.0083, 0.8109\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1531, 0.5750, 0.1727, 0.2656, 0.9694\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0082\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 3\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0047, 0.0116, 0.0064, 0.0082, 0.8088\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1482, 0.5785, 0.1661, 0.2581, 0.9687\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0085\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 4\n",
      "0it [00:00, ?it/s]Train epoch: 4 [batch #0, batch_size 8, seq length 512]\tLoss: 0.006532\n",
      "24it [00:01, 15.92it/s]Train epoch: 4 [batch #25, batch_size 8, seq length 512]\tLoss: 0.004942\n",
      "50it [00:03, 14.20it/s]Train epoch: 4 [batch #50, batch_size 8, seq length 512]\tLoss: 0.004261\n",
      "74it [00:05, 13.62it/s]Train epoch: 4 [batch #75, batch_size 8, seq length 512]\tLoss: 0.003857\n",
      "100it [00:06, 13.23it/s]Train epoch: 4 [batch #100, batch_size 8, seq length 512]\tLoss: 0.004278\n",
      "124it [00:08, 13.12it/s]Train epoch: 4 [batch #125, batch_size 8, seq length 512]\tLoss: 0.004160\n",
      "150it [00:10, 12.59it/s]Train epoch: 4 [batch #150, batch_size 8, seq length 512]\tLoss: 0.003934\n",
      "174it [00:12, 12.20it/s]Train epoch: 4 [batch #175, batch_size 8, seq length 512]\tLoss: 0.004335\n",
      "200it [00:14, 11.98it/s]Train epoch: 4 [batch #200, batch_size 8, seq length 512]\tLoss: 0.003641\n",
      "224it [00:16, 11.87it/s]Train epoch: 4 [batch #225, batch_size 8, seq length 512]\tLoss: 0.004143\n",
      "250it [00:19, 11.37it/s]Train epoch: 4 [batch #250, batch_size 8, seq length 512]\tLoss: 0.003999\n",
      "274it [00:21, 11.35it/s]Train epoch: 4 [batch #275, batch_size 8, seq length 512]\tLoss: 0.004184\n",
      "300it [00:23, 11.37it/s]Train epoch: 4 [batch #300, batch_size 8, seq length 512]\tLoss: 0.004324\n",
      "324it [00:25, 11.22it/s]Train epoch: 4 [batch #325, batch_size 8, seq length 512]\tLoss: 0.004151\n",
      "350it [00:28, 10.85it/s]Train epoch: 4 [batch #350, batch_size 8, seq length 512]\tLoss: 0.004053\n",
      "374it [00:30, 10.54it/s]Train epoch: 4 [batch #375, batch_size 8, seq length 512]\tLoss: 0.004131\n",
      "400it [00:32, 10.42it/s]Train epoch: 4 [batch #400, batch_size 8, seq length 512]\tLoss: 0.003915\n",
      "424it [00:35, 10.55it/s]Train epoch: 4 [batch #425, batch_size 8, seq length 512]\tLoss: 0.004530\n",
      "450it [00:37, 10.41it/s]Train epoch: 4 [batch #450, batch_size 8, seq length 512]\tLoss: 0.004056\n",
      "474it [00:39, 10.50it/s]Train epoch: 4 [batch #475, batch_size 8, seq length 512]\tLoss: 0.003845\n",
      "500it [00:42,  9.87it/s]Train epoch: 4 [batch #500, batch_size 8, seq length 512]\tLoss: 0.004451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525it [00:44,  9.94it/s]Train epoch: 4 [batch #525, batch_size 8, seq length 512]\tLoss: 0.004124\n",
      "549it [00:47, 10.01it/s]Train epoch: 4 [batch #550, batch_size 8, seq length 512]\tLoss: 0.004524\n",
      "575it [00:50,  9.72it/s]Train epoch: 4 [batch #575, batch_size 8, seq length 512]\tLoss: 0.004700\n",
      "600it [00:52,  9.88it/s]Train epoch: 4 [batch #600, batch_size 8, seq length 512]\tLoss: 0.004393\n",
      "625it [00:55,  9.68it/s]Train epoch: 4 [batch #625, batch_size 8, seq length 512]\tLoss: 0.004442\n",
      "650it [00:57,  9.51it/s]Train epoch: 4 [batch #650, batch_size 8, seq length 512]\tLoss: 0.004479\n",
      "675it [01:00,  9.80it/s]Train epoch: 4 [batch #675, batch_size 8, seq length 512]\tLoss: 0.005248\n",
      "700it [01:02,  9.40it/s]Train epoch: 4 [batch #700, batch_size 8, seq length 512]\tLoss: 0.004478\n",
      "725it [01:05,  9.49it/s]Train epoch: 4 [batch #725, batch_size 8, seq length 512]\tLoss: 0.004294\n",
      "750it [01:08,  9.65it/s]Train epoch: 4 [batch #750, batch_size 8, seq length 512]\tLoss: 0.005172\n",
      "775it [01:10,  9.22it/s]Train epoch: 4 [batch #775, batch_size 8, seq length 512]\tLoss: 0.004081\n",
      "799it [01:13,  9.20it/s]Train epoch: 4 [batch #800, batch_size 8, seq length 512]\tLoss: 0.003993\n",
      "825it [01:16,  9.06it/s]Train epoch: 4 [batch #825, batch_size 8, seq length 512]\tLoss: 0.004444\n",
      "850it [01:19,  8.94it/s]Train epoch: 4 [batch #850, batch_size 8, seq length 512]\tLoss: 0.004549\n",
      "875it [01:21,  9.55it/s]Train epoch: 4 [batch #875, batch_size 8, seq length 512]\tLoss: 0.004794\n",
      "900it [01:24,  9.10it/s]Train epoch: 4 [batch #900, batch_size 8, seq length 512]\tLoss: 0.004578\n",
      "925it [01:27,  8.90it/s]Train epoch: 4 [batch #925, batch_size 8, seq length 512]\tLoss: 0.004786\n",
      "950it [01:30,  8.83it/s]Train epoch: 4 [batch #950, batch_size 8, seq length 512]\tLoss: 0.003758\n",
      "975it [01:32,  9.17it/s]Train epoch: 4 [batch #975, batch_size 8, seq length 512]\tLoss: 0.004770\n",
      "1000it [01:35,  8.91it/s]Train epoch: 4 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.004300\n",
      "1025it [01:38,  9.00it/s]Train epoch: 4 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.004270\n",
      "1050it [01:41,  9.24it/s]Train epoch: 4 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.004679\n",
      "1075it [01:44,  8.82it/s]Train epoch: 4 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.004457\n",
      "1100it [01:46,  8.46it/s]Train epoch: 4 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.004760\n",
      "1125it [01:49,  8.58it/s]Train epoch: 4 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.004621\n",
      "1150it [01:52,  8.95it/s]Train epoch: 4 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.003964\n",
      "1175it [01:55,  8.62it/s]Train epoch: 4 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.004588\n",
      "1200it [01:58,  8.45it/s]Train epoch: 4 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.005036\n",
      "1225it [02:01,  8.62it/s]Train epoch: 4 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.004784\n",
      "1250it [02:04,  8.17it/s]Train epoch: 4 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.004416\n",
      "1275it [02:07,  8.67it/s]Train epoch: 4 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.005686\n",
      "1300it [02:10,  8.38it/s]Train epoch: 4 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.004619\n",
      "1325it [02:13,  8.46it/s]Train epoch: 4 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.004818\n",
      "1350it [02:16,  8.07it/s]Train epoch: 4 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.004307\n",
      "1375it [02:19,  8.15it/s]Train epoch: 4 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.005462\n",
      "1400it [02:22,  8.32it/s]Train epoch: 4 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.004551\n",
      "1425it [02:25,  8.22it/s]Train epoch: 4 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.004809\n",
      "1450it [02:28,  8.21it/s]Train epoch: 4 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.005069\n",
      "1475it [02:31,  8.04it/s]Train epoch: 4 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.004946\n",
      "1500it [02:34,  8.03it/s]Train epoch: 4 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.005367\n",
      "1525it [02:37,  8.19it/s]Train epoch: 4 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.005150\n",
      "1550it [02:40,  7.92it/s]Train epoch: 4 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.005033\n",
      "1575it [02:44,  7.77it/s]Train epoch: 4 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.004809\n",
      "1600it [02:47,  8.09it/s]Train epoch: 4 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.005484\n",
      "1625it [02:50,  8.04it/s]Train epoch: 4 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.005205\n",
      "1650it [02:53,  8.02it/s]Train epoch: 4 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.005594\n",
      "1675it [02:56,  7.62it/s]Train epoch: 4 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.005239\n",
      "1700it [02:59,  7.68it/s]Train epoch: 4 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.005215\n",
      "1725it [03:03,  7.75it/s]Train epoch: 4 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.005314\n",
      "1750it [03:06,  7.84it/s]Train epoch: 4 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.005143\n",
      "1775it [03:09,  7.80it/s]Train epoch: 4 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.005501\n",
      "1800it [03:12,  7.57it/s]Train epoch: 4 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.005361\n",
      "1825it [03:16,  7.67it/s]Train epoch: 4 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.005050\n",
      "1850it [03:19,  7.78it/s]Train epoch: 4 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.004908\n",
      "1875it [03:22,  7.38it/s]Train epoch: 4 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.005245\n",
      "1900it [03:26,  7.58it/s]Train epoch: 4 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.005924\n",
      "1925it [03:29,  7.74it/s]Train epoch: 4 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.005170\n",
      "1950it [03:32,  7.67it/s]Train epoch: 4 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.005494\n",
      "1975it [03:35,  7.62it/s]Train epoch: 4 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.005695\n",
      "2000it [03:39,  7.45it/s]Train epoch: 4 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.004958\n",
      "2025it [03:42,  7.42it/s]Train epoch: 4 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.005384\n",
      "2050it [03:45,  7.33it/s]Train epoch: 4 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.005589\n",
      "2075it [03:49,  7.36it/s]Train epoch: 4 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.005314\n",
      "2100it [03:52,  7.18it/s]Train epoch: 4 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.005674\n",
      "2125it [03:56,  7.55it/s]Train epoch: 4 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.005345\n",
      "2150it [03:59,  7.19it/s]Train epoch: 4 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.005771\n",
      "2175it [04:03,  7.31it/s]Train epoch: 4 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.005442\n",
      "2200it [04:06,  7.39it/s]Train epoch: 4 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.005346\n",
      "2225it [04:09,  7.24it/s]Train epoch: 4 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.005308\n",
      "2250it [04:13,  7.21it/s]Train epoch: 4 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.005962\n",
      "2275it [04:16,  7.17it/s]Train epoch: 4 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.005342\n",
      "2300it [04:20,  7.16it/s]Train epoch: 4 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.005123\n",
      "2325it [04:23,  7.01it/s]Train epoch: 4 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.005806\n",
      "2350it [04:27,  7.06it/s]Train epoch: 4 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.005458\n",
      "2375it [04:30,  7.09it/s]Train epoch: 4 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.005818\n",
      "2400it [04:34,  7.07it/s]Train epoch: 4 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.005724\n",
      "2425it [04:38,  7.00it/s]Train epoch: 4 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.005692\n",
      "2450it [04:41,  7.03it/s]Train epoch: 4 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.005826\n",
      "2475it [04:45,  6.94it/s]Train epoch: 4 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.005378\n",
      "2500it [04:48,  6.91it/s]Train epoch: 4 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.005715\n",
      "2525it [04:52,  6.93it/s]Train epoch: 4 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.005309\n",
      "2550it [04:56,  6.92it/s]Train epoch: 4 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.005642\n",
      "2575it [04:59,  6.87it/s]Train epoch: 4 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.005956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600it [05:03,  6.89it/s]Train epoch: 4 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.005467\n",
      "2625it [05:07,  6.73it/s]Train epoch: 4 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.005796\n",
      "2650it [05:10,  6.81it/s]Train epoch: 4 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.005330\n",
      "2675it [05:14,  6.78it/s]Train epoch: 4 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.005950\n",
      "2700it [05:18,  6.73it/s]Train epoch: 4 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.006450\n",
      "2725it [05:21,  6.63it/s]Train epoch: 4 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.005982\n",
      "2750it [05:25,  6.60it/s]Train epoch: 4 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.006820\n",
      "2775it [05:29,  6.70it/s]Train epoch: 4 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.005910\n",
      "2800it [05:33,  6.65it/s]Train epoch: 4 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.006266\n",
      "2825it [05:36,  6.54it/s]Train epoch: 4 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.005366\n",
      "2850it [05:40,  6.61it/s]Train epoch: 4 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.006133\n",
      "2875it [05:44,  6.57it/s]Train epoch: 4 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.006817\n",
      "2900it [05:48,  6.61it/s]Train epoch: 4 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.005907\n",
      "2925it [05:52,  6.48it/s]Train epoch: 4 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.006227\n",
      "2950it [05:56,  6.63it/s]Train epoch: 4 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.006739\n",
      "2975it [05:59,  6.47it/s]Train epoch: 4 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.005802\n",
      "3000it [06:03,  6.45it/s]Train epoch: 4 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.006034\n",
      "3025it [06:07,  6.40it/s]Train epoch: 4 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.005890\n",
      "3050it [06:11,  6.38it/s]Train epoch: 4 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.005776\n",
      "3075it [06:15,  6.35it/s]Train epoch: 4 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.006008\n",
      "3100it [06:19,  6.24it/s]Train epoch: 4 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.005886\n",
      "3125it [06:23,  6.30it/s]Train epoch: 4 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.005831\n",
      "3150it [06:27,  6.31it/s]Train epoch: 4 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.006154\n",
      "3175it [06:31,  6.23it/s]Train epoch: 4 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.006556\n",
      "3200it [06:35,  6.30it/s]Train epoch: 4 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.005834\n",
      "3225it [06:39,  6.23it/s]Train epoch: 4 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.006183\n",
      "3250it [06:43,  6.18it/s]Train epoch: 4 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.006429\n",
      "3275it [06:47,  6.18it/s]Train epoch: 4 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.006441\n",
      "3300it [06:51,  6.17it/s]Train epoch: 4 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.006579\n",
      "3325it [06:55,  6.18it/s]Train epoch: 4 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.006556\n",
      "3350it [06:59,  6.08it/s]Train epoch: 4 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.006655\n",
      "3375it [07:03,  6.15it/s]Train epoch: 4 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.006017\n",
      "3400it [07:07,  6.14it/s]Train epoch: 4 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.006410\n",
      "3425it [07:11,  5.96it/s]Train epoch: 4 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.006289\n",
      "3450it [07:16,  5.79it/s]Train epoch: 4 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.006328\n",
      "3475it [07:20,  5.90it/s]Train epoch: 4 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.006885\n",
      "3500it [07:24,  5.88it/s]Train epoch: 4 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.006302\n",
      "3525it [07:28,  6.00it/s]Train epoch: 4 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.006172\n",
      "3550it [07:33,  5.80it/s]Train epoch: 4 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.006702\n",
      "3575it [07:37,  5.85it/s]Train epoch: 4 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.006807\n",
      "3600it [07:41,  5.82it/s]Train epoch: 4 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.006961\n",
      "3625it [07:45,  5.82it/s]Train epoch: 4 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.006215\n",
      "3650it [07:50,  5.80it/s]Train epoch: 4 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.006940\n",
      "3675it [07:54,  5.80it/s]Train epoch: 4 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.007052\n",
      "3700it [07:58,  5.79it/s]Train epoch: 4 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.006414\n",
      "3725it [08:03,  5.53it/s]Train epoch: 4 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.006799\n",
      "3750it [08:07,  5.69it/s]Train epoch: 4 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.006669\n",
      "3775it [08:12,  5.40it/s]Train epoch: 4 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.006934\n",
      "3800it [08:16,  5.57it/s]Train epoch: 4 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.007324\n",
      "3825it [08:21,  5.66it/s]Train epoch: 4 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.006548\n",
      "3850it [08:25,  5.60it/s]Train epoch: 4 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.006541\n",
      "3875it [08:30,  5.66it/s]Train epoch: 4 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.006895\n",
      "3900it [08:34,  5.57it/s]Train epoch: 4 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.007029\n",
      "3925it [08:39,  5.60it/s]Train epoch: 4 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.006069\n",
      "3950it [08:43,  5.62it/s]Train epoch: 4 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.006532\n",
      "3975it [08:48,  5.54it/s]Train epoch: 4 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.007099\n",
      "4000it [08:52,  5.54it/s]Train epoch: 4 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.006535\n",
      "4025it [08:57,  5.52it/s]Train epoch: 4 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.006366\n",
      "4050it [09:01,  5.27it/s]Train epoch: 4 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.006462\n",
      "4075it [09:06,  5.34it/s]Train epoch: 4 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.006512\n",
      "4100it [09:11,  5.18it/s]Train epoch: 4 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.006727\n",
      "4125it [09:15,  5.44it/s]Train epoch: 4 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.006887\n",
      "4150it [09:20,  5.42it/s]Train epoch: 4 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.007117\n",
      "4175it [09:25,  5.29it/s]Train epoch: 4 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.006610\n",
      "4200it [09:29,  5.36it/s]Train epoch: 4 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.006187\n",
      "4225it [09:34,  5.32it/s]Train epoch: 4 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.006899\n",
      "4250it [09:39,  5.33it/s]Train epoch: 4 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.007393\n",
      "4275it [09:44,  5.24it/s]Train epoch: 4 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.007233\n",
      "4300it [09:48,  5.27it/s]Train epoch: 4 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.006668\n",
      "4325it [09:53,  5.30it/s]Train epoch: 4 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.007254\n",
      "4350it [09:58,  5.17it/s]Train epoch: 4 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.007694\n",
      "4375it [10:03,  5.24it/s]Train epoch: 4 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.007245\n",
      "4400it [10:08,  5.08it/s]Train epoch: 4 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.006991\n",
      "4425it [10:12,  5.24it/s]Train epoch: 4 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.007204\n",
      "4450it [10:17,  5.11it/s]Train epoch: 4 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.006995\n",
      "4475it [10:22,  4.96it/s]Train epoch: 4 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.008067\n",
      "4500it [10:27,  5.06it/s]Train epoch: 4 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.007500\n",
      "4525it [10:32,  4.96it/s]Train epoch: 4 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.007224\n",
      "4550it [10:37,  5.14it/s]Train epoch: 4 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.007326\n",
      "4575it [10:42,  5.06it/s]Train epoch: 4 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.006922\n",
      "4600it [10:47,  4.96it/s]Train epoch: 4 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.007129\n",
      "4625it [10:52,  4.95it/s]Train epoch: 4 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.007591\n",
      "4650it [10:57,  4.99it/s]Train epoch: 4 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.007884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4675it [11:02,  4.87it/s]Train epoch: 4 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.007715\n",
      "4700it [11:08,  4.84it/s]Train epoch: 4 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.007341\n",
      "4725it [11:13,  4.80it/s]Train epoch: 4 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.007538\n",
      "4750it [11:18,  4.78it/s]Train epoch: 4 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.007458\n",
      "4775it [11:23,  4.69it/s]Train epoch: 4 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.007652\n",
      "4800it [11:28,  4.73it/s]Train epoch: 4 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.007960\n",
      "4825it [11:34,  4.70it/s]Train epoch: 4 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.006937\n",
      "4850it [11:39,  4.73it/s]Train epoch: 4 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.007440\n",
      "4875it [11:44,  4.65it/s]Train epoch: 4 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.007794\n",
      "4900it [11:50,  4.68it/s]Train epoch: 4 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.007730\n",
      "4925it [11:55,  4.73it/s]Train epoch: 4 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.008105\n",
      "4950it [12:01,  4.60it/s]Train epoch: 4 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.008282\n",
      "4975it [12:06,  4.54it/s]Train epoch: 4 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.008162\n",
      "5000it [12:12,  4.42it/s]Train epoch: 4 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.007709\n",
      "5025it [12:17,  4.55it/s]Train epoch: 4 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.008502\n",
      "5050it [12:23,  4.50it/s]Train epoch: 4 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.008226\n",
      "5075it [12:28,  4.42it/s]Train epoch: 4 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.007837\n",
      "5100it [12:34,  4.38it/s]Train epoch: 4 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.007795\n",
      "5125it [12:40,  4.35it/s]Train epoch: 4 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.008426\n",
      "5150it [12:45,  4.35it/s]Train epoch: 4 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.008484\n",
      "5175it [12:51,  4.31it/s]Train epoch: 4 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.008455\n",
      "5200it [12:57,  4.37it/s]Train epoch: 4 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.008897\n",
      "5225it [13:03,  4.26it/s]Train epoch: 4 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.008489\n",
      "5250it [13:09,  4.25it/s]Train epoch: 4 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.008176\n",
      "5275it [13:15,  4.18it/s]Train epoch: 4 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.008427\n",
      "5300it [13:21,  4.15it/s]Train epoch: 4 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.008237\n",
      "5325it [13:27,  4.15it/s]Train epoch: 4 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.008045\n",
      "5350it [13:33,  4.07it/s]Train epoch: 4 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.008765\n",
      "5375it [13:39,  4.08it/s]Train epoch: 4 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.008948\n",
      "5400it [13:45,  3.97it/s]Train epoch: 4 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.008675\n",
      "5425it [13:51,  4.06it/s]Train epoch: 4 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.008675\n",
      "5450it [13:58,  3.90it/s]Train epoch: 4 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.008846\n",
      "5475it [14:04,  3.87it/s]Train epoch: 4 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.008775\n",
      "5500it [14:10,  3.86it/s]Train epoch: 4 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.008985\n",
      "5525it [14:17,  3.74it/s]Train epoch: 4 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.009492\n",
      "5550it [14:24,  3.62it/s]Train epoch: 4 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.009450\n",
      "5575it [14:30,  3.75it/s]Train epoch: 4 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.008695\n",
      "5600it [14:37,  3.73it/s]Train epoch: 4 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.009061\n",
      "5625it [14:44,  3.65it/s]Train epoch: 4 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.009692\n",
      "5650it [14:51,  3.61it/s]Train epoch: 4 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.008548\n",
      "5675it [14:58,  3.52it/s]Train epoch: 4 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.009935\n",
      "5700it [15:05,  3.48it/s]Train epoch: 4 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.009302\n",
      "5725it [15:12,  3.42it/s]Train epoch: 4 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.009661\n",
      "5750it [15:19,  3.32it/s]Train epoch: 4 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.010225\n",
      "5775it [15:27,  3.29it/s]Train epoch: 4 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.009609\n",
      "5800it [15:35,  3.23it/s]Train epoch: 4 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.010159\n",
      "5825it [15:43,  3.12it/s]Train epoch: 4 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.010224\n",
      "5850it [15:51,  3.02it/s]Train epoch: 4 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.010046\n",
      "5875it [15:59,  2.89it/s]Train epoch: 4 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.010731\n",
      "5900it [16:08,  2.75it/s]Train epoch: 4 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.009859\n",
      "5925it [16:18,  2.55it/s]Train epoch: 4 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.011336\n",
      "5950it [16:28,  2.18it/s]Train epoch: 4 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.012164\n",
      "5965it [16:36,  5.98it/s]\n",
      "epoch loss: 0.006356018131219432\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.37it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0081, 0.0165, 0.0114, 0.0135, 0.8240\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1907, 0.5914, 0.2197, 0.3204, 0.9717\n",
      "rec_at_8: 0.2617\n",
      "prec_at_8: 0.5036\n",
      "rec_at_15: 0.3574\n",
      "prec_at_15: 0.3777\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.13it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0075, 0.0165, 0.0105, 0.0128, 0.8222\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1828, 0.5884, 0.2096, 0.3091, 0.9709\n",
      "rec_at_8: 0.2510\n",
      "prec_at_8: 0.5000\n",
      "rec_at_15: 0.3420\n",
      "prec_at_15: 0.3754\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0081, 0.0165, 0.0114, 0.0135, 0.8240\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1907, 0.5914, 0.2197, 0.3204, 0.9717\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 4\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0075, 0.0165, 0.0105, 0.0128, 0.8222\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.1828, 0.5884, 0.2096, 0.3091, 0.9709\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0082\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 5\n",
      "0it [00:00, ?it/s]Train epoch: 5 [batch #0, batch_size 8, seq length 512]\tLoss: 0.006629\n",
      "24it [00:01, 15.63it/s]Train epoch: 5 [batch #25, batch_size 8, seq length 512]\tLoss: 0.004639\n",
      "50it [00:03, 14.32it/s]Train epoch: 5 [batch #50, batch_size 8, seq length 512]\tLoss: 0.004069\n",
      "74it [00:05, 14.04it/s]Train epoch: 5 [batch #75, batch_size 8, seq length 512]\tLoss: 0.003633\n",
      "100it [00:07, 13.06it/s]Train epoch: 5 [batch #100, batch_size 8, seq length 512]\tLoss: 0.004010\n",
      "124it [00:08, 12.63it/s]Train epoch: 5 [batch #125, batch_size 8, seq length 512]\tLoss: 0.003932\n",
      "150it [00:10, 12.43it/s]Train epoch: 5 [batch #150, batch_size 8, seq length 512]\tLoss: 0.003723\n",
      "174it [00:12, 12.54it/s]Train epoch: 5 [batch #175, batch_size 8, seq length 512]\tLoss: 0.004099\n",
      "200it [00:15, 12.22it/s]Train epoch: 5 [batch #200, batch_size 8, seq length 512]\tLoss: 0.003450\n",
      "224it [00:17, 11.42it/s]Train epoch: 5 [batch #225, batch_size 8, seq length 512]\tLoss: 0.003890\n",
      "250it [00:19, 11.50it/s]Train epoch: 5 [batch #250, batch_size 8, seq length 512]\tLoss: 0.003774\n",
      "274it [00:21, 11.58it/s]Train epoch: 5 [batch #275, batch_size 8, seq length 512]\tLoss: 0.003965\n",
      "300it [00:23, 11.15it/s]Train epoch: 5 [batch #300, batch_size 8, seq length 512]\tLoss: 0.004081\n",
      "324it [00:25, 10.87it/s]Train epoch: 5 [batch #325, batch_size 8, seq length 512]\tLoss: 0.003923\n",
      "350it [00:28, 11.42it/s]Train epoch: 5 [batch #350, batch_size 8, seq length 512]\tLoss: 0.003861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374it [00:30, 10.99it/s]Train epoch: 5 [batch #375, batch_size 8, seq length 512]\tLoss: 0.003902\n",
      "400it [00:32, 10.71it/s]Train epoch: 5 [batch #400, batch_size 8, seq length 512]\tLoss: 0.003682\n",
      "424it [00:35, 10.52it/s]Train epoch: 5 [batch #425, batch_size 8, seq length 512]\tLoss: 0.004315\n",
      "450it [00:37, 10.48it/s]Train epoch: 5 [batch #450, batch_size 8, seq length 512]\tLoss: 0.003833\n",
      "474it [00:40, 10.47it/s]Train epoch: 5 [batch #475, batch_size 8, seq length 512]\tLoss: 0.003644\n",
      "500it [00:42, 10.14it/s]Train epoch: 5 [batch #500, batch_size 8, seq length 512]\tLoss: 0.004255\n",
      "525it [00:45, 10.16it/s]Train epoch: 5 [batch #525, batch_size 8, seq length 512]\tLoss: 0.003933\n",
      "550it [00:47,  9.85it/s]Train epoch: 5 [batch #550, batch_size 8, seq length 512]\tLoss: 0.004265\n",
      "575it [00:50,  9.77it/s]Train epoch: 5 [batch #575, batch_size 8, seq length 512]\tLoss: 0.004426\n",
      "600it [00:52, 10.02it/s]Train epoch: 5 [batch #600, batch_size 8, seq length 512]\tLoss: 0.004168\n",
      "625it [00:55,  9.69it/s]Train epoch: 5 [batch #625, batch_size 8, seq length 512]\tLoss: 0.004171\n",
      "650it [00:57,  9.62it/s]Train epoch: 5 [batch #650, batch_size 8, seq length 512]\tLoss: 0.004275\n",
      "675it [01:00,  9.34it/s]Train epoch: 5 [batch #675, batch_size 8, seq length 512]\tLoss: 0.004986\n",
      "700it [01:03,  9.32it/s]Train epoch: 5 [batch #700, batch_size 8, seq length 512]\tLoss: 0.004266\n",
      "725it [01:05,  9.46it/s]Train epoch: 5 [batch #725, batch_size 8, seq length 512]\tLoss: 0.004117\n",
      "750it [01:08,  9.64it/s]Train epoch: 5 [batch #750, batch_size 8, seq length 512]\tLoss: 0.004957\n",
      "775it [01:10,  9.24it/s]Train epoch: 5 [batch #775, batch_size 8, seq length 512]\tLoss: 0.003877\n",
      "800it [01:13,  9.35it/s]Train epoch: 5 [batch #800, batch_size 8, seq length 512]\tLoss: 0.003762\n",
      "825it [01:16,  9.31it/s]Train epoch: 5 [batch #825, batch_size 8, seq length 512]\tLoss: 0.004209\n",
      "850it [01:19,  9.13it/s]Train epoch: 5 [batch #850, batch_size 8, seq length 512]\tLoss: 0.004321\n",
      "875it [01:21,  9.11it/s]Train epoch: 5 [batch #875, batch_size 8, seq length 512]\tLoss: 0.004516\n",
      "900it [01:24,  9.27it/s]Train epoch: 5 [batch #900, batch_size 8, seq length 512]\tLoss: 0.004338\n",
      "925it [01:27,  8.87it/s]Train epoch: 5 [batch #925, batch_size 8, seq length 512]\tLoss: 0.004587\n",
      "950it [01:30,  8.78it/s]Train epoch: 5 [batch #950, batch_size 8, seq length 512]\tLoss: 0.003552\n",
      "975it [01:32,  8.99it/s]Train epoch: 5 [batch #975, batch_size 8, seq length 512]\tLoss: 0.004523\n",
      "1000it [01:35,  8.53it/s]Train epoch: 5 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.004075\n",
      "1025it [01:38,  8.97it/s]Train epoch: 5 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.004080\n",
      "1050it [01:41,  8.66it/s]Train epoch: 5 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.004434\n",
      "1075it [01:44,  8.67it/s]Train epoch: 5 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.004281\n",
      "1100it [01:47,  8.73it/s]Train epoch: 5 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.004524\n",
      "1125it [01:49,  8.56it/s]Train epoch: 5 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.004389\n",
      "1150it [01:52,  8.77it/s]Train epoch: 5 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.003784\n",
      "1175it [01:55,  8.68it/s]Train epoch: 5 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.004381\n",
      "1200it [01:58,  8.70it/s]Train epoch: 5 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.004754\n",
      "1225it [02:01,  8.32it/s]Train epoch: 5 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.004555\n",
      "1250it [02:04,  8.48it/s]Train epoch: 5 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.004192\n",
      "1275it [02:07,  8.45it/s]Train epoch: 5 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.005423\n",
      "1300it [02:10,  8.33it/s]Train epoch: 5 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.004421\n",
      "1325it [02:13,  8.04it/s]Train epoch: 5 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.004553\n",
      "1350it [02:16,  8.25it/s]Train epoch: 5 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.004118\n",
      "1375it [02:19,  8.08it/s]Train epoch: 5 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.005179\n",
      "1400it [02:22,  8.10it/s]Train epoch: 5 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.004295\n",
      "1425it [02:25,  8.11it/s]Train epoch: 5 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.004609\n",
      "1450it [02:28,  8.11it/s]Train epoch: 5 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.004784\n",
      "1475it [02:31,  8.35it/s]Train epoch: 5 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.004680\n",
      "1500it [02:34,  8.00it/s]Train epoch: 5 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.005164\n",
      "1525it [02:37,  8.22it/s]Train epoch: 5 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.004828\n",
      "1550it [02:41,  7.94it/s]Train epoch: 5 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.004739\n",
      "1575it [02:44,  7.98it/s]Train epoch: 5 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.004532\n",
      "1600it [02:47,  8.21it/s]Train epoch: 5 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.005167\n",
      "1625it [02:50,  7.89it/s]Train epoch: 5 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.004969\n",
      "1650it [02:53,  7.93it/s]Train epoch: 5 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.005329\n",
      "1675it [02:56,  7.78it/s]Train epoch: 5 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.005069\n",
      "1700it [03:00,  7.81it/s]Train epoch: 5 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.004917\n",
      "1725it [03:03,  7.76it/s]Train epoch: 5 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.005063\n",
      "1750it [03:06,  7.88it/s]Train epoch: 5 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.004910\n",
      "1775it [03:09,  7.80it/s]Train epoch: 5 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.005251\n",
      "1800it [03:12,  7.69it/s]Train epoch: 5 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.005088\n",
      "1825it [03:16,  7.65it/s]Train epoch: 5 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.004826\n",
      "1850it [03:19,  7.54it/s]Train epoch: 5 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.004669\n",
      "1875it [03:22,  7.59it/s]Train epoch: 5 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.004988\n",
      "1900it [03:26,  7.78it/s]Train epoch: 5 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.005639\n",
      "1925it [03:29,  7.81it/s]Train epoch: 5 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.004952\n",
      "1950it [03:32,  7.49it/s]Train epoch: 5 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.005265\n",
      "1975it [03:36,  7.47it/s]Train epoch: 5 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.005391\n",
      "2000it [03:39,  7.38it/s]Train epoch: 5 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.004729\n",
      "2025it [03:42,  7.51it/s]Train epoch: 5 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.005111\n",
      "2050it [03:46,  7.24it/s]Train epoch: 5 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.005332\n",
      "2075it [03:49,  7.51it/s]Train epoch: 5 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.005020\n",
      "2100it [03:52,  7.53it/s]Train epoch: 5 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.005418\n",
      "2125it [03:56,  7.22it/s]Train epoch: 5 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.005110\n",
      "2150it [03:59,  7.32it/s]Train epoch: 5 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.005540\n",
      "2175it [04:03,  7.36it/s]Train epoch: 5 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.005147\n",
      "2200it [04:06,  7.21it/s]Train epoch: 5 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.005048\n",
      "2225it [04:10,  7.17it/s]Train epoch: 5 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.005067\n",
      "2250it [04:13,  7.13it/s]Train epoch: 5 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.005664\n",
      "2275it [04:17,  7.16it/s]Train epoch: 5 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.005118\n",
      "2300it [04:20,  7.22it/s]Train epoch: 5 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.004843\n",
      "2325it [04:24,  7.01it/s]Train epoch: 5 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.005596\n",
      "2350it [04:27,  7.00it/s]Train epoch: 5 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.005175\n",
      "2375it [04:31,  7.01it/s]Train epoch: 5 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.005533\n",
      "2400it [04:35,  6.84it/s]Train epoch: 5 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.005447\n",
      "2425it [04:38,  7.05it/s]Train epoch: 5 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.005407\n",
      "2450it [04:42,  6.91it/s]Train epoch: 5 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.005519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2475it [04:45,  6.90it/s]Train epoch: 5 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.005146\n",
      "2500it [04:49,  6.72it/s]Train epoch: 5 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.005447\n",
      "2525it [04:53,  6.93it/s]Train epoch: 5 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.005000\n",
      "2550it [04:56,  7.02it/s]Train epoch: 5 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.005381\n",
      "2575it [05:00,  6.77it/s]Train epoch: 5 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.005738\n",
      "2600it [05:04,  6.83it/s]Train epoch: 5 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.005221\n",
      "2625it [05:07,  6.83it/s]Train epoch: 5 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.005476\n",
      "2650it [05:11,  6.86it/s]Train epoch: 5 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.005083\n",
      "2675it [05:15,  6.75it/s]Train epoch: 5 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.005624\n",
      "2700it [05:18,  6.72it/s]Train epoch: 5 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.006156\n",
      "2725it [05:22,  6.76it/s]Train epoch: 5 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.005716\n",
      "2750it [05:26,  6.66it/s]Train epoch: 5 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.006491\n",
      "2775it [05:30,  6.52it/s]Train epoch: 5 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.005619\n",
      "2800it [05:33,  6.57it/s]Train epoch: 5 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.005976\n",
      "2825it [05:37,  6.55it/s]Train epoch: 5 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.005105\n",
      "2850it [05:41,  6.58it/s]Train epoch: 5 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.005871\n",
      "2875it [05:45,  6.59it/s]Train epoch: 5 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.006542\n",
      "2900it [05:49,  6.41it/s]Train epoch: 5 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.005693\n",
      "2925it [05:52,  6.52it/s]Train epoch: 5 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.005963\n",
      "2950it [05:56,  6.47it/s]Train epoch: 5 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.006466\n",
      "2975it [06:00,  6.33it/s]Train epoch: 5 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.005574\n",
      "3000it [06:04,  6.52it/s]Train epoch: 5 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.005787\n",
      "3025it [06:08,  6.47it/s]Train epoch: 5 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.005613\n",
      "3050it [06:12,  6.19it/s]Train epoch: 5 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.005534\n",
      "3075it [06:16,  6.28it/s]Train epoch: 5 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.005771\n",
      "3100it [06:20,  6.12it/s]Train epoch: 5 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.005625\n",
      "3125it [06:24,  6.17it/s]Train epoch: 5 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.005531\n",
      "3150it [06:28,  6.26it/s]Train epoch: 5 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.005885\n",
      "3175it [06:32,  6.23it/s]Train epoch: 5 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.006276\n",
      "3200it [06:36,  6.08it/s]Train epoch: 5 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.005550\n",
      "3225it [06:40,  6.23it/s]Train epoch: 5 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.005925\n",
      "3250it [06:44,  6.09it/s]Train epoch: 5 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.006156\n",
      "3275it [06:48,  6.30it/s]Train epoch: 5 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.006155\n",
      "3300it [06:52,  6.07it/s]Train epoch: 5 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.006353\n",
      "3325it [06:56,  6.08it/s]Train epoch: 5 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.006285\n",
      "3350it [07:00,  6.12it/s]Train epoch: 5 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.006324\n",
      "3375it [07:04,  5.99it/s]Train epoch: 5 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.005692\n",
      "3400it [07:09,  6.10it/s]Train epoch: 5 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.006179\n",
      "3425it [07:13,  5.93it/s]Train epoch: 5 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.006094\n",
      "3450it [07:17,  6.02it/s]Train epoch: 5 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.006024\n",
      "3475it [07:21,  6.05it/s]Train epoch: 5 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.006638\n",
      "3500it [07:25,  5.96it/s]Train epoch: 5 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.005966\n",
      "3525it [07:30,  5.90it/s]Train epoch: 5 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.005924\n",
      "3550it [07:34,  5.97it/s]Train epoch: 5 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.006352\n",
      "3575it [07:38,  5.88it/s]Train epoch: 5 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.006505\n",
      "3600it [07:42,  5.89it/s]Train epoch: 5 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.006693\n",
      "3625it [07:47,  5.69it/s]Train epoch: 5 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.005934\n",
      "3650it [07:51,  5.81it/s]Train epoch: 5 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.006663\n",
      "3675it [07:55,  5.70it/s]Train epoch: 5 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.006798\n",
      "3700it [08:00,  5.74it/s]Train epoch: 5 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.006103\n",
      "3725it [08:04,  5.73it/s]Train epoch: 5 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.006533\n",
      "3750it [08:09,  5.80it/s]Train epoch: 5 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.006370\n",
      "3775it [08:13,  5.70it/s]Train epoch: 5 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.006611\n",
      "3800it [08:17,  5.55it/s]Train epoch: 5 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.007058\n",
      "3825it [08:22,  5.76it/s]Train epoch: 5 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.006298\n",
      "3850it [08:26,  5.64it/s]Train epoch: 5 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.006264\n",
      "3875it [08:31,  5.67it/s]Train epoch: 5 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.006589\n",
      "3900it [08:35,  5.55it/s]Train epoch: 5 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.006706\n",
      "3925it [08:40,  5.56it/s]Train epoch: 5 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.005889\n",
      "3950it [08:44,  5.64it/s]Train epoch: 5 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.006269\n",
      "3975it [08:49,  5.47it/s]Train epoch: 5 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.006755\n",
      "4000it [08:53,  5.48it/s]Train epoch: 5 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.006266\n",
      "4025it [08:58,  5.45it/s]Train epoch: 5 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.006140\n",
      "4050it [09:02,  5.49it/s]Train epoch: 5 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.006238\n",
      "4075it [09:07,  5.47it/s]Train epoch: 5 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.006257\n",
      "4100it [09:12,  5.42it/s]Train epoch: 5 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.006453\n",
      "4125it [09:16,  5.32it/s]Train epoch: 5 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.006609\n",
      "4150it [09:21,  5.31it/s]Train epoch: 5 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.006805\n",
      "4175it [09:26,  5.38it/s]Train epoch: 5 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.006348\n",
      "4200it [09:30,  5.29it/s]Train epoch: 5 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.005952\n",
      "4225it [09:35,  5.22it/s]Train epoch: 5 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.006553\n",
      "4250it [09:40,  5.20it/s]Train epoch: 5 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.007152\n",
      "4275it [09:44,  5.23it/s]Train epoch: 5 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.006867\n",
      "4300it [09:49,  5.22it/s]Train epoch: 5 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.006415\n",
      "4325it [09:54,  5.21it/s]Train epoch: 5 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.006954\n",
      "4350it [09:59,  5.21it/s]Train epoch: 5 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.007375\n",
      "4375it [10:04,  5.16it/s]Train epoch: 5 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.007009\n",
      "4400it [10:08,  5.18it/s]Train epoch: 5 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.006693\n",
      "4425it [10:13,  5.04it/s]Train epoch: 5 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.006908\n",
      "4450it [10:18,  5.16it/s]Train epoch: 5 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.006708\n",
      "4475it [10:23,  4.96it/s]Train epoch: 5 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.007711\n",
      "4500it [10:28,  4.94it/s]Train epoch: 5 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.007253\n",
      "4525it [10:33,  4.98it/s]Train epoch: 5 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.006911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4550it [10:38,  4.93it/s]Train epoch: 5 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.007003\n",
      "4575it [10:43,  5.00it/s]Train epoch: 5 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.006647\n",
      "4600it [10:48,  4.96it/s]Train epoch: 5 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.006887\n",
      "4625it [10:54,  5.00it/s]Train epoch: 5 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.007293\n",
      "4650it [10:59,  4.88it/s]Train epoch: 5 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.007621\n",
      "4675it [11:04,  4.83it/s]Train epoch: 5 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.007384\n",
      "4700it [11:09,  4.85it/s]Train epoch: 5 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.007115\n",
      "4725it [11:14,  4.85it/s]Train epoch: 5 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.007268\n",
      "4750it [11:19,  4.76it/s]Train epoch: 5 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.007160\n",
      "4775it [11:25,  4.73it/s]Train epoch: 5 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.007349\n",
      "4800it [11:30,  4.74it/s]Train epoch: 5 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.007632\n",
      "4825it [11:35,  4.74it/s]Train epoch: 5 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.006690\n",
      "4850it [11:40,  4.65it/s]Train epoch: 5 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.007151\n",
      "4875it [11:46,  4.71it/s]Train epoch: 5 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.007484\n",
      "4900it [11:51,  4.62it/s]Train epoch: 5 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.007467\n",
      "4925it [11:57,  4.68it/s]Train epoch: 5 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.007800\n",
      "4950it [12:02,  4.59it/s]Train epoch: 5 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.007902\n",
      "4975it [12:08,  4.54it/s]Train epoch: 5 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.007875\n",
      "5000it [12:13,  4.49it/s]Train epoch: 5 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.007409\n",
      "5025it [12:19,  4.56it/s]Train epoch: 5 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.008194\n",
      "5050it [12:24,  4.47it/s]Train epoch: 5 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.007953\n",
      "5075it [12:30,  4.36it/s]Train epoch: 5 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.007570\n",
      "5100it [12:36,  4.37it/s]Train epoch: 5 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.007536\n",
      "5125it [12:41,  4.41it/s]Train epoch: 5 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.008177\n",
      "5150it [12:47,  4.43it/s]Train epoch: 5 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.008223\n",
      "5175it [12:53,  4.34it/s]Train epoch: 5 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.008116\n",
      "5200it [12:59,  4.31it/s]Train epoch: 5 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.008616\n",
      "5225it [13:04,  4.26it/s]Train epoch: 5 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.008169\n",
      "5250it [13:10,  4.31it/s]Train epoch: 5 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.007906\n",
      "5275it [13:16,  4.25it/s]Train epoch: 5 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.008141\n",
      "5300it [13:22,  4.16it/s]Train epoch: 5 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.007986\n",
      "5325it [13:28,  4.15it/s]Train epoch: 5 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.007742\n",
      "5350it [13:34,  4.03it/s]Train epoch: 5 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.008460\n",
      "5375it [13:41,  4.07it/s]Train epoch: 5 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.008692\n",
      "5400it [13:47,  4.02it/s]Train epoch: 5 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.008366\n",
      "5425it [13:53,  3.98it/s]Train epoch: 5 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.008334\n",
      "5450it [13:59,  3.98it/s]Train epoch: 5 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.008560\n",
      "5475it [14:06,  3.89it/s]Train epoch: 5 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.008475\n",
      "5500it [14:12,  3.84it/s]Train epoch: 5 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.008676\n",
      "5525it [14:18,  3.86it/s]Train epoch: 5 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.009089\n",
      "5550it [14:25,  3.78it/s]Train epoch: 5 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.009169\n",
      "5575it [14:32,  3.80it/s]Train epoch: 5 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.008341\n",
      "5600it [14:38,  3.72it/s]Train epoch: 5 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.008841\n",
      "5625it [14:45,  3.65it/s]Train epoch: 5 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.009349\n",
      "5650it [14:52,  3.63it/s]Train epoch: 5 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.008272\n",
      "5675it [14:59,  3.53it/s]Train epoch: 5 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.009610\n",
      "5700it [15:06,  3.43it/s]Train epoch: 5 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.009031\n",
      "5725it [15:13,  3.41it/s]Train epoch: 5 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.009343\n",
      "5750it [15:21,  3.38it/s]Train epoch: 5 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.009973\n",
      "5775it [15:28,  3.29it/s]Train epoch: 5 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.009310\n",
      "5800it [15:36,  3.17it/s]Train epoch: 5 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.009751\n",
      "5825it [15:44,  3.12it/s]Train epoch: 5 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.009929\n",
      "5850it [15:52,  3.02it/s]Train epoch: 5 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.009777\n",
      "5875it [16:01,  2.88it/s]Train epoch: 5 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.010389\n",
      "5900it [16:10,  2.76it/s]Train epoch: 5 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.009547\n",
      "5925it [16:19,  2.54it/s]Train epoch: 5 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.010993\n",
      "5950it [16:30,  2.17it/s]Train epoch: 5 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.011871\n",
      "5965it [16:38,  5.97it/s]\n",
      "epoch loss: 0.006085624599794968\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.17it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0103, 0.0194, 0.0150, 0.0169, 0.8337\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2094, 0.5749, 0.2477, 0.3462, 0.9731\n",
      "rec_at_8: 0.2751\n",
      "prec_at_8: 0.5244\n",
      "rec_at_15: 0.3769\n",
      "prec_at_15: 0.3946\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.02it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0101, 0.0214, 0.0145, 0.0173, 0.8321\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2019, 0.5723, 0.2377, 0.3359, 0.9724\n",
      "rec_at_8: 0.2640\n",
      "prec_at_8: 0.5208\n",
      "rec_at_15: 0.3616\n",
      "prec_at_15: 0.3931\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 5\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0103, 0.0194, 0.0150, 0.0169, 0.8337\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2094, 0.5749, 0.2477, 0.3462, 0.9731\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0078\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 5\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0101, 0.0214, 0.0145, 0.0173, 0.8321\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2019, 0.5723, 0.2377, 0.3359, 0.9724\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0081\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 6\n",
      "0it [00:00, ?it/s]Train epoch: 6 [batch #0, batch_size 8, seq length 512]\tLoss: 0.006147\n",
      "25it [00:01, 15.81it/s]Train epoch: 6 [batch #25, batch_size 8, seq length 512]\tLoss: 0.004367\n",
      "49it [00:03, 14.41it/s]Train epoch: 6 [batch #50, batch_size 8, seq length 512]\tLoss: 0.003865\n",
      "75it [00:05, 13.80it/s]Train epoch: 6 [batch #75, batch_size 8, seq length 512]\tLoss: 0.003442\n",
      "99it [00:06, 13.39it/s]Train epoch: 6 [batch #100, batch_size 8, seq length 512]\tLoss: 0.003833\n",
      "125it [00:08, 12.84it/s]Train epoch: 6 [batch #125, batch_size 8, seq length 512]\tLoss: 0.003731\n",
      "149it [00:10, 12.73it/s]Train epoch: 6 [batch #150, batch_size 8, seq length 512]\tLoss: 0.003566\n",
      "175it [00:12, 12.46it/s]Train epoch: 6 [batch #175, batch_size 8, seq length 512]\tLoss: 0.003941\n",
      "199it [00:14, 12.25it/s]Train epoch: 6 [batch #200, batch_size 8, seq length 512]\tLoss: 0.003261\n",
      "225it [00:16, 12.00it/s]Train epoch: 6 [batch #225, batch_size 8, seq length 512]\tLoss: 0.003710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249it [00:19, 11.59it/s]Train epoch: 6 [batch #250, batch_size 8, seq length 512]\tLoss: 0.003586\n",
      "275it [00:21, 11.32it/s]Train epoch: 6 [batch #275, batch_size 8, seq length 512]\tLoss: 0.003757\n",
      "299it [00:23, 11.22it/s]Train epoch: 6 [batch #300, batch_size 8, seq length 512]\tLoss: 0.003909\n",
      "325it [00:25, 11.23it/s]Train epoch: 6 [batch #325, batch_size 8, seq length 512]\tLoss: 0.003754\n",
      "349it [00:27, 10.93it/s]Train epoch: 6 [batch #350, batch_size 8, seq length 512]\tLoss: 0.003681\n",
      "375it [00:30, 11.22it/s]Train epoch: 6 [batch #375, batch_size 8, seq length 512]\tLoss: 0.003705\n",
      "399it [00:32, 10.79it/s]Train epoch: 6 [batch #400, batch_size 8, seq length 512]\tLoss: 0.003525\n",
      "425it [00:34, 10.06it/s]Train epoch: 6 [batch #425, batch_size 8, seq length 512]\tLoss: 0.004131\n",
      "449it [00:37, 10.33it/s]Train epoch: 6 [batch #450, batch_size 8, seq length 512]\tLoss: 0.003688\n",
      "475it [00:39, 10.32it/s]Train epoch: 6 [batch #475, batch_size 8, seq length 512]\tLoss: 0.003494\n",
      "500it [00:42,  9.86it/s]Train epoch: 6 [batch #500, batch_size 8, seq length 512]\tLoss: 0.004059\n",
      "524it [00:44,  9.85it/s]Train epoch: 6 [batch #525, batch_size 8, seq length 512]\tLoss: 0.003751\n",
      "550it [00:47,  9.88it/s]Train epoch: 6 [batch #550, batch_size 8, seq length 512]\tLoss: 0.004100\n",
      "575it [00:49,  9.98it/s]Train epoch: 6 [batch #575, batch_size 8, seq length 512]\tLoss: 0.004221\n",
      "600it [00:52,  9.47it/s]Train epoch: 6 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003971\n",
      "625it [00:55,  9.79it/s]Train epoch: 6 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003992\n",
      "650it [00:57,  9.61it/s]Train epoch: 6 [batch #650, batch_size 8, seq length 512]\tLoss: 0.004064\n",
      "675it [01:00,  9.01it/s]Train epoch: 6 [batch #675, batch_size 8, seq length 512]\tLoss: 0.004797\n",
      "700it [01:02,  9.66it/s]Train epoch: 6 [batch #700, batch_size 8, seq length 512]\tLoss: 0.004076\n",
      "725it [01:05,  9.58it/s]Train epoch: 6 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003967\n",
      "750it [01:08,  9.19it/s]Train epoch: 6 [batch #750, batch_size 8, seq length 512]\tLoss: 0.004736\n",
      "775it [01:10,  9.62it/s]Train epoch: 6 [batch #775, batch_size 8, seq length 512]\tLoss: 0.003727\n",
      "800it [01:13,  9.18it/s]Train epoch: 6 [batch #800, batch_size 8, seq length 512]\tLoss: 0.003581\n",
      "825it [01:16,  9.15it/s]Train epoch: 6 [batch #825, batch_size 8, seq length 512]\tLoss: 0.004036\n",
      "850it [01:18,  9.24it/s]Train epoch: 6 [batch #850, batch_size 8, seq length 512]\tLoss: 0.004103\n",
      "875it [01:21,  9.04it/s]Train epoch: 6 [batch #875, batch_size 8, seq length 512]\tLoss: 0.004309\n",
      "900it [01:24,  9.15it/s]Train epoch: 6 [batch #900, batch_size 8, seq length 512]\tLoss: 0.004140\n",
      "925it [01:27,  8.94it/s]Train epoch: 6 [batch #925, batch_size 8, seq length 512]\tLoss: 0.004381\n",
      "950it [01:29,  9.03it/s]Train epoch: 6 [batch #950, batch_size 8, seq length 512]\tLoss: 0.003384\n",
      "975it [01:32,  8.88it/s]Train epoch: 6 [batch #975, batch_size 8, seq length 512]\tLoss: 0.004350\n",
      "1000it [01:35,  9.14it/s]Train epoch: 6 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003955\n",
      "1025it [01:38,  9.13it/s]Train epoch: 6 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.003890\n",
      "1050it [01:41,  8.80it/s]Train epoch: 6 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.004242\n",
      "1075it [01:44,  8.91it/s]Train epoch: 6 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.004071\n",
      "1100it [01:47,  8.71it/s]Train epoch: 6 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.004302\n",
      "1125it [01:49,  8.62it/s]Train epoch: 6 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.004189\n",
      "1150it [01:52,  8.60it/s]Train epoch: 6 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.003649\n",
      "1175it [01:55,  8.24it/s]Train epoch: 6 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.004170\n",
      "1200it [01:58,  8.04it/s]Train epoch: 6 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.004570\n",
      "1225it [02:01,  8.45it/s]Train epoch: 6 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.004348\n",
      "1250it [02:04,  8.60it/s]Train epoch: 6 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003990\n",
      "1275it [02:07,  8.47it/s]Train epoch: 6 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.005171\n",
      "1300it [02:10,  8.40it/s]Train epoch: 6 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.004252\n",
      "1325it [02:13,  8.08it/s]Train epoch: 6 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.004371\n",
      "1350it [02:16,  8.22it/s]Train epoch: 6 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003937\n",
      "1375it [02:19,  8.28it/s]Train epoch: 6 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.004969\n",
      "1400it [02:22,  8.29it/s]Train epoch: 6 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.004126\n",
      "1425it [02:25,  8.20it/s]Train epoch: 6 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.004418\n",
      "1450it [02:28,  8.26it/s]Train epoch: 6 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.004600\n",
      "1475it [02:32,  8.15it/s]Train epoch: 6 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.004463\n",
      "1500it [02:35,  8.04it/s]Train epoch: 6 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004978\n",
      "1525it [02:38,  8.01it/s]Train epoch: 6 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.004584\n",
      "1550it [02:41,  8.27it/s]Train epoch: 6 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.004521\n",
      "1575it [02:44,  8.26it/s]Train epoch: 6 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.004352\n",
      "1600it [02:47,  8.00it/s]Train epoch: 6 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.004968\n",
      "1625it [02:50,  8.00it/s]Train epoch: 6 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.004784\n",
      "1650it [02:53,  7.93it/s]Train epoch: 6 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.005118\n",
      "1675it [02:56,  7.86it/s]Train epoch: 6 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.004886\n",
      "1700it [03:00,  7.82it/s]Train epoch: 6 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.004687\n",
      "1725it [03:03,  7.86it/s]Train epoch: 6 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.004880\n",
      "1750it [03:06,  7.72it/s]Train epoch: 6 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.004716\n",
      "1775it [03:09,  7.75it/s]Train epoch: 6 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.005035\n",
      "1800it [03:12,  7.72it/s]Train epoch: 6 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.004887\n",
      "1825it [03:16,  7.87it/s]Train epoch: 6 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.004648\n",
      "1850it [03:19,  7.70it/s]Train epoch: 6 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.004489\n",
      "1875it [03:22,  7.56it/s]Train epoch: 6 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.004759\n",
      "1900it [03:25,  7.55it/s]Train epoch: 6 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.005408\n",
      "1925it [03:29,  7.82it/s]Train epoch: 6 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.004780\n",
      "1950it [03:32,  7.40it/s]Train epoch: 6 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.005006\n",
      "1975it [03:35,  7.54it/s]Train epoch: 6 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.005151\n",
      "2000it [03:39,  7.37it/s]Train epoch: 6 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.004516\n",
      "2025it [03:42,  7.37it/s]Train epoch: 6 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.004868\n",
      "2050it [03:46,  7.30it/s]Train epoch: 6 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.005147\n",
      "2075it [03:49,  7.39it/s]Train epoch: 6 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.004834\n",
      "2100it [03:52,  7.48it/s]Train epoch: 6 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.005191\n",
      "2125it [03:56,  7.20it/s]Train epoch: 6 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.004920\n",
      "2150it [03:59,  7.23it/s]Train epoch: 6 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.005341\n",
      "2175it [04:03,  7.24it/s]Train epoch: 6 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.004912\n",
      "2200it [04:06,  7.26it/s]Train epoch: 6 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.004815\n",
      "2225it [04:10,  7.20it/s]Train epoch: 6 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.004897\n",
      "2250it [04:13,  7.25it/s]Train epoch: 6 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.005445\n",
      "2275it [04:17,  7.16it/s]Train epoch: 6 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.004922\n",
      "2300it [04:20,  7.25it/s]Train epoch: 6 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.004667\n",
      "2325it [04:24,  6.93it/s]Train epoch: 6 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.005403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350it [04:27,  7.10it/s]Train epoch: 6 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.004914\n",
      "2375it [04:31,  7.14it/s]Train epoch: 6 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.005353\n",
      "2400it [04:34,  7.02it/s]Train epoch: 6 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.005204\n",
      "2425it [04:38,  6.99it/s]Train epoch: 6 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.005201\n",
      "2450it [04:41,  7.10it/s]Train epoch: 6 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.005278\n",
      "2475it [04:45,  6.85it/s]Train epoch: 6 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.004928\n",
      "2500it [04:48,  6.96it/s]Train epoch: 6 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.005245\n",
      "2525it [04:52,  7.07it/s]Train epoch: 6 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.004794\n",
      "2550it [04:56,  7.05it/s]Train epoch: 6 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.005144\n",
      "2575it [04:59,  6.74it/s]Train epoch: 6 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.005500\n",
      "2600it [05:03,  6.74it/s]Train epoch: 6 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.005000\n",
      "2625it [05:07,  6.77it/s]Train epoch: 6 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.005206\n",
      "2650it [05:11,  6.82it/s]Train epoch: 6 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.004899\n",
      "2675it [05:14,  6.64it/s]Train epoch: 6 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.005367\n",
      "2700it [05:18,  6.68it/s]Train epoch: 6 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.005875\n",
      "2725it [05:22,  6.61it/s]Train epoch: 6 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.005485\n",
      "2750it [05:26,  6.41it/s]Train epoch: 6 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.006240\n",
      "2775it [05:29,  6.57it/s]Train epoch: 6 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.005379\n",
      "2800it [05:33,  6.58it/s]Train epoch: 6 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.005748\n",
      "2825it [05:37,  6.66it/s]Train epoch: 6 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.004883\n",
      "2850it [05:41,  6.72it/s]Train epoch: 6 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.005677\n",
      "2875it [05:45,  6.64it/s]Train epoch: 6 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.006314\n",
      "2900it [05:48,  6.52it/s]Train epoch: 6 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.005488\n",
      "2925it [05:52,  6.57it/s]Train epoch: 6 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.005755\n",
      "2950it [05:56,  6.51it/s]Train epoch: 6 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.006168\n",
      "2975it [06:00,  6.59it/s]Train epoch: 6 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.005322\n",
      "3000it [06:04,  6.39it/s]Train epoch: 6 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.005508\n",
      "3025it [06:08,  6.46it/s]Train epoch: 6 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.005410\n",
      "3050it [06:12,  6.28it/s]Train epoch: 6 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.005319\n",
      "3075it [06:16,  6.31it/s]Train epoch: 6 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.005556\n",
      "3100it [06:19,  6.52it/s]Train epoch: 6 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.005426\n",
      "3125it [06:23,  6.37it/s]Train epoch: 6 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.005279\n",
      "3150it [06:27,  6.42it/s]Train epoch: 6 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.005652\n",
      "3175it [06:31,  6.19it/s]Train epoch: 6 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.006002\n",
      "3200it [06:35,  6.19it/s]Train epoch: 6 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.005323\n",
      "3225it [06:39,  6.24it/s]Train epoch: 6 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.005672\n",
      "3250it [06:43,  6.28it/s]Train epoch: 6 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.005900\n",
      "3275it [06:48,  6.14it/s]Train epoch: 6 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.005910\n",
      "3300it [06:52,  6.09it/s]Train epoch: 6 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.006121\n",
      "3325it [06:56,  6.05it/s]Train epoch: 6 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.006040\n",
      "3350it [07:00,  6.10it/s]Train epoch: 6 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.006098\n",
      "3375it [07:04,  6.12it/s]Train epoch: 6 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.005469\n",
      "3400it [07:08,  5.98it/s]Train epoch: 6 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.005932\n",
      "3425it [07:12,  5.92it/s]Train epoch: 6 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.005885\n",
      "3450it [07:17,  5.94it/s]Train epoch: 6 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.005761\n",
      "3475it [07:21,  6.06it/s]Train epoch: 6 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.006405\n",
      "3500it [07:25,  5.98it/s]Train epoch: 6 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.005792\n",
      "3525it [07:29,  5.94it/s]Train epoch: 6 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.005727\n",
      "3550it [07:33,  5.81it/s]Train epoch: 6 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.006158\n",
      "3575it [07:38,  5.82it/s]Train epoch: 6 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.006277\n",
      "3600it [07:42,  5.91it/s]Train epoch: 6 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.006452\n",
      "3625it [07:46,  5.71it/s]Train epoch: 6 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.005699\n",
      "3650it [07:51,  5.82it/s]Train epoch: 6 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.006364\n",
      "3675it [07:55,  5.81it/s]Train epoch: 6 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.006557\n",
      "3700it [07:59,  5.81it/s]Train epoch: 6 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.005916\n",
      "3725it [08:04,  5.79it/s]Train epoch: 6 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.006330\n",
      "3750it [08:08,  5.68it/s]Train epoch: 6 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.006139\n",
      "3775it [08:12,  5.68it/s]Train epoch: 6 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.006411\n",
      "3800it [08:17,  5.64it/s]Train epoch: 6 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.006786\n",
      "3825it [08:21,  5.69it/s]Train epoch: 6 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.006048\n",
      "3850it [08:25,  5.60it/s]Train epoch: 6 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.006032\n",
      "3875it [08:30,  5.66it/s]Train epoch: 6 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.006336\n",
      "3900it [08:34,  5.62it/s]Train epoch: 6 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.006468\n",
      "3925it [08:39,  5.50it/s]Train epoch: 6 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.005615\n",
      "3950it [08:43,  5.65it/s]Train epoch: 6 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.006046\n",
      "3975it [08:48,  5.61it/s]Train epoch: 6 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.006525\n",
      "4000it [08:52,  5.51it/s]Train epoch: 6 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.006060\n",
      "4025it [08:57,  5.67it/s]Train epoch: 6 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.005940\n",
      "4050it [09:01,  5.51it/s]Train epoch: 6 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.006061\n",
      "4075it [09:06,  5.45it/s]Train epoch: 6 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.006063\n",
      "4100it [09:11,  5.43it/s]Train epoch: 6 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.006244\n",
      "4125it [09:15,  5.35it/s]Train epoch: 6 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.006372\n",
      "4150it [09:20,  5.41it/s]Train epoch: 6 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.006558\n",
      "4175it [09:25,  5.35it/s]Train epoch: 6 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.006173\n",
      "4200it [09:29,  5.20it/s]Train epoch: 6 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.005733\n",
      "4225it [09:34,  5.29it/s]Train epoch: 6 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.006336\n",
      "4250it [09:39,  5.38it/s]Train epoch: 6 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.006929\n",
      "4275it [09:44,  5.22it/s]Train epoch: 6 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.006590\n",
      "4300it [09:48,  5.24it/s]Train epoch: 6 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.006168\n",
      "4325it [09:53,  5.26it/s]Train epoch: 6 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.006681\n",
      "4350it [09:58,  5.13it/s]Train epoch: 6 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.007121\n",
      "4375it [10:03,  5.18it/s]Train epoch: 6 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.006717\n",
      "4400it [10:08,  5.04it/s]Train epoch: 6 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.006480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4425it [10:13,  5.12it/s]Train epoch: 6 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.006677\n",
      "4450it [10:17,  5.14it/s]Train epoch: 6 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.006468\n",
      "4475it [10:22,  4.92it/s]Train epoch: 6 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.007450\n",
      "4500it [10:27,  5.05it/s]Train epoch: 6 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.007046\n",
      "4525it [10:32,  5.00it/s]Train epoch: 6 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.006672\n",
      "4550it [10:37,  4.97it/s]Train epoch: 6 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.006802\n",
      "4575it [10:42,  4.94it/s]Train epoch: 6 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.006395\n",
      "4600it [10:47,  5.05it/s]Train epoch: 6 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.006615\n",
      "4625it [10:53,  4.90it/s]Train epoch: 6 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.007084\n",
      "4650it [10:58,  4.86it/s]Train epoch: 6 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.007331\n",
      "4675it [11:03,  4.83it/s]Train epoch: 6 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.007107\n",
      "4700it [11:08,  4.75it/s]Train epoch: 6 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.006874\n",
      "4725it [11:13,  4.73it/s]Train epoch: 6 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.007008\n",
      "4750it [11:18,  4.84it/s]Train epoch: 6 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.006935\n",
      "4775it [11:24,  4.77it/s]Train epoch: 6 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.007117\n",
      "4800it [11:29,  4.84it/s]Train epoch: 6 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.007434\n",
      "4825it [11:34,  4.70it/s]Train epoch: 6 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.006445\n",
      "4850it [11:39,  4.66it/s]Train epoch: 6 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.006944\n",
      "4875it [11:45,  4.69it/s]Train epoch: 6 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.007269\n",
      "4900it [11:50,  4.70it/s]Train epoch: 6 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.007183\n",
      "4925it [11:56,  4.63it/s]Train epoch: 6 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.007527\n",
      "4950it [12:01,  4.52it/s]Train epoch: 6 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.007625\n",
      "4975it [12:07,  4.48it/s]Train epoch: 6 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.007635\n",
      "5000it [12:12,  4.57it/s]Train epoch: 6 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.007175\n",
      "5025it [12:18,  4.46it/s]Train epoch: 6 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.007953\n",
      "5050it [12:23,  4.46it/s]Train epoch: 6 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.007702\n",
      "5075it [12:29,  4.40it/s]Train epoch: 6 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.007320\n",
      "5100it [12:35,  4.39it/s]Train epoch: 6 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.007285\n",
      "5125it [12:40,  4.39it/s]Train epoch: 6 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.007899\n",
      "5150it [12:46,  4.32it/s]Train epoch: 6 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.007967\n",
      "5175it [12:52,  4.34it/s]Train epoch: 6 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.007824\n",
      "5200it [12:58,  4.26it/s]Train epoch: 6 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.008277\n",
      "5225it [13:03,  4.26it/s]Train epoch: 6 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.007979\n",
      "5250it [13:09,  4.22it/s]Train epoch: 6 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.007687\n",
      "5275it [13:15,  4.16it/s]Train epoch: 6 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.007939\n",
      "5300it [13:21,  4.23it/s]Train epoch: 6 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.007715\n",
      "5325it [13:27,  4.16it/s]Train epoch: 6 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.007544\n",
      "5350it [13:33,  4.13it/s]Train epoch: 6 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.008200\n",
      "5375it [13:40,  4.06it/s]Train epoch: 6 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.008472\n",
      "5400it [13:46,  4.02it/s]Train epoch: 6 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.008105\n",
      "5425it [13:52,  3.97it/s]Train epoch: 6 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.008127\n",
      "5450it [13:58,  3.97it/s]Train epoch: 6 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.008370\n",
      "5475it [14:05,  3.93it/s]Train epoch: 6 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.008263\n",
      "5500it [14:11,  3.86it/s]Train epoch: 6 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.008471\n",
      "5525it [14:18,  3.82it/s]Train epoch: 6 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.008825\n",
      "5550it [14:24,  3.76it/s]Train epoch: 6 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.008986\n",
      "5575it [14:31,  3.77it/s]Train epoch: 6 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.008095\n",
      "5600it [14:38,  3.64it/s]Train epoch: 6 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.008537\n",
      "5625it [14:44,  3.61it/s]Train epoch: 6 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.009038\n",
      "5650it [14:51,  3.62it/s]Train epoch: 6 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.008037\n",
      "5675it [14:58,  3.51it/s]Train epoch: 6 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.009381\n",
      "5700it [15:05,  3.47it/s]Train epoch: 6 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.008795\n",
      "5725it [15:13,  3.41it/s]Train epoch: 6 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.009121\n",
      "5750it [15:20,  3.35it/s]Train epoch: 6 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.009752\n",
      "5775it [15:28,  3.32it/s]Train epoch: 6 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.009037\n",
      "5800it [15:35,  3.24it/s]Train epoch: 6 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.009496\n",
      "5825it [15:43,  3.10it/s]Train epoch: 6 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.009595\n",
      "5850it [15:52,  3.00it/s]Train epoch: 6 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.009493\n",
      "5875it [16:00,  2.87it/s]Train epoch: 6 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.010163\n",
      "5900it [16:09,  2.73it/s]Train epoch: 6 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.009315\n",
      "5925it [16:19,  2.51it/s]Train epoch: 6 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.010624\n",
      "5950it [16:29,  2.14it/s]Train epoch: 6 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.011552\n",
      "5965it [16:37,  5.98it/s]\n",
      "epoch loss: 0.005860767196274494\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 46.95it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0127, 0.0237, 0.0183, 0.0206, 0.8394\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2233, 0.5828, 0.2658, 0.3651, 0.9744\n",
      "rec_at_8: 0.2893\n",
      "prec_at_8: 0.5462\n",
      "rec_at_15: 0.3949\n",
      "prec_at_15: 0.4117\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.01it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0128, 0.0268, 0.0180, 0.0215, 0.8385\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2150, 0.5783, 0.2550, 0.3539, 0.9737\n",
      "rec_at_8: 0.2758\n",
      "prec_at_8: 0.5400\n",
      "rec_at_15: 0.3783\n",
      "prec_at_15: 0.4090\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 6\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0127, 0.0237, 0.0183, 0.0206, 0.8394\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2233, 0.5828, 0.2658, 0.3651, 0.9744\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 6\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0128, 0.0268, 0.0180, 0.0215, 0.8385\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2150, 0.5783, 0.2550, 0.3539, 0.9737\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 7\n",
      "0it [00:00, ?it/s]Train epoch: 7 [batch #0, batch_size 8, seq length 512]\tLoss: 0.006197\n",
      "24it [00:01, 16.10it/s]Train epoch: 7 [batch #25, batch_size 8, seq length 512]\tLoss: 0.004229\n",
      "50it [00:03, 14.07it/s]Train epoch: 7 [batch #50, batch_size 8, seq length 512]\tLoss: 0.003708\n",
      "74it [00:04, 13.64it/s]Train epoch: 7 [batch #75, batch_size 8, seq length 512]\tLoss: 0.003305\n",
      "100it [00:06, 13.47it/s]Train epoch: 7 [batch #100, batch_size 8, seq length 512]\tLoss: 0.003683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124it [00:08, 12.79it/s]Train epoch: 7 [batch #125, batch_size 8, seq length 512]\tLoss: 0.003562\n",
      "150it [00:10, 11.99it/s]Train epoch: 7 [batch #150, batch_size 8, seq length 512]\tLoss: 0.003440\n",
      "174it [00:12, 12.21it/s]Train epoch: 7 [batch #175, batch_size 8, seq length 512]\tLoss: 0.003767\n",
      "200it [00:14, 11.64it/s]Train epoch: 7 [batch #200, batch_size 8, seq length 512]\tLoss: 0.003090\n",
      "224it [00:17, 11.56it/s]Train epoch: 7 [batch #225, batch_size 8, seq length 512]\tLoss: 0.003549\n",
      "250it [00:19, 11.40it/s]Train epoch: 7 [batch #250, batch_size 8, seq length 512]\tLoss: 0.003429\n",
      "274it [00:21, 11.11it/s]Train epoch: 7 [batch #275, batch_size 8, seq length 512]\tLoss: 0.003609\n",
      "300it [00:23, 11.41it/s]Train epoch: 7 [batch #300, batch_size 8, seq length 512]\tLoss: 0.003743\n",
      "324it [00:25, 11.29it/s]Train epoch: 7 [batch #325, batch_size 8, seq length 512]\tLoss: 0.003576\n",
      "350it [00:28, 11.08it/s]Train epoch: 7 [batch #350, batch_size 8, seq length 512]\tLoss: 0.003535\n",
      "374it [00:30, 11.15it/s]Train epoch: 7 [batch #375, batch_size 8, seq length 512]\tLoss: 0.003542\n",
      "400it [00:32, 10.50it/s]Train epoch: 7 [batch #400, batch_size 8, seq length 512]\tLoss: 0.003395\n",
      "424it [00:35,  9.88it/s]Train epoch: 7 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003908\n",
      "450it [00:37, 10.39it/s]Train epoch: 7 [batch #450, batch_size 8, seq length 512]\tLoss: 0.003521\n",
      "474it [00:40, 10.53it/s]Train epoch: 7 [batch #475, batch_size 8, seq length 512]\tLoss: 0.003329\n",
      "500it [00:42, 10.12it/s]Train epoch: 7 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003914\n",
      "525it [00:45,  9.80it/s]Train epoch: 7 [batch #525, batch_size 8, seq length 512]\tLoss: 0.003606\n",
      "550it [00:47,  9.95it/s]Train epoch: 7 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003955\n",
      "575it [00:50,  9.96it/s]Train epoch: 7 [batch #575, batch_size 8, seq length 512]\tLoss: 0.004015\n",
      "599it [00:52,  9.77it/s]Train epoch: 7 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003790\n",
      "625it [00:55,  9.63it/s]Train epoch: 7 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003816\n",
      "650it [00:57,  9.44it/s]Train epoch: 7 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003869\n",
      "675it [01:00,  9.47it/s]Train epoch: 7 [batch #675, batch_size 8, seq length 512]\tLoss: 0.004594\n",
      "700it [01:02,  9.26it/s]Train epoch: 7 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003912\n",
      "725it [01:05,  9.64it/s]Train epoch: 7 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003835\n",
      "750it [01:08,  9.61it/s]Train epoch: 7 [batch #750, batch_size 8, seq length 512]\tLoss: 0.004546\n",
      "775it [01:10,  9.38it/s]Train epoch: 7 [batch #775, batch_size 8, seq length 512]\tLoss: 0.003590\n",
      "800it [01:13,  9.18it/s]Train epoch: 7 [batch #800, batch_size 8, seq length 512]\tLoss: 0.003423\n",
      "825it [01:16,  8.93it/s]Train epoch: 7 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003896\n",
      "850it [01:19,  9.35it/s]Train epoch: 7 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003900\n",
      "875it [01:21,  9.17it/s]Train epoch: 7 [batch #875, batch_size 8, seq length 512]\tLoss: 0.004153\n",
      "900it [01:24,  9.03it/s]Train epoch: 7 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003975\n",
      "925it [01:27,  8.93it/s]Train epoch: 7 [batch #925, batch_size 8, seq length 512]\tLoss: 0.004206\n",
      "950it [01:30,  9.10it/s]Train epoch: 7 [batch #950, batch_size 8, seq length 512]\tLoss: 0.003254\n",
      "975it [01:32,  9.07it/s]Train epoch: 7 [batch #975, batch_size 8, seq length 512]\tLoss: 0.004162\n",
      "1000it [01:35,  8.82it/s]Train epoch: 7 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003812\n",
      "1025it [01:38,  9.09it/s]Train epoch: 7 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.003730\n",
      "1050it [01:41,  8.54it/s]Train epoch: 7 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.004087\n",
      "1075it [01:44,  8.66it/s]Train epoch: 7 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003934\n",
      "1100it [01:47,  8.63it/s]Train epoch: 7 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.004159\n",
      "1125it [01:50,  9.03it/s]Train epoch: 7 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003993\n",
      "1150it [01:52,  8.50it/s]Train epoch: 7 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.003529\n",
      "1175it [01:55,  8.56it/s]Train epoch: 7 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.004005\n",
      "1200it [01:58,  8.34it/s]Train epoch: 7 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.004387\n",
      "1225it [02:01,  8.52it/s]Train epoch: 7 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.004199\n",
      "1250it [02:04,  8.41it/s]Train epoch: 7 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003848\n",
      "1275it [02:07,  7.98it/s]Train epoch: 7 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.005004\n",
      "1300it [02:10,  8.45it/s]Train epoch: 7 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.004092\n",
      "1325it [02:13,  8.33it/s]Train epoch: 7 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.004192\n",
      "1350it [02:16,  8.21it/s]Train epoch: 7 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003777\n",
      "1375it [02:19,  8.25it/s]Train epoch: 7 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.004807\n",
      "1400it [02:22,  8.29it/s]Train epoch: 7 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003996\n",
      "1425it [02:25,  8.40it/s]Train epoch: 7 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.004260\n",
      "1450it [02:28,  8.16it/s]Train epoch: 7 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.004425\n",
      "1475it [02:32,  8.31it/s]Train epoch: 7 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.004304\n",
      "1500it [02:35,  7.99it/s]Train epoch: 7 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004835\n",
      "1525it [02:38,  8.14it/s]Train epoch: 7 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.004453\n",
      "1550it [02:41,  7.93it/s]Train epoch: 7 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.004341\n",
      "1575it [02:44,  8.10it/s]Train epoch: 7 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.004147\n",
      "1600it [02:47,  8.05it/s]Train epoch: 7 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.004789\n",
      "1625it [02:50,  7.54it/s]Train epoch: 7 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.004615\n",
      "1650it [02:54,  7.74it/s]Train epoch: 7 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.004932\n",
      "1675it [02:57,  7.82it/s]Train epoch: 7 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.004675\n",
      "1700it [03:00,  7.89it/s]Train epoch: 7 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.004541\n",
      "1725it [03:03,  7.74it/s]Train epoch: 7 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.004671\n",
      "1750it [03:06,  7.63it/s]Train epoch: 7 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.004560\n",
      "1775it [03:10,  7.66it/s]Train epoch: 7 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.004816\n",
      "1800it [03:13,  7.77it/s]Train epoch: 7 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.004683\n",
      "1825it [03:16,  7.74it/s]Train epoch: 7 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.004483\n",
      "1850it [03:19,  7.74it/s]Train epoch: 7 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.004322\n",
      "1875it [03:23,  7.65it/s]Train epoch: 7 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.004623\n",
      "1900it [03:26,  7.69it/s]Train epoch: 7 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.005224\n",
      "1925it [03:29,  7.63it/s]Train epoch: 7 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.004598\n",
      "1950it [03:33,  7.60it/s]Train epoch: 7 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.004823\n",
      "1975it [03:36,  7.52it/s]Train epoch: 7 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.004942\n",
      "2000it [03:39,  7.54it/s]Train epoch: 7 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.004311\n",
      "2025it [03:43,  7.44it/s]Train epoch: 7 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.004621\n",
      "2050it [03:46,  7.49it/s]Train epoch: 7 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.004983\n",
      "2075it [03:49,  7.26it/s]Train epoch: 7 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.004697\n",
      "2100it [03:53,  7.34it/s]Train epoch: 7 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.005022\n",
      "2125it [03:56,  7.32it/s]Train epoch: 7 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.004775\n",
      "2150it [04:00,  7.40it/s]Train epoch: 7 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.005154\n",
      "2175it [04:03,  7.51it/s]Train epoch: 7 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.004733\n",
      "2200it [04:07,  7.06it/s]Train epoch: 7 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.004644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225it [04:10,  7.23it/s]Train epoch: 7 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.004741\n",
      "2250it [04:13,  7.05it/s]Train epoch: 7 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.005250\n",
      "2275it [04:17,  7.16it/s]Train epoch: 7 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.004751\n",
      "2300it [04:20,  7.13it/s]Train epoch: 7 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.004512\n",
      "2325it [04:24,  7.22it/s]Train epoch: 7 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.005245\n",
      "2350it [04:28,  6.95it/s]Train epoch: 7 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.004754\n",
      "2375it [04:31,  7.20it/s]Train epoch: 7 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.005128\n",
      "2400it [04:35,  6.91it/s]Train epoch: 7 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.005025\n",
      "2425it [04:38,  6.99it/s]Train epoch: 7 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.005005\n",
      "2450it [04:42,  7.04it/s]Train epoch: 7 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.005064\n",
      "2475it [04:45,  6.93it/s]Train epoch: 7 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.004737\n",
      "2500it [04:49,  6.89it/s]Train epoch: 7 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.005126\n",
      "2525it [04:53,  6.92it/s]Train epoch: 7 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.004635\n",
      "2550it [04:56,  6.72it/s]Train epoch: 7 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.004924\n",
      "2575it [05:00,  6.74it/s]Train epoch: 7 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.005297\n",
      "2600it [05:04,  6.71it/s]Train epoch: 7 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.004832\n",
      "2625it [05:07,  6.75it/s]Train epoch: 7 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.005011\n",
      "2650it [05:11,  7.05it/s]Train epoch: 7 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.004760\n",
      "2675it [05:15,  6.64it/s]Train epoch: 7 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.005177\n",
      "2700it [05:18,  6.87it/s]Train epoch: 7 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.005636\n",
      "2725it [05:22,  6.62it/s]Train epoch: 7 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.005284\n",
      "2750it [05:26,  6.49it/s]Train epoch: 7 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.005985\n",
      "2775it [05:30,  6.57it/s]Train epoch: 7 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.005153\n",
      "2800it [05:34,  6.71it/s]Train epoch: 7 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.005541\n",
      "2825it [05:37,  6.61it/s]Train epoch: 7 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.004741\n",
      "2850it [05:41,  6.61it/s]Train epoch: 7 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.005465\n",
      "2875it [05:45,  6.48it/s]Train epoch: 7 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.006121\n",
      "2900it [05:49,  6.44it/s]Train epoch: 7 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.005332\n",
      "2925it [05:53,  6.32it/s]Train epoch: 7 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.005548\n",
      "2950it [05:57,  6.42it/s]Train epoch: 7 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.005962\n",
      "2975it [06:00,  6.38it/s]Train epoch: 7 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.005176\n",
      "3000it [06:04,  6.45it/s]Train epoch: 7 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.005349\n",
      "3025it [06:08,  6.37it/s]Train epoch: 7 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.005247\n",
      "3050it [06:12,  6.46it/s]Train epoch: 7 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.005140\n",
      "3075it [06:16,  6.37it/s]Train epoch: 7 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.005420\n",
      "3100it [06:20,  6.41it/s]Train epoch: 7 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.005279\n",
      "3125it [06:24,  6.22it/s]Train epoch: 7 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.005132\n",
      "3150it [06:28,  6.29it/s]Train epoch: 7 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.005454\n",
      "3175it [06:32,  6.41it/s]Train epoch: 7 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.005840\n",
      "3200it [06:36,  6.36it/s]Train epoch: 7 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.005127\n",
      "3225it [06:40,  6.25it/s]Train epoch: 7 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.005445\n",
      "3250it [06:44,  6.37it/s]Train epoch: 7 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.005737\n",
      "3275it [06:48,  6.15it/s]Train epoch: 7 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.005716\n",
      "3300it [06:52,  5.96it/s]Train epoch: 7 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.005918\n",
      "3325it [06:56,  6.06it/s]Train epoch: 7 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.005846\n",
      "3350it [07:00,  6.08it/s]Train epoch: 7 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.005925\n",
      "3375it [07:05,  6.09it/s]Train epoch: 7 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.005306\n",
      "3400it [07:09,  5.99it/s]Train epoch: 7 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.005753\n",
      "3425it [07:13,  5.89it/s]Train epoch: 7 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.005640\n",
      "3450it [07:17,  6.04it/s]Train epoch: 7 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.005589\n",
      "3475it [07:21,  5.99it/s]Train epoch: 7 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.006167\n",
      "3500it [07:25,  6.13it/s]Train epoch: 7 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.005578\n",
      "3525it [07:30,  5.96it/s]Train epoch: 7 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.005532\n",
      "3550it [07:34,  5.86it/s]Train epoch: 7 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.005966\n",
      "3575it [07:38,  5.81it/s]Train epoch: 7 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.006040\n",
      "3600it [07:42,  5.84it/s]Train epoch: 7 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.006260\n",
      "3625it [07:47,  5.86it/s]Train epoch: 7 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.005515\n",
      "3650it [07:51,  5.81it/s]Train epoch: 7 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.006182\n",
      "3675it [07:55,  5.61it/s]Train epoch: 7 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.006366\n",
      "3700it [08:00,  5.72it/s]Train epoch: 7 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.005730\n",
      "3725it [08:04,  5.68it/s]Train epoch: 7 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.006125\n",
      "3750it [08:08,  5.76it/s]Train epoch: 7 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.005900\n",
      "3775it [08:13,  5.75it/s]Train epoch: 7 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.006181\n",
      "3800it [08:17,  5.62it/s]Train epoch: 7 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.006612\n",
      "3825it [08:22,  5.65it/s]Train epoch: 7 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.005876\n",
      "3850it [08:26,  5.59it/s]Train epoch: 7 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.005853\n",
      "3875it [08:31,  5.67it/s]Train epoch: 7 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.006128\n",
      "3900it [08:35,  5.50it/s]Train epoch: 7 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.006294\n",
      "3925it [08:40,  5.57it/s]Train epoch: 7 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.005490\n",
      "3950it [08:44,  5.54it/s]Train epoch: 7 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.005860\n",
      "3975it [08:49,  5.53it/s]Train epoch: 7 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.006296\n",
      "4000it [08:53,  5.51it/s]Train epoch: 7 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.005826\n",
      "4025it [08:58,  5.45it/s]Train epoch: 7 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.005738\n",
      "4050it [09:02,  5.40it/s]Train epoch: 7 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.005825\n",
      "4075it [09:07,  5.42it/s]Train epoch: 7 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.005828\n",
      "4100it [09:12,  5.47it/s]Train epoch: 7 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.006021\n",
      "4125it [09:16,  5.33it/s]Train epoch: 7 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.006170\n",
      "4150it [09:21,  5.29it/s]Train epoch: 7 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.006395\n",
      "4175it [09:26,  5.30it/s]Train epoch: 7 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.005932\n",
      "4200it [09:30,  5.32it/s]Train epoch: 7 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.005559\n",
      "4225it [09:35,  5.26it/s]Train epoch: 7 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.006142\n",
      "4250it [09:40,  5.30it/s]Train epoch: 7 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.006709\n",
      "4275it [09:45,  5.25it/s]Train epoch: 7 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.006365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300it [09:49,  5.20it/s]Train epoch: 7 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.005949\n",
      "4325it [09:54,  5.25it/s]Train epoch: 7 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.006443\n",
      "4350it [09:59,  5.21it/s]Train epoch: 7 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.006889\n",
      "4375it [10:04,  5.16it/s]Train epoch: 7 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.006451\n",
      "4400it [10:09,  5.07it/s]Train epoch: 7 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.006287\n",
      "4425it [10:14,  5.07it/s]Train epoch: 7 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.006452\n",
      "4450it [10:19,  5.14it/s]Train epoch: 7 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.006260\n",
      "4475it [10:24,  5.07it/s]Train epoch: 7 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.007228\n",
      "4500it [10:29,  4.98it/s]Train epoch: 7 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.006854\n",
      "4525it [10:34,  4.98it/s]Train epoch: 7 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.006475\n",
      "4550it [10:39,  4.97it/s]Train epoch: 7 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.006575\n",
      "4575it [10:44,  4.96it/s]Train epoch: 7 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.006233\n",
      "4600it [10:49,  4.96it/s]Train epoch: 7 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.006437\n",
      "4625it [10:54,  4.99it/s]Train epoch: 7 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.006875\n",
      "4650it [10:59,  4.87it/s]Train epoch: 7 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.007102\n",
      "4675it [11:04,  4.82it/s]Train epoch: 7 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.006892\n",
      "4700it [11:09,  4.88it/s]Train epoch: 7 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.006735\n",
      "4725it [11:14,  4.82it/s]Train epoch: 7 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.006796\n",
      "4750it [11:20,  4.82it/s]Train epoch: 7 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.006755\n",
      "4775it [11:25,  4.85it/s]Train epoch: 7 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.006852\n",
      "4800it [11:30,  4.73it/s]Train epoch: 7 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.007209\n",
      "4825it [11:35,  4.69it/s]Train epoch: 7 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.006301\n",
      "4850it [11:41,  4.66it/s]Train epoch: 7 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.006705\n",
      "4875it [11:46,  4.74it/s]Train epoch: 7 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.007004\n",
      "4900it [11:51,  4.60it/s]Train epoch: 7 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.007047\n",
      "4925it [11:57,  4.60it/s]Train epoch: 7 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.007316\n",
      "4950it [12:02,  4.56it/s]Train epoch: 7 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.007398\n",
      "4975it [12:08,  4.53it/s]Train epoch: 7 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.007395\n",
      "5000it [12:13,  4.52it/s]Train epoch: 7 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.006982\n",
      "5025it [12:19,  4.49it/s]Train epoch: 7 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.007719\n",
      "5050it [12:24,  4.52it/s]Train epoch: 7 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.007509\n",
      "5075it [12:30,  4.41it/s]Train epoch: 7 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.007135\n",
      "5100it [12:36,  4.37it/s]Train epoch: 7 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.007084\n",
      "5125it [12:41,  4.38it/s]Train epoch: 7 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.007647\n",
      "5150it [12:47,  4.32it/s]Train epoch: 7 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.007745\n",
      "5175it [12:53,  4.31it/s]Train epoch: 7 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.007562\n",
      "5200it [12:59,  4.27it/s]Train epoch: 7 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.008079\n",
      "5225it [13:05,  4.24it/s]Train epoch: 7 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.007719\n",
      "5250it [13:11,  4.23it/s]Train epoch: 7 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.007467\n",
      "5275it [13:16,  4.12it/s]Train epoch: 7 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.007743\n",
      "5300it [13:22,  4.16it/s]Train epoch: 7 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.007518\n",
      "5325it [13:29,  4.16it/s]Train epoch: 7 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.007358\n",
      "5350it [13:35,  4.09it/s]Train epoch: 7 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.007951\n",
      "5375it [13:41,  4.06it/s]Train epoch: 7 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.008257\n",
      "5400it [13:47,  4.05it/s]Train epoch: 7 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.007949\n",
      "5425it [13:53,  4.00it/s]Train epoch: 7 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.007936\n",
      "5450it [13:59,  3.96it/s]Train epoch: 7 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.008114\n",
      "5475it [14:06,  3.95it/s]Train epoch: 7 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.008030\n",
      "5500it [14:12,  3.85it/s]Train epoch: 7 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.008242\n",
      "5525it [14:19,  3.80it/s]Train epoch: 7 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.008567\n",
      "5550it [14:25,  3.76it/s]Train epoch: 7 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.008764\n",
      "5575it [14:32,  3.75it/s]Train epoch: 7 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.007827\n",
      "5600it [14:39,  3.70it/s]Train epoch: 7 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.008296\n",
      "5625it [14:45,  3.65it/s]Train epoch: 7 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.008817\n",
      "5650it [14:52,  3.62it/s]Train epoch: 7 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.007791\n",
      "5675it [14:59,  3.55it/s]Train epoch: 7 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.009122\n",
      "5700it [15:06,  3.47it/s]Train epoch: 7 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.008612\n",
      "5725it [15:14,  3.45it/s]Train epoch: 7 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.008901\n",
      "5750it [15:21,  3.36it/s]Train epoch: 7 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.009488\n",
      "5775it [15:29,  3.27it/s]Train epoch: 7 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.008785\n",
      "5800it [15:36,  3.20it/s]Train epoch: 7 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.009294\n",
      "5825it [15:44,  3.14it/s]Train epoch: 7 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.009438\n",
      "5850it [15:53,  3.02it/s]Train epoch: 7 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.009269\n",
      "5875it [16:01,  2.85it/s]Train epoch: 7 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.009901\n",
      "5900it [16:10,  2.78it/s]Train epoch: 7 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.009052\n",
      "5925it [16:19,  2.53it/s]Train epoch: 7 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.010376\n",
      "5950it [16:30,  2.17it/s]Train epoch: 7 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.011240\n",
      "5965it [16:38,  5.97it/s]\n",
      "epoch loss: 0.005668438433170668\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.23it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0140, 0.0267, 0.0194, 0.0225, 0.8424\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2247, 0.5882, 0.2667, 0.3670, 0.9748\n",
      "rec_at_8: 0.2937\n",
      "prec_at_8: 0.5513\n",
      "rec_at_15: 0.4021\n",
      "prec_at_15: 0.4180\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.10it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0139, 0.0307, 0.0190, 0.0235, 0.8420\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2160, 0.5843, 0.2552, 0.3552, 0.9742\n",
      "rec_at_8: 0.2793\n",
      "prec_at_8: 0.5456\n",
      "rec_at_15: 0.3837\n",
      "prec_at_15: 0.4144\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0140, 0.0267, 0.0194, 0.0225, 0.8424\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2247, 0.5882, 0.2667, 0.3670, 0.9748\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0074\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 7\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0139, 0.0307, 0.0190, 0.0235, 0.8420\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2160, 0.5843, 0.2552, 0.3552, 0.9742\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0077\n",
      "\n",
      "---------------------------------------------------\n",
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Train epoch: 8 [batch #0, batch_size 8, seq length 512]\tLoss: 0.005787\n",
      "24it [00:01, 15.79it/s]Train epoch: 8 [batch #25, batch_size 8, seq length 512]\tLoss: 0.004045\n",
      "50it [00:03, 13.81it/s]Train epoch: 8 [batch #50, batch_size 8, seq length 512]\tLoss: 0.003577\n",
      "74it [00:05, 13.29it/s]Train epoch: 8 [batch #75, batch_size 8, seq length 512]\tLoss: 0.003166\n",
      "100it [00:07, 12.98it/s]Train epoch: 8 [batch #100, batch_size 8, seq length 512]\tLoss: 0.003537\n",
      "124it [00:08, 12.90it/s]Train epoch: 8 [batch #125, batch_size 8, seq length 512]\tLoss: 0.003408\n",
      "150it [00:10, 12.64it/s]Train epoch: 8 [batch #150, batch_size 8, seq length 512]\tLoss: 0.003292\n",
      "174it [00:12, 11.96it/s]Train epoch: 8 [batch #175, batch_size 8, seq length 512]\tLoss: 0.003605\n",
      "200it [00:15, 12.14it/s]Train epoch: 8 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002962\n",
      "224it [00:17, 12.05it/s]Train epoch: 8 [batch #225, batch_size 8, seq length 512]\tLoss: 0.003426\n",
      "250it [00:19, 11.61it/s]Train epoch: 8 [batch #250, batch_size 8, seq length 512]\tLoss: 0.003247\n",
      "274it [00:21, 11.36it/s]Train epoch: 8 [batch #275, batch_size 8, seq length 512]\tLoss: 0.003455\n",
      "300it [00:23, 11.25it/s]Train epoch: 8 [batch #300, batch_size 8, seq length 512]\tLoss: 0.003618\n",
      "324it [00:26, 10.60it/s]Train epoch: 8 [batch #325, batch_size 8, seq length 512]\tLoss: 0.003429\n",
      "350it [00:28, 10.59it/s]Train epoch: 8 [batch #350, batch_size 8, seq length 512]\tLoss: 0.003415\n",
      "374it [00:30, 11.16it/s]Train epoch: 8 [batch #375, batch_size 8, seq length 512]\tLoss: 0.003407\n",
      "400it [00:33, 10.58it/s]Train epoch: 8 [batch #400, batch_size 8, seq length 512]\tLoss: 0.003277\n",
      "424it [00:35, 10.50it/s]Train epoch: 8 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003781\n",
      "450it [00:37, 10.30it/s]Train epoch: 8 [batch #450, batch_size 8, seq length 512]\tLoss: 0.003406\n",
      "474it [00:40, 10.54it/s]Train epoch: 8 [batch #475, batch_size 8, seq length 512]\tLoss: 0.003210\n",
      "499it [00:42,  9.59it/s]Train epoch: 8 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003785\n",
      "525it [00:45,  9.90it/s]Train epoch: 8 [batch #525, batch_size 8, seq length 512]\tLoss: 0.003473\n",
      "550it [00:47,  9.78it/s]Train epoch: 8 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003816\n",
      "575it [00:50,  9.87it/s]Train epoch: 8 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003838\n",
      "600it [00:52,  9.97it/s]Train epoch: 8 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003658\n",
      "625it [00:55,  9.73it/s]Train epoch: 8 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003656\n",
      "650it [00:57,  9.56it/s]Train epoch: 8 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003779\n",
      "675it [01:00,  9.71it/s]Train epoch: 8 [batch #675, batch_size 8, seq length 512]\tLoss: 0.004441\n",
      "700it [01:03,  8.96it/s]Train epoch: 8 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003795\n",
      "725it [01:05,  9.54it/s]Train epoch: 8 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003732\n",
      "750it [01:08,  9.43it/s]Train epoch: 8 [batch #750, batch_size 8, seq length 512]\tLoss: 0.004448\n",
      "775it [01:11,  9.41it/s]Train epoch: 8 [batch #775, batch_size 8, seq length 512]\tLoss: 0.003464\n",
      "800it [01:13,  9.20it/s]Train epoch: 8 [batch #800, batch_size 8, seq length 512]\tLoss: 0.003314\n",
      "825it [01:16,  8.94it/s]Train epoch: 8 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003810\n",
      "850it [01:19,  8.99it/s]Train epoch: 8 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003776\n",
      "875it [01:22,  9.06it/s]Train epoch: 8 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003966\n",
      "900it [01:24,  9.17it/s]Train epoch: 8 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003833\n",
      "925it [01:27,  8.48it/s]Train epoch: 8 [batch #925, batch_size 8, seq length 512]\tLoss: 0.004039\n",
      "950it [01:30,  9.05it/s]Train epoch: 8 [batch #950, batch_size 8, seq length 512]\tLoss: 0.003095\n",
      "975it [01:33,  8.95it/s]Train epoch: 8 [batch #975, batch_size 8, seq length 512]\tLoss: 0.004052\n",
      "1000it [01:36,  8.93it/s]Train epoch: 8 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003723\n",
      "1025it [01:38,  9.06it/s]Train epoch: 8 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.003655\n",
      "1050it [01:41,  8.83it/s]Train epoch: 8 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003915\n",
      "1075it [01:44,  8.91it/s]Train epoch: 8 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003812\n",
      "1100it [01:47,  8.65it/s]Train epoch: 8 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.004003\n",
      "1125it [01:50,  8.88it/s]Train epoch: 8 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003821\n",
      "1150it [01:53,  8.67it/s]Train epoch: 8 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.003360\n",
      "1175it [01:56,  8.48it/s]Train epoch: 8 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003901\n",
      "1200it [01:59,  8.35it/s]Train epoch: 8 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.004245\n",
      "1225it [02:01,  8.41it/s]Train epoch: 8 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003984\n",
      "1250it [02:04,  8.70it/s]Train epoch: 8 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003680\n",
      "1275it [02:07,  8.34it/s]Train epoch: 8 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.004849\n",
      "1300it [02:10,  8.40it/s]Train epoch: 8 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003943\n",
      "1325it [02:13,  8.22it/s]Train epoch: 8 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.004098\n",
      "1350it [02:16,  8.29it/s]Train epoch: 8 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003614\n",
      "1375it [02:19,  8.43it/s]Train epoch: 8 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.004611\n",
      "1400it [02:22,  8.42it/s]Train epoch: 8 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003882\n",
      "1425it [02:25,  8.14it/s]Train epoch: 8 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.004093\n",
      "1450it [02:28,  7.92it/s]Train epoch: 8 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.004251\n",
      "1475it [02:32,  8.10it/s]Train epoch: 8 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.004166\n",
      "1500it [02:35,  7.80it/s]Train epoch: 8 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004652\n",
      "1525it [02:38,  8.00it/s]Train epoch: 8 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.004257\n",
      "1550it [02:41,  7.60it/s]Train epoch: 8 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.004254\n",
      "1575it [02:44,  7.81it/s]Train epoch: 8 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.004033\n",
      "1600it [02:47,  7.70it/s]Train epoch: 8 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.004688\n",
      "1625it [02:50,  8.07it/s]Train epoch: 8 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.004468\n",
      "1650it [02:54,  7.88it/s]Train epoch: 8 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.004828\n",
      "1675it [02:57,  7.67it/s]Train epoch: 8 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.004501\n",
      "1700it [03:00,  7.70it/s]Train epoch: 8 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.004392\n",
      "1725it [03:03,  7.78it/s]Train epoch: 8 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.004529\n",
      "1750it [03:06,  8.00it/s]Train epoch: 8 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.004413\n",
      "1775it [03:10,  7.49it/s]Train epoch: 8 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.004655\n",
      "1800it [03:13,  7.77it/s]Train epoch: 8 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.004558\n",
      "1825it [03:16,  7.71it/s]Train epoch: 8 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.004350\n",
      "1850it [03:19,  7.57it/s]Train epoch: 8 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.004189\n",
      "1875it [03:23,  7.55it/s]Train epoch: 8 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.004466\n",
      "1900it [03:26,  7.66it/s]Train epoch: 8 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.005070\n",
      "1925it [03:29,  7.80it/s]Train epoch: 8 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.004419\n",
      "1950it [03:33,  7.50it/s]Train epoch: 8 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.004668\n",
      "1975it [03:36,  7.54it/s]Train epoch: 8 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.004773\n",
      "2000it [03:39,  7.38it/s]Train epoch: 8 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.004176\n",
      "2025it [03:43,  7.52it/s]Train epoch: 8 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.004499\n",
      "2050it [03:46,  7.47it/s]Train epoch: 8 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.004828\n",
      "2075it [03:49,  7.33it/s]Train epoch: 8 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.004572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100it [03:53,  7.46it/s]Train epoch: 8 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.004854\n",
      "2125it [03:56,  7.37it/s]Train epoch: 8 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.004600\n",
      "2150it [04:00,  7.16it/s]Train epoch: 8 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004967\n",
      "2175it [04:03,  7.23it/s]Train epoch: 8 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.004604\n",
      "2200it [04:07,  7.28it/s]Train epoch: 8 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.004482\n",
      "2225it [04:10,  7.13it/s]Train epoch: 8 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.004565\n",
      "2250it [04:14,  7.16it/s]Train epoch: 8 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.005054\n",
      "2275it [04:17,  7.18it/s]Train epoch: 8 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.004626\n",
      "2300it [04:21,  7.22it/s]Train epoch: 8 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.004390\n",
      "2325it [04:24,  7.09it/s]Train epoch: 8 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.005067\n",
      "2350it [04:28,  6.90it/s]Train epoch: 8 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.004589\n",
      "2375it [04:31,  6.79it/s]Train epoch: 8 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.005015\n",
      "2400it [04:35,  7.03it/s]Train epoch: 8 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.004862\n",
      "2425it [04:38,  6.94it/s]Train epoch: 8 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.004842\n",
      "2450it [04:42,  7.03it/s]Train epoch: 8 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.004903\n",
      "2475it [04:46,  6.94it/s]Train epoch: 8 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.004586\n",
      "2500it [04:49,  6.93it/s]Train epoch: 8 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.004884\n",
      "2525it [04:53,  6.89it/s]Train epoch: 8 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.004487\n",
      "2550it [04:56,  6.85it/s]Train epoch: 8 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.004763\n",
      "2575it [05:00,  6.71it/s]Train epoch: 8 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.005124\n",
      "2600it [05:04,  6.73it/s]Train epoch: 8 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.004677\n",
      "2625it [05:08,  6.77it/s]Train epoch: 8 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.004855\n",
      "2650it [05:11,  6.79it/s]Train epoch: 8 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.004606\n",
      "2675it [05:15,  6.61it/s]Train epoch: 8 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004978\n",
      "2700it [05:19,  6.73it/s]Train epoch: 8 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.005522\n",
      "2725it [05:22,  6.46it/s]Train epoch: 8 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.005141\n",
      "2750it [05:26,  6.77it/s]Train epoch: 8 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.005831\n",
      "2775it [05:30,  6.65it/s]Train epoch: 8 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.005012\n",
      "2800it [05:34,  6.61it/s]Train epoch: 8 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.005387\n",
      "2825it [05:37,  6.58it/s]Train epoch: 8 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.004602\n",
      "2850it [05:41,  6.49it/s]Train epoch: 8 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.005348\n",
      "2875it [05:45,  6.52it/s]Train epoch: 8 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.005927\n",
      "2900it [05:49,  6.43it/s]Train epoch: 8 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.005167\n",
      "2925it [05:53,  6.50it/s]Train epoch: 8 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.005410\n",
      "2950it [05:57,  6.56it/s]Train epoch: 8 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.005763\n",
      "2975it [06:01,  6.38it/s]Train epoch: 8 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.005023\n",
      "3000it [06:04,  6.41it/s]Train epoch: 8 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.005201\n",
      "3025it [06:08,  6.16it/s]Train epoch: 8 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.005147\n",
      "3050it [06:12,  6.41it/s]Train epoch: 8 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.005023\n",
      "3075it [06:16,  6.31it/s]Train epoch: 8 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.005260\n",
      "3100it [06:20,  6.38it/s]Train epoch: 8 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.005128\n",
      "3125it [06:24,  6.29it/s]Train epoch: 8 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.004957\n",
      "3150it [06:28,  6.28it/s]Train epoch: 8 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.005314\n",
      "3175it [06:32,  6.25it/s]Train epoch: 8 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.005672\n",
      "3200it [06:36,  6.24it/s]Train epoch: 8 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004972\n",
      "3225it [06:40,  6.29it/s]Train epoch: 8 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.005291\n",
      "3250it [06:44,  6.08it/s]Train epoch: 8 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.005568\n",
      "3275it [06:48,  6.06it/s]Train epoch: 8 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.005553\n",
      "3300it [06:52,  6.23it/s]Train epoch: 8 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.005733\n",
      "3325it [06:56,  6.14it/s]Train epoch: 8 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.005707\n",
      "3350it [07:01,  5.99it/s]Train epoch: 8 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.005687\n",
      "3375it [07:05,  6.09it/s]Train epoch: 8 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.005114\n",
      "3400it [07:09,  5.91it/s]Train epoch: 8 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.005572\n",
      "3425it [07:13,  6.02it/s]Train epoch: 8 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.005473\n",
      "3450it [07:17,  6.00it/s]Train epoch: 8 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.005421\n",
      "3475it [07:21,  5.91it/s]Train epoch: 8 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.006021\n",
      "3500it [07:26,  5.90it/s]Train epoch: 8 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.005375\n",
      "3525it [07:30,  5.82it/s]Train epoch: 8 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.005420\n",
      "3550it [07:34,  5.86it/s]Train epoch: 8 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.005788\n",
      "3575it [07:38,  5.78it/s]Train epoch: 8 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.005850\n",
      "3600it [07:43,  5.93it/s]Train epoch: 8 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.006093\n",
      "3625it [07:47,  5.76it/s]Train epoch: 8 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.005371\n",
      "3650it [07:51,  5.78it/s]Train epoch: 8 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.005995\n",
      "3675it [07:56,  5.74it/s]Train epoch: 8 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.006161\n",
      "3700it [08:00,  5.70it/s]Train epoch: 8 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.005516\n",
      "3725it [08:04,  5.77it/s]Train epoch: 8 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.005991\n",
      "3750it [08:09,  5.68it/s]Train epoch: 8 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.005693\n",
      "3775it [08:13,  5.72it/s]Train epoch: 8 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.006028\n",
      "3800it [08:17,  5.58it/s]Train epoch: 8 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.006398\n",
      "3825it [08:22,  5.75it/s]Train epoch: 8 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.005753\n",
      "3850it [08:26,  5.57it/s]Train epoch: 8 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.005693\n",
      "3875it [08:31,  5.59it/s]Train epoch: 8 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.005963\n",
      "3900it [08:35,  5.57it/s]Train epoch: 8 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.006087\n",
      "3925it [08:40,  5.60it/s]Train epoch: 8 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.005295\n",
      "3950it [08:44,  5.55it/s]Train epoch: 8 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.005663\n",
      "3975it [08:49,  5.52it/s]Train epoch: 8 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.006116\n",
      "4000it [08:53,  5.48it/s]Train epoch: 8 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.005714\n",
      "4025it [08:58,  5.49it/s]Train epoch: 8 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.005585\n",
      "4050it [09:02,  5.48it/s]Train epoch: 8 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.005657\n",
      "4075it [09:07,  5.42it/s]Train epoch: 8 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.005628\n",
      "4100it [09:12,  5.40it/s]Train epoch: 8 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.005873\n",
      "4125it [09:16,  5.44it/s]Train epoch: 8 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.005976\n",
      "4150it [09:21,  5.32it/s]Train epoch: 8 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.006173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4175it [09:26,  5.22it/s]Train epoch: 8 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.005784\n",
      "4200it [09:30,  5.40it/s]Train epoch: 8 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.005394\n",
      "4225it [09:35,  5.25it/s]Train epoch: 8 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.005952\n",
      "4250it [09:40,  5.31it/s]Train epoch: 8 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.006481\n",
      "4275it [09:45,  5.23it/s]Train epoch: 8 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.006161\n",
      "4300it [09:49,  5.38it/s]Train epoch: 8 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.005804\n",
      "4325it [09:54,  5.20it/s]Train epoch: 8 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.006263\n",
      "4350it [09:59,  5.21it/s]Train epoch: 8 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.006712\n",
      "4375it [10:04,  5.08it/s]Train epoch: 8 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.006282\n",
      "4400it [10:09,  5.10it/s]Train epoch: 8 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.006113\n",
      "4425it [10:14,  5.07it/s]Train epoch: 8 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.006259\n",
      "4450it [10:19,  5.05it/s]Train epoch: 8 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.006051\n",
      "4475it [10:24,  4.99it/s]Train epoch: 8 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.007039\n",
      "4500it [10:29,  4.96it/s]Train epoch: 8 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.006711\n",
      "4525it [10:34,  5.06it/s]Train epoch: 8 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.006300\n",
      "4550it [10:39,  5.03it/s]Train epoch: 8 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.006413\n",
      "4575it [10:44,  4.93it/s]Train epoch: 8 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.006069\n",
      "4600it [10:49,  4.98it/s]Train epoch: 8 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.006309\n",
      "4625it [10:54,  4.92it/s]Train epoch: 8 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.006741\n",
      "4650it [10:59,  4.85it/s]Train epoch: 8 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.006895\n",
      "4675it [11:04,  4.88it/s]Train epoch: 8 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.006673\n",
      "4700it [11:09,  4.69it/s]Train epoch: 8 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.006533\n",
      "4725it [11:14,  4.78it/s]Train epoch: 8 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.006614\n",
      "4750it [11:20,  4.79it/s]Train epoch: 8 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.006501\n",
      "4775it [11:25,  4.76it/s]Train epoch: 8 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.006646\n",
      "4800it [11:30,  4.78it/s]Train epoch: 8 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.006988\n",
      "4825it [11:35,  4.71it/s]Train epoch: 8 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.006124\n",
      "4850it [11:41,  4.68it/s]Train epoch: 8 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.006558\n",
      "4875it [11:46,  4.67it/s]Train epoch: 8 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.006846\n",
      "4900it [11:51,  4.66it/s]Train epoch: 8 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.006752\n",
      "4925it [11:57,  4.62it/s]Train epoch: 8 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.007172\n",
      "4950it [12:02,  4.39it/s]Train epoch: 8 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.007129\n",
      "4975it [12:08,  4.54it/s]Train epoch: 8 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.007259\n",
      "5000it [12:13,  4.53it/s]Train epoch: 8 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.006840\n",
      "5025it [12:19,  4.51it/s]Train epoch: 8 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.007511\n",
      "5050it [12:25,  4.51it/s]Train epoch: 8 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.007325\n",
      "5075it [12:30,  4.36it/s]Train epoch: 8 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.006958\n",
      "5100it [12:36,  4.36it/s]Train epoch: 8 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.006895\n",
      "5125it [12:42,  4.34it/s]Train epoch: 8 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.007480\n",
      "5150it [12:47,  4.38it/s]Train epoch: 8 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.007534\n",
      "5175it [12:53,  4.35it/s]Train epoch: 8 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.007334\n",
      "5200it [12:59,  4.32it/s]Train epoch: 8 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.007808\n",
      "5225it [13:05,  4.27it/s]Train epoch: 8 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.007545\n",
      "5250it [13:11,  4.24it/s]Train epoch: 8 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.007248\n",
      "5275it [13:17,  4.22it/s]Train epoch: 8 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.007492\n",
      "5300it [13:23,  4.15it/s]Train epoch: 8 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.007322\n",
      "5325it [13:29,  4.12it/s]Train epoch: 8 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.007177\n",
      "5350it [13:35,  4.07it/s]Train epoch: 8 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.007757\n",
      "5375it [13:41,  4.02it/s]Train epoch: 8 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.008082\n",
      "5400it [13:47,  4.04it/s]Train epoch: 8 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.007725\n",
      "5425it [13:53,  4.03it/s]Train epoch: 8 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.007716\n",
      "5450it [14:00,  3.98it/s]Train epoch: 8 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.007945\n",
      "5475it [14:06,  3.87it/s]Train epoch: 8 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.007883\n",
      "5500it [14:12,  3.82it/s]Train epoch: 8 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.008005\n",
      "5525it [14:19,  3.80it/s]Train epoch: 8 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.008344\n",
      "5550it [14:25,  3.81it/s]Train epoch: 8 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.008565\n",
      "5575it [14:32,  3.77it/s]Train epoch: 8 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.007650\n",
      "5600it [14:39,  3.75it/s]Train epoch: 8 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.008063\n",
      "5625it [14:46,  3.65it/s]Train epoch: 8 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.008619\n",
      "5650it [14:53,  3.58it/s]Train epoch: 8 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.007592\n",
      "5675it [15:00,  3.55it/s]Train epoch: 8 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.008902\n",
      "5700it [15:07,  3.48it/s]Train epoch: 8 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.008369\n",
      "5725it [15:14,  3.45it/s]Train epoch: 8 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.008709\n",
      "5750it [15:21,  3.34it/s]Train epoch: 8 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.009204\n",
      "5775it [15:29,  3.29it/s]Train epoch: 8 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.008587\n",
      "5800it [15:37,  3.22it/s]Train epoch: 8 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.009048\n",
      "5825it [15:44,  3.11it/s]Train epoch: 8 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.009234\n",
      "5850it [15:53,  3.00it/s]Train epoch: 8 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.009027\n",
      "5875it [16:01,  2.90it/s]Train epoch: 8 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.009717\n",
      "5900it [16:10,  2.76it/s]Train epoch: 8 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.008896\n",
      "5925it [16:20,  2.56it/s]Train epoch: 8 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.010130\n",
      "5950it [16:30,  2.17it/s]Train epoch: 8 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.010976\n",
      "5965it [16:38,  5.97it/s]\n",
      "epoch loss: 0.005501152190757636\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.37it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0168, 0.0304, 0.0236, 0.0265, 0.8441\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2389, 0.5716, 0.2910, 0.3857, 0.9750\n",
      "rec_at_8: 0.2968\n",
      "prec_at_8: 0.5594\n",
      "rec_at_15: 0.4078\n",
      "prec_at_15: 0.4230\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.26it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0161, 0.0341, 0.0224, 0.0270, 0.8447\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2279, 0.5644, 0.2766, 0.3712, 0.9745\n",
      "rec_at_8: 0.2829\n",
      "prec_at_8: 0.5517\n",
      "rec_at_15: 0.3896\n",
      "prec_at_15: 0.4204\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 8\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0168, 0.0304, 0.0236, 0.0265, 0.8441\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2389, 0.5716, 0.2910, 0.3857, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0074\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 8\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0161, 0.0341, 0.0224, 0.0270, 0.8447\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2279, 0.5644, 0.2766, 0.3712, 0.9745\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0077\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 9\n",
      "0it [00:00, ?it/s]Train epoch: 9 [batch #0, batch_size 8, seq length 512]\tLoss: 0.005471\n",
      "24it [00:01, 15.35it/s]Train epoch: 9 [batch #25, batch_size 8, seq length 512]\tLoss: 0.003896\n",
      "50it [00:03, 14.74it/s]Train epoch: 9 [batch #50, batch_size 8, seq length 512]\tLoss: 0.003472\n",
      "74it [00:05, 13.51it/s]Train epoch: 9 [batch #75, batch_size 8, seq length 512]\tLoss: 0.003071\n",
      "100it [00:06, 13.20it/s]Train epoch: 9 [batch #100, batch_size 8, seq length 512]\tLoss: 0.003446\n",
      "124it [00:08, 12.70it/s]Train epoch: 9 [batch #125, batch_size 8, seq length 512]\tLoss: 0.003239\n",
      "150it [00:10, 12.32it/s]Train epoch: 9 [batch #150, batch_size 8, seq length 512]\tLoss: 0.003215\n",
      "174it [00:12, 12.27it/s]Train epoch: 9 [batch #175, batch_size 8, seq length 512]\tLoss: 0.003489\n",
      "200it [00:15, 12.15it/s]Train epoch: 9 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002848\n",
      "224it [00:17, 11.49it/s]Train epoch: 9 [batch #225, batch_size 8, seq length 512]\tLoss: 0.003290\n",
      "250it [00:19, 11.63it/s]Train epoch: 9 [batch #250, batch_size 8, seq length 512]\tLoss: 0.003126\n",
      "274it [00:21, 11.48it/s]Train epoch: 9 [batch #275, batch_size 8, seq length 512]\tLoss: 0.003287\n",
      "300it [00:23, 11.22it/s]Train epoch: 9 [batch #300, batch_size 8, seq length 512]\tLoss: 0.003478\n",
      "324it [00:25, 11.19it/s]Train epoch: 9 [batch #325, batch_size 8, seq length 512]\tLoss: 0.003352\n",
      "350it [00:28, 11.10it/s]Train epoch: 9 [batch #350, batch_size 8, seq length 512]\tLoss: 0.003306\n",
      "374it [00:30, 10.34it/s]Train epoch: 9 [batch #375, batch_size 8, seq length 512]\tLoss: 0.003309\n",
      "400it [00:32, 10.79it/s]Train epoch: 9 [batch #400, batch_size 8, seq length 512]\tLoss: 0.003173\n",
      "424it [00:35, 10.73it/s]Train epoch: 9 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003602\n",
      "450it [00:37, 10.42it/s]Train epoch: 9 [batch #450, batch_size 8, seq length 512]\tLoss: 0.003257\n",
      "474it [00:40, 10.05it/s]Train epoch: 9 [batch #475, batch_size 8, seq length 512]\tLoss: 0.003123\n",
      "500it [00:42, 10.15it/s]Train epoch: 9 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003686\n",
      "525it [00:45, 10.27it/s]Train epoch: 9 [batch #525, batch_size 8, seq length 512]\tLoss: 0.003350\n",
      "550it [00:47, 10.21it/s]Train epoch: 9 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003712\n",
      "575it [00:50,  9.70it/s]Train epoch: 9 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003752\n",
      "600it [00:52,  9.50it/s]Train epoch: 9 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003542\n",
      "625it [00:55,  9.74it/s]Train epoch: 9 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003504\n",
      "650it [00:57,  9.73it/s]Train epoch: 9 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003660\n",
      "675it [01:00,  9.16it/s]Train epoch: 9 [batch #675, batch_size 8, seq length 512]\tLoss: 0.004300\n",
      "700it [01:02,  9.36it/s]Train epoch: 9 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003681\n",
      "725it [01:05,  9.43it/s]Train epoch: 9 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003637\n",
      "750it [01:08,  9.58it/s]Train epoch: 9 [batch #750, batch_size 8, seq length 512]\tLoss: 0.004294\n",
      "775it [01:10,  9.00it/s]Train epoch: 9 [batch #775, batch_size 8, seq length 512]\tLoss: 0.003353\n",
      "800it [01:13,  9.50it/s]Train epoch: 9 [batch #800, batch_size 8, seq length 512]\tLoss: 0.003185\n",
      "825it [01:16,  9.36it/s]Train epoch: 9 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003690\n",
      "850it [01:19,  9.13it/s]Train epoch: 9 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003663\n",
      "875it [01:21,  9.17it/s]Train epoch: 9 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003854\n",
      "900it [01:24,  9.21it/s]Train epoch: 9 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003724\n",
      "925it [01:27,  8.60it/s]Train epoch: 9 [batch #925, batch_size 8, seq length 512]\tLoss: 0.003867\n",
      "950it [01:30,  8.98it/s]Train epoch: 9 [batch #950, batch_size 8, seq length 512]\tLoss: 0.003003\n",
      "975it [01:32,  8.83it/s]Train epoch: 9 [batch #975, batch_size 8, seq length 512]\tLoss: 0.003899\n",
      "1000it [01:35,  9.01it/s]Train epoch: 9 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003595\n",
      "1025it [01:38,  8.98it/s]Train epoch: 9 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.003529\n",
      "1050it [01:41,  8.76it/s]Train epoch: 9 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003798\n",
      "1075it [01:44,  8.29it/s]Train epoch: 9 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003699\n",
      "1100it [01:46,  8.70it/s]Train epoch: 9 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.003857\n",
      "1125it [01:49,  8.59it/s]Train epoch: 9 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003694\n",
      "1150it [01:52,  8.46it/s]Train epoch: 9 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.003298\n",
      "1175it [01:55,  8.50it/s]Train epoch: 9 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003793\n",
      "1200it [01:58,  8.49it/s]Train epoch: 9 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.004080\n",
      "1225it [02:01,  8.25it/s]Train epoch: 9 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003883\n",
      "1250it [02:04,  8.43it/s]Train epoch: 9 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003586\n",
      "1275it [02:07,  8.42it/s]Train epoch: 9 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.004694\n",
      "1300it [02:10,  8.47it/s]Train epoch: 9 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003844\n",
      "1325it [02:13,  8.18it/s]Train epoch: 9 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.003992\n",
      "1350it [02:16,  8.22it/s]Train epoch: 9 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003530\n",
      "1375it [02:19,  8.35it/s]Train epoch: 9 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.004440\n",
      "1400it [02:22,  8.23it/s]Train epoch: 9 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003762\n",
      "1425it [02:25,  8.16it/s]Train epoch: 9 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.003987\n",
      "1450it [02:28,  8.12it/s]Train epoch: 9 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.004125\n",
      "1475it [02:31,  8.26it/s]Train epoch: 9 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.004061\n",
      "1500it [02:34,  7.77it/s]Train epoch: 9 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004554\n",
      "1525it [02:38,  8.12it/s]Train epoch: 9 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.004135\n",
      "1550it [02:41,  8.01it/s]Train epoch: 9 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.004091\n",
      "1575it [02:44,  8.05it/s]Train epoch: 9 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.003896\n",
      "1600it [02:47,  8.09it/s]Train epoch: 9 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.004531\n",
      "1625it [02:50,  7.83it/s]Train epoch: 9 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.004301\n",
      "1650it [02:53,  7.82it/s]Train epoch: 9 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.004675\n",
      "1675it [02:56,  7.76it/s]Train epoch: 9 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.004385\n",
      "1700it [03:00,  7.84it/s]Train epoch: 9 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.004229\n",
      "1725it [03:03,  7.97it/s]Train epoch: 9 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.004370\n",
      "1750it [03:06,  7.79it/s]Train epoch: 9 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.004285\n",
      "1775it [03:09,  7.73it/s]Train epoch: 9 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.004547\n",
      "1800it [03:13,  7.29it/s]Train epoch: 9 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.004438\n",
      "1825it [03:16,  7.63it/s]Train epoch: 9 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.004223\n",
      "1850it [03:19,  7.86it/s]Train epoch: 9 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.004047\n",
      "1875it [03:23,  7.60it/s]Train epoch: 9 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.004356\n",
      "1900it [03:26,  7.49it/s]Train epoch: 9 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.004938\n",
      "1925it [03:29,  7.32it/s]Train epoch: 9 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.004230\n",
      "1950it [03:33,  7.31it/s]Train epoch: 9 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.004522\n",
      "1975it [03:36,  7.41it/s]Train epoch: 9 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.004628\n",
      "2000it [03:40,  7.18it/s]Train epoch: 9 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.004064\n",
      "2025it [03:43,  7.47it/s]Train epoch: 9 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.004312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050it [03:46,  7.16it/s]Train epoch: 9 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.004658\n",
      "2075it [03:50,  7.28it/s]Train epoch: 9 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.004401\n",
      "2100it [03:53,  7.57it/s]Train epoch: 9 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.004763\n",
      "2125it [03:57,  7.31it/s]Train epoch: 9 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.004458\n",
      "2150it [04:00,  7.13it/s]Train epoch: 9 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004815\n",
      "2175it [04:04,  7.25it/s]Train epoch: 9 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.004479\n",
      "2200it [04:07,  7.20it/s]Train epoch: 9 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.004362\n",
      "2225it [04:11,  7.18it/s]Train epoch: 9 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.004380\n",
      "2250it [04:14,  7.25it/s]Train epoch: 9 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.004941\n",
      "2275it [04:18,  7.19it/s]Train epoch: 9 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.004432\n",
      "2300it [04:21,  7.15it/s]Train epoch: 9 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.004209\n",
      "2325it [04:25,  7.19it/s]Train epoch: 9 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.004959\n",
      "2350it [04:28,  7.19it/s]Train epoch: 9 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.004465\n",
      "2375it [04:32,  7.03it/s]Train epoch: 9 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.004833\n",
      "2400it [04:35,  7.01it/s]Train epoch: 9 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.004720\n",
      "2425it [04:39,  6.94it/s]Train epoch: 9 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.004688\n",
      "2450it [04:42,  6.94it/s]Train epoch: 9 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.004711\n",
      "2475it [04:46,  7.04it/s]Train epoch: 9 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.004452\n",
      "2500it [04:49,  7.10it/s]Train epoch: 9 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.004780\n",
      "2525it [04:53,  6.92it/s]Train epoch: 9 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.004378\n",
      "2550it [04:57,  6.93it/s]Train epoch: 9 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.004642\n",
      "2575it [05:00,  6.85it/s]Train epoch: 9 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.004992\n",
      "2600it [05:04,  6.79it/s]Train epoch: 9 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.004574\n",
      "2625it [05:08,  6.80it/s]Train epoch: 9 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.004699\n",
      "2650it [05:11,  6.61it/s]Train epoch: 9 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.004446\n",
      "2675it [05:15,  6.65it/s]Train epoch: 9 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004840\n",
      "2700it [05:19,  6.74it/s]Train epoch: 9 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.005329\n",
      "2725it [05:23,  6.72it/s]Train epoch: 9 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.005002\n",
      "2750it [05:26,  6.66it/s]Train epoch: 9 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.005640\n",
      "2775it [05:30,  6.65it/s]Train epoch: 9 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.004826\n",
      "2800it [05:34,  6.38it/s]Train epoch: 9 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.005183\n",
      "2825it [05:38,  6.64it/s]Train epoch: 9 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.004431\n",
      "2850it [05:42,  6.43it/s]Train epoch: 9 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.005168\n",
      "2875it [05:45,  6.54it/s]Train epoch: 9 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.005743\n",
      "2900it [05:49,  6.54it/s]Train epoch: 9 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.005058\n",
      "2925it [05:53,  6.45it/s]Train epoch: 9 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.005234\n",
      "2950it [05:57,  6.50it/s]Train epoch: 9 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.005564\n",
      "2975it [06:01,  6.45it/s]Train epoch: 9 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.004867\n",
      "3000it [06:05,  6.32it/s]Train epoch: 9 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.005034\n",
      "3025it [06:09,  6.32it/s]Train epoch: 9 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.005003\n",
      "3050it [06:13,  6.43it/s]Train epoch: 9 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.004857\n",
      "3075it [06:16,  6.31it/s]Train epoch: 9 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.005109\n",
      "3100it [06:20,  6.26it/s]Train epoch: 9 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.004974\n",
      "3125it [06:24,  6.30it/s]Train epoch: 9 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.004813\n",
      "3150it [06:28,  6.23it/s]Train epoch: 9 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.005128\n",
      "3175it [06:32,  6.34it/s]Train epoch: 9 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.005489\n",
      "3200it [06:36,  6.22it/s]Train epoch: 9 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004858\n",
      "3225it [06:40,  6.23it/s]Train epoch: 9 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.005144\n",
      "3250it [06:44,  6.15it/s]Train epoch: 9 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.005424\n",
      "3275it [06:48,  6.17it/s]Train epoch: 9 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.005392\n",
      "3300it [06:53,  6.15it/s]Train epoch: 9 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.005588\n",
      "3325it [06:57,  6.06it/s]Train epoch: 9 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.005521\n",
      "3350it [07:01,  6.06it/s]Train epoch: 9 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.005506\n",
      "3375it [07:05,  6.06it/s]Train epoch: 9 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.004957\n",
      "3400it [07:09,  5.96it/s]Train epoch: 9 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.005471\n",
      "3425it [07:13,  6.09it/s]Train epoch: 9 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.005364\n",
      "3450it [07:17,  5.79it/s]Train epoch: 9 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.005306\n",
      "3475it [07:22,  5.95it/s]Train epoch: 9 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.005912\n",
      "3500it [07:26,  5.97it/s]Train epoch: 9 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.005245\n",
      "3525it [07:30,  5.98it/s]Train epoch: 9 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.005267\n",
      "3550it [07:34,  5.99it/s]Train epoch: 9 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.005630\n",
      "3575it [07:38,  5.81it/s]Train epoch: 9 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.005743\n",
      "3600it [07:43,  5.86it/s]Train epoch: 9 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.005910\n",
      "3625it [07:47,  5.86it/s]Train epoch: 9 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.005220\n",
      "3650it [07:51,  5.68it/s]Train epoch: 9 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.005802\n",
      "3675it [07:56,  5.79it/s]Train epoch: 9 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.005978\n",
      "3700it [08:00,  5.76it/s]Train epoch: 9 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.005366\n",
      "3725it [08:04,  5.80it/s]Train epoch: 9 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.005830\n",
      "3750it [08:09,  5.69it/s]Train epoch: 9 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.005560\n",
      "3775it [08:13,  5.69it/s]Train epoch: 9 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.005864\n",
      "3800it [08:18,  5.72it/s]Train epoch: 9 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.006199\n",
      "3825it [08:22,  5.64it/s]Train epoch: 9 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.005600\n",
      "3850it [08:26,  5.75it/s]Train epoch: 9 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.005525\n",
      "3875it [08:31,  5.66it/s]Train epoch: 9 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.005810\n",
      "3900it [08:35,  5.59it/s]Train epoch: 9 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.005937\n",
      "3925it [08:40,  5.65it/s]Train epoch: 9 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.005171\n",
      "3950it [08:44,  5.57it/s]Train epoch: 9 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.005554\n",
      "3975it [08:49,  5.51it/s]Train epoch: 9 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.005978\n",
      "4000it [08:53,  5.48it/s]Train epoch: 9 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.005577\n",
      "4025it [08:58,  5.51it/s]Train epoch: 9 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.005476\n",
      "4050it [09:02,  5.49it/s]Train epoch: 9 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.005521\n",
      "4075it [09:07,  5.46it/s]Train epoch: 9 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.005482\n",
      "4100it [09:12,  5.45it/s]Train epoch: 9 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.005677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4125it [09:16,  5.34it/s]Train epoch: 9 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.005803\n",
      "4150it [09:21,  5.37it/s]Train epoch: 9 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.006070\n",
      "4175it [09:26,  5.27it/s]Train epoch: 9 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.005675\n",
      "4200it [09:30,  5.30it/s]Train epoch: 9 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.005290\n",
      "4225it [09:35,  5.30it/s]Train epoch: 9 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.005838\n",
      "4250it [09:40,  5.18it/s]Train epoch: 9 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.006338\n",
      "4275it [09:45,  5.27it/s]Train epoch: 9 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.005972\n",
      "4300it [09:49,  5.21it/s]Train epoch: 9 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.005616\n",
      "4325it [09:54,  5.14it/s]Train epoch: 9 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.006131\n",
      "4350it [09:59,  5.18it/s]Train epoch: 9 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.006574\n",
      "4375it [10:04,  5.15it/s]Train epoch: 9 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.006091\n",
      "4400it [10:09,  5.16it/s]Train epoch: 9 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.005948\n",
      "4425it [10:14,  5.05it/s]Train epoch: 9 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.006088\n",
      "4450it [10:18,  5.20it/s]Train epoch: 9 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.005934\n",
      "4475it [10:23,  4.99it/s]Train epoch: 9 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.006817\n",
      "4500it [10:28,  5.01it/s]Train epoch: 9 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.006514\n",
      "4525it [10:33,  4.94it/s]Train epoch: 9 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.006191\n",
      "4550it [10:38,  4.95it/s]Train epoch: 9 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.006220\n",
      "4575it [10:43,  4.96it/s]Train epoch: 9 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.005935\n",
      "4600it [10:49,  4.96it/s]Train epoch: 9 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.006102\n",
      "4625it [10:54,  4.96it/s]Train epoch: 9 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.006601\n",
      "4650it [10:59,  4.96it/s]Train epoch: 9 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.006684\n",
      "4675it [11:04,  4.85it/s]Train epoch: 9 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.006553\n",
      "4700it [11:09,  4.78it/s]Train epoch: 9 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.006372\n",
      "4725it [11:14,  4.83it/s]Train epoch: 9 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.006472\n",
      "4750it [11:19,  4.76it/s]Train epoch: 9 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.006413\n",
      "4775it [11:25,  4.66it/s]Train epoch: 9 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.006505\n",
      "4800it [11:30,  4.75it/s]Train epoch: 9 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.006836\n",
      "4825it [11:35,  4.71it/s]Train epoch: 9 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.005961\n",
      "4850it [11:41,  4.72it/s]Train epoch: 9 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.006382\n",
      "4875it [11:46,  4.65it/s]Train epoch: 9 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.006646\n",
      "4900it [11:51,  4.59it/s]Train epoch: 9 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.006618\n",
      "4925it [11:57,  4.62it/s]Train epoch: 9 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.006972\n",
      "4950it [12:02,  4.62it/s]Train epoch: 9 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.007018\n",
      "4975it [12:08,  4.47it/s]Train epoch: 9 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.007056\n",
      "5000it [12:13,  4.52it/s]Train epoch: 9 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.006704\n",
      "5025it [12:19,  4.54it/s]Train epoch: 9 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.007354\n",
      "5050it [12:24,  4.47it/s]Train epoch: 9 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.007162\n",
      "5075it [12:30,  4.43it/s]Train epoch: 9 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.006760\n",
      "5100it [12:36,  4.35it/s]Train epoch: 9 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.006773\n",
      "5125it [12:41,  4.38it/s]Train epoch: 9 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.007325\n",
      "5150it [12:47,  4.36it/s]Train epoch: 9 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.007407\n",
      "5175it [12:53,  4.29it/s]Train epoch: 9 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.007145\n",
      "5200it [12:59,  4.30it/s]Train epoch: 9 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.007634\n",
      "5225it [13:05,  4.29it/s]Train epoch: 9 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.007404\n",
      "5250it [13:11,  4.18it/s]Train epoch: 9 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.007063\n",
      "5275it [13:16,  4.18it/s]Train epoch: 9 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.007350\n",
      "5300it [13:22,  4.17it/s]Train epoch: 9 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.007125\n",
      "5325it [13:28,  4.13it/s]Train epoch: 9 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.007024\n",
      "5350it [13:35,  4.12it/s]Train epoch: 9 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.007632\n",
      "5375it [13:41,  4.06it/s]Train epoch: 9 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.007866\n",
      "5400it [13:47,  4.06it/s]Train epoch: 9 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.007528\n",
      "5425it [13:53,  4.00it/s]Train epoch: 9 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.007507\n",
      "5450it [13:59,  3.98it/s]Train epoch: 9 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.007799\n",
      "5475it [14:06,  3.92it/s]Train epoch: 9 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.007687\n",
      "5500it [14:12,  3.84it/s]Train epoch: 9 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.007818\n",
      "5525it [14:19,  3.88it/s]Train epoch: 9 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.008173\n",
      "5550it [14:25,  3.82it/s]Train epoch: 9 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.008397\n",
      "5575it [14:32,  3.75it/s]Train epoch: 9 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.007471\n",
      "5600it [14:39,  3.70it/s]Train epoch: 9 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.007872\n",
      "5625it [14:45,  3.63it/s]Train epoch: 9 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.008370\n",
      "5650it [14:52,  3.63it/s]Train epoch: 9 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.007505\n",
      "5675it [14:59,  3.55it/s]Train epoch: 9 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.008759\n",
      "5700it [15:06,  3.45it/s]Train epoch: 9 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.008146\n",
      "5725it [15:14,  3.43it/s]Train epoch: 9 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.008542\n",
      "5750it [15:21,  3.38it/s]Train epoch: 9 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.008986\n",
      "5775it [15:29,  3.29it/s]Train epoch: 9 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.008372\n",
      "5800it [15:36,  3.27it/s]Train epoch: 9 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.008862\n",
      "5825it [15:44,  3.13it/s]Train epoch: 9 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.009055\n",
      "5850it [15:52,  3.02it/s]Train epoch: 9 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.008835\n",
      "5875it [16:01,  2.89it/s]Train epoch: 9 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.009475\n",
      "5900it [16:10,  2.77it/s]Train epoch: 9 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.008726\n",
      "5925it [16:19,  2.54it/s]Train epoch: 9 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.009966\n",
      "5950it [16:30,  2.17it/s]Train epoch: 9 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.010780\n",
      "5965it [16:38,  5.97it/s]\n",
      "epoch loss: 0.00535295843880558\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.34it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_8: 0.2971\n",
      "prec_at_8: 0.5593\n",
      "rec_at_15: 0.4093\n",
      "prec_at_15: 0.4247\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.25it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_8: 0.2843\n",
      "prec_at_8: 0.5528\n",
      "rec_at_15: 0.3920\n",
      "prec_at_15: 0.4222\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save best model --> ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 10\n",
      "0it [00:00, ?it/s]Train epoch: 10 [batch #0, batch_size 8, seq length 512]\tLoss: 0.005523\n",
      "24it [00:01, 15.89it/s]Train epoch: 10 [batch #25, batch_size 8, seq length 512]\tLoss: 0.003755\n",
      "50it [00:03, 14.43it/s]Train epoch: 10 [batch #50, batch_size 8, seq length 512]\tLoss: 0.003328\n",
      "74it [00:04, 13.97it/s]Train epoch: 10 [batch #75, batch_size 8, seq length 512]\tLoss: 0.003006\n",
      "100it [00:06, 13.21it/s]Train epoch: 10 [batch #100, batch_size 8, seq length 512]\tLoss: 0.003333\n",
      "124it [00:08, 12.83it/s]Train epoch: 10 [batch #125, batch_size 8, seq length 512]\tLoss: 0.003178\n",
      "150it [00:10, 12.17it/s]Train epoch: 10 [batch #150, batch_size 8, seq length 512]\tLoss: 0.003123\n",
      "174it [00:12, 12.26it/s]Train epoch: 10 [batch #175, batch_size 8, seq length 512]\tLoss: 0.003363\n",
      "200it [00:15, 12.19it/s]Train epoch: 10 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002742\n",
      "224it [00:17, 11.28it/s]Train epoch: 10 [batch #225, batch_size 8, seq length 512]\tLoss: 0.003184\n",
      "250it [00:19, 11.49it/s]Train epoch: 10 [batch #250, batch_size 8, seq length 512]\tLoss: 0.003011\n",
      "274it [00:21, 11.33it/s]Train epoch: 10 [batch #275, batch_size 8, seq length 512]\tLoss: 0.003229\n",
      "300it [00:23, 11.49it/s]Train epoch: 10 [batch #300, batch_size 8, seq length 512]\tLoss: 0.003351\n",
      "324it [00:25, 11.30it/s]Train epoch: 10 [batch #325, batch_size 8, seq length 512]\tLoss: 0.003273\n",
      "350it [00:28, 11.22it/s]Train epoch: 10 [batch #350, batch_size 8, seq length 512]\tLoss: 0.003215\n",
      "374it [00:30, 10.78it/s]Train epoch: 10 [batch #375, batch_size 8, seq length 512]\tLoss: 0.003219\n",
      "400it [00:32, 10.60it/s]Train epoch: 10 [batch #400, batch_size 8, seq length 512]\tLoss: 0.003083\n",
      "424it [00:35, 10.18it/s]Train epoch: 10 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003524\n",
      "450it [00:37, 10.08it/s]Train epoch: 10 [batch #450, batch_size 8, seq length 512]\tLoss: 0.003178\n",
      "475it [00:40, 10.14it/s]Train epoch: 10 [batch #475, batch_size 8, seq length 512]\tLoss: 0.003048\n",
      "500it [00:42, 10.12it/s]Train epoch: 10 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003564\n",
      "525it [00:45,  9.95it/s]Train epoch: 10 [batch #525, batch_size 8, seq length 512]\tLoss: 0.003262\n",
      "550it [00:47,  9.43it/s]Train epoch: 10 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003609\n",
      "575it [00:50,  9.89it/s]Train epoch: 10 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003634\n",
      "600it [00:52,  9.82it/s]Train epoch: 10 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003441\n",
      "625it [00:55,  9.83it/s]Train epoch: 10 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003411\n",
      "650it [00:57,  9.56it/s]Train epoch: 10 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003535\n",
      "675it [01:00,  9.73it/s]Train epoch: 10 [batch #675, batch_size 8, seq length 512]\tLoss: 0.004180\n",
      "700it [01:03,  9.58it/s]Train epoch: 10 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003543\n",
      "725it [01:05,  9.38it/s]Train epoch: 10 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003550\n",
      "749it [01:08,  9.49it/s]Train epoch: 10 [batch #750, batch_size 8, seq length 512]\tLoss: 0.004231\n",
      "775it [01:11,  9.16it/s]Train epoch: 10 [batch #775, batch_size 8, seq length 512]\tLoss: 0.003275\n",
      "800it [01:13,  9.35it/s]Train epoch: 10 [batch #800, batch_size 8, seq length 512]\tLoss: 0.003122\n",
      "825it [01:16,  9.25it/s]Train epoch: 10 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003584\n",
      "850it [01:19,  8.78it/s]Train epoch: 10 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003535\n",
      "875it [01:21,  9.18it/s]Train epoch: 10 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003759\n",
      "900it [01:24,  8.86it/s]Train epoch: 10 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003608\n",
      "925it [01:27,  8.99it/s]Train epoch: 10 [batch #925, batch_size 8, seq length 512]\tLoss: 0.003799\n",
      "950it [01:30,  8.94it/s]Train epoch: 10 [batch #950, batch_size 8, seq length 512]\tLoss: 0.002936\n",
      "975it [01:33,  8.91it/s]Train epoch: 10 [batch #975, batch_size 8, seq length 512]\tLoss: 0.003786\n",
      "1000it [01:35,  8.55it/s]Train epoch: 10 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003480\n",
      "1025it [01:38,  9.15it/s]Train epoch: 10 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.003385\n",
      "1050it [01:41,  8.79it/s]Train epoch: 10 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003693\n",
      "1075it [01:44,  8.86it/s]Train epoch: 10 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003580\n",
      "1100it [01:47,  8.63it/s]Train epoch: 10 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.003758\n",
      "1125it [01:50,  8.83it/s]Train epoch: 10 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003555\n",
      "1150it [01:52,  8.61it/s]Train epoch: 10 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.003198\n",
      "1175it [01:55,  8.77it/s]Train epoch: 10 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003681\n",
      "1200it [01:58,  8.55it/s]Train epoch: 10 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.003981\n",
      "1225it [02:01,  8.60it/s]Train epoch: 10 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003787\n",
      "1250it [02:04,  8.68it/s]Train epoch: 10 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003480\n",
      "1275it [02:07,  8.48it/s]Train epoch: 10 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.004539\n",
      "1300it [02:10,  8.33it/s]Train epoch: 10 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003753\n",
      "1325it [02:13,  8.20it/s]Train epoch: 10 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.003873\n",
      "1350it [02:16,  8.28it/s]Train epoch: 10 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003426\n",
      "1375it [02:19,  8.25it/s]Train epoch: 10 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.004374\n",
      "1400it [02:22,  8.19it/s]Train epoch: 10 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003671\n",
      "1425it [02:25,  8.19it/s]Train epoch: 10 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.003863\n",
      "1450it [02:28,  8.16it/s]Train epoch: 10 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.003998\n",
      "1475it [02:32,  8.02it/s]Train epoch: 10 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.003983\n",
      "1500it [02:35,  7.94it/s]Train epoch: 10 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004447\n",
      "1525it [02:38,  7.96it/s]Train epoch: 10 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.004013\n",
      "1550it [02:41,  8.00it/s]Train epoch: 10 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.003989\n",
      "1575it [02:44,  8.08it/s]Train epoch: 10 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.003768\n",
      "1600it [02:47,  8.08it/s]Train epoch: 10 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.004437\n",
      "1625it [02:50,  7.94it/s]Train epoch: 10 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.004194\n",
      "1650it [02:54,  7.93it/s]Train epoch: 10 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.004525\n",
      "1675it [02:57,  7.79it/s]Train epoch: 10 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.004208\n",
      "1700it [03:00,  7.86it/s]Train epoch: 10 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.004116\n",
      "1725it [03:03,  7.72it/s]Train epoch: 10 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.004268\n",
      "1750it [03:06,  7.62it/s]Train epoch: 10 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.004221\n",
      "1775it [03:10,  7.59it/s]Train epoch: 10 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.004380\n",
      "1800it [03:13,  7.59it/s]Train epoch: 10 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.004302\n",
      "1825it [03:16,  7.55it/s]Train epoch: 10 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.004106\n",
      "1850it [03:19,  7.61it/s]Train epoch: 10 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.003970\n",
      "1875it [03:23,  7.56it/s]Train epoch: 10 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.004223\n",
      "1900it [03:26,  7.52it/s]Train epoch: 10 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.004798\n",
      "1925it [03:29,  7.52it/s]Train epoch: 10 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.004142\n",
      "1950it [03:33,  7.54it/s]Train epoch: 10 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.004375\n",
      "1975it [03:36,  7.58it/s]Train epoch: 10 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.004478\n",
      "2000it [03:39,  7.38it/s]Train epoch: 10 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.003924\n",
      "2025it [03:43,  7.54it/s]Train epoch: 10 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.004172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050it [03:46,  7.20it/s]Train epoch: 10 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.004551\n",
      "2075it [03:50,  7.10it/s]Train epoch: 10 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.004269\n",
      "2100it [03:53,  7.33it/s]Train epoch: 10 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.004627\n",
      "2125it [03:56,  7.54it/s]Train epoch: 10 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.004309\n",
      "2150it [04:00,  7.39it/s]Train epoch: 10 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004715\n",
      "2175it [04:03,  7.11it/s]Train epoch: 10 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.004309\n",
      "2200it [04:07,  7.20it/s]Train epoch: 10 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.004229\n",
      "2225it [04:10,  7.16it/s]Train epoch: 10 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.004256\n",
      "2250it [04:14,  7.23it/s]Train epoch: 10 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.004792\n",
      "2275it [04:17,  7.08it/s]Train epoch: 10 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.004296\n",
      "2300it [04:21,  7.20it/s]Train epoch: 10 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.004106\n",
      "2325it [04:24,  6.97it/s]Train epoch: 10 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.004820\n",
      "2350it [04:28,  7.05it/s]Train epoch: 10 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.004293\n",
      "2375it [04:31,  7.18it/s]Train epoch: 10 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.004704\n",
      "2400it [04:35,  7.00it/s]Train epoch: 10 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.004596\n",
      "2425it [04:38,  7.06it/s]Train epoch: 10 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.004555\n",
      "2450it [04:42,  7.11it/s]Train epoch: 10 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.004644\n",
      "2475it [04:46,  6.94it/s]Train epoch: 10 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.004340\n",
      "2500it [04:49,  7.13it/s]Train epoch: 10 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.004685\n",
      "2525it [04:53,  7.03it/s]Train epoch: 10 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.004219\n",
      "2550it [04:57,  6.75it/s]Train epoch: 10 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.004478\n",
      "2575it [05:00,  6.60it/s]Train epoch: 10 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.004858\n",
      "2600it [05:04,  6.92it/s]Train epoch: 10 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.004437\n",
      "2625it [05:08,  6.66it/s]Train epoch: 10 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.004620\n",
      "2650it [05:11,  6.74it/s]Train epoch: 10 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.004337\n",
      "2675it [05:15,  6.69it/s]Train epoch: 10 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004717\n",
      "2700it [05:19,  6.59it/s]Train epoch: 10 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.005234\n",
      "2725it [05:23,  6.70it/s]Train epoch: 10 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.004861\n",
      "2750it [05:26,  6.54it/s]Train epoch: 10 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.005460\n",
      "2775it [05:30,  6.61it/s]Train epoch: 10 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.004715\n",
      "2800it [05:34,  6.63it/s]Train epoch: 10 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.005072\n",
      "2825it [05:38,  6.66it/s]Train epoch: 10 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.004340\n",
      "2850it [05:42,  6.51it/s]Train epoch: 10 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.005050\n",
      "2875it [05:45,  6.72it/s]Train epoch: 10 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.005586\n",
      "2900it [05:49,  6.42it/s]Train epoch: 10 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.004906\n",
      "2925it [05:53,  6.49it/s]Train epoch: 10 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.005140\n",
      "2950it [05:57,  6.45it/s]Train epoch: 10 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.005409\n",
      "2975it [06:01,  6.36it/s]Train epoch: 10 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.004726\n",
      "3000it [06:05,  6.40it/s]Train epoch: 10 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.004894\n",
      "3025it [06:09,  6.30it/s]Train epoch: 10 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.004912\n",
      "3050it [06:13,  6.29it/s]Train epoch: 10 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.004764\n",
      "3075it [06:17,  6.25it/s]Train epoch: 10 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.004991\n",
      "3100it [06:21,  6.22it/s]Train epoch: 10 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.004886\n",
      "3125it [06:25,  6.18it/s]Train epoch: 10 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.004711\n",
      "3150it [06:29,  6.23it/s]Train epoch: 10 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.004987\n",
      "3175it [06:33,  6.31it/s]Train epoch: 10 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.005395\n",
      "3200it [06:37,  6.25it/s]Train epoch: 10 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004703\n",
      "3225it [06:41,  6.20it/s]Train epoch: 10 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.005020\n",
      "3250it [06:45,  6.28it/s]Train epoch: 10 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.005247\n",
      "3275it [06:49,  6.08it/s]Train epoch: 10 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.005275\n",
      "3300it [06:53,  6.11it/s]Train epoch: 10 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.005470\n",
      "3325it [06:57,  6.00it/s]Train epoch: 10 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.005384\n",
      "3350it [07:01,  6.04it/s]Train epoch: 10 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.005415\n",
      "3375it [07:05,  6.07it/s]Train epoch: 10 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.004809\n",
      "3400it [07:09,  6.07it/s]Train epoch: 10 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.005266\n",
      "3425it [07:14,  5.97it/s]Train epoch: 10 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.005217\n",
      "3450it [07:18,  5.91it/s]Train epoch: 10 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.005144\n",
      "3475it [07:22,  5.90it/s]Train epoch: 10 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.005750\n",
      "3500it [07:26,  5.84it/s]Train epoch: 10 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.005104\n",
      "3525it [07:30,  5.87it/s]Train epoch: 10 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.005081\n",
      "3550it [07:35,  5.78it/s]Train epoch: 10 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.005466\n",
      "3575it [07:39,  5.64it/s]Train epoch: 10 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.005591\n",
      "3600it [07:43,  5.74it/s]Train epoch: 10 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.005736\n",
      "3625it [07:48,  5.93it/s]Train epoch: 10 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.005089\n",
      "3650it [07:52,  5.81it/s]Train epoch: 10 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.005629\n",
      "3675it [07:56,  5.79it/s]Train epoch: 10 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.005886\n",
      "3700it [08:01,  5.65it/s]Train epoch: 10 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.005243\n",
      "3725it [08:05,  5.75it/s]Train epoch: 10 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.005707\n",
      "3750it [08:09,  5.72it/s]Train epoch: 10 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.005379\n",
      "3775it [08:14,  5.73it/s]Train epoch: 10 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.005689\n",
      "3800it [08:18,  5.66it/s]Train epoch: 10 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.006067\n",
      "3825it [08:23,  5.64it/s]Train epoch: 10 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.005480\n",
      "3850it [08:27,  5.44it/s]Train epoch: 10 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.005343\n",
      "3875it [08:32,  5.62it/s]Train epoch: 10 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.005644\n",
      "3900it [08:36,  5.67it/s]Train epoch: 10 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.005815\n",
      "3925it [08:41,  5.53it/s]Train epoch: 10 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.005055\n",
      "3950it [08:45,  5.61it/s]Train epoch: 10 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.005387\n",
      "3975it [08:50,  5.46it/s]Train epoch: 10 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.005798\n",
      "4000it [08:54,  5.55it/s]Train epoch: 10 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.005383\n",
      "4025it [08:59,  5.34it/s]Train epoch: 10 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.005285\n",
      "4050it [09:03,  5.45it/s]Train epoch: 10 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.005439\n",
      "4075it [09:08,  5.47it/s]Train epoch: 10 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.005305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100it [09:13,  5.42it/s]Train epoch: 10 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.005585\n",
      "4125it [09:17,  5.42it/s]Train epoch: 10 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.005628\n",
      "4150it [09:22,  5.30it/s]Train epoch: 10 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.005903\n",
      "4175it [09:27,  5.07it/s]Train epoch: 10 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.005473\n",
      "4200it [09:31,  5.29it/s]Train epoch: 10 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.005133\n",
      "4225it [09:36,  5.24it/s]Train epoch: 10 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.005714\n",
      "4250it [09:41,  5.25it/s]Train epoch: 10 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.006258\n",
      "4275it [09:46,  5.27it/s]Train epoch: 10 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.005854\n",
      "4300it [09:50,  5.21it/s]Train epoch: 10 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.005505\n",
      "4325it [09:55,  5.17it/s]Train epoch: 10 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.006006\n",
      "4350it [10:00,  5.21it/s]Train epoch: 10 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.006361\n",
      "4375it [10:05,  5.13it/s]Train epoch: 10 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.005951\n",
      "4400it [10:10,  5.09it/s]Train epoch: 10 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.005792\n",
      "4425it [10:15,  5.02it/s]Train epoch: 10 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.005940\n",
      "4450it [10:20,  5.00it/s]Train epoch: 10 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.005697\n",
      "4475it [10:25,  5.04it/s]Train epoch: 10 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.006669\n",
      "4500it [10:30,  4.96it/s]Train epoch: 10 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.006351\n",
      "4525it [10:35,  4.82it/s]Train epoch: 10 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.005995\n",
      "4550it [10:40,  4.97it/s]Train epoch: 10 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.006015\n",
      "4575it [10:45,  4.93it/s]Train epoch: 10 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.005785\n",
      "4600it [10:50,  4.95it/s]Train epoch: 10 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.005981\n",
      "4625it [10:55,  4.93it/s]Train epoch: 10 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.006400\n",
      "4650it [11:00,  4.87it/s]Train epoch: 10 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.006524\n",
      "4675it [11:05,  4.81it/s]Train epoch: 10 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.006392\n",
      "4700it [11:10,  4.84it/s]Train epoch: 10 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.006296\n",
      "4725it [11:16,  4.79it/s]Train epoch: 10 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.006290\n",
      "4750it [11:21,  4.73it/s]Train epoch: 10 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.006229\n",
      "4775it [11:26,  4.75it/s]Train epoch: 10 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.006356\n",
      "4800it [11:31,  4.51it/s]Train epoch: 10 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.006700\n",
      "4825it [11:37,  4.69it/s]Train epoch: 10 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.005799\n",
      "4850it [11:42,  4.58it/s]Train epoch: 10 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.006267\n",
      "4875it [11:48,  4.63it/s]Train epoch: 10 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.006533\n",
      "4900it [11:53,  4.60it/s]Train epoch: 10 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.006429\n",
      "4925it [11:58,  4.53it/s]Train epoch: 10 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.006831\n",
      "4950it [12:04,  4.51it/s]Train epoch: 10 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.006804\n",
      "4975it [12:09,  4.57it/s]Train epoch: 10 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.006916\n",
      "5000it [12:15,  4.53it/s]Train epoch: 10 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.006592\n",
      "5025it [12:21,  4.50it/s]Train epoch: 10 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.007211\n",
      "5050it [12:26,  4.45it/s]Train epoch: 10 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.007038\n",
      "5075it [12:32,  4.43it/s]Train epoch: 10 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.006603\n",
      "5100it [12:37,  4.46it/s]Train epoch: 10 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.006583\n",
      "5125it [12:43,  4.39it/s]Train epoch: 10 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.007181\n",
      "5150it [12:49,  4.40it/s]Train epoch: 10 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.007254\n",
      "5175it [12:54,  4.32it/s]Train epoch: 10 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.006962\n",
      "5200it [13:00,  4.30it/s]Train epoch: 10 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.007424\n",
      "5225it [13:06,  4.21it/s]Train epoch: 10 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.007303\n",
      "5250it [13:12,  4.25it/s]Train epoch: 10 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.006903\n",
      "5275it [13:18,  4.15it/s]Train epoch: 10 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.007210\n",
      "5300it [13:24,  4.20it/s]Train epoch: 10 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.006968\n",
      "5325it [13:30,  4.12it/s]Train epoch: 10 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.006895\n",
      "5350it [13:36,  4.14it/s]Train epoch: 10 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.007450\n",
      "5375it [13:42,  4.05it/s]Train epoch: 10 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.007749\n",
      "5400it [13:48,  4.00it/s]Train epoch: 10 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.007412\n",
      "5425it [13:55,  3.96it/s]Train epoch: 10 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.007324\n",
      "5450it [14:01,  3.98it/s]Train epoch: 10 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.007622\n",
      "5475it [14:07,  3.90it/s]Train epoch: 10 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.007539\n",
      "5500it [14:14,  3.91it/s]Train epoch: 10 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.007678\n",
      "5525it [14:20,  3.78it/s]Train epoch: 10 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.008007\n",
      "5550it [14:27,  3.81it/s]Train epoch: 10 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.008227\n",
      "5575it [14:33,  3.79it/s]Train epoch: 10 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.007352\n",
      "5600it [14:40,  3.75it/s]Train epoch: 10 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.007685\n",
      "5625it [14:47,  3.69it/s]Train epoch: 10 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.008272\n",
      "5650it [14:54,  3.60it/s]Train epoch: 10 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.007328\n",
      "5675it [15:01,  3.54it/s]Train epoch: 10 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.008567\n",
      "5700it [15:08,  3.43it/s]Train epoch: 10 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.008074\n",
      "5725it [15:15,  3.43it/s]Train epoch: 10 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.008373\n",
      "5750it [15:23,  3.34it/s]Train epoch: 10 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.008848\n",
      "5775it [15:30,  3.25it/s]Train epoch: 10 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.008212\n",
      "5800it [15:38,  3.19it/s]Train epoch: 10 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.008740\n",
      "5825it [15:46,  3.14it/s]Train epoch: 10 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.008876\n",
      "5850it [15:54,  3.01it/s]Train epoch: 10 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.008593\n",
      "5875it [16:02,  2.87it/s]Train epoch: 10 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.009417\n",
      "5900it [16:11,  2.76it/s]Train epoch: 10 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.008581\n",
      "5925it [16:21,  2.55it/s]Train epoch: 10 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.009780\n",
      "5950it [16:32,  2.18it/s]Train epoch: 10 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.010588\n",
      "5965it [16:40,  5.96it/s]\n",
      "epoch loss: 0.005218653054576139\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.19it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0210, 0.0349, 0.0307, 0.0326, 0.8455\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2446, 0.5484, 0.3063, 0.3931, 0.9747\n",
      "rec_at_8: 0.2991\n",
      "prec_at_8: 0.5602\n",
      "rec_at_15: 0.4117\n",
      "prec_at_15: 0.4267\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.21it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0206, 0.0396, 0.0299, 0.0341, 0.8463\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2346, 0.5412, 0.2929, 0.3801, 0.9743\n",
      "rec_at_8: 0.2861\n",
      "prec_at_8: 0.5554\n",
      "rec_at_15: 0.3945\n",
      "prec_at_15: 0.4246\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 11\n",
      "0it [00:00, ?it/s]Train epoch: 11 [batch #0, batch_size 8, seq length 512]\tLoss: 0.005304\n",
      "25it [00:01, 15.68it/s]Train epoch: 11 [batch #25, batch_size 8, seq length 512]\tLoss: 0.003666\n",
      "49it [00:03, 14.48it/s]Train epoch: 11 [batch #50, batch_size 8, seq length 512]\tLoss: 0.003259\n",
      "75it [00:05, 13.17it/s]Train epoch: 11 [batch #75, batch_size 8, seq length 512]\tLoss: 0.002897\n",
      "99it [00:06, 12.94it/s]Train epoch: 11 [batch #100, batch_size 8, seq length 512]\tLoss: 0.003274\n",
      "125it [00:08, 13.13it/s]Train epoch: 11 [batch #125, batch_size 8, seq length 512]\tLoss: 0.003070\n",
      "149it [00:10, 12.38it/s]Train epoch: 11 [batch #150, batch_size 8, seq length 512]\tLoss: 0.003011\n",
      "175it [00:12, 12.26it/s]Train epoch: 11 [batch #175, batch_size 8, seq length 512]\tLoss: 0.003292\n",
      "199it [00:14, 11.67it/s]Train epoch: 11 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002664\n",
      "225it [00:17, 11.74it/s]Train epoch: 11 [batch #225, batch_size 8, seq length 512]\tLoss: 0.003100\n",
      "249it [00:19, 11.62it/s]Train epoch: 11 [batch #250, batch_size 8, seq length 512]\tLoss: 0.002943\n",
      "275it [00:21, 11.44it/s]Train epoch: 11 [batch #275, batch_size 8, seq length 512]\tLoss: 0.003130\n",
      "299it [00:23, 11.19it/s]Train epoch: 11 [batch #300, batch_size 8, seq length 512]\tLoss: 0.003239\n",
      "325it [00:25, 11.41it/s]Train epoch: 11 [batch #325, batch_size 8, seq length 512]\tLoss: 0.003139\n",
      "349it [00:28, 11.20it/s]Train epoch: 11 [batch #350, batch_size 8, seq length 512]\tLoss: 0.003122\n",
      "375it [00:30, 10.88it/s]Train epoch: 11 [batch #375, batch_size 8, seq length 512]\tLoss: 0.003108\n",
      "399it [00:32, 10.60it/s]Train epoch: 11 [batch #400, batch_size 8, seq length 512]\tLoss: 0.002960\n",
      "425it [00:35, 10.34it/s]Train epoch: 11 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003426\n",
      "449it [00:37, 10.09it/s]Train epoch: 11 [batch #450, batch_size 8, seq length 512]\tLoss: 0.003079\n",
      "475it [00:40,  9.99it/s]Train epoch: 11 [batch #475, batch_size 8, seq length 512]\tLoss: 0.002949\n",
      "499it [00:42, 10.19it/s]Train epoch: 11 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003512\n",
      "525it [00:45,  9.90it/s]Train epoch: 11 [batch #525, batch_size 8, seq length 512]\tLoss: 0.003178\n",
      "550it [00:47,  9.92it/s]Train epoch: 11 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003501\n",
      "575it [00:50,  9.87it/s]Train epoch: 11 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003523\n",
      "600it [00:52,  9.81it/s]Train epoch: 11 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003365\n",
      "625it [00:55,  9.93it/s]Train epoch: 11 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003345\n",
      "650it [00:57,  9.58it/s]Train epoch: 11 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003412\n",
      "675it [01:00,  9.35it/s]Train epoch: 11 [batch #675, batch_size 8, seq length 512]\tLoss: 0.004072\n",
      "700it [01:02,  9.56it/s]Train epoch: 11 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003457\n",
      "725it [01:05,  9.76it/s]Train epoch: 11 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003412\n",
      "750it [01:08,  9.70it/s]Train epoch: 11 [batch #750, batch_size 8, seq length 512]\tLoss: 0.004136\n",
      "775it [01:10,  9.04it/s]Train epoch: 11 [batch #775, batch_size 8, seq length 512]\tLoss: 0.003170\n",
      "800it [01:13,  9.35it/s]Train epoch: 11 [batch #800, batch_size 8, seq length 512]\tLoss: 0.003028\n",
      "825it [01:16,  9.08it/s]Train epoch: 11 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003482\n",
      "850it [01:18,  9.10it/s]Train epoch: 11 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003444\n",
      "875it [01:21,  9.34it/s]Train epoch: 11 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003677\n",
      "900it [01:24,  9.07it/s]Train epoch: 11 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003516\n",
      "925it [01:27,  8.98it/s]Train epoch: 11 [batch #925, batch_size 8, seq length 512]\tLoss: 0.003656\n",
      "950it [01:30,  8.49it/s]Train epoch: 11 [batch #950, batch_size 8, seq length 512]\tLoss: 0.002850\n",
      "975it [01:32,  8.99it/s]Train epoch: 11 [batch #975, batch_size 8, seq length 512]\tLoss: 0.003715\n",
      "1000it [01:35,  8.92it/s]Train epoch: 11 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003414\n",
      "1025it [01:38,  8.83it/s]Train epoch: 11 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.003294\n",
      "1050it [01:41,  8.76it/s]Train epoch: 11 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003542\n",
      "1075it [01:44,  8.68it/s]Train epoch: 11 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003500\n",
      "1100it [01:47,  8.45it/s]Train epoch: 11 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.003652\n",
      "1125it [01:50,  8.65it/s]Train epoch: 11 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003474\n",
      "1150it [01:53,  8.39it/s]Train epoch: 11 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.003107\n",
      "1175it [01:56,  8.40it/s]Train epoch: 11 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003592\n",
      "1200it [01:58,  8.47it/s]Train epoch: 11 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.003847\n",
      "1225it [02:01,  8.42it/s]Train epoch: 11 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003649\n",
      "1250it [02:04,  8.50it/s]Train epoch: 11 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003413\n",
      "1275it [02:07,  8.35it/s]Train epoch: 11 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.004491\n",
      "1300it [02:10,  8.47it/s]Train epoch: 11 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003615\n",
      "1325it [02:13,  8.44it/s]Train epoch: 11 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.003784\n",
      "1350it [02:16,  8.19it/s]Train epoch: 11 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003326\n",
      "1375it [02:19,  8.27it/s]Train epoch: 11 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.004227\n",
      "1400it [02:22,  8.06it/s]Train epoch: 11 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003607\n",
      "1425it [02:26,  8.20it/s]Train epoch: 11 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.003747\n",
      "1450it [02:29,  8.36it/s]Train epoch: 11 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.003894\n",
      "1475it [02:32,  8.04it/s]Train epoch: 11 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.003868\n",
      "1500it [02:35,  8.04it/s]Train epoch: 11 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004367\n",
      "1525it [02:38,  8.02it/s]Train epoch: 11 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.003906\n",
      "1550it [02:41,  7.99it/s]Train epoch: 11 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.003832\n",
      "1575it [02:44,  7.99it/s]Train epoch: 11 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.003667\n",
      "1600it [02:47,  7.92it/s]Train epoch: 11 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.004301\n",
      "1625it [02:50,  7.95it/s]Train epoch: 11 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.004082\n",
      "1650it [02:53,  8.13it/s]Train epoch: 11 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.004395\n",
      "1675it [02:57,  7.81it/s]Train epoch: 11 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.004123\n",
      "1700it [03:00,  7.93it/s]Train epoch: 11 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.004046\n",
      "1725it [03:03,  7.59it/s]Train epoch: 11 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.004127\n",
      "1750it [03:06,  7.94it/s]Train epoch: 11 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.004079\n",
      "1775it [03:09,  7.54it/s]Train epoch: 11 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.004238\n",
      "1800it [03:13,  7.95it/s]Train epoch: 11 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.004202\n",
      "1825it [03:16,  7.73it/s]Train epoch: 11 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.003966\n",
      "1850it [03:19,  7.66it/s]Train epoch: 11 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.003789\n",
      "1875it [03:22,  7.54it/s]Train epoch: 11 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.004142\n",
      "1900it [03:26,  7.52it/s]Train epoch: 11 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.004675\n",
      "1925it [03:29,  7.52it/s]Train epoch: 11 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.004022\n",
      "1950it [03:32,  7.63it/s]Train epoch: 11 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.004269\n",
      "1975it [03:36,  7.34it/s]Train epoch: 11 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.004388\n",
      "2000it [03:39,  7.54it/s]Train epoch: 11 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.003806\n",
      "2025it [03:42,  7.67it/s]Train epoch: 11 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.004112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050it [03:46,  7.39it/s]Train epoch: 11 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.004411\n",
      "2075it [03:49,  7.28it/s]Train epoch: 11 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.004158\n",
      "2100it [03:53,  7.24it/s]Train epoch: 11 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.004513\n",
      "2125it [03:56,  7.20it/s]Train epoch: 11 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.004200\n",
      "2150it [03:59,  7.23it/s]Train epoch: 11 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004613\n",
      "2175it [04:03,  7.29it/s]Train epoch: 11 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.004242\n",
      "2200it [04:06,  7.24it/s]Train epoch: 11 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.004092\n",
      "2225it [04:10,  7.28it/s]Train epoch: 11 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.004171\n",
      "2250it [04:13,  7.25it/s]Train epoch: 11 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.004663\n",
      "2275it [04:17,  7.38it/s]Train epoch: 11 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.004177\n",
      "2300it [04:20,  7.17it/s]Train epoch: 11 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.004012\n",
      "2325it [04:24,  7.00it/s]Train epoch: 11 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.004699\n",
      "2350it [04:27,  7.06it/s]Train epoch: 11 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.004196\n",
      "2375it [04:31,  7.17it/s]Train epoch: 11 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.004591\n",
      "2400it [04:34,  7.04it/s]Train epoch: 11 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.004469\n",
      "2425it [04:38,  6.88it/s]Train epoch: 11 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.004484\n",
      "2450it [04:41,  6.93it/s]Train epoch: 11 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.004524\n",
      "2475it [04:45,  6.87it/s]Train epoch: 11 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.004186\n",
      "2500it [04:49,  6.88it/s]Train epoch: 11 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.004546\n",
      "2525it [04:52,  6.90it/s]Train epoch: 11 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.004117\n",
      "2550it [04:56,  6.84it/s]Train epoch: 11 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.004390\n",
      "2575it [05:00,  6.82it/s]Train epoch: 11 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.004761\n",
      "2600it [05:03,  6.95it/s]Train epoch: 11 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.004340\n",
      "2625it [05:07,  6.73it/s]Train epoch: 11 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.004485\n",
      "2650it [05:11,  6.73it/s]Train epoch: 11 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.004218\n",
      "2675it [05:14,  6.66it/s]Train epoch: 11 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004615\n",
      "2700it [05:18,  6.72it/s]Train epoch: 11 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.005028\n",
      "2725it [05:22,  6.66it/s]Train epoch: 11 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.004756\n",
      "2750it [05:26,  6.78it/s]Train epoch: 11 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.005340\n",
      "2775it [05:29,  6.60it/s]Train epoch: 11 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.004614\n",
      "2800it [05:33,  6.72it/s]Train epoch: 11 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.004949\n",
      "2825it [05:37,  6.41it/s]Train epoch: 11 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.004223\n",
      "2850it [05:41,  6.60it/s]Train epoch: 11 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.004924\n",
      "2875it [05:44,  6.56it/s]Train epoch: 11 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.005475\n",
      "2900it [05:48,  6.69it/s]Train epoch: 11 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.004828\n",
      "2925it [05:52,  6.44it/s]Train epoch: 11 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.005057\n",
      "2950it [05:56,  6.65it/s]Train epoch: 11 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.005255\n",
      "2975it [06:00,  6.31it/s]Train epoch: 11 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.004589\n",
      "3000it [06:04,  6.38it/s]Train epoch: 11 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.004703\n",
      "3025it [06:08,  6.39it/s]Train epoch: 11 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.004760\n",
      "3050it [06:12,  6.27it/s]Train epoch: 11 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.004641\n",
      "3075it [06:16,  6.43it/s]Train epoch: 11 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.004852\n",
      "3100it [06:19,  6.29it/s]Train epoch: 11 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.004810\n",
      "3125it [06:23,  6.11it/s]Train epoch: 11 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.004565\n",
      "3150it [06:27,  6.43it/s]Train epoch: 11 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.004849\n",
      "3175it [06:31,  6.18it/s]Train epoch: 11 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.005233\n",
      "3200it [06:36,  6.23it/s]Train epoch: 11 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004619\n",
      "3225it [06:40,  6.18it/s]Train epoch: 11 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.004903\n",
      "3250it [06:44,  6.09it/s]Train epoch: 11 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.005148\n",
      "3275it [06:48,  6.20it/s]Train epoch: 11 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.005077\n",
      "3300it [06:52,  6.10it/s]Train epoch: 11 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.005312\n",
      "3325it [06:56,  5.97it/s]Train epoch: 11 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.005256\n",
      "3350it [07:00,  6.00it/s]Train epoch: 11 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.005224\n",
      "3375it [07:04,  6.07it/s]Train epoch: 11 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.004744\n",
      "3400it [07:08,  6.07it/s]Train epoch: 11 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.005204\n",
      "3425it [07:13,  6.03it/s]Train epoch: 11 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.005082\n",
      "3450it [07:17,  6.03it/s]Train epoch: 11 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.005017\n",
      "3475it [07:21,  5.83it/s]Train epoch: 11 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.005597\n",
      "3500it [07:25,  5.95it/s]Train epoch: 11 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.004949\n",
      "3525it [07:29,  5.95it/s]Train epoch: 11 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.004970\n",
      "3550it [07:33,  5.90it/s]Train epoch: 11 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.005408\n",
      "3575it [07:38,  5.92it/s]Train epoch: 11 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.005457\n",
      "3600it [07:42,  5.82it/s]Train epoch: 11 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.005615\n",
      "3625it [07:46,  5.95it/s]Train epoch: 11 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.004978\n",
      "3650it [07:51,  5.80it/s]Train epoch: 11 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.005474\n",
      "3675it [07:55,  5.83it/s]Train epoch: 11 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.005709\n",
      "3700it [07:59,  5.77it/s]Train epoch: 11 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.005175\n",
      "3725it [08:04,  5.73it/s]Train epoch: 11 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.005560\n",
      "3750it [08:08,  5.67it/s]Train epoch: 11 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.005251\n",
      "3775it [08:12,  5.70it/s]Train epoch: 11 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.005557\n",
      "3800it [08:17,  5.71it/s]Train epoch: 11 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.005863\n",
      "3825it [08:21,  5.65it/s]Train epoch: 11 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.005380\n",
      "3850it [08:26,  5.50it/s]Train epoch: 11 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.005241\n",
      "3875it [08:30,  5.64it/s]Train epoch: 11 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.005531\n",
      "3900it [08:35,  5.59it/s]Train epoch: 11 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.005649\n",
      "3925it [08:39,  5.71it/s]Train epoch: 11 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.004905\n",
      "3950it [08:44,  5.50it/s]Train epoch: 11 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.005300\n",
      "3975it [08:48,  5.46it/s]Train epoch: 11 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.005669\n",
      "4000it [08:53,  5.47it/s]Train epoch: 11 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.005269\n",
      "4025it [08:57,  5.52it/s]Train epoch: 11 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.005177\n",
      "4050it [09:02,  5.56it/s]Train epoch: 11 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.005182\n",
      "4075it [09:06,  5.36it/s]Train epoch: 11 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.005188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100it [09:11,  5.40it/s]Train epoch: 11 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.005478\n",
      "4125it [09:15,  5.37it/s]Train epoch: 11 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.005564\n",
      "4150it [09:20,  5.26it/s]Train epoch: 11 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.005775\n",
      "4175it [09:25,  5.36it/s]Train epoch: 11 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.005352\n",
      "4200it [09:30,  5.31it/s]Train epoch: 11 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.005060\n",
      "4225it [09:34,  5.30it/s]Train epoch: 11 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.005570\n",
      "4250it [09:39,  5.36it/s]Train epoch: 11 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.006114\n",
      "4275it [09:44,  5.24it/s]Train epoch: 11 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.005705\n",
      "4300it [09:48,  5.32it/s]Train epoch: 11 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.005341\n",
      "4325it [09:53,  5.03it/s]Train epoch: 11 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.005817\n",
      "4350it [09:58,  5.17it/s]Train epoch: 11 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.006233\n",
      "4375it [10:03,  5.20it/s]Train epoch: 11 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.005863\n",
      "4400it [10:08,  5.10it/s]Train epoch: 11 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.005699\n",
      "4425it [10:13,  5.15it/s]Train epoch: 11 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.005855\n",
      "4450it [10:18,  5.05it/s]Train epoch: 11 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.005621\n",
      "4475it [10:23,  5.06it/s]Train epoch: 11 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.006526\n",
      "4500it [10:28,  5.00it/s]Train epoch: 11 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.006267\n",
      "4525it [10:33,  4.96it/s]Train epoch: 11 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.005807\n",
      "4550it [10:38,  4.96it/s]Train epoch: 11 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.005991\n",
      "4575it [10:43,  4.96it/s]Train epoch: 11 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.005678\n",
      "4600it [10:48,  4.99it/s]Train epoch: 11 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.005851\n",
      "4625it [10:53,  4.94it/s]Train epoch: 11 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.006294\n",
      "4650it [10:58,  4.97it/s]Train epoch: 11 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.006383\n",
      "4675it [11:03,  4.81it/s]Train epoch: 11 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.006254\n",
      "4700it [11:08,  4.69it/s]Train epoch: 11 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.006132\n",
      "4725it [11:13,  4.68it/s]Train epoch: 11 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.006130\n",
      "4750it [11:19,  4.81it/s]Train epoch: 11 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.006089\n",
      "4775it [11:24,  4.74it/s]Train epoch: 11 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.006171\n",
      "4800it [11:29,  4.73it/s]Train epoch: 11 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.006551\n",
      "4825it [11:35,  4.72it/s]Train epoch: 11 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.005720\n",
      "4850it [11:40,  4.76it/s]Train epoch: 11 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.006154\n",
      "4875it [11:45,  4.76it/s]Train epoch: 11 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.006320\n",
      "4900it [11:51,  4.67it/s]Train epoch: 11 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.006303\n",
      "4925it [11:56,  4.56it/s]Train epoch: 11 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.006657\n",
      "4950it [12:02,  4.55it/s]Train epoch: 11 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.006634\n",
      "4975it [12:07,  4.57it/s]Train epoch: 11 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.006777\n",
      "5000it [12:13,  4.53it/s]Train epoch: 11 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.006457\n",
      "5025it [12:18,  4.56it/s]Train epoch: 11 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.007047\n",
      "5050it [12:24,  4.44it/s]Train epoch: 11 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.006871\n",
      "5075it [12:29,  4.44it/s]Train epoch: 11 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.006464\n",
      "5100it [12:35,  4.38it/s]Train epoch: 11 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.006438\n",
      "5125it [12:41,  4.45it/s]Train epoch: 11 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.006955\n",
      "5150it [12:47,  4.36it/s]Train epoch: 11 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.007114\n",
      "5175it [12:52,  4.31it/s]Train epoch: 11 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.006811\n",
      "5200it [12:58,  4.34it/s]Train epoch: 11 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.007206\n",
      "5225it [13:04,  4.22it/s]Train epoch: 11 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.007132\n",
      "5250it [13:10,  4.16it/s]Train epoch: 11 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.006778\n",
      "5275it [13:16,  4.17it/s]Train epoch: 11 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.007047\n",
      "5300it [13:22,  4.17it/s]Train epoch: 11 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.006849\n",
      "5325it [13:28,  4.11it/s]Train epoch: 11 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.006720\n",
      "5350it [13:34,  4.12it/s]Train epoch: 11 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.007261\n",
      "5375it [13:40,  4.05it/s]Train epoch: 11 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.007589\n",
      "5400it [13:46,  4.03it/s]Train epoch: 11 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.007239\n",
      "5425it [13:53,  4.00it/s]Train epoch: 11 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.007153\n",
      "5450it [13:59,  3.94it/s]Train epoch: 11 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.007548\n",
      "5475it [14:05,  3.96it/s]Train epoch: 11 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.007391\n",
      "5500it [14:12,  3.91it/s]Train epoch: 11 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.007504\n",
      "5525it [14:18,  3.84it/s]Train epoch: 11 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.007843\n",
      "5550it [14:25,  3.80it/s]Train epoch: 11 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.008093\n",
      "5575it [14:31,  3.77it/s]Train epoch: 11 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.007168\n",
      "5600it [14:38,  3.70it/s]Train epoch: 11 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.007541\n",
      "5625it [14:45,  3.64it/s]Train epoch: 11 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.008119\n",
      "5650it [14:52,  3.63it/s]Train epoch: 11 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.007244\n",
      "5675it [14:59,  3.53it/s]Train epoch: 11 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.008356\n",
      "5700it [15:06,  3.44it/s]Train epoch: 11 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.007898\n",
      "5725it [15:13,  3.44it/s]Train epoch: 11 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.008256\n",
      "5750it [15:21,  3.34it/s]Train epoch: 11 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.008600\n",
      "5775it [15:28,  3.29it/s]Train epoch: 11 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.008099\n",
      "5800it [15:36,  3.21it/s]Train epoch: 11 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.008586\n",
      "5825it [15:44,  3.16it/s]Train epoch: 11 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.008721\n",
      "5850it [15:52,  3.00it/s]Train epoch: 11 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.008446\n",
      "5875it [16:00,  2.92it/s]Train epoch: 11 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.009226\n",
      "5900it [16:09,  2.75it/s]Train epoch: 11 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.008448\n",
      "5925it [16:19,  2.55it/s]Train epoch: 11 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.009585\n",
      "5950it [16:30,  2.17it/s]Train epoch: 11 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.010411\n",
      "5965it [16:38,  5.98it/s]\n",
      "epoch loss: 0.005095881199692934\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.37it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0225, 0.0380, 0.0326, 0.0351, 0.8458\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2473, 0.5502, 0.3099, 0.3965, 0.9749\n",
      "rec_at_8: 0.3040\n",
      "prec_at_8: 0.5674\n",
      "rec_at_15: 0.4143\n",
      "prec_at_15: 0.4301\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.13it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0218, 0.0423, 0.0316, 0.0362, 0.8461\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2383, 0.5472, 0.2968, 0.3849, 0.9746\n",
      "rec_at_8: 0.2888\n",
      "prec_at_8: 0.5607\n",
      "rec_at_15: 0.3994\n",
      "prec_at_15: 0.4292\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 12\n",
      "0it [00:00, ?it/s]Train epoch: 12 [batch #0, batch_size 8, seq length 512]\tLoss: 0.005001\n",
      "24it [00:01, 15.88it/s]Train epoch: 12 [batch #25, batch_size 8, seq length 512]\tLoss: 0.003531\n",
      "50it [00:03, 14.83it/s]Train epoch: 12 [batch #50, batch_size 8, seq length 512]\tLoss: 0.003173\n",
      "74it [00:05, 13.31it/s]Train epoch: 12 [batch #75, batch_size 8, seq length 512]\tLoss: 0.002862\n",
      "100it [00:06, 13.12it/s]Train epoch: 12 [batch #100, batch_size 8, seq length 512]\tLoss: 0.003161\n",
      "124it [00:08, 12.89it/s]Train epoch: 12 [batch #125, batch_size 8, seq length 512]\tLoss: 0.002971\n",
      "150it [00:10, 12.55it/s]Train epoch: 12 [batch #150, batch_size 8, seq length 512]\tLoss: 0.002922\n",
      "174it [00:12, 12.25it/s]Train epoch: 12 [batch #175, batch_size 8, seq length 512]\tLoss: 0.003197\n",
      "200it [00:15, 12.16it/s]Train epoch: 12 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002608\n",
      "224it [00:17, 11.91it/s]Train epoch: 12 [batch #225, batch_size 8, seq length 512]\tLoss: 0.003033\n",
      "250it [00:19, 11.56it/s]Train epoch: 12 [batch #250, batch_size 8, seq length 512]\tLoss: 0.002845\n",
      "274it [00:21, 11.60it/s]Train epoch: 12 [batch #275, batch_size 8, seq length 512]\tLoss: 0.003067\n",
      "300it [00:23, 11.47it/s]Train epoch: 12 [batch #300, batch_size 8, seq length 512]\tLoss: 0.003172\n",
      "324it [00:25, 10.83it/s]Train epoch: 12 [batch #325, batch_size 8, seq length 512]\tLoss: 0.003069\n",
      "350it [00:28, 11.22it/s]Train epoch: 12 [batch #350, batch_size 8, seq length 512]\tLoss: 0.003024\n",
      "374it [00:30, 10.90it/s]Train epoch: 12 [batch #375, batch_size 8, seq length 512]\tLoss: 0.003046\n",
      "400it [00:32, 10.65it/s]Train epoch: 12 [batch #400, batch_size 8, seq length 512]\tLoss: 0.002896\n",
      "424it [00:34, 10.34it/s]Train epoch: 12 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003335\n",
      "450it [00:37, 10.26it/s]Train epoch: 12 [batch #450, batch_size 8, seq length 512]\tLoss: 0.003008\n",
      "474it [00:39, 10.34it/s]Train epoch: 12 [batch #475, batch_size 8, seq length 512]\tLoss: 0.002878\n",
      "500it [00:42, 10.03it/s]Train epoch: 12 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003387\n",
      "524it [00:44,  9.89it/s]Train epoch: 12 [batch #525, batch_size 8, seq length 512]\tLoss: 0.003071\n",
      "550it [00:47, 10.18it/s]Train epoch: 12 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003412\n",
      "574it [00:49,  9.99it/s]Train epoch: 12 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003440\n",
      "600it [00:52,  9.79it/s]Train epoch: 12 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003268\n",
      "625it [00:54,  9.75it/s]Train epoch: 12 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003215\n",
      "649it [00:57,  9.82it/s]Train epoch: 12 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003375\n",
      "675it [01:00,  9.70it/s]Train epoch: 12 [batch #675, batch_size 8, seq length 512]\tLoss: 0.003989\n",
      "700it [01:02,  9.63it/s]Train epoch: 12 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003368\n",
      "725it [01:05,  9.37it/s]Train epoch: 12 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003361\n",
      "750it [01:07,  9.53it/s]Train epoch: 12 [batch #750, batch_size 8, seq length 512]\tLoss: 0.004020\n",
      "775it [01:10,  9.38it/s]Train epoch: 12 [batch #775, batch_size 8, seq length 512]\tLoss: 0.003107\n",
      "800it [01:13,  9.26it/s]Train epoch: 12 [batch #800, batch_size 8, seq length 512]\tLoss: 0.002938\n",
      "825it [01:15,  9.30it/s]Train epoch: 12 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003409\n",
      "850it [01:18,  9.30it/s]Train epoch: 12 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003352\n",
      "875it [01:21,  9.21it/s]Train epoch: 12 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003566\n",
      "900it [01:24,  9.17it/s]Train epoch: 12 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003427\n",
      "925it [01:26,  9.00it/s]Train epoch: 12 [batch #925, batch_size 8, seq length 512]\tLoss: 0.003563\n",
      "950it [01:29,  9.12it/s]Train epoch: 12 [batch #950, batch_size 8, seq length 512]\tLoss: 0.002778\n",
      "975it [01:32,  9.04it/s]Train epoch: 12 [batch #975, batch_size 8, seq length 512]\tLoss: 0.003584\n",
      "1000it [01:35,  8.92it/s]Train epoch: 12 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003303\n",
      "1025it [01:38,  8.88it/s]Train epoch: 12 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.003208\n",
      "1050it [01:40,  8.94it/s]Train epoch: 12 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003448\n",
      "1075it [01:43,  8.93it/s]Train epoch: 12 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003414\n",
      "1100it [01:46,  8.74it/s]Train epoch: 12 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.003543\n",
      "1125it [01:49,  8.69it/s]Train epoch: 12 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003401\n",
      "1150it [01:52,  8.65it/s]Train epoch: 12 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.002996\n",
      "1175it [01:55,  8.63it/s]Train epoch: 12 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003521\n",
      "1200it [01:58,  8.44it/s]Train epoch: 12 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.003745\n",
      "1225it [02:01,  8.56it/s]Train epoch: 12 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003576\n",
      "1250it [02:03,  8.76it/s]Train epoch: 12 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003320\n",
      "1275it [02:06,  8.44it/s]Train epoch: 12 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.004378\n",
      "1300it [02:09,  8.56it/s]Train epoch: 12 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003525\n",
      "1325it [02:12,  8.32it/s]Train epoch: 12 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.003706\n",
      "1350it [02:15,  8.41it/s]Train epoch: 12 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003259\n",
      "1375it [02:18,  8.41it/s]Train epoch: 12 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.004136\n",
      "1400it [02:21,  8.42it/s]Train epoch: 12 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003506\n",
      "1425it [02:24,  8.28it/s]Train epoch: 12 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.003643\n",
      "1450it [02:27,  8.21it/s]Train epoch: 12 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.003790\n",
      "1475it [02:30,  8.12it/s]Train epoch: 12 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.003768\n",
      "1500it [02:34,  8.01it/s]Train epoch: 12 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004237\n",
      "1525it [02:37,  8.03it/s]Train epoch: 12 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.003843\n",
      "1550it [02:40,  8.07it/s]Train epoch: 12 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.003771\n",
      "1575it [02:43,  8.02it/s]Train epoch: 12 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.003604\n",
      "1600it [02:46,  8.08it/s]Train epoch: 12 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.004210\n",
      "1625it [02:49,  7.89it/s]Train epoch: 12 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.003984\n",
      "1650it [02:52,  7.94it/s]Train epoch: 12 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.004291\n",
      "1675it [02:55,  7.78it/s]Train epoch: 12 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.004009\n",
      "1700it [02:59,  7.80it/s]Train epoch: 12 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.003881\n",
      "1725it [03:02,  7.74it/s]Train epoch: 12 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.004023\n",
      "1750it [03:05,  7.85it/s]Train epoch: 12 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.004013\n",
      "1775it [03:08,  7.75it/s]Train epoch: 12 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.004111\n",
      "1800it [03:11,  7.83it/s]Train epoch: 12 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.004074\n",
      "1825it [03:15,  7.68it/s]Train epoch: 12 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.003902\n",
      "1850it [03:18,  7.82it/s]Train epoch: 12 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.003678\n",
      "1875it [03:21,  7.55it/s]Train epoch: 12 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.004013\n",
      "1900it [03:24,  7.68it/s]Train epoch: 12 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.004598\n",
      "1925it [03:28,  7.63it/s]Train epoch: 12 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.003937\n",
      "1950it [03:31,  7.60it/s]Train epoch: 12 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.004190\n",
      "1975it [03:34,  7.52it/s]Train epoch: 12 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.004256\n",
      "2000it [03:38,  7.62it/s]Train epoch: 12 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.003710\n",
      "2025it [03:41,  7.55it/s]Train epoch: 12 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.003982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050it [03:44,  7.47it/s]Train epoch: 12 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.004270\n",
      "2075it [03:48,  7.35it/s]Train epoch: 12 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.004110\n",
      "2100it [03:51,  7.40it/s]Train epoch: 12 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.004368\n",
      "2125it [03:54,  7.52it/s]Train epoch: 12 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.004129\n",
      "2150it [03:58,  7.25it/s]Train epoch: 12 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004490\n",
      "2175it [04:01,  7.28it/s]Train epoch: 12 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.004139\n",
      "2200it [04:05,  7.19it/s]Train epoch: 12 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.004013\n",
      "2225it [04:08,  7.45it/s]Train epoch: 12 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.004025\n",
      "2250it [04:12,  7.19it/s]Train epoch: 12 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.004568\n",
      "2275it [04:15,  7.35it/s]Train epoch: 12 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.004104\n",
      "2300it [04:19,  6.95it/s]Train epoch: 12 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.003867\n",
      "2325it [04:22,  6.98it/s]Train epoch: 12 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.004567\n",
      "2350it [04:26,  7.08it/s]Train epoch: 12 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.004023\n",
      "2375it [04:29,  7.05it/s]Train epoch: 12 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.004478\n",
      "2400it [04:33,  7.01it/s]Train epoch: 12 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.004370\n",
      "2425it [04:36,  7.01it/s]Train epoch: 12 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.004369\n",
      "2450it [04:40,  7.07it/s]Train epoch: 12 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.004401\n",
      "2475it [04:43,  6.81it/s]Train epoch: 12 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.004123\n",
      "2500it [04:47,  6.86it/s]Train epoch: 12 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.004460\n",
      "2525it [04:51,  6.95it/s]Train epoch: 12 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.004008\n",
      "2550it [04:54,  7.22it/s]Train epoch: 12 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.004247\n",
      "2575it [04:58,  7.01it/s]Train epoch: 12 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.004582\n",
      "2600it [05:02,  6.75it/s]Train epoch: 12 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.004287\n",
      "2625it [05:05,  6.80it/s]Train epoch: 12 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.004340\n",
      "2650it [05:09,  6.78it/s]Train epoch: 12 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.004109\n",
      "2675it [05:13,  6.74it/s]Train epoch: 12 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004455\n",
      "2700it [05:16,  6.65it/s]Train epoch: 12 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.004954\n",
      "2725it [05:20,  6.47it/s]Train epoch: 12 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.004637\n",
      "2750it [05:24,  6.66it/s]Train epoch: 12 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.005187\n",
      "2775it [05:28,  6.74it/s]Train epoch: 12 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.004511\n",
      "2800it [05:31,  6.61it/s]Train epoch: 12 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.004837\n",
      "2825it [05:35,  6.50it/s]Train epoch: 12 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.004132\n",
      "2850it [05:39,  6.59it/s]Train epoch: 12 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.004851\n",
      "2875it [05:43,  6.52it/s]Train epoch: 12 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.005373\n",
      "2900it [05:47,  6.46it/s]Train epoch: 12 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.004706\n",
      "2925it [05:51,  6.50it/s]Train epoch: 12 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.004920\n",
      "2950it [05:54,  6.43it/s]Train epoch: 12 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.005135\n",
      "2975it [05:58,  6.17it/s]Train epoch: 12 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.004542\n",
      "3000it [06:02,  6.52it/s]Train epoch: 12 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.004623\n",
      "3025it [06:06,  6.46it/s]Train epoch: 12 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.004635\n",
      "3050it [06:10,  6.50it/s]Train epoch: 12 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.004504\n",
      "3075it [06:14,  6.27it/s]Train epoch: 12 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.004731\n",
      "3100it [06:18,  6.33it/s]Train epoch: 12 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.004649\n",
      "3125it [06:22,  6.35it/s]Train epoch: 12 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.004386\n",
      "3150it [06:26,  6.33it/s]Train epoch: 12 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.004775\n",
      "3175it [06:30,  6.28it/s]Train epoch: 12 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.005161\n",
      "3200it [06:34,  6.22it/s]Train epoch: 12 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004474\n",
      "3225it [06:38,  6.28it/s]Train epoch: 12 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.004738\n",
      "3250it [06:42,  6.15it/s]Train epoch: 12 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.005016\n",
      "3275it [06:46,  6.33it/s]Train epoch: 12 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.004979\n",
      "3300it [06:50,  6.10it/s]Train epoch: 12 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.005232\n",
      "3325it [06:54,  6.17it/s]Train epoch: 12 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.005144\n",
      "3350it [06:58,  6.09it/s]Train epoch: 12 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.005140\n",
      "3375it [07:03,  6.07it/s]Train epoch: 12 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.004554\n",
      "3400it [07:07,  6.05it/s]Train epoch: 12 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.005081\n",
      "3425it [07:11,  6.17it/s]Train epoch: 12 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.004961\n",
      "3450it [07:15,  5.94it/s]Train epoch: 12 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.004907\n",
      "3475it [07:19,  6.04it/s]Train epoch: 12 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.005473\n",
      "3500it [07:23,  5.96it/s]Train epoch: 12 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.004904\n",
      "3525it [07:28,  5.83it/s]Train epoch: 12 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.004906\n",
      "3550it [07:32,  5.91it/s]Train epoch: 12 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.005215\n",
      "3575it [07:36,  5.66it/s]Train epoch: 12 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.005330\n",
      "3600it [07:41,  5.90it/s]Train epoch: 12 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.005531\n",
      "3625it [07:45,  5.85it/s]Train epoch: 12 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.004867\n",
      "3650it [07:49,  5.76it/s]Train epoch: 12 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.005355\n",
      "3675it [07:53,  5.84it/s]Train epoch: 12 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.005562\n",
      "3700it [07:58,  5.85it/s]Train epoch: 12 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.004985\n",
      "3725it [08:02,  5.69it/s]Train epoch: 12 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.005413\n",
      "3750it [08:06,  5.56it/s]Train epoch: 12 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.005127\n",
      "3775it [08:11,  5.71it/s]Train epoch: 12 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.005397\n",
      "3800it [08:15,  5.73it/s]Train epoch: 12 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.005778\n",
      "3825it [08:20,  5.64it/s]Train epoch: 12 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.005249\n",
      "3850it [08:24,  5.69it/s]Train epoch: 12 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.005098\n",
      "3875it [08:29,  5.37it/s]Train epoch: 12 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.005378\n",
      "3900it [08:33,  5.56it/s]Train epoch: 12 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.005538\n",
      "3925it [08:37,  5.62it/s]Train epoch: 12 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.004852\n",
      "3950it [08:42,  5.51it/s]Train epoch: 12 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.005164\n",
      "3975it [08:47,  5.48it/s]Train epoch: 12 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.005525\n",
      "4000it [08:51,  5.56it/s]Train epoch: 12 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.005158\n",
      "4025it [08:56,  5.57it/s]Train epoch: 12 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.005058\n",
      "4050it [09:00,  5.43it/s]Train epoch: 12 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.005118\n",
      "4075it [09:05,  5.45it/s]Train epoch: 12 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.005039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100it [09:09,  5.46it/s]Train epoch: 12 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.005366\n",
      "4125it [09:14,  5.42it/s]Train epoch: 12 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.005389\n",
      "4150it [09:19,  5.23it/s]Train epoch: 12 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.005662\n",
      "4175it [09:23,  5.33it/s]Train epoch: 12 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.005249\n",
      "4200it [09:28,  5.28it/s]Train epoch: 12 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.004938\n",
      "4225it [09:33,  5.24it/s]Train epoch: 12 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.005506\n",
      "4250it [09:38,  5.20it/s]Train epoch: 12 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.005971\n",
      "4275it [09:42,  5.33it/s]Train epoch: 12 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.005530\n",
      "4300it [09:47,  5.03it/s]Train epoch: 12 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.005254\n",
      "4325it [09:52,  5.05it/s]Train epoch: 12 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.005677\n",
      "4350it [09:57,  5.23it/s]Train epoch: 12 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.006091\n",
      "4375it [10:02,  5.11it/s]Train epoch: 12 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.005652\n",
      "4400it [10:07,  5.17it/s]Train epoch: 12 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.005558\n",
      "4425it [10:12,  5.05it/s]Train epoch: 12 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.005692\n",
      "4450it [10:16,  5.05it/s]Train epoch: 12 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.005472\n",
      "4475it [10:21,  4.92it/s]Train epoch: 12 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.006419\n",
      "4500it [10:26,  5.00it/s]Train epoch: 12 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.006102\n",
      "4525it [10:31,  4.98it/s]Train epoch: 12 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.005721\n",
      "4550it [10:36,  4.98it/s]Train epoch: 12 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.005752\n",
      "4575it [10:42,  5.00it/s]Train epoch: 12 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.005505\n",
      "4600it [10:47,  5.02it/s]Train epoch: 12 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.005694\n",
      "4625it [10:52,  4.96it/s]Train epoch: 12 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.006155\n",
      "4650it [10:57,  4.97it/s]Train epoch: 12 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.006226\n",
      "4675it [11:02,  4.89it/s]Train epoch: 12 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.006157\n",
      "4700it [11:07,  4.84it/s]Train epoch: 12 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.005944\n",
      "4725it [11:12,  4.83it/s]Train epoch: 12 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.005978\n",
      "4750it [11:17,  4.63it/s]Train epoch: 12 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.006002\n",
      "4775it [11:23,  4.79it/s]Train epoch: 12 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.006069\n",
      "4800it [11:28,  4.75it/s]Train epoch: 12 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.006458\n",
      "4825it [11:33,  4.70it/s]Train epoch: 12 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.005548\n",
      "4850it [11:38,  4.67it/s]Train epoch: 12 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.006042\n",
      "4875it [11:44,  4.67it/s]Train epoch: 12 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.006220\n",
      "4900it [11:49,  4.54it/s]Train epoch: 12 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.006191\n",
      "4925it [11:55,  4.61it/s]Train epoch: 12 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.006577\n",
      "4950it [12:00,  4.61it/s]Train epoch: 12 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.006515\n",
      "4975it [12:06,  4.49it/s]Train epoch: 12 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.006613\n",
      "5000it [12:11,  4.44it/s]Train epoch: 12 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.006325\n",
      "5025it [12:17,  4.57it/s]Train epoch: 12 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.006885\n",
      "5050it [12:22,  4.51it/s]Train epoch: 12 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.006731\n",
      "5075it [12:28,  4.45it/s]Train epoch: 12 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.006328\n",
      "5100it [12:33,  4.41it/s]Train epoch: 12 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.006344\n",
      "5125it [12:39,  4.35it/s]Train epoch: 12 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.006861\n",
      "5150it [12:45,  4.43it/s]Train epoch: 12 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.006943\n",
      "5175it [12:51,  4.32it/s]Train epoch: 12 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.006667\n",
      "5200it [12:56,  4.31it/s]Train epoch: 12 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.007043\n",
      "5225it [13:02,  4.26it/s]Train epoch: 12 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.007034\n",
      "5250it [13:08,  4.18it/s]Train epoch: 12 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.006646\n",
      "5275it [13:14,  4.18it/s]Train epoch: 12 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.006933\n",
      "5300it [13:20,  4.20it/s]Train epoch: 12 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.006678\n",
      "5325it [13:26,  4.15it/s]Train epoch: 12 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.006645\n",
      "5350it [13:32,  4.23it/s]Train epoch: 12 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.007114\n",
      "5375it [13:38,  4.05it/s]Train epoch: 12 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.007433\n",
      "5400it [13:45,  3.96it/s]Train epoch: 12 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.007073\n",
      "5425it [13:51,  4.00it/s]Train epoch: 12 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.007109\n",
      "5450it [13:57,  4.05it/s]Train epoch: 12 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.007273\n",
      "5475it [14:03,  3.98it/s]Train epoch: 12 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.007193\n",
      "5500it [14:10,  3.80it/s]Train epoch: 12 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.007386\n",
      "5525it [14:16,  3.82it/s]Train epoch: 12 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.007674\n",
      "5550it [14:23,  3.85it/s]Train epoch: 12 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.007919\n",
      "5575it [14:29,  3.77it/s]Train epoch: 12 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.007095\n",
      "5600it [14:36,  3.75it/s]Train epoch: 12 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.007416\n",
      "5625it [14:43,  3.61it/s]Train epoch: 12 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.007951\n",
      "5650it [14:50,  3.63it/s]Train epoch: 12 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.007027\n",
      "5675it [14:57,  3.57it/s]Train epoch: 12 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.008228\n",
      "5700it [15:04,  3.48it/s]Train epoch: 12 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.007662\n",
      "5725it [15:11,  3.43it/s]Train epoch: 12 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.008077\n",
      "5750it [15:18,  3.36it/s]Train epoch: 12 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.008486\n",
      "5775it [15:26,  3.30it/s]Train epoch: 12 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.007921\n",
      "5800it [15:34,  3.23it/s]Train epoch: 12 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.008361\n",
      "5825it [15:42,  3.13it/s]Train epoch: 12 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.008624\n",
      "5850it [15:50,  3.01it/s]Train epoch: 12 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.008297\n",
      "5875it [15:58,  2.87it/s]Train epoch: 12 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.009018\n",
      "5900it [16:07,  2.76it/s]Train epoch: 12 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.008255\n",
      "5925it [16:17,  2.56it/s]Train epoch: 12 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.009425\n",
      "5950it [16:27,  2.18it/s]Train epoch: 12 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.010258\n",
      "5965it [16:35,  5.99it/s]\n",
      "epoch loss: 0.004980515141730186\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.18it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0230, 0.0392, 0.0331, 0.0359, 0.8448\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2484, 0.5467, 0.3128, 0.3979, 0.9748\n",
      "rec_at_8: 0.3048\n",
      "prec_at_8: 0.5686\n",
      "rec_at_15: 0.4156\n",
      "prec_at_15: 0.4310\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 46.97it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0228, 0.0447, 0.0325, 0.0376, 0.8452\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2398, 0.5438, 0.3003, 0.3869, 0.9744\n",
      "rec_at_8: 0.2895\n",
      "prec_at_8: 0.5613\n",
      "rec_at_15: 0.4008\n",
      "prec_at_15: 0.4300\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 13\n",
      "0it [00:00, ?it/s]Train epoch: 13 [batch #0, batch_size 8, seq length 512]\tLoss: 0.004853\n",
      "25it [00:01, 15.79it/s]Train epoch: 13 [batch #25, batch_size 8, seq length 512]\tLoss: 0.003439\n",
      "49it [00:03, 13.95it/s]Train epoch: 13 [batch #50, batch_size 8, seq length 512]\tLoss: 0.003098\n",
      "75it [00:05, 13.68it/s]Train epoch: 13 [batch #75, batch_size 8, seq length 512]\tLoss: 0.002799\n",
      "99it [00:06, 13.38it/s]Train epoch: 13 [batch #100, batch_size 8, seq length 512]\tLoss: 0.003111\n",
      "125it [00:08, 12.66it/s]Train epoch: 13 [batch #125, batch_size 8, seq length 512]\tLoss: 0.002884\n",
      "149it [00:10, 12.89it/s]Train epoch: 13 [batch #150, batch_size 8, seq length 512]\tLoss: 0.002908\n",
      "175it [00:13, 12.05it/s]Train epoch: 13 [batch #175, batch_size 8, seq length 512]\tLoss: 0.003120\n",
      "199it [00:14, 12.40it/s]Train epoch: 13 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002570\n",
      "225it [00:17, 11.73it/s]Train epoch: 13 [batch #225, batch_size 8, seq length 512]\tLoss: 0.002908\n",
      "249it [00:19, 11.66it/s]Train epoch: 13 [batch #250, batch_size 8, seq length 512]\tLoss: 0.002806\n",
      "275it [00:21, 12.08it/s]Train epoch: 13 [batch #275, batch_size 8, seq length 512]\tLoss: 0.002957\n",
      "299it [00:23, 11.38it/s]Train epoch: 13 [batch #300, batch_size 8, seq length 512]\tLoss: 0.003102\n",
      "325it [00:25, 11.37it/s]Train epoch: 13 [batch #325, batch_size 8, seq length 512]\tLoss: 0.003015\n",
      "349it [00:27, 11.12it/s]Train epoch: 13 [batch #350, batch_size 8, seq length 512]\tLoss: 0.002940\n",
      "375it [00:30, 10.89it/s]Train epoch: 13 [batch #375, batch_size 8, seq length 512]\tLoss: 0.002943\n",
      "399it [00:32, 10.88it/s]Train epoch: 13 [batch #400, batch_size 8, seq length 512]\tLoss: 0.002810\n",
      "425it [00:35, 10.35it/s]Train epoch: 13 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003276\n",
      "450it [00:37, 10.01it/s]Train epoch: 13 [batch #450, batch_size 8, seq length 512]\tLoss: 0.002941\n",
      "474it [00:39, 10.17it/s]Train epoch: 13 [batch #475, batch_size 8, seq length 512]\tLoss: 0.002807\n",
      "500it [00:42, 10.12it/s]Train epoch: 13 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003341\n",
      "524it [00:44, 10.15it/s]Train epoch: 13 [batch #525, batch_size 8, seq length 512]\tLoss: 0.003018\n",
      "550it [00:47,  9.93it/s]Train epoch: 13 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003338\n",
      "575it [00:50,  9.79it/s]Train epoch: 13 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003336\n",
      "600it [00:52,  9.80it/s]Train epoch: 13 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003185\n",
      "625it [00:55,  9.41it/s]Train epoch: 13 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003149\n",
      "650it [00:57,  9.60it/s]Train epoch: 13 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003294\n",
      "675it [01:00,  9.03it/s]Train epoch: 13 [batch #675, batch_size 8, seq length 512]\tLoss: 0.003886\n",
      "700it [01:03,  9.48it/s]Train epoch: 13 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003323\n",
      "725it [01:05,  9.14it/s]Train epoch: 13 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003289\n",
      "750it [01:08,  9.58it/s]Train epoch: 13 [batch #750, batch_size 8, seq length 512]\tLoss: 0.003959\n",
      "775it [01:11,  9.20it/s]Train epoch: 13 [batch #775, batch_size 8, seq length 512]\tLoss: 0.003024\n",
      "800it [01:13,  9.27it/s]Train epoch: 13 [batch #800, batch_size 8, seq length 512]\tLoss: 0.002875\n",
      "824it [01:16,  9.34it/s]Train epoch: 13 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003309\n",
      "850it [01:19,  9.05it/s]Train epoch: 13 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003282\n",
      "875it [01:21,  9.04it/s]Train epoch: 13 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003516\n",
      "900it [01:24,  9.16it/s]Train epoch: 13 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003354\n",
      "925it [01:27,  9.20it/s]Train epoch: 13 [batch #925, batch_size 8, seq length 512]\tLoss: 0.003484\n",
      "950it [01:30,  9.13it/s]Train epoch: 13 [batch #950, batch_size 8, seq length 512]\tLoss: 0.002696\n",
      "975it [01:32,  8.81it/s]Train epoch: 13 [batch #975, batch_size 8, seq length 512]\tLoss: 0.003505\n",
      "1000it [01:35,  8.71it/s]Train epoch: 13 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003281\n",
      "1025it [01:38,  8.82it/s]Train epoch: 13 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.003143\n",
      "1050it [01:41,  8.81it/s]Train epoch: 13 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003372\n",
      "1075it [01:44,  8.74it/s]Train epoch: 13 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003313\n",
      "1100it [01:47,  8.55it/s]Train epoch: 13 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.003468\n",
      "1125it [01:49,  8.86it/s]Train epoch: 13 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003286\n",
      "1150it [01:52,  8.63it/s]Train epoch: 13 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.002959\n",
      "1175it [01:55,  8.65it/s]Train epoch: 13 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003447\n",
      "1200it [01:58,  8.65it/s]Train epoch: 13 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.003653\n",
      "1225it [02:01,  8.46it/s]Train epoch: 13 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003544\n",
      "1250it [02:04,  8.48it/s]Train epoch: 13 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003221\n",
      "1275it [02:07,  8.71it/s]Train epoch: 13 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.004287\n",
      "1300it [02:10,  8.18it/s]Train epoch: 13 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003445\n",
      "1325it [02:13,  8.36it/s]Train epoch: 13 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.003633\n",
      "1350it [02:16,  8.26it/s]Train epoch: 13 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003193\n",
      "1375it [02:19,  8.27it/s]Train epoch: 13 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.004054\n",
      "1400it [02:22,  8.23it/s]Train epoch: 13 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003418\n",
      "1425it [02:25,  8.15it/s]Train epoch: 13 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.003571\n",
      "1450it [02:28,  7.76it/s]Train epoch: 13 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.003720\n",
      "1475it [02:31,  8.08it/s]Train epoch: 13 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.003681\n",
      "1500it [02:35,  7.84it/s]Train epoch: 13 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004152\n",
      "1525it [02:38,  8.09it/s]Train epoch: 13 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.003721\n",
      "1550it [02:41,  7.97it/s]Train epoch: 13 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.003660\n",
      "1575it [02:44,  7.86it/s]Train epoch: 13 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.003494\n",
      "1600it [02:47,  7.98it/s]Train epoch: 13 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.004145\n",
      "1625it [02:50,  8.03it/s]Train epoch: 13 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.003941\n",
      "1650it [02:53,  7.85it/s]Train epoch: 13 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.004211\n",
      "1675it [02:56,  7.90it/s]Train epoch: 13 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.003936\n",
      "1700it [03:00,  7.61it/s]Train epoch: 13 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.003808\n",
      "1725it [03:03,  7.88it/s]Train epoch: 13 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.003916\n",
      "1750it [03:06,  7.72it/s]Train epoch: 13 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.003889\n",
      "1775it [03:09,  7.67it/s]Train epoch: 13 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.004041\n",
      "1800it [03:13,  7.81it/s]Train epoch: 13 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.003991\n",
      "1825it [03:16,  7.51it/s]Train epoch: 13 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.003770\n",
      "1850it [03:19,  7.52it/s]Train epoch: 13 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.003566\n",
      "1875it [03:23,  7.50it/s]Train epoch: 13 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.003878\n",
      "1900it [03:26,  7.45it/s]Train epoch: 13 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.004475\n",
      "1925it [03:29,  7.49it/s]Train epoch: 13 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.003800\n",
      "1950it [03:32,  7.37it/s]Train epoch: 13 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.004112\n",
      "1975it [03:36,  7.64it/s]Train epoch: 13 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.004176\n",
      "2000it [03:39,  7.46it/s]Train epoch: 13 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.003621\n",
      "2025it [03:43,  7.64it/s]Train epoch: 13 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.003864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050it [03:46,  7.42it/s]Train epoch: 13 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.004176\n",
      "2075it [03:49,  7.51it/s]Train epoch: 13 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.004004\n",
      "2100it [03:53,  7.32it/s]Train epoch: 13 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.004289\n",
      "2125it [03:56,  7.49it/s]Train epoch: 13 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.003985\n",
      "2150it [03:59,  7.19it/s]Train epoch: 13 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004374\n",
      "2175it [04:03,  7.48it/s]Train epoch: 13 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.004037\n",
      "2200it [04:06,  7.31it/s]Train epoch: 13 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.003859\n",
      "2225it [04:10,  7.22it/s]Train epoch: 13 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.003946\n",
      "2250it [04:13,  7.09it/s]Train epoch: 13 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.004424\n",
      "2275it [04:17,  7.19it/s]Train epoch: 13 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.004020\n",
      "2300it [04:20,  7.07it/s]Train epoch: 13 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.003737\n",
      "2325it [04:24,  7.08it/s]Train epoch: 13 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.004472\n",
      "2350it [04:27,  6.90it/s]Train epoch: 13 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.003938\n",
      "2375it [04:31,  7.04it/s]Train epoch: 13 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.004341\n",
      "2400it [04:35,  6.99it/s]Train epoch: 13 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.004239\n",
      "2425it [04:38,  6.76it/s]Train epoch: 13 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.004269\n",
      "2450it [04:42,  6.95it/s]Train epoch: 13 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.004289\n",
      "2475it [04:45,  6.97it/s]Train epoch: 13 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.003973\n",
      "2500it [04:49,  6.78it/s]Train epoch: 13 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.004261\n",
      "2525it [04:53,  6.76it/s]Train epoch: 13 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.003984\n",
      "2550it [04:56,  6.60it/s]Train epoch: 13 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.004225\n",
      "2575it [05:00,  6.94it/s]Train epoch: 13 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.004549\n",
      "2600it [05:04,  6.74it/s]Train epoch: 13 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.004178\n",
      "2625it [05:08,  6.66it/s]Train epoch: 13 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.004253\n",
      "2650it [05:11,  6.70it/s]Train epoch: 13 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.004028\n",
      "2675it [05:15,  6.64it/s]Train epoch: 13 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004387\n",
      "2700it [05:19,  6.59it/s]Train epoch: 13 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.004794\n",
      "2725it [05:22,  6.47it/s]Train epoch: 13 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.004508\n",
      "2750it [05:26,  6.63it/s]Train epoch: 13 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.005052\n",
      "2775it [05:30,  6.62it/s]Train epoch: 13 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.004375\n",
      "2800it [05:34,  6.65it/s]Train epoch: 13 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.004680\n",
      "2825it [05:38,  6.54it/s]Train epoch: 13 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.004003\n",
      "2850it [05:41,  6.48it/s]Train epoch: 13 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.004721\n",
      "2875it [05:45,  6.73it/s]Train epoch: 13 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.005231\n",
      "2900it [05:49,  6.40it/s]Train epoch: 13 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.004630\n",
      "2925it [05:53,  6.46it/s]Train epoch: 13 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.004810\n",
      "2950it [05:57,  6.50it/s]Train epoch: 13 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.004992\n",
      "2975it [06:01,  6.42it/s]Train epoch: 13 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.004406\n",
      "3000it [06:05,  6.38it/s]Train epoch: 13 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.004529\n",
      "3025it [06:09,  6.28it/s]Train epoch: 13 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.004535\n",
      "3050it [06:12,  6.47it/s]Train epoch: 13 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.004413\n",
      "3075it [06:16,  6.38it/s]Train epoch: 13 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.004641\n",
      "3100it [06:20,  6.34it/s]Train epoch: 13 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.004612\n",
      "3125it [06:24,  6.17it/s]Train epoch: 13 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.004367\n",
      "3150it [06:28,  6.36it/s]Train epoch: 13 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.004637\n",
      "3175it [06:32,  6.28it/s]Train epoch: 13 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.004993\n",
      "3200it [06:36,  6.20it/s]Train epoch: 13 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004377\n",
      "3225it [06:40,  6.32it/s]Train epoch: 13 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.004685\n",
      "3250it [06:44,  6.24it/s]Train epoch: 13 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.004931\n",
      "3275it [06:48,  5.99it/s]Train epoch: 13 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.004821\n",
      "3300it [06:53,  6.28it/s]Train epoch: 13 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.005048\n",
      "3325it [06:57,  6.10it/s]Train epoch: 13 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.005019\n",
      "3350it [07:01,  5.85it/s]Train epoch: 13 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.005004\n",
      "3375it [07:05,  5.97it/s]Train epoch: 13 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.004473\n",
      "3400it [07:09,  6.06it/s]Train epoch: 13 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.004965\n",
      "3425it [07:13,  5.99it/s]Train epoch: 13 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.004874\n",
      "3450it [07:17,  6.01it/s]Train epoch: 13 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.004794\n",
      "3475it [07:22,  5.90it/s]Train epoch: 13 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.005386\n",
      "3500it [07:26,  5.97it/s]Train epoch: 13 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.004780\n",
      "3525it [07:30,  5.91it/s]Train epoch: 13 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.004761\n",
      "3550it [07:34,  6.03it/s]Train epoch: 13 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.005101\n",
      "3575it [07:39,  5.68it/s]Train epoch: 13 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.005183\n",
      "3600it [07:43,  5.79it/s]Train epoch: 13 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.005350\n",
      "3625it [07:47,  5.87it/s]Train epoch: 13 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.004720\n",
      "3650it [07:51,  5.82it/s]Train epoch: 13 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.005246\n",
      "3675it [07:56,  5.74it/s]Train epoch: 13 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.005478\n",
      "3700it [08:00,  5.65it/s]Train epoch: 13 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.004889\n",
      "3725it [08:05,  5.74it/s]Train epoch: 13 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.005310\n",
      "3750it [08:09,  5.75it/s]Train epoch: 13 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.004981\n",
      "3775it [08:13,  5.69it/s]Train epoch: 13 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.005327\n",
      "3800it [08:18,  5.67it/s]Train epoch: 13 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.005638\n",
      "3825it [08:22,  5.63it/s]Train epoch: 13 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.005147\n",
      "3850it [08:26,  5.66it/s]Train epoch: 13 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.004988\n",
      "3875it [08:31,  5.59it/s]Train epoch: 13 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.005282\n",
      "3900it [08:35,  5.56it/s]Train epoch: 13 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.005371\n",
      "3925it [08:40,  5.58it/s]Train epoch: 13 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.004756\n",
      "3950it [08:44,  5.56it/s]Train epoch: 13 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.005015\n",
      "3975it [08:49,  5.58it/s]Train epoch: 13 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.005426\n",
      "4000it [08:54,  5.54it/s]Train epoch: 13 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.005064\n",
      "4025it [08:58,  5.54it/s]Train epoch: 13 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.004964\n",
      "4050it [09:03,  5.51it/s]Train epoch: 13 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.005031\n",
      "4075it [09:07,  5.44it/s]Train epoch: 13 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.004933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100it [09:12,  5.39it/s]Train epoch: 13 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.005245\n",
      "4125it [09:16,  5.39it/s]Train epoch: 13 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.005295\n",
      "4150it [09:21,  5.36it/s]Train epoch: 13 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.005542\n",
      "4175it [09:26,  5.46it/s]Train epoch: 13 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.005133\n",
      "4200it [09:31,  5.32it/s]Train epoch: 13 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.004868\n",
      "4225it [09:35,  5.20it/s]Train epoch: 13 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.005375\n",
      "4250it [09:40,  5.31it/s]Train epoch: 13 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.005881\n",
      "4275it [09:45,  5.23it/s]Train epoch: 13 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.005420\n",
      "4300it [09:50,  5.20it/s]Train epoch: 13 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.005172\n",
      "4325it [09:54,  5.30it/s]Train epoch: 13 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.005626\n",
      "4350it [09:59,  5.07it/s]Train epoch: 13 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.005938\n",
      "4375it [10:04,  5.05it/s]Train epoch: 13 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.005570\n",
      "4400it [10:09,  5.22it/s]Train epoch: 13 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.005415\n",
      "4425it [10:14,  5.12it/s]Train epoch: 13 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.005623\n",
      "4450it [10:19,  5.13it/s]Train epoch: 13 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.005388\n",
      "4475it [10:24,  4.92it/s]Train epoch: 13 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.006235\n",
      "4500it [10:29,  4.91it/s]Train epoch: 13 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.005952\n",
      "4525it [10:34,  4.93it/s]Train epoch: 13 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.005607\n",
      "4550it [10:39,  5.01it/s]Train epoch: 13 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.005673\n",
      "4575it [10:44,  4.95it/s]Train epoch: 13 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.005353\n",
      "4600it [10:49,  4.91it/s]Train epoch: 13 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.005606\n",
      "4625it [10:54,  4.94it/s]Train epoch: 13 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.006057\n",
      "4650it [10:59,  4.87it/s]Train epoch: 13 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.006141\n",
      "4675it [11:04,  4.92it/s]Train epoch: 13 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.005947\n",
      "4700it [11:09,  4.82it/s]Train epoch: 13 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.005896\n",
      "4725it [11:14,  4.81it/s]Train epoch: 13 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.005851\n",
      "4750it [11:20,  4.81it/s]Train epoch: 13 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.005846\n",
      "4775it [11:25,  4.77it/s]Train epoch: 13 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.006047\n",
      "4800it [11:30,  4.66it/s]Train epoch: 13 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.006292\n",
      "4825it [11:36,  4.75it/s]Train epoch: 13 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.005454\n",
      "4850it [11:41,  4.71it/s]Train epoch: 13 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.005889\n",
      "4875it [11:46,  4.76it/s]Train epoch: 13 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.006122\n",
      "4900it [11:52,  4.52it/s]Train epoch: 13 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.006006\n",
      "4925it [11:57,  4.61it/s]Train epoch: 13 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.006415\n",
      "4950it [12:02,  4.56it/s]Train epoch: 13 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.006409\n",
      "4975it [12:08,  4.67it/s]Train epoch: 13 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.006473\n",
      "5000it [12:13,  4.52it/s]Train epoch: 13 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.006200\n",
      "5025it [12:19,  4.50it/s]Train epoch: 13 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.006802\n",
      "5050it [12:25,  4.45it/s]Train epoch: 13 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.006620\n",
      "5075it [12:30,  4.43it/s]Train epoch: 13 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.006209\n",
      "5100it [12:36,  4.40it/s]Train epoch: 13 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.006201\n",
      "5125it [12:42,  4.37it/s]Train epoch: 13 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.006708\n",
      "5150it [12:47,  4.24it/s]Train epoch: 13 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.006822\n",
      "5175it [12:53,  4.35it/s]Train epoch: 13 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.006539\n",
      "5200it [12:59,  4.28it/s]Train epoch: 13 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.006901\n",
      "5225it [13:05,  4.27it/s]Train epoch: 13 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.006913\n",
      "5250it [13:11,  4.25it/s]Train epoch: 13 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.006493\n",
      "5275it [13:17,  4.17it/s]Train epoch: 13 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.006864\n",
      "5300it [13:23,  4.17it/s]Train epoch: 13 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.006613\n",
      "5325it [13:29,  4.11it/s]Train epoch: 13 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.006564\n",
      "5350it [13:35,  4.13it/s]Train epoch: 13 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.007009\n",
      "5375it [13:41,  4.06it/s]Train epoch: 13 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.007312\n",
      "5400it [13:47,  4.01it/s]Train epoch: 13 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.006885\n",
      "5425it [13:53,  3.97it/s]Train epoch: 13 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.006942\n",
      "5450it [14:00,  3.93it/s]Train epoch: 13 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.007218\n",
      "5475it [14:06,  3.93it/s]Train epoch: 13 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.007072\n",
      "5500it [14:13,  3.90it/s]Train epoch: 13 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.007201\n",
      "5525it [14:19,  3.79it/s]Train epoch: 13 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.007556\n",
      "5550it [14:26,  3.83it/s]Train epoch: 13 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.007768\n",
      "5575it [14:32,  3.75it/s]Train epoch: 13 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.006970\n",
      "5600it [14:39,  3.72it/s]Train epoch: 13 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.007235\n",
      "5625it [14:46,  3.66it/s]Train epoch: 13 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.007804\n",
      "5650it [14:53,  3.60it/s]Train epoch: 13 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.006948\n",
      "5675it [15:00,  3.57it/s]Train epoch: 13 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.008068\n",
      "5700it [15:07,  3.44it/s]Train epoch: 13 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.007575\n",
      "5725it [15:14,  3.42it/s]Train epoch: 13 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.007958\n",
      "5750it [15:22,  3.34it/s]Train epoch: 13 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.008330\n",
      "5775it [15:29,  3.30it/s]Train epoch: 13 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.007698\n",
      "5800it [15:37,  3.22it/s]Train epoch: 13 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.008183\n",
      "5825it [15:45,  3.16it/s]Train epoch: 13 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.008352\n",
      "5850it [15:53,  3.02it/s]Train epoch: 13 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.008168\n",
      "5875it [16:01,  2.85it/s]Train epoch: 13 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.008854\n",
      "5900it [16:10,  2.73it/s]Train epoch: 13 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.008183\n",
      "5925it [16:20,  2.56it/s]Train epoch: 13 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.009295\n",
      "5950it [16:31,  2.18it/s]Train epoch: 13 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.010107\n",
      "5965it [16:39,  5.97it/s]\n",
      "epoch loss: 0.004873072129087983\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.28it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0251, 0.0412, 0.0362, 0.0386, 0.8441\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2505, 0.5444, 0.3169, 0.4006, 0.9744\n",
      "rec_at_8: 0.3076\n",
      "prec_at_8: 0.5737\n",
      "rec_at_15: 0.4170\n",
      "prec_at_15: 0.4322\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.23it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0245, 0.0457, 0.0356, 0.0400, 0.8456\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2433, 0.5430, 0.3059, 0.3914, 0.9741\n",
      "rec_at_8: 0.2928\n",
      "prec_at_8: 0.5658\n",
      "rec_at_15: 0.4038\n",
      "prec_at_15: 0.4328\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 14\n",
      "0it [00:00, ?it/s]Train epoch: 14 [batch #0, batch_size 8, seq length 512]\tLoss: 0.004796\n",
      "25it [00:01, 15.79it/s]Train epoch: 14 [batch #25, batch_size 8, seq length 512]\tLoss: 0.003434\n",
      "49it [00:03, 14.52it/s]Train epoch: 14 [batch #50, batch_size 8, seq length 512]\tLoss: 0.003021\n",
      "75it [00:05, 13.52it/s]Train epoch: 14 [batch #75, batch_size 8, seq length 512]\tLoss: 0.002724\n",
      "99it [00:06, 13.70it/s]Train epoch: 14 [batch #100, batch_size 8, seq length 512]\tLoss: 0.003027\n",
      "125it [00:08, 13.01it/s]Train epoch: 14 [batch #125, batch_size 8, seq length 512]\tLoss: 0.002800\n",
      "149it [00:10, 12.23it/s]Train epoch: 14 [batch #150, batch_size 8, seq length 512]\tLoss: 0.002784\n",
      "175it [00:13, 12.09it/s]Train epoch: 14 [batch #175, batch_size 8, seq length 512]\tLoss: 0.003051\n",
      "199it [00:15, 11.80it/s]Train epoch: 14 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002478\n",
      "225it [00:17, 11.97it/s]Train epoch: 14 [batch #225, batch_size 8, seq length 512]\tLoss: 0.002886\n",
      "249it [00:19, 11.50it/s]Train epoch: 14 [batch #250, batch_size 8, seq length 512]\tLoss: 0.002760\n",
      "275it [00:21, 11.53it/s]Train epoch: 14 [batch #275, batch_size 8, seq length 512]\tLoss: 0.002879\n",
      "299it [00:23, 11.47it/s]Train epoch: 14 [batch #300, batch_size 8, seq length 512]\tLoss: 0.003021\n",
      "325it [00:25, 10.97it/s]Train epoch: 14 [batch #325, batch_size 8, seq length 512]\tLoss: 0.002952\n",
      "349it [00:28, 11.04it/s]Train epoch: 14 [batch #350, batch_size 8, seq length 512]\tLoss: 0.002841\n",
      "375it [00:30, 10.99it/s]Train epoch: 14 [batch #375, batch_size 8, seq length 512]\tLoss: 0.002890\n",
      "399it [00:32, 10.77it/s]Train epoch: 14 [batch #400, batch_size 8, seq length 512]\tLoss: 0.002750\n",
      "425it [00:35, 10.53it/s]Train epoch: 14 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003163\n",
      "449it [00:37,  9.96it/s]Train epoch: 14 [batch #450, batch_size 8, seq length 512]\tLoss: 0.002848\n",
      "475it [00:40, 10.30it/s]Train epoch: 14 [batch #475, batch_size 8, seq length 512]\tLoss: 0.002726\n",
      "499it [00:42,  9.98it/s]Train epoch: 14 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003254\n",
      "525it [00:45, 10.16it/s]Train epoch: 14 [batch #525, batch_size 8, seq length 512]\tLoss: 0.002941\n",
      "549it [00:47,  9.71it/s]Train epoch: 14 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003218\n",
      "574it [00:49,  9.66it/s]Train epoch: 14 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003303\n",
      "600it [00:52,  9.84it/s]Train epoch: 14 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003101\n",
      "625it [00:55,  9.47it/s]Train epoch: 14 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003068\n",
      "650it [00:57,  9.86it/s]Train epoch: 14 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003164\n",
      "675it [01:00,  9.66it/s]Train epoch: 14 [batch #675, batch_size 8, seq length 512]\tLoss: 0.003795\n",
      "699it [01:02,  9.42it/s]Train epoch: 14 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003185\n",
      "725it [01:05,  9.37it/s]Train epoch: 14 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003182\n",
      "750it [01:08,  9.28it/s]Train epoch: 14 [batch #750, batch_size 8, seq length 512]\tLoss: 0.003865\n",
      "775it [01:10,  9.16it/s]Train epoch: 14 [batch #775, batch_size 8, seq length 512]\tLoss: 0.002942\n",
      "799it [01:13,  9.28it/s]Train epoch: 14 [batch #800, batch_size 8, seq length 512]\tLoss: 0.002832\n",
      "825it [01:16,  9.13it/s]Train epoch: 14 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003240\n",
      "850it [01:19,  9.17it/s]Train epoch: 14 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003165\n",
      "875it [01:21,  9.03it/s]Train epoch: 14 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003402\n",
      "900it [01:24,  9.05it/s]Train epoch: 14 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003256\n",
      "925it [01:27,  8.95it/s]Train epoch: 14 [batch #925, batch_size 8, seq length 512]\tLoss: 0.003405\n",
      "950it [01:30,  8.93it/s]Train epoch: 14 [batch #950, batch_size 8, seq length 512]\tLoss: 0.002649\n",
      "975it [01:32,  8.90it/s]Train epoch: 14 [batch #975, batch_size 8, seq length 512]\tLoss: 0.003436\n",
      "1000it [01:35,  8.70it/s]Train epoch: 14 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003218\n",
      "1025it [01:38,  8.39it/s]Train epoch: 14 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.003049\n",
      "1050it [01:41,  8.79it/s]Train epoch: 14 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003264\n",
      "1075it [01:44,  8.39it/s]Train epoch: 14 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003270\n",
      "1100it [01:47,  8.70it/s]Train epoch: 14 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.003395\n",
      "1125it [01:50,  8.79it/s]Train epoch: 14 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003208\n",
      "1150it [01:52,  8.42it/s]Train epoch: 14 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.002901\n",
      "1175it [01:55,  8.55it/s]Train epoch: 14 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003393\n",
      "1200it [01:58,  8.48it/s]Train epoch: 14 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.003553\n",
      "1225it [02:01,  8.25it/s]Train epoch: 14 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003392\n",
      "1250it [02:04,  8.55it/s]Train epoch: 14 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003154\n",
      "1275it [02:07,  8.61it/s]Train epoch: 14 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.004183\n",
      "1300it [02:10,  8.63it/s]Train epoch: 14 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003355\n",
      "1325it [02:13,  8.29it/s]Train epoch: 14 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.003555\n",
      "1350it [02:16,  8.09it/s]Train epoch: 14 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003149\n",
      "1375it [02:19,  8.34it/s]Train epoch: 14 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.003979\n",
      "1400it [02:22,  8.33it/s]Train epoch: 14 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003313\n",
      "1425it [02:25,  7.90it/s]Train epoch: 14 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.003487\n",
      "1450it [02:29,  7.96it/s]Train epoch: 14 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.003647\n",
      "1475it [02:32,  8.39it/s]Train epoch: 14 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.003614\n",
      "1500it [02:35,  8.12it/s]Train epoch: 14 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004069\n",
      "1525it [02:38,  8.02it/s]Train epoch: 14 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.003656\n",
      "1550it [02:41,  7.69it/s]Train epoch: 14 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.003554\n",
      "1575it [02:44,  7.75it/s]Train epoch: 14 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.003406\n",
      "1600it [02:47,  7.75it/s]Train epoch: 14 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.004043\n",
      "1625it [02:51,  7.75it/s]Train epoch: 14 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.003826\n",
      "1650it [02:54,  7.86it/s]Train epoch: 14 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.004137\n",
      "1675it [02:57,  7.82it/s]Train epoch: 14 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.003800\n",
      "1700it [03:00,  7.82it/s]Train epoch: 14 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.003739\n",
      "1725it [03:04,  7.93it/s]Train epoch: 14 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.003813\n",
      "1750it [03:07,  7.63it/s]Train epoch: 14 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.003814\n",
      "1775it [03:10,  7.79it/s]Train epoch: 14 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.003938\n",
      "1800it [03:13,  7.76it/s]Train epoch: 14 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.003861\n",
      "1825it [03:16,  7.59it/s]Train epoch: 14 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.003672\n",
      "1850it [03:20,  7.72it/s]Train epoch: 14 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.003448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875it [03:23,  7.74it/s]Train epoch: 14 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.003849\n",
      "1900it [03:26,  7.69it/s]Train epoch: 14 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.004396\n",
      "1925it [03:30,  7.60it/s]Train epoch: 14 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.003747\n",
      "1950it [03:33,  7.44it/s]Train epoch: 14 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.003966\n",
      "1975it [03:36,  7.47it/s]Train epoch: 14 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.004064\n",
      "2000it [03:40,  7.43it/s]Train epoch: 14 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.003510\n",
      "2025it [03:43,  7.49it/s]Train epoch: 14 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.003776\n",
      "2050it [03:46,  7.52it/s]Train epoch: 14 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.004115\n",
      "2075it [03:50,  7.55it/s]Train epoch: 14 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.003893\n",
      "2100it [03:53,  7.42it/s]Train epoch: 14 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.004093\n",
      "2125it [03:56,  7.27it/s]Train epoch: 14 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.003916\n",
      "2150it [04:00,  7.28it/s]Train epoch: 14 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004344\n",
      "2175it [04:03,  7.44it/s]Train epoch: 14 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.003979\n",
      "2200it [04:07,  7.42it/s]Train epoch: 14 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.003792\n",
      "2225it [04:10,  7.15it/s]Train epoch: 14 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.003802\n",
      "2250it [04:14,  7.09it/s]Train epoch: 14 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.004338\n",
      "2275it [04:17,  7.21it/s]Train epoch: 14 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.003887\n",
      "2300it [04:21,  7.26it/s]Train epoch: 14 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.003646\n",
      "2325it [04:24,  6.82it/s]Train epoch: 14 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.004428\n",
      "2350it [04:28,  6.96it/s]Train epoch: 14 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.003846\n",
      "2375it [04:31,  7.09it/s]Train epoch: 14 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.004253\n",
      "2400it [04:35,  7.03it/s]Train epoch: 14 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.004137\n",
      "2425it [04:38,  6.73it/s]Train epoch: 14 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.004180\n",
      "2450it [04:42,  6.97it/s]Train epoch: 14 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.004236\n",
      "2475it [04:45,  6.94it/s]Train epoch: 14 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.003849\n",
      "2500it [04:49,  6.97it/s]Train epoch: 14 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.004237\n",
      "2525it [04:53,  6.53it/s]Train epoch: 14 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.003802\n",
      "2550it [04:56,  6.85it/s]Train epoch: 14 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.004110\n",
      "2575it [05:00,  6.85it/s]Train epoch: 14 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.004446\n",
      "2600it [05:04,  6.86it/s]Train epoch: 14 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.004028\n",
      "2625it [05:07,  7.01it/s]Train epoch: 14 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.004158\n",
      "2650it [05:11,  6.88it/s]Train epoch: 14 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.003915\n",
      "2675it [05:15,  6.70it/s]Train epoch: 14 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004247\n",
      "2700it [05:19,  6.69it/s]Train epoch: 14 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.004723\n",
      "2725it [05:22,  6.51it/s]Train epoch: 14 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.004378\n",
      "2750it [05:26,  6.29it/s]Train epoch: 14 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.004889\n",
      "2775it [05:30,  6.74it/s]Train epoch: 14 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.004291\n",
      "2800it [05:34,  6.65it/s]Train epoch: 14 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.004542\n",
      "2825it [05:37,  6.58it/s]Train epoch: 14 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.003915\n",
      "2850it [05:41,  6.70it/s]Train epoch: 14 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.004634\n",
      "2875it [05:45,  6.43it/s]Train epoch: 14 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.005115\n",
      "2900it [05:49,  6.50it/s]Train epoch: 14 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.004514\n",
      "2925it [05:53,  6.32it/s]Train epoch: 14 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.004681\n",
      "2950it [05:57,  6.46it/s]Train epoch: 14 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.004869\n",
      "2975it [06:01,  6.61it/s]Train epoch: 14 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.004286\n",
      "3000it [06:04,  6.43it/s]Train epoch: 14 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.004366\n",
      "3025it [06:08,  6.30it/s]Train epoch: 14 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.004440\n",
      "3050it [06:12,  6.34it/s]Train epoch: 14 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.004322\n",
      "3075it [06:16,  6.46it/s]Train epoch: 14 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.004576\n",
      "3100it [06:20,  6.30it/s]Train epoch: 14 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.004534\n",
      "3125it [06:24,  6.37it/s]Train epoch: 14 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.004234\n",
      "3150it [06:28,  6.25it/s]Train epoch: 14 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.004536\n",
      "3175it [06:32,  6.31it/s]Train epoch: 14 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.004883\n",
      "3200it [06:36,  6.20it/s]Train epoch: 14 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004286\n",
      "3225it [06:40,  6.17it/s]Train epoch: 14 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.004561\n",
      "3250it [06:44,  6.22it/s]Train epoch: 14 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.004837\n",
      "3275it [06:48,  6.14it/s]Train epoch: 14 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.004742\n",
      "3300it [06:52,  6.09it/s]Train epoch: 14 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.004987\n",
      "3325it [06:56,  5.94it/s]Train epoch: 14 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.004935\n",
      "3350it [07:01,  6.00it/s]Train epoch: 14 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.004947\n",
      "3375it [07:05,  6.07it/s]Train epoch: 14 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.004427\n",
      "3400it [07:09,  6.03it/s]Train epoch: 14 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.004878\n",
      "3425it [07:13,  6.04it/s]Train epoch: 14 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.004755\n",
      "3450it [07:17,  6.05it/s]Train epoch: 14 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.004698\n",
      "3475it [07:21,  6.11it/s]Train epoch: 14 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.005295\n",
      "3500it [07:26,  5.96it/s]Train epoch: 14 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.004650\n",
      "3525it [07:30,  5.91it/s]Train epoch: 14 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.004675\n",
      "3550it [07:34,  5.87it/s]Train epoch: 14 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.005057\n",
      "3575it [07:38,  5.84it/s]Train epoch: 14 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.005066\n",
      "3600it [07:43,  5.86it/s]Train epoch: 14 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.005253\n",
      "3625it [07:47,  5.90it/s]Train epoch: 14 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.004619\n",
      "3650it [07:51,  5.87it/s]Train epoch: 14 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.005193\n",
      "3675it [07:55,  5.89it/s]Train epoch: 14 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.005356\n",
      "3700it [08:00,  5.67it/s]Train epoch: 14 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.004732\n",
      "3725it [08:04,  5.65it/s]Train epoch: 14 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.005170\n",
      "3750it [08:09,  5.70it/s]Train epoch: 14 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.004883\n",
      "3775it [08:13,  5.73it/s]Train epoch: 14 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.005252\n",
      "3800it [08:17,  5.66it/s]Train epoch: 14 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.005478\n",
      "3825it [08:22,  5.67it/s]Train epoch: 14 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.005025\n",
      "3850it [08:26,  5.61it/s]Train epoch: 14 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.004874\n",
      "3875it [08:31,  5.69it/s]Train epoch: 14 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.005121\n",
      "3900it [08:35,  5.51it/s]Train epoch: 14 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.005269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3925it [08:40,  5.60it/s]Train epoch: 14 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.004581\n",
      "3950it [08:44,  5.56it/s]Train epoch: 14 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.004946\n",
      "3975it [08:49,  5.48it/s]Train epoch: 14 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.005269\n",
      "4000it [08:53,  5.55it/s]Train epoch: 14 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.004911\n",
      "4025it [08:58,  5.50it/s]Train epoch: 14 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.004843\n",
      "4050it [09:02,  5.52it/s]Train epoch: 14 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.004871\n",
      "4075it [09:07,  5.40it/s]Train epoch: 14 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.004871\n",
      "4100it [09:12,  5.48it/s]Train epoch: 14 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.005129\n",
      "4125it [09:16,  5.36it/s]Train epoch: 14 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.005155\n",
      "4150it [09:21,  5.35it/s]Train epoch: 14 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.005484\n",
      "4175it [09:26,  5.27it/s]Train epoch: 14 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.005018\n",
      "4200it [09:30,  5.27it/s]Train epoch: 14 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.004754\n",
      "4225it [09:35,  5.23it/s]Train epoch: 14 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.005254\n",
      "4250it [09:40,  5.30it/s]Train epoch: 14 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.005781\n",
      "4275it [09:45,  5.24it/s]Train epoch: 14 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.005340\n",
      "4300it [09:49,  5.35it/s]Train epoch: 14 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.005057\n",
      "4325it [09:54,  5.15it/s]Train epoch: 14 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.005507\n",
      "4350it [09:59,  5.15it/s]Train epoch: 14 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.005843\n",
      "4375it [10:04,  5.11it/s]Train epoch: 14 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.005408\n",
      "4400it [10:09,  5.09it/s]Train epoch: 14 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.005331\n",
      "4425it [10:14,  5.11it/s]Train epoch: 14 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.005480\n",
      "4450it [10:19,  5.03it/s]Train epoch: 14 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.005299\n",
      "4475it [10:24,  5.00it/s]Train epoch: 14 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.006118\n",
      "4500it [10:28,  5.13it/s]Train epoch: 14 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.005857\n",
      "4525it [10:33,  4.99it/s]Train epoch: 14 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.005513\n",
      "4550it [10:38,  5.09it/s]Train epoch: 14 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.005564\n",
      "4575it [10:43,  4.93it/s]Train epoch: 14 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.005250\n",
      "4600it [10:49,  5.00it/s]Train epoch: 14 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.005526\n",
      "4625it [10:54,  4.92it/s]Train epoch: 14 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.005962\n",
      "4650it [10:59,  4.90it/s]Train epoch: 14 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.005945\n",
      "4675it [11:04,  4.89it/s]Train epoch: 14 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.005866\n",
      "4700it [11:09,  4.95it/s]Train epoch: 14 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.005686\n",
      "4725it [11:14,  4.80it/s]Train epoch: 14 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.005759\n",
      "4750it [11:19,  4.76it/s]Train epoch: 14 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.005782\n",
      "4775it [11:25,  4.80it/s]Train epoch: 14 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.005878\n",
      "4800it [11:30,  4.73it/s]Train epoch: 14 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.006140\n",
      "4825it [11:35,  4.63it/s]Train epoch: 14 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.005338\n",
      "4850it [11:41,  4.68it/s]Train epoch: 14 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.005780\n",
      "4875it [11:46,  4.66it/s]Train epoch: 14 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.005961\n",
      "4900it [11:51,  4.56it/s]Train epoch: 14 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.005923\n",
      "4925it [11:57,  4.59it/s]Train epoch: 14 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.006284\n",
      "4950it [12:02,  4.60it/s]Train epoch: 14 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.006232\n",
      "4975it [12:08,  4.58it/s]Train epoch: 14 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.006310\n",
      "5000it [12:13,  4.51it/s]Train epoch: 14 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.006108\n",
      "5025it [12:19,  4.47it/s]Train epoch: 14 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.006684\n",
      "5050it [12:24,  4.46it/s]Train epoch: 14 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.006501\n",
      "5075it [12:30,  4.47it/s]Train epoch: 14 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.006123\n",
      "5100it [12:36,  4.42it/s]Train epoch: 14 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.006075\n",
      "5125it [12:41,  4.40it/s]Train epoch: 14 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.006649\n",
      "5150it [12:47,  4.33it/s]Train epoch: 14 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.006719\n",
      "5175it [12:53,  4.29it/s]Train epoch: 14 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.006433\n",
      "5200it [12:59,  4.30it/s]Train epoch: 14 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.006714\n",
      "5225it [13:05,  4.25it/s]Train epoch: 14 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.006791\n",
      "5250it [13:11,  4.21it/s]Train epoch: 14 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.006377\n",
      "5275it [13:17,  4.21it/s]Train epoch: 14 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.006695\n",
      "5300it [13:23,  4.18it/s]Train epoch: 14 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.006474\n",
      "5325it [13:29,  4.15it/s]Train epoch: 14 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.006412\n",
      "5350it [13:35,  4.04it/s]Train epoch: 14 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.006867\n",
      "5375it [13:41,  4.06it/s]Train epoch: 14 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.007174\n",
      "5400it [13:47,  4.01it/s]Train epoch: 14 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.006860\n",
      "5425it [13:53,  3.98it/s]Train epoch: 14 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.006774\n",
      "5450it [14:00,  3.97it/s]Train epoch: 14 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.007075\n",
      "5475it [14:06,  3.97it/s]Train epoch: 14 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.006967\n",
      "5500it [14:12,  3.85it/s]Train epoch: 14 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.007132\n",
      "5525it [14:19,  3.80it/s]Train epoch: 14 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.007436\n",
      "5550it [14:25,  3.82it/s]Train epoch: 14 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.007630\n",
      "5575it [14:32,  3.80it/s]Train epoch: 14 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.006780\n",
      "5600it [14:39,  3.71it/s]Train epoch: 14 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.007130\n",
      "5625it [14:45,  3.65it/s]Train epoch: 14 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.007692\n",
      "5650it [14:52,  3.58it/s]Train epoch: 14 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.006841\n",
      "5675it [14:59,  3.56it/s]Train epoch: 14 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.007948\n",
      "5700it [15:06,  3.48it/s]Train epoch: 14 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.007465\n",
      "5725it [15:14,  3.41it/s]Train epoch: 14 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.007809\n",
      "5750it [15:21,  3.35it/s]Train epoch: 14 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.008160\n",
      "5775it [15:29,  3.28it/s]Train epoch: 14 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.007633\n",
      "5800it [15:36,  3.22it/s]Train epoch: 14 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.008123\n",
      "5825it [15:44,  3.10it/s]Train epoch: 14 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.008296\n",
      "5850it [15:53,  3.04it/s]Train epoch: 14 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.008027\n",
      "5875it [16:01,  2.88it/s]Train epoch: 14 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.008756\n",
      "5900it [16:10,  2.77it/s]Train epoch: 14 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.008007\n",
      "5925it [16:20,  2.54it/s]Train epoch: 14 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.009193\n",
      "5950it [16:30,  2.16it/s]Train epoch: 14 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.009919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5965it [16:38,  5.97it/s]\n",
      "epoch loss: 0.004772763414178059\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.31it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0272, 0.0428, 0.0415, 0.0421, 0.8434\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2552, 0.5103, 0.3379, 0.4066, 0.9742\n",
      "rec_at_8: 0.3078\n",
      "prec_at_8: 0.5741\n",
      "rec_at_15: 0.4157\n",
      "prec_at_15: 0.4307\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.17it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0268, 0.0467, 0.0419, 0.0442, 0.8446\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2495, 0.5084, 0.3288, 0.3993, 0.9739\n",
      "rec_at_8: 0.2923\n",
      "prec_at_8: 0.5650\n",
      "rec_at_15: 0.4025\n",
      "prec_at_15: 0.4314\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 15\n",
      "0it [00:00, ?it/s]Train epoch: 15 [batch #0, batch_size 8, seq length 512]\tLoss: 0.004652\n",
      "24it [00:01, 15.77it/s]Train epoch: 15 [batch #25, batch_size 8, seq length 512]\tLoss: 0.003312\n",
      "50it [00:03, 14.13it/s]Train epoch: 15 [batch #50, batch_size 8, seq length 512]\tLoss: 0.002944\n",
      "74it [00:05, 13.57it/s]Train epoch: 15 [batch #75, batch_size 8, seq length 512]\tLoss: 0.002683\n",
      "100it [00:07, 13.34it/s]Train epoch: 15 [batch #100, batch_size 8, seq length 512]\tLoss: 0.002962\n",
      "124it [00:08, 12.96it/s]Train epoch: 15 [batch #125, batch_size 8, seq length 512]\tLoss: 0.002719\n",
      "150it [00:10, 12.61it/s]Train epoch: 15 [batch #150, batch_size 8, seq length 512]\tLoss: 0.002728\n",
      "174it [00:12, 12.42it/s]Train epoch: 15 [batch #175, batch_size 8, seq length 512]\tLoss: 0.002944\n",
      "200it [00:15, 11.83it/s]Train epoch: 15 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002409\n",
      "224it [00:17, 11.84it/s]Train epoch: 15 [batch #225, batch_size 8, seq length 512]\tLoss: 0.002796\n",
      "250it [00:19, 11.26it/s]Train epoch: 15 [batch #250, batch_size 8, seq length 512]\tLoss: 0.002652\n",
      "274it [00:21, 11.45it/s]Train epoch: 15 [batch #275, batch_size 8, seq length 512]\tLoss: 0.002813\n",
      "300it [00:23, 11.61it/s]Train epoch: 15 [batch #300, batch_size 8, seq length 512]\tLoss: 0.002963\n",
      "324it [00:25, 11.18it/s]Train epoch: 15 [batch #325, batch_size 8, seq length 512]\tLoss: 0.002847\n",
      "350it [00:28, 11.23it/s]Train epoch: 15 [batch #350, batch_size 8, seq length 512]\tLoss: 0.002806\n",
      "374it [00:30, 11.06it/s]Train epoch: 15 [batch #375, batch_size 8, seq length 512]\tLoss: 0.002817\n",
      "400it [00:32, 10.56it/s]Train epoch: 15 [batch #400, batch_size 8, seq length 512]\tLoss: 0.002649\n",
      "424it [00:35, 10.79it/s]Train epoch: 15 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003111\n",
      "449it [00:37,  9.78it/s]Train epoch: 15 [batch #450, batch_size 8, seq length 512]\tLoss: 0.002819\n",
      "475it [00:40, 10.11it/s]Train epoch: 15 [batch #475, batch_size 8, seq length 512]\tLoss: 0.002686\n",
      "499it [00:42,  9.93it/s]Train epoch: 15 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003195\n",
      "525it [00:45, 10.00it/s]Train epoch: 15 [batch #525, batch_size 8, seq length 512]\tLoss: 0.002889\n",
      "550it [00:47,  9.91it/s]Train epoch: 15 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003161\n",
      "574it [00:49, 10.05it/s]Train epoch: 15 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003172\n",
      "599it [00:52, 10.12it/s]Train epoch: 15 [batch #600, batch_size 8, seq length 512]\tLoss: 0.003012\n",
      "624it [00:55,  9.97it/s]Train epoch: 15 [batch #625, batch_size 8, seq length 512]\tLoss: 0.003016\n",
      "650it [00:57,  9.67it/s]Train epoch: 15 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003117\n",
      "675it [01:00,  9.25it/s]Train epoch: 15 [batch #675, batch_size 8, seq length 512]\tLoss: 0.003722\n",
      "700it [01:02,  9.49it/s]Train epoch: 15 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003098\n",
      "725it [01:05,  9.47it/s]Train epoch: 15 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003124\n",
      "750it [01:08,  9.57it/s]Train epoch: 15 [batch #750, batch_size 8, seq length 512]\tLoss: 0.003783\n",
      "775it [01:10,  9.22it/s]Train epoch: 15 [batch #775, batch_size 8, seq length 512]\tLoss: 0.002886\n",
      "800it [01:13,  9.33it/s]Train epoch: 15 [batch #800, batch_size 8, seq length 512]\tLoss: 0.002761\n",
      "825it [01:16,  9.34it/s]Train epoch: 15 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003185\n",
      "850it [01:18,  9.13it/s]Train epoch: 15 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003088\n",
      "875it [01:21,  9.31it/s]Train epoch: 15 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003356\n",
      "900it [01:24,  9.07it/s]Train epoch: 15 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003178\n",
      "925it [01:27,  9.14it/s]Train epoch: 15 [batch #925, batch_size 8, seq length 512]\tLoss: 0.003354\n",
      "950it [01:29,  9.00it/s]Train epoch: 15 [batch #950, batch_size 8, seq length 512]\tLoss: 0.002549\n",
      "975it [01:32,  8.89it/s]Train epoch: 15 [batch #975, batch_size 8, seq length 512]\tLoss: 0.003367\n",
      "1000it [01:35,  8.75it/s]Train epoch: 15 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003130\n",
      "1025it [01:38,  8.81it/s]Train epoch: 15 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.002988\n",
      "1050it [01:41,  8.99it/s]Train epoch: 15 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003245\n",
      "1075it [01:44,  8.67it/s]Train epoch: 15 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003182\n",
      "1100it [01:46,  8.87it/s]Train epoch: 15 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.003300\n",
      "1125it [01:49,  8.42it/s]Train epoch: 15 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003161\n",
      "1150it [01:52,  8.65it/s]Train epoch: 15 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.002815\n",
      "1175it [01:55,  8.36it/s]Train epoch: 15 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003286\n",
      "1200it [01:58,  8.46it/s]Train epoch: 15 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.003522\n",
      "1225it [02:01,  8.39it/s]Train epoch: 15 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003338\n",
      "1250it [02:04,  8.50it/s]Train epoch: 15 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003108\n",
      "1275it [02:07,  8.51it/s]Train epoch: 15 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.004116\n",
      "1300it [02:10,  8.40it/s]Train epoch: 15 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003340\n",
      "1325it [02:13,  8.28it/s]Train epoch: 15 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.003438\n",
      "1350it [02:16,  8.26it/s]Train epoch: 15 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003072\n",
      "1375it [02:19,  8.22it/s]Train epoch: 15 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.003878\n",
      "1400it [02:22,  7.99it/s]Train epoch: 15 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003271\n",
      "1425it [02:25,  8.26it/s]Train epoch: 15 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.003411\n",
      "1450it [02:28,  8.21it/s]Train epoch: 15 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.003533\n",
      "1475it [02:31,  8.12it/s]Train epoch: 15 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.003536\n",
      "1500it [02:34,  7.74it/s]Train epoch: 15 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.004025\n",
      "1525it [02:38,  8.02it/s]Train epoch: 15 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.003553\n",
      "1550it [02:41,  7.96it/s]Train epoch: 15 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.003471\n",
      "1575it [02:44,  7.87it/s]Train epoch: 15 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.003363\n",
      "1600it [02:47,  7.64it/s]Train epoch: 15 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.003932\n",
      "1625it [02:50,  8.03it/s]Train epoch: 15 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.003739\n",
      "1650it [02:53,  7.93it/s]Train epoch: 15 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.004040\n",
      "1675it [02:56,  7.70it/s]Train epoch: 15 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.003744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700it [03:00,  7.90it/s]Train epoch: 15 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.003654\n",
      "1725it [03:03,  7.69it/s]Train epoch: 15 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.003674\n",
      "1750it [03:06,  7.58it/s]Train epoch: 15 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.003752\n",
      "1775it [03:09,  7.70it/s]Train epoch: 15 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.003862\n",
      "1800it [03:13,  7.59it/s]Train epoch: 15 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.003801\n",
      "1825it [03:16,  7.65it/s]Train epoch: 15 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.003605\n",
      "1850it [03:19,  7.68it/s]Train epoch: 15 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.003392\n",
      "1875it [03:23,  7.60it/s]Train epoch: 15 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.003752\n",
      "1900it [03:26,  7.44it/s]Train epoch: 15 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.004296\n",
      "1925it [03:29,  7.41it/s]Train epoch: 15 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.003680\n",
      "1950it [03:33,  7.60it/s]Train epoch: 15 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.003930\n",
      "1975it [03:36,  7.66it/s]Train epoch: 15 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.003943\n",
      "2000it [03:39,  7.11it/s]Train epoch: 15 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.003438\n",
      "2025it [03:43,  7.65it/s]Train epoch: 15 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.003691\n",
      "2050it [03:46,  7.36it/s]Train epoch: 15 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.004005\n",
      "2075it [03:49,  7.50it/s]Train epoch: 15 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.003875\n",
      "2100it [03:53,  7.48it/s]Train epoch: 15 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.004063\n",
      "2125it [03:56,  7.32it/s]Train epoch: 15 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.003808\n",
      "2150it [04:00,  7.21it/s]Train epoch: 15 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004221\n",
      "2175it [04:03,  7.16it/s]Train epoch: 15 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.003867\n",
      "2200it [04:07,  7.24it/s]Train epoch: 15 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.003708\n",
      "2225it [04:10,  7.29it/s]Train epoch: 15 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.003698\n",
      "2250it [04:13,  7.17it/s]Train epoch: 15 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.004209\n",
      "2275it [04:17,  7.41it/s]Train epoch: 15 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.003756\n",
      "2300it [04:20,  7.16it/s]Train epoch: 15 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.003565\n",
      "2325it [04:24,  7.24it/s]Train epoch: 15 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.004277\n",
      "2350it [04:27,  7.05it/s]Train epoch: 15 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.003702\n",
      "2375it [04:31,  7.24it/s]Train epoch: 15 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.004183\n",
      "2400it [04:34,  6.91it/s]Train epoch: 15 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.004037\n",
      "2425it [04:38,  6.97it/s]Train epoch: 15 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.004073\n",
      "2450it [04:42,  6.88it/s]Train epoch: 15 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.004077\n",
      "2475it [04:45,  6.92it/s]Train epoch: 15 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.003788\n",
      "2500it [04:49,  7.01it/s]Train epoch: 15 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.004149\n",
      "2525it [04:52,  6.84it/s]Train epoch: 15 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.003720\n",
      "2550it [04:56,  6.50it/s]Train epoch: 15 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.004015\n",
      "2575it [05:00,  6.79it/s]Train epoch: 15 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.004337\n",
      "2600it [05:03,  6.86it/s]Train epoch: 15 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.003972\n",
      "2625it [05:07,  6.82it/s]Train epoch: 15 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.004044\n",
      "2650it [05:11,  6.73it/s]Train epoch: 15 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.003848\n",
      "2675it [05:15,  6.76it/s]Train epoch: 15 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004171\n",
      "2700it [05:18,  6.72it/s]Train epoch: 15 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.004633\n",
      "2725it [05:22,  6.48it/s]Train epoch: 15 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.004326\n",
      "2750it [05:26,  6.52it/s]Train epoch: 15 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.004748\n",
      "2775it [05:30,  6.61it/s]Train epoch: 15 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.004137\n",
      "2800it [05:33,  6.56it/s]Train epoch: 15 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.004479\n",
      "2825it [05:37,  6.53it/s]Train epoch: 15 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.003881\n",
      "2850it [05:41,  6.61it/s]Train epoch: 15 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.004458\n",
      "2875it [05:45,  6.31it/s]Train epoch: 15 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.004995\n",
      "2900it [05:49,  6.50it/s]Train epoch: 15 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.004422\n",
      "2925it [05:53,  6.50it/s]Train epoch: 15 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.004589\n",
      "2950it [05:56,  6.59it/s]Train epoch: 15 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.004843\n",
      "2975it [06:00,  6.50it/s]Train epoch: 15 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.004237\n",
      "3000it [06:04,  6.40it/s]Train epoch: 15 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.004305\n",
      "3025it [06:08,  6.44it/s]Train epoch: 15 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.004336\n",
      "3050it [06:12,  6.34it/s]Train epoch: 15 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.004191\n",
      "3075it [06:16,  6.30it/s]Train epoch: 15 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.004499\n",
      "3100it [06:20,  6.31it/s]Train epoch: 15 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.004423\n",
      "3125it [06:24,  6.42it/s]Train epoch: 15 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.004087\n",
      "3150it [06:28,  6.28it/s]Train epoch: 15 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.004442\n",
      "3175it [06:32,  6.16it/s]Train epoch: 15 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.004788\n",
      "3200it [06:36,  6.37it/s]Train epoch: 15 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004207\n",
      "3225it [06:40,  6.22it/s]Train epoch: 15 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.004420\n",
      "3250it [06:44,  6.12it/s]Train epoch: 15 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.004746\n",
      "3275it [06:48,  6.02it/s]Train epoch: 15 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.004637\n",
      "3300it [06:52,  5.98it/s]Train epoch: 15 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.004878\n",
      "3325it [06:56,  6.13it/s]Train epoch: 15 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.004821\n",
      "3350it [07:00,  5.99it/s]Train epoch: 15 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.004850\n",
      "3375it [07:04,  6.10it/s]Train epoch: 15 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.004263\n",
      "3400it [07:09,  5.96it/s]Train epoch: 15 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.004782\n",
      "3425it [07:13,  6.13it/s]Train epoch: 15 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.004628\n",
      "3450it [07:17,  6.04it/s]Train epoch: 15 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.004622\n",
      "3475it [07:21,  5.86it/s]Train epoch: 15 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.005180\n",
      "3500it [07:25,  5.68it/s]Train epoch: 15 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.004551\n",
      "3525it [07:30,  5.93it/s]Train epoch: 15 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.004534\n",
      "3550it [07:34,  5.81it/s]Train epoch: 15 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.004968\n",
      "3575it [07:38,  5.85it/s]Train epoch: 15 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.004957\n",
      "3600it [07:42,  5.83it/s]Train epoch: 15 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.005160\n",
      "3625it [07:47,  6.06it/s]Train epoch: 15 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.004568\n",
      "3650it [07:51,  5.93it/s]Train epoch: 15 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.005056\n",
      "3675it [07:55,  5.76it/s]Train epoch: 15 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.005212\n",
      "3700it [08:00,  5.77it/s]Train epoch: 15 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.004616\n",
      "3725it [08:04,  5.81it/s]Train epoch: 15 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.005068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750it [08:08,  5.66it/s]Train epoch: 15 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.004806\n",
      "3775it [08:13,  5.46it/s]Train epoch: 15 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.005053\n",
      "3800it [08:17,  5.59it/s]Train epoch: 15 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.005378\n",
      "3825it [08:22,  5.67it/s]Train epoch: 15 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.004907\n",
      "3850it [08:26,  5.59it/s]Train epoch: 15 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.004768\n",
      "3875it [08:30,  5.67it/s]Train epoch: 15 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.005046\n",
      "3900it [08:35,  5.58it/s]Train epoch: 15 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.005192\n",
      "3925it [08:39,  5.53it/s]Train epoch: 15 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.004475\n",
      "3950it [08:44,  5.58it/s]Train epoch: 15 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.004756\n",
      "3975it [08:48,  5.47it/s]Train epoch: 15 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.005256\n",
      "4000it [08:53,  5.50it/s]Train epoch: 15 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.004859\n",
      "4025it [08:57,  5.48it/s]Train epoch: 15 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.004715\n",
      "4050it [09:02,  5.31it/s]Train epoch: 15 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.004807\n",
      "4075it [09:07,  5.31it/s]Train epoch: 15 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.004757\n",
      "4100it [09:11,  5.43it/s]Train epoch: 15 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.005043\n",
      "4125it [09:16,  5.30it/s]Train epoch: 15 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.005076\n",
      "4150it [09:21,  5.38it/s]Train epoch: 15 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.005327\n",
      "4175it [09:25,  5.32it/s]Train epoch: 15 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.004944\n",
      "4200it [09:30,  5.36it/s]Train epoch: 15 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.004689\n",
      "4225it [09:35,  5.36it/s]Train epoch: 15 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.005171\n",
      "4250it [09:40,  5.24it/s]Train epoch: 15 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.005727\n",
      "4275it [09:44,  5.21it/s]Train epoch: 15 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.005261\n",
      "4300it [09:49,  5.21it/s]Train epoch: 15 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.004954\n",
      "4325it [09:54,  5.06it/s]Train epoch: 15 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.005391\n",
      "4350it [09:59,  5.17it/s]Train epoch: 15 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.005717\n",
      "4375it [10:04,  5.19it/s]Train epoch: 15 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.005289\n",
      "4400it [10:08,  5.03it/s]Train epoch: 15 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.005189\n",
      "4425it [10:13,  5.18it/s]Train epoch: 15 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.005372\n",
      "4450it [10:18,  5.06it/s]Train epoch: 15 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.005146\n",
      "4475it [10:23,  4.97it/s]Train epoch: 15 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.006028\n",
      "4500it [10:28,  4.72it/s]Train epoch: 15 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.005735\n",
      "4525it [10:33,  4.97it/s]Train epoch: 15 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.005445\n",
      "4550it [10:38,  5.01it/s]Train epoch: 15 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.005465\n",
      "4575it [10:43,  5.00it/s]Train epoch: 15 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.005105\n",
      "4600it [10:49,  4.87it/s]Train epoch: 15 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.005376\n",
      "4625it [10:54,  5.00it/s]Train epoch: 15 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.005792\n",
      "4650it [10:59,  4.82it/s]Train epoch: 15 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.005806\n",
      "4675it [11:04,  4.84it/s]Train epoch: 15 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.005784\n",
      "4700it [11:09,  4.69it/s]Train epoch: 15 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.005625\n",
      "4725it [11:14,  4.84it/s]Train epoch: 15 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.005585\n",
      "4750it [11:19,  4.72it/s]Train epoch: 15 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.005659\n",
      "4775it [11:25,  4.74it/s]Train epoch: 15 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.005745\n",
      "4800it [11:30,  4.54it/s]Train epoch: 15 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.006060\n",
      "4825it [11:35,  4.72it/s]Train epoch: 15 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.005224\n",
      "4850it [11:41,  4.77it/s]Train epoch: 15 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.005706\n",
      "4875it [11:46,  4.68it/s]Train epoch: 15 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.005808\n",
      "4900it [11:51,  4.64it/s]Train epoch: 15 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.005806\n",
      "4925it [11:57,  4.62it/s]Train epoch: 15 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.006196\n",
      "4950it [12:02,  4.61it/s]Train epoch: 15 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.006169\n",
      "4975it [12:08,  4.59it/s]Train epoch: 15 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.006306\n",
      "5000it [12:13,  4.49it/s]Train epoch: 15 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.005950\n",
      "5025it [12:19,  4.52it/s]Train epoch: 15 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.006544\n",
      "5050it [12:24,  4.46it/s]Train epoch: 15 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.006380\n",
      "5075it [12:30,  4.32it/s]Train epoch: 15 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.005992\n",
      "5100it [12:36,  4.37it/s]Train epoch: 15 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.006011\n",
      "5125it [12:41,  4.26it/s]Train epoch: 15 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.006468\n",
      "5150it [12:47,  4.34it/s]Train epoch: 15 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.006570\n",
      "5175it [12:53,  4.37it/s]Train epoch: 15 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.006325\n",
      "5200it [12:59,  4.31it/s]Train epoch: 15 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.006607\n",
      "5225it [13:04,  4.24it/s]Train epoch: 15 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.006670\n",
      "5250it [13:10,  4.20it/s]Train epoch: 15 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.006322\n",
      "5275it [13:16,  4.21it/s]Train epoch: 15 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.006630\n",
      "5300it [13:22,  4.13it/s]Train epoch: 15 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.006356\n",
      "5325it [13:28,  4.17it/s]Train epoch: 15 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.006294\n",
      "5350it [13:34,  4.13it/s]Train epoch: 15 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.006748\n",
      "5375it [13:40,  4.03it/s]Train epoch: 15 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.007078\n",
      "5400it [13:47,  4.07it/s]Train epoch: 15 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.006704\n",
      "5425it [13:53,  3.98it/s]Train epoch: 15 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.006702\n",
      "5450it [13:59,  3.97it/s]Train epoch: 15 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.006932\n",
      "5475it [14:06,  3.92it/s]Train epoch: 15 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.006824\n",
      "5500it [14:12,  3.87it/s]Train epoch: 15 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.006963\n",
      "5525it [14:18,  3.83it/s]Train epoch: 15 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.007329\n",
      "5550it [14:25,  3.78it/s]Train epoch: 15 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.007509\n",
      "5575it [14:32,  3.74it/s]Train epoch: 15 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.006745\n",
      "5600it [14:38,  3.72it/s]Train epoch: 15 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.007075\n",
      "5625it [14:45,  3.64it/s]Train epoch: 15 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.007527\n",
      "5650it [14:52,  3.60it/s]Train epoch: 15 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.006663\n",
      "5675it [14:59,  3.55it/s]Train epoch: 15 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.007826\n",
      "5700it [15:06,  3.50it/s]Train epoch: 15 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.007348\n",
      "5725it [15:13,  3.43it/s]Train epoch: 15 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.007674\n",
      "5750it [15:21,  3.35it/s]Train epoch: 15 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.008033\n",
      "5775it [15:28,  3.30it/s]Train epoch: 15 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.007480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800it [15:36,  3.21it/s]Train epoch: 15 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.007963\n",
      "5825it [15:44,  3.14it/s]Train epoch: 15 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.008125\n",
      "5850it [15:52,  3.03it/s]Train epoch: 15 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.007896\n",
      "5875it [16:01,  2.90it/s]Train epoch: 15 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.008617\n",
      "5900it [16:10,  2.74it/s]Train epoch: 15 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.007872\n",
      "5925it [16:19,  2.55it/s]Train epoch: 15 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.009005\n",
      "5950it [16:30,  2.18it/s]Train epoch: 15 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.009773\n",
      "5965it [16:38,  5.98it/s]\n",
      "epoch loss: 0.004674024484744834\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.19it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0279, 0.0448, 0.0426, 0.0437, 0.8408\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2539, 0.5003, 0.3401, 0.4049, 0.9737\n",
      "rec_at_8: 0.3047\n",
      "prec_at_8: 0.5679\n",
      "rec_at_15: 0.4141\n",
      "prec_at_15: 0.4284\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.04it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0277, 0.0478, 0.0429, 0.0452, 0.8434\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2468, 0.4971, 0.3289, 0.3959, 0.9736\n",
      "rec_at_8: 0.2895\n",
      "prec_at_8: 0.5584\n",
      "rec_at_15: 0.3996\n",
      "prec_at_15: 0.4283\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 16\n",
      "0it [00:00, ?it/s]Train epoch: 16 [batch #0, batch_size 8, seq length 512]\tLoss: 0.004696\n",
      "24it [00:01, 15.41it/s]Train epoch: 16 [batch #25, batch_size 8, seq length 512]\tLoss: 0.003295\n",
      "50it [00:03, 14.46it/s]Train epoch: 16 [batch #50, batch_size 8, seq length 512]\tLoss: 0.002859\n",
      "74it [00:05, 13.33it/s]Train epoch: 16 [batch #75, batch_size 8, seq length 512]\tLoss: 0.002597\n",
      "100it [00:07, 13.40it/s]Train epoch: 16 [batch #100, batch_size 8, seq length 512]\tLoss: 0.002911\n",
      "124it [00:08, 12.60it/s]Train epoch: 16 [batch #125, batch_size 8, seq length 512]\tLoss: 0.002660\n",
      "150it [00:10, 12.43it/s]Train epoch: 16 [batch #150, batch_size 8, seq length 512]\tLoss: 0.002678\n",
      "174it [00:12, 12.14it/s]Train epoch: 16 [batch #175, batch_size 8, seq length 512]\tLoss: 0.002898\n",
      "200it [00:15, 12.04it/s]Train epoch: 16 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002352\n",
      "224it [00:17, 11.90it/s]Train epoch: 16 [batch #225, batch_size 8, seq length 512]\tLoss: 0.002716\n",
      "250it [00:19, 11.13it/s]Train epoch: 16 [batch #250, batch_size 8, seq length 512]\tLoss: 0.002589\n",
      "274it [00:21, 11.61it/s]Train epoch: 16 [batch #275, batch_size 8, seq length 512]\tLoss: 0.002747\n",
      "300it [00:23, 11.30it/s]Train epoch: 16 [batch #300, batch_size 8, seq length 512]\tLoss: 0.002909\n",
      "324it [00:25, 11.10it/s]Train epoch: 16 [batch #325, batch_size 8, seq length 512]\tLoss: 0.002815\n",
      "350it [00:28, 10.99it/s]Train epoch: 16 [batch #350, batch_size 8, seq length 512]\tLoss: 0.002740\n",
      "374it [00:30, 10.84it/s]Train epoch: 16 [batch #375, batch_size 8, seq length 512]\tLoss: 0.002745\n",
      "400it [00:32, 10.65it/s]Train epoch: 16 [batch #400, batch_size 8, seq length 512]\tLoss: 0.002584\n",
      "424it [00:35, 10.56it/s]Train epoch: 16 [batch #425, batch_size 8, seq length 512]\tLoss: 0.003024\n",
      "450it [00:37, 10.37it/s]Train epoch: 16 [batch #450, batch_size 8, seq length 512]\tLoss: 0.002710\n",
      "475it [00:40, 10.23it/s]Train epoch: 16 [batch #475, batch_size 8, seq length 512]\tLoss: 0.002638\n",
      "499it [00:42,  9.99it/s]Train epoch: 16 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003099\n",
      "525it [00:45,  9.86it/s]Train epoch: 16 [batch #525, batch_size 8, seq length 512]\tLoss: 0.002851\n",
      "549it [00:47, 10.04it/s]Train epoch: 16 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003120\n",
      "575it [00:50,  9.74it/s]Train epoch: 16 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003156\n",
      "600it [00:52, 10.22it/s]Train epoch: 16 [batch #600, batch_size 8, seq length 512]\tLoss: 0.002993\n",
      "625it [00:55,  9.50it/s]Train epoch: 16 [batch #625, batch_size 8, seq length 512]\tLoss: 0.002927\n",
      "650it [00:57,  9.76it/s]Train epoch: 16 [batch #650, batch_size 8, seq length 512]\tLoss: 0.003017\n",
      "675it [01:00,  9.54it/s]Train epoch: 16 [batch #675, batch_size 8, seq length 512]\tLoss: 0.003604\n",
      "700it [01:03,  9.44it/s]Train epoch: 16 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003086\n",
      "725it [01:05,  9.45it/s]Train epoch: 16 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003025\n",
      "750it [01:08,  9.49it/s]Train epoch: 16 [batch #750, batch_size 8, seq length 512]\tLoss: 0.003680\n",
      "775it [01:11,  8.93it/s]Train epoch: 16 [batch #775, batch_size 8, seq length 512]\tLoss: 0.002872\n",
      "800it [01:13,  9.56it/s]Train epoch: 16 [batch #800, batch_size 8, seq length 512]\tLoss: 0.002716\n",
      "825it [01:16,  9.53it/s]Train epoch: 16 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003079\n",
      "850it [01:19,  9.20it/s]Train epoch: 16 [batch #850, batch_size 8, seq length 512]\tLoss: 0.003041\n",
      "875it [01:21,  9.26it/s]Train epoch: 16 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003271\n",
      "900it [01:24,  9.05it/s]Train epoch: 16 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003149\n",
      "925it [01:27,  9.02it/s]Train epoch: 16 [batch #925, batch_size 8, seq length 512]\tLoss: 0.003266\n",
      "950it [01:30,  8.82it/s]Train epoch: 16 [batch #950, batch_size 8, seq length 512]\tLoss: 0.002486\n",
      "975it [01:32,  9.02it/s]Train epoch: 16 [batch #975, batch_size 8, seq length 512]\tLoss: 0.003311\n",
      "1000it [01:35,  9.04it/s]Train epoch: 16 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003096\n",
      "1025it [01:38,  8.57it/s]Train epoch: 16 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.002946\n",
      "1050it [01:41,  8.73it/s]Train epoch: 16 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003129\n",
      "1075it [01:44,  8.77it/s]Train epoch: 16 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.003097\n",
      "1100it [01:47,  8.76it/s]Train epoch: 16 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.003201\n",
      "1125it [01:50,  8.74it/s]Train epoch: 16 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003070\n",
      "1150it [01:53,  8.44it/s]Train epoch: 16 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.002772\n",
      "1175it [01:55,  8.78it/s]Train epoch: 16 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003219\n",
      "1200it [01:58,  8.66it/s]Train epoch: 16 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.003424\n",
      "1225it [02:01,  8.52it/s]Train epoch: 16 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003214\n",
      "1250it [02:04,  8.45it/s]Train epoch: 16 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.003047\n",
      "1275it [02:07,  8.51it/s]Train epoch: 16 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.004050\n",
      "1300it [02:10,  8.63it/s]Train epoch: 16 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003283\n",
      "1325it [02:13,  8.53it/s]Train epoch: 16 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.003398\n",
      "1350it [02:16,  8.35it/s]Train epoch: 16 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.003018\n",
      "1375it [02:19,  8.20it/s]Train epoch: 16 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.003759\n",
      "1400it [02:22,  8.49it/s]Train epoch: 16 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003194\n",
      "1425it [02:25,  8.04it/s]Train epoch: 16 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.003324\n",
      "1450it [02:28,  8.04it/s]Train epoch: 16 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.003500\n",
      "1475it [02:31,  8.38it/s]Train epoch: 16 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.003438\n",
      "1500it [02:34,  7.89it/s]Train epoch: 16 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.003911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525it [02:37,  8.00it/s]Train epoch: 16 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.003478\n",
      "1550it [02:41,  7.93it/s]Train epoch: 16 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.003418\n",
      "1575it [02:44,  8.23it/s]Train epoch: 16 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.003231\n",
      "1600it [02:47,  7.98it/s]Train epoch: 16 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.003909\n",
      "1625it [02:50,  7.84it/s]Train epoch: 16 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.003664\n",
      "1650it [02:53,  8.01it/s]Train epoch: 16 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.003976\n",
      "1675it [02:56,  7.80it/s]Train epoch: 16 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.003646\n",
      "1700it [02:59,  7.74it/s]Train epoch: 16 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.003561\n",
      "1725it [03:03,  7.81it/s]Train epoch: 16 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.003605\n",
      "1750it [03:06,  7.64it/s]Train epoch: 16 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.003632\n",
      "1775it [03:09,  7.84it/s]Train epoch: 16 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.003785\n",
      "1800it [03:12,  7.53it/s]Train epoch: 16 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.003708\n",
      "1825it [03:16,  7.64it/s]Train epoch: 16 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.003522\n",
      "1850it [03:19,  7.68it/s]Train epoch: 16 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.003308\n",
      "1875it [03:22,  7.58it/s]Train epoch: 16 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.003675\n",
      "1900it [03:25,  7.86it/s]Train epoch: 16 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.004166\n",
      "1925it [03:29,  7.63it/s]Train epoch: 16 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.003542\n",
      "1950it [03:32,  7.27it/s]Train epoch: 16 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.003847\n",
      "1975it [03:35,  7.44it/s]Train epoch: 16 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.003863\n",
      "2000it [03:39,  7.56it/s]Train epoch: 16 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.003364\n",
      "2025it [03:42,  7.60it/s]Train epoch: 16 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.003671\n",
      "2050it [03:45,  7.37it/s]Train epoch: 16 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.003926\n",
      "2075it [03:49,  7.14it/s]Train epoch: 16 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.003809\n",
      "2100it [03:52,  7.38it/s]Train epoch: 16 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.003932\n",
      "2125it [03:56,  7.24it/s]Train epoch: 16 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.003721\n",
      "2150it [03:59,  7.37it/s]Train epoch: 16 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004079\n",
      "2175it [04:03,  7.15it/s]Train epoch: 16 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.003778\n",
      "2200it [04:06,  7.15it/s]Train epoch: 16 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.003617\n",
      "2225it [04:10,  7.04it/s]Train epoch: 16 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.003629\n",
      "2250it [04:13,  7.20it/s]Train epoch: 16 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.004149\n",
      "2275it [04:16,  7.19it/s]Train epoch: 16 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.003682\n",
      "2300it [04:20,  6.99it/s]Train epoch: 16 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.003502\n",
      "2325it [04:24,  7.12it/s]Train epoch: 16 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.004186\n",
      "2350it [04:27,  6.94it/s]Train epoch: 16 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.003603\n",
      "2375it [04:31,  7.12it/s]Train epoch: 16 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.004046\n",
      "2400it [04:34,  7.14it/s]Train epoch: 16 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.003969\n",
      "2425it [04:38,  6.90it/s]Train epoch: 16 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.003992\n",
      "2450it [04:41,  6.93it/s]Train epoch: 16 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.004010\n",
      "2475it [04:45,  6.93it/s]Train epoch: 16 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.003675\n",
      "2500it [04:49,  6.96it/s]Train epoch: 16 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.003951\n",
      "2525it [04:52,  6.88it/s]Train epoch: 16 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.003665\n",
      "2550it [04:56,  6.88it/s]Train epoch: 16 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.003925\n",
      "2575it [05:00,  6.99it/s]Train epoch: 16 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.004248\n",
      "2600it [05:03,  6.65it/s]Train epoch: 16 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.003909\n",
      "2625it [05:07,  6.91it/s]Train epoch: 16 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.003993\n",
      "2650it [05:11,  6.96it/s]Train epoch: 16 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.003760\n",
      "2675it [05:14,  6.75it/s]Train epoch: 16 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004044\n",
      "2700it [05:18,  6.80it/s]Train epoch: 16 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.004553\n",
      "2725it [05:22,  6.72it/s]Train epoch: 16 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.004240\n",
      "2750it [05:26,  6.72it/s]Train epoch: 16 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.004662\n",
      "2775it [05:29,  6.74it/s]Train epoch: 16 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.004134\n",
      "2800it [05:33,  6.51it/s]Train epoch: 16 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.004403\n",
      "2825it [05:37,  6.58it/s]Train epoch: 16 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.003827\n",
      "2850it [05:41,  6.56it/s]Train epoch: 16 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.004417\n",
      "2875it [05:45,  6.45it/s]Train epoch: 16 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.004868\n",
      "2900it [05:49,  6.53it/s]Train epoch: 16 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.004321\n",
      "2925it [05:52,  6.51it/s]Train epoch: 16 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.004472\n",
      "2950it [05:56,  6.50it/s]Train epoch: 16 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.004667\n",
      "2975it [06:00,  6.17it/s]Train epoch: 16 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.004161\n",
      "3000it [06:04,  6.34it/s]Train epoch: 16 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.004187\n",
      "3025it [06:08,  6.35it/s]Train epoch: 16 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.004280\n",
      "3050it [06:12,  6.33it/s]Train epoch: 16 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.004164\n",
      "3075it [06:16,  6.30it/s]Train epoch: 16 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.004365\n",
      "3100it [06:20,  6.23it/s]Train epoch: 16 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.004304\n",
      "3125it [06:24,  6.37it/s]Train epoch: 16 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.004040\n",
      "3150it [06:28,  6.25it/s]Train epoch: 16 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.004338\n",
      "3175it [06:32,  6.38it/s]Train epoch: 16 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.004735\n",
      "3200it [06:36,  6.33it/s]Train epoch: 16 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004129\n",
      "3225it [06:40,  6.11it/s]Train epoch: 16 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.004340\n",
      "3250it [06:44,  6.29it/s]Train epoch: 16 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.004679\n",
      "3275it [06:48,  6.15it/s]Train epoch: 16 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.004510\n",
      "3300it [06:52,  6.12it/s]Train epoch: 16 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.004778\n",
      "3325it [06:56,  6.01it/s]Train epoch: 16 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.004737\n",
      "3350it [07:00,  6.05it/s]Train epoch: 16 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.004748\n",
      "3375it [07:05,  6.03it/s]Train epoch: 16 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.004223\n",
      "3400it [07:09,  6.05it/s]Train epoch: 16 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.004712\n",
      "3425it [07:13,  6.00it/s]Train epoch: 16 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.004602\n",
      "3450it [07:17,  6.02it/s]Train epoch: 16 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.004517\n",
      "3475it [07:21,  5.87it/s]Train epoch: 16 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.005114\n",
      "3500it [07:25,  5.88it/s]Train epoch: 16 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.004501\n",
      "3525it [07:30,  5.91it/s]Train epoch: 16 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.004451\n",
      "3550it [07:34,  5.88it/s]Train epoch: 16 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.004809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3575it [07:38,  5.89it/s]Train epoch: 16 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.004845\n",
      "3600it [07:42,  5.83it/s]Train epoch: 16 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.004993\n",
      "3625it [07:47,  5.88it/s]Train epoch: 16 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.004468\n",
      "3650it [07:51,  5.75it/s]Train epoch: 16 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.004977\n",
      "3675it [07:55,  5.77it/s]Train epoch: 16 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.005107\n",
      "3700it [08:00,  5.72it/s]Train epoch: 16 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.004539\n",
      "3725it [08:04,  5.68it/s]Train epoch: 16 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.004956\n",
      "3750it [08:09,  5.64it/s]Train epoch: 16 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.004696\n",
      "3775it [08:13,  5.71it/s]Train epoch: 16 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.004979\n",
      "3800it [08:17,  5.55it/s]Train epoch: 16 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.005280\n",
      "3825it [08:22,  5.60it/s]Train epoch: 16 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.004818\n",
      "3850it [08:26,  5.19it/s]Train epoch: 16 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.004698\n",
      "3875it [08:31,  5.56it/s]Train epoch: 16 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.004978\n",
      "3900it [08:35,  5.57it/s]Train epoch: 16 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.005108\n",
      "3925it [08:40,  5.62it/s]Train epoch: 16 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.004382\n",
      "3950it [08:44,  5.62it/s]Train epoch: 16 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.004673\n",
      "3975it [08:49,  5.46it/s]Train epoch: 16 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.005093\n",
      "4000it [08:53,  5.46it/s]Train epoch: 16 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.004668\n",
      "4025it [08:58,  5.46it/s]Train epoch: 16 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.004636\n",
      "4050it [09:03,  5.53it/s]Train epoch: 16 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.004707\n",
      "4075it [09:07,  5.40it/s]Train epoch: 16 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.004650\n",
      "4100it [09:12,  5.42it/s]Train epoch: 16 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.004931\n",
      "4125it [09:16,  5.35it/s]Train epoch: 16 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.004949\n",
      "4150it [09:21,  5.34it/s]Train epoch: 16 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.005238\n",
      "4175it [09:26,  5.26it/s]Train epoch: 16 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.004814\n",
      "4200it [09:30,  5.26it/s]Train epoch: 16 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.004592\n",
      "4225it [09:35,  5.25it/s]Train epoch: 16 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.005058\n",
      "4250it [09:40,  5.29it/s]Train epoch: 16 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.005562\n",
      "4275it [09:45,  5.27it/s]Train epoch: 16 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.005152\n",
      "4300it [09:49,  5.28it/s]Train epoch: 16 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.004837\n",
      "4325it [09:54,  5.19it/s]Train epoch: 16 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.005282\n",
      "4350it [09:59,  5.11it/s]Train epoch: 16 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.005606\n",
      "4375it [10:04,  5.16it/s]Train epoch: 16 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.005172\n",
      "4400it [10:09,  5.11it/s]Train epoch: 16 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.005114\n",
      "4425it [10:14,  5.01it/s]Train epoch: 16 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.005257\n",
      "4450it [10:19,  5.04it/s]Train epoch: 16 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.005030\n",
      "4475it [10:24,  5.14it/s]Train epoch: 16 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.005846\n",
      "4500it [10:29,  4.98it/s]Train epoch: 16 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.005588\n",
      "4525it [10:34,  4.96it/s]Train epoch: 16 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.005346\n",
      "4550it [10:39,  4.96it/s]Train epoch: 16 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.005376\n",
      "4575it [10:44,  4.95it/s]Train epoch: 16 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.005025\n",
      "4600it [10:49,  5.00it/s]Train epoch: 16 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.005200\n",
      "4625it [10:54,  5.01it/s]Train epoch: 16 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.005694\n",
      "4650it [10:59,  4.84it/s]Train epoch: 16 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.005709\n",
      "4675it [11:04,  4.90it/s]Train epoch: 16 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.005686\n",
      "4700it [11:09,  4.89it/s]Train epoch: 16 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.005513\n",
      "4725it [11:14,  4.80it/s]Train epoch: 16 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.005499\n",
      "4750it [11:20,  4.81it/s]Train epoch: 16 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.005517\n",
      "4775it [11:25,  4.71it/s]Train epoch: 16 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.005657\n",
      "4800it [11:30,  4.67it/s]Train epoch: 16 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.005965\n",
      "4825it [11:35,  4.69it/s]Train epoch: 16 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.005132\n",
      "4850it [11:41,  4.66it/s]Train epoch: 16 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.005549\n",
      "4875it [11:46,  4.62it/s]Train epoch: 16 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.005732\n",
      "4900it [11:52,  4.57it/s]Train epoch: 16 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.005676\n",
      "4925it [11:57,  4.64it/s]Train epoch: 16 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.006091\n",
      "4950it [12:02,  4.57it/s]Train epoch: 16 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.006058\n",
      "4975it [12:08,  4.51it/s]Train epoch: 16 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.006161\n",
      "5000it [12:14,  4.54it/s]Train epoch: 16 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.005889\n",
      "5025it [12:19,  4.45it/s]Train epoch: 16 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.006422\n",
      "5050it [12:25,  4.42it/s]Train epoch: 16 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.006231\n",
      "5075it [12:30,  4.40it/s]Train epoch: 16 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.005871\n",
      "5100it [12:36,  4.40it/s]Train epoch: 16 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.005888\n",
      "5125it [12:42,  4.38it/s]Train epoch: 16 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.006448\n",
      "5150it [12:48,  4.32it/s]Train epoch: 16 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.006486\n",
      "5175it [12:53,  4.29it/s]Train epoch: 16 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.006195\n",
      "5200it [12:59,  4.28it/s]Train epoch: 16 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.006453\n",
      "5225it [13:05,  4.19it/s]Train epoch: 16 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.006534\n",
      "5250it [13:11,  4.21it/s]Train epoch: 16 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.006106\n",
      "5275it [13:17,  4.12it/s]Train epoch: 16 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.006477\n",
      "5300it [13:23,  4.20it/s]Train epoch: 16 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.006203\n",
      "5325it [13:29,  4.15it/s]Train epoch: 16 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.006243\n",
      "5350it [13:35,  4.05it/s]Train epoch: 16 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.006631\n",
      "5375it [13:41,  4.09it/s]Train epoch: 16 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.006932\n",
      "5400it [13:47,  4.00it/s]Train epoch: 16 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.006605\n",
      "5425it [13:54,  4.02it/s]Train epoch: 16 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.006552\n",
      "5450it [14:00,  3.97it/s]Train epoch: 16 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.006855\n",
      "5475it [14:06,  3.92it/s]Train epoch: 16 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.006712\n",
      "5500it [14:13,  3.89it/s]Train epoch: 16 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.006934\n",
      "5525it [14:19,  3.80it/s]Train epoch: 16 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.007193\n",
      "5550it [14:26,  3.78it/s]Train epoch: 16 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.007442\n",
      "5575it [14:32,  3.75it/s]Train epoch: 16 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.006595\n",
      "5600it [14:39,  3.71it/s]Train epoch: 16 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.006898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625it [14:46,  3.69it/s]Train epoch: 16 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.007352\n",
      "5650it [14:53,  3.60it/s]Train epoch: 16 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.006619\n",
      "5675it [15:00,  3.55it/s]Train epoch: 16 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.007731\n",
      "5700it [15:07,  3.47it/s]Train epoch: 16 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.007221\n",
      "5725it [15:14,  3.43it/s]Train epoch: 16 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.007567\n",
      "5750it [15:21,  3.36it/s]Train epoch: 16 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.007916\n",
      "5775it [15:29,  3.29it/s]Train epoch: 16 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.007418\n",
      "5800it [15:37,  3.23it/s]Train epoch: 16 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.007883\n",
      "5825it [15:45,  3.14it/s]Train epoch: 16 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.007992\n",
      "5850it [15:53,  3.00it/s]Train epoch: 16 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.007731\n",
      "5875it [16:01,  2.84it/s]Train epoch: 16 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.008498\n",
      "5900it [16:10,  2.76it/s]Train epoch: 16 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.007726\n",
      "5925it [16:20,  2.51it/s]Train epoch: 16 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.008896\n",
      "5950it [16:31,  2.17it/s]Train epoch: 16 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.009612\n",
      "5965it [16:38,  5.97it/s]\n",
      "epoch loss: 0.004583407830125328\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.37it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0286, 0.0436, 0.0466, 0.0450, 0.8392\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2522, 0.4570, 0.3601, 0.4028, 0.9731\n",
      "rec_at_8: 0.3004\n",
      "prec_at_8: 0.5600\n",
      "rec_at_15: 0.4097\n",
      "prec_at_15: 0.4235\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.18it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0292, 0.0480, 0.0480, 0.0480, 0.8421\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2477, 0.4582, 0.3503, 0.3970, 0.9730\n",
      "rec_at_8: 0.2860\n",
      "prec_at_8: 0.5533\n",
      "rec_at_15: 0.3950\n",
      "prec_at_15: 0.4237\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "EPOCH 17\n",
      "0it [00:00, ?it/s]Train epoch: 17 [batch #0, batch_size 8, seq length 512]\tLoss: 0.004584\n",
      "25it [00:01, 15.53it/s]Train epoch: 17 [batch #25, batch_size 8, seq length 512]\tLoss: 0.003231\n",
      "49it [00:03, 14.01it/s]Train epoch: 17 [batch #50, batch_size 8, seq length 512]\tLoss: 0.002862\n",
      "75it [00:05, 13.54it/s]Train epoch: 17 [batch #75, batch_size 8, seq length 512]\tLoss: 0.002607\n",
      "99it [00:06, 13.56it/s]Train epoch: 17 [batch #100, batch_size 8, seq length 512]\tLoss: 0.002843\n",
      "125it [00:08, 12.87it/s]Train epoch: 17 [batch #125, batch_size 8, seq length 512]\tLoss: 0.002542\n",
      "149it [00:10, 12.78it/s]Train epoch: 17 [batch #150, batch_size 8, seq length 512]\tLoss: 0.002620\n",
      "175it [00:12, 12.32it/s]Train epoch: 17 [batch #175, batch_size 8, seq length 512]\tLoss: 0.002842\n",
      "199it [00:14, 11.86it/s]Train epoch: 17 [batch #200, batch_size 8, seq length 512]\tLoss: 0.002324\n",
      "225it [00:17, 11.81it/s]Train epoch: 17 [batch #225, batch_size 8, seq length 512]\tLoss: 0.002641\n",
      "249it [00:19, 11.50it/s]Train epoch: 17 [batch #250, batch_size 8, seq length 512]\tLoss: 0.002565\n",
      "275it [00:21, 11.17it/s]Train epoch: 17 [batch #275, batch_size 8, seq length 512]\tLoss: 0.002722\n",
      "299it [00:23, 10.90it/s]Train epoch: 17 [batch #300, batch_size 8, seq length 512]\tLoss: 0.002805\n",
      "325it [00:25, 11.23it/s]Train epoch: 17 [batch #325, batch_size 8, seq length 512]\tLoss: 0.002762\n",
      "349it [00:28, 10.74it/s]Train epoch: 17 [batch #350, batch_size 8, seq length 512]\tLoss: 0.002645\n",
      "375it [00:30, 10.99it/s]Train epoch: 17 [batch #375, batch_size 8, seq length 512]\tLoss: 0.002720\n",
      "399it [00:32, 10.93it/s]Train epoch: 17 [batch #400, batch_size 8, seq length 512]\tLoss: 0.002590\n",
      "425it [00:34, 11.00it/s]Train epoch: 17 [batch #425, batch_size 8, seq length 512]\tLoss: 0.002949\n",
      "449it [00:37, 10.42it/s]Train epoch: 17 [batch #450, batch_size 8, seq length 512]\tLoss: 0.002655\n",
      "475it [00:39, 10.62it/s]Train epoch: 17 [batch #475, batch_size 8, seq length 512]\tLoss: 0.002569\n",
      "499it [00:42, 10.21it/s]Train epoch: 17 [batch #500, batch_size 8, seq length 512]\tLoss: 0.003055\n",
      "525it [00:44, 10.24it/s]Train epoch: 17 [batch #525, batch_size 8, seq length 512]\tLoss: 0.002764\n",
      "550it [00:47,  9.92it/s]Train epoch: 17 [batch #550, batch_size 8, seq length 512]\tLoss: 0.003043\n",
      "575it [00:49,  9.88it/s]Train epoch: 17 [batch #575, batch_size 8, seq length 512]\tLoss: 0.003068\n",
      "600it [00:52,  9.63it/s]Train epoch: 17 [batch #600, batch_size 8, seq length 512]\tLoss: 0.002869\n",
      "625it [00:54,  9.72it/s]Train epoch: 17 [batch #625, batch_size 8, seq length 512]\tLoss: 0.002854\n",
      "650it [00:57,  9.68it/s]Train epoch: 17 [batch #650, batch_size 8, seq length 512]\tLoss: 0.002933\n",
      "675it [00:59,  9.70it/s]Train epoch: 17 [batch #675, batch_size 8, seq length 512]\tLoss: 0.003564\n",
      "700it [01:02,  9.37it/s]Train epoch: 17 [batch #700, batch_size 8, seq length 512]\tLoss: 0.003011\n",
      "724it [01:05,  9.37it/s]Train epoch: 17 [batch #725, batch_size 8, seq length 512]\tLoss: 0.003009\n",
      "750it [01:07,  9.54it/s]Train epoch: 17 [batch #750, batch_size 8, seq length 512]\tLoss: 0.003639\n",
      "775it [01:10,  9.44it/s]Train epoch: 17 [batch #775, batch_size 8, seq length 512]\tLoss: 0.002785\n",
      "800it [01:13,  9.19it/s]Train epoch: 17 [batch #800, batch_size 8, seq length 512]\tLoss: 0.002650\n",
      "825it [01:15,  9.27it/s]Train epoch: 17 [batch #825, batch_size 8, seq length 512]\tLoss: 0.003026\n",
      "850it [01:18,  9.17it/s]Train epoch: 17 [batch #850, batch_size 8, seq length 512]\tLoss: 0.002975\n",
      "875it [01:21,  9.03it/s]Train epoch: 17 [batch #875, batch_size 8, seq length 512]\tLoss: 0.003227\n",
      "900it [01:23,  9.37it/s]Train epoch: 17 [batch #900, batch_size 8, seq length 512]\tLoss: 0.003002\n",
      "925it [01:26,  9.10it/s]Train epoch: 17 [batch #925, batch_size 8, seq length 512]\tLoss: 0.003211\n",
      "950it [01:29,  8.95it/s]Train epoch: 17 [batch #950, batch_size 8, seq length 512]\tLoss: 0.002426\n",
      "975it [01:32,  8.86it/s]Train epoch: 17 [batch #975, batch_size 8, seq length 512]\tLoss: 0.003208\n",
      "1000it [01:35,  8.67it/s]Train epoch: 17 [batch #1000, batch_size 8, seq length 512]\tLoss: 0.003016\n",
      "1025it [01:38,  9.00it/s]Train epoch: 17 [batch #1025, batch_size 8, seq length 512]\tLoss: 0.002865\n",
      "1050it [01:41,  8.75it/s]Train epoch: 17 [batch #1050, batch_size 8, seq length 512]\tLoss: 0.003062\n",
      "1075it [01:43,  8.88it/s]Train epoch: 17 [batch #1075, batch_size 8, seq length 512]\tLoss: 0.002988\n",
      "1100it [01:46,  8.57it/s]Train epoch: 17 [batch #1100, batch_size 8, seq length 512]\tLoss: 0.003145\n",
      "1125it [01:49,  8.69it/s]Train epoch: 17 [batch #1125, batch_size 8, seq length 512]\tLoss: 0.003006\n",
      "1150it [01:52,  8.67it/s]Train epoch: 17 [batch #1150, batch_size 8, seq length 512]\tLoss: 0.002697\n",
      "1175it [01:55,  8.69it/s]Train epoch: 17 [batch #1175, batch_size 8, seq length 512]\tLoss: 0.003179\n",
      "1200it [01:58,  8.64it/s]Train epoch: 17 [batch #1200, batch_size 8, seq length 512]\tLoss: 0.003359\n",
      "1225it [02:01,  8.36it/s]Train epoch: 17 [batch #1225, batch_size 8, seq length 512]\tLoss: 0.003182\n",
      "1250it [02:04,  8.43it/s]Train epoch: 17 [batch #1250, batch_size 8, seq length 512]\tLoss: 0.002941\n",
      "1275it [02:07,  8.40it/s]Train epoch: 17 [batch #1275, batch_size 8, seq length 512]\tLoss: 0.003996\n",
      "1300it [02:10,  8.48it/s]Train epoch: 17 [batch #1300, batch_size 8, seq length 512]\tLoss: 0.003202\n",
      "1325it [02:13,  8.60it/s]Train epoch: 17 [batch #1325, batch_size 8, seq length 512]\tLoss: 0.003349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350it [02:16,  8.15it/s]Train epoch: 17 [batch #1350, batch_size 8, seq length 512]\tLoss: 0.002963\n",
      "1375it [02:19,  8.06it/s]Train epoch: 17 [batch #1375, batch_size 8, seq length 512]\tLoss: 0.003730\n",
      "1400it [02:22,  8.10it/s]Train epoch: 17 [batch #1400, batch_size 8, seq length 512]\tLoss: 0.003063\n",
      "1425it [02:25,  8.15it/s]Train epoch: 17 [batch #1425, batch_size 8, seq length 512]\tLoss: 0.003236\n",
      "1450it [02:28,  8.00it/s]Train epoch: 17 [batch #1450, batch_size 8, seq length 512]\tLoss: 0.003430\n",
      "1475it [02:31,  7.97it/s]Train epoch: 17 [batch #1475, batch_size 8, seq length 512]\tLoss: 0.003383\n",
      "1500it [02:34,  8.02it/s]Train epoch: 17 [batch #1500, batch_size 8, seq length 512]\tLoss: 0.003843\n",
      "1525it [02:37,  8.06it/s]Train epoch: 17 [batch #1525, batch_size 8, seq length 512]\tLoss: 0.003427\n",
      "1550it [02:40,  8.10it/s]Train epoch: 17 [batch #1550, batch_size 8, seq length 512]\tLoss: 0.003316\n",
      "1575it [02:44,  7.96it/s]Train epoch: 17 [batch #1575, batch_size 8, seq length 512]\tLoss: 0.003201\n",
      "1600it [02:47,  7.97it/s]Train epoch: 17 [batch #1600, batch_size 8, seq length 512]\tLoss: 0.003807\n",
      "1625it [02:50,  8.07it/s]Train epoch: 17 [batch #1625, batch_size 8, seq length 512]\tLoss: 0.003599\n",
      "1650it [02:53,  7.94it/s]Train epoch: 17 [batch #1650, batch_size 8, seq length 512]\tLoss: 0.003874\n",
      "1675it [02:56,  7.78it/s]Train epoch: 17 [batch #1675, batch_size 8, seq length 512]\tLoss: 0.003530\n",
      "1700it [02:59,  7.71it/s]Train epoch: 17 [batch #1700, batch_size 8, seq length 512]\tLoss: 0.003484\n",
      "1725it [03:03,  7.67it/s]Train epoch: 17 [batch #1725, batch_size 8, seq length 512]\tLoss: 0.003573\n",
      "1750it [03:06,  7.79it/s]Train epoch: 17 [batch #1750, batch_size 8, seq length 512]\tLoss: 0.003550\n",
      "1775it [03:09,  7.69it/s]Train epoch: 17 [batch #1775, batch_size 8, seq length 512]\tLoss: 0.003641\n",
      "1800it [03:12,  7.71it/s]Train epoch: 17 [batch #1800, batch_size 8, seq length 512]\tLoss: 0.003659\n",
      "1825it [03:15,  7.68it/s]Train epoch: 17 [batch #1825, batch_size 8, seq length 512]\tLoss: 0.003492\n",
      "1850it [03:19,  7.47it/s]Train epoch: 17 [batch #1850, batch_size 8, seq length 512]\tLoss: 0.003248\n",
      "1875it [03:22,  7.74it/s]Train epoch: 17 [batch #1875, batch_size 8, seq length 512]\tLoss: 0.003561\n",
      "1900it [03:25,  7.53it/s]Train epoch: 17 [batch #1900, batch_size 8, seq length 512]\tLoss: 0.004116\n",
      "1925it [03:29,  7.14it/s]Train epoch: 17 [batch #1925, batch_size 8, seq length 512]\tLoss: 0.003544\n",
      "1950it [03:32,  7.59it/s]Train epoch: 17 [batch #1950, batch_size 8, seq length 512]\tLoss: 0.003718\n",
      "1975it [03:35,  7.48it/s]Train epoch: 17 [batch #1975, batch_size 8, seq length 512]\tLoss: 0.003822\n",
      "2000it [03:39,  7.40it/s]Train epoch: 17 [batch #2000, batch_size 8, seq length 512]\tLoss: 0.003269\n",
      "2025it [03:42,  7.33it/s]Train epoch: 17 [batch #2025, batch_size 8, seq length 512]\tLoss: 0.003530\n",
      "2050it [03:45,  7.38it/s]Train epoch: 17 [batch #2050, batch_size 8, seq length 512]\tLoss: 0.003871\n",
      "2075it [03:49,  7.56it/s]Train epoch: 17 [batch #2075, batch_size 8, seq length 512]\tLoss: 0.003702\n",
      "2100it [03:52,  7.44it/s]Train epoch: 17 [batch #2100, batch_size 8, seq length 512]\tLoss: 0.003851\n",
      "2125it [03:56,  7.32it/s]Train epoch: 17 [batch #2125, batch_size 8, seq length 512]\tLoss: 0.003657\n",
      "2150it [03:59,  7.33it/s]Train epoch: 17 [batch #2150, batch_size 8, seq length 512]\tLoss: 0.004035\n",
      "2175it [04:02,  7.34it/s]Train epoch: 17 [batch #2175, batch_size 8, seq length 512]\tLoss: 0.003706\n",
      "2200it [04:06,  7.24it/s]Train epoch: 17 [batch #2200, batch_size 8, seq length 512]\tLoss: 0.003559\n",
      "2225it [04:09,  7.20it/s]Train epoch: 17 [batch #2225, batch_size 8, seq length 512]\tLoss: 0.003570\n",
      "2250it [04:13,  7.28it/s]Train epoch: 17 [batch #2250, batch_size 8, seq length 512]\tLoss: 0.004020\n",
      "2275it [04:16,  7.30it/s]Train epoch: 17 [batch #2275, batch_size 8, seq length 512]\tLoss: 0.003645\n",
      "2300it [04:20,  7.19it/s]Train epoch: 17 [batch #2300, batch_size 8, seq length 512]\tLoss: 0.003458\n",
      "2325it [04:23,  6.98it/s]Train epoch: 17 [batch #2325, batch_size 8, seq length 512]\tLoss: 0.004083\n",
      "2350it [04:27,  7.20it/s]Train epoch: 17 [batch #2350, batch_size 8, seq length 512]\tLoss: 0.003526\n",
      "2375it [04:30,  7.01it/s]Train epoch: 17 [batch #2375, batch_size 8, seq length 512]\tLoss: 0.003988\n",
      "2400it [04:34,  7.03it/s]Train epoch: 17 [batch #2400, batch_size 8, seq length 512]\tLoss: 0.003836\n",
      "2425it [04:38,  7.01it/s]Train epoch: 17 [batch #2425, batch_size 8, seq length 512]\tLoss: 0.003934\n",
      "2450it [04:41,  6.95it/s]Train epoch: 17 [batch #2450, batch_size 8, seq length 512]\tLoss: 0.003907\n",
      "2475it [04:45,  6.91it/s]Train epoch: 17 [batch #2475, batch_size 8, seq length 512]\tLoss: 0.003618\n",
      "2500it [04:48,  6.85it/s]Train epoch: 17 [batch #2500, batch_size 8, seq length 512]\tLoss: 0.003989\n",
      "2525it [04:52,  6.89it/s]Train epoch: 17 [batch #2525, batch_size 8, seq length 512]\tLoss: 0.003568\n",
      "2550it [04:56,  6.96it/s]Train epoch: 17 [batch #2550, batch_size 8, seq length 512]\tLoss: 0.003827\n",
      "2575it [04:59,  6.76it/s]Train epoch: 17 [batch #2575, batch_size 8, seq length 512]\tLoss: 0.004186\n",
      "2600it [05:03,  6.73it/s]Train epoch: 17 [batch #2600, batch_size 8, seq length 512]\tLoss: 0.003788\n",
      "2625it [05:07,  6.73it/s]Train epoch: 17 [batch #2625, batch_size 8, seq length 512]\tLoss: 0.003910\n",
      "2650it [05:10,  6.75it/s]Train epoch: 17 [batch #2650, batch_size 8, seq length 512]\tLoss: 0.003656\n",
      "2675it [05:14,  6.85it/s]Train epoch: 17 [batch #2675, batch_size 8, seq length 512]\tLoss: 0.004003\n",
      "2700it [05:18,  6.81it/s]Train epoch: 17 [batch #2700, batch_size 8, seq length 512]\tLoss: 0.004472\n",
      "2725it [05:22,  6.70it/s]Train epoch: 17 [batch #2725, batch_size 8, seq length 512]\tLoss: 0.004154\n",
      "2750it [05:25,  6.65it/s]Train epoch: 17 [batch #2750, batch_size 8, seq length 512]\tLoss: 0.004545\n",
      "2775it [05:29,  6.82it/s]Train epoch: 17 [batch #2775, batch_size 8, seq length 512]\tLoss: 0.004041\n",
      "2800it [05:33,  6.64it/s]Train epoch: 17 [batch #2800, batch_size 8, seq length 512]\tLoss: 0.004300\n",
      "2825it [05:37,  6.62it/s]Train epoch: 17 [batch #2825, batch_size 8, seq length 512]\tLoss: 0.003727\n",
      "2850it [05:40,  6.60it/s]Train epoch: 17 [batch #2850, batch_size 8, seq length 512]\tLoss: 0.004332\n",
      "2875it [05:44,  6.59it/s]Train epoch: 17 [batch #2875, batch_size 8, seq length 512]\tLoss: 0.004811\n",
      "2900it [05:48,  6.56it/s]Train epoch: 17 [batch #2900, batch_size 8, seq length 512]\tLoss: 0.004235\n",
      "2925it [05:52,  6.47it/s]Train epoch: 17 [batch #2925, batch_size 8, seq length 512]\tLoss: 0.004385\n",
      "2950it [05:56,  6.45it/s]Train epoch: 17 [batch #2950, batch_size 8, seq length 512]\tLoss: 0.004586\n",
      "2975it [05:59,  6.47it/s]Train epoch: 17 [batch #2975, batch_size 8, seq length 512]\tLoss: 0.004075\n",
      "3000it [06:03,  6.46it/s]Train epoch: 17 [batch #3000, batch_size 8, seq length 512]\tLoss: 0.004162\n",
      "3025it [06:07,  6.44it/s]Train epoch: 17 [batch #3025, batch_size 8, seq length 512]\tLoss: 0.004183\n",
      "3050it [06:11,  6.31it/s]Train epoch: 17 [batch #3050, batch_size 8, seq length 512]\tLoss: 0.004062\n",
      "3075it [06:15,  6.45it/s]Train epoch: 17 [batch #3075, batch_size 8, seq length 512]\tLoss: 0.004297\n",
      "3100it [06:19,  6.26it/s]Train epoch: 17 [batch #3100, batch_size 8, seq length 512]\tLoss: 0.004226\n",
      "3125it [06:23,  6.26it/s]Train epoch: 17 [batch #3125, batch_size 8, seq length 512]\tLoss: 0.003925\n",
      "3150it [06:27,  6.28it/s]Train epoch: 17 [batch #3150, batch_size 8, seq length 512]\tLoss: 0.004247\n",
      "3175it [06:31,  6.24it/s]Train epoch: 17 [batch #3175, batch_size 8, seq length 512]\tLoss: 0.004605\n",
      "3200it [06:35,  6.24it/s]Train epoch: 17 [batch #3200, batch_size 8, seq length 512]\tLoss: 0.004045\n",
      "3225it [06:39,  6.33it/s]Train epoch: 17 [batch #3225, batch_size 8, seq length 512]\tLoss: 0.004266\n",
      "3250it [06:43,  6.24it/s]Train epoch: 17 [batch #3250, batch_size 8, seq length 512]\tLoss: 0.004529\n",
      "3275it [06:47,  6.18it/s]Train epoch: 17 [batch #3275, batch_size 8, seq length 512]\tLoss: 0.004450\n",
      "3300it [06:51,  6.14it/s]Train epoch: 17 [batch #3300, batch_size 8, seq length 512]\tLoss: 0.004747\n",
      "3325it [06:55,  6.12it/s]Train epoch: 17 [batch #3325, batch_size 8, seq length 512]\tLoss: 0.004701\n",
      "3350it [06:59,  6.05it/s]Train epoch: 17 [batch #3350, batch_size 8, seq length 512]\tLoss: 0.004617\n",
      "3375it [07:03,  6.08it/s]Train epoch: 17 [batch #3375, batch_size 8, seq length 512]\tLoss: 0.004093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400it [07:08,  6.10it/s]Train epoch: 17 [batch #3400, batch_size 8, seq length 512]\tLoss: 0.004554\n",
      "3425it [07:12,  6.08it/s]Train epoch: 17 [batch #3425, batch_size 8, seq length 512]\tLoss: 0.004516\n",
      "3450it [07:16,  6.01it/s]Train epoch: 17 [batch #3450, batch_size 8, seq length 512]\tLoss: 0.004452\n",
      "3475it [07:20,  5.98it/s]Train epoch: 17 [batch #3475, batch_size 8, seq length 512]\tLoss: 0.005013\n",
      "3500it [07:24,  5.93it/s]Train epoch: 17 [batch #3500, batch_size 8, seq length 512]\tLoss: 0.004415\n",
      "3525it [07:28,  5.85it/s]Train epoch: 17 [batch #3525, batch_size 8, seq length 512]\tLoss: 0.004381\n",
      "3550it [07:33,  5.94it/s]Train epoch: 17 [batch #3550, batch_size 8, seq length 512]\tLoss: 0.004677\n",
      "3575it [07:37,  5.85it/s]Train epoch: 17 [batch #3575, batch_size 8, seq length 512]\tLoss: 0.004842\n",
      "3600it [07:41,  5.88it/s]Train epoch: 17 [batch #3600, batch_size 8, seq length 512]\tLoss: 0.004948\n",
      "3625it [07:45,  5.85it/s]Train epoch: 17 [batch #3625, batch_size 8, seq length 512]\tLoss: 0.004349\n",
      "3650it [07:50,  5.82it/s]Train epoch: 17 [batch #3650, batch_size 8, seq length 512]\tLoss: 0.004845\n",
      "3675it [07:54,  5.76it/s]Train epoch: 17 [batch #3675, batch_size 8, seq length 512]\tLoss: 0.005011\n",
      "3700it [07:58,  5.79it/s]Train epoch: 17 [batch #3700, batch_size 8, seq length 512]\tLoss: 0.004450\n",
      "3725it [08:03,  5.74it/s]Train epoch: 17 [batch #3725, batch_size 8, seq length 512]\tLoss: 0.004874\n",
      "3750it [08:07,  5.69it/s]Train epoch: 17 [batch #3750, batch_size 8, seq length 512]\tLoss: 0.004626\n",
      "3775it [08:11,  5.70it/s]Train epoch: 17 [batch #3775, batch_size 8, seq length 512]\tLoss: 0.004892\n",
      "3800it [08:16,  5.68it/s]Train epoch: 17 [batch #3800, batch_size 8, seq length 512]\tLoss: 0.005240\n",
      "3825it [08:20,  5.71it/s]Train epoch: 17 [batch #3825, batch_size 8, seq length 512]\tLoss: 0.004764\n",
      "3850it [08:25,  5.62it/s]Train epoch: 17 [batch #3850, batch_size 8, seq length 512]\tLoss: 0.004620\n",
      "3875it [08:29,  5.75it/s]Train epoch: 17 [batch #3875, batch_size 8, seq length 512]\tLoss: 0.004867\n",
      "3900it [08:34,  5.55it/s]Train epoch: 17 [batch #3900, batch_size 8, seq length 512]\tLoss: 0.004935\n",
      "3925it [08:38,  5.60it/s]Train epoch: 17 [batch #3925, batch_size 8, seq length 512]\tLoss: 0.004293\n",
      "3950it [08:42,  5.61it/s]Train epoch: 17 [batch #3950, batch_size 8, seq length 512]\tLoss: 0.004562\n",
      "3975it [08:47,  5.52it/s]Train epoch: 17 [batch #3975, batch_size 8, seq length 512]\tLoss: 0.005022\n",
      "4000it [08:52,  5.47it/s]Train epoch: 17 [batch #4000, batch_size 8, seq length 512]\tLoss: 0.004601\n",
      "4025it [08:56,  5.43it/s]Train epoch: 17 [batch #4025, batch_size 8, seq length 512]\tLoss: 0.004569\n",
      "4050it [09:01,  5.44it/s]Train epoch: 17 [batch #4050, batch_size 8, seq length 512]\tLoss: 0.004609\n",
      "4075it [09:05,  5.47it/s]Train epoch: 17 [batch #4075, batch_size 8, seq length 512]\tLoss: 0.004566\n",
      "4100it [09:10,  5.42it/s]Train epoch: 17 [batch #4100, batch_size 8, seq length 512]\tLoss: 0.004824\n",
      "4125it [09:15,  5.40it/s]Train epoch: 17 [batch #4125, batch_size 8, seq length 512]\tLoss: 0.004932\n",
      "4150it [09:19,  5.46it/s]Train epoch: 17 [batch #4150, batch_size 8, seq length 512]\tLoss: 0.005094\n",
      "4175it [09:24,  5.35it/s]Train epoch: 17 [batch #4175, batch_size 8, seq length 512]\tLoss: 0.004786\n",
      "4200it [09:29,  5.31it/s]Train epoch: 17 [batch #4200, batch_size 8, seq length 512]\tLoss: 0.004446\n",
      "4225it [09:33,  5.26it/s]Train epoch: 17 [batch #4225, batch_size 8, seq length 512]\tLoss: 0.004965\n",
      "4250it [09:38,  5.34it/s]Train epoch: 17 [batch #4250, batch_size 8, seq length 512]\tLoss: 0.005494\n",
      "4275it [09:43,  5.23it/s]Train epoch: 17 [batch #4275, batch_size 8, seq length 512]\tLoss: 0.005062\n",
      "4300it [09:48,  5.22it/s]Train epoch: 17 [batch #4300, batch_size 8, seq length 512]\tLoss: 0.004737\n",
      "4325it [09:52,  5.19it/s]Train epoch: 17 [batch #4325, batch_size 8, seq length 512]\tLoss: 0.005217\n",
      "4350it [09:57,  5.11it/s]Train epoch: 17 [batch #4350, batch_size 8, seq length 512]\tLoss: 0.005465\n",
      "4375it [10:02,  5.21it/s]Train epoch: 17 [batch #4375, batch_size 8, seq length 512]\tLoss: 0.005058\n",
      "4400it [10:07,  5.06it/s]Train epoch: 17 [batch #4400, batch_size 8, seq length 512]\tLoss: 0.005000\n",
      "4425it [10:12,  5.00it/s]Train epoch: 17 [batch #4425, batch_size 8, seq length 512]\tLoss: 0.005159\n",
      "4450it [10:17,  5.09it/s]Train epoch: 17 [batch #4450, batch_size 8, seq length 512]\tLoss: 0.004904\n",
      "4475it [10:22,  5.02it/s]Train epoch: 17 [batch #4475, batch_size 8, seq length 512]\tLoss: 0.005778\n",
      "4500it [10:27,  4.98it/s]Train epoch: 17 [batch #4500, batch_size 8, seq length 512]\tLoss: 0.005512\n",
      "4525it [10:32,  5.00it/s]Train epoch: 17 [batch #4525, batch_size 8, seq length 512]\tLoss: 0.005213\n",
      "4550it [10:37,  5.00it/s]Train epoch: 17 [batch #4550, batch_size 8, seq length 512]\tLoss: 0.005219\n",
      "4575it [10:42,  4.97it/s]Train epoch: 17 [batch #4575, batch_size 8, seq length 512]\tLoss: 0.004924\n",
      "4600it [10:47,  5.04it/s]Train epoch: 17 [batch #4600, batch_size 8, seq length 512]\tLoss: 0.005123\n",
      "4625it [10:52,  4.94it/s]Train epoch: 17 [batch #4625, batch_size 8, seq length 512]\tLoss: 0.005658\n",
      "4650it [10:57,  4.94it/s]Train epoch: 17 [batch #4650, batch_size 8, seq length 512]\tLoss: 0.005606\n",
      "4675it [11:02,  4.88it/s]Train epoch: 17 [batch #4675, batch_size 8, seq length 512]\tLoss: 0.005596\n",
      "4700it [11:07,  4.91it/s]Train epoch: 17 [batch #4700, batch_size 8, seq length 512]\tLoss: 0.005407\n",
      "4725it [11:12,  4.72it/s]Train epoch: 17 [batch #4725, batch_size 8, seq length 512]\tLoss: 0.005390\n",
      "4750it [11:17,  4.77it/s]Train epoch: 17 [batch #4750, batch_size 8, seq length 512]\tLoss: 0.005445\n",
      "4775it [11:23,  4.71it/s]Train epoch: 17 [batch #4775, batch_size 8, seq length 512]\tLoss: 0.005565\n",
      "4800it [11:28,  4.77it/s]Train epoch: 17 [batch #4800, batch_size 8, seq length 512]\tLoss: 0.005864\n",
      "4825it [11:33,  4.70it/s]Train epoch: 17 [batch #4825, batch_size 8, seq length 512]\tLoss: 0.005066\n",
      "4850it [11:39,  4.67it/s]Train epoch: 17 [batch #4850, batch_size 8, seq length 512]\tLoss: 0.005507\n",
      "4875it [11:44,  4.65it/s]Train epoch: 17 [batch #4875, batch_size 8, seq length 512]\tLoss: 0.005672\n",
      "4900it [11:49,  4.64it/s]Train epoch: 17 [batch #4900, batch_size 8, seq length 512]\tLoss: 0.005535\n",
      "4925it [11:55,  4.58it/s]Train epoch: 17 [batch #4925, batch_size 8, seq length 512]\tLoss: 0.005924\n",
      "4950it [12:00,  4.52it/s]Train epoch: 17 [batch #4950, batch_size 8, seq length 512]\tLoss: 0.005914\n",
      "4975it [12:06,  4.64it/s]Train epoch: 17 [batch #4975, batch_size 8, seq length 512]\tLoss: 0.006082\n",
      "5000it [12:11,  4.52it/s]Train epoch: 17 [batch #5000, batch_size 8, seq length 512]\tLoss: 0.005774\n",
      "5025it [12:17,  4.53it/s]Train epoch: 17 [batch #5025, batch_size 8, seq length 512]\tLoss: 0.006350\n",
      "5050it [12:22,  4.44it/s]Train epoch: 17 [batch #5050, batch_size 8, seq length 512]\tLoss: 0.006170\n",
      "5075it [12:28,  4.37it/s]Train epoch: 17 [batch #5075, batch_size 8, seq length 512]\tLoss: 0.005772\n",
      "5100it [12:34,  4.43it/s]Train epoch: 17 [batch #5100, batch_size 8, seq length 512]\tLoss: 0.005755\n",
      "5125it [12:39,  4.39it/s]Train epoch: 17 [batch #5125, batch_size 8, seq length 512]\tLoss: 0.006286\n",
      "5150it [12:45,  4.35it/s]Train epoch: 17 [batch #5150, batch_size 8, seq length 512]\tLoss: 0.006317\n",
      "5175it [12:51,  4.30it/s]Train epoch: 17 [batch #5175, batch_size 8, seq length 512]\tLoss: 0.006083\n",
      "5200it [12:56,  4.30it/s]Train epoch: 17 [batch #5200, batch_size 8, seq length 512]\tLoss: 0.006355\n",
      "5225it [13:02,  4.29it/s]Train epoch: 17 [batch #5225, batch_size 8, seq length 512]\tLoss: 0.006434\n",
      "5250it [13:08,  4.17it/s]Train epoch: 17 [batch #5250, batch_size 8, seq length 512]\tLoss: 0.006076\n",
      "5275it [13:14,  4.23it/s]Train epoch: 17 [batch #5275, batch_size 8, seq length 512]\tLoss: 0.006395\n",
      "5300it [13:20,  4.25it/s]Train epoch: 17 [batch #5300, batch_size 8, seq length 512]\tLoss: 0.006092\n",
      "5325it [13:26,  4.19it/s]Train epoch: 17 [batch #5325, batch_size 8, seq length 512]\tLoss: 0.006099\n",
      "5350it [13:32,  4.12it/s]Train epoch: 17 [batch #5350, batch_size 8, seq length 512]\tLoss: 0.006532\n",
      "5375it [13:38,  4.08it/s]Train epoch: 17 [batch #5375, batch_size 8, seq length 512]\tLoss: 0.006848\n",
      "5400it [13:45,  4.01it/s]Train epoch: 17 [batch #5400, batch_size 8, seq length 512]\tLoss: 0.006499\n",
      "5425it [13:51,  4.02it/s]Train epoch: 17 [batch #5425, batch_size 8, seq length 512]\tLoss: 0.006440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5450it [13:57,  4.02it/s]Train epoch: 17 [batch #5450, batch_size 8, seq length 512]\tLoss: 0.006692\n",
      "5475it [14:03,  3.93it/s]Train epoch: 17 [batch #5475, batch_size 8, seq length 512]\tLoss: 0.006576\n",
      "5500it [14:10,  3.84it/s]Train epoch: 17 [batch #5500, batch_size 8, seq length 512]\tLoss: 0.006779\n",
      "5525it [14:16,  3.85it/s]Train epoch: 17 [batch #5525, batch_size 8, seq length 512]\tLoss: 0.007017\n",
      "5550it [14:23,  3.75it/s]Train epoch: 17 [batch #5550, batch_size 8, seq length 512]\tLoss: 0.007309\n",
      "5575it [14:29,  3.78it/s]Train epoch: 17 [batch #5575, batch_size 8, seq length 512]\tLoss: 0.006494\n",
      "5600it [14:36,  3.74it/s]Train epoch: 17 [batch #5600, batch_size 8, seq length 512]\tLoss: 0.006812\n",
      "5625it [14:43,  3.65it/s]Train epoch: 17 [batch #5625, batch_size 8, seq length 512]\tLoss: 0.007277\n",
      "5650it [14:50,  3.63it/s]Train epoch: 17 [batch #5650, batch_size 8, seq length 512]\tLoss: 0.006461\n",
      "5675it [14:57,  3.59it/s]Train epoch: 17 [batch #5675, batch_size 8, seq length 512]\tLoss: 0.007603\n",
      "5700it [15:04,  3.46it/s]Train epoch: 17 [batch #5700, batch_size 8, seq length 512]\tLoss: 0.007108\n",
      "5725it [15:11,  3.45it/s]Train epoch: 17 [batch #5725, batch_size 8, seq length 512]\tLoss: 0.007396\n",
      "5750it [15:19,  3.35it/s]Train epoch: 17 [batch #5750, batch_size 8, seq length 512]\tLoss: 0.007774\n",
      "5775it [15:26,  3.30it/s]Train epoch: 17 [batch #5775, batch_size 8, seq length 512]\tLoss: 0.007335\n",
      "5800it [15:34,  3.24it/s]Train epoch: 17 [batch #5800, batch_size 8, seq length 512]\tLoss: 0.007731\n",
      "5825it [15:42,  3.17it/s]Train epoch: 17 [batch #5825, batch_size 8, seq length 512]\tLoss: 0.007912\n",
      "5850it [15:50,  3.02it/s]Train epoch: 17 [batch #5850, batch_size 8, seq length 512]\tLoss: 0.007664\n",
      "5875it [15:58,  2.91it/s]Train epoch: 17 [batch #5875, batch_size 8, seq length 512]\tLoss: 0.008382\n",
      "5900it [16:07,  2.76it/s]Train epoch: 17 [batch #5900, batch_size 8, seq length 512]\tLoss: 0.007647\n",
      "5925it [16:17,  2.55it/s]Train epoch: 17 [batch #5925, batch_size 8, seq length 512]\tLoss: 0.008699\n",
      "5950it [16:27,  2.19it/s]Train epoch: 17 [batch #5950, batch_size 8, seq length 512]\tLoss: 0.009497\n",
      "5965it [16:35,  5.99it/s]\n",
      "epoch loss: 0.004497565337818207\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.34it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0289, 0.0433, 0.0464, 0.0448, 0.8375\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2500, 0.4535, 0.3578, 0.4000, 0.9727\n",
      "rec_at_8: 0.2990\n",
      "prec_at_8: 0.5572\n",
      "rec_at_15: 0.4082\n",
      "prec_at_15: 0.4220\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 47.17it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0294, 0.0487, 0.0484, 0.0485, 0.8398\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2451, 0.4529, 0.3482, 0.3937, 0.9725\n",
      "rec_at_8: 0.2834\n",
      "prec_at_8: 0.5479\n",
      "rec_at_15: 0.3924\n",
      "prec_at_15: 0.4205\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory ./outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "prec_at_8 hasn't improved in 3 epochs, early stopping...\n",
      "file for evaluation: ./mimicdata/mimic3/dev_full.csv\n",
      "1631it [00:34, 47.23it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0272, 0.0428, 0.0415, 0.0421, 0.8434\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2552, 0.5103, 0.3379, 0.4066, 0.9742\n",
      "rec_at_8: 0.3078\n",
      "prec_at_8: 0.5741\n",
      "rec_at_15: 0.4157\n",
      "prec_at_15: 0.4307\n",
      "\n",
      "\n",
      "evaluating on test\n",
      "file for evaluation: ./mimicdata/mimic3/test_full.csv\n",
      "3372it [01:11, 46.95it/s]\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0268, 0.0467, 0.0419, 0.0442, 0.8446\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2495, 0.5084, 0.3288, 0.3993, 0.9739\n",
      "rec_at_8: 0.2923\n",
      "prec_at_8: 0.5650\n",
      "rec_at_15: 0.4025\n",
      "prec_at_15: 0.4314\n",
      "\n",
      "\n",
      "------------------- Best (Dev) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0193, 0.0332, 0.0280, 0.0304, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2438, 0.5456, 0.3060, 0.3921, 0.9750\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Dev loss: 0.0076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------- Best (Test) -------------------\n",
      "Best Epoch: 9\n",
      "\n",
      "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.0187, 0.0366, 0.0273, 0.0313, 0.8454\n",
      "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
      "0.2347, 0.5403, 0.2933, 0.3802, 0.9746\n",
      "rec_at_5: 0.0000\n",
      "prec_at_5: 0.0000\n",
      "\n",
      "Test loss: 0.0079\n",
      "\n",
      "---------------------------------------------------\n",
      "saved metrics, params, model to directory /home/voyageth/develop/ml-for-healthcare/project/BERT-MIMIC3-ICD9/outputs/debug3/bert-tiny_Jun_28_02:59:39\n",
      "\n",
      "TOTAL ELAPSED TIME FOR bert-tiny MODEL AND 19 EPOCHS: 20525.512362\n"
     ]
    }
   ],
   "source": [
    "# bert-tiny 512 BPE\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny \\\n",
    "    50 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience 3 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 8 \\\n",
    "    --last_module caml_attn \\\n",
    "    --redefined_tokenizer \\\n",
    "    --max_sequence_length 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(Y='full', batch_size=1, bert_parallel_count=None, bert_parallel_final_layer='sum', bidirectional=None, cell_type='gru', code_emb=None, criterion='prec_at_8', cuda_device_no=None, data_path='./mimicdata/mimic3/train_full.csv', dropout=0.2, embed_file='./mimicdata/mimic3/processed_full.embed', embed_size=100, filter_size='10', from_prev_result=None, from_scratch=False, gpu=True, last_module='caml_attn', lmbda=0, lr=5e-05, max_sequence_length=512, model='bert', n_epochs=50, num_filter_maps=50, patience=3, pool=None, pos=False, pretrain=False, pretrain_batch_size=2, pretrain_datafile='./mimicdata/mimic3/pretrain_bert_tiny_2500', pretrain_epochs=3, pretrain_lr=0.0001, public_model=None, quiet=None, redefined_tokenizer=True, rnn_dim=128, rnn_layers=1, samples=None, seed=6590, stack_filters=None, test_model=None, tokenizer_path='./tokenizers/bert-tiny-mimic3-full-100-limit-100000-vocab.txt', version='mimic3', vocab='./mimicdata/mimic3/vocab.csv', warmup_steps=0, weight_decay=0)\n",
      "loading lookups...\n",
      "BertForMedical(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (redefined_word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (bert_pool): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (bert_attention): Linear(in_features=768, out_features=8921, bias=False)\n",
      "  (bert_classifier): Linear(in_features=768, out_features=8921, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "0it [00:00, ?it/s]Train epoch: 0 [batch #0, batch_size 1, seq length 512]\tLoss: 0.697936\n",
      "25it [00:03,  6.86it/s]Train epoch: 0 [batch #25, batch_size 1, seq length 512]\tLoss: 0.372363\n",
      "50it [00:06,  7.34it/s]Train epoch: 0 [batch #50, batch_size 1, seq length 512]\tLoss: 0.067787\n",
      "75it [00:10,  7.23it/s]Train epoch: 0 [batch #75, batch_size 1, seq length 512]\tLoss: 0.018845\n",
      "100it [00:13,  7.23it/s]Train epoch: 0 [batch #100, batch_size 1, seq length 512]\tLoss: 0.009995\n",
      "125it [00:17,  7.22it/s]Train epoch: 0 [batch #125, batch_size 1, seq length 512]\tLoss: 0.010885\n",
      "150it [00:20,  6.61it/s]Train epoch: 0 [batch #150, batch_size 1, seq length 512]\tLoss: 0.007646\n",
      "175it [00:24,  7.04it/s]Train epoch: 0 [batch #175, batch_size 1, seq length 512]\tLoss: 0.007008\n",
      "200it [00:28,  6.75it/s]Train epoch: 0 [batch #200, batch_size 1, seq length 512]\tLoss: 0.006867\n",
      "225it [00:31,  7.12it/s]Train epoch: 0 [batch #225, batch_size 1, seq length 512]\tLoss: 0.007759\n",
      "250it [00:35,  6.79it/s]Train epoch: 0 [batch #250, batch_size 1, seq length 512]\tLoss: 0.006897\n",
      "275it [00:38,  7.02it/s]Train epoch: 0 [batch #275, batch_size 1, seq length 512]\tLoss: 0.006283\n",
      "300it [00:42,  7.04it/s]Train epoch: 0 [batch #300, batch_size 1, seq length 512]\tLoss: 0.006204\n",
      "325it [00:46,  7.05it/s]Train epoch: 0 [batch #325, batch_size 1, seq length 512]\tLoss: 0.007120\n",
      "350it [00:49,  7.07it/s]Train epoch: 0 [batch #350, batch_size 1, seq length 512]\tLoss: 0.005707\n",
      "375it [00:53,  6.97it/s]Train epoch: 0 [batch #375, batch_size 1, seq length 512]\tLoss: 0.006624\n",
      "400it [00:56,  7.03it/s]Train epoch: 0 [batch #400, batch_size 1, seq length 512]\tLoss: 0.005478\n",
      "425it [01:00,  7.02it/s]Train epoch: 0 [batch #425, batch_size 1, seq length 512]\tLoss: 0.008865\n",
      "450it [01:03,  7.06it/s]Train epoch: 0 [batch #450, batch_size 1, seq length 512]\tLoss: 0.007053\n",
      "475it [01:07,  7.02it/s]Train epoch: 0 [batch #475, batch_size 1, seq length 512]\tLoss: 0.006459\n",
      "500it [01:10,  7.01it/s]Train epoch: 0 [batch #500, batch_size 1, seq length 512]\tLoss: 0.004742\n",
      "525it [01:14,  7.00it/s]Train epoch: 0 [batch #525, batch_size 1, seq length 512]\tLoss: 0.005242\n",
      "550it [01:18,  6.98it/s]Train epoch: 0 [batch #550, batch_size 1, seq length 512]\tLoss: 0.004714\n",
      "575it [01:21,  7.01it/s]Train epoch: 0 [batch #575, batch_size 1, seq length 512]\tLoss: 0.006630\n",
      "600it [01:25,  6.93it/s]Train epoch: 0 [batch #600, batch_size 1, seq length 512]\tLoss: 0.004991\n",
      "625it [01:28,  7.00it/s]Train epoch: 0 [batch #625, batch_size 1, seq length 512]\tLoss: 0.006901\n",
      "650it [01:32,  6.92it/s]Train epoch: 0 [batch #650, batch_size 1, seq length 512]\tLoss: 0.005820\n",
      "675it [01:35,  7.01it/s]Train epoch: 0 [batch #675, batch_size 1, seq length 512]\tLoss: 0.008789\n",
      "700it [01:39,  7.00it/s]Train epoch: 0 [batch #700, batch_size 1, seq length 512]\tLoss: 0.005754\n",
      "725it [01:43,  7.00it/s]Train epoch: 0 [batch #725, batch_size 1, seq length 512]\tLoss: 0.007174\n",
      "750it [01:46,  6.99it/s]Train epoch: 0 [batch #750, batch_size 1, seq length 512]\tLoss: 0.004865\n",
      "775it [01:50,  6.97it/s]Train epoch: 0 [batch #775, batch_size 1, seq length 512]\tLoss: 0.006392\n",
      "800it [01:53,  6.97it/s]Train epoch: 0 [batch #800, batch_size 1, seq length 512]\tLoss: 0.004834\n",
      "825it [01:57,  6.92it/s]Train epoch: 0 [batch #825, batch_size 1, seq length 512]\tLoss: 0.005530\n",
      "850it [02:01,  7.01it/s]Train epoch: 0 [batch #850, batch_size 1, seq length 512]\tLoss: 0.005836\n",
      "875it [02:04,  6.95it/s]Train epoch: 0 [batch #875, batch_size 1, seq length 512]\tLoss: 0.008868\n",
      "900it [02:08,  7.00it/s]Train epoch: 0 [batch #900, batch_size 1, seq length 512]\tLoss: 0.006152\n",
      "925it [02:11,  6.92it/s]Train epoch: 0 [batch #925, batch_size 1, seq length 512]\tLoss: 0.006455\n",
      "950it [02:15,  6.97it/s]Train epoch: 0 [batch #950, batch_size 1, seq length 512]\tLoss: 0.007277\n",
      "975it [02:18,  7.00it/s]Train epoch: 0 [batch #975, batch_size 1, seq length 512]\tLoss: 0.005607\n",
      "1000it [02:22,  7.00it/s]Train epoch: 0 [batch #1000, batch_size 1, seq length 512]\tLoss: 0.005596\n",
      "1025it [02:26,  7.02it/s]Train epoch: 0 [batch #1025, batch_size 1, seq length 512]\tLoss: 0.007022\n",
      "1050it [02:29,  6.98it/s]Train epoch: 0 [batch #1050, batch_size 1, seq length 512]\tLoss: 0.005118\n",
      "1075it [02:33,  7.00it/s]Train epoch: 0 [batch #1075, batch_size 1, seq length 512]\tLoss: 0.005225\n",
      "1100it [02:36,  6.89it/s]Train epoch: 0 [batch #1100, batch_size 1, seq length 512]\tLoss: 0.004511\n",
      "1125it [02:40,  6.90it/s]Train epoch: 0 [batch #1125, batch_size 1, seq length 512]\tLoss: 0.005324\n",
      "1150it [02:44,  7.02it/s]Train epoch: 0 [batch #1150, batch_size 1, seq length 512]\tLoss: 0.006267\n",
      "1175it [02:47,  7.02it/s]Train epoch: 0 [batch #1175, batch_size 1, seq length 512]\tLoss: 0.005150\n",
      "1200it [02:51,  7.01it/s]Train epoch: 0 [batch #1200, batch_size 1, seq length 512]\tLoss: 0.008566\n",
      "1225it [02:54,  6.97it/s]Train epoch: 0 [batch #1225, batch_size 1, seq length 512]\tLoss: 0.007194\n",
      "1250it [02:58,  6.99it/s]Train epoch: 0 [batch #1250, batch_size 1, seq length 512]\tLoss: 0.009061\n",
      "1275it [03:01,  7.02it/s]Train epoch: 0 [batch #1275, batch_size 1, seq length 512]\tLoss: 0.005555\n",
      "1300it [03:05,  6.97it/s]Train epoch: 0 [batch #1300, batch_size 1, seq length 512]\tLoss: 0.004663\n",
      "1325it [03:09,  7.00it/s]Train epoch: 0 [batch #1325, batch_size 1, seq length 512]\tLoss: 0.007284\n",
      "1350it [03:12,  6.97it/s]Train epoch: 0 [batch #1350, batch_size 1, seq length 512]\tLoss: 0.006354\n",
      "1375it [03:16,  6.98it/s]Train epoch: 0 [batch #1375, batch_size 1, seq length 512]\tLoss: 0.005382\n",
      "1400it [03:19,  7.05it/s]Train epoch: 0 [batch #1400, batch_size 1, seq length 512]\tLoss: 0.008090\n",
      "1425it [03:23,  6.98it/s]Train epoch: 0 [batch #1425, batch_size 1, seq length 512]\tLoss: 0.005198\n",
      "1450it [03:26,  6.95it/s]Train epoch: 0 [batch #1450, batch_size 1, seq length 512]\tLoss: 0.006456\n",
      "1475it [03:30,  7.01it/s]Train epoch: 0 [batch #1475, batch_size 1, seq length 512]\tLoss: 0.006364\n",
      "1500it [03:34,  6.95it/s]Train epoch: 0 [batch #1500, batch_size 1, seq length 512]\tLoss: 0.006881\n",
      "1525it [03:37,  7.01it/s]Train epoch: 0 [batch #1525, batch_size 1, seq length 512]\tLoss: 0.005718\n",
      "1550it [03:41,  6.97it/s]Train epoch: 0 [batch #1550, batch_size 1, seq length 512]\tLoss: 0.003927\n",
      "1575it [03:44,  6.99it/s]Train epoch: 0 [batch #1575, batch_size 1, seq length 512]\tLoss: 0.005490\n",
      "1600it [03:48,  7.04it/s]Train epoch: 0 [batch #1600, batch_size 1, seq length 512]\tLoss: 0.005005\n",
      "1625it [03:52,  7.00it/s]Train epoch: 0 [batch #1625, batch_size 1, seq length 512]\tLoss: 0.006431\n",
      "1650it [03:55,  7.04it/s]Train epoch: 0 [batch #1650, batch_size 1, seq length 512]\tLoss: 0.005644\n",
      "1675it [03:59,  6.98it/s]Train epoch: 0 [batch #1675, batch_size 1, seq length 512]\tLoss: 0.006071\n",
      "1700it [04:02,  6.96it/s]Train epoch: 0 [batch #1700, batch_size 1, seq length 512]\tLoss: 0.006211\n",
      "1725it [04:06,  7.06it/s]Train epoch: 0 [batch #1725, batch_size 1, seq length 512]\tLoss: 0.006073\n",
      "1750it [04:09,  6.95it/s]Train epoch: 0 [batch #1750, batch_size 1, seq length 512]\tLoss: 0.006924\n",
      "1775it [04:13,  6.96it/s]Train epoch: 0 [batch #1775, batch_size 1, seq length 512]\tLoss: 0.005282\n",
      "1800it [04:17,  6.96it/s]Train epoch: 0 [batch #1800, batch_size 1, seq length 512]\tLoss: 0.006384\n",
      "1825it [04:20,  6.99it/s]Train epoch: 0 [batch #1825, batch_size 1, seq length 512]\tLoss: 0.005035\n",
      "1850it [04:24,  6.98it/s]Train epoch: 0 [batch #1850, batch_size 1, seq length 512]\tLoss: 0.007351\n",
      "1875it [04:27,  6.98it/s]Train epoch: 0 [batch #1875, batch_size 1, seq length 512]\tLoss: 0.006209\n",
      "1900it [04:31,  6.94it/s]Train epoch: 0 [batch #1900, batch_size 1, seq length 512]\tLoss: 0.009939\n",
      "1925it [04:34,  7.04it/s]Train epoch: 0 [batch #1925, batch_size 1, seq length 512]\tLoss: 0.008229\n",
      "1950it [04:38,  6.83it/s]Train epoch: 0 [batch #1950, batch_size 1, seq length 512]\tLoss: 0.006796\n",
      "1975it [04:42,  6.96it/s]Train epoch: 0 [batch #1975, batch_size 1, seq length 512]\tLoss: 0.005427\n",
      "2000it [04:45,  7.00it/s]Train epoch: 0 [batch #2000, batch_size 1, seq length 512]\tLoss: 0.005687\n",
      "2025it [04:49,  6.98it/s]Train epoch: 0 [batch #2025, batch_size 1, seq length 512]\tLoss: 0.006356\n",
      "2050it [04:52,  7.01it/s]Train epoch: 0 [batch #2050, batch_size 1, seq length 512]\tLoss: 0.006707\n",
      "2075it [04:56,  6.97it/s]Train epoch: 0 [batch #2075, batch_size 1, seq length 512]\tLoss: 0.005889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100it [05:00,  6.99it/s]Train epoch: 0 [batch #2100, batch_size 1, seq length 512]\tLoss: 0.006317\n",
      "2125it [05:03,  7.02it/s]Train epoch: 0 [batch #2125, batch_size 1, seq length 512]\tLoss: 0.005736\n",
      "2150it [05:07,  7.00it/s]Train epoch: 0 [batch #2150, batch_size 1, seq length 512]\tLoss: 0.005185\n",
      "2175it [05:10,  6.99it/s]Train epoch: 0 [batch #2175, batch_size 1, seq length 512]\tLoss: 0.006178\n",
      "2200it [05:14,  7.00it/s]Train epoch: 0 [batch #2200, batch_size 1, seq length 512]\tLoss: 0.005878\n",
      "2225it [05:17,  7.01it/s]Train epoch: 0 [batch #2225, batch_size 1, seq length 512]\tLoss: 0.005574\n",
      "2250it [05:21,  7.00it/s]Train epoch: 0 [batch #2250, batch_size 1, seq length 512]\tLoss: 0.009046\n",
      "2275it [05:25,  6.96it/s]Train epoch: 0 [batch #2275, batch_size 1, seq length 512]\tLoss: 0.005657\n",
      "2300it [05:28,  7.02it/s]Train epoch: 0 [batch #2300, batch_size 1, seq length 512]\tLoss: 0.005934\n",
      "2325it [05:32,  7.00it/s]Train epoch: 0 [batch #2325, batch_size 1, seq length 512]\tLoss: 0.006080\n",
      "2350it [05:35,  7.02it/s]Train epoch: 0 [batch #2350, batch_size 1, seq length 512]\tLoss: 0.004807\n",
      "2375it [05:39,  6.99it/s]Train epoch: 0 [batch #2375, batch_size 1, seq length 512]\tLoss: 0.006435\n",
      "2400it [05:43,  6.99it/s]Train epoch: 0 [batch #2400, batch_size 1, seq length 512]\tLoss: 0.006509\n",
      "2425it [05:46,  7.00it/s]Train epoch: 0 [batch #2425, batch_size 1, seq length 512]\tLoss: 0.005360\n",
      "2450it [05:50,  7.00it/s]Train epoch: 0 [batch #2450, batch_size 1, seq length 512]\tLoss: 0.008912\n",
      "2475it [05:53,  7.00it/s]Train epoch: 0 [batch #2475, batch_size 1, seq length 512]\tLoss: 0.006021\n",
      "2500it [05:57,  6.98it/s]Train epoch: 0 [batch #2500, batch_size 1, seq length 512]\tLoss: 0.006682\n",
      "2525it [06:00,  7.04it/s]Train epoch: 0 [batch #2525, batch_size 1, seq length 512]\tLoss: 0.005399\n",
      "2550it [06:04,  6.98it/s]Train epoch: 0 [batch #2550, batch_size 1, seq length 512]\tLoss: 0.005760\n",
      "2575it [06:07,  7.01it/s]Train epoch: 0 [batch #2575, batch_size 1, seq length 512]\tLoss: 0.006076\n",
      "2600it [06:11,  7.02it/s]Train epoch: 0 [batch #2600, batch_size 1, seq length 512]\tLoss: 0.007203\n",
      "2625it [06:15,  6.99it/s]Train epoch: 0 [batch #2625, batch_size 1, seq length 512]\tLoss: 0.006976\n",
      "2650it [06:18,  6.98it/s]Train epoch: 0 [batch #2650, batch_size 1, seq length 512]\tLoss: 0.007138\n",
      "2675it [06:22,  7.04it/s]Train epoch: 0 [batch #2675, batch_size 1, seq length 512]\tLoss: 0.004658\n",
      "2700it [06:25,  6.99it/s]Train epoch: 0 [batch #2700, batch_size 1, seq length 512]\tLoss: 0.006474\n",
      "2725it [06:29,  6.99it/s]Train epoch: 0 [batch #2725, batch_size 1, seq length 512]\tLoss: 0.004543\n",
      "2750it [06:33,  7.00it/s]Train epoch: 0 [batch #2750, batch_size 1, seq length 512]\tLoss: 0.006447\n",
      "2775it [06:36,  6.82it/s]Train epoch: 0 [batch #2775, batch_size 1, seq length 512]\tLoss: 0.006864\n",
      "2800it [06:40,  7.04it/s]Train epoch: 0 [batch #2800, batch_size 1, seq length 512]\tLoss: 0.006387\n",
      "2825it [06:43,  6.98it/s]Train epoch: 0 [batch #2825, batch_size 1, seq length 512]\tLoss: 0.006998\n",
      "2850it [06:47,  7.01it/s]Train epoch: 0 [batch #2850, batch_size 1, seq length 512]\tLoss: 0.006559\n",
      "2875it [06:50,  7.01it/s]Train epoch: 0 [batch #2875, batch_size 1, seq length 512]\tLoss: 0.007347\n",
      "2900it [06:54,  7.00it/s]Train epoch: 0 [batch #2900, batch_size 1, seq length 512]\tLoss: 0.005004\n",
      "2925it [06:58,  6.96it/s]Train epoch: 0 [batch #2925, batch_size 1, seq length 512]\tLoss: 0.005140\n",
      "2950it [07:01,  6.68it/s]Train epoch: 0 [batch #2950, batch_size 1, seq length 512]\tLoss: 0.005083\n",
      "2975it [07:05,  6.92it/s]Train epoch: 0 [batch #2975, batch_size 1, seq length 512]\tLoss: 0.005689\n",
      "3000it [07:09,  6.66it/s]Train epoch: 0 [batch #3000, batch_size 1, seq length 512]\tLoss: 0.006277\n",
      "3025it [07:12,  6.87it/s]Train epoch: 0 [batch #3025, batch_size 1, seq length 512]\tLoss: 0.007265\n",
      "3050it [07:16,  7.10it/s]Train epoch: 0 [batch #3050, batch_size 1, seq length 512]\tLoss: 0.005440\n",
      "3075it [07:19,  7.08it/s]Train epoch: 0 [batch #3075, batch_size 1, seq length 512]\tLoss: 0.006166\n",
      "3100it [07:23,  7.05it/s]Train epoch: 0 [batch #3100, batch_size 1, seq length 512]\tLoss: 0.006387\n",
      "3125it [07:26,  7.00it/s]Train epoch: 0 [batch #3125, batch_size 1, seq length 512]\tLoss: 0.005184\n",
      "3150it [07:30,  7.04it/s]Train epoch: 0 [batch #3150, batch_size 1, seq length 512]\tLoss: 0.005054\n",
      "3175it [07:34,  7.01it/s]Train epoch: 0 [batch #3175, batch_size 1, seq length 512]\tLoss: 0.006912\n",
      "3200it [07:37,  7.09it/s]Train epoch: 0 [batch #3200, batch_size 1, seq length 512]\tLoss: 0.005417\n",
      "3225it [07:41,  7.02it/s]Train epoch: 0 [batch #3225, batch_size 1, seq length 512]\tLoss: 0.005239\n",
      "3250it [07:44,  7.03it/s]Train epoch: 0 [batch #3250, batch_size 1, seq length 512]\tLoss: 0.006035\n",
      "3275it [07:48,  7.08it/s]Train epoch: 0 [batch #3275, batch_size 1, seq length 512]\tLoss: 0.008098\n",
      "3300it [07:51,  7.09it/s]Train epoch: 0 [batch #3300, batch_size 1, seq length 512]\tLoss: 0.005419\n",
      "3325it [07:55,  7.07it/s]Train epoch: 0 [batch #3325, batch_size 1, seq length 512]\tLoss: 0.005537\n",
      "3350it [07:58,  7.05it/s]Train epoch: 0 [batch #3350, batch_size 1, seq length 512]\tLoss: 0.008139\n",
      "3375it [08:02,  7.07it/s]Train epoch: 0 [batch #3375, batch_size 1, seq length 512]\tLoss: 0.009071\n",
      "3400it [08:05,  7.05it/s]Train epoch: 0 [batch #3400, batch_size 1, seq length 512]\tLoss: 0.004808\n",
      "3425it [08:09,  7.08it/s]Train epoch: 0 [batch #3425, batch_size 1, seq length 512]\tLoss: 0.006670\n",
      "3450it [08:13,  7.04it/s]Train epoch: 0 [batch #3450, batch_size 1, seq length 512]\tLoss: 0.006133\n",
      "3475it [08:16,  7.07it/s]Train epoch: 0 [batch #3475, batch_size 1, seq length 512]\tLoss: 0.005468\n",
      "3500it [08:20,  7.05it/s]Train epoch: 0 [batch #3500, batch_size 1, seq length 512]\tLoss: 0.008716\n",
      "3525it [08:23,  7.07it/s]Train epoch: 0 [batch #3525, batch_size 1, seq length 512]\tLoss: 0.009095\n",
      "3550it [08:27,  6.96it/s]Train epoch: 0 [batch #3550, batch_size 1, seq length 512]\tLoss: 0.005260\n",
      "3575it [08:30,  6.98it/s]Train epoch: 0 [batch #3575, batch_size 1, seq length 512]\tLoss: 0.006125\n",
      "3600it [08:34,  7.00it/s]Train epoch: 0 [batch #3600, batch_size 1, seq length 512]\tLoss: 0.006923\n",
      "3625it [08:37,  6.92it/s]Train epoch: 0 [batch #3625, batch_size 1, seq length 512]\tLoss: 0.008850\n",
      "3650it [08:41,  7.01it/s]Train epoch: 0 [batch #3650, batch_size 1, seq length 512]\tLoss: 0.004457\n",
      "3675it [08:45,  6.99it/s]Train epoch: 0 [batch #3675, batch_size 1, seq length 512]\tLoss: 0.006170\n",
      "3700it [08:48,  7.05it/s]Train epoch: 0 [batch #3700, batch_size 1, seq length 512]\tLoss: 0.005930\n",
      "3725it [08:52,  6.92it/s]Train epoch: 0 [batch #3725, batch_size 1, seq length 512]\tLoss: 0.006393\n",
      "3750it [08:55,  6.98it/s]Train epoch: 0 [batch #3750, batch_size 1, seq length 512]\tLoss: 0.005423\n",
      "3775it [08:59,  6.96it/s]Train epoch: 0 [batch #3775, batch_size 1, seq length 512]\tLoss: 0.006127\n",
      "3800it [09:03,  7.00it/s]Train epoch: 0 [batch #3800, batch_size 1, seq length 512]\tLoss: 0.006042\n",
      "3825it [09:06,  7.02it/s]Train epoch: 0 [batch #3825, batch_size 1, seq length 512]\tLoss: 0.006004\n",
      "3850it [09:10,  7.02it/s]Train epoch: 0 [batch #3850, batch_size 1, seq length 512]\tLoss: 0.005219\n",
      "3875it [09:13,  7.03it/s]Train epoch: 0 [batch #3875, batch_size 1, seq length 512]\tLoss: 0.005048\n",
      "3900it [09:17,  7.01it/s]Train epoch: 0 [batch #3900, batch_size 1, seq length 512]\tLoss: 0.004991\n",
      "3925it [09:20,  7.25it/s]Train epoch: 0 [batch #3925, batch_size 1, seq length 512]\tLoss: 0.005997\n",
      "3950it [09:24,  7.21it/s]Train epoch: 0 [batch #3950, batch_size 1, seq length 512]\tLoss: 0.006769\n",
      "3975it [09:27,  6.90it/s]Train epoch: 0 [batch #3975, batch_size 1, seq length 512]\tLoss: 0.005290\n",
      "4000it [09:31,  6.91it/s]Train epoch: 0 [batch #4000, batch_size 1, seq length 512]\tLoss: 0.007986\n",
      "4025it [09:35,  7.01it/s]Train epoch: 0 [batch #4025, batch_size 1, seq length 512]\tLoss: 0.005775\n",
      "4050it [09:38,  6.98it/s]Train epoch: 0 [batch #4050, batch_size 1, seq length 512]\tLoss: 0.007590\n",
      "4075it [09:42,  7.01it/s]Train epoch: 0 [batch #4075, batch_size 1, seq length 512]\tLoss: 0.006718\n",
      "4100it [09:45,  7.03it/s]Train epoch: 0 [batch #4100, batch_size 1, seq length 512]\tLoss: 0.007808\n",
      "4125it [09:49,  6.98it/s]Train epoch: 0 [batch #4125, batch_size 1, seq length 512]\tLoss: 0.006452\n",
      "4150it [09:52,  6.99it/s]Train epoch: 0 [batch #4150, batch_size 1, seq length 512]\tLoss: 0.006480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4175it [09:56,  7.01it/s]Train epoch: 0 [batch #4175, batch_size 1, seq length 512]\tLoss: 0.005604\n",
      "4200it [10:00,  7.00it/s]Train epoch: 0 [batch #4200, batch_size 1, seq length 512]\tLoss: 0.005486\n",
      "4225it [10:03,  7.06it/s]Train epoch: 0 [batch #4225, batch_size 1, seq length 512]\tLoss: 0.007576\n",
      "4250it [10:07,  7.04it/s]Train epoch: 0 [batch #4250, batch_size 1, seq length 512]\tLoss: 0.006886\n",
      "4275it [10:10,  7.04it/s]Train epoch: 0 [batch #4275, batch_size 1, seq length 512]\tLoss: 0.007233\n",
      "4300it [10:14,  7.04it/s]Train epoch: 0 [batch #4300, batch_size 1, seq length 512]\tLoss: 0.005104\n",
      "4325it [10:17,  7.04it/s]Train epoch: 0 [batch #4325, batch_size 1, seq length 512]\tLoss: 0.007148\n",
      "4350it [10:21,  7.07it/s]Train epoch: 0 [batch #4350, batch_size 1, seq length 512]\tLoss: 0.006509\n",
      "4375it [10:24,  6.97it/s]Train epoch: 0 [batch #4375, batch_size 1, seq length 512]\tLoss: 0.007810\n",
      "4400it [10:28,  6.99it/s]Train epoch: 0 [batch #4400, batch_size 1, seq length 512]\tLoss: 0.005846\n",
      "4425it [10:32,  6.97it/s]Train epoch: 0 [batch #4425, batch_size 1, seq length 512]\tLoss: 0.005212\n",
      "4450it [10:35,  7.01it/s]Train epoch: 0 [batch #4450, batch_size 1, seq length 512]\tLoss: 0.007324\n",
      "4475it [10:39,  6.98it/s]Train epoch: 0 [batch #4475, batch_size 1, seq length 512]\tLoss: 0.009300\n",
      "4500it [10:42,  7.01it/s]Train epoch: 0 [batch #4500, batch_size 1, seq length 512]\tLoss: 0.004746\n",
      "4525it [10:46,  6.95it/s]Train epoch: 0 [batch #4525, batch_size 1, seq length 512]\tLoss: 0.005900\n",
      "4550it [10:49,  7.01it/s]Train epoch: 0 [batch #4550, batch_size 1, seq length 512]\tLoss: 0.006319\n",
      "4575it [10:53,  6.97it/s]Train epoch: 0 [batch #4575, batch_size 1, seq length 512]\tLoss: 0.006474\n",
      "4600it [10:57,  7.01it/s]Train epoch: 0 [batch #4600, batch_size 1, seq length 512]\tLoss: 0.007794\n",
      "4625it [11:00,  7.06it/s]Train epoch: 0 [batch #4625, batch_size 1, seq length 512]\tLoss: 0.005733\n",
      "4650it [11:04,  7.08it/s]Train epoch: 0 [batch #4650, batch_size 1, seq length 512]\tLoss: 0.006503\n",
      "4675it [11:07,  7.03it/s]Train epoch: 0 [batch #4675, batch_size 1, seq length 512]\tLoss: 0.004947\n",
      "4700it [11:11,  7.03it/s]Train epoch: 0 [batch #4700, batch_size 1, seq length 512]\tLoss: 0.009468\n",
      "4725it [11:14,  7.01it/s]Train epoch: 0 [batch #4725, batch_size 1, seq length 512]\tLoss: 0.006738\n",
      "4750it [11:18,  7.05it/s]Train epoch: 0 [batch #4750, batch_size 1, seq length 512]\tLoss: 0.005813\n",
      "4775it [11:22,  7.12it/s]Train epoch: 0 [batch #4775, batch_size 1, seq length 512]\tLoss: 0.008538\n",
      "4800it [11:25,  7.16it/s]Train epoch: 0 [batch #4800, batch_size 1, seq length 512]\tLoss: 0.007500\n",
      "4825it [11:28,  7.14it/s]Train epoch: 0 [batch #4825, batch_size 1, seq length 512]\tLoss: 0.007609\n",
      "4850it [11:32,  7.18it/s]Train epoch: 0 [batch #4850, batch_size 1, seq length 512]\tLoss: 0.008231\n",
      "4875it [11:35,  7.14it/s]Train epoch: 0 [batch #4875, batch_size 1, seq length 512]\tLoss: 0.008758\n",
      "4900it [11:39,  7.08it/s]Train epoch: 0 [batch #4900, batch_size 1, seq length 512]\tLoss: 0.006381\n",
      "4925it [11:43,  7.09it/s]Train epoch: 0 [batch #4925, batch_size 1, seq length 512]\tLoss: 0.007001\n",
      "4950it [11:46,  7.08it/s]Train epoch: 0 [batch #4950, batch_size 1, seq length 512]\tLoss: 0.005592\n",
      "4975it [11:50,  7.09it/s]Train epoch: 0 [batch #4975, batch_size 1, seq length 512]\tLoss: 0.006746\n",
      "5000it [11:53,  7.06it/s]Train epoch: 0 [batch #5000, batch_size 1, seq length 512]\tLoss: 0.007814\n",
      "5025it [11:57,  7.07it/s]Train epoch: 0 [batch #5025, batch_size 1, seq length 512]\tLoss: 0.007054\n",
      "5050it [12:00,  7.10it/s]Train epoch: 0 [batch #5050, batch_size 1, seq length 512]\tLoss: 0.005395\n",
      "5075it [12:04,  7.05it/s]Train epoch: 0 [batch #5075, batch_size 1, seq length 512]\tLoss: 0.006101\n",
      "5100it [12:07,  7.07it/s]Train epoch: 0 [batch #5100, batch_size 1, seq length 512]\tLoss: 0.004419\n",
      "5125it [12:11,  7.07it/s]Train epoch: 0 [batch #5125, batch_size 1, seq length 512]\tLoss: 0.006073\n",
      "5150it [12:14,  7.06it/s]Train epoch: 0 [batch #5150, batch_size 1, seq length 512]\tLoss: 0.006842\n",
      "5175it [12:18,  7.05it/s]Train epoch: 0 [batch #5175, batch_size 1, seq length 512]\tLoss: 0.005140\n",
      "5200it [12:21,  7.02it/s]Train epoch: 0 [batch #5200, batch_size 1, seq length 512]\tLoss: 0.006153\n",
      "5225it [12:25,  7.02it/s]Train epoch: 0 [batch #5225, batch_size 1, seq length 512]\tLoss: 0.006527\n",
      "5250it [12:29,  7.03it/s]Train epoch: 0 [batch #5250, batch_size 1, seq length 512]\tLoss: 0.007454\n",
      "5275it [12:32,  6.98it/s]Train epoch: 0 [batch #5275, batch_size 1, seq length 512]\tLoss: 0.006662\n",
      "5300it [12:36,  7.07it/s]Train epoch: 0 [batch #5300, batch_size 1, seq length 512]\tLoss: 0.006590\n",
      "5325it [12:39,  7.02it/s]Train epoch: 0 [batch #5325, batch_size 1, seq length 512]\tLoss: 0.007172\n",
      "5350it [12:43,  7.03it/s]Train epoch: 0 [batch #5350, batch_size 1, seq length 512]\tLoss: 0.008738\n",
      "5375it [12:46,  6.99it/s]Train epoch: 0 [batch #5375, batch_size 1, seq length 512]\tLoss: 0.006259\n",
      "5400it [12:50,  6.98it/s]Train epoch: 0 [batch #5400, batch_size 1, seq length 512]\tLoss: 0.007122\n",
      "5425it [12:54,  7.00it/s]Train epoch: 0 [batch #5425, batch_size 1, seq length 512]\tLoss: 0.005302\n",
      "5450it [12:57,  7.01it/s]Train epoch: 0 [batch #5450, batch_size 1, seq length 512]\tLoss: 0.006987\n",
      "5475it [13:01,  7.03it/s]Train epoch: 0 [batch #5475, batch_size 1, seq length 512]\tLoss: 0.005971\n",
      "5500it [13:04,  6.98it/s]Train epoch: 0 [batch #5500, batch_size 1, seq length 512]\tLoss: 0.007114\n",
      "5525it [13:08,  6.97it/s]Train epoch: 0 [batch #5525, batch_size 1, seq length 512]\tLoss: 0.008275\n",
      "5550it [13:11,  7.02it/s]Train epoch: 0 [batch #5550, batch_size 1, seq length 512]\tLoss: 0.007303\n",
      "5575it [13:15,  6.97it/s]Train epoch: 0 [batch #5575, batch_size 1, seq length 512]\tLoss: 0.006288\n",
      "5600it [13:19,  6.99it/s]Train epoch: 0 [batch #5600, batch_size 1, seq length 512]\tLoss: 0.005824\n",
      "5625it [13:22,  6.99it/s]Train epoch: 0 [batch #5625, batch_size 1, seq length 512]\tLoss: 0.006009\n",
      "5650it [13:26,  6.99it/s]Train epoch: 0 [batch #5650, batch_size 1, seq length 512]\tLoss: 0.007709\n",
      "5675it [13:29,  6.96it/s]Train epoch: 0 [batch #5675, batch_size 1, seq length 512]\tLoss: 0.005139\n",
      "5700it [13:33,  6.90it/s]Train epoch: 0 [batch #5700, batch_size 1, seq length 512]\tLoss: 0.007460\n",
      "5725it [13:37,  7.00it/s]Train epoch: 0 [batch #5725, batch_size 1, seq length 512]\tLoss: 0.004508\n",
      "5750it [13:40,  6.99it/s]Train epoch: 0 [batch #5750, batch_size 1, seq length 512]\tLoss: 0.006787\n",
      "5775it [13:44,  6.96it/s]Train epoch: 0 [batch #5775, batch_size 1, seq length 512]\tLoss: 0.005406\n",
      "5800it [13:47,  6.96it/s]Train epoch: 0 [batch #5800, batch_size 1, seq length 512]\tLoss: 0.006435\n",
      "5825it [13:51,  6.95it/s]Train epoch: 0 [batch #5825, batch_size 1, seq length 512]\tLoss: 0.005395\n",
      "5850it [13:54,  6.97it/s]Train epoch: 0 [batch #5850, batch_size 1, seq length 512]\tLoss: 0.008210\n",
      "5875it [13:58,  6.94it/s]Train epoch: 0 [batch #5875, batch_size 1, seq length 512]\tLoss: 0.004808\n",
      "5900it [14:02,  6.94it/s]Train epoch: 0 [batch #5900, batch_size 1, seq length 512]\tLoss: 0.007677\n",
      "5925it [14:05,  7.01it/s]Train epoch: 0 [batch #5925, batch_size 1, seq length 512]\tLoss: 0.005055\n",
      "5950it [14:09,  6.98it/s]Train epoch: 0 [batch #5950, batch_size 1, seq length 512]\tLoss: 0.007050\n",
      "5975it [14:12,  6.94it/s]Train epoch: 0 [batch #5975, batch_size 1, seq length 512]\tLoss: 0.007413\n",
      "6000it [14:16,  6.93it/s]Train epoch: 0 [batch #6000, batch_size 1, seq length 512]\tLoss: 0.006705\n",
      "6025it [14:20,  6.96it/s]Train epoch: 0 [batch #6025, batch_size 1, seq length 512]\tLoss: 0.005021\n",
      "6050it [14:23,  6.91it/s]Train epoch: 0 [batch #6050, batch_size 1, seq length 512]\tLoss: 0.005021\n",
      "6075it [14:27,  6.92it/s]Train epoch: 0 [batch #6075, batch_size 1, seq length 512]\tLoss: 0.004298\n",
      "6100it [14:30,  6.94it/s]Train epoch: 0 [batch #6100, batch_size 1, seq length 512]\tLoss: 0.007099\n",
      "6125it [14:34,  6.93it/s]Train epoch: 0 [batch #6125, batch_size 1, seq length 512]\tLoss: 0.007032\n",
      "6150it [14:38,  6.88it/s]Train epoch: 0 [batch #6150, batch_size 1, seq length 512]\tLoss: 0.006000\n",
      "6175it [14:41,  6.92it/s]Train epoch: 0 [batch #6175, batch_size 1, seq length 512]\tLoss: 0.006409\n",
      "6200it [14:45,  6.92it/s]Train epoch: 0 [batch #6200, batch_size 1, seq length 512]\tLoss: 0.005030\n",
      "6225it [14:49,  6.95it/s]Train epoch: 0 [batch #6225, batch_size 1, seq length 512]\tLoss: 0.006204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250it [14:52,  6.93it/s]Train epoch: 0 [batch #6250, batch_size 1, seq length 512]\tLoss: 0.005371\n",
      "6275it [14:56,  6.95it/s]Train epoch: 0 [batch #6275, batch_size 1, seq length 512]\tLoss: 0.007794\n",
      "6300it [14:59,  6.94it/s]Train epoch: 0 [batch #6300, batch_size 1, seq length 512]\tLoss: 0.005145\n",
      "6325it [15:03,  6.95it/s]Train epoch: 0 [batch #6325, batch_size 1, seq length 512]\tLoss: 0.006247\n",
      "6350it [15:07,  6.89it/s]Train epoch: 0 [batch #6350, batch_size 1, seq length 512]\tLoss: 0.005149\n",
      "6375it [15:10,  6.93it/s]Train epoch: 0 [batch #6375, batch_size 1, seq length 512]\tLoss: 0.007195\n",
      "6400it [15:14,  6.97it/s]Train epoch: 0 [batch #6400, batch_size 1, seq length 512]\tLoss: 0.005176\n",
      "6425it [15:17,  7.00it/s]Train epoch: 0 [batch #6425, batch_size 1, seq length 512]\tLoss: 0.007236\n",
      "6450it [15:21,  6.94it/s]Train epoch: 0 [batch #6450, batch_size 1, seq length 512]\tLoss: 0.006460\n",
      "6475it [15:25,  6.92it/s]Train epoch: 0 [batch #6475, batch_size 1, seq length 512]\tLoss: 0.007126\n",
      "6500it [15:28,  6.89it/s]Train epoch: 0 [batch #6500, batch_size 1, seq length 512]\tLoss: 0.007140\n",
      "6525it [15:32,  6.89it/s]Train epoch: 0 [batch #6525, batch_size 1, seq length 512]\tLoss: 0.007014\n",
      "6550it [15:35,  6.89it/s]Train epoch: 0 [batch #6550, batch_size 1, seq length 512]\tLoss: 0.006400\n",
      "6575it [15:39,  6.95it/s]Train epoch: 0 [batch #6575, batch_size 1, seq length 512]\tLoss: 0.006366\n",
      "6600it [15:43,  6.95it/s]Train epoch: 0 [batch #6600, batch_size 1, seq length 512]\tLoss: 0.006007\n",
      "6625it [15:46,  6.88it/s]Train epoch: 0 [batch #6625, batch_size 1, seq length 512]\tLoss: 0.006625\n",
      "6650it [15:50,  6.94it/s]Train epoch: 0 [batch #6650, batch_size 1, seq length 512]\tLoss: 0.003648\n",
      "6675it [15:54,  6.91it/s]Train epoch: 0 [batch #6675, batch_size 1, seq length 512]\tLoss: 0.007686\n",
      "6700it [15:57,  6.89it/s]Train epoch: 0 [batch #6700, batch_size 1, seq length 512]\tLoss: 0.006117\n",
      "6725it [16:01,  6.86it/s]Train epoch: 0 [batch #6725, batch_size 1, seq length 512]\tLoss: 0.006144\n",
      "6750it [16:04,  6.94it/s]Train epoch: 0 [batch #6750, batch_size 1, seq length 512]\tLoss: 0.008675\n",
      "6775it [16:08,  6.93it/s]Train epoch: 0 [batch #6775, batch_size 1, seq length 512]\tLoss: 0.007453\n",
      "6800it [16:12,  6.91it/s]Train epoch: 0 [batch #6800, batch_size 1, seq length 512]\tLoss: 0.005546\n",
      "6825it [16:15,  6.91it/s]Train epoch: 0 [batch #6825, batch_size 1, seq length 512]\tLoss: 0.006765\n",
      "6850it [16:19,  6.95it/s]Train epoch: 0 [batch #6850, batch_size 1, seq length 512]\tLoss: 0.007880\n",
      "6875it [16:22,  6.91it/s]Train epoch: 0 [batch #6875, batch_size 1, seq length 512]\tLoss: 0.006274\n",
      "6900it [16:26,  6.99it/s]Train epoch: 0 [batch #6900, batch_size 1, seq length 512]\tLoss: 0.005266\n",
      "6925it [16:30,  6.96it/s]Train epoch: 0 [batch #6925, batch_size 1, seq length 512]\tLoss: 0.006329\n",
      "6950it [16:33,  6.92it/s]Train epoch: 0 [batch #6950, batch_size 1, seq length 512]\tLoss: 0.006192\n",
      "6975it [16:37,  6.88it/s]Train epoch: 0 [batch #6975, batch_size 1, seq length 512]\tLoss: 0.006533\n",
      "7000it [16:41,  6.90it/s]Train epoch: 0 [batch #7000, batch_size 1, seq length 512]\tLoss: 0.008320\n",
      "7025it [16:44,  6.89it/s]Train epoch: 0 [batch #7025, batch_size 1, seq length 512]\tLoss: 0.008414\n",
      "7050it [16:48,  6.95it/s]Train epoch: 0 [batch #7050, batch_size 1, seq length 512]\tLoss: 0.005637\n",
      "7075it [16:51,  6.86it/s]Train epoch: 0 [batch #7075, batch_size 1, seq length 512]\tLoss: 0.189395\n",
      "7100it [16:55,  6.90it/s]Train epoch: 0 [batch #7100, batch_size 1, seq length 512]\tLoss: 0.006397\n",
      "7125it [16:59,  6.89it/s]Train epoch: 0 [batch #7125, batch_size 1, seq length 512]\tLoss: 0.006691\n",
      "7150it [17:02,  6.91it/s]Train epoch: 0 [batch #7150, batch_size 1, seq length 512]\tLoss: 0.005623\n",
      "7175it [17:06,  6.87it/s]Train epoch: 0 [batch #7175, batch_size 1, seq length 512]\tLoss: 0.004923\n",
      "7200it [17:10,  6.91it/s]Train epoch: 0 [batch #7200, batch_size 1, seq length 512]\tLoss: 0.006578\n",
      "7225it [17:13,  6.91it/s]Train epoch: 0 [batch #7225, batch_size 1, seq length 512]\tLoss: 0.006718\n",
      "7250it [17:17,  6.90it/s]Train epoch: 0 [batch #7250, batch_size 1, seq length 512]\tLoss: 0.006727\n",
      "7275it [17:20,  6.95it/s]Train epoch: 0 [batch #7275, batch_size 1, seq length 512]\tLoss: 0.005896\n",
      "7300it [17:24,  6.90it/s]Train epoch: 0 [batch #7300, batch_size 1, seq length 512]\tLoss: 0.007255\n",
      "7325it [17:28,  6.93it/s]Train epoch: 0 [batch #7325, batch_size 1, seq length 512]\tLoss: 0.005354\n",
      "7350it [17:31,  6.80it/s]Train epoch: 0 [batch #7350, batch_size 1, seq length 512]\tLoss: 0.007676\n",
      "7375it [17:35,  6.92it/s]Train epoch: 0 [batch #7375, batch_size 1, seq length 512]\tLoss: 0.006810\n",
      "7400it [17:38,  6.92it/s]Train epoch: 0 [batch #7400, batch_size 1, seq length 512]\tLoss: 0.006160\n",
      "7425it [17:42,  6.81it/s]Train epoch: 0 [batch #7425, batch_size 1, seq length 512]\tLoss: 0.006327\n",
      "7450it [17:46,  6.87it/s]Train epoch: 0 [batch #7450, batch_size 1, seq length 512]\tLoss: 0.006214\n",
      "7475it [17:49,  6.99it/s]Train epoch: 0 [batch #7475, batch_size 1, seq length 512]\tLoss: 0.006816\n",
      "7500it [17:53,  6.41it/s]Train epoch: 0 [batch #7500, batch_size 1, seq length 512]\tLoss: 0.008083\n",
      "7525it [17:57,  6.49it/s]Train epoch: 0 [batch #7525, batch_size 1, seq length 512]\tLoss: 0.006733\n",
      "7550it [18:01,  6.89it/s]Train epoch: 0 [batch #7550, batch_size 1, seq length 512]\tLoss: 0.004773\n",
      "7575it [18:04,  6.60it/s]Train epoch: 0 [batch #7575, batch_size 1, seq length 512]\tLoss: 0.005454\n",
      "7600it [18:08,  6.68it/s]Train epoch: 0 [batch #7600, batch_size 1, seq length 512]\tLoss: 0.005822\n",
      "7625it [18:12,  6.76it/s]Train epoch: 0 [batch #7625, batch_size 1, seq length 512]\tLoss: 0.006197\n",
      "7650it [18:16,  6.69it/s]Train epoch: 0 [batch #7650, batch_size 1, seq length 512]\tLoss: 0.005220\n",
      "7675it [18:19,  6.89it/s]Train epoch: 0 [batch #7675, batch_size 1, seq length 512]\tLoss: 0.006294\n",
      "7700it [18:23,  6.91it/s]Train epoch: 0 [batch #7700, batch_size 1, seq length 512]\tLoss: 0.006644\n",
      "7725it [18:27,  6.86it/s]Train epoch: 0 [batch #7725, batch_size 1, seq length 512]\tLoss: 0.008094\n",
      "7750it [18:30,  6.86it/s]Train epoch: 0 [batch #7750, batch_size 1, seq length 512]\tLoss: 0.008123\n",
      "7775it [18:34,  6.84it/s]Train epoch: 0 [batch #7775, batch_size 1, seq length 512]\tLoss: 0.005849\n",
      "7800it [18:38,  6.78it/s]Train epoch: 0 [batch #7800, batch_size 1, seq length 512]\tLoss: 0.006190\n",
      "7825it [18:41,  6.86it/s]Train epoch: 0 [batch #7825, batch_size 1, seq length 512]\tLoss: 0.007506\n",
      "7850it [18:45,  6.76it/s]Train epoch: 0 [batch #7850, batch_size 1, seq length 512]\tLoss: 0.007151\n",
      "7875it [18:49,  6.56it/s]Train epoch: 0 [batch #7875, batch_size 1, seq length 512]\tLoss: 0.008265\n",
      "7900it [18:53,  6.69it/s]Train epoch: 0 [batch #7900, batch_size 1, seq length 512]\tLoss: 0.007193\n",
      "7925it [18:56,  6.78it/s]Train epoch: 0 [batch #7925, batch_size 1, seq length 512]\tLoss: 0.007235\n",
      "7950it [19:00,  6.85it/s]Train epoch: 0 [batch #7950, batch_size 1, seq length 512]\tLoss: 0.006104\n",
      "7975it [19:04,  6.81it/s]Train epoch: 0 [batch #7975, batch_size 1, seq length 512]\tLoss: 0.005921\n",
      "8000it [19:07,  6.93it/s]Train epoch: 0 [batch #8000, batch_size 1, seq length 512]\tLoss: 0.005844\n",
      "8025it [19:11,  6.22it/s]Train epoch: 0 [batch #8025, batch_size 1, seq length 512]\tLoss: 0.008568\n",
      "8050it [19:15,  6.39it/s]Train epoch: 0 [batch #8050, batch_size 1, seq length 512]\tLoss: 0.006525\n",
      "8075it [19:19,  6.91it/s]Train epoch: 0 [batch #8075, batch_size 1, seq length 512]\tLoss: 0.007672\n",
      "8100it [19:22,  7.04it/s]Train epoch: 0 [batch #8100, batch_size 1, seq length 512]\tLoss: 0.006434\n",
      "8125it [19:26,  6.94it/s]Train epoch: 0 [batch #8125, batch_size 1, seq length 512]\tLoss: 0.006589\n",
      "8150it [19:29,  7.07it/s]Train epoch: 0 [batch #8150, batch_size 1, seq length 512]\tLoss: 0.005333\n",
      "8175it [19:33,  6.99it/s]Train epoch: 0 [batch #8175, batch_size 1, seq length 512]\tLoss: 0.007428\n",
      "8200it [19:37,  6.95it/s]Train epoch: 0 [batch #8200, batch_size 1, seq length 512]\tLoss: 0.005844\n",
      "8225it [19:40,  6.97it/s]Train epoch: 0 [batch #8225, batch_size 1, seq length 512]\tLoss: 0.005818\n",
      "8250it [19:44,  7.00it/s]Train epoch: 0 [batch #8250, batch_size 1, seq length 512]\tLoss: 0.006116\n",
      "8275it [19:47,  7.00it/s]Train epoch: 0 [batch #8275, batch_size 1, seq length 512]\tLoss: 0.005997\n",
      "8300it [19:51,  6.97it/s]Train epoch: 0 [batch #8300, batch_size 1, seq length 512]\tLoss: 0.006614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8325it [19:55,  6.94it/s]Train epoch: 0 [batch #8325, batch_size 1, seq length 512]\tLoss: 0.008293\n",
      "8350it [19:58,  7.06it/s]Train epoch: 0 [batch #8350, batch_size 1, seq length 512]\tLoss: 0.007220\n",
      "8375it [20:02,  6.98it/s]Train epoch: 0 [batch #8375, batch_size 1, seq length 512]\tLoss: 0.007653\n",
      "8400it [20:05,  6.97it/s]Train epoch: 0 [batch #8400, batch_size 1, seq length 512]\tLoss: 0.007147\n",
      "8425it [20:09,  6.98it/s]Train epoch: 0 [batch #8425, batch_size 1, seq length 512]\tLoss: 0.007585\n",
      "8450it [20:12,  7.01it/s]Train epoch: 0 [batch #8450, batch_size 1, seq length 512]\tLoss: 0.008075\n",
      "8475it [20:16,  7.01it/s]Train epoch: 0 [batch #8475, batch_size 1, seq length 512]\tLoss: 0.009446\n",
      "8500it [20:20,  6.82it/s]Train epoch: 0 [batch #8500, batch_size 1, seq length 512]\tLoss: 0.005966\n",
      "8525it [20:23,  6.98it/s]Train epoch: 0 [batch #8525, batch_size 1, seq length 512]\tLoss: 0.007127\n",
      "8550it [20:27,  6.98it/s]Train epoch: 0 [batch #8550, batch_size 1, seq length 512]\tLoss: 0.006471\n",
      "8575it [20:30,  6.98it/s]Train epoch: 0 [batch #8575, batch_size 1, seq length 512]\tLoss: 0.006915\n",
      "8600it [20:34,  6.97it/s]Train epoch: 0 [batch #8600, batch_size 1, seq length 512]\tLoss: 0.005983\n",
      "8625it [20:38,  6.98it/s]Train epoch: 0 [batch #8625, batch_size 1, seq length 512]\tLoss: 0.008205\n",
      "8650it [20:41,  6.97it/s]Train epoch: 0 [batch #8650, batch_size 1, seq length 512]\tLoss: 0.007830\n",
      "8675it [20:45,  6.96it/s]Train epoch: 0 [batch #8675, batch_size 1, seq length 512]\tLoss: 0.007434\n",
      "8700it [20:48,  6.93it/s]Train epoch: 0 [batch #8700, batch_size 1, seq length 512]\tLoss: 0.006678\n",
      "8725it [20:52,  7.01it/s]Train epoch: 0 [batch #8725, batch_size 1, seq length 512]\tLoss: 0.005324\n",
      "8750it [20:55,  6.96it/s]Train epoch: 0 [batch #8750, batch_size 1, seq length 512]\tLoss: 0.006228\n",
      "8775it [20:59,  7.00it/s]Train epoch: 0 [batch #8775, batch_size 1, seq length 512]\tLoss: 0.007643\n",
      "8800it [21:03,  6.95it/s]Train epoch: 0 [batch #8800, batch_size 1, seq length 512]\tLoss: 0.005325\n",
      "8825it [21:06,  6.97it/s]Train epoch: 0 [batch #8825, batch_size 1, seq length 512]\tLoss: 0.007662\n",
      "8850it [21:10,  6.97it/s]Train epoch: 0 [batch #8850, batch_size 1, seq length 512]\tLoss: 0.005913\n",
      "8875it [21:13,  6.93it/s]Train epoch: 0 [batch #8875, batch_size 1, seq length 512]\tLoss: 0.006346\n",
      "8900it [21:17,  6.68it/s]Train epoch: 0 [batch #8900, batch_size 1, seq length 512]\tLoss: 0.007224\n",
      "8925it [21:21,  6.74it/s]Train epoch: 0 [batch #8925, batch_size 1, seq length 512]\tLoss: 0.005666\n",
      "8950it [21:25,  6.74it/s]Train epoch: 0 [batch #8950, batch_size 1, seq length 512]\tLoss: 0.011086\n",
      "8975it [21:28,  6.45it/s]Train epoch: 0 [batch #8975, batch_size 1, seq length 512]\tLoss: 0.005363\n",
      "9000it [21:32,  6.67it/s]Train epoch: 0 [batch #9000, batch_size 1, seq length 512]\tLoss: 0.007370\n",
      "9025it [21:36,  6.78it/s]Train epoch: 0 [batch #9025, batch_size 1, seq length 512]\tLoss: 0.006097\n",
      "9050it [21:40,  6.83it/s]Train epoch: 0 [batch #9050, batch_size 1, seq length 512]\tLoss: 0.006287\n",
      "9075it [21:43,  6.86it/s]Train epoch: 0 [batch #9075, batch_size 1, seq length 512]\tLoss: 0.006898\n",
      "9100it [21:47,  6.83it/s]Train epoch: 0 [batch #9100, batch_size 1, seq length 512]\tLoss: 0.007745\n",
      "9125it [21:51,  6.88it/s]Train epoch: 0 [batch #9125, batch_size 1, seq length 512]\tLoss: 0.007368\n",
      "9150it [21:54,  6.81it/s]Train epoch: 0 [batch #9150, batch_size 1, seq length 512]\tLoss: 0.006266\n",
      "9175it [21:58,  6.74it/s]Train epoch: 0 [batch #9175, batch_size 1, seq length 512]\tLoss: 0.005638\n",
      "9200it [22:02,  6.85it/s]Train epoch: 0 [batch #9200, batch_size 1, seq length 512]\tLoss: 0.005950\n",
      "9225it [22:05,  6.84it/s]Train epoch: 0 [batch #9225, batch_size 1, seq length 512]\tLoss: 0.006382\n",
      "9250it [22:09,  6.85it/s]Train epoch: 0 [batch #9250, batch_size 1, seq length 512]\tLoss: 0.006497\n",
      "9275it [22:12,  6.81it/s]Train epoch: 0 [batch #9275, batch_size 1, seq length 512]\tLoss: 0.007460\n",
      "9300it [22:16,  6.86it/s]Train epoch: 0 [batch #9300, batch_size 1, seq length 512]\tLoss: 0.007402\n",
      "9325it [22:20,  6.85it/s]Train epoch: 0 [batch #9325, batch_size 1, seq length 512]\tLoss: 0.008044\n",
      "9350it [22:23,  6.87it/s]Train epoch: 0 [batch #9350, batch_size 1, seq length 512]\tLoss: 0.008895\n",
      "9375it [22:27,  6.85it/s]Train epoch: 0 [batch #9375, batch_size 1, seq length 512]\tLoss: 0.006320\n",
      "9400it [22:31,  6.81it/s]Train epoch: 0 [batch #9400, batch_size 1, seq length 512]\tLoss: 0.007029\n",
      "9425it [22:34,  6.82it/s]Train epoch: 0 [batch #9425, batch_size 1, seq length 512]\tLoss: 0.008057\n",
      "9450it [22:38,  6.73it/s]Train epoch: 0 [batch #9450, batch_size 1, seq length 512]\tLoss: 0.006814\n",
      "9475it [22:42,  6.88it/s]Train epoch: 0 [batch #9475, batch_size 1, seq length 512]\tLoss: 0.007383\n",
      "9500it [22:45,  6.83it/s]Train epoch: 0 [batch #9500, batch_size 1, seq length 512]\tLoss: 0.010934\n",
      "9525it [22:49,  6.90it/s]Train epoch: 0 [batch #9525, batch_size 1, seq length 512]\tLoss: 0.006676\n",
      "9550it [22:53,  6.80it/s]Train epoch: 0 [batch #9550, batch_size 1, seq length 512]\tLoss: 0.007007\n",
      "9575it [22:56,  6.83it/s]Train epoch: 0 [batch #9575, batch_size 1, seq length 512]\tLoss: 0.007248\n",
      "9600it [23:00,  6.83it/s]Train epoch: 0 [batch #9600, batch_size 1, seq length 512]\tLoss: 0.007635\n",
      "9625it [23:04,  6.83it/s]Train epoch: 0 [batch #9625, batch_size 1, seq length 512]\tLoss: 0.005758\n",
      "9650it [23:07,  6.82it/s]Train epoch: 0 [batch #9650, batch_size 1, seq length 512]\tLoss: 0.007935\n",
      "9675it [23:11,  6.74it/s]Train epoch: 0 [batch #9675, batch_size 1, seq length 512]\tLoss: 0.005728\n",
      "9700it [23:15,  6.86it/s]Train epoch: 0 [batch #9700, batch_size 1, seq length 512]\tLoss: 0.005991\n",
      "9725it [23:18,  6.85it/s]Train epoch: 0 [batch #9725, batch_size 1, seq length 512]\tLoss: 0.007618\n",
      "9750it [23:22,  6.82it/s]Train epoch: 0 [batch #9750, batch_size 1, seq length 512]\tLoss: 0.008899\n",
      "9775it [23:26,  6.83it/s]Train epoch: 0 [batch #9775, batch_size 1, seq length 512]\tLoss: 0.005233\n",
      "9800it [23:29,  6.81it/s]Train epoch: 0 [batch #9800, batch_size 1, seq length 512]\tLoss: 0.007871\n",
      "9825it [23:33,  6.83it/s]Train epoch: 0 [batch #9825, batch_size 1, seq length 512]\tLoss: 0.006338\n",
      "9850it [23:37,  6.82it/s]Train epoch: 0 [batch #9850, batch_size 1, seq length 512]\tLoss: 0.009345\n",
      "9875it [23:40,  6.78it/s]Train epoch: 0 [batch #9875, batch_size 1, seq length 512]\tLoss: 0.007666\n",
      "9900it [23:44,  6.81it/s]Train epoch: 0 [batch #9900, batch_size 1, seq length 512]\tLoss: 0.006363\n",
      "9925it [23:48,  6.79it/s]Train epoch: 0 [batch #9925, batch_size 1, seq length 512]\tLoss: 0.008015\n",
      "9950it [23:51,  6.80it/s]Train epoch: 0 [batch #9950, batch_size 1, seq length 512]\tLoss: 0.006496\n",
      "9975it [23:55,  6.84it/s]Train epoch: 0 [batch #9975, batch_size 1, seq length 512]\tLoss: 0.006791\n",
      "10000it [23:59,  6.82it/s]Train epoch: 0 [batch #10000, batch_size 1, seq length 512]\tLoss: 0.005831\n",
      "10025it [24:02,  6.84it/s]Train epoch: 0 [batch #10025, batch_size 1, seq length 512]\tLoss: 0.006967\n",
      "10050it [24:06,  6.82it/s]Train epoch: 0 [batch #10050, batch_size 1, seq length 512]\tLoss: 0.005784\n",
      "10075it [24:10,  6.89it/s]Train epoch: 0 [batch #10075, batch_size 1, seq length 512]\tLoss: 0.006190\n",
      "10100it [24:13,  6.84it/s]Train epoch: 0 [batch #10100, batch_size 1, seq length 512]\tLoss: 0.007659\n",
      "10125it [24:17,  6.80it/s]Train epoch: 0 [batch #10125, batch_size 1, seq length 512]\tLoss: 0.006713\n",
      "10150it [24:21,  6.83it/s]Train epoch: 0 [batch #10150, batch_size 1, seq length 512]\tLoss: 0.007358\n",
      "10175it [24:24,  6.83it/s]Train epoch: 0 [batch #10175, batch_size 1, seq length 512]\tLoss: 0.007487\n",
      "10200it [24:28,  6.83it/s]Train epoch: 0 [batch #10200, batch_size 1, seq length 512]\tLoss: 0.007253\n",
      "10225it [24:32,  6.84it/s]Train epoch: 0 [batch #10225, batch_size 1, seq length 512]\tLoss: 0.005823\n",
      "10250it [24:35,  6.82it/s]Train epoch: 0 [batch #10250, batch_size 1, seq length 512]\tLoss: 0.007067\n",
      "10275it [24:39,  6.77it/s]Train epoch: 0 [batch #10275, batch_size 1, seq length 512]\tLoss: 0.007386\n",
      "10300it [24:43,  6.80it/s]Train epoch: 0 [batch #10300, batch_size 1, seq length 512]\tLoss: 0.006884\n",
      "10325it [24:46,  6.84it/s]Train epoch: 0 [batch #10325, batch_size 1, seq length 512]\tLoss: 0.006762\n",
      "10350it [24:50,  6.80it/s]Train epoch: 0 [batch #10350, batch_size 1, seq length 512]\tLoss: 0.006187\n",
      "10375it [24:54,  6.86it/s]Train epoch: 0 [batch #10375, batch_size 1, seq length 512]\tLoss: 0.006564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400it [24:57,  6.80it/s]Train epoch: 0 [batch #10400, batch_size 1, seq length 512]\tLoss: 0.006772\n",
      "10425it [25:01,  6.79it/s]Train epoch: 0 [batch #10425, batch_size 1, seq length 512]\tLoss: 0.006340\n",
      "10450it [25:05,  6.84it/s]Train epoch: 0 [batch #10450, batch_size 1, seq length 512]\tLoss: 0.005697\n",
      "10475it [25:08,  6.81it/s]Train epoch: 0 [batch #10475, batch_size 1, seq length 512]\tLoss: 0.008289\n",
      "10500it [25:12,  6.81it/s]Train epoch: 0 [batch #10500, batch_size 1, seq length 512]\tLoss: 0.007120\n",
      "10525it [25:16,  6.86it/s]Train epoch: 0 [batch #10525, batch_size 1, seq length 512]\tLoss: 0.006212\n",
      "10550it [25:19,  6.83it/s]Train epoch: 0 [batch #10550, batch_size 1, seq length 512]\tLoss: 0.007412\n",
      "10575it [25:23,  6.86it/s]Train epoch: 0 [batch #10575, batch_size 1, seq length 512]\tLoss: 0.008817\n",
      "10600it [25:27,  6.80it/s]Train epoch: 0 [batch #10600, batch_size 1, seq length 512]\tLoss: 0.006956\n",
      "10625it [25:30,  6.84it/s]Train epoch: 0 [batch #10625, batch_size 1, seq length 512]\tLoss: 0.007880\n",
      "10650it [25:34,  6.84it/s]Train epoch: 0 [batch #10650, batch_size 1, seq length 512]\tLoss: 0.007762\n",
      "10675it [25:38,  6.85it/s]Train epoch: 0 [batch #10675, batch_size 1, seq length 512]\tLoss: 0.007880\n",
      "10700it [25:41,  6.75it/s]Train epoch: 0 [batch #10700, batch_size 1, seq length 512]\tLoss: 0.007066\n",
      "10725it [25:45,  6.88it/s]Train epoch: 0 [batch #10725, batch_size 1, seq length 512]\tLoss: 0.008164\n",
      "10750it [25:48,  6.85it/s]Train epoch: 0 [batch #10750, batch_size 1, seq length 512]\tLoss: 0.007460\n",
      "10775it [25:52,  6.83it/s]Train epoch: 0 [batch #10775, batch_size 1, seq length 512]\tLoss: 0.006648\n",
      "10800it [25:56,  6.86it/s]Train epoch: 0 [batch #10800, batch_size 1, seq length 512]\tLoss: 0.006051\n",
      "10825it [25:59,  6.80it/s]Train epoch: 0 [batch #10825, batch_size 1, seq length 512]\tLoss: 0.006414\n",
      "10850it [26:03,  6.82it/s]Train epoch: 0 [batch #10850, batch_size 1, seq length 512]\tLoss: 0.007374\n",
      "10875it [26:07,  6.78it/s]Train epoch: 0 [batch #10875, batch_size 1, seq length 512]\tLoss: 0.007027\n",
      "10900it [26:11,  6.80it/s]Train epoch: 0 [batch #10900, batch_size 1, seq length 512]\tLoss: 0.005920\n",
      "10925it [26:14,  6.80it/s]Train epoch: 0 [batch #10925, batch_size 1, seq length 512]\tLoss: 0.008485\n",
      "10950it [26:18,  6.81it/s]Train epoch: 0 [batch #10950, batch_size 1, seq length 512]\tLoss: 0.007612\n",
      "10975it [26:22,  6.78it/s]Train epoch: 0 [batch #10975, batch_size 1, seq length 512]\tLoss: 0.008340\n",
      "11000it [26:25,  6.77it/s]Train epoch: 0 [batch #11000, batch_size 1, seq length 512]\tLoss: 0.008997\n",
      "11025it [26:29,  6.80it/s]Train epoch: 0 [batch #11025, batch_size 1, seq length 512]\tLoss: 0.005432\n",
      "11050it [26:33,  6.84it/s]Train epoch: 0 [batch #11050, batch_size 1, seq length 512]\tLoss: 0.008163\n",
      "11075it [26:36,  6.74it/s]Train epoch: 0 [batch #11075, batch_size 1, seq length 512]\tLoss: 0.008458\n",
      "11100it [26:40,  6.76it/s]Train epoch: 0 [batch #11100, batch_size 1, seq length 512]\tLoss: 0.005889\n",
      "11125it [26:44,  6.84it/s]Train epoch: 0 [batch #11125, batch_size 1, seq length 512]\tLoss: 0.007746\n",
      "11150it [26:47,  6.88it/s]Train epoch: 0 [batch #11150, batch_size 1, seq length 512]\tLoss: 0.005925\n",
      "11175it [26:51,  6.83it/s]Train epoch: 0 [batch #11175, batch_size 1, seq length 512]\tLoss: 0.006298\n",
      "11200it [26:55,  6.86it/s]Train epoch: 0 [batch #11200, batch_size 1, seq length 512]\tLoss: 0.007417\n",
      "11225it [26:58,  6.75it/s]Train epoch: 0 [batch #11225, batch_size 1, seq length 512]\tLoss: 0.006588\n",
      "11250it [27:02,  6.80it/s]Train epoch: 0 [batch #11250, batch_size 1, seq length 512]\tLoss: 0.007081\n",
      "11275it [27:06,  6.83it/s]Train epoch: 0 [batch #11275, batch_size 1, seq length 512]\tLoss: 0.006721\n",
      "11300it [27:09,  6.82it/s]Train epoch: 0 [batch #11300, batch_size 1, seq length 512]\tLoss: 0.006486\n",
      "11325it [27:13,  6.76it/s]Train epoch: 0 [batch #11325, batch_size 1, seq length 512]\tLoss: 0.008167\n",
      "11350it [27:17,  6.82it/s]Train epoch: 0 [batch #11350, batch_size 1, seq length 512]\tLoss: 0.007739\n",
      "11375it [27:20,  6.87it/s]Train epoch: 0 [batch #11375, batch_size 1, seq length 512]\tLoss: 0.005757\n",
      "11400it [27:24,  6.85it/s]Train epoch: 0 [batch #11400, batch_size 1, seq length 512]\tLoss: 0.008386\n",
      "11425it [27:28,  6.83it/s]Train epoch: 0 [batch #11425, batch_size 1, seq length 512]\tLoss: 0.006829\n",
      "11450it [27:31,  6.75it/s]Train epoch: 0 [batch #11450, batch_size 1, seq length 512]\tLoss: 0.007689\n",
      "11475it [27:35,  6.90it/s]Train epoch: 0 [batch #11475, batch_size 1, seq length 512]\tLoss: 0.007807\n",
      "11500it [27:39,  6.83it/s]Train epoch: 0 [batch #11500, batch_size 1, seq length 512]\tLoss: 0.007884\n",
      "11525it [27:42,  6.77it/s]Train epoch: 0 [batch #11525, batch_size 1, seq length 512]\tLoss: 0.005813\n",
      "11550it [27:46,  6.83it/s]Train epoch: 0 [batch #11550, batch_size 1, seq length 512]\tLoss: 0.006956\n",
      "11575it [27:50,  6.82it/s]Train epoch: 0 [batch #11575, batch_size 1, seq length 512]\tLoss: 0.006363\n",
      "11600it [27:53,  6.81it/s]Train epoch: 0 [batch #11600, batch_size 1, seq length 512]\tLoss: 0.008657\n",
      "11625it [27:57,  6.74it/s]Train epoch: 0 [batch #11625, batch_size 1, seq length 512]\tLoss: 0.006039\n",
      "11650it [28:01,  6.78it/s]Train epoch: 0 [batch #11650, batch_size 1, seq length 512]\tLoss: 0.005837\n",
      "11675it [28:04,  6.74it/s]Train epoch: 0 [batch #11675, batch_size 1, seq length 512]\tLoss: 0.006948\n",
      "11700it [28:08,  6.86it/s]Train epoch: 0 [batch #11700, batch_size 1, seq length 512]\tLoss: 0.008844\n",
      "11725it [28:12,  6.80it/s]Train epoch: 0 [batch #11725, batch_size 1, seq length 512]\tLoss: 0.009743\n",
      "11750it [28:15,  6.80it/s]Train epoch: 0 [batch #11750, batch_size 1, seq length 512]\tLoss: 0.007477\n",
      "11775it [28:19,  6.76it/s]Train epoch: 0 [batch #11775, batch_size 1, seq length 512]\tLoss: 0.007953\n",
      "11800it [28:23,  6.85it/s]Train epoch: 0 [batch #11800, batch_size 1, seq length 512]\tLoss: 0.006845\n",
      "11825it [28:26,  6.81it/s]Train epoch: 0 [batch #11825, batch_size 1, seq length 512]\tLoss: 0.007119\n",
      "11850it [28:30,  6.81it/s]Train epoch: 0 [batch #11850, batch_size 1, seq length 512]\tLoss: 0.006514\n",
      "11875it [28:34,  6.79it/s]Train epoch: 0 [batch #11875, batch_size 1, seq length 512]\tLoss: 0.008191\n",
      "11900it [28:37,  6.80it/s]Train epoch: 0 [batch #11900, batch_size 1, seq length 512]\tLoss: 0.006182\n",
      "11925it [28:41,  6.79it/s]Train epoch: 0 [batch #11925, batch_size 1, seq length 512]\tLoss: 0.005845\n",
      "11950it [28:45,  6.83it/s]Train epoch: 0 [batch #11950, batch_size 1, seq length 512]\tLoss: 0.008563\n",
      "11975it [28:48,  6.80it/s]Train epoch: 0 [batch #11975, batch_size 1, seq length 512]\tLoss: 0.007910\n",
      "12000it [28:52,  6.81it/s]Train epoch: 0 [batch #12000, batch_size 1, seq length 512]\tLoss: 0.007951\n",
      "12025it [28:56,  6.83it/s]Train epoch: 0 [batch #12025, batch_size 1, seq length 512]\tLoss: 0.006869\n",
      "12050it [28:59,  6.85it/s]Train epoch: 0 [batch #12050, batch_size 1, seq length 512]\tLoss: 0.008482\n",
      "12075it [29:03,  6.79it/s]Train epoch: 0 [batch #12075, batch_size 1, seq length 512]\tLoss: 0.007984\n",
      "12100it [29:07,  6.81it/s]Train epoch: 0 [batch #12100, batch_size 1, seq length 512]\tLoss: 0.008602\n",
      "12125it [29:10,  6.83it/s]Train epoch: 0 [batch #12125, batch_size 1, seq length 512]\tLoss: 0.007917\n",
      "12150it [29:14,  6.80it/s]Train epoch: 0 [batch #12150, batch_size 1, seq length 512]\tLoss: 0.009018\n",
      "12175it [29:18,  6.79it/s]Train epoch: 0 [batch #12175, batch_size 1, seq length 512]\tLoss: 0.006341\n",
      "12200it [29:21,  6.80it/s]Train epoch: 0 [batch #12200, batch_size 1, seq length 512]\tLoss: 0.008250\n",
      "12225it [29:25,  6.83it/s]Train epoch: 0 [batch #12225, batch_size 1, seq length 512]\tLoss: 0.006051\n",
      "12250it [29:29,  6.78it/s]Train epoch: 0 [batch #12250, batch_size 1, seq length 512]\tLoss: 0.006332\n",
      "12275it [29:32,  6.76it/s]Train epoch: 0 [batch #12275, batch_size 1, seq length 512]\tLoss: 0.008441\n",
      "12300it [29:36,  6.82it/s]Train epoch: 0 [batch #12300, batch_size 1, seq length 512]\tLoss: 0.007080\n",
      "12325it [29:40,  6.80it/s]Train epoch: 0 [batch #12325, batch_size 1, seq length 512]\tLoss: 0.008390\n",
      "12350it [29:43,  6.84it/s]Train epoch: 0 [batch #12350, batch_size 1, seq length 512]\tLoss: 0.007317\n",
      "12375it [29:47,  6.77it/s]Train epoch: 0 [batch #12375, batch_size 1, seq length 512]\tLoss: 0.008422\n",
      "12400it [29:51,  6.78it/s]Train epoch: 0 [batch #12400, batch_size 1, seq length 512]\tLoss: 0.006511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12425it [29:54,  6.80it/s]Train epoch: 0 [batch #12425, batch_size 1, seq length 512]\tLoss: 0.007248\n",
      "12450it [29:58,  6.83it/s]Train epoch: 0 [batch #12450, batch_size 1, seq length 512]\tLoss: 0.006171\n",
      "12475it [30:02,  6.82it/s]Train epoch: 0 [batch #12475, batch_size 1, seq length 512]\tLoss: 0.007888\n",
      "12500it [30:05,  6.89it/s]Train epoch: 0 [batch #12500, batch_size 1, seq length 512]\tLoss: 0.008087\n",
      "12525it [30:09,  6.76it/s]Train epoch: 0 [batch #12525, batch_size 1, seq length 512]\tLoss: 0.007412\n",
      "12550it [30:13,  6.79it/s]Train epoch: 0 [batch #12550, batch_size 1, seq length 512]\tLoss: 0.007007\n",
      "12575it [30:16,  6.76it/s]Train epoch: 0 [batch #12575, batch_size 1, seq length 512]\tLoss: 0.006824\n",
      "12600it [30:20,  6.83it/s]Train epoch: 0 [batch #12600, batch_size 1, seq length 512]\tLoss: 0.006228\n",
      "12625it [30:24,  6.83it/s]Train epoch: 0 [batch #12625, batch_size 1, seq length 512]\tLoss: 0.010766\n",
      "12650it [30:28,  6.81it/s]Train epoch: 0 [batch #12650, batch_size 1, seq length 512]\tLoss: 0.007355\n",
      "12675it [30:31,  6.79it/s]Train epoch: 0 [batch #12675, batch_size 1, seq length 512]\tLoss: 0.005621\n",
      "12700it [30:35,  6.81it/s]Train epoch: 0 [batch #12700, batch_size 1, seq length 512]\tLoss: 0.006187\n",
      "12725it [30:39,  6.78it/s]Train epoch: 0 [batch #12725, batch_size 1, seq length 512]\tLoss: 0.008764\n",
      "12750it [30:42,  6.82it/s]Train epoch: 0 [batch #12750, batch_size 1, seq length 512]\tLoss: 0.007086\n",
      "12775it [30:46,  6.81it/s]Train epoch: 0 [batch #12775, batch_size 1, seq length 512]\tLoss: 0.006898\n",
      "12800it [30:50,  6.82it/s]Train epoch: 0 [batch #12800, batch_size 1, seq length 512]\tLoss: 0.006384\n",
      "12825it [30:53,  6.82it/s]Train epoch: 0 [batch #12825, batch_size 1, seq length 512]\tLoss: 0.006383\n",
      "12850it [30:57,  6.79it/s]Train epoch: 0 [batch #12850, batch_size 1, seq length 512]\tLoss: 0.006300\n",
      "12875it [31:01,  6.76it/s]Train epoch: 0 [batch #12875, batch_size 1, seq length 512]\tLoss: 0.007716\n",
      "12900it [31:04,  6.78it/s]Train epoch: 0 [batch #12900, batch_size 1, seq length 512]\tLoss: 0.006554\n",
      "12925it [31:08,  6.77it/s]Train epoch: 0 [batch #12925, batch_size 1, seq length 512]\tLoss: 0.008379\n",
      "12950it [31:12,  6.79it/s]Train epoch: 0 [batch #12950, batch_size 1, seq length 512]\tLoss: 0.007668\n",
      "12975it [31:15,  6.82it/s]Train epoch: 0 [batch #12975, batch_size 1, seq length 512]\tLoss: 0.006510\n",
      "13000it [31:19,  6.86it/s]Train epoch: 0 [batch #13000, batch_size 1, seq length 512]\tLoss: 0.006898\n",
      "13025it [31:23,  6.81it/s]Train epoch: 0 [batch #13025, batch_size 1, seq length 512]\tLoss: 0.006709\n",
      "13050it [31:26,  6.78it/s]Train epoch: 0 [batch #13050, batch_size 1, seq length 512]\tLoss: 0.006067\n",
      "13075it [31:30,  6.71it/s]Train epoch: 0 [batch #13075, batch_size 1, seq length 512]\tLoss: 0.007348\n",
      "13100it [31:34,  6.79it/s]Train epoch: 0 [batch #13100, batch_size 1, seq length 512]\tLoss: 0.006252\n",
      "13125it [31:37,  6.84it/s]Train epoch: 0 [batch #13125, batch_size 1, seq length 512]\tLoss: 0.007924\n",
      "13150it [31:41,  6.84it/s]Train epoch: 0 [batch #13150, batch_size 1, seq length 512]\tLoss: 0.007485\n",
      "13175it [31:45,  6.82it/s]Train epoch: 0 [batch #13175, batch_size 1, seq length 512]\tLoss: 0.010371\n",
      "13200it [31:49,  6.81it/s]Train epoch: 0 [batch #13200, batch_size 1, seq length 512]\tLoss: 0.007571\n",
      "13225it [31:52,  6.81it/s]Train epoch: 0 [batch #13225, batch_size 1, seq length 512]\tLoss: 0.006576\n",
      "13250it [31:56,  6.80it/s]Train epoch: 0 [batch #13250, batch_size 1, seq length 512]\tLoss: 0.006479\n",
      "13275it [32:00,  6.77it/s]Train epoch: 0 [batch #13275, batch_size 1, seq length 512]\tLoss: 0.006403\n",
      "13300it [32:03,  6.80it/s]Train epoch: 0 [batch #13300, batch_size 1, seq length 512]\tLoss: 0.007398\n",
      "13325it [32:07,  6.83it/s]Train epoch: 0 [batch #13325, batch_size 1, seq length 512]\tLoss: 0.006602\n",
      "13350it [32:11,  6.80it/s]Train epoch: 0 [batch #13350, batch_size 1, seq length 512]\tLoss: 0.008362\n",
      "13375it [32:14,  6.79it/s]Train epoch: 0 [batch #13375, batch_size 1, seq length 512]\tLoss: 0.008666\n",
      "13400it [32:18,  6.79it/s]Train epoch: 0 [batch #13400, batch_size 1, seq length 512]\tLoss: 0.006142\n",
      "13425it [32:22,  6.79it/s]Train epoch: 0 [batch #13425, batch_size 1, seq length 512]\tLoss: 0.007070\n",
      "13450it [32:25,  6.78it/s]Train epoch: 0 [batch #13450, batch_size 1, seq length 512]\tLoss: 0.010978\n",
      "13475it [32:29,  6.75it/s]Train epoch: 0 [batch #13475, batch_size 1, seq length 512]\tLoss: 0.008524\n",
      "13500it [32:33,  6.84it/s]Train epoch: 0 [batch #13500, batch_size 1, seq length 512]\tLoss: 0.007773\n",
      "13525it [32:36,  6.71it/s]Train epoch: 0 [batch #13525, batch_size 1, seq length 512]\tLoss: 0.007418\n",
      "13550it [32:40,  6.75it/s]Train epoch: 0 [batch #13550, batch_size 1, seq length 512]\tLoss: 0.007667\n",
      "13575it [32:44,  6.79it/s]Train epoch: 0 [batch #13575, batch_size 1, seq length 512]\tLoss: 0.007717\n",
      "13600it [32:47,  6.80it/s]Train epoch: 0 [batch #13600, batch_size 1, seq length 512]\tLoss: 0.007543\n",
      "13625it [32:51,  6.80it/s]Train epoch: 0 [batch #13625, batch_size 1, seq length 512]\tLoss: 0.007836\n",
      "13650it [32:55,  6.79it/s]Train epoch: 0 [batch #13650, batch_size 1, seq length 512]\tLoss: 0.008638\n",
      "13675it [32:59,  6.81it/s]Train epoch: 0 [batch #13675, batch_size 1, seq length 512]\tLoss: 0.008319\n",
      "13700it [33:02,  6.84it/s]Train epoch: 0 [batch #13700, batch_size 1, seq length 512]\tLoss: 0.007156\n",
      "13725it [33:06,  6.82it/s]Train epoch: 0 [batch #13725, batch_size 1, seq length 512]\tLoss: 0.006928\n",
      "13750it [33:10,  6.75it/s]Train epoch: 0 [batch #13750, batch_size 1, seq length 512]\tLoss: 0.008473\n",
      "13775it [33:13,  6.80it/s]Train epoch: 0 [batch #13775, batch_size 1, seq length 512]\tLoss: 0.006366\n",
      "13800it [33:17,  6.79it/s]Train epoch: 0 [batch #13800, batch_size 1, seq length 512]\tLoss: 0.007205\n",
      "13825it [33:21,  6.80it/s]Train epoch: 0 [batch #13825, batch_size 1, seq length 512]\tLoss: 0.006715\n",
      "13850it [33:24,  6.75it/s]Train epoch: 0 [batch #13850, batch_size 1, seq length 512]\tLoss: 0.006621\n",
      "13875it [33:28,  6.83it/s]Train epoch: 0 [batch #13875, batch_size 1, seq length 512]\tLoss: 0.008337\n",
      "13900it [33:32,  6.82it/s]Train epoch: 0 [batch #13900, batch_size 1, seq length 512]\tLoss: 0.006977\n",
      "13925it [33:35,  6.79it/s]Train epoch: 0 [batch #13925, batch_size 1, seq length 512]\tLoss: 0.006380\n",
      "13950it [33:39,  6.79it/s]Train epoch: 0 [batch #13950, batch_size 1, seq length 512]\tLoss: 0.008593\n",
      "13975it [33:43,  6.78it/s]Train epoch: 0 [batch #13975, batch_size 1, seq length 512]\tLoss: 0.007531\n",
      "14000it [33:46,  6.78it/s]Train epoch: 0 [batch #14000, batch_size 1, seq length 512]\tLoss: 0.007113\n",
      "14025it [33:50,  6.79it/s]Train epoch: 0 [batch #14025, batch_size 1, seq length 512]\tLoss: 0.008085\n",
      "14050it [33:54,  6.82it/s]Train epoch: 0 [batch #14050, batch_size 1, seq length 512]\tLoss: 0.007405\n",
      "14075it [33:57,  6.80it/s]Train epoch: 0 [batch #14075, batch_size 1, seq length 512]\tLoss: 0.008598\n",
      "14100it [34:01,  6.73it/s]Train epoch: 0 [batch #14100, batch_size 1, seq length 512]\tLoss: 0.007101\n",
      "14125it [34:05,  6.79it/s]Train epoch: 0 [batch #14125, batch_size 1, seq length 512]\tLoss: 0.006402\n",
      "14150it [34:09,  6.72it/s]Train epoch: 0 [batch #14150, batch_size 1, seq length 512]\tLoss: 0.008012\n",
      "14175it [34:12,  6.81it/s]Train epoch: 0 [batch #14175, batch_size 1, seq length 512]\tLoss: 0.008121\n",
      "14200it [34:16,  6.81it/s]Train epoch: 0 [batch #14200, batch_size 1, seq length 512]\tLoss: 0.007818\n",
      "14225it [34:20,  6.81it/s]Train epoch: 0 [batch #14225, batch_size 1, seq length 512]\tLoss: 0.009518\n",
      "14250it [34:23,  6.82it/s]Train epoch: 0 [batch #14250, batch_size 1, seq length 512]\tLoss: 0.006475\n",
      "14275it [34:27,  6.80it/s]Train epoch: 0 [batch #14275, batch_size 1, seq length 512]\tLoss: 0.006985\n",
      "14300it [34:31,  6.80it/s]Train epoch: 0 [batch #14300, batch_size 1, seq length 512]\tLoss: 0.006058\n",
      "14325it [34:34,  6.30it/s]Train epoch: 0 [batch #14325, batch_size 1, seq length 512]\tLoss: 0.011563\n",
      "14350it [34:38,  6.64it/s]Train epoch: 0 [batch #14350, batch_size 1, seq length 512]\tLoss: 0.006150\n",
      "14375it [34:42,  6.76it/s]Train epoch: 0 [batch #14375, batch_size 1, seq length 512]\tLoss: 0.008888\n",
      "14400it [34:46,  6.82it/s]Train epoch: 0 [batch #14400, batch_size 1, seq length 512]\tLoss: 0.007105\n",
      "14425it [34:49,  6.83it/s]Train epoch: 0 [batch #14425, batch_size 1, seq length 512]\tLoss: 0.008933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14450it [34:53,  6.84it/s]Train epoch: 0 [batch #14450, batch_size 1, seq length 512]\tLoss: 0.006821\n",
      "14475it [34:57,  6.90it/s]Train epoch: 0 [batch #14475, batch_size 1, seq length 512]\tLoss: 0.006079\n",
      "14500it [35:00,  6.86it/s]Train epoch: 0 [batch #14500, batch_size 1, seq length 512]\tLoss: 0.007814\n",
      "14525it [35:04,  6.90it/s]Train epoch: 0 [batch #14525, batch_size 1, seq length 512]\tLoss: 0.006896\n",
      "14550it [35:08,  6.80it/s]Train epoch: 0 [batch #14550, batch_size 1, seq length 512]\tLoss: 0.006884\n",
      "14575it [35:11,  6.80it/s]Train epoch: 0 [batch #14575, batch_size 1, seq length 512]\tLoss: 0.006631\n",
      "14600it [35:15,  6.86it/s]Train epoch: 0 [batch #14600, batch_size 1, seq length 512]\tLoss: 0.008708\n",
      "14625it [35:19,  6.86it/s]Train epoch: 0 [batch #14625, batch_size 1, seq length 512]\tLoss: 0.007585\n",
      "14650it [35:22,  6.81it/s]Train epoch: 0 [batch #14650, batch_size 1, seq length 512]\tLoss: 0.007323\n",
      "14675it [35:26,  6.81it/s]Train epoch: 0 [batch #14675, batch_size 1, seq length 512]\tLoss: 0.008961\n",
      "14700it [35:29,  6.83it/s]Train epoch: 0 [batch #14700, batch_size 1, seq length 512]\tLoss: 0.007720\n",
      "14725it [35:33,  6.77it/s]Train epoch: 0 [batch #14725, batch_size 1, seq length 512]\tLoss: 0.007354\n",
      "14750it [35:37,  6.85it/s]Train epoch: 0 [batch #14750, batch_size 1, seq length 512]\tLoss: 0.006381\n",
      "14775it [35:41,  6.78it/s]Train epoch: 0 [batch #14775, batch_size 1, seq length 512]\tLoss: 0.006798\n",
      "14800it [35:44,  6.82it/s]Train epoch: 0 [batch #14800, batch_size 1, seq length 512]\tLoss: 0.008207\n",
      "14825it [35:48,  6.81it/s]Train epoch: 0 [batch #14825, batch_size 1, seq length 512]\tLoss: 0.008544\n",
      "14850it [35:52,  6.79it/s]Train epoch: 0 [batch #14850, batch_size 1, seq length 512]\tLoss: 0.007657\n",
      "14875it [35:55,  6.78it/s]Train epoch: 0 [batch #14875, batch_size 1, seq length 512]\tLoss: 0.008851\n",
      "14900it [35:59,  6.83it/s]Train epoch: 0 [batch #14900, batch_size 1, seq length 512]\tLoss: 0.006614\n",
      "14925it [36:03,  6.79it/s]Train epoch: 0 [batch #14925, batch_size 1, seq length 512]\tLoss: 0.007857\n",
      "14950it [36:06,  6.83it/s]Train epoch: 0 [batch #14950, batch_size 1, seq length 512]\tLoss: 0.006699\n",
      "14975it [36:10,  6.84it/s]Train epoch: 0 [batch #14975, batch_size 1, seq length 512]\tLoss: 0.008391\n",
      "15000it [36:14,  6.79it/s]Train epoch: 0 [batch #15000, batch_size 1, seq length 512]\tLoss: 0.009211\n",
      "15025it [36:17,  6.78it/s]Train epoch: 0 [batch #15025, batch_size 1, seq length 512]\tLoss: 0.008374\n",
      "15050it [36:21,  6.85it/s]Train epoch: 0 [batch #15050, batch_size 1, seq length 512]\tLoss: 0.009803\n",
      "15075it [36:25,  6.80it/s]Train epoch: 0 [batch #15075, batch_size 1, seq length 512]\tLoss: 0.007378\n",
      "15100it [36:28,  6.77it/s]Train epoch: 0 [batch #15100, batch_size 1, seq length 512]\tLoss: 0.008533\n",
      "15125it [36:32,  6.84it/s]Train epoch: 0 [batch #15125, batch_size 1, seq length 512]\tLoss: 0.007904\n",
      "15150it [36:36,  6.84it/s]Train epoch: 0 [batch #15150, batch_size 1, seq length 512]\tLoss: 0.011916\n",
      "15175it [36:39,  6.85it/s]Train epoch: 0 [batch #15175, batch_size 1, seq length 512]\tLoss: 0.008066\n",
      "15200it [36:43,  6.79it/s]Train epoch: 0 [batch #15200, batch_size 1, seq length 512]\tLoss: 0.006304\n",
      "15225it [36:47,  6.79it/s]Train epoch: 0 [batch #15225, batch_size 1, seq length 512]\tLoss: 0.007992\n",
      "15250it [36:50,  6.67it/s]Train epoch: 0 [batch #15250, batch_size 1, seq length 512]\tLoss: 0.009158\n",
      "15275it [36:54,  6.60it/s]Train epoch: 0 [batch #15275, batch_size 1, seq length 512]\tLoss: 0.006529\n",
      "15300it [36:58,  6.72it/s]Train epoch: 0 [batch #15300, batch_size 1, seq length 512]\tLoss: 0.008147\n",
      "15325it [37:02,  6.91it/s]Train epoch: 0 [batch #15325, batch_size 1, seq length 512]\tLoss: 0.009497\n",
      "15350it [37:05,  6.91it/s]Train epoch: 0 [batch #15350, batch_size 1, seq length 512]\tLoss: 0.008523\n",
      "15375it [37:09,  6.99it/s]Train epoch: 0 [batch #15375, batch_size 1, seq length 512]\tLoss: 0.007417\n",
      "15400it [37:13,  6.89it/s]Train epoch: 0 [batch #15400, batch_size 1, seq length 512]\tLoss: 0.005108\n",
      "15425it [37:16,  6.89it/s]Train epoch: 0 [batch #15425, batch_size 1, seq length 512]\tLoss: 0.008330\n",
      "15450it [37:20,  6.92it/s]Train epoch: 0 [batch #15450, batch_size 1, seq length 512]\tLoss: 0.008790\n",
      "15475it [37:23,  6.92it/s]Train epoch: 0 [batch #15475, batch_size 1, seq length 512]\tLoss: 0.006378\n",
      "15500it [37:27,  6.81it/s]Train epoch: 0 [batch #15500, batch_size 1, seq length 512]\tLoss: 0.008095\n",
      "15525it [37:31,  6.89it/s]Train epoch: 0 [batch #15525, batch_size 1, seq length 512]\tLoss: 0.006538\n",
      "15550it [37:34,  6.88it/s]Train epoch: 0 [batch #15550, batch_size 1, seq length 512]\tLoss: 0.007931\n",
      "15575it [37:38,  6.91it/s]Train epoch: 0 [batch #15575, batch_size 1, seq length 512]\tLoss: 0.008700\n",
      "15600it [37:42,  6.63it/s]Train epoch: 0 [batch #15600, batch_size 1, seq length 512]\tLoss: 0.008042\n",
      "15625it [37:45,  6.86it/s]Train epoch: 0 [batch #15625, batch_size 1, seq length 512]\tLoss: 0.009070\n",
      "15650it [37:49,  6.86it/s]Train epoch: 0 [batch #15650, batch_size 1, seq length 512]\tLoss: 0.007529\n",
      "15675it [37:53,  6.90it/s]Train epoch: 0 [batch #15675, batch_size 1, seq length 512]\tLoss: 0.007206\n",
      "15700it [37:56,  6.97it/s]Train epoch: 0 [batch #15700, batch_size 1, seq length 512]\tLoss: 0.007684\n",
      "15725it [38:00,  6.84it/s]Train epoch: 0 [batch #15725, batch_size 1, seq length 512]\tLoss: 0.007992\n",
      "15750it [38:03,  6.89it/s]Train epoch: 0 [batch #15750, batch_size 1, seq length 512]\tLoss: 0.007474\n",
      "15775it [38:07,  6.93it/s]Train epoch: 0 [batch #15775, batch_size 1, seq length 512]\tLoss: 0.008940\n",
      "15800it [38:11,  6.95it/s]Train epoch: 0 [batch #15800, batch_size 1, seq length 512]\tLoss: 0.008256\n",
      "15825it [38:14,  6.87it/s]Train epoch: 0 [batch #15825, batch_size 1, seq length 512]\tLoss: 0.007842\n",
      "15850it [38:18,  6.84it/s]Train epoch: 0 [batch #15850, batch_size 1, seq length 512]\tLoss: 0.006526\n",
      "15875it [38:22,  6.89it/s]Train epoch: 0 [batch #15875, batch_size 1, seq length 512]\tLoss: 0.011102\n",
      "15900it [38:25,  6.89it/s]Train epoch: 0 [batch #15900, batch_size 1, seq length 512]\tLoss: 0.010531\n",
      "15925it [38:29,  6.90it/s]Train epoch: 0 [batch #15925, batch_size 1, seq length 512]\tLoss: 0.008384\n",
      "15950it [38:32,  6.95it/s]Train epoch: 0 [batch #15950, batch_size 1, seq length 512]\tLoss: 0.006696\n",
      "15975it [38:36,  6.93it/s]Train epoch: 0 [batch #15975, batch_size 1, seq length 512]\tLoss: 0.007287\n",
      "16000it [38:40,  6.89it/s]Train epoch: 0 [batch #16000, batch_size 1, seq length 512]\tLoss: 0.007493\n",
      "16025it [38:43,  6.90it/s]Train epoch: 0 [batch #16025, batch_size 1, seq length 512]\tLoss: 0.007975\n",
      "16050it [38:47,  6.85it/s]Train epoch: 0 [batch #16050, batch_size 1, seq length 512]\tLoss: 0.006957\n",
      "16075it [38:51,  6.89it/s]Train epoch: 0 [batch #16075, batch_size 1, seq length 512]\tLoss: 0.008325\n",
      "16100it [38:54,  6.92it/s]Train epoch: 0 [batch #16100, batch_size 1, seq length 512]\tLoss: 0.008427\n",
      "16125it [38:58,  6.85it/s]Train epoch: 0 [batch #16125, batch_size 1, seq length 512]\tLoss: 0.006922\n",
      "16150it [39:01,  6.87it/s]Train epoch: 0 [batch #16150, batch_size 1, seq length 512]\tLoss: 0.006577\n",
      "16175it [39:05,  6.86it/s]Train epoch: 0 [batch #16175, batch_size 1, seq length 512]\tLoss: 0.009548\n",
      "16200it [39:09,  6.91it/s]Train epoch: 0 [batch #16200, batch_size 1, seq length 512]\tLoss: 0.007878\n",
      "16225it [39:12,  6.88it/s]Train epoch: 0 [batch #16225, batch_size 1, seq length 512]\tLoss: 0.008691\n",
      "16250it [39:16,  6.88it/s]Train epoch: 0 [batch #16250, batch_size 1, seq length 512]\tLoss: 0.006773\n",
      "16275it [39:20,  6.88it/s]Train epoch: 0 [batch #16275, batch_size 1, seq length 512]\tLoss: 0.008727\n",
      "16300it [39:23,  6.89it/s]Train epoch: 0 [batch #16300, batch_size 1, seq length 512]\tLoss: 0.008236\n",
      "16325it [39:27,  6.80it/s]Train epoch: 0 [batch #16325, batch_size 1, seq length 512]\tLoss: 0.007779\n",
      "16350it [39:31,  6.85it/s]Train epoch: 0 [batch #16350, batch_size 1, seq length 512]\tLoss: 0.007270\n",
      "16375it [39:34,  6.88it/s]Train epoch: 0 [batch #16375, batch_size 1, seq length 512]\tLoss: 0.008313\n",
      "16400it [39:38,  6.86it/s]Train epoch: 0 [batch #16400, batch_size 1, seq length 512]\tLoss: 0.010105\n",
      "16425it [39:41,  6.86it/s]Train epoch: 0 [batch #16425, batch_size 1, seq length 512]\tLoss: 0.008199\n",
      "16450it [39:45,  6.88it/s]Train epoch: 0 [batch #16450, batch_size 1, seq length 512]\tLoss: 0.006218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16475it [39:49,  6.87it/s]Train epoch: 0 [batch #16475, batch_size 1, seq length 512]\tLoss: 0.009511\n",
      "16500it [39:52,  6.88it/s]Train epoch: 0 [batch #16500, batch_size 1, seq length 512]\tLoss: 0.007732\n",
      "16525it [39:56,  6.84it/s]Train epoch: 0 [batch #16525, batch_size 1, seq length 512]\tLoss: 0.006574\n",
      "16550it [40:00,  6.90it/s]Train epoch: 0 [batch #16550, batch_size 1, seq length 512]\tLoss: 0.007511\n",
      "16575it [40:03,  6.91it/s]Train epoch: 0 [batch #16575, batch_size 1, seq length 512]\tLoss: 0.007907\n",
      "16600it [40:07,  6.85it/s]Train epoch: 0 [batch #16600, batch_size 1, seq length 512]\tLoss: 0.007978\n",
      "16625it [40:11,  6.85it/s]Train epoch: 0 [batch #16625, batch_size 1, seq length 512]\tLoss: 0.008364\n",
      "16650it [40:14,  6.93it/s]Train epoch: 0 [batch #16650, batch_size 1, seq length 512]\tLoss: 0.007973\n",
      "16675it [40:18,  6.83it/s]Train epoch: 0 [batch #16675, batch_size 1, seq length 512]\tLoss: 0.008061\n",
      "16700it [40:21,  6.87it/s]Train epoch: 0 [batch #16700, batch_size 1, seq length 512]\tLoss: 0.007490\n",
      "16725it [40:25,  6.85it/s]Train epoch: 0 [batch #16725, batch_size 1, seq length 512]\tLoss: 0.008731\n",
      "16750it [40:29,  6.88it/s]Train epoch: 0 [batch #16750, batch_size 1, seq length 512]\tLoss: 0.007790\n",
      "16775it [40:32,  6.93it/s]Train epoch: 0 [batch #16775, batch_size 1, seq length 512]\tLoss: 0.007383\n",
      "16800it [40:36,  6.96it/s]Train epoch: 0 [batch #16800, batch_size 1, seq length 512]\tLoss: 0.008464\n",
      "16825it [40:40,  6.83it/s]Train epoch: 0 [batch #16825, batch_size 1, seq length 512]\tLoss: 0.010113\n",
      "16850it [40:43,  6.91it/s]Train epoch: 0 [batch #16850, batch_size 1, seq length 512]\tLoss: 0.006609\n",
      "16875it [40:47,  6.90it/s]Train epoch: 0 [batch #16875, batch_size 1, seq length 512]\tLoss: 0.007466\n",
      "16900it [40:51,  6.90it/s]Train epoch: 0 [batch #16900, batch_size 1, seq length 512]\tLoss: 0.006544\n",
      "16925it [40:54,  6.89it/s]Train epoch: 0 [batch #16925, batch_size 1, seq length 512]\tLoss: 0.008881\n",
      "16950it [40:58,  6.91it/s]Train epoch: 0 [batch #16950, batch_size 1, seq length 512]\tLoss: 0.006978\n",
      "16975it [41:01,  6.87it/s]Train epoch: 0 [batch #16975, batch_size 1, seq length 512]\tLoss: 0.007335\n",
      "17000it [41:05,  6.86it/s]Train epoch: 0 [batch #17000, batch_size 1, seq length 512]\tLoss: 0.007945\n",
      "17025it [41:09,  6.86it/s]Train epoch: 0 [batch #17025, batch_size 1, seq length 512]\tLoss: 0.005968\n",
      "17050it [41:12,  6.89it/s]Train epoch: 0 [batch #17050, batch_size 1, seq length 512]\tLoss: 0.008305\n",
      "17075it [41:16,  6.88it/s]Train epoch: 0 [batch #17075, batch_size 1, seq length 512]\tLoss: 0.007645\n",
      "17100it [41:20,  6.55it/s]Train epoch: 0 [batch #17100, batch_size 1, seq length 512]\tLoss: 0.006811\n",
      "17125it [41:24,  6.58it/s]Train epoch: 0 [batch #17125, batch_size 1, seq length 512]\tLoss: 0.008105\n",
      "17150it [41:27,  6.11it/s]Train epoch: 0 [batch #17150, batch_size 1, seq length 512]\tLoss: 0.006650\n",
      "17175it [41:31,  6.78it/s]Train epoch: 0 [batch #17175, batch_size 1, seq length 512]\tLoss: 0.008201\n",
      "17200it [41:35,  6.72it/s]Train epoch: 0 [batch #17200, batch_size 1, seq length 512]\tLoss: 0.007978\n",
      "17225it [41:39,  6.47it/s]Train epoch: 0 [batch #17225, batch_size 1, seq length 512]\tLoss: 0.007846\n",
      "17250it [41:42,  6.79it/s]Train epoch: 0 [batch #17250, batch_size 1, seq length 512]\tLoss: 0.006158\n",
      "17275it [41:46,  6.72it/s]Train epoch: 0 [batch #17275, batch_size 1, seq length 512]\tLoss: 0.008992\n",
      "17300it [41:50,  6.77it/s]Train epoch: 0 [batch #17300, batch_size 1, seq length 512]\tLoss: 0.008869\n",
      "17325it [41:54,  6.71it/s]Train epoch: 0 [batch #17325, batch_size 1, seq length 512]\tLoss: 0.008155\n",
      "17350it [41:58,  6.27it/s]Train epoch: 0 [batch #17350, batch_size 1, seq length 512]\tLoss: 0.007536\n",
      "17375it [42:01,  6.17it/s]Train epoch: 0 [batch #17375, batch_size 1, seq length 512]\tLoss: 0.007935\n",
      "17400it [42:05,  6.67it/s]Train epoch: 0 [batch #17400, batch_size 1, seq length 512]\tLoss: 0.010085\n",
      "17425it [42:09,  6.41it/s]Train epoch: 0 [batch #17425, batch_size 1, seq length 512]\tLoss: 0.006807\n",
      "17450it [42:13,  6.30it/s]Train epoch: 0 [batch #17450, batch_size 1, seq length 512]\tLoss: 0.007495\n",
      "17475it [42:17,  6.43it/s]Train epoch: 0 [batch #17475, batch_size 1, seq length 512]\tLoss: 0.008324\n",
      "17500it [42:21,  6.63it/s]Train epoch: 0 [batch #17500, batch_size 1, seq length 512]\tLoss: 0.008687\n",
      "17525it [42:24,  6.84it/s]Train epoch: 0 [batch #17525, batch_size 1, seq length 512]\tLoss: 0.008104\n",
      "17550it [42:28,  6.55it/s]Train epoch: 0 [batch #17550, batch_size 1, seq length 512]\tLoss: 0.008317\n",
      "17575it [42:32,  6.82it/s]Train epoch: 0 [batch #17575, batch_size 1, seq length 512]\tLoss: 0.007219\n",
      "17600it [42:35,  6.72it/s]Train epoch: 0 [batch #17600, batch_size 1, seq length 512]\tLoss: 0.008173\n",
      "17625it [42:39,  6.84it/s]Train epoch: 0 [batch #17625, batch_size 1, seq length 512]\tLoss: 0.009635\n",
      "17650it [42:43,  6.59it/s]Train epoch: 0 [batch #17650, batch_size 1, seq length 512]\tLoss: 0.010940\n",
      "17675it [42:46,  6.86it/s]Train epoch: 0 [batch #17675, batch_size 1, seq length 512]\tLoss: 0.009161\n",
      "17700it [42:50,  6.85it/s]Train epoch: 0 [batch #17700, batch_size 1, seq length 512]\tLoss: 0.007384\n",
      "17725it [42:54,  6.47it/s]Train epoch: 0 [batch #17725, batch_size 1, seq length 512]\tLoss: 0.006951\n",
      "17750it [42:58,  6.89it/s]Train epoch: 0 [batch #17750, batch_size 1, seq length 512]\tLoss: 0.007532\n",
      "17775it [43:01,  6.74it/s]Train epoch: 0 [batch #17775, batch_size 1, seq length 512]\tLoss: 0.006564\n",
      "17800it [43:05,  6.83it/s]Train epoch: 0 [batch #17800, batch_size 1, seq length 512]\tLoss: 0.007121\n",
      "17825it [43:09,  6.83it/s]Train epoch: 0 [batch #17825, batch_size 1, seq length 512]\tLoss: 0.008079\n",
      "17850it [43:13,  6.82it/s]Train epoch: 0 [batch #17850, batch_size 1, seq length 512]\tLoss: 0.008121\n",
      "17875it [43:16,  6.79it/s]Train epoch: 0 [batch #17875, batch_size 1, seq length 512]\tLoss: 0.007261\n",
      "17900it [43:20,  6.88it/s]Train epoch: 0 [batch #17900, batch_size 1, seq length 512]\tLoss: 0.008396\n",
      "17925it [43:24,  6.88it/s]Train epoch: 0 [batch #17925, batch_size 1, seq length 512]\tLoss: 0.006521\n",
      "17950it [43:27,  6.78it/s]Train epoch: 0 [batch #17950, batch_size 1, seq length 512]\tLoss: 0.007589\n",
      "17975it [43:31,  6.79it/s]Train epoch: 0 [batch #17975, batch_size 1, seq length 512]\tLoss: 0.009054\n",
      "18000it [43:35,  6.48it/s]Train epoch: 0 [batch #18000, batch_size 1, seq length 512]\tLoss: 0.010086\n",
      "18025it [43:39,  6.63it/s]Train epoch: 0 [batch #18025, batch_size 1, seq length 512]\tLoss: 0.008588\n",
      "18050it [43:43,  6.32it/s]Train epoch: 0 [batch #18050, batch_size 1, seq length 512]\tLoss: 0.008569\n",
      "18075it [43:46,  6.49it/s]Train epoch: 0 [batch #18075, batch_size 1, seq length 512]\tLoss: 0.008412\n",
      "18100it [43:50,  6.17it/s]Train epoch: 0 [batch #18100, batch_size 1, seq length 512]\tLoss: 0.007382\n",
      "18125it [43:54,  6.63it/s]Train epoch: 0 [batch #18125, batch_size 1, seq length 512]\tLoss: 0.006632\n",
      "18150it [43:58,  6.69it/s]Train epoch: 0 [batch #18150, batch_size 1, seq length 512]\tLoss: 0.007631\n",
      "18175it [44:02,  6.71it/s]Train epoch: 0 [batch #18175, batch_size 1, seq length 512]\tLoss: 0.007540\n",
      "18200it [44:05,  6.73it/s]Train epoch: 0 [batch #18200, batch_size 1, seq length 512]\tLoss: 0.006827\n",
      "18225it [44:09,  6.84it/s]Train epoch: 0 [batch #18225, batch_size 1, seq length 512]\tLoss: 0.009804\n",
      "18250it [44:13,  6.86it/s]Train epoch: 0 [batch #18250, batch_size 1, seq length 512]\tLoss: 0.008342\n",
      "18275it [44:16,  6.75it/s]Train epoch: 0 [batch #18275, batch_size 1, seq length 512]\tLoss: 0.007573\n",
      "18300it [44:20,  6.73it/s]Train epoch: 0 [batch #18300, batch_size 1, seq length 512]\tLoss: 0.008215\n",
      "18325it [44:24,  6.79it/s]Train epoch: 0 [batch #18325, batch_size 1, seq length 512]\tLoss: 0.008779\n",
      "18350it [44:27,  6.72it/s]Train epoch: 0 [batch #18350, batch_size 1, seq length 512]\tLoss: 0.006981\n",
      "18375it [44:31,  6.34it/s]Train epoch: 0 [batch #18375, batch_size 1, seq length 512]\tLoss: 0.006697\n",
      "18400it [44:35,  6.48it/s]Train epoch: 0 [batch #18400, batch_size 1, seq length 512]\tLoss: 0.007675\n",
      "18425it [44:39,  6.87it/s]Train epoch: 0 [batch #18425, batch_size 1, seq length 512]\tLoss: 0.008052\n",
      "18450it [44:43,  6.50it/s]Train epoch: 0 [batch #18450, batch_size 1, seq length 512]\tLoss: 0.007705\n",
      "18475it [44:46,  6.71it/s]Train epoch: 0 [batch #18475, batch_size 1, seq length 512]\tLoss: 0.006749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18500it [44:50,  6.73it/s]Train epoch: 0 [batch #18500, batch_size 1, seq length 512]\tLoss: 0.007758\n",
      "18525it [44:54,  6.75it/s]Train epoch: 0 [batch #18525, batch_size 1, seq length 512]\tLoss: 0.007961\n",
      "18550it [44:57,  6.85it/s]Train epoch: 0 [batch #18550, batch_size 1, seq length 512]\tLoss: 0.007274\n",
      "18575it [45:01,  6.87it/s]Train epoch: 0 [batch #18575, batch_size 1, seq length 512]\tLoss: 0.008203\n",
      "18600it [45:05,  6.71it/s]Train epoch: 0 [batch #18600, batch_size 1, seq length 512]\tLoss: 0.008367\n",
      "18625it [45:09,  6.67it/s]Train epoch: 0 [batch #18625, batch_size 1, seq length 512]\tLoss: 0.009031\n",
      "18650it [45:12,  6.65it/s]Train epoch: 0 [batch #18650, batch_size 1, seq length 512]\tLoss: 0.010247\n",
      "18675it [45:16,  6.47it/s]Train epoch: 0 [batch #18675, batch_size 1, seq length 512]\tLoss: 0.007902\n",
      "18700it [45:20,  6.80it/s]Train epoch: 0 [batch #18700, batch_size 1, seq length 512]\tLoss: 0.008027\n",
      "18725it [45:24,  6.41it/s]Train epoch: 0 [batch #18725, batch_size 1, seq length 512]\tLoss: 0.009043\n",
      "18728it [45:24,  6.37it/s]"
     ]
    }
   ],
   "source": [
    "# BERT-base 512 BPE\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert \\\n",
    "    50 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience 3 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --batch-size 1 \\\n",
    "    --gpu \\\n",
    "    --redefined_tokenizer \\\n",
    "    --last_module caml_attn \\\n",
    "    --max_sequence_length 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert-tiny-parallel-caml 4 3500 W2V\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny-parallel-caml \\\n",
    "    50 \\\n",
    "    --batch-size 2 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.3 \\\n",
    "    --patience 3 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-size 100 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --max_sequence_length 3500 \\\n",
    "    --last_module caml_attn \\\n",
    "    --bert_parallel_count 4 \\\n",
    "    --bert_parallel_final_layer sum \\\n",
    "    --cuda_device_no 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert-tiny 2500 BPE -> part2 notebook\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny \\\n",
    "    50 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience 3 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 4 \\\n",
    "    --last_module caml_attn \\\n",
    "    --redefine_tokenizer \\\n",
    "    --max_sequence_length 2500 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert-tiny pretrain BPE 2500 -> part2 notebook\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny \\\n",
    "    50 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience 3 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 4 \\\n",
    "    --last_module caml_attn \\\n",
    "    --redefined_tokenizer \\\n",
    "    --pretrain_lr 1e-4 \\\n",
    "    --pretrain-batch-size 2 \\\n",
    "    --pretrain \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('mlhc': conda)",
   "language": "python",
   "name": "python37764bitmlhcconda1212f3f7d082463bae9a49ba6e3c1c5e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
