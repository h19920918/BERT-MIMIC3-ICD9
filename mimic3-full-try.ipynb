{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir tokenizer\n",
    "!python create_tokenizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert-tiny 2500 word2vec\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny \\\n",
    "    50 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience \\\n",
    "    10 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 4 \\\n",
    "    --last_module caml_attn \\\n",
    "    --max_sequence_length 2500 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert-tiny 512 BPE\n",
    "!python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny \\\n",
    "    50 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience \\\n",
    "    10 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 4 \\\n",
    "    --last_module caml_attn \\\n",
    "    --redefine_tokenizer \\\n",
    "    --max_sequence_length 512 \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain\n",
    "CUDA_VISIBLE_DEVICES=3 python training.py \\\n",
    "    ./mimicdata/mimic3/train_full.csv \\\n",
    "    ./mimicdata/mimic3/vocab.csv \\\n",
    "    full \\\n",
    "    bert-tiny \\\n",
    "    50 \\\n",
    "    --filter-size 10 \\\n",
    "    --num-filter-maps 50 \\\n",
    "    --dropout 0.2 \\\n",
    "    --patience \\\n",
    "    10 \\\n",
    "    --criterion prec_at_8 \\\n",
    "    --lr 5e-5 \\\n",
    "    --embed-file ./mimicdata/mimic3/processed_full.embed \\\n",
    "    --gpu \\\n",
    "    --batch-size 4 \\\n",
    "    --last_module caml_attn \\\n",
    "    --pretrain-batch-size 1 \\\n",
    "    --pretrain \\\n",
    "    # --pos \\\n",
    "    # --pretrain-batch-size 2 \\\n",
    "    --redefined_tokenizer \\\n",
    "    # --pretrain \\\n",
    "    # --from_scratch \\\n",
    "    # conv_attn \\\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('mlhc': conda)",
   "language": "python",
   "name": "python37764bitmlhcconda1212f3f7d082463bae9a49ba6e3c1c5e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
